{"page_id": "develop-interoperability-intro-to-xcm", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 23, "end_char": 695, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot’s unique value lies in its ability to enable interoperability between parachains and other blockchain systems. At the core of this capability is XCM (Cross-Consensus Messaging)—a flexible messaging format that facilitates communication and collaboration between independent consensus systems.\n\nWith XCM, one chain can send intents to another one, fostering a more interconnected ecosystem. Although it was developed specifically for Polkadot, XCM is a universal format, usable in any blockchain environment. This guide provides an overview of XCM’s core principles, design, and functionality, alongside practical examples of its implementation."}
{"page_id": "develop-interoperability-intro-to-xcm", "index": 1, "depth": 2, "title": "Messaging Format", "anchor": "messaging-format", "start_char": 695, "end_char": 1569, "estimated_token_count": 153, "token_estimator": "heuristic-v1", "text": "## Messaging Format\n\nXCM is not a protocol but a standardized [messaging format](https://github.com/polkadot-fellows/xcm-format){target=\\_blank}. It defines the structure and behavior of messages but does not handle their delivery. This separation allows developers to focus on crafting instructions for target systems without worrying about transmission mechanics.\n\nXCM messages are intent-driven, outlining desired actions for the receiving blockchain to consider and potentially alter its state. These messages do not directly execute changes; instead, they rely on the host chain's environment to interpret and implement them. By utilizing asynchronous composability, XCM facilitates efficient execution where messages can be processed independently of their original order, similar to how RESTful services handle HTTP requests without requiring sequential processing."}
{"page_id": "develop-interoperability-intro-to-xcm", "index": 2, "depth": 2, "title": "The Four Principles of XCM", "anchor": "the-four-principles-of-xcm", "start_char": 1569, "end_char": 2505, "estimated_token_count": 174, "token_estimator": "heuristic-v1", "text": "## The Four Principles of XCM\n\nXCM adheres to four guiding principles that ensure robust and reliable communication across consensus systems:\n\n- **Asynchronous**: XCM messages operate independently of sender acknowledgment, avoiding delays due to blocked processes.\n- **Absolute**: XCM messages are guaranteed to be delivered and interpreted accurately, in order, and timely. Once a message is sent, one can be sure it will be processed as intended.\n- **Asymmetric**: XCM messages follow the 'fire and forget' paradigm meaning no automatic feedback is provided to the sender. Any results must be communicated separately to the sender with an additional message back to the origin.\n- **Agnostic**: XCM operates independently of the specific consensus mechanisms, making it compatible across diverse systems.\n\nThese principles guarantee that XCM provides a reliable framework for cross-chain communication, even in complex environments."}
{"page_id": "develop-interoperability-intro-to-xcm", "index": 3, "depth": 2, "title": "The XCM Tech Stack", "anchor": "the-xcm-tech-stack", "start_char": 2505, "end_char": 2867, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## The XCM Tech Stack\n\n![Diagram of the XCM tech stack](/images/develop/interoperability/intro-to-xcm/intro-to-xcm-01.webp)\n\nThe XCM tech stack is designed to facilitate seamless interoperable communication between chains that reside within the Polkadot ecosystem. XCM can be used to express the meaning of the messages over each of the communication channels."}
{"page_id": "develop-interoperability-intro-to-xcm", "index": 4, "depth": 2, "title": "Core Functionalities of XCM", "anchor": "core-functionalities-of-xcm", "start_char": 2867, "end_char": 3863, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## Core Functionalities of XCM\n\nXCM enhances cross-consensus communication by introducing several powerful features:\n\n- **Programmability**: Supports dynamic message handling, allowing for more comprehensive use cases. Includes branching logic, safe dispatches for version checks, and asset operations like NFT management.\n- **Functional Multichain Decomposition**: Enables mechanisms such as remote asset locking, asset namespacing, and inter-chain state referencing, with contextual message identification.\n- **Bridging**: Establishes a universal reference framework for multi-hop setups, connecting disparate systems like Ethereum and Bitcoin with the Polkadot relay chain acting as a universal location.\n\nThe standardized format for messages allows parachains to handle tasks like user balances, governance, and staking, freeing the Polkadot relay chain to focus on shared security. These features make XCM indispensable for implementing scalable and interoperable blockchain applications."}
{"page_id": "develop-interoperability-intro-to-xcm", "index": 5, "depth": 2, "title": "XCM Example", "anchor": "xcm-example", "start_char": 3863, "end_char": 6839, "estimated_token_count": 710, "token_estimator": "heuristic-v1", "text": "## XCM Example\n\nThe following is a simplified XCM message demonstrating a token transfer from Alice to Bob on the same chain (ParaA).\n\n```rust\n-let message = Xcm(vec![\n    WithdrawAsset((Here, amount).into()),\n    BuyExecution { \n        fees: (Here, amount).into(), \n        weight_limit: WeightLimit::Unlimited \n    },\n    DepositAsset {\n        assets: All.into(),\n        beneficiary: MultiLocation {\n            parents: 0,\n            interior: Junction::AccountId32 {\n                network: None,\n                id: BOB.clone().into()\n            }.into(),\n        }.into()\n    }\n]);\n```\n\nThe message consists of three instructions described as follows:\n\n- **[WithdrawAsset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#withdrawasset){target=\\_blank}**: Transfers a specified number of tokens from Alice's account to a holding register.\n\n    ```rust\n    -    WithdrawAsset((Here, amount).into()),\n    ```\n\n    - **`Here`**: The native parachain token.\n    - **`amount`**: The number of tokens that are transferred.\n\n    The first instruction takes as an input the MultiAsset that should be withdrawn. The MultiAsset describes the native parachain token with the `Here` keyword. The `amount` parameter is the number of tokens that are transferred. The withdrawal account depends on the origin of the message. In this example the origin of the message is Alice. The `WithdrawAsset` instruction moves `amount` number of native tokens from Alice's account into the holding register.\n\n- **[BuyExecution](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#buyexecution){target=\\_blank}**: Allocates fees to cover the execution [weight](/polkadot-protocol/glossary/#weight){target=\\_blank} of the XCM instructions.\n\n    ```rust\n    -    BuyExecution { \n        fees: (Here, amount).into(), \n        weight_limit: WeightLimit::Unlimited \n    },\n    ```\n\n    - **`fees`**: Describes the asset in the holding register that should be used to pay for the weight.\n    - **`weight_limit`**: Defines the maximum fees that can be used to buy weight.\n\n- **[DepositAsset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#depositasset){target=\\_blank}**: Moves the remaining tokens from the holding register to Bob’s account.\n\n    ```rust\n    -    DepositAsset {\n        assets: All.into(),\n        beneficiary: MultiLocation {\n            parents: 0,\n            interior: Junction::AccountId32 {\n                network: None,\n                id: BOB.clone().into()\n            }.into(),\n        }.into()\n    }\n    ```\n\n    - **`All`**: The wildcard for the asset(s) to be deposited. In this case, all assets in the holding register should be deposited.\n    \nThis step-by-step process showcases how XCM enables precise state changes within a blockchain system. You can find a complete XCM message example in the [XCM repository](https://github.com/paritytech/xcm-docs/blob/main/examples/src/0_first_look/mod.rs){target=\\_blank}."}
{"page_id": "develop-interoperability-intro-to-xcm", "index": 6, "depth": 2, "title": "Overview", "anchor": "overview", "start_char": 6839, "end_char": 7412, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "## Overview\n\nXCM revolutionizes cross-chain communication by enabling use cases such as:\n\n- Token transfers between blockchains.\n- Asset locking for cross-chain smart contract interactions.\n- Remote execution of functions on other blockchains.\n\nThese functionalities empower developers to build innovative, multi-chain applications, leveraging the strengths of various blockchain networks. To stay updated on XCM’s evolving format or contribute, visit the [XCM repository](https://github.com/paritytech/xcm-docs/blob/main/examples/src/0_first_look/mod.rs){target=\\_blank}."}
{"page_id": "develop-interoperability-send-messages", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 917, "estimated_token_count": 181, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nOne of the core FRAME pallets that enables parachains to engage in cross-chain communication using the Cross-Consensus Message (XCM) format is [`pallet-xcm`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/index.html){target=\\_blank}. It facilitates the sending, execution, and management of XCM messages, thereby allowing parachains to interact with other chains within the ecosystem. Additionally, `pallet-xcm`, also referred to as the XCM pallet, supports essential operations like asset transfers, version negotiation, and message routing.\n\nThis page provides a detailed overview of the XCM pallet's key features, its primary roles in XCM operations, and the main extrinsics it offers. Whether aiming to execute XCM messages locally or send them to external chains, this guide covers the foundational concepts and practical applications you need to know."}
{"page_id": "develop-interoperability-send-messages", "index": 1, "depth": 2, "title": "XCM Frame Pallet Overview", "anchor": "xcm-frame-pallet-overview", "start_char": 917, "end_char": 2612, "estimated_token_count": 439, "token_estimator": "heuristic-v1", "text": "## XCM Frame Pallet Overview\n\nThe [`pallet-xcm`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/index.html){target=\\_blank} provides a set of pre-defined, commonly used [XCVM programs](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#12-the-xcvm){target=\\_blank} in the form of a [set of extrinsics](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/dispatchables/index.html){target=\\blank}. This pallet provides some [default implementations](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/struct.Pallet.html#implementations){target=\\_blank} for traits required by [`XcmConfig`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm_benchmarks/trait.Config.html#associatedtype.XcmConfig){target=\\_blank}. The [XCM executor](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/struct.XcmExecutor.html){target=\\_blank} is also included as an associated type within the pallet's configuration. \n\nFor further details about the XCM configuration, see the [XCM Configuration](/develop/interoperability/xcm-config/){target=\\_blank} page.\n\nWhere the [XCM format](https://github.com/polkadot-fellows/xcm-format){target=\\_blank} defines a set of instructions used to construct XCVM programs, `pallet-xcm` defines a set of extrinsics that can be utilized to build XCVM programs, either to target the local or external chains. The `pallet-xcm` functionality is divided into three categories:\n\n- **Primitive**: Dispatchable functions to execute XCM locally.\n- **High-level**: Functions for asset transfers between chains.\n- **Version negotiation-specific**: Functions for managing XCM version compatibility."}
{"page_id": "develop-interoperability-send-messages", "index": 2, "depth": 3, "title": "Key Roles of the XCM Pallet", "anchor": "key-roles-of-the-xcm-pallet", "start_char": 2612, "end_char": 3620, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "### Key Roles of the XCM Pallet\n\nThe XCM pallet plays a central role in managing cross-chain messages, with its primary responsibilities including:\n\n- **Execute XCM messages**: Interacts with the XCM executor to validate and execute messages, adhering to predefined security and filter criteria.\n- **Send messages across chains**: Allows authorized origins to send XCM messages, enabling controlled cross-chain communication.\n- **Reserve-based transfers and teleports**: Supports asset movement between chains, governed by filters that restrict operations to authorized origins.\n- **XCM version negotiation**: Ensures compatibility by selecting the appropriate XCM version for inter-chain communication.\n- **Asset trapping and recovery**: Manages trapped assets, enabling safe reallocation or recovery when issues occur during cross-chain transfers.\n- **Support for XCVM operations**: Oversees state and configuration requirements necessary for executing cross-consensus programs within the XCVM framework."}
{"page_id": "develop-interoperability-send-messages", "index": 3, "depth": 2, "title": "Primary Extrinsics of the XCM Pallet", "anchor": "primary-extrinsics-of-the-xcm-pallet", "start_char": 3620, "end_char": 3820, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Primary Extrinsics of the XCM Pallet\n\nThis page will highlight the two **Primary Primitive Calls** responsible for sending and executing XCVM programs as dispatchable functions within the pallet."}
{"page_id": "develop-interoperability-send-messages", "index": 4, "depth": 3, "title": "Execute", "anchor": "execute", "start_char": 3820, "end_char": 5071, "estimated_token_count": 298, "token_estimator": "heuristic-v1", "text": "### Execute\n\nThe [`execute`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/enum.Call.html#variant.execute){target=\\_blank} call directly interacts with the XCM executor, allowing for the execution of XCM messages originating from a locally signed origin. The executor validates the message, ensuring it complies with any configured barriers or filters before executing.\n\nOnce validated, the message is executed locally, and an event is emitted to indicate the result—whether the message was fully executed or only partially completed. Execution is capped by a maximum weight ([`max_weight`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/enum.Call.html#variant.execute.field.max_weight){target=\\_blank}); if the required weight exceeds this limit, the message will not be executed.\n\n```rust\npub fn execute<T: Config>(\n    message: Box<VersionedXcm<<T as Config>::RuntimeCall>>,\n    max_weight: Weight,\n)\n```\n\nFor further details about the `execute` extrinsic, see the [`pallet-xcm` documentation](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/struct.Pallet.html){target=\\_blank}.\n\n!!!warning\n    Partial execution of messages may occur depending on the constraints or barriers applied."}
{"page_id": "develop-interoperability-send-messages", "index": 5, "depth": 3, "title": "Send", "anchor": "send", "start_char": 5071, "end_char": 6081, "estimated_token_count": 254, "token_estimator": "heuristic-v1", "text": "### Send\n\nThe [`send`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/enum.Call.html#variant.send){target=\\_blank} call enables XCM messages to be sent to a specified destination. This could be a parachain, smart contract, or any external system governed by consensus. Unlike the execute call, the message is not executed locally but is transported to the destination chain for processing.\n\nThe destination is defined using a [Location](https://paritytech.github.io/polkadot-sdk/master/xcm_docs/glossary/index.html#location){target=\\_blank}, which describes the target chain or system. This ensures precise delivery through the configured XCM transport mechanism.\n\n```rust\npub fn send<T: Config>(\n    dest: Box<MultiLocation>,\n    message: Box<VersionedXcm<<T as Config>::RuntimeCall>>,\n)\n```\n\nFor further information about the `send` extrinsic, see the [`pallet-xcm` documentation](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/struct.Pallet.html){target=\\_blank}."}
{"page_id": "develop-interoperability-send-messages", "index": 6, "depth": 2, "title": "XCM Router", "anchor": "xcm-router", "start_char": 6081, "end_char": 7225, "estimated_token_count": 261, "token_estimator": "heuristic-v1", "text": "## XCM Router\n\nThe [`XcmRouter`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/trait.Config.html#associatedtype.XcmRouter){target=\\_blank} is a critical component the XCM pallet requires to facilitate sending XCM messages. It defines where messages can be sent and determines the appropriate XCM transport protocol for the operation.\n\nFor instance, the Kusama network employs the [`ChildParachainRouter`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_common/xcm_sender/struct.ChildParachainRouter.html){target=\\_blank}, which restricts routing to [Downward Message Passing (DMP)](https://wiki.polkadot.com/learn/learn-xcm-transport/#dmp-downward-message-passing){target=\\_blank} from the relay chain to parachains, ensuring secure and controlled communication.\n\n```rust\n-pub type XcmRouter = WithUniqueTopic<(\n\t// Only one router so far - use DMP to communicate with child parachains.\n\tChildParachainRouter<Runtime, XcmPallet, PriceForChildParachainDelivery>,\n)>;\n```\n\nFor more details about XCM transport protocols, see the [XCM Channels](/develop/interoperability/xcm-channels/){target=\\_blank} page."}
{"page_id": "develop-interoperability-test-and-debug", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 25, "end_char": 875, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nCross-Consensus Messaging (XCM) is a core feature of the Polkadot ecosystem, enabling communication between parachains, relay chains, and system chains. To ensure the reliability of XCM-powered blockchains, thorough testing and debugging are essential before production deployment.\n\nThis guide covers the XCM Emulator, a tool designed to facilitate onboarding and testing for developers. Use the emulator if:\n\n- A live runtime is not yet available.\n- Extensive configuration adjustments are needed, as emulated chains differ from live networks.\n- Rust-based tests are preferred for automation and integration.\n\nFor scenarios where real blockchain state is required, [Chopsticks](/tutorials/polkadot-sdk/testing/fork-live-chains/#xcm-testing){target=\\_blank} allows testing with any client compatible with Polkadot SDK-based chains."}
{"page_id": "develop-interoperability-test-and-debug", "index": 1, "depth": 2, "title": "XCM Emulator", "anchor": "xcm-emulator", "start_char": 875, "end_char": 2024, "estimated_token_count": 223, "token_estimator": "heuristic-v1", "text": "## XCM Emulator\n\nSetting up a live network with multiple interconnected parachains for XCM testing can be complex and resource-intensive. \n\nThe [`xcm-emulator`](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/cumulus/xcm/xcm-emulator){target=\\_blank} is a tool designed to simulate the execution of XCM programs using predefined runtime configurations. These configurations include those utilized by live networks like Kusama, Polkadot, and Asset Hub.\n\nThis tool enables testing of cross-chain message passing, providing a way to verify outcomes, weights, and side effects efficiently. It achieves this by utilizing mocked runtimes for both the relay chain and connected parachains, enabling developers to focus on message logic and configuration without needing a live network.\n\nThe `xcm-emulator` relies on transport layer pallets. However, the messages do not leverage the same messaging infrastructure as live networks since the transport mechanism is mocked. Additionally, consensus-related events are not covered, such as disputes and staking events. Parachains should use end-to-end (E2E) tests to validate these events."}
{"page_id": "develop-interoperability-test-and-debug", "index": 2, "depth": 3, "title": "Advantages and Limitations", "anchor": "advantages-and-limitations", "start_char": 2024, "end_char": 3128, "estimated_token_count": 219, "token_estimator": "heuristic-v1", "text": "### Advantages and Limitations\n\nThe XCM Emulator provides both advantages and limitations when testing cross-chain communication in simulated environments.\n\n- **Advantages**:\n    - **Interactive debugging**: Offers tracing capabilities similar to EVM, enabling detailed analysis of issues.\n    - **Runtime composability**: Facilitates testing and integration of multiple runtime components.\n    - **Immediate feedback**: Supports Test-Driven Development (TDD) by providing rapid test results.\n    - **Seamless integration testing**: Simplifies the process of testing new runtime versions in an isolated environment.\n\n- **Limitations**:\n    - **Simplified emulation**: Always assumes message delivery, which may not mimic real-world network behavior.\n    - **Dependency challenges**: Requires careful management of dependency versions and patching. Refer to the [Cargo dependency documentation](https://doc.rust-lang.org/cargo/reference/overriding-dependencies.html){target=\\_blank}.\n    - **Compilation overhead**: Testing environments can be resource-intensive, requiring frequent compilation updates."}
{"page_id": "develop-interoperability-test-and-debug", "index": 3, "depth": 3, "title": "How Does It Work?", "anchor": "how-does-it-work", "start_char": 3128, "end_char": 7439, "estimated_token_count": 873, "token_estimator": "heuristic-v1", "text": "### How Does It Work?\n\nThe `xcm-emulator` provides macros for defining a mocked testing environment. Check all the existing macros and functionality in the [XCM Emulator source code](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/cumulus/xcm/xcm-emulator/src/lib.rs){target=\\_blank}. The most important macros are:\n\n- **[`decl_test_relay_chains`](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/cumulus/xcm/xcm-emulator/src/lib.rs#L361){target=\\_blank}**: Defines runtime and configuration for the relay chains. Example:\n\n    ```rust\n    -decl_test_relay_chains! {\n\t#[api_version(13)]\n\tpub struct Westend {\n\t\tgenesis = genesis::genesis(),\n\t\ton_init = (),\n\t\truntime = westend_runtime,\n\t\tcore = {\n\t\t\tSovereignAccountOf: westend_runtime::xcm_config::LocationConverter,\n\t\t},\n\t\tpallets = {\n\t\t\tXcmPallet: westend_runtime::XcmPallet,\n\t\t\tSudo: westend_runtime::Sudo,\n\t\t\tBalances: westend_runtime::Balances,\n\t\t\tTreasury: westend_runtime::Treasury,\n\t\t\tAssetRate: westend_runtime::AssetRate,\n\t\t\tHrmp: westend_runtime::Hrmp,\n\t\t\tIdentity: westend_runtime::Identity,\n\t\t\tIdentityMigrator: westend_runtime::IdentityMigrator,\n\t\t}\n\t},\n}\n    ```\n\n- **[`decl_test_parachains`](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/cumulus/xcm/xcm-emulator/src/lib.rs#L596){target=\\_blank}**: Defines runtime and configuration for parachains. Example:\n\n    ```rust\n    -decl_test_parachains! {\n\tpub struct AssetHubWestend {\n\t\tgenesis = genesis::genesis(),\n\t\ton_init = {\n\t\t\tasset_hub_westend_runtime::AuraExt::on_initialize(1);\n\t\t},\n\t\truntime = asset_hub_westend_runtime,\n\t\tcore = {\n\t\t\tXcmpMessageHandler: asset_hub_westend_runtime::XcmpQueue,\n\t\t\tLocationToAccountId: asset_hub_westend_runtime::xcm_config::LocationToAccountId,\n\t\t\tParachainInfo: asset_hub_westend_runtime::ParachainInfo,\n\t\t\tMessageOrigin: cumulus_primitives_core::AggregateMessageOrigin,\n\t\t\tDigestProvider: (),\n\t\t},\n\t\tpallets = {\n\t\t\tPolkadotXcm: asset_hub_westend_runtime::PolkadotXcm,\n\t\t\tBalances: asset_hub_westend_runtime::Balances,\n\t\t\tAssets: asset_hub_westend_runtime::Assets,\n\t\t\tForeignAssets: asset_hub_westend_runtime::ForeignAssets,\n\t\t\tPoolAssets: asset_hub_westend_runtime::PoolAssets,\n\t\t\tAssetConversion: asset_hub_westend_runtime::AssetConversion,\n\t\t\tSnowbridgeSystemFrontend: asset_hub_westend_runtime::SnowbridgeSystemFrontend,\n\t\t\tRevive: asset_hub_westend_runtime::Revive,\n\t\t}\n\t},\n}\n    ```\n\n- **[`decl_test_bridges`](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/cumulus/xcm/xcm-emulator/src/lib.rs#L1221){target=\\_blank}**: Creates bridges between chains, specifying the source, target, and message handler. Example:\n\n    ```rust\n    -decl_test_bridges! {\n\tpub struct RococoWestendMockBridge {\n\t\tsource = BridgeHubRococoPara,\n\t\ttarget = BridgeHubWestendPara,\n\t\thandler = RococoWestendMessageHandler\n\t},\n\tpub struct WestendRococoMockBridge {\n\t\tsource = BridgeHubWestendPara,\n\t\ttarget = BridgeHubRococoPara,\n\t\thandler = WestendRococoMessageHandler\n\t}\n}\n    ```\n\n- **[`decl_test_networks`](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/cumulus/xcm/xcm-emulator/src/lib.rs#L958){target=\\_blank}**: Defines a testing network with relay chains, parachains, and bridges, implementing message transport and processing logic. Example:\n\n    ```rust\n    -decl_test_networks! {\n\tpub struct WestendMockNet {\n\t\trelay_chain = Westend,\n\t\tparachains = vec![\n\t\t\tAssetHubWestend,\n\t\t\tBridgeHubWestend,\n\t\t\tCollectivesWestend,\n\t\t\tCoretimeWestend,\n\t\t\tPeopleWestend,\n\t\t\tPenpalA,\n\t\t\tPenpalB,\n\t\t],\n\t\tbridge = ()\n\t},\n}\n    ```\n\nBy leveraging these macros, developers can customize their testing networks by defining relay chains and parachains tailored to their needs. For guidance on implementing a mock runtime for a Polkadot SDK-based chain, refer to the [Pallet Testing](/develop/parachains/testing/pallet-testing/){target=\\_blank} article. \n\nThis framework enables thorough testing of runtime and cross-chain interactions, enabling developers to effectively design, test, and optimize cross-chain functionality.\n\nTo see a complete example of implementing and executing tests, refer to the [integration tests](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/cumulus/parachains/integration-tests/emulated){target=\\_blank} in the Polkadot SDK repository."}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 0, "depth": 2, "title": "The problem before v5", "anchor": "the-problem-before-v5", "start_char": 446, "end_char": 932, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "## The problem before v5\n\nWhen XCM execution failed and assets became trapped:\n\n- **Governance dependency**: Most trapped asset recovery requires governance proposals.\n- **Complex procedures**: Manual intervention through referendum processes.\n- **Long delays**: Recovery could take weeks or months through governance.\n- **Risk of loss**: Assets could remain permanently trapped if governance didn't act.\n- **High barriers**: Small amounts often weren't worth the governance overhead."}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 1, "depth": 2, "title": "The V5 Solution: `AssetClaimer` Hint", "anchor": "the-v5-solution-assetclaimer-hint", "start_char": 932, "end_char": 1343, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## The V5 Solution: `AssetClaimer` Hint\n\nThe new [`AssetClaimer`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Hint.html#variant.AssetClaimer){target=\\_blank} hint allows XCM programs to preemptively designate who can claim trapped assets:\n\n```typescript\n// Set asset claimer before risky operations\nXcmV5Instruction.SetHints({ \n  hints: [Enum('AssetClaimer', claimerLocation)] \n})\n```"}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 2, "depth": 2, "title": "How it Improves the Situation", "anchor": "how-it-improves-the-situation", "start_char": 1343, "end_char": 2490, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "## How it Improves the Situation\n\nThe `AssetClaimer` hint transforms the recovery process by allowing proactive designation of claimers, eliminating the need for governance intervention in most cases.\n\n- **Before XCM V5:**\n\n    ```typescript\n    // If this XCM fails, assets become trapped\n    const riskyXcm = [\n        XcmInstruction.WithdrawAsset([assets]),\n        XcmInstruction.BuyExecution({ fees, weight_limit }),\n        XcmInstruction.Transact({ /* risky call */ }),\n        XcmInstruction.DepositAsset({ assets, beneficiary })\n    ]\n\n    // Recovery required governance intervention\n    ```\n\n- **With XCM V5:**\n\n    ```typescript\n    // Proactive asset claimer setup\n    const saferXcm = [\n        // Anyone can now claim if execution fails\n        XcmV5Instruction.SetHints({ \n            hints: [Enum('AssetClaimer', claimerLocation)] \n        }),\n        XcmV5Instruction.WithdrawAsset([assets]),\n        XcmV5Instruction.PayFees({ asset }),\n        XcmV5Instruction.Transact({ /* risky call */ }),\n        XcmV5Instruction.DepositAsset({ assets, beneficiary })\n    ]\n\n    // Recovery can be done immediately by the claimer\n    ```"}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 3, "depth": 2, "title": "Key Improvements", "anchor": "key-improvements", "start_char": 2490, "end_char": 3242, "estimated_token_count": 168, "token_estimator": "heuristic-v1", "text": "## Key Improvements\n\nThe `AssetClaimer` hint addresses several critical pain points in trapped asset recovery, transforming the process from governance-dependent to user-controlled.\n\n| Feature | Before XCM V5 | After XCM V5 |\n| :-----: | :-----------: | :----------: |\n| **Recovery Speed** | Wait for governance process (weeks/months) | Designated claimer can act immediately |\n| **Governance Burden** | Every trapped asset requires a governance proposal | Only complex cases need governance intervention |\n| **Recovery Predictability** | Uncertain if governance would approve recovery | Predetermined claimer provides certainty |\n| **Accessibility** | Small amounts are often not worth governance overhead | Any amount can be efficiently recovered |"}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 4, "depth": 2, "title": "Best Practices", "anchor": "best-practices", "start_char": 3242, "end_char": 3398, "estimated_token_count": 26, "token_estimator": "heuristic-v1", "text": "## Best Practices\n\nFollowing these best practices ensures effective use of the `AssetClaimer` hint and maximizes the benefits of automated asset recovery."}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 5, "depth": 3, "title": "Set Hint Early", "anchor": "set-hint-early", "start_char": 3398, "end_char": 3767, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "### Set Hint Early\n\nAlways set the `AssetClaimer` hint before any operations that might fail, ensuring trapped assets can be recovered immediately without governance intervention.\n\n```typescript\n// Set claimer hint before any risky operations\nXcmV5Instruction.SetHints({ hints: [Enum('AssetClaimer', claimerLocation)] }),\n// ... other instructions that might fail\n```"}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 6, "depth": 3, "title": "Use for Cross-Chain Transfers", "anchor": "use-for-cross-chain-transfers", "start_char": 3767, "end_char": 4151, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "### Use for Cross-Chain Transfers\n\nParticularly useful for setting local accounts on destination chains:\n\n```typescript\n// In remote_xcm for cross-chain transfers\nconst remoteXcm = [\n  XcmV5Instruction.SetHints({ \n    hints: [Enum('AssetClaimer', {\n      parents: 0,\n      interior: { X1: { AccountId32: { id: localAccountId } } }\n    })] \n  }),\n  // ... transfer instructions\n]\n```"}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 7, "depth": 3, "title": "Consider Origin Preservation", "anchor": "consider-origin-preservation", "start_char": 4151, "end_char": 4344, "estimated_token_count": 29, "token_estimator": "heuristic-v1", "text": "### Consider Origin Preservation\n\nWhen origin preservation is available, trapped assets are automatically associated with the original origin, making claiming easier without additional hints."}
{"page_id": "develop-interoperability-versions-v5-asset-claimer", "index": 8, "depth": 2, "title": "Migration Impact", "anchor": "migration-impact", "start_char": 4344, "end_char": 5080, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "## Migration Impact\n\nThe introduction of the `AssetClaimer` hint represents a significant improvement in XCM's fault tolerance and user experience, making cross-chain operations safer and more predictable.\n\nThis change makes XCM programs more resilient and user-friendly:\n\n- **Reduced risk**: Assets are less likely to be permanently lost.\n- **Better UX**: Users can recover their own assets without waiting for governance.\n- **Increased adoption**: Lower risk encourages more XCM usage.\n- **Operational efficiency**: Reduces governance workload for routine recoveries.\n\nThe `AssetClaimer` hint represents a significant improvement in XCM's fault tolerance and user experience, making cross-chain operations safer and more predictable."}
{"page_id": "develop-interoperability-versions-v5-fees", "index": 0, "depth": 2, "title": "Key Changes from V4", "anchor": "key-changes-from-v4", "start_char": 153, "end_char": 562, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## Key Changes from V4\n\nXCM V5 replaces the [`BuyExecution`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.BuyExecution){target=\\_blank} instruction with a more predictable [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.PayFees){target=\\_blank} approach that handles both execution and delivery fees."}
{"page_id": "develop-interoperability-versions-v5-fees", "index": 1, "depth": 3, "title": "BuyExecution vs. PayFees", "anchor": "buyexecution-vs-payfees", "start_char": 562, "end_char": 1160, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### BuyExecution vs. PayFees\n\n- **XCM V4 Approach:**\n\n    - Used `BuyExecution` instruction that handles only execution fees.\n    - Leftover assets after buying execution are returned to holding.\n    - Required explicit specification of execution weight limits.\n    - Delivery fees may not be found, and an error may occur.\n\n- **XCM V5 Approach:**\n\n    - Introduces `PayFees` instruction for unified fee handling.\n    - All assets passed to `PayFees` are kept in a special `fees` register; they are _NOT_ returned to holding.\n    - No need to specify weights, only assets.\n    - More predictable."}
{"page_id": "develop-interoperability-versions-v5-fees", "index": 2, "depth": 3, "title": "PayFees Instruction", "anchor": "payfees-instruction", "start_char": 1160, "end_char": 1759, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "### PayFees Instruction\n\nThe new `PayFees` instruction provides a cleaner interface:\n\n```typescript\n// XCM V5 - New PayFees instruction\nXcmV5Instruction.PayFees({\n  asset: {\n    id: // Asset id for fee payment\n    fun: // Amount to dedicate for fees (both execution + delivery)\n  },\n})\n```\n\nThis replaces the more complex `BuyExecution` pattern:\n\n```typescript\n// XCM V4 - BuyExecution instruction\nXcmV4Instruction.BuyExecution({\n  fees: {\n    id: // Asset id\n    fun: // Fee amount (only execution will be charged, rest is returned to holding)\n  },\n  weight_limit: // Explicit weight limit\n})\n```"}
{"page_id": "develop-interoperability-versions-v5-fees", "index": 3, "depth": 2, "title": "Backward Compatibility", "anchor": "backward-compatibility", "start_char": 1759, "end_char": 2099, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Backward Compatibility\n\nXCM V5 maintains backward compatibility with `BuyExecution` for existing implementations. Both instructions are supported, allowing gradual migration:\n\n- **BuyExecution**: Still supported for compatibility with existing XCM programs.\n- **PayFees**: Recommended for new development and simplified fee management."}
{"page_id": "develop-interoperability-versions-v5-fees", "index": 4, "depth": 2, "title": "Migration Considerations", "anchor": "migration-considerations", "start_char": 2099, "end_char": 2681, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Migration Considerations\n\nWhen migrating from XCM V4 to XCM V5:\n\n- `BuyExecution` can remain in existing programs.\n- New programs should use `PayFees` for better maintainability.\n- Fee estimation becomes more straightforward with the new approach.\n- No breaking changes to existing functionality.\n\nWhen using `PayFees`, keep in mind that _ALL_ assets passed to the instruction will be entirely dedicated to fees, not returned to holding.\nThat's why it's more important than before to [to estimate XCM fees properly](/develop/interoperability/xcm-runtime-apis/){target=\\_blank}."}
{"page_id": "develop-interoperability-versions-v5-fees", "index": 5, "depth": 2, "title": "`RefundSurplus` Instruction", "anchor": "refundsurplus-instruction", "start_char": 2681, "end_char": 4145, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "## `RefundSurplus` Instruction\n\nWhen you overestimate fees with [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.PayFees){target=\\_blank}, you can recover unused funds using the [`RefundSurplus`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.RefundSurplus){target=\\_blank} instruction.\n\nYou can use `RefundSurplus` to put the leftover fees back into holding. This is useful when you've overestimated the fees needed for your XCM program. You can then deposit them into some account with [`DepositAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.DepositAsset){target=\\_blank}.\n\n```typescript\n// After all instructions that send messages.\nXcmV5Instruction.RefundSurplus(),\nXcmV5Instruction.DepositAsset({\n  assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.All()),\n  beneficiary: {\n    parents: 0,\n    interior: XcmV5Junctions.X1(\n      XcmV5Junction.AccountId32({\n        id: ACCOUNT,\n        network: undefined,\n      }),\n    ),\n  }\n})\n```\n\nThe `RefundSurplus` instruction:\n\n- Takes any unused fees from the fees register.\n- Moves them back to the holding register.\n- Allows you to use or return the surplus assets with `DepositAsset`.\n\nThis is especially important with `PayFees` since all assets passed to it are dedicated to fees, unlike `BuyExecution` which automatically returned unused assets to holding."}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 0, "depth": 2, "title": "When to migrate", "anchor": "when-to-migrate", "start_char": 245, "end_char": 1319, "estimated_token_count": 240, "token_estimator": "heuristic-v1", "text": "## When to migrate\n\nMigrating to XCM V5 provides significant benefits, so migration is recommended as soon as possible.\n\nWhether migration is possible depends mainly on if the target chains have already upgraded to XCM V5 or not.\n\nTo determine whether a chain supports XCM V5:\n\n- Read the changelog.\n- Explore the metadata with PAPI's descriptors.\n- Explore the metadata with a tool like [subwasm](https://github.com/chevdor/subwasm){target=\\_blank}.\n\nFor example, when generating PAPI descriptors for a chain, you can check if the `XcmVersionedXcm` known type has the V5 variant.\n\n```bash\nnpx papi add myChain -w <INSERT_RPC_WEB_SOCKET_ENDPOINT>\n```\n\nEnsure to replace the `<INSERT_RPC_WEB_SOCKET_ENDPOINT>` with the actual RPC web socket endpoint of the chain.\n\nAlternatively, you can navigate to the [PAPI developer console](https://dev.papi.how/extrinsics){target=\\_blank}, connect to the chain, and under extrinsics choose `PolkadotXcm -> execute` and check for the V5 variant:\n\n![](/images/develop/interoperability/versions/v5/migration-guide/check-xcm-version.webp)"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 1, "depth": 2, "title": "Key Changes", "anchor": "key-changes", "start_char": 1319, "end_char": 1335, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Key Changes"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 2, "depth": 3, "title": "From Dedicated Extrinsics to Raw XCMs", "anchor": "from-dedicated-extrinsics-to-raw-xcms", "start_char": 1335, "end_char": 3773, "estimated_token_count": 565, "token_estimator": "heuristic-v1", "text": "### From Dedicated Extrinsics to Raw XCMs\n\nWith XCM V5, the ecosystem is shifting toward writing XCM programs directly instead of relying on an ever-increasing number of custom extrinsics.\n\n- **Before (XCM V4)**:\n\n    ```typescript\n    // Multiple extrinsics for different scenarios\n    api.tx.xcmPallet.teleportAssets(...)\n    api.tx.xcmPallet.limitedReserveTransferAssets(...)\n    api.tx.xcmPallet.limitedTeleportAssets(...)\n    ```\n\n- **After (XCM V5)**:\n\n    ```typescript\n    // Single pattern: craft XCM + execute\n    const xcm = XcmVersionedXcm.V5([\n    XcmV5Instruction.WithdrawAsset([...]),\n    XcmV5Instruction.PayFees({...}),\n    XcmV5Instruction.InitiateTransfer({...}),\n    ]);\n    const weight = api.apis.XcmPaymentApi.query_xcm_weight(xcm);\n\n    api.tx.PolkadotXcm.execute({\n    message: xcm,\n    max_weight: weight.value,\n    });\n    ```\n\nMigration Impact:\n\n- More verbose but significantly more flexible.\n- Need to calculate weights using runtime APIs.\n- Better control over execution flow.\n\n!!! note \"Is this `execute` new?\"\n\n    The XCM pallet has always had it, however, in previous versions of XCM (2 and below) it wasn't safe\n    to have it enabled for anyone to use. That's why some chains might have it disabled.\n\nThis approach adds more flexibility but clearly requires the developer to know how to build XCMs.\nIf XCM construction is unfamiliar, this approach enables other developers to build SDKs that handle these complexities.\n\nFor example, the [Paraspell SDK](https://paraspell.xyz){target=\\_blank} enables cross-chain transfers (and much more!) with a very simple API. The following example transfers 10 DOT from Asset Hub Polkadot to Hydration chain using the Paraspell SDK's builder pattern:\n\n```typescript\nimport { Builder } from '@paraspell/sdk';\n\nconst tx = await Builder()\n    .from('AssetHubPolkadot')\n    .to('Hydration')\n    .currency({ symbol: 'DOT', amount: '10000000000' })\n    .address(beneficiary)\n    .build();\nconst result = await tx.signAndSubmit(signer);\n```\n\n!!! note \"Are the extrinsics going away?\"\n\n    No! The extrinsics will continue to be supported in the XCM pallet for an undefined period of time. Although it is expected that as more chains support XCM V5 and more dApp developers use [execute](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/struct.Pallet.html#method.execute){target=\\_blank},\n    they'll reap the benefits and no longer require extrinsics."}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 3, "depth": 3, "title": "Unified Transfer Instructions", "anchor": "unified-transfer-instructions", "start_char": 3773, "end_char": 4793, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "### Unified Transfer Instructions\n\nBeyond the shift to direct XCM execution, XCM V5 also consolidates transfer operations into a single, more powerful instruction.\n\n- **Before (XCM V4)**:\n\n    ```typescript\n    // Different instructions for different transfer types\n    XcmV4Instruction.InitiateTeleport({\n    assets,\n    dest: destination,\n    xcm: remoteXcm,\n    })\n\n    XcmV4Instruction.InitiateReserveWithdraw({\n    assets,\n    reserve: reserveLocation,\n    xcm: remoteXcm,\n    })\n    ```\n\n- **After (XCM V5)**:\n\n    ```typescript\n    // Single instruction with transfer type specified per asset.\n    XcmV5Instruction.InitiateTransfer({\n    destination: destination,\n    remote_fees: Enum('Teleport', feeAssets),\n    assets: [\n        Enum('Teleport', teleportAssets),\n        Enum('ReserveWithdraw', reserveAssets),\n    ],\n    remote_xcm: remoteXcm,\n    preserve_origin: false,\n    })\n    ```\n\nMigration Benefits:\n\n- Different transfer types in single operation\n- Clearer fee handling\n- Origin preservation option"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 4, "depth": 3, "title": "Predictable fee payment", "anchor": "predictable-fee-payment", "start_char": 4793, "end_char": 7410, "estimated_token_count": 550, "token_estimator": "heuristic-v1", "text": "### Predictable fee payment\n\n- **Before (XCM V4)**:\n\n    ```typescript\n    // Fees embedded in transfer instructions.\n    // Limited control over fee allocation.\n    api.tx.xcmPallet.limitedTeleportAssets({\n    dest: destination,\n    beneficiary: beneficiary,\n    assets: assets,\n    fee_asset_item: 0, // Index-based fee selection.\n    weight_limit: weightLimit,\n    })\n    ```\n\n- **After (XCM V5)**:\n\n    ```typescript\n    // Explicit fee management.\n    XcmV5Instruction.PayFees({\n    asset: {\n        id: feeAssetId,\n        fun: XcmV3MultiassetFungibility.Fungible(feeAmount),\n    },\n    }),\n    // Remote fees handled in InitiateTransfer\n    XcmV5Instruction.InitiateTransfer({\n    ...,\n    remote_fees: Enum('Teleport', remoteFeeAssets),\n    ...,\n    });\n    ```\n\nMigration Benefits:\n\n- Precise fee control\n- Multi-hop fee planning\n- Better fee estimation support\n\nThe old `BuyExecution` instruction looks like this:\n\n```typescript\nXcmV4Instruction.BuyExecution({\n    fees: {\n        id: feeAssetId,\n        fun: XcmV3MultiassetFungibility.Fungible(feeAmount),\n    },\n    weight_limit: XcmV3WeightLimit.Unlimited(),\n});\n```\n\nThe new `PayFees` instruction just has the asset for fee payment. The `weight_limit` parameter has historically been set to `Unlimited` due to the difficulty in estimating weight and the fees being sufficient to limit the maximum execution cost.\n\nThere is another key difference between `PayFees` and `BuyExecution`:\n\n- With `BuyExecution`, if too much was supplied for fees, the leftover after paying for execution would be returned to the [holding register](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/struct.XcmExecutor.html#method.holding) to be used in the rest of the XCM.\n- With `PayFees`, the full amount put into `assets` is stored in the fees register; nothing is returned to the holding register.\n\nThis means the full amount intended for fee payment must be specified. It makes it much more predictable. For example, withdrawing 11 DOT with 1 DOT in `PayFees` ensures exactly 10 DOT is sent.\n\nThe reason for this is the introduction of **delivery fees**, which are charged in addition to **execution fees**. Delivery fees are charged the moment an instruction is encountered that results in sending a new XCM. That's why fees can't be returned to the holding register as before; they need to be kept in the new fees register.\n\n!!! note \"Is BuyExecution going away?\"\n\n    No! As with many things in XCM V5, the old instruction is kept for backwards compatibility. However, it is planned for removal in future versions, once enough time has passed."}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 5, "depth": 2, "title": "Migration Examples", "anchor": "migration-examples", "start_char": 7410, "end_char": 7535, "estimated_token_count": 22, "token_estimator": "heuristic-v1", "text": "## Migration Examples\n\nThese practical examples demonstrate how to convert existing XCM V4 code to the new XCM V5 patterns."}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 6, "depth": 3, "title": "Simple Teleport", "anchor": "simple-teleport", "start_char": 7535, "end_char": 9768, "estimated_token_count": 462, "token_estimator": "heuristic-v1", "text": "### Simple Teleport\n\nThis example shows the basic migration from XCM V4's `limitedTeleportAssets` extrinsic to XCM V5's manual XCM construction using `PayFees` and `InitiateTransfer`.\n\n- **XCM V4 Code**:\n\n    ```typescript\n    const tx = api.tx.xcmPallet.limitedTeleportAssets({\n    dest: XcmVersionedLocation.V4({ parents: 1, interior: XcmV3Junctions.X1(XcmV3Junction.Parachain(1000))}),\n    beneficiary: XcmVersionedLocation.V4({\n        parents: 0,\n        interior: XcmV3Junctions.X1(XcmV3Junction.AccountId32({ id: beneficiaryId, network: undefined })),\n    }),\n    assets: XcmVersionedAssets.V4([{ \n        id: { parents: 1, interior: XcmV3Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(amount),\n    ]),\n    fee_asset_item: 0,\n    weight_limit: XcmV3WeightLimit.Unlimited(),\n    });\n    ```\n\n- **XCM V5 Equivalent**:\n\n    ```typescript\n    const xcm = XcmVersionedXcm.V5([\n    XcmV5Instruction.WithdrawAsset([{\n        id: { parents: 1, interior: XcmV3Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(amount),\n    }]),\n    XcmV5Instruction.PayFees({\n        asset: {\n        id: { parents: 1, interior: XcmV3Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(feeAmount),\n        },\n    }),\n    XcmV5Instruction.InitiateTransfer({\n        destination: { parents: 1, interior: XcmV3Junctions.X1(XcmV3Junction.Parachain(1000)) },\n        remote_fees: Enum('Teleport', XcmV5AssetFilter.Definite([{\n        id: { parents: 1, interior: XcmV3Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(remoteFeeAmount),\n        }])),\n        preserve_origin: false,\n        assets: [Enum('Teleport', XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)))],\n        remote_xcm: [\n        XcmV5Instruction.DepositAsset({\n            assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n            beneficiary: {\n            parents: 0,\n            interior: XcmV3Junctions.X1(XcmV3Junction.AccountId32({\n                id: beneficiaryId,\n                network: undefined,\n            })),\n            },\n        }),\n        ],\n    }),\n    ]);\n\n    const tx = api.tx.PolkadotXcm.execute({\n    message: xcm,\n    max_weight: calculatedWeight,\n    });\n    ```"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 7, "depth": 3, "title": "Example 2: Multi-Asset Transfer and a Transact", "anchor": "example-2-multi-asset-transfer-and-a-transact", "start_char": 9768, "end_char": 10773, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "### Example 2: Multi-Asset Transfer and a Transact\n\nThis example shows how XCM V5 enables combining multiple asset transfers with different transfer types while executing calls on the destination chain.\n\n- **New in XCM V5 - No XCM V4 equivalent**:\n\n    ```typescript\n    // This pattern wasn't possible in v4\n    XcmV5Instruction.InitiateTransfer({\n    destination: destination,\n    remote_fees: Enum('ReserveDeposit', ethFees), // Fee with different transfer type\n    assets: [\n        Enum('Teleport', dotAssets),           // Teleport DOT\n        Enum('ReserveDeposit', usdtAssets),    // Reserve transfer USDT\n        Enum('ReserveDeposit', usdcAssets),    // Reserve transfer USDC\n    ],\n    preserve_origin: true, // Enable cross-chain calls\n    remote_xcm: [\n        // Can now call functions on destination!\n        XcmV5Instruction.Transact({\n        origin_kind: XcmV2OriginKind.SovereignAccount(),\n        call: encodedCall,\n        fallback_max_weight: ...,\n        }),\n    ],\n    })\n    ```"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 8, "depth": 2, "title": "Breaking Changes to Watch Out For", "anchor": "breaking-changes-to-watch-out-for", "start_char": 10773, "end_char": 10811, "estimated_token_count": 8, "token_estimator": "heuristic-v1", "text": "## Breaking Changes to Watch Out For"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 9, "depth": 3, "title": "`fallback_max_weight` in `Transact`", "anchor": "fallback_max_weight-in-transact", "start_char": 10811, "end_char": 12377, "estimated_token_count": 292, "token_estimator": "heuristic-v1", "text": "### `fallback_max_weight` in `Transact`\n\nThe `Transact` instruction has been updated in XCM V5 to reduce the likelihood of bugs when executing calls on remote chains.\n\nThe `Transact` instruction looked like this in XCM V4:\n\n- **XCM V4:**\n\n    ```typescript\n    XcmV4Instruction.Transact({\n    call: encodedCall,\n    origin_kind: XcmV2OriginKind.SovereignAccount(),\n    require_weight_at_most: { ref_time: 1_000_000_000, proof_size: 100_000 }, // Required.\n    });\n    ```\n\n- **XCM V5:**\n\n    ```typescript\n    XcmV5Instruction.Transact({\n        call: encodedCall,\n        origin_kind: XcmV2OriginKind.SovereignAccount(),\n        fallback_max_weight: { ref_time: 1_000_000_000, proof_size: 100_000 }, // Optional.\n    });\n    ```\n\nThe old `require_weight_at_most` parameter caused frequent failures:\n\n- Runtime upgrades broke XCMs: When destination chains updated their runtime weights, existing XCMs would fail.\n- Hard to estimate correctly: Developers had to guess call weights for remote chains.\n- Maintenance burden: Weight values needed constant updates across chain upgrades.\n\nNew behavior:\n\n- Automatic weight calculation: XCM V5-compatible chains calculate call weights automatically when decoding the message.\n- Fallback compatibility: The optional `fallback_max_weight` is only used when the destination chain hasn't upgraded to XCM V5 yet.\n- Fail-safe design: If weight calculation fails, the fallback value is used.\n\nThis change makes `Transact` more reliable and reduces the maintenance burden of keeping weight values current across runtime upgrades."}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 10, "depth": 3, "title": "Network IDs Cleanup", "anchor": "network-ids-cleanup", "start_char": 12377, "end_char": 13310, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "### Network IDs Cleanup\n\nThis change affects how testnet networks are referenced in XCM.\n\nThe network IDs, used in the `GlobalConsensus` junction, for `Rococo` and `Westend` were removed. Instead, the generic `ByGenesis` network ID should be used for referencing testnets. This change was made because testnets come and go, as was shown by the [removal of Rococo](https://forum.polkadot.network/t/rococo-to-be-deprecated-in-october/8702) and [appearance of Paseo](https://forum.polkadot.network/t/the-new-polkadot-community-testnet/4956). From now on, only mainnets will have an explicit network ID; testnets should always be referenced with `ByGenesis`.\n\nIf storing these network IDs, they must be migrated to `ByGenesis`. These are the genesis hashes for the migration:\n\n- Westend: `0xe143f23803ac50e8f6f8e62695d1ce9e4e1d68aa36c1cd2cfd15340213f3423e`\n- Rococo: `0x6408de7737c59c238890533af25896a2c20608d8b380bb01029acb392781063e`"}
{"page_id": "develop-interoperability-versions-v5-migration-guide", "index": 11, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 13310, "end_char": 13459, "estimated_token_count": 25, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\nOnce migrated, unique XCM V5 features become available:\n\n- Origin preservation\n- Transferring multiple assets\n- Better asset claiming"}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 0, "depth": 2, "title": "Changes from V4", "anchor": "changes-from-v4", "start_char": 339, "end_char": 464, "estimated_token_count": 20, "token_estimator": "heuristic-v1", "text": "## Changes from V4\n\nXCM V5 improves weight handling by making weight specification optional to reduce transaction failures."}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 1, "depth": 3, "title": "Weight Parameter Evolution", "anchor": "weight-parameter-evolution", "start_char": 464, "end_char": 1098, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "### Weight Parameter Evolution\n\n- **Previous Versions:**\n\n    ```typescript\n    // Required explicit weight specification\n    XcmV4Instruction.Transact({\n    origin_kind: XcmV2OriginKind.SovereignAccount(),\n    require_weight_at_most: {\n        ref_time: 1000000000n,\n        proof_size: 100000n\n    },\n    call: encodedCall\n    })\n    ```\n\n- **XCM V5:**\n\n    ```typescript\n    // Optional weight specification with fallback\n    XcmV5Instruction.Transact({\n        origin_kind: XcmV2OriginKind.SovereignAccount(),\n        fallback_max_weight: undefined, // or weight object for compatibility\n        call: encodedCall\n    })\n    ```"}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 2, "depth": 2, "title": "The `fallback_max_weight` Parameter", "anchor": "the-fallback_max_weight-parameter", "start_char": 1098, "end_char": 1138, "estimated_token_count": 7, "token_estimator": "heuristic-v1", "text": "## The `fallback_max_weight` Parameter"}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 3, "depth": 3, "title": "When to Use `undefined`", "anchor": "when-to-use-undefined", "start_char": 1138, "end_char": 1590, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "### When to Use `undefined`\n\nUse `fallback_max_weight: undefined` when:\n\n- The destination chain supports XCM V5.\n- You want automatic weight calculation.\n- You prefer simplified, more reliable execution.\n\n    ```typescript\n    // Preferred approach for v5-compatible destinations\n    XcmV5Instruction.Transact({\n        origin_kind: XcmV2OriginKind.SovereignAccount(),\n        fallback_max_weight: undefined,\n        call: encodedCall\n    })\n    ```"}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 4, "depth": 3, "title": "When to Specify Weight", "anchor": "when-to-specify-weight", "start_char": 1590, "end_char": 2109, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "### When to Specify Weight\n\nUse `fallback_max_weight: { ref_time: ..., proof_size: ... }` when:\n\n- The destination chain doesn't support XCM V5 yet.\n- You need backward compatibility.\n- You want explicit weight control.\n\n    ```typescript\n    // Backward compatibility approach\n    XcmV5Instruction.Transact({\n        origin_kind: XcmV2OriginKind.SovereignAccount(), \n        fallback_max_weight: {\n            ref_time: 1000000000n,\n            proof_size: 100000n\n        },\n        call: encodedCall\n    })\n    ```"}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 5, "depth": 2, "title": "Benefits of the New Approach", "anchor": "benefits-of-the-new-approach", "start_char": 2109, "end_char": 2142, "estimated_token_count": 7, "token_estimator": "heuristic-v1", "text": "## Benefits of the New Approach"}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 6, "depth": 3, "title": "Problems Solved", "anchor": "problems-solved", "start_char": 2142, "end_char": 2457, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### Problems Solved\n\nThe previous mandatory weight specification created:\n\n- **Brittle implementations**: Weight requirements changed with runtime upgrades.\n- **Over/under-estimation**: Incorrect weight estimates that led to failures or waste.\n- **Maintenance overhead**: Constant monitoring and updates required."}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 7, "depth": 3, "title": "XCM V5 Improvements", "anchor": "xcm-v5-improvements", "start_char": 2457, "end_char": 2845, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "### XCM V5 Improvements\n\n- **Automatic weight handling**: Destination chains calculate appropriate weights when `fallback_max_weight` is `undefined`.\n- **Backward compatibility**: Legacy chains still work with specified weights.\n- **Flexibility**: Choose the approach based on destination chain capabilities.\n- **Reduced brittleness**: Less prone to failures from weight miscalculation."}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 8, "depth": 2, "title": "Migration Strategy", "anchor": "migration-strategy", "start_char": 2845, "end_char": 3190, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Migration Strategy\n\nWhen migrating from XCM V4 to XCM V5:\n\n- **For V5-compatible destinations**: Replace `require_weight_at_most` with `fallback_max_weight: undefined`.\n- **For mixed environments**: Keep weight specification for non-v5 chains.\n- **Gradual transition**: Start with explicit weights and move to `undefined` as chains upgrade."}
{"page_id": "develop-interoperability-versions-v5-transact", "index": 9, "depth": 2, "title": "Fee Implications", "anchor": "fee-implications", "start_char": 3190, "end_char": 3637, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Fee Implications\n\nFees are still required for `Transact` execution:\n\n- Use `PayFees` or `BuyExecution` before the instruction.\n- With `fallback_max_weight: undefined`, fees are deducted based on actual execution weight.\n- Fee estimation becomes more predictable without manual weight calculations.\n\nThis change makes `Transact` both more developer-friendly and backward-compatible while maintaining powerful cross-chain execution capabilities."}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 0, "depth": 2, "title": "Changes from v4", "anchor": "changes-from-v4", "start_char": 289, "end_char": 309, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Changes from v4"}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 1, "depth": 3, "title": "Instruction Consolidation", "anchor": "instruction-consolidation", "start_char": 309, "end_char": 787, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "### Instruction Consolidation\n\n- **Previous versions:**\n\n    - `InitiateTeleport`: For teleport transfers.\n    - `InitiateReserveWithdraw`: For reserve withdrawals.  \n    - `DepositReserveAsset`: For reserve deposits.\n    - Separate instructions for different transfer types.\n\n- **XCM V5:**\n\n    - Single `InitiateTransfer` instruction for all transfer types.\n    - Transfer type specified within the instruction parameters.\n    - Unified interface with enhanced capabilities."}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 2, "depth": 3, "title": "Enhanced Transfer Specification", "anchor": "enhanced-transfer-specification", "start_char": 787, "end_char": 1510, "estimated_token_count": 154, "token_estimator": "heuristic-v1", "text": "### Enhanced Transfer Specification\n\n- **Previous approach:**\n\n    ```typescript\n    // Separate instructions for different transfer types\n    XcmV4Instruction.InitiateTeleport({ /* teleport params */ })\n    XcmV4Instruction.InitiateReserveWithdraw({ /* reserve params */ })\n    ```\n\n- **XCM V5 approach:**\n\n    ```typescript\n    // Unified instruction with transfer type specification\n    XcmV5Instruction.InitiateTransfer({\n    destination: /* location */,\n    remote_fees: Enum('ReserveDeposit', /* fee asset */),\n    preserve_origin: false,\n    assets: [\n        Enum('Teleport', /* teleport assets */),\n        Enum('ReserveDeposit', /* reserve assets */)\n    ],\n    remote_xcm: /* remote execution */\n    })\n    ```"}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 3, "depth": 2, "title": "Key Enhancements", "anchor": "key-enhancements", "start_char": 1510, "end_char": 1531, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Key Enhancements"}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 4, "depth": 3, "title": "Mixed Transfer Types", "anchor": "mixed-transfer-types", "start_char": 1531, "end_char": 1798, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### Mixed Transfer Types\n\nXCM V5 allows mixing different transfer types in a single transaction:\n\n- Teleport some assets while reserve-transferring others.\n- Use different transfer types for fees vs. main assets.\n- More flexible asset handling in complex scenarios."}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 5, "depth": 3, "title": "Origin Preservation", "anchor": "origin-preservation", "start_char": 1798, "end_char": 2373, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "### Origin Preservation\n\nThe new `preserve_origin` parameter enables:\n\n- Maintaining the original sender's identity on destination chains.\n- Executing transactions (`Transact`) on behalf of the origin.\n- More sophisticated cross-chain operations.\n\n!!! note \"Important\"\n\n    Origin preservation requires a specific configuration on the destination chain.\n    If the destination chain doesn't support it, transfers with `preserve_origin: true` will fail.\n    Setting `preserve_origin: false` will continue to work as before, regardless of the destination chain configuration."}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 6, "depth": 3, "title": "Integrated Fee Handling", "anchor": "integrated-fee-handling", "start_char": 2373, "end_char": 2585, "estimated_token_count": 39, "token_estimator": "heuristic-v1", "text": "### Integrated Fee Handling\n\nBuilt-in `remote_fees` parameter:\n\n- Automatic `PayFees` instruction insertion on destination.\n- Cleaner fee specification with transfer type.\n- Better fee management across chains."}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 7, "depth": 2, "title": "Backward Compatibility", "anchor": "backward-compatibility", "start_char": 2585, "end_char": 2897, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Backward Compatibility\n\nXCM V5 maintains full backward compatibility:\n\n- Previous transfer instructions `InitiateTeleport`, `InitiateReserveWithdraw`, `DepositReserveAsset` remain available.\n- Existing XCM programs continue to work without modification.\n- Gradual migration path to the new unified approach."}
{"page_id": "develop-interoperability-versions-v5-transfers", "index": 8, "depth": 2, "title": "Migration Benefits", "anchor": "migration-benefits", "start_char": 2897, "end_char": 3243, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "## Migration Benefits\n\nMoving to `InitiateTransfer` provides:\n\n- **Simplified development**: Single instruction for all transfer scenarios.\n- **Enhanced flexibility**: Mix transfer types and preserve origins.\n- **Better maintainability**: Fewer instruction types to manage.\n- **Future-proofing**: Foundation for additional transfer enhancements."}
{"page_id": "develop-interoperability-versions-v5-writing-xcm-programs", "index": 0, "depth": 2, "title": "The Paradigm Shift", "anchor": "the-paradigm-shift", "start_char": 154, "end_char": 177, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## The Paradigm Shift"}
{"page_id": "develop-interoperability-versions-v5-writing-xcm-programs", "index": 1, "depth": 3, "title": "Previous Approach", "anchor": "previous-approach", "start_char": 177, "end_char": 560, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "### Previous Approach\n\nThe previous approach was to use specialized extrinsics in `pallet-xcm` and `xtokens` for different operations:\n\n- Used specialized extrinsics in `pallet-xcm` and `xtokens`.\n- Separate functions for different operations:\n    - `limited_teleport_assets`\n    - `limited_reserve_transfer_assets`\n    - `claim_assets`\n\nEach new use case required a new extrinsic."}
{"page_id": "develop-interoperability-versions-v5-writing-xcm-programs", "index": 2, "depth": 3, "title": "XCM V5 Recommendation", "anchor": "xcm-v5-recommendation", "start_char": 560, "end_char": 757, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "### XCM V5 Recommendation\n\n- Craft raw XCM programs directly.\n- Use `pallet_xcm::execute()` for execution.\n- Compose instructions within programs.\n- No new extrinsics needed for custom use cases."}
{"page_id": "develop-interoperability-versions-v5-writing-xcm-programs", "index": 3, "depth": 2, "title": "Execution Approach", "anchor": "execution-approach", "start_char": 757, "end_char": 1274, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Execution Approach\n\nXCM V5 promotes using `execute()` directly:\n\n```typescript\n// XCM V5 recommended approach\nconst tx = api.tx.PolkadotXcm.execute({\n  message: xcm, // The XCM program\n  max_weight: weight, // Weight limit for execution\n})\n```\n\nThis provides more flexibility than calling specialized extrinsics:\n\n```typescript\n// Previous approach - specialized extrinsics\napi.tx.PolkadotXcm.limitedTeleportAssets(...)\napi.tx.PolkadotXcm.limitedReserveTransferAssets(...)\napi.tx.PolkadotXcm.claimAssets(...)\n```"}
{"page_id": "develop-interoperability-versions-v5-writing-xcm-programs", "index": 4, "depth": 2, "title": "Benefits of Direct Execution", "anchor": "benefits-of-direct-execution", "start_char": 1274, "end_char": 1572, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Benefits of Direct Execution\n\n1. **Flexibility**: Full control over XCM instruction sequences.\n2. **Composability**: Combine multiple operations in a single program.\n3. **Extensibility**: Custom use cases without new extrinsics.\n4. **Maintainability**: Fewer specialized functions to maintain."}
{"page_id": "develop-interoperability-versions-v5-writing-xcm-programs", "index": 5, "depth": 2, "title": "Migration Considerations", "anchor": "migration-considerations", "start_char": 1572, "end_char": 1830, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## Migration Considerations\n\n- Existing dedicated extrinsics continue to work.\n- No breaking changes to existing programs.\n- New development should prefer `execute()` for better flexibility.\n- A gradual migration path is available for existing applications."}
{"page_id": "develop-interoperability-xcm-channels", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 1386, "estimated_token_count": 294, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot is designed to enable interoperability between its connected parachains. At the core of this interoperability is the [Cross-Consensus Message Format (XCM)](/develop/interoperability/intro-to-xcm/){target=\\_blank}, a standard language that allows parachains to communicate and interact with each other.\n\nThe network-layer protocol responsible for delivering XCM-formatted messages between parachains is the [Cross-Chain Message Passing (XCMP)](https://wiki.polkadot.com/learn/learn-xcm-transport/#xcmp-cross-chain-message-passing){target=\\_blank} protocol. XCMP maintains messaging queues on the relay chain, serving as a bridge to facilitate cross-chain interactions.\n\nAs XCMP is still under development, Polkadot has implemented a temporary alternative called [Horizontal Relay-routed Message Passing (HRMP)](https://wiki.polkadot.com/learn/learn-xcm-transport/#hrmp-xcmp-lite){target=\\_blank}. HRMP offers the same interface and functionality as the planned XCMP but it has a crucial difference, it stores all messages directly in the relay chain's storage, which is more resource-intensive.\n\nOnce XCMP is fully implemented, HRMP will be deprecated in favor of the native XCMP protocol. XCMP will offer a more efficient and scalable solution for cross-chain message passing, as it will not require the relay chain to store all the messages."}
{"page_id": "develop-interoperability-xcm-channels", "index": 1, "depth": 2, "title": "Establishing HRMP Channels", "anchor": "establishing-hrmp-channels", "start_char": 1386, "end_char": 2076, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Establishing HRMP Channels\n\nTo enable communication between parachains using the HRMP protocol, the parachains must explicitly establish communication channels by registering them on the relay chain.\n\nDownward and upward channels from and to the relay chain are implicitly available, meaning they do not need to be explicitly opened.\n\nOpening an HRMP channel requires the parachains involved to make a deposit on the relay chain. This deposit serves a specific purpose, it covers the costs associated with using the relay chain's storage for the message queues linked to the channel. The amount of this deposit varies based on parameters defined by the specific relay chain being used."}
{"page_id": "develop-interoperability-xcm-channels", "index": 2, "depth": 3, "title": "Relay Chain Parameters", "anchor": "relay-chain-parameters", "start_char": 2076, "end_char": 3987, "estimated_token_count": 431, "token_estimator": "heuristic-v1", "text": "### Relay Chain Parameters\n\nEach Polkadot relay chain has a set of configurable parameters that control the behavior of the message channels between parachains. These parameters include [`hrmpSenderDeposit`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/configuration/struct.HostConfiguration.html#structfield.hrmp_sender_deposit){target=\\_blank}, [`hrmpRecipientDeposit`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/configuration/struct.HostConfiguration.html#structfield.hrmp_recipient_deposit){target=\\_blank}, [`hrmpChannelMaxMessageSize`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/configuration/struct.HostConfiguration.html#structfield.hrmp_channel_max_message_size){target=\\_blank}, [`hrmpChannelMaxCapacity`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/configuration/struct.HostConfiguration.html#structfield.hrmp_channel_max_capacity){target=\\_blank}, and more.\n\nWhen a parachain wants to open a new channel, it must consider these parameter values to ensure the channel is configured correctly.\n\nTo view the current values of these parameters in the Polkadot network:\n\n1. Visit [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fpolkadot.api.onfinality.io%2Fpublic-ws#/explorer), navigate to the **Developer** dropdown and select the **Chain state** option.\n\n    ![](/images/develop/interoperability/xcm-channels/xcm-channels-1.webp)\n\n2. Query the chain configuration parameters. The result will display the current settings for all the Polkadot network parameters, including the HRMP channel settings.\n\n    1. Select **`configuration`**.\n    2. Choose the **`activeConfig()`** call.\n    3. Click the **+** button to execute the query.\n    4. Check the chain configuration.\n\n        ![](/images/develop/interoperability/xcm-channels/xcm-channels-2.webp)"}
{"page_id": "develop-interoperability-xcm-channels", "index": 3, "depth": 3, "title": "Dispatching Extrinsics", "anchor": "dispatching-extrinsics", "start_char": 3987, "end_char": 5489, "estimated_token_count": 328, "token_estimator": "heuristic-v1", "text": "### Dispatching Extrinsics\n\nEstablishing new HRMP channels between parachains requires dispatching specific extrinsic calls on the Polkadot Relay Chain from the parachain's origin.\n\nThe most straightforward approach is to implement the channel opening logic off-chain, then use the XCM pallet's [`send`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/dispatchables/fn.send.html){target=\\_blank} extrinsic to submit the necessary instructions to the relay chain. However, the ability to send arbitrary programs through the [`Transact`](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#transact){target=\\_blank} instruction in XCM is typically restricted to privileged origins, such as the [`sudo`](https://paritytech.github.io/polkadot-sdk/master/pallet_sudo/pallet/dispatchables/fn.sudo.html){target=\\_blank} pallet or governance mechanisms.\n\nParachain developers have a few options for triggering the required extrinsic calls from their parachain's origin, depending on the configuration and access controls defined:\n\n- **Sudo**: If the parachain has a `sudo` pallet configured, the sudo key holder can use the sudo extrinsic to dispatch the necessary channel opening calls.\n- **Governance**: The parachain's governance system, such as a council or OpenGov, can be used to authorize the channel opening calls.\n- **Privileged accounts**: The parachain may have other designated privileged accounts that are allowed to dispatch the HRMP channel opening extrinsics."}
{"page_id": "develop-interoperability-xcm-channels", "index": 4, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5489, "end_char": 6418, "estimated_token_count": 202, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nExplore the following tutorials for detailed, step-by-step guidance on setting up cross-chain communication channels in Polkadot:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Opening HRMP Channels Between Parachains__\n\n    ---\n\n    Learn how to open HRMP channels between parachains on Polkadot. Discover the step-by-step process for establishing uni- and bidirectional communication.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/interoperability/xcm-channels/para-to-para/)\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Opening HRMP Channels with System Parachains__\n\n    ---\n\n    Learn how to open HRMP channels with Polkadot system parachains. Discover the process for establishing bi-directional communication using a single XCM message.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/interoperability/xcm-channels/para-to-system/)\n\n</div>"}
{"page_id": "develop-interoperability-xcm-config", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 1544, "estimated_token_count": 337, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [XCM executor](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/index.html){target=\\_blank} is a crucial component responsible for interpreting and executing XCM messages (XCMs) with Polkadot SDK-based chains. It processes and manages XCM instructions, ensuring they are executed correctly and in sequentially. Adhering to the [Cross-Consensus Virtual Machine (XCVM) specification](https://paritytech.github.io/xcm-docs/overview/xcvm.html#the-xcvm){target=\\_blank}, the XCM executor can be customized or replaced with an alternative that also complies with the [XCVM standards](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#12-the-xcvm){target=\\_blank}.\n\nThe `XcmExecutor` is not a pallet but a struct parameterized by a `Config` trait. The `Config` trait is the inner configuration, parameterizing the outer `XcmExecutor<Config>` struct. Both configurations are set up within the runtime.\n\nThe executor is highly configurable, with the [XCM builder](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/index.html){target=\\_blank} offering building blocks to tailor the configuration to specific needs. While they serve as a foundation, users can easily create custom blocks to suit unique configurations. Users can also create their building blocks to address unique needs. This article examines the XCM configuration process, explains each configurable item, and provides examples of the tools and types available to help customize these settings."}
{"page_id": "develop-interoperability-xcm-config", "index": 1, "depth": 2, "title": "XCM Executor Configuration", "anchor": "xcm-executor-configuration", "start_char": 1544, "end_char": 3821, "estimated_token_count": 389, "token_estimator": "heuristic-v1", "text": "## XCM Executor Configuration\n\nThe `Config` trait defines the XCM executor’s configuration, which requires several associated types. Each type has specific trait bounds that the concrete implementation must fulfill. Some types, such as `RuntimeCall`, come with a default implementation in most cases, while others use the unit type `()` as the default. For many of these types, selecting the appropriate implementation carefully is crucial. Predefined solutions and building blocks can be adapted to your specific needs. These solutions can be found in the [`xcm-builder`](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/polkadot/xcm/xcm-builder){target=\\_blank} folder.\n\nEach type is explained below, along with an overview of some of its implementations:\n\n```rust\n-pub trait Config {\n    type RuntimeCall: Parameter + Dispatchable<PostInfo = PostDispatchInfo> + GetDispatchInfo;\n    type XcmSender: SendXcm;\n    type AssetTransactor: TransactAsset;\n    type OriginConverter: ConvertOrigin<<Self::RuntimeCall as Dispatchable>::RuntimeOrigin>;\n    type IsReserve: ContainsPair<MultiAsset, MultiLocation>;\n    type IsTeleporter: ContainsPair<MultiAsset, MultiLocation>;\n    type Aliasers: ContainsPair<Location, Location>;\n    type UniversalLocation: Get<InteriorMultiLocation>;\n    type Barrier: ShouldExecute;\n    type Weigher: WeightBounds<Self::RuntimeCall>;\n    type Trader: WeightTrader;\n    type ResponseHandler: OnResponse;\n    type AssetTrap: DropAssets;\n    type AssetClaims: ClaimAssets;\n    type AssetLocker: AssetLock;\n    type AssetExchanger: AssetExchange;\n    type SubscriptionService: VersionChangeNotifier;\n    type PalletInstancesInfo: PalletsInfoAccess;\n    type MaxAssetsIntoHolding: Get<u32>;\n    type FeeManager: FeeManager;\n    type MessageExporter: ExportXcm;\n    type UniversalAliases: Contains<(MultiLocation, Junction)>;\n    type CallDispatcher: CallDispatcher<Self::RuntimeCall>;\n    type SafeCallFilter: Contains<Self::RuntimeCall>;\n    type TransactionalProcessor: ProcessTransaction;\n    type HrmpNewChannelOpenRequestHandler: HandleHrmpNewChannelOpenRequest;\n    type HrmpChannelAcceptedHandler: HandleHrmpChannelAccepted;\n    type HrmpChannelClosingHandler: HandleHrmpChannelClosing;\n    type XcmRecorder: RecordXcm;\n}\n```"}
{"page_id": "develop-interoperability-xcm-config", "index": 2, "depth": 2, "title": "Config Items", "anchor": "config-items", "start_char": 3821, "end_char": 18394, "estimated_token_count": 3491, "token_estimator": "heuristic-v1", "text": "## Config Items\n\nEach configuration item is explained below, detailing the associated type’s purpose and role in the XCM executor. Many of these types have predefined solutions available in the `xcm-builder`. Therefore, the available configuration items are:\n\n- **[`RuntimeCall`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.RuntimeCall){target=\\_blank}**: Defines the runtime's callable functions, created via the [`frame::runtime`](https://paritytech.github.io/polkadot-sdk/master/frame_support/attr.runtime.html){target=\\_blank} macro. It represents an enum listing the callable functions of all implemented pallets.\n\n    ```rust\n    type RuntimeCall: Parameter + Dispatchable<PostInfo = PostDispatchInfo> + GetDispatchInfo\n    ```\n   The associated traits signify:\n\n    - **`Parameter`**: Ensures the type is encodable, decodable, and usable as a parameter.\n    - **`Dispatchable`**: Indicates it can be executed in the runtime.\n    - **`GetDispatchInfo`**: Provides weight details, determining how long execution takes.\n\n- **[`XcmSender`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.XcmSender){target=\\_blank}**: Implements the [`SendXcm`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v4/trait.SendXcm.html){target=\\_blank} trait, specifying how the executor sends XCMs using transport layers (e.g., UMP for relay chains or XCMP for sibling chains). If a runtime lacks certain transport layers, such as [HRMP](https://wiki.polkadot.com/learn/learn-xcm-transport/#hrmp-xcmp-lite){target=\\_blank} (or [XCMP](https://wiki.polkadot.com/learn/learn-xcm-transport/#xcmp-cross-consensus-message-passing-design-summary){target=\\_blank}).\n\n    ```rust\n    type XcmSender: SendXcm;\n    ```\n\n- **[`AssetTransactor`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.AssetTransactor){target=\\_blank}**: Implements the [`TransactAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.TransactAsset.html){target=\\_blank} trait, handling the conversion and transfer of MultiAssets between accounts or registers. It can be configured to support native tokens, fungibles, and non-fungibles or multiple tokens using pre-defined adapters like [`FungibleAdapter`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.FungibleAdapter.html){target=\\_blank} or custom solutions.\n\n    ```rust\n    type AssetTransactor: TransactAsset;\n    ```\n\n- **[`OriginConverter`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.OriginConverter){target=\\_blank}**: Implements the [`ConvertOrigin`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.ConvertOrigin.html){target=\\_blank} trait to map `MultiLocation` origins to `RuntimeOrigin`. Multiple implementations can be combined, and [`OriginKind`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/test_utils/enum.OriginKind.html){target=\\_blank} is used to resolve conflicts. Pre-defined converters like [`SovereignSignedViaLocation`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.SovereignSignedViaLocation.html){target=\\_blank} and [`SignedAccountId32AsNative`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.SignedAccountId32AsNative.html){target=\\_blank} handle sovereign and local accounts respectively.\n\n    ```rust\n    type OriginConverter: ConvertOrigin<<Self::RuntimeCall as Dispatchable>::RuntimeOrigin>;\n    ```\n\n- **[`IsReserve`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.IsReserve){target=\\_blank}**: Specifies trusted `<MultiAsset, MultiLocation>` pairs for depositing reserve assets. Using the unit type `()` blocks reserve deposits. The [`NativeAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.NativeAsset.html){target=\\_blank} struct is an example of a reserve implementation.\n\n    ```rust\n    type IsReserve: ContainsPair<MultiAsset, MultiLocation>;\n    ```\n\n- **[`IsTeleporter`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.IsTeleporter){target=\\_blank}**: Defines trusted `<MultiAsset, MultiLocation>` pairs for teleporting assets to the chain. Using `()` blocks the [`ReceiveTeleportedAssets`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/test_utils/enum.Instruction.html#variant.ReceiveTeleportedAsset){target=\\_blank} instruction. The [`NativeAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.NativeAsset.html){target=\\_blank} struct can act as an implementation.\n\n    ```rust\n    type IsTeleporter: ContainsPair<MultiAsset, MultiLocation>;\n    ```\n\n- **[`Aliasers`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.Aliasers){target=\\_blank}**: A list of `(Origin, Target)` pairs enabling each `Origin` to be replaced with its corresponding `Target`.\n\n    ```rust\n    type Aliasers: ContainsPair<Location, Location>;\n    ```\n\n- **[`UniversalLocation`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.UniversalLocation){target=\\_blank}**: Specifies the runtime's location in the consensus universe.\n\n    ```rust\n    type UniversalLocation: Get<InteriorMultiLocation>;\n    ```\n\n    - Some examples are:\n        - `X1(GlobalConsensus(NetworkId::Polkadot))` for Polkadot\n        - `X1(GlobalConsensus(NetworkId::Kusama))` for Kusama\n        - `X2(GlobalConsensus(NetworkId::Polkadot), Parachain(1000))` for Statemint\n\n- **[`Barrier`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.Barrier){target=\\_blank}**: Implements the [`ShouldExecute`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.ShouldExecute.html){target=\\_blank} trait, functioning as a firewall for XCM execution. Multiple barriers can be combined in a tuple, where execution halts if one succeeds.\n\n    ```rust\n    type Barrier: ShouldExecute;\n    ```\n\n- **[`Weigher`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.Weigher){target=\\_blank}**: Calculates the weight of XCMs and instructions, enforcing limits and refunding unused weight. Common solutions include [`FixedWeightBounds`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.FixedWeightBounds.html){target=\\_blank}, which uses a base weight and limits on instructions.\n\n    ```rust\n    type Weigher: WeightBounds<Self::RuntimeCall>;\n    ```\n\n- **[`Trader`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.Trader){target=\\_blank}**: Manages asset-based weight purchases and refunds for `BuyExecution` instructions. The [`UsingComponents`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_builder/struct.UsingComponents.html){target=\\_blank} trader is a common implementation.\n\n    ```rust\n    type Trader: WeightTrader;\n    ```\n\n- **[`ResponseHandler`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.ResponseHandler){target=\\_blank}**: Handles `QueryResponse` instructions, implementing the [`OnResponse`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.OnResponse.html){target=\\_blank} trait. FRAME systems typically use the pallet-xcm implementation.\n\n    ```rust\n    type ResponseHandler: OnResponse;\n    ```\n\n- **[`AssetTrap`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.AssetTrap){target=\\_blank}**: Handles leftover assets in the holding register after XCM execution, allowing them to be claimed via `ClaimAsset`. If unsupported, assets are burned.\n\n    ```rust\n    type AssetTrap: DropAssets;\n    ```\n\n- **[`AssetClaims`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.AssetClaims){target=\\_blank}**: Facilitates the claiming of trapped assets during the execution of the `ClaimAsset` instruction. Commonly implemented via pallet-xcm.\n\n    ```rust\n    type AssetClaims: ClaimAssets;\n    ```\n\n- **[`AssetLocker`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.AssetLocker){target=\\_blank}**: Handles the locking and unlocking of assets. Can be omitted using `()` if asset locking is unnecessary.\n\n    ```rust\n    type AssetLocker: AssetLock;\n    ```\n\n- **[`AssetExchanger`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.AssetExchanger){target=\\_blank}**: Implements the [`AssetExchange`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.AssetExchange.html){target=\\_blank} trait to manage asset exchanges during the `ExchangeAsset` instruction. The unit type `()` disables this functionality.\n\n    ```rust\n    type AssetExchanger: AssetExchange;\n    ```\n\n- **[`SubscriptionService`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.SubscriptionService){target=\\_blank}**: Manages `(Un)SubscribeVersion` instructions and returns the XCM version via `QueryResponse`. Typically implemented by pallet-xcm.\n\n    ```rust\n    type SubscriptionService: VersionChangeNotifier;\n    ```\n\n- **[`PalletInstancesInfo`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.PalletInstancesInfo){target=\\_blank}**: Provides runtime pallet information for `QueryPallet` and `ExpectPallet` instructions. FRAME-specific systems often use this, or it can be disabled with `()`.\n\n    ```rust\n    type PalletInstancesInfo: PalletsInfoAccess;\n    ```\n\n \n- [**`MaxAssetsIntoHolding`**](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.MaxAssetsIntoHolding){target=\\_blank}: Limits the number of assets in the [Holding register](https://wiki.polkadot.com/learn/learn-xcm/#holding-register){target=\\_blank}. At most, twice this limit can be held under worst-case conditions.\n    ```rust\n    type MaxAssetsIntoHolding: Get<u32>;\n    ```\n\n- **[`FeeManager`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.FeeManager){target=\\_blank}**: Manages fees for XCM instructions, determining whether fees should be paid, waived, or handled in specific ways. Fees can be waived entirely using `()`.\n\n    ```rust\n    type FeeManager: FeeManager;\n    ```\n\n- **[`MessageExporter`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.MessageExporter){target=\\_blank}**: Implements the [`ExportXcm`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.ExportXcm.html){target=\\_blank} trait, enabling XCMs export to other consensus systems. It can spoof origins for use in bridges. Use `()` to disable exporting.\n\n    ```rust\n    type MessageExporter: ExportXcm;\n    ```\n\n- **[`UniversalAliases`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.UniversalAliases){target=\\_blank}**: Lists origin locations and universal junctions allowed to elevate themselves in the `UniversalOrigin` instruction. Using `Nothing` prevents origin aliasing.\n\n    ```rust\n    type UniversalAliases: Contains<(MultiLocation, Junction)>;\n    ```\n\n- **[`CallDispatcher`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.CallDispatcher){target=\\_blank}**: Dispatches calls from the `Transact` instruction, adapting the origin or modifying the call as needed. Can default to `RuntimeCall`.\n\n    ```rust\n    type CallDispatcher: CallDispatcher<Self::RuntimeCall>;\n    ```\n\n- **[`SafeCallFilter`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.SafeCallFilter){target=\\_blank}**: Whitelists calls permitted in the `Transact` instruction. Using `Everything` allows all calls, though this is temporary until proof size weights are accounted for.\n\n    ```rust\n    type SafeCallFilter: Contains<Self::RuntimeCall>;\n    ```\n\n- **[`TransactionalProcessor`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.TransactionalProcessor){target=\\_blank}**: Implements the [`ProccessTransaction`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/traits/trait.ProcessTransaction.html){target=\\_blank} trait. It ensures that XCM instructions are executed atomically, meaning they either fully succeed or fully fail without any partial effects. This type allows for non-transactional XCM instruction processing by setting the `()` type.\n\n    ```rust\n    type TransactionalProcessor: ProcessTransaction;\n    ```\n\n- **[`HrmpNewChannelOpenRequestHandler`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.HrmpNewChannelOpenRequestHandler){target=\\_blank}**: Enables optional logic execution in response to the `HrmpNewChannelOpenRequest` XCM notification.\n\n    ```rust\n    type HrmpNewChannelOpenRequestHandler: HandleHrmpNewChannelOpenRequest;\n    ```\n\n- **[`HrmpChannelAcceptedHandler`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.HrmpChannelAcceptedHandler){target=\\_blank}**: Enables optional logic execution in response to the `HrmpChannelAccepted` XCM notification.\n\n    ```rust\n    type HrmpChannelAcceptedHandler: HandleHrmpChannelAccepted;\n    ```\n\n- **[`HrmpChannelClosingHandler`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.HrmpChannelClosingHandler){target=\\_blank}**: Enables optional logic execution in response to the `HrmpChannelClosing` XCM notification.\n\n    ```rust\n    type HrmpChannelClosingHandler: HandleHrmpChannelClosing;\n    ```\n\n- **[`XcmRecorder`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/trait.Config.html#associatedtype.XcmRecorder){target=\\_blank}**: Allows tracking of the most recently executed XCM, primarily for use with dry-run runtime APIs.\n\n    ```rust\n    type XcmRecorder: RecordXcm;\n    ```"}
{"page_id": "develop-interoperability-xcm-config", "index": 3, "depth": 3, "title": "Inner Config", "anchor": "inner-config", "start_char": 18394, "end_char": 20068, "estimated_token_count": 420, "token_estimator": "heuristic-v1", "text": "### Inner Config\n\nThe `Config` trait underpins the `XcmExecutor`, defining its core behavior through associated types for asset handling, XCM processing, and permission management. These types are categorized as follows:\n\n- **Handlers**: Manage XCMs sending, asset transactions, and special notifications.\n- **Filters**: Define trusted combinations, origin substitutions, and execution barriers.\n- **Converters**: Handle origin conversion for call execution.\n- **Accessors**: Provide weight determination and pallet information.\n- **Constants**: Specify universal locations and asset limits.\n- **Common Configs**: Include shared settings like `RuntimeCall`.\n\nThe following diagram outlines this categorization:\n\n```mermaid\nflowchart LR\n    A[Inner Config] --> B[Handlers]\n    A --> C[Filters]\n    A --> D[Converters]\n    A --> E[Accessors]\n    A --> F[Constants]\n    A --> G[Common Configs]\n\n    B --> H[XcmSender]\n    B --> I[AssetTransactor]\n    B --> J[Trader]\n    B --> K[ResponseHandler]\n    B --> L[AssetTrap]\n    B --> M[AssetLocker]\n    B --> N[AssetExchanger]\n    B --> O[AssetClaims]\n    B --> P[SubscriptionService]\n    B --> Q[FeeManager]\n    B --> R[MessageExporter]\n    B --> S[CallDispatcher]\n    B --> T[HrmpNewChannelOpenRequestHandler]\n    B --> U[HrmpChannelAcceptedHandler]\n    B --> V[HrmpChannelClosingHandler]\n\n    C --> W[IsReserve]\n    C --> X[IsTeleporter]\n    C --> Y[Aliasers]\n    C --> Z[Barrier]\n    C --> AA[UniversalAliases]\n    C --> AB[SafeCallFilter]\n\n    D --> AC[OriginConverter]\n\n    E --> AD[Weigher]\n    E --> AE[PalletInstancesInfo]\n\n    F --> AF[UniversalLocation]\n    F --> AG[MaxAssetsIntoHolding]\n\n    G --> AH[RuntimeCall]\n```"}
{"page_id": "develop-interoperability-xcm-config", "index": 4, "depth": 3, "title": "Outer Config", "anchor": "outer-config", "start_char": 20068, "end_char": 20483, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "### Outer Config\n\nThe `XcmExecutor<Config>` struct extends the functionality of the inner config by introducing fields for execution context, asset handling, error tracking, and operational management. For further details, see the documentation for [`XcmExecutor<Config>`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm_executor/struct.XcmExecutor.html#impl-XcmExecutor%3CConfig%3E){target=\\_blank}."}
{"page_id": "develop-interoperability-xcm-config", "index": 5, "depth": 2, "title": "Multiple Implementations", "anchor": "multiple-implementations", "start_char": 20483, "end_char": 21710, "estimated_token_count": 249, "token_estimator": "heuristic-v1", "text": "## Multiple Implementations\n\nSome associated types in the `Config` trait are highly configurable and may have multiple implementations (e.g., Barrier). These implementations are organized into a tuple `(impl_1, impl_2, ..., impl_n)`, and the execution follows a sequential order. Each item in the tuple is evaluated individually, each being checked to see if it fails. If an item passes (e.g., returns `Ok` or `true`), the execution stops, and the remaining items are not evaluated. The following example of the `Barrier` type demonstrates how this grouping operates (understanding each item in the tuple is unnecessary for this explanation).\n\nIn the following example, the system will first check the `TakeWeightCredit` type when evaluating the barrier. If it fails, it will check `AllowTopLevelPaidExecutionFrom`, and so on, until one of them returns a positive result. If all checks fail, a Barrier error will be triggered.\n\n```rust\n-pub type Barrier = (\n    TakeWeightCredit,\n    AllowTopLevelPaidExecutionFrom<Everything>,\n    AllowKnownQueryResponses<XcmPallet>,\n    AllowSubscriptionsFrom<Everything>,\n);\n\npub struct XcmConfig;\nimpl xcm_executor::Config for XcmConfig {\n    ...\n    type Barrier = Barrier;\n    ...\n}\n```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 27, "end_char": 374, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhen XCM execution fails or succeeds, leftover assets can become \"trapped\" on the destination chain. These assets are held by the system but are not accessible through normal means. XCM provides mechanisms to claim these trapped assets and recover them.\nThis guide details the process and required steps to claim trapped assets."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 1, "depth": 2, "title": "Trapped Assets Causes", "anchor": "trapped-assets-causes", "start_char": 374, "end_char": 1135, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Trapped Assets Causes\n\nAssets become trapped whenever execution halts and there are leftover assets. This can happen for example if:\n\n- An XCM execution throws an error in any instruction when assets are in holding such as:\n    - `DepositAsset` can't deposit because the account doesn't exist.\n    - `Transact` can't execute the call because it doesn't exist.\n    - `PayFees` not enough funds or not paying enough for execution.\n\n- XCM execution finishes successfully but not all assets were deposited:\n    - Funds were withdrawn but some were not deposited.\n    - `Transact` overestimated the weight and `RefundSurplus` got some funds into holding that were never deposited\n    - Fees in `PayFees` were overestimated and some were kept there until the end"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 2, "depth": 2, "title": "The `ClaimAsset` Instruction", "anchor": "the-claimasset-instruction", "start_char": 1135, "end_char": 1637, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## The `ClaimAsset` Instruction\n\nThe [`ClaimAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.ClaimAsset){target=\\_blank} instruction allows retrieving assets trapped on a chain:\n\n```typescript\nXcmV5Instruction.ClaimAsset({\n    assets: /* Exact assets to claim, these must match those in the `AssetsTrapped` event */,\n    ticket: /* Additional information about the trapped assets, e.g. the XCM version that was in use at the time */\n});\n```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 3, "depth": 3, "title": "Parameters", "anchor": "parameters", "start_char": 1637, "end_char": 2349, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "### Parameters\n\n- **`assets`**: The trapped assets that want to be claimed. These must be exactly the same as the ones that appear\nin the [`AssetsTrapped`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/enum.Event.html#variant.AssetsTrapped){target=\\_blank} event.\n\n- **`ticket`**: Additional information about the trapped assets. Currently only specifies the XCM version used when the assets got trapped. Must be of the form:\n    ```typescript\n    { \n        parents: 0, \n        interior: XcmV5Junctions.X1(XcmV5Junction.GeneralIndex(INSERT_XCM_VERSION_HERE))\n    }\n    ```\n\n    Ensure to replace the `INSERT_XCM_VERSION_HERE` with the actual XCM version used when the assets got trapped."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 4, "depth": 3, "title": "Basic Claiming Process", "anchor": "basic-claiming-process", "start_char": 2349, "end_char": 4500, "estimated_token_count": 492, "token_estimator": "heuristic-v1", "text": "### Basic Claiming Process\n\nWhen assets are trapped you'll see the `AssetsTrapped` event:\n\n![](/images/develop/interoperability/guides/from-apps/claiming-trapped-assets/assets-trapped-event.webp)\n\nTo claim these assets, a message like the following needs to be sent from the origin:\n\n```typescript\nconst claimAssetsXcm = XcmVersionedXcm.V5([\n  // Claim trapped DOT.\n  XcmV5Instruction.ClaimAsset({\n    assets: [{\n      // USDC.\n      id: {\n        parents: 0,\n        interior: XcmV5Junctions.X2([\n          XcmV5Junction.PalletInstance(50),\n          XcmV5Junction.GeneralIndex(1337n),\n        ]),\n      },\n      fun: XcmV3MultiassetFungibility.Fungible(49_334n) // 0.049334 units.\n    }],\n    // Version 5.\n    ticket: { parents: 0, interior: XcmV5Junctions.X1(XcmV5Junction.GeneralIndex(5n)) }\n  }),\n  XcmV5Instruction.PayFees(/* Pay for fees */),\n  XcmV5Instruction.DepositAsset(/* Deposit everything to an account */),\n]);\n```\n\nNote that this example uses the claimed USDC assets to pay for the execution fees of the claiming message. If the trapped asset cannot be used for fee payment on the destination chain, you need a different approach: first `WithdrawAsset` (with fee-eligible assets), then `PayFees`, then `ClaimAsset`, and finally `DepositAsset`.\n\nIn this case, the origin is a local account so the `execute()` transaction needs to be submitted by that same account. The origin could be another chain, in which case the governance of that chain would need to get involved, or an account on another chain, in which case the `execute()` transaction would need to be submitted on that other chain and a message sent to the chain with trapped funds.\n\nMultiple assets can be claimed with the same message. This is useful when governance needs to get involved.\n\n```typescript\nconst claimAssetsXcm = XcmVersionedXcm.V5([\n  // Claim trapped DOT.\n  XcmV5Instruction.ClaimAsset(/* ... */),\n  XcmV5Instruction.PayFees(/* Pay for fees */),\n  XcmV5Instruction.ClaimAsset(/* ... */),\n  XcmV5Instruction.ClaimAsset(/* ... */),\n  XcmV5Instruction.ClaimAsset(/* ... */),\n  XcmV5Instruction.DepositAsset(/* Deposit everything to an account */),\n]);\n```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 5, "depth": 2, "title": "The `AssetClaimer` Hint", "anchor": "the-assetclaimer-hint", "start_char": 4500, "end_char": 8239, "estimated_token_count": 673, "token_estimator": "heuristic-v1", "text": "## The `AssetClaimer` Hint\n\nThe [`AssetClaimer`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/enum.Hint.html#variant.AssetClaimer){target=\\_blank} execution hint allows setting a specific location that can claim trapped assets, making the claiming process easier. This is set after withdrawing assets and before anything else:\n\n```typescript\nconst failingXcm = XcmVersionedXcm.V5([\n  // Withdraw 1 DOT (10 decimals).\n  XcmV5Instruction.WithdrawAsset([\n    {\n      id: { parents: 1, interior: XcmV5Junctions.Here() },\n      fun: XcmV3MultiassetFungibility.Fungible(10_000_000_000n),\n    },\n  ]),\n  // Set the asset claimer.\n  XcmV5Instruction.SetHints({\n    hints: [\n      Enum(\n        'AssetClaimer',\n        {\n          location: {\n            parents: 0,\n            interior: XcmV5Junctions.X1(XcmV5Junction.AccountId32({\n              id: FixedSizeBinary.fromAccountId32(SS58_ACCOUNT),\n              network: undefined,\n            })),\n          }\n        }\n      )\n    ]\n  }),\n  // Pay fees.\n  XcmV5Instruction.PayFees({\n    asset: {\n      id: { parents: 1, interior: XcmV5Junctions.Here() },\n      fun: XcmV3MultiassetFungibility.Fungible(1_000_000_000n),\n    },\n  }),\n  // Explicitly trap. Alternatively, doing nothing would still result in the assets getting trapped.\n  XcmV5Instruction.Trap(0n),\n]);\n```\n\nThis allows this other `SS58_ACCOUNT` to claim the trapped assets. This could also be done before a transfer.\n\n??? code \"Teleport with custom asset claimer example\"\n\n    ```typescript\n    const setAssetClaimerRemotely = XcmVersionedXcm.V5([\n      // Withdraw 1 DOT (10 decimals).\n      XcmV5Instruction.WithdrawAsset([\n        {\n          id: { parents: 1, interior: XcmV5Junctions.Here() },\n          fun: XcmV3MultiassetFungibility.Fungible(10_000_000_000n),\n        },\n      ]),\n      // Pay fees.\n      XcmV5Instruction.PayFees({\n        asset: {\n          id: { parents: 1, interior: XcmV5Junctions.Here() },\n          fun: XcmV3MultiassetFungibility.Fungible(1_000_000_000n),\n        },\n      }),\n      // Cross-chain transfer.\n      XcmV5Instruction.InitiateTransfer({\n        destination: { parents: 1, interior: XcmV5Junctions.X1(XcmV5Junction.Parachain(1000)) },\n        remote_fees: Enum(\n          'Teleport',\n          XcmV5AssetFilter.Definite([\n            {\n              id: { parents: 1, interior: XcmV5Junctions.Here() },\n              fun: XcmV3MultiassetFungibility.Fungible(1_000_000_000n),\n            },\n          ])\n        ),\n        preserve_origin: false,\n        assets: [\n          Enum(\n            'Teleport',\n            XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1))\n          ),\n        ],\n        remote_xcm: [\n          // Set the asset claimer on the destination chain.\n          // If any asset gets trapped, this account will be able to claim them.\n          XcmV5Instruction.SetHints({\n            hints: [\n              Enum(\n                'AssetClaimer',\n                {\n                  location: {\n                    parents: 0,\n                    interior: XcmV5Junctions.X1(XcmV5Junction.AccountId32({\n                      id: FixedSizeBinary.fromAccountId32(SS58_ACCOUNT),\n                      network: undefined,\n                    })),\n                  }\n                }\n              )\n            ]\n          }),\n          XcmV5Instruction.DepositAsset({\n            assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n            beneficiary: {\n              parents: 1, interior: XcmV5Junctions.X1(XcmV5Junction.AccountId32({\n                id: FixedSizeBinary.fromAccountId32(SS58_ACCOUNT),\n                network: undefined,\n              })),\n            }\n          }),\n        ],\n      }),\n    ]);\n    ```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-claiming-trapped-assets", "index": 6, "depth": 2, "title": "Best practices", "anchor": "best-practices", "start_char": 8239, "end_char": 8821, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Best practices\n\n1. **Always set a claimer**: Include `SetAssetClaimer` in XCMs with valuable assets.\n2. **Use accessible locations**: Ensure the claimer location is controlled by someone who can act.\n3. **Monitor for failures**: Track XCM execution to detect when claiming is needed.\n4. **Test claiming flows**: Verify your claiming logic works in test environments.\n5. **Document recovery procedures**: Maintain clear instructions for asset recovery.\n\nSetting a custom asset claimer is a good practice for recovering trapped assets without the need for governance intervention."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-fees", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 8, "end_char": 1091, "estimated_token_count": 233, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn blockchain systems, fees are crucial. They prevent malicious actors from exhausting the results of the network, making such attacks expensive. The XCM subsystem has its own way of dealing with fees, flexible enough to allow feeless execution in situations that warrant it.\n\nIt's important to distinguish between **transaction fees** and **XCM fees**. Transaction fees are paid when submitting extrinsics to a blockchain. XCM fees, on the other hand, are charged for processing XCM instructions and consist of execution fees (computational costs) and delivery fees (message transport costs). While a transaction can include XCM fees, as happens with [`palletXcm.execute()`](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm/pallet/struct.Pallet.html#method.execute){target=\\_blank} extrinsic, they are separate fee systems. When a chain receives and processes an XCM message, it charges XCM fees but no transaction fees, since no extrinsic is being submitted.\n\nThere are two main types of fees in XCM: [execution](#execution) and [delivery](#delivery)."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-fees", "index": 1, "depth": 2, "title": "Execution", "anchor": "execution", "start_char": 1091, "end_char": 1661, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "## Execution\n\nAll XCMs have a weight associated with them. Each XCM instruction is benchmarked for a particular system (blockchain), which assigns them a weight. The weight of an XCM is the sum of the weight of all instructions. It's important to correctly benchmark this with the worst case so that your system is safe from [Denial-of-Service (DoS)](https://en.wikipedia.org/wiki/Denial-of-service_attack){target=\\_blank} attacks.\n\nThis generated weight represents how much time, and space, is needed for executing the XCM. It directly translates to _execution fees_."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-fees", "index": 2, "depth": 2, "title": "Delivery", "anchor": "delivery", "start_char": 1661, "end_char": 1954, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "## Delivery\n\nXCMs, although capable of performing tasks locally, are meant to be sent to other consensus systems, i.e. blockchains.\n_Delivery fees_ are charged when a message is sent to a destination. The delivery fee amount depends on the size of the message, in bytes, and the destination."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-fees", "index": 3, "depth": 2, "title": "PayFees", "anchor": "payfees", "start_char": 1954, "end_char": 3856, "estimated_token_count": 409, "token_estimator": "heuristic-v1", "text": "## PayFees\n\nIn order to keep things simpler, these two fees are dealt in the same way. The user is asked to input the maximum amount they want to dedicate for fees. This amount is used _only_ for fees.\n\nThe amount is specified using the [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.PayFees){target=\\_blank} instruction:\n\n```typescript\nXcmV5Instruction.PayFees({\n  asset: {\n    id: // Asset id.\n    fun: // Fungibility. Specify the amount if fungible or the instance if NFT.\n  },\n})\n```\n\nThis mechanism is simple and flexible. The user requires no knowledge of the different types of fees. New fees might arise in the future and they'll be taken using this same mechanism, without the need for any modification.\n\nWhich assets can be used for fee payment depends on the destination chain's configuration. For example, on [Asset Hub](/polkadot-protocol/architecture/system-chains/asset-hub/){target=\\_blank}, fees can be paid with any asset that has a liquidity pool with DOT, allowing the chain to automatically convert the fee asset to DOT for actual fee payment. Other chains may have different fee payment policies, so it's important to understand the specific requirements of the destination chain before selecting fee assets.\n\n!!! note \"Sufficient assets vs fee payment assets\"\n\n    It's important to distinguish between \"sufficient\" assets and assets eligible for fee payment. Sufficient assets can be used to satisfy the [Existential Deposit](/polkadot-protocol/glossary/#existential-deposit){target=\\_blank} requirement for account creation and maintenance, but this doesn't automatically make them eligible for fee payment. While sufficient assets are generally also usable for fee payment, this isn't guaranteed and depends on the chain's specific configuration. The terms are related but serve different purposes in system."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-fees", "index": 4, "depth": 2, "title": "Estimations", "anchor": "estimations", "start_char": 3856, "end_char": 6304, "estimated_token_count": 620, "token_estimator": "heuristic-v1", "text": "## Estimations\n\nThe entirety of the asset passed to [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.PayFees){target=\\_blank} will be taken from the effective assets and used only for fees. This means if you overestimate the fees required, you'll be losing efficiency.\n\nIt's necessary to have a mechanism to accurately estimate the fee needed so it can be put into [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.PayFees){target=\\_blank}. This is more complicated than it sounds since the process involves execution and delivery fees, potentially in multiple hops.\n\nImagine a scenario where parachain A sends a message to B which forwards another message to C:\n\n``` mermaid\nflowchart LR\n  A(Parachain A) --sends message--> B(Parachain B)\n  B --forwards message--> C(Parachain C)\n```\n\n1. Execution fees need to be paid on A.\n2. Delivery fees need to be paid from A to B.\n3. Execution occurs on B.\n4. Delivery from B to C.\n5. Execution occurs on C.\n\nAn XCM that does this might look like so:\n\n```typescript\nconst xcm = XcmVersionedXcm.V5([\n  XcmV5Instruction.WithdrawAsset(/* some assets */),\n  XcmV5Instruction.PayFees(/* execution + delivery on A */),\n  XcmV5Instruction.InitiateTransfer({\n    // ...\n    remote_fees: /* execution + delivery on B */,\n    remote_xcm: [\n      XcmV5Instruction.InitiateTransfer({\n        // ...\n        remote_fees: /* execution on C */,\n        // ...\n      }),\n    ],\n    // ...\n  }),\n])\n```\n\nPaying fees on a remote system is so common that the [`InitiateTransfer`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.InitiateTransfer){target=\\_blank} instruction provides the [`remote_fees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.InitiateTransfer.field.remote_fees){target=\\_blank} parameter for this purpose. When `remote_fees` is specified, it automatically generates a [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.PayFees){target=\\_blank} instruction on the destination chain using the specified fees, eliminating the need to manually add [`PayFees`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.PayFees){target=\\_blank} to the `remote_xcm` parameter."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transact", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 2141, "estimated_token_count": 525, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [`Transact`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.Transact){target=\\_blank} instruction enables arbitrary cross-chain execution of pallet calls or smart contract functions. It's one of the most powerful XCM instructions because it allows you to perform any operation that would normally be done locally on a remote chain. However, it requires knowing the implementation details of the destination chain.\n\nThe basic structure of the [`Transact`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.Transact){target=\\_blank} instruction is as follows:\n\n```typescript\nXcmV5Instruction.Transact({\n  call: /* The encoded call to execute */,\n  origin_kind: /* OriginKind specifying how to treat the origin */,\n  fallback_max_weight: /* Optional weight limit for non-v5 destinations */,\n})\n```\n\nThe parameters are as follows:\n\n- **`call`**: The encoded runtime call to execute on the destination chain.\n- **`origin_kind`**: Specifies how the origin should be interpreted on the destination chain:\n    - [`Native`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v3/enum.OriginKind.html#variant.Native){target=\\_blank}: Execute as the native account of the origin.\n    - [`SovereignAccount`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v3/enum.OriginKind.html#variant.SovereignAccount){target=\\_blank}: Execute as the sovereign account of the origin.\n    - [`Superuser`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v3/enum.OriginKind.html#variant.Superuser){target=\\_blank}: Execute with root privileges (requires special configuration).\n    - [`Xcm`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v3/enum.OriginKind.html#variant.Xcm){target=\\_blank}: Execute as a generic XCM origin.\n- **`fallback_max_weight`**: Optional weight limit for execution:\n    - `None`: Let the destination chain calculate weight automatically (requires XCMv5 support).\n    - `Some(weight)`: Specify maximum weight for backward compatibility with pre-v5 chains."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transact", "index": 1, "depth": 2, "title": "Chain-Specific Knowledge Required", "anchor": "chain-specific-knowledge-required", "start_char": 2141, "end_char": 2730, "estimated_token_count": 158, "token_estimator": "heuristic-v1", "text": "## Chain-Specific Knowledge Required\n\nUnlike other XCM instructions like [`DepositAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.DepositAsset){target=\\_blank} or [`WithdrawAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.WithdrawAsset){target=\\_blank}, which are generic, [`Transact`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.Transact){target=\\_blank} requires detailed knowledge of the destination chain:"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transact", "index": 2, "depth": 3, "title": "Required Knowledge", "anchor": "required-knowledge", "start_char": 2730, "end_char": 3026, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "### Required Knowledge\n\n1. **Runtime metadata**: The specific pallets, calls, and their parameters available on the destination chain.\n2. **Call encoding**: How to properly encode the call data for the destination runtime.\n3. **Permissions**: What origins are allowed to execute specific calls."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transact", "index": 3, "depth": 3, "title": "Examples of Chain-Specific Requirements", "anchor": "examples-of-chain-specific-requirements", "start_char": 3026, "end_char": 3483, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "### Examples of Chain-Specific Requirements\n\n```typescript\n// Example: Different chains have different ways to represent the same operation\n\n// Asset Hub - using pallet_assets\nconst assetHubCall = api.tx.Assets.transfer({\n  id: 1984, // USDT\n  target: beneficiary,\n  amount: 1_000_000n\n})\n\n// Hydration - using pallet_currencies\nconst hydrationCall = api.tx.Currencies.transfer({\n  dest: beneficiary,\n  currency_id: 10, // USDT\n  amount: 1_000_000n\n})\n```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transact", "index": 4, "depth": 2, "title": "Origin Considerations", "anchor": "origin-considerations", "start_char": 3483, "end_char": 4444, "estimated_token_count": 233, "token_estimator": "heuristic-v1", "text": "## Origin Considerations\n\nThe choice of [`origin_kind`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.Transact.field.origin_kind){target=\\_blank} significantly affects what operations are permitted:\n\n- Use [`SovereignAccount`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v3/enum.OriginKind.html#variant.SovereignAccount){target=\\_blank} for most application use cases.\n- [`Superuser`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v3/enum.OriginKind.html#variant.Superuser){target=\\_blank} requires special trust relationships and configuration.\n- Consider how the destination chain interprets different origin kinds.\n\nThe [`Transact`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/opaque/type.Instruction.html#variant.Transact){target=\\_blank} instruction is powerful but requires careful consideration of the trade-offs between flexibility and maintainability."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transfers", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 789, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [`InitiateTransfer`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.InitiateTransfer){target=\\_blank} instruction is the primary mechanism for cross-chain transfers in XCM. It provides a unified interface for different types of transfers and brings additional functionalities not possible with previous instruction versions.\n\n```typescript\nXcmV5Instruction.InitiateTransfer({\n  destination: /* location of recipient */,\n  remote_fees: /* fees for recipient */,\n  preserve_origin: /* whether or not the original origin should be preserved */,\n  assets: /* the assets being transferred and the type of transfer */,\n  remote_xcm: /* xcm to be executed in the recipient after transferring the assets */,\n})\n```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transfers", "index": 1, "depth": 2, "title": "Transfer Types", "anchor": "transfer-types", "start_char": 789, "end_char": 3447, "estimated_token_count": 625, "token_estimator": "heuristic-v1", "text": "## Transfer Types\n\nThe `remote_fees` parameter only takes one asset, while `assets` can list multiple. Both must specify a **transfer type** — either:\n\n- [**Teleport**](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.AssetTransferFilter.html#variant.Teleport){target=\\_blank} – Moves assets by effectively \"destroying\" them on the source chain and \"creating\" them on the destination. Useful when both chains trust each other for that asset.\n- [**Reserve Deposit**](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.AssetTransferFilter.html#variant.ReserveDeposit){target=\\_blank} – A reserve transfer where _your chain is the reserve_ for the asset. The asset stays locked on your chain, and a representation is minted on the destination.\n- [**Reserve Withdraw**](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.AssetTransferFilter.html#variant.ReserveWithdraw){target=\\_blank} – A reserve transfer where _the destination chain is the reserve_. Assets are withdrawn from their reserve location and credited to the recipient.\n\nThese types come from the [`AssetTransferFilter`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.AssetTransferFilter.html){target=\\_blank} enum in XCM.\n\nFor example, to transfer 50 DOT via a teleport, the transfer type must be specified as a teleport. This also requires using an [Asset Filter](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.AssetFilter.html){target=\\_blank}.\n\nInstead of this:\n\n```typescript\nconst assets = [\n  XcmV5AssetFilter.Definite([\n    {\n      id: DOT,\n      fun: XcmV3MultiassetFungibility.Fungible(50n * DOT_UNITS),\n    },\n  ]),\n];\n```\n\nThe correct approach is:\n\n```typescript\nconst assets = [\n  Enum(\n    'Teleport',\n    XcmV5AssetFilter.Definite([\n      {\n        id: DOT,\n        fun: XcmV3MultiassetFungibility.Fungible(50n * DOT_UNITS),\n      },\n    ]),\n  ),\n];\n```\n\nThis allows specifying multiple assets with multiple different transfer types. It also allows sending the remote fees with a different transfer type. For example:\n\n```typescript\nconst remoteFees = Enum(\n  'ReserveDeposit',\n  XcmV5AssetFilter.Definite([\n    {\n      id: ETH,\n      fun: ...,\n    },\n  ]),\n);\nconst assets = [\n  Enum(\n    'Teleport',\n    XcmV5AssetFilter.Definite([\n      {\n        id: DOT,\n        fun: XcmV3MultiassetFungibility.Fungible(50n * DOT_UNITS),\n      },\n    ]),\n  ),\n  Enum(\n    'ReserveDeposit',\n    XcmV5AssetFilter.Definite([\n      {\n        id: USDT,\n        fun: ...,\n      },\n      {\n        id: USDC,\n        fun: ...,\n      },\n    ]),\n  ),\n];\n```\n\nNote that `remoteFees` takes only one asset."}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transfers", "index": 2, "depth": 2, "title": "Remote Fees", "anchor": "remote-fees", "start_char": 3447, "end_char": 10519, "estimated_token_count": 1537, "token_estimator": "heuristic-v1", "text": "## Remote Fees\n\nPaying fees on the remote chain is such a common operation that [`InitiateTransfer`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.InitiateTransfer){target=\\_blank} has a parameter for it.\nJust by specifying the assets that go here, the XCM on the destination will include a `PayFees` instruction.\nAs mentioned before, you need to specify the transfer type.\n\n!!! note \"Do I have to specify remote fees all the time?\"\n\n    Yes. Fees are important for decentralized systems to prevent spam. Although it is possible to not specify remote fees, this is most likely not what you want when developing applications. Omitting the remote fees will append an [`UnpaidExecution`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.UnpaidExecution){target=\\_blank} instruction to the remote XCM. This instruction signals to the destination system that there is a reason execution is allowed a message without paying for fees.\n\n    This usually means you're a privileged origin, like `Root` or the `Fellowship` origin. It's mostly used from the runtime of the Polkadot SDK-based chains instead of from applications.\n\n??? code \"Teleport Example\"\n\n    This example creates an XCM program that teleports DOT from Asset Hub to People. The following code uses the PAPI library, check out the [PAPI guide](/develop/toolkit/api-libraries/papi/){target=\\_blank} for more information.\n\n    The setup for this script is [installing PAPI](/develop/toolkit/api-libraries/papi#get-started){target=\\_blank} and generating descriptors for Asset Hub:\n    `bun papi add ahp -n polkadot_asset_hub`\n\n    ```typescript title=\"teleport-example.ts\"\n    -// `ahp` is the name given to `npx papi add`\nimport {\n  ahp,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3MultiassetFungibility,\n  XcmV5AssetFilter,\n  XcmV5Instruction,\n  XcmV5Junction,\n  XcmV5Junctions,\n  XcmV5WildAsset,\n  XcmVersionedXcm,\n} from '@polkadot-api/descriptors';\nimport { createClient, Enum, FixedSizeBinary } from 'polkadot-api';\n// import from \"polkadot-api/ws-provider/node\"\n// if running in a NodeJS environment\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport { sr25519CreateDerive } from '@polkadot-labs/hdkd';\nimport {\n  DEV_PHRASE,\n  entropyToMiniSecret,\n  mnemonicToEntropy,\n} from '@polkadot-labs/hdkd-helpers';\nimport { getPolkadotSigner } from 'polkadot-api/signer';\n\nconst entropy = mnemonicToEntropy(DEV_PHRASE);\nconst miniSecret = entropyToMiniSecret(entropy);\nconst derive = sr25519CreateDerive(miniSecret);\nconst keyPair = derive('//Alice');\n\nconst polkadotSigner = getPolkadotSigner(\n  keyPair.publicKey,\n  'Sr25519',\n  keyPair.sign\n);\n\n// Connect to Polkadot Asset Hub.\n// Pointing to localhost since this example uses chopsticks.\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('ws://localhost:8000'))\n);\n\n// Get the typed API, a typesafe API for interacting with the chain.\nconst ahpApi = client.getTypedApi(ahp);\n\nconst PEOPLE_PARA_ID = 1004;\n// The identifier for DOT is the location of the Polkadot Relay Chain,\n// which is 1 up relative to any parachain.\nconst DOT = {\n  parents: 1,\n  interior: XcmV3Junctions.Here(),\n};\n// DOT has 10 decimals.\nconst DOT_UNITS = 10_000_000_000n;\n\n// The DOT to withdraw for both fees and transfer.\nconst dotToWithdraw = {\n  id: DOT,\n  fun: XcmV3MultiassetFungibility.Fungible(10n * DOT_UNITS),\n};\n// The DOT to use for local fee payment.\nconst dotToPayFees = {\n  id: DOT,\n  fun: XcmV3MultiassetFungibility.Fungible(1n * DOT_UNITS),\n};\n// The location of the People Chain from Asset Hub.\nconst destination = {\n  parents: 1,\n  interior: XcmV3Junctions.X1(XcmV3Junction.Parachain(PEOPLE_PARA_ID)),\n};\n// Pay for fees on the People Chain with teleported DOT.\n// This is specified independently of the transferred assets since they're used\n// exclusively for fees. Also because fees can be paid in a different\n// asset from the transferred assets.\nconst remoteFees = Enum(\n  'Teleport',\n  XcmV5AssetFilter.Definite([\n    {\n      id: DOT,\n      fun: XcmV3MultiassetFungibility.Fungible(1n * DOT_UNITS),\n    },\n  ])\n);\n// No need to preserve origin for this example.\nconst preserveOrigin = false;\n// The assets to transfer are whatever remains in the\n// holding register at the time of executing the `InitiateTransfer`\n// instruction. DOT in this case, teleported.\nconst assets = [\n  Enum('Teleport', XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1))),\n];\n// The beneficiary is the same account but on the People Chain.\n// This is a very common pattern for one public/private key pair\n// to hold assets on multiple chains.\nconst beneficiary = FixedSizeBinary.fromBytes(keyPair.publicKey);\n// The XCM to be executed on the destination chain.\n// It's basically depositing everything to the beneficiary.\nconst remoteXcm = [\n  XcmV5Instruction.DepositAsset({\n    assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV5Junctions.X1(\n        XcmV5Junction.AccountId32({\n          id: beneficiary,\n          network: undefined,\n        })\n      ),\n    },\n  }),\n];\n\n// The message assembles all the previously defined parameters.\nconst xcm = XcmVersionedXcm.V5([\n  XcmV5Instruction.WithdrawAsset([dotToWithdraw]),\n  XcmV5Instruction.PayFees({ asset: dotToPayFees }),\n  XcmV5Instruction.InitiateTransfer({\n    destination,\n    remote_fees: remoteFees,\n    preserve_origin: preserveOrigin,\n    assets,\n    remote_xcm: remoteXcm,\n  }),\n  // Return any leftover fees from the fees register back to holding.\n  XcmV5Instruction.RefundSurplus(),\n  // Deposit remaining assets (refunded fees) to the originating account.\n  // Using AllCounted(1) since only one asset type (DOT) remains - a minor optimization.\n  XcmV5Instruction.DepositAsset({\n    assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV5Junctions.X1(\n        XcmV5Junction.AccountId32({\n          id: beneficiary, // The originating account.\n          network: undefined,\n        })\n      ),\n    },\n  }),\n]);\n\n// The XCM weight is needed to set the `max_weight` parameter\n// on the actual `PolkadotXcm.execute()` call.\nconst weightResult = await ahpApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n\nif (weightResult.success) {\n  const weight = weightResult.success\n    ? weightResult.value\n    : { ref_time: 0n, proof_size: 0n };\n\n  console.dir(weight);\n\n  // The actual transaction to submit.\n  // This tells Asset Hub to execute the XCM.\n  const tx = ahpApi.tx.PolkadotXcm.execute({\n    message: xcm,\n    max_weight: weight,\n  });\n\n  // Sign and propagate to the network.\n  const result = await tx.signAndSubmit(polkadotSigner);\n  console.log(stringify(result));\n}\n\nclient.destroy();\n\n// A helper function to print numbers inside of the result.\nfunction stringify(obj: any) {\n  return JSON.stringify(\n    obj,\n    (_, v) => (typeof v === 'bigint' ? v.toString() : v),\n    2\n  );\n}\n\n    ```"}
{"page_id": "develop-interoperability-xcm-guides-from-apps-transfers", "index": 3, "depth": 2, "title": "Origin Preservation", "anchor": "origin-preservation", "start_char": 10519, "end_char": 18928, "estimated_token_count": 1858, "token_estimator": "heuristic-v1", "text": "## Origin Preservation\n\nIn previous versions of XCM, doing cross-chain transfers meant losing the origin. The XCM on the destination chain would have access to the transferred assets, but not to the origin. This means any instruction which uses assets but not the origin could be executed, that's enough to call [`DepositAsset`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.DepositAsset){target=\\_blank} for example and complete the transfer, but not to call [`Transact`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.Transact){target=\\_blank} and execute a call.\n\nIn XCMv5, [`InitiateTransfer`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.InitiateTransfer){target=\\_blank} allows **preserving the origin**, enabling more use-cases such as executing a call on the destination chain via [`Transact`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.Transact){target=\\_blank}.\nTo enable this feature, the [`preserve_origin`](https://paritytech.github.io/polkadot-sdk/master/staging_xcm/v5/enum.Instruction.html#variant.InitiateTransfer.field.preserve_origin){target=\\_blank} parameter must be set to `true`.\n\n!!! note \"Why isn't preserving the origin the default?\"\n\n    Preserving the origin requires a specific configuration on the underlying chain executing the XCM. Some chains have the right configuration, for example all system chains, but not every chain has it. If you make a transfer with `preserve_origin: true` to a chain configured incorrectly, the transfer will fail.\n\n    However, if you set `preserve_origin: false` then there is no problem. Because of this, origin preservation is not the default, and likely never will be.\n\n??? code \"Teleport and Transact Example\"\n\n    This example creates an XCM program that teleports DOT from Asset Hub to People and executes a call there. The whole script is almost the same as the one for a simple teleport above, most changes are in the `remoteXcm` variable.\n\n    The setup for this script is [installing PAPI](/develop/toolkit/api-libraries/papi#get-started){target=\\_blank} and generating descriptors for both Asset Hub and People:\n    `bun papi add ahp -n polkadot_asset_hub && bun papi add people -n polkadot_people`\n\n    ```typescript title=\"teleport-and-transact.ts\"\n    -// `ahp` is the name given to `npx papi add`\nimport {\n  ahp,\n  people,\n  XcmV2OriginKind,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3MultiassetFungibility,\n  XcmV5AssetFilter,\n  XcmV5Instruction,\n  XcmV5Junction,\n  XcmV5Junctions,\n  XcmV5WildAsset,\n  XcmVersionedXcm,\n} from '@polkadot-api/descriptors';\nimport { Binary, createClient, Enum, FixedSizeBinary } from 'polkadot-api';\n// import from \"polkadot-api/ws-provider/node\"\n// if running in a NodeJS environment\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport { sr25519CreateDerive } from '@polkadot-labs/hdkd';\nimport {\n  DEV_PHRASE,\n  entropyToMiniSecret,\n  mnemonicToEntropy,\n  ss58Address,\n} from '@polkadot-labs/hdkd-helpers';\nimport { getPolkadotSigner } from 'polkadot-api/signer';\n\nconst entropy = mnemonicToEntropy(DEV_PHRASE);\nconst miniSecret = entropyToMiniSecret(entropy);\nconst derive = sr25519CreateDerive(miniSecret);\nconst keyPair = derive('//Alice');\n\nconst polkadotSigner = getPolkadotSigner(\n  keyPair.publicKey,\n  'Sr25519',\n  keyPair.sign\n);\n\n// Connect to Polkadot Asset Hub.\n// Pointing to localhost since this example uses chopsticks.\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('ws://localhost:8000'))\n);\n\n// Get the typed API, a typesafe API for interacting with the chain.\nconst ahpApi = client.getTypedApi(ahp);\n\nconst PEOPLE_PARA_ID = 1004;\n// The identifier for DOT is the location of the Polkadot Relay Chain,\n// which is 1 up relative to any parachain.\nconst DOT = {\n  parents: 1,\n  interior: XcmV3Junctions.Here(),\n};\n// DOT has 10 decimals.\nconst DOT_UNITS = 10_000_000_000n;\n\n// The DOT to withdraw for both fees and transfer.\nconst dotToWithdraw = {\n  id: DOT,\n  fun: XcmV3MultiassetFungibility.Fungible(10n * DOT_UNITS),\n};\n// The DOT to use for local fee payment.\nconst dotToPayFees = {\n  id: DOT,\n  fun: XcmV3MultiassetFungibility.Fungible(1n * DOT_UNITS),\n};\n// The location of the People Chain from Asset Hub.\nconst destination = {\n  parents: 1,\n  interior: XcmV3Junctions.X1(XcmV3Junction.Parachain(PEOPLE_PARA_ID)),\n};\n// Pay for fees on the People Chain with teleported DOT.\n// This is specified independently of the transferred assets since they're used\n// exclusively for fees. Also because fees can be paid in a different\n// asset from the transferred assets.\nconst remoteFees = Enum(\n  'Teleport',\n  XcmV5AssetFilter.Definite([\n    {\n      id: DOT,\n      fun: XcmV3MultiassetFungibility.Fungible(1n * DOT_UNITS),\n    },\n  ])\n);\n// No need to preserve origin for this example.\nconst preserveOrigin = false;\n// The assets to transfer are whatever remains in the\n// holding register at the time of executing the `InitiateTransfer`\n// instruction. DOT in this case, teleported.\nconst assets = [\n  Enum('Teleport', XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1))),\n];\n// The beneficiary is the same account but on the People Chain.\n// This is a very common pattern for one public/private key pair\n// to hold assets on multiple chains.\nconst beneficiary = FixedSizeBinary.fromBytes(keyPair.publicKey);\n// The call to be executed on the destination chain.\n// It's a simple remark with an event.\n// Create the call on Asset Hub since the system pallet is present in\n// every runtime, but if using any other pallet, connect to\n// the destination chain and create the call there.\nconst remark = Binary.fromText('Hello, cross-chain!');\nconst call = await ahpApi.tx.System.remark_with_event({\n  remark,\n}).getEncodedData();\n// The XCM to be executed on the destination chain.\n// It's basically depositing everything to the beneficiary.\nconst remoteXcm = [\n  XcmV5Instruction.Transact({\n    origin_kind: XcmV2OriginKind.SovereignAccount(),\n    fallback_max_weight: undefined,\n    call,\n  }),\n  XcmV5Instruction.RefundSurplus(),\n  XcmV5Instruction.DepositAsset({\n    assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV5Junctions.X1(\n        XcmV5Junction.AccountId32({\n          id: beneficiary,\n          network: undefined,\n        })\n      ),\n    },\n  }),\n];\n\n// The message assembles all the previously defined parameters.\nconst xcm = XcmVersionedXcm.V5([\n  XcmV5Instruction.WithdrawAsset([dotToWithdraw]),\n  XcmV5Instruction.PayFees({ asset: dotToPayFees }),\n  XcmV5Instruction.InitiateTransfer({\n    destination,\n    remote_fees: remoteFees,\n    preserve_origin: preserveOrigin,\n    assets,\n    remote_xcm: remoteXcm,\n  }),\n  // Return any leftover fees from the fees register back to holding.\n  XcmV5Instruction.RefundSurplus(),\n  // Deposit remaining assets (refunded fees) to the originating account.\n  // Using AllCounted(1) since only one asset type (DOT) remains - a minor optimization.\n  XcmV5Instruction.DepositAsset({\n    assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV5Junctions.X1(\n        XcmV5Junction.AccountId32({\n          id: beneficiary, // The originating account.\n          network: undefined,\n        })\n      ),\n    },\n  }),\n]);\n\n// The XCM weight is needed to set the `max_weight` parameter\n// on the actual `PolkadotXcm.execute()` call.\nconst weightResult = await ahpApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n\nif (weightResult.success) {\n  const weight = weightResult.success\n    ? weightResult.value\n    : { ref_time: 0n, proof_size: 0n };\n\n  console.dir(weight);\n\n  // The actual transaction to submit.\n  // This tells Asset Hub to execute the XCM.\n  const tx = ahpApi.tx.PolkadotXcm.execute({\n    message: xcm,\n    max_weight: weight,\n  });\n\n  // Sign and propagate to the network.\n  const result = await tx.signAndSubmit(polkadotSigner);\n  console.log(stringify(result));\n}\n\nclient.destroy();\n\n// A helper function to print numbers inside of the result.\nfunction stringify(obj: any) {\n  return JSON.stringify(\n    obj,\n    (_, v) => (typeof v === 'bigint' ? v.toString() : v),\n    2\n  );\n}\n\n    ```"}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 932, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRuntime APIs allow node-side code to extract information from the runtime state. While simple storage access retrieves stored values directly, runtime APIs enable arbitrary computation, making them a powerful tool for interacting with the chain's state.\n\nUnlike direct storage access, runtime APIs can derive values from storage based on arguments or perform computations that don't require storage access. For example, a runtime API might expose a formula for fee calculation, using only the provided arguments as inputs rather than fetching data from storage.\n\nIn general, runtime APIs are used for:\n\n- Accessing a storage item.\n- Retrieving a bundle of related storage items.\n- Deriving a value from storage based on arguments.\n- Exposing formulas for complex computational calculations.\n\nThis section will teach you about specific runtime APIs that support XCM processing and manipulation."}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 1, "depth": 2, "title": "Dry Run API", "anchor": "dry-run-api", "start_char": 932, "end_char": 1492, "estimated_token_count": 140, "token_estimator": "heuristic-v1", "text": "## Dry Run API\n\nThe [Dry-run API](https://paritytech.github.io/polkadot-sdk/master/xcm_runtime_apis/dry_run/trait.DryRunApi.html){target=\\_blank}, given an extrinsic, or an XCM program, returns its effects:\n\n- Execution result\n- Local XCM (in the case of an extrinsic)\n- Forwarded XCMs\n- List of events\n\nThis API can be used independently for dry-running, double-checking, or testing. However, it mainly shines when used with the [Xcm Payment API](#xcm-payment-api), given that it only estimates fees if you know the specific XCM you want to execute or send."}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 2, "depth": 3, "title": "Dry Run Call", "anchor": "dry-run-call", "start_char": 1492, "end_char": 23918, "estimated_token_count": 3675, "token_estimator": "heuristic-v1", "text": "### Dry Run Call\n\nThis API allows a dry-run of any extrinsic and obtaining the outcome if it fails or succeeds, as well as the local xcm and remote xcm messages sent to other chains.\n\n```rust\n-fn dry_run_call(origin: OriginCaller, call: Call, result_xcms_version: XcmVersion) -> Result<CallDryRunEffects<Event>, Error>;\n```\n\n??? interface \"Input parameters\"\n\n    `origin` ++\"OriginCaller\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    The origin used for executing the transaction.\n\n    ---\n\n    `call` ++\"Call\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    The extrinsic to be executed.\n\n    ---\n\n??? interface \"Output parameters\"\n\n    ++\"Result<CallDryRunEffects<Event>, Error>\"++\n\n    Effects of dry-running an extrinsic. If an error occurs, it is returned instead of the effects.\n\n    ??? child \"Type `CallDryRunEffects<Event>`\"\n\n        `execution_result` ++\"DispatchResultWithPostInfo\"++\n\n        The result of executing the extrinsic.\n\n        ---\n\n        `emitted_events` ++\"Vec<Event>\"++\n\n        The list of events fired by the extrinsic.\n\n        ---\n\n        `local_xcm` ++\"Option<VersionedXcm<()>>\"++\n\n        The local XCM that was attempted to be executed, if any.\n\n        ---\n\n        `forwarded_xcms` ++\"Vec<(VersionedLocation, Vec<VersionedXcm<()>>)>\"++\n\n        The list of XCMs that were queued for sending.\n\n    ??? child \"Type `Error`\"\n\n        Enum:\n\n        - **`Unimplemented`**: An API part is unsupported.\n        - **`VersionedConversionFailed`**: Converting a versioned data structure from one version to another failed.\n\n??? interface \"Example\"\n\n    This example demonstrates how to simulate a cross-chain asset transfer from the Paseo network to the Pop Network using a [reserve transfer](https://wiki.polkadot.com/learn/learn-xcm-usecases/#reserve-asset-transfer){target=\\_blank} mechanism. Instead of executing the actual transfer, the code shows how to test and verify the transaction's behavior through a dry run before performing it on the live network.\n\n    Replace `INSERT_USER_ADDRESS` with your SS58 address before running the script.\n\n    ***Usage with PAPI***\n\n    ```js\n    -import { paseo } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport {\n  PolkadotRuntimeOriginCaller,\n  XcmVersionedLocation,\n  XcmVersionedAssets,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3WeightLimit,\n  XcmV3MultiassetFungibility,\n  XcmV3MultiassetAssetId,\n} from '@polkadot-api/descriptors';\nimport { DispatchRawOrigin } from '@polkadot-api/descriptors';\nimport { Binary } from 'polkadot-api';\nimport { ss58Decode } from '@polkadot-labs/hdkd-helpers';\n\n// Connect to the Paseo relay chain\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('wss://paseo-rpc.dwellir.com')),\n);\n\nconst paseoApi = client.getTypedApi(paseo);\n\nconst popParaID = 4001;\nconst userAddress = 'INSERT_USER_ADDRESS';\nconst userPublicKey = ss58Decode(userAddress)[0];\nconst idBeneficiary = Binary.fromBytes(userPublicKey);\n\n// Define the origin caller\n// This is a regular signed account owned by a user\nlet origin = PolkadotRuntimeOriginCaller.system(\n  DispatchRawOrigin.Signed(userAddress),\n);\n\n// Define a transaction to transfer assets from Polkadot to Pop Network using a Reserve Transfer\nconst tx = paseoApi.tx.XcmPallet.limited_reserve_transfer_assets({\n  dest: XcmVersionedLocation.V3({\n    parents: 0,\n    interior: XcmV3Junctions.X1(\n      XcmV3Junction.Parachain(popParaID), // Destination is the Pop Network parachain\n    ),\n  }),\n  beneficiary: XcmVersionedLocation.V3({\n    parents: 0,\n    interior: XcmV3Junctions.X1(\n      XcmV3Junction.AccountId32({\n        // Beneficiary address on Pop Network\n        network: undefined,\n        id: idBeneficiary,\n      }),\n    ),\n  }),\n  assets: XcmVersionedAssets.V3([\n    {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 0,\n        interior: XcmV3Junctions.Here(), // Native asset from the sender. In this case PAS\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(120000000000n), // Asset amount to transfer\n    },\n  ]),\n  fee_asset_item: 0, // Asset used to pay transaction fees\n  weight_limit: XcmV3WeightLimit.Unlimited(), // No weight limit on transaction\n});\n\n// Execute the dry run call to simulate the transaction\nconst dryRunResult = await paseoApi.apis.DryRunApi.dry_run_call(\n  origin,\n  tx.decodedCall,\n);\n\n// Extract the data from the dry run result\nconst {\n  execution_result: executionResult,\n  emitted_events: emmittedEvents,\n  local_xcm: localXcm,\n  forwarded_xcms: forwardedXcms,\n} = dryRunResult.value;\n\n// Extract the XCM generated by this call\nconst xcmsToPop = forwardedXcms.find(\n  ([location, _]) =>\n    location.type === 'V4' &&\n    location.value.parents === 0 &&\n    location.value.interior.type === 'X1' &&\n    location.value.interior.value.type === 'Parachain' &&\n    location.value.interior.value.value === popParaID, // Pop network's ParaID\n);\nconst destination = xcmsToPop[0];\nconst remoteXcm = xcmsToPop[1][0];\n\n// Print the results\nconst resultObject = {\n  execution_result: executionResult,\n  emitted_events: emmittedEvents,\n  local_xcm: localXcm,\n  destination: destination,\n  remote_xcm: remoteXcm,\n};\n\nconsole.dir(resultObject, { depth: null });\n\nclient.destroy();\n\n    ```\n\n    ***Output***\n\n    -<div id=\"termynal\" data-termynal>\n  <pre>\n    {\n      execution_result: {\n        success: true,\n        value: {\n          actual_weight: undefined,\n          pays_fee: { type: 'Yes', value: undefined }\n        }\n      },\n      emitted_events: [\n        {\n          type: 'Balances',\n          value: {\n            type: 'Transfer',\n            value: {\n              from: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET',\n              to: '13YMK2ePPKQeW7ynqLozB65WYjMnNgffQ9uR4AzyGmqnKeLq',\n              amount: 120000000000n\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: { type: 'Issued', value: { amount: 0n } }\n        },\n        {\n          type: 'XcmPallet',\n          value: {\n            type: 'Attempted',\n            value: {\n              outcome: {\n                type: 'Complete',\n                value: { used: { ref_time: 251861000n, proof_size: 6196n } }\n              }\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Burned',\n            value: {\n              who: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET',\n              amount: 397000000n\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Minted',\n            value: {\n              who: '13UVJyLnbVp9RBZYFwFGyDvVd1y27Tt8tkntv6Q7JVPhFsTB',\n              amount: 397000000n\n            }\n          }\n        },\n        {\n          type: 'XcmPallet',\n          value: {\n            type: 'FeesPaid',\n            value: {\n              paying: {\n                parents: 0,\n                interior: {\n                  type: 'X1',\n                  value: {\n                    type: 'AccountId32',\n                    value: {\n                      network: { type: 'Polkadot', value: undefined },\n                      id: FixedSizeBinary {\n                        asText: [Function (anonymous)],\n                        asHex: [Function (anonymous)],\n                        asOpaqueHex: [Function (anonymous)],\n                        asBytes: [Function (anonymous)],\n                        asOpaqueBytes: [Function (anonymous)]\n                      }\n                    }\n                  }\n                }\n              },\n              fees: [\n                {\n                  id: {\n                    parents: 0,\n                    interior: { type: 'Here', value: undefined }\n                  },\n                  fun: { type: 'Fungible', value: 397000000n }\n                }\n              ]\n            }\n          }\n        },\n        {\n          type: 'XcmPallet',\n          value: {\n            type: 'Sent',\n            value: {\n              origin: {\n                parents: 0,\n                interior: {\n                  type: 'X1',\n                  value: {\n                    type: 'AccountId32',\n                    value: {\n                      network: { type: 'Polkadot', value: undefined },\n                      id: FixedSizeBinary {\n                        asText: [Function (anonymous)],\n                        asHex: [Function (anonymous)],\n                        asOpaqueHex: [Function (anonymous)],\n                        asBytes: [Function (anonymous)],\n                        asOpaqueBytes: [Function (anonymous)]\n                      }\n                    }\n                  }\n                }\n              },\n              destination: {\n                parents: 0,\n                interior: { type: 'X1', value: { type: 'Parachain', value: 4001 } }\n              },\n              message: [\n                {\n                  type: 'ReserveAssetDeposited',\n                  value: [\n                    {\n                      id: {\n                        parents: 1,\n                        interior: { type: 'Here', value: undefined }\n                      },\n                      fun: { type: 'Fungible', value: 120000000000n }\n                    }\n                  ]\n                },\n                { type: 'ClearOrigin', value: undefined },\n                {\n                  type: 'BuyExecution',\n                  value: {\n                    fees: {\n                      id: {\n                        parents: 1,\n                        interior: { type: 'Here', value: undefined }\n                      },\n                      fun: { type: 'Fungible', value: 120000000000n }\n                    },\n                    weight_limit: { type: 'Unlimited', value: undefined }\n                  }\n                },\n                {\n                  type: 'DepositAsset',\n                  value: {\n                    assets: {\n                      type: 'Wild',\n                      value: { type: 'AllCounted', value: 1 }\n                    },\n                    beneficiary: {\n                      parents: 0,\n                      interior: {\n                        type: 'X1',\n                        value: {\n                          type: 'AccountId32',\n                          value: {\n                            network: undefined,\n                            id: FixedSizeBinary {\n                              asText: [Function (anonymous)],\n                              asHex: [Function (anonymous)],\n                              asOpaqueHex: [Function (anonymous)],\n                              asBytes: [Function (anonymous)],\n                              asOpaqueBytes: [Function (anonymous)]\n                            }\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              ],\n              message_id: FixedSizeBinary {\n                asText: [Function (anonymous)],\n                asHex: [Function (anonymous)],\n                asOpaqueHex: [Function (anonymous)],\n                asBytes: [Function (anonymous)],\n                asOpaqueBytes: [Function (anonymous)]\n              }\n            }\n          }\n        }\n      ],\n      local_xcm: undefined,\n      destination: {\n        type: 'V4',\n        value: {\n          parents: 0,\n          interior: { type: 'X1', value: { type: 'Parachain', value: 4001 } }\n        }\n      },\n      remote_xcm: {\n        type: 'V3',\n        value: [\n          {\n            type: 'ReserveAssetDeposited',\n            value: [\n              {\n                id: {\n                  type: 'Concrete',\n                  value: {\n                    parents: 1,\n                    interior: { type: 'Here', value: undefined }\n                  }\n                },\n                fun: { type: 'Fungible', value: 120000000000n }\n              }\n            ]\n          },\n          { type: 'ClearOrigin', value: undefined },\n          {\n            type: 'BuyExecution',\n            value: {\n              fees: {\n                id: {\n                  type: 'Concrete',\n                  value: {\n                    parents: 1,\n                    interior: { type: 'Here', value: undefined }\n                  }\n                },\n                fun: { type: 'Fungible', value: 120000000000n }\n              },\n              weight_limit: { type: 'Unlimited', value: undefined }\n            }\n          },\n          {\n            type: 'DepositAsset',\n            value: {\n              assets: { type: 'Wild', value: { type: 'AllCounted', value: 1 } },\n              beneficiary: {\n                parents: 0,\n                interior: {\n                  type: 'X1',\n                  value: {\n                    type: 'AccountId32',\n                    value: {\n                      network: undefined,\n                      id: FixedSizeBinary {\n                        asText: [Function (anonymous)],\n                        asHex: [Function (anonymous)],\n                        asOpaqueHex: [Function (anonymous)],\n                        asBytes: [Function (anonymous)],\n                        asOpaqueBytes: [Function (anonymous)]\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          },\n          {\n            type: 'SetTopic',\n            value: FixedSizeBinary {\n              asText: [Function (anonymous)],\n              asHex: [Function (anonymous)],\n              asOpaqueHex: [Function (anonymous)],\n              asBytes: [Function (anonymous)],\n              asOpaqueBytes: [Function (anonymous)]\n            }\n          }\n        ]\n      }\n    }      \n  </pre>\n</div>\n\n                ...\n    -<div id=\"termynal\" data-termynal>\n  <pre>\n    {\n      execution_result: {\n        success: true,\n        value: {\n          actual_weight: undefined,\n          pays_fee: { type: 'Yes', value: undefined }\n        }\n      },\n      emitted_events: [\n        {\n          type: 'Balances',\n          value: {\n            type: 'Transfer',\n            value: {\n              from: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET',\n              to: '13YMK2ePPKQeW7ynqLozB65WYjMnNgffQ9uR4AzyGmqnKeLq',\n              amount: 120000000000n\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: { type: 'Issued', value: { amount: 0n } }\n        },\n        {\n          type: 'XcmPallet',\n          value: {\n            type: 'Attempted',\n            value: {\n              outcome: {\n                type: 'Complete',\n                value: { used: { ref_time: 251861000n, proof_size: 6196n } }\n              }\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Burned',\n            value: {\n              who: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET',\n              amount: 397000000n\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Minted',\n            value: {\n              who: '13UVJyLnbVp9RBZYFwFGyDvVd1y27Tt8tkntv6Q7JVPhFsTB',\n              amount: 397000000n\n            }\n          }\n        },\n        {\n          type: 'XcmPallet',\n          value: {\n            type: 'FeesPaid',\n            value: {\n              paying: {\n                parents: 0,\n                interior: {\n                  type: 'X1',\n                  value: {\n                    type: 'AccountId32',\n                    value: {\n                      network: { type: 'Polkadot', value: undefined },\n                      id: FixedSizeBinary {\n                        asText: [Function (anonymous)],\n                        asHex: [Function (anonymous)],\n                        asOpaqueHex: [Function (anonymous)],\n                        asBytes: [Function (anonymous)],\n                        asOpaqueBytes: [Function (anonymous)]\n                      }\n                    }\n                  }\n                }\n              },\n              fees: [\n                {\n                  id: {\n                    parents: 0,\n                    interior: { type: 'Here', value: undefined }\n                  },\n                  fun: { type: 'Fungible', value: 397000000n }\n                }\n              ]\n            }\n          }\n        },\n        {\n          type: 'XcmPallet',\n          value: {\n            type: 'Sent',\n            value: {\n              origin: {\n                parents: 0,\n                interior: {\n                  type: 'X1',\n                  value: {\n                    type: 'AccountId32',\n                    value: {\n                      network: { type: 'Polkadot', value: undefined },\n                      id: FixedSizeBinary {\n                        asText: [Function (anonymous)],\n                        asHex: [Function (anonymous)],\n                        asOpaqueHex: [Function (anonymous)],\n                        asBytes: [Function (anonymous)],\n                        asOpaqueBytes: [Function (anonymous)]\n                      }\n                    }\n                  }\n                }\n              },\n              destination: {\n                parents: 0,\n                interior: { type: 'X1', value: { type: 'Parachain', value: 4001 } }\n              },\n              message: [\n                {\n                  type: 'ReserveAssetDeposited',\n                  value: [\n                    {\n                      id: {\n                        parents: 1,\n                        interior: { type: 'Here', value: undefined }\n                      },\n                      fun: { type: 'Fungible', value: 120000000000n }\n                    }\n                  ]\n                },\n                { type: 'ClearOrigin', value: undefined },\n                {\n                  type: 'BuyExecution',\n                  value: {\n                    fees: {\n                      id: {\n                        parents: 1,\n                        interior: { type: 'Here', value: undefined }\n                      },\n                      fun: { type: 'Fungible', value: 120000000000n }\n                    },\n                    weight_limit: { type: 'Unlimited', value: undefined }\n                  }\n                },\n                {\n                  type: 'DepositAsset',\n                  value: {\n                    assets: {\n                      type: 'Wild',\n                      value: { type: 'AllCounted', value: 1 }\n                    },\n                    beneficiary: {\n                      parents: 0,\n                      interior: {\n                        type: 'X1',\n                        value: {\n                          type: 'AccountId32',\n                          value: {\n                            network: undefined,\n                            id: FixedSizeBinary {\n                              asText: [Function (anonymous)],\n                              asHex: [Function (anonymous)],\n                              asOpaqueHex: [Function (anonymous)],\n                              asBytes: [Function (anonymous)],\n                              asOpaqueBytes: [Function (anonymous)]\n                            }\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              ],\n              message_id: FixedSizeBinary {\n                asText: [Function (anonymous)],\n                asHex: [Function (anonymous)],\n                asOpaqueHex: [Function (anonymous)],\n                asBytes: [Function (anonymous)],\n                asOpaqueBytes: [Function (anonymous)]\n              }\n            }\n          }\n        }\n      ],\n      local_xcm: undefined,\n      destination: {\n        type: 'V4',\n        value: {\n          parents: 0,\n          interior: { type: 'X1', value: { type: 'Parachain', value: 4001 } }\n        }\n      },\n      remote_xcm: {\n        type: 'V3',\n        value: [\n          {\n            type: 'ReserveAssetDeposited',\n            value: [\n              {\n                id: {\n                  type: 'Concrete',\n                  value: {\n                    parents: 1,\n                    interior: { type: 'Here', value: undefined }\n                  }\n                },\n                fun: { type: 'Fungible', value: 120000000000n }\n              }\n            ]\n          },\n          { type: 'ClearOrigin', value: undefined },\n          {\n            type: 'BuyExecution',\n            value: {\n              fees: {\n                id: {\n                  type: 'Concrete',\n                  value: {\n                    parents: 1,\n                    interior: { type: 'Here', value: undefined }\n                  }\n                },\n                fun: { type: 'Fungible', value: 120000000000n }\n              },\n              weight_limit: { type: 'Unlimited', value: undefined }\n            }\n          },\n          {\n            type: 'DepositAsset',\n            value: {\n              assets: { type: 'Wild', value: { type: 'AllCounted', value: 1 } },\n              beneficiary: {\n                parents: 0,\n                interior: {\n                  type: 'X1',\n                  value: {\n                    type: 'AccountId32',\n                    value: {\n                      network: undefined,\n                      id: FixedSizeBinary {\n                        asText: [Function (anonymous)],\n                        asHex: [Function (anonymous)],\n                        asOpaqueHex: [Function (anonymous)],\n                        asBytes: [Function (anonymous)],\n                        asOpaqueBytes: [Function (anonymous)]\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          },\n          {\n            type: 'SetTopic',\n            value: FixedSizeBinary {\n              asText: [Function (anonymous)],\n              asHex: [Function (anonymous)],\n              asOpaqueHex: [Function (anonymous)],\n              asBytes: [Function (anonymous)],\n              asOpaqueBytes: [Function (anonymous)]\n            }\n          }\n        ]\n      }\n    }      \n  </pre>\n</div>\n\n\n    ---"}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 3, "depth": 3, "title": "Dry Run XCM", "anchor": "dry-run-xcm", "start_char": 23918, "end_char": 29784, "estimated_token_count": 1179, "token_estimator": "heuristic-v1", "text": "### Dry Run XCM\n\nThis API allows the direct dry-run of an xcm message instead of an extrinsic one, checks if it will execute successfully, and determines what other xcm messages will be forwarded to other chains.\n\n```rust\n-fn dry_run_xcm(origin_location: VersionedLocation, xcm: VersionedXcm<Call>) -> Result<XcmDryRunEffects<Event>, Error>;\n```\n\n??? interface \"Input parameters\"\n\n    `origin_location` ++\"VersionedLocation\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    The location of the origin that will execute the xcm message.\n\n    ---\n\n    `xcm` ++\"VersionedXcm<Call>\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    A versioned XCM message.\n\n    ---\n\n??? interface \"Output parameters\"\n\n    ++\"Result<XcmDryRunEffects<Event>, Error>\"++\n\n    Effects of dry-running an extrinsic. If an error occurs, it is returned instead of the effects.\n\n    ??? child \"Type `XcmDryRunEffects<Event>`\"\n\n        `execution_result` ++\"DispatchResultWithPostInfo\"++\n\n        The result of executing the extrinsic.\n\n        ---\n\n        `emitted_events` ++\"Vec<Event>\"++\n\n        The list of events fired by the extrinsic.\n\n        ---\n\n        `forwarded_xcms` ++\"Vec<(VersionedLocation, Vec<VersionedXcm<()>>)>\"++\n\n        The list of XCMs that were queued for sending.\n\n    ??? child \"Type `Error`\"\n\n        Enum:\n\n        - **`Unimplemented`**: An API part is unsupported.\n        - **`VersionedConversionFailed`**: Converting a versioned data structure from one version to another failed.\n\n    ---\n\n??? interface \"Example\"\n\n    This example demonstrates how to simulate a [teleport asset transfer](https://wiki.polkadot.com/learn/learn-xcm-usecases/#asset-teleportation){target=\\_blank} from the Paseo network to the Paseo Asset Hub parachain. The code shows how to test and verify the received XCM message's behavior in the destination chain through a dry run on the live network.\n\n    Replace `INSERT_USER_ADDRESS` with your SS58 address before running the script.\n\n     ***Usage with PAPI***\n\n    ```js\n    -import { createClient } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport {\n  XcmVersionedXcm,\n  paseoAssetHub,\n  XcmVersionedLocation,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3WeightLimit,\n  XcmV3MultiassetFungibility,\n  XcmV3MultiassetAssetId,\n  XcmV3Instruction,\n  XcmV3MultiassetMultiAssetFilter,\n  XcmV3MultiassetWildMultiAsset,\n} from '@polkadot-api/descriptors';\nimport { Binary } from 'polkadot-api';\nimport { ss58Decode } from '@polkadot-labs/hdkd-helpers';\n\n// Connect to Paseo Asset Hub\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('wss://asset-hub-paseo-rpc.dwellir.com')),\n);\n\nconst paseoAssetHubApi = client.getTypedApi(paseoAssetHub);\n\nconst userAddress = 'INSERT_USER_ADDRESS';\nconst userPublicKey = ss58Decode(userAddress)[0];\nconst idBeneficiary = Binary.fromBytes(userPublicKey);\n\n// Define the origin\nconst origin = XcmVersionedLocation.V3({\n  parents: 1,\n  interior: XcmV3Junctions.Here(),\n});\n\n// Define a xcm message comming from the Paseo relay chain to Asset Hub to Teleport some tokens\nconst xcm = XcmVersionedXcm.V3([\n  XcmV3Instruction.ReceiveTeleportedAsset([\n    {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 1,\n        interior: XcmV3Junctions.Here(),\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(12000000000n),\n    },\n  ]),\n  XcmV3Instruction.ClearOrigin(),\n  XcmV3Instruction.BuyExecution({\n    fees: {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 1,\n        interior: XcmV3Junctions.Here(),\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(BigInt(12000000000n)),\n    },\n    weight_limit: XcmV3WeightLimit.Unlimited(),\n  }),\n  XcmV3Instruction.DepositAsset({\n    assets: XcmV3MultiassetMultiAssetFilter.Wild(\n      XcmV3MultiassetWildMultiAsset.All(),\n    ),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV3Junctions.X1(\n        XcmV3Junction.AccountId32({\n          network: undefined,\n          id: idBeneficiary,\n        }),\n      ),\n    },\n  }),\n]);\n\n// Execute dry run xcm\nconst dryRunResult = await paseoAssetHubApi.apis.DryRunApi.dry_run_xcm(\n  origin,\n  xcm,\n);\n\n// Print the results\nconsole.dir(dryRunResult.value, { depth: null });\n\nclient.destroy();\n\n    ```\n\n    ***Output***\n\n    -<div id=\"termynal\" data-termynal>\n  <pre>\n    {\n      execution_result: {\n        type: 'Complete',\n        value: { used: { ref_time: 15574200000n, proof_size: 359300n } }\n      },\n      emitted_events: [\n        {\n          type: 'System',\n          value: {\n            type: 'NewAccount',\n            value: { account: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET' }\n          }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Endowed',\n            value: {\n              account: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET',\n              free_balance: 10203500000n\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Minted',\n            value: {\n              who: '12pGtwHPL4tUAUcyeCoJ783NKRspztpWmXv4uxYRwiEnYNET',\n              amount: 10203500000n\n            }\n          }\n        },\n        {\n          type: 'Balances',\n          value: { type: 'Issued', value: { amount: 1796500000n } }\n        },\n        {\n          type: 'Balances',\n          value: {\n            type: 'Deposit',\n            value: {\n              who: '13UVJyLgBASGhE2ok3TvxUfaQBGUt88JCcdYjHvUhvQkFTTx',\n              amount: 1796500000n\n            }\n          }\n        }\n      ],\n      forwarded_xcms: [\n        [\n          {\n            type: 'V4',\n            value: { parents: 1, interior: { type: 'Here', value: undefined } }\n          },\n          []\n        ]\n      ]\n    }\n  </pre>\n</div>\n\n\n    ---"}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 4, "depth": 2, "title": "XCM Payment API", "anchor": "xcm-payment-api", "start_char": 29784, "end_char": 30870, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "## XCM Payment API\n\nThe [XCM Payment API](https://paritytech.github.io/polkadot-sdk/master/xcm_runtime_apis/fees/trait.XcmPaymentApi.html){target=\\_blank} provides a standardized way to determine the costs and payment options for executing XCM messages. Specifically, it enables clients to:\n\n- Retrieve the [weight](/polkadot-protocol/glossary/#weight) required to execute an XCM message.\n- Obtain a list of acceptable `AssetIds` for paying execution fees.\n- Calculate the cost of the weight in a specified `AssetId`.\n- Estimate the fees for XCM message delivery.\n\nThis API eliminates the need for clients to guess execution fees or identify acceptable assets manually. Instead, clients can query the list of supported asset IDs formatted according to the XCM version they understand. With this information, they can weigh the XCM program they intend to execute and convert the computed weight into its cost using one of the acceptable assets.\n\nTo use the API effectively, the client must already know the XCM program to be executed and the chains involved in the program's execution."}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 5, "depth": 3, "title": "Query Acceptable Payment Assets", "anchor": "query-acceptable-payment-assets", "start_char": 30870, "end_char": 33400, "estimated_token_count": 585, "token_estimator": "heuristic-v1", "text": "### Query Acceptable Payment Assets\n\nRetrieves the list of assets that are acceptable for paying fees when using a specific XCM version\n\n```rust\n-fn query_acceptable_payment_assets(xcm_version: Version) -> Result<Vec<VersionedAssetId>, Error>;\n```\n\n??? interface \"Input parameters\"\n\n    `xcm_version` ++\"Version\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Specifies the XCM version that will be used to send the XCM message.\n\n    ---\n\n??? interface \"Output parameters\"\n\n    ++\"Result<Vec<VersionedAssetId>, Error>\"++\n\n    A list of acceptable payment assets. Each asset is provided in a versioned format (`VersionedAssetId`) that matches the specified XCM version. If an error occurs, it is returned instead of the asset list.\n\n    ??? child \"Type `Error`\"\n\n        Enum:\n\n        - **`Unimplemented`**: An API part is unsupported.\n        - **`VersionedConversionFailed`**: Converting a versioned data structure from one version to another failed.\n        - **`WeightNotComputable`**: XCM message weight calculation failed.\n        - **`UnhandledXcmVersion`**: XCM version not able to be handled.\n        - **`AssetNotFound`**: The given asset is not handled as a fee asset.\n        - **`Unroutable`**: Destination is known to be unroutable.\n\n    ---\n\n??? interface \"Example\"\n\n    This example demonstrates how to query the acceptable payment assets for executing XCM messages on the Paseo Asset Hub network using XCM version 3.\n\n    ***Usage with PAPI***\n\n    ```js\n    -import { paseoAssetHub } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\n\n// Connect to the polkadot relay chain\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('wss://asset-hub-paseo-rpc.dwellir.com')),\n);\n\nconst paseoAssetHubApi = client.getTypedApi(paseoAssetHub);\n\n// Define the xcm version to use\nconst xcmVersion = 3;\n\n// Execute the runtime call to query the assets\nconst result =\n  await paseoAssetHubApi.apis.XcmPaymentApi.query_acceptable_payment_assets(\n    xcmVersion,\n  );\n\n// Print the assets\nconsole.dir(result.value, { depth: null });\n\nclient.destroy();\n\n    ```\n\n    ***Output***\n\n    -<div id=\"termynal\" data-termynal>\n  <pre>\n    [\n      {\n        type: 'V3',\n        value: {\n          type: 'Concrete',\n          value: { parents: 1, interior: { type: 'Here', value: undefined } }\n        }\n      }\n    ]\n  </pre>\n</div>\n\n\n    ---"}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 6, "depth": 3, "title": "Query XCM Weight", "anchor": "query-xcm-weight", "start_char": 33400, "end_char": 37733, "estimated_token_count": 925, "token_estimator": "heuristic-v1", "text": "### Query XCM Weight\n\nCalculates the weight required to execute a given XCM message. It is useful for estimating the execution cost of a cross-chain message in the destination chain before sending it.\n\n```rust\n-fn query_xcm_weight(message: VersionedXcm<()>) -> Result<Weight, Error>;\n```\n\n??? interface \"Input parameters\"\n\n    `message` ++\"VersionedXcm<()>\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    A versioned XCM message whose execution weight is being queried.\n\n    ---\n\n??? interface \"Output parameters\"\n\n    ++\"Result<Weight, Error>\"++\n    \n    The calculated weight required to execute the provided XCM message. If the calculation fails, an error is returned instead.\n\n    ??? child \"Type `Weight`\"\n\n        `ref_time` ++\"u64\"++\n\n        The weight of computational time used based on some reference hardware.\n\n        ---\n\n        `proof_size` ++\"u64\"++\n\n        The weight of storage space used by proof of validity.\n\n        ---\n\n    ??? child \"Type `Error`\"\n\n        Enum:\n\n        - **`Unimplemented`**: An API part is unsupported.\n        - **`VersionedConversionFailed`**: Converting a versioned data structure from one version to another failed.\n        - **`WeightNotComputable`**: XCM message weight calculation failed.\n        - **`UnhandledXcmVersion`**: XCM version not able to be handled.\n        - **`AssetNotFound`**: The given asset is not handled as a fee asset.\n        - **`Unroutable`**: Destination is known to be unroutable.\n\n    ---\n\n??? interface \"Example\"\n\n    This example demonstrates how to calculate the weight needed to execute a [teleport transfer](https://wiki.polkadot.com/learn/learn-xcm-usecases/#asset-teleportation){target=\\_blank} from the Paseo network to the Paseo Asset Hub parachain using the XCM Payment API. The result shows the required weight in terms of reference time and proof size needed in the destination chain.\n\n    Replace `INSERT_USER_ADDRESS` with your SS58 address before running the script.\n\n    ***Usage with PAPI***\n\n    ```js\n    -import { createClient } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport {\n  XcmVersionedXcm,\n  paseoAssetHub,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3WeightLimit,\n  XcmV3MultiassetFungibility,\n  XcmV3MultiassetAssetId,\n  XcmV3Instruction,\n  XcmV3MultiassetMultiAssetFilter,\n  XcmV3MultiassetWildMultiAsset,\n} from '@polkadot-api/descriptors';\nimport { Binary } from 'polkadot-api';\nimport { ss58Decode } from '@polkadot-labs/hdkd-helpers';\n\n// Connect to Paseo Asset Hub\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('wss://asset-hub-paseo-rpc.dwellir.com')),\n);\n\nconst paseoAssetHubApi = client.getTypedApi(paseoAssetHub);\n\nconst userAddress = 'INSERT_USER_ADDRESS';\nconst userPublicKey = ss58Decode(userAddress)[0];\nconst idBeneficiary = Binary.fromBytes(userPublicKey);\n\n// Define a xcm message comming from the Paseo relay chain to Asset Hub to Teleport some tokens\nconst xcm = XcmVersionedXcm.V3([\n  XcmV3Instruction.ReceiveTeleportedAsset([\n    {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 1,\n        interior: XcmV3Junctions.Here(),\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(12000000000n),\n    },\n  ]),\n  XcmV3Instruction.ClearOrigin(),\n  XcmV3Instruction.BuyExecution({\n    fees: {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 1,\n        interior: XcmV3Junctions.Here(),\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(BigInt(12000000000n)),\n    },\n    weight_limit: XcmV3WeightLimit.Unlimited(),\n  }),\n  XcmV3Instruction.DepositAsset({\n    assets: XcmV3MultiassetMultiAssetFilter.Wild(\n      XcmV3MultiassetWildMultiAsset.All(),\n    ),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV3Junctions.X1(\n        XcmV3Junction.AccountId32({\n          network: undefined,\n          id: idBeneficiary,\n        }),\n      ),\n    },\n  }),\n]);\n\n// Execute the query weight runtime call\nconst result = await paseoAssetHubApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n\n// Print the results\nconsole.dir(result.value, { depth: null });\n\nclient.destroy();\n\n    ```\n\n    ***Output***\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty>{ ref_time: 15574200000n, proof_size: 359300n }</span>\n</div>\n\n\n    ---"}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 7, "depth": 3, "title": "Query Weight to Asset Fee", "anchor": "query-weight-to-asset-fee", "start_char": 37733, "end_char": 40674, "estimated_token_count": 702, "token_estimator": "heuristic-v1", "text": "### Query Weight to Asset Fee\n\nConverts a given weight into the corresponding fee for a specified `AssetId`. It allows clients to determine the cost of execution in terms of the desired asset.\n\n```rust\n-fn query_weight_to_asset_fee(weight: Weight, asset: VersionedAssetId) -> Result<u128, Error>;\n```\n\n??? interface \"Input parameters\"\n\n    `weight` ++\"Weight\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    The execution weight to be converted into a fee.\n\n    ??? child \"Type `Weight`\"\n\n        `ref_time` ++\"u64\"++\n\n        The weight of computational time used based on some reference hardware.\n\n        ---\n\n        `proof_size` ++\"u64\"++\n\n        The weight of storage space used by proof of validity.\n\n        ---\n\n    ---\n\n    `asset` ++\"VersionedAssetId\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    The asset in which the fee will be calculated. This must be a versioned asset ID compatible with the runtime.\n\n    ---\n\n??? interface \"Output parameters\"\n\n    ++\"Result<u128, Error>\"++\n    \n    The fee needed to pay for the execution for the given `AssetId.`\n\n    ??? child \"Type `Error`\"\n\n        Enum:\n\n        - **`Unimplemented`**: An API part is unsupported.\n        - **`VersionedConversionFailed`**: Converting a versioned data structure from one version to another failed.\n        - **`WeightNotComputable`**: XCM message weight calculation failed.\n        - **`UnhandledXcmVersion`**: XCM version not able to be handled.\n        - **`AssetNotFound`**: The given asset is not handled as a fee asset.\n        - **`Unroutable`**: Destination is known to be unroutable.\n\n    ---\n\n??? interface \"Example\"\n\n    This example demonstrates how to calculate the fee for a given execution weight using a specific versioned asset ID (PAS token) on Paseo Asset Hub.\n\n    ***Usage with PAPI***\n\n    ```js\n    -import { paseoAssetHub } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\n\n// Connect to the polkadot relay chain\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('wss://asset-hub-paseo-rpc.dwellir.com')),\n);\n\nconst paseoAssetHubApi = client.getTypedApi(paseoAssetHub);\n\n// Define the weight to convert to fee\nconst weight = { ref_time: 15574200000n, proof_size: 359300n };\n\n// Define the versioned asset id\nconst versionedAssetId = {\n  type: 'V4',\n  value: { parents: 1, interior: { type: 'Here', value: undefined } },\n};\n\n// Execute the runtime call to convert the weight to fee\nconst result =\n  await paseoAssetHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n    weight,\n    versionedAssetId,\n  );\n\n// Print the fee\nconsole.dir(result.value, { depth: null });\n\nclient.destroy();\n\n    ```\n\n    ***Output***\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty>1796500000n</span>\n</div>\n\n    ---"}
{"page_id": "develop-interoperability-xcm-runtime-apis", "index": 8, "depth": 3, "title": "Query Delivery Fees", "anchor": "query-delivery-fees", "start_char": 40674, "end_char": 45291, "estimated_token_count": 968, "token_estimator": "heuristic-v1", "text": "### Query Delivery Fees\n\nRetrieves the delivery fees for sending a specific XCM message to a designated destination. The fees are always returned in a specific asset defined by the destination chain.\n\n```rust\n-fn query_delivery_fees(destination: VersionedLocation, message: VersionedXcm<()>) -> Result<VersionedAssets, Error>;\n```\n\n??? interface \"Input parameters\"\n\n    `destination` ++\"VersionedLocation\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    The target location where the message will be sent. Fees may vary depending on the destination, as different destinations often have unique fee structures and sender mechanisms.\n\n    ---\n\n    `message` ++\"VersionedXcm<()>\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    The XCM message to be sent. The delivery fees are calculated based on the message's content and size, which can influence the cost.\n\n    ---\n\n??? interface \"Output parameters\"\n\n    ++\"Result<VersionedAssets, Error>\"++\n    \n    The calculated delivery fees expressed in a specific asset supported by the destination chain. If an error occurs during the query, it returns an error instead.\n\n    ??? child \"Type `Error`\"\n\n        Enum:\n\n        - **`Unimplemented`**: An API part is unsupported.\n        - **`VersionedConversionFailed`**: Converting a versioned data structure from one version to another failed.\n        - **`WeightNotComputable`**: XCM message weight calculation failed.\n        - **`UnhandledXcmVersion`**: XCM version not able to be handled.\n        - **`AssetNotFound`**: The given asset is not handled as a fee asset.\n        - **`Unroutable`**: Destination is known to be unroutable.\n\n    ---\n\n??? interface \"Example\"\n\n    This example demonstrates how to query the delivery fees for sending an XCM message from Paseo to Paseo Asset Hub.\n\n    Replace `INSERT_USER_ADDRESS` with your SS58 address before running the script.\n\n    ***Usage with PAPI***\n\n    ```js\n    -import { createClient } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport {\n  XcmVersionedXcm,\n  paseo,\n  XcmVersionedLocation,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3WeightLimit,\n  XcmV3MultiassetFungibility,\n  XcmV3MultiassetAssetId,\n  XcmV3Instruction,\n  XcmV3MultiassetMultiAssetFilter,\n  XcmV3MultiassetWildMultiAsset,\n} from '@polkadot-api/descriptors';\nimport { Binary } from 'polkadot-api';\nimport { ss58Decode } from '@polkadot-labs/hdkd-helpers';\n\nconst client = createClient(\n  withPolkadotSdkCompat(getWsProvider('wss://paseo-rpc.dwellir.com')),\n);\n\nconst paseoApi = client.getTypedApi(paseo);\n\nconst paseoAssetHubParaID = 1000;\nconst userAddress = 'INSERT_USER_ADDRESS';\nconst userPublicKey = ss58Decode(userAddress)[0];\nconst idBeneficiary = Binary.fromBytes(userPublicKey);\n\n// Define the destination\nconst destination = XcmVersionedLocation.V3({\n  parents: 0,\n  interior: XcmV3Junctions.X1(XcmV3Junction.Parachain(paseoAssetHubParaID)),\n});\n\n// Define the xcm message that will be sent to the destination\nconst xcm = XcmVersionedXcm.V3([\n  XcmV3Instruction.ReceiveTeleportedAsset([\n    {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 1,\n        interior: XcmV3Junctions.Here(),\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(12000000000n),\n    },\n  ]),\n  XcmV3Instruction.ClearOrigin(),\n  XcmV3Instruction.BuyExecution({\n    fees: {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 1,\n        interior: XcmV3Junctions.Here(),\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(BigInt(12000000000n)),\n    },\n    weight_limit: XcmV3WeightLimit.Unlimited(),\n  }),\n  XcmV3Instruction.DepositAsset({\n    assets: XcmV3MultiassetMultiAssetFilter.Wild(\n      XcmV3MultiassetWildMultiAsset.All(),\n    ),\n    beneficiary: {\n      parents: 0,\n      interior: XcmV3Junctions.X1(\n        XcmV3Junction.AccountId32({\n          network: undefined,\n          id: idBeneficiary,\n        }),\n      ),\n    },\n  }),\n]);\n\n// Execute the query delivery fees runtime call\nconst result = await paseoApi.apis.XcmPaymentApi.query_delivery_fees(\n  destination,\n  xcm,\n);\n\n// Print the results\nconsole.dir(result.value, { depth: null });\n\nclient.destroy();\n\n    ```\n\n    ***Output***\n\n    -<div id=\"termynal\" data-termynal>\n  <pre>\n    {\n      type: 'V3',\n      value: [\n        {\n          id: {\n            type: 'Concrete',\n            value: { parents: 0, interior: { type: 'Here', value: undefined } }\n          },\n          fun: { type: 'Fungible', value: 396000000n }\n        }\n      ]\n    }\n  </pre>\n</div>\n\n    ---"}
{"page_id": "develop-networks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 513, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot ecosystem consists of multiple networks designed to support different stages of blockchain development, from main networks to test networks. Each network serves a unique purpose, providing developers with flexible environments for building, testing, and deploying blockchain applications.\n\nThis section includes essential network information such as RPC endpoints, currency symbols and decimals, and how to acquire TestNet tokens for the Polkadot ecosystem of networks."}
{"page_id": "develop-networks", "index": 1, "depth": 2, "title": "Production Networks", "anchor": "production-networks", "start_char": 513, "end_char": 537, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Production Networks"}
{"page_id": "develop-networks", "index": 2, "depth": 3, "title": "Polkadot", "anchor": "polkadot", "start_char": 537, "end_char": 1992, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "### Polkadot\n\nPolkadot is the primary production blockchain network for high-stakes, enterprise-grade applications. Polkadot MainNet has been running since May 2020 and has implementations in various programming languages ranging from Rust to JavaScript.\n\n=== \"Network Details\"\n\n    **Currency symbol**: `DOT`\n\n    ---\n    \n    **Currency decimals**: 10\n\n    ---\n\n    **Block explorer**: [Polkadot Subscan](https://polkadot.subscan.io/){target=\\_blank}\n\n=== \"RPC Endpoints\"\n\n    Blockops\n\n    ```\n    wss://polkadot-public-rpc.blockops.network/ws\n    ```\n\n    ---\n\n    Dwellir\n\n    ```\n    wss://polkadot-rpc.dwellir.com\n    ```\n\n    ---\n\n    Dwellir Tunisia\n\n    ```\n    wss://polkadot-rpc-tn.dwellir.com\n    ```\n\n    ---\n\n    IBP1\n\n    ```\n    wss://rpc.ibp.network/polkadot\n    ```\n\n    ---\n\n    IBP2\n\n    ```\n    wss://polkadot.dotters.network\n    ```\n\n    ---\n\n    LuckyFriday\n\n    ```\n    wss://rpc-polkadot.luckyfriday.io\n    ```\n\n    ---\n\n    OnFinality\n\n    ```\n    wss://polkadot.api.onfinality.io/public-ws\n    ```\n\n    ---\n\n    RadiumBlock\n\n    ```\n    wss://polkadot.public.curie.radiumblock.co/ws\n    ```\n\n    ---\n\n    RockX\n\n    ```\n    wss://rockx-dot.w3node.com/polka-public-dot/ws\n    ```\n\n    ---\n\n    Stakeworld\n\n    ```\n    wss://dot-rpc.stakeworld.io\n    ```\n\n    ---\n\n    SubQuery\n\n    ```\n    wss://polkadot.rpc.subquery.network/public/ws\n    ```\n\n    ---\n\n    Light client\n\n    ```\n    light://substrate-connect/polkadot\n    ```"}
{"page_id": "develop-networks", "index": 3, "depth": 3, "title": "Kusama", "anchor": "kusama", "start_char": 1992, "end_char": 3486, "estimated_token_count": 391, "token_estimator": "heuristic-v1", "text": "### Kusama\n\nKusama is a network built as a risk-taking, fast-moving \"canary in the coal mine\" for its cousin Polkadot. As it is built on top of the same infrastructure, Kusama often acts as a final testing ground for new features before they are launched on Polkadot. Unlike true TestNets, however, the Kusama KSM native token does have economic value. This incentive encourages participants to maintain this robust and performant structure for the benefit of the community.\n\n=== \"Network Details\"\n\n    **Currency symbol**: `KSM`\n\n    ---\n\n    **Currency decimals**: 12\n\n    ---\n    \n    **Block explorer**: [Kusama Subscan](https://kusama.subscan.io/){target=\\_blank}\n\n=== \"RPC Endpoints\"\n\n    Dwellir\n\n    ```\n    wss://kusama-rpc.dwellir.com\n    ```\n\n    ---\n\n    Dwellir Tunisia\n\n    ```\n    wss://kusama-rpc-tn.dwellir.com\n    ```\n\n    ---\n\n    IBP1\n\n    ```\n    wss://rpc.ibp.network/kusama\n    ```\n\n    ---\n\n    IBP2\n\n    ```\n    wss://kusama.dotters.network\n    ```\n\n    ---\n\n    LuckyFriday\n\n    ```\n    wss://rpc-kusama.luckyfriday.io\n    ```\n\n    ---\n\n    OnFinality\n\n    ```\n    wss://kusama.api.onfinality.io/public-ws\n    ```\n\n    ---\n\n    RadiumBlock\n\n    ```\n    wss://kusama.public.curie.radiumblock.co/ws\n    ```\n\n    ---\n\n    RockX\n\n    ```\n    wss://rockx-ksm.w3node.com/polka-public-ksm/ws\n    ```\n\n    ---\n\n    Stakeworld\n\n    ```\n    wss://rockx-ksm.w3node.com/polka-public-ksm/ws\n    ```\n\n    ---\n\n    Light client\n\n    ```\n    light://substrate-connect/kusama\n    ```"}
{"page_id": "develop-networks", "index": 4, "depth": 2, "title": "Test Networks", "anchor": "test-networks", "start_char": 3486, "end_char": 3504, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Test Networks"}
{"page_id": "develop-networks", "index": 5, "depth": 3, "title": "Westend", "anchor": "westend", "start_char": 3504, "end_char": 4650, "estimated_token_count": 301, "token_estimator": "heuristic-v1", "text": "### Westend\n\nWestend is the primary test network that mirrors Polkadot's functionality for protocol-level feature development. As a true TestNet, the WND native token intentionally does not have any economic value. Use the faucet information in the following section to obtain WND tokens.\n\n=== \"Network Information\"\n\n    **Currency symbol**: `WND`\n\n    ---\n\n    **Currency decimals**: 12\n\n    ---\n    \n    **Block explorer**: [Westend Subscan](https://westend.subscan.io/){target=\\_blank}\n\n    ---\n\n    **Faucet**: [Official Westend faucet](https://faucet.polkadot.io/westend){target=\\_blank}\n\n\n=== \"RPC Endpoints\"\n\n    Dwellir\n\n    ```\n    wss://westend-rpc.dwellir.com\n    ```\n\n    ---\n\n    Dwellir Tunisia\n\n    ```\n    wss://westend-rpc-tn.dwellir.com\n    ```\n\n    ---\n\n    IBP1\n\n    ```\n    wss://rpc.ibp.network/westend\n    ```\n\n    ---\n\n    IBP2\n\n    ```\n    wss://westend.dotters.network\n    ```\n\n    ---\n\n    OnFinality\n\n    ```\n    wss://westend.api.onfinality.io/public-ws\n    ```\n\n    ---\n\n    Parity\n\n    ```\n    wss://westend-rpc.polkadot.io\n    ```\n\n    ---\n\n    Light client\n\n    ```\n    light://substrate-connect/westend\n    ```"}
{"page_id": "develop-networks", "index": 6, "depth": 3, "title": "Paseo", "anchor": "paseo", "start_char": 4650, "end_char": 5723, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "### Paseo\n\nPaseo is a decentralised, community run, stable testnet for parachain and dapp developers to build and test their applications. Unlike Westend, Paseo is not intended for protocol-level testing. As a true TestNet, the PAS native token intentionally does not have any economic value. Use the faucet information in the following section to obtain PAS tokens.\n\n=== \"Network Information\"\n\n    **Currency symbol**: `PAS`\n\n    ---\n\n    **Currency decimals**: 10\n\n    ---\n    \n    **Block explorer**: [Paseo Subscan](https://paseo.subscan.io/){target=\\_blank}\n\n    ---\n\n    **Faucet**: [Official Paseo faucet](https://faucet.polkadot.io/){target=\\_blank}\n\n=== \"RPC Endpoints\"\n\n    Amforc\n    \n    ```\n    wss://paseo.rpc.amforc.com\n    ```\n    \n    ---\n    \n    Dwellir\n    \n    ```\n    wss://paseo-rpc.dwellir.com\n    ```\n    \n    ---\n    \n    IBP1\n    \n    ```\n    wss://rpc.ibp.network/paseo\n    ```\n    \n    ---\n    \n    IBP2\n    \n    ```\n    wss://paseo.dotters.network\n    ```\n    \n    ---\n    \n    StakeWorld\n    \n    ```\n    wss://pas-rpc.stakeworld.io\n    ```"}
{"page_id": "develop-networks", "index": 7, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 5723, "end_char": 6097, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- [**Polkadot Fellowship runtimes repository**](https://github.com/polkadot-fellows/runtimes){target=\\_blank}: Find a collection of runtimes for Polkadot, Kusama, and their system-parachains as maintained by the community via the [Polkadot Technical Fellowship](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank}."}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 31, "end_char": 845, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot SDK Solochain Template](https://github.com/paritytech/polkadot-sdk-solochain-template){target=\\_blank} provides a functional runtime that includes default FRAME development modules (pallets) to help you get started with building a custom blockchain.\n\nEach pallet has specific configuration requirements, such as the parameters and types needed to enable the pallet's functionality. In this guide, you'll learn how to add a pallet to a runtime and configure the settings specific to that pallet.\n\nThe purpose of this article is to help you:\n\n- Learn how to update runtime dependencies to integrate a new pallet.\n- Understand how to configure pallet-specific Rust traits to enable the pallet's functionality.\n- Grasp the entire workflow of integrating a new pallet into your runtime."}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 1, "depth": 2, "title": "Configuring Runtime Dependencies", "anchor": "configuring-runtime-dependencies", "start_char": 845, "end_char": 2121, "estimated_token_count": 267, "token_estimator": "heuristic-v1", "text": "## Configuring Runtime Dependencies\n\nFor Rust programs, this configuration is defined in the `Cargo.toml` file, which specifies the settings and dependencies that control what gets compiled into the final binary. Since the Polkadot SDK runtime compiles to both a native binary (which includes standard Rust library functions) and a Wasm binary (which does not include the standard Rust library), the `runtime/Cargo.toml` file manages two key aspects:\n\n- The locations and versions of the pallets that are to be imported as dependencies for the runtime.\n- The features in each pallet that should be enabled when compiling the native Rust binary. By enabling the standard (`std`) feature set from each pallet, you ensure that the runtime includes the functions, types, and primitives necessary for the native build, which are otherwise excluded when compiling the Wasm binary.\n\n\nFor information about adding dependencies in `Cargo.toml` files, see the [Dependencies](https://doc.rust-lang.org/cargo/guide/dependencies.html){target=\\_blank} page in the Cargo documentation. To learn more about enabling and managing features from dependent packages, see the [Features](https://doc.rust-lang.org/cargo/reference/features.html){target=\\_blank} section in the Cargo documentation."}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 2, "depth": 2, "title": "Dependencies for a New Pallet", "anchor": "dependencies-for-a-new-pallet", "start_char": 2121, "end_char": 4899, "estimated_token_count": 674, "token_estimator": "heuristic-v1", "text": "## Dependencies for a New Pallet\n\nTo add the dependencies for a new pallet to the runtime, you must modify the `Cargo.toml` file by adding a new line into the `[workspace.dependencies]` section with the pallet you want to add. This pallet definition might look like:\n\n```toml title=\"Cargo.toml\"\npallet-example = { version = \"4.0.0-dev\", default-features = false }\n```\n\nThis line imports the `pallet-example` crate as a dependency and specifies the following:\n\n- **`version`**: The specific version of the crate to import.\n- **`default-features`**: Determines the behavior for including pallet features when compiling the runtime with standard Rust libraries.\n\n!!! tip\n    If you're importing a pallet that isn't available on [`crates.io`](https://crates.io/){target=\\_blank}, you can specify the pallet's location (either locally or from a remote repository) by using the `git` or `path` key. For example:\n\n    ```toml title=\"Cargo.toml\"\n    pallet-example = { \n        version = \"4.0.0-dev\",\n        default-features = false,\n        git = \"INSERT_PALLET_REMOTE_URL\",\n    }\n    ```\n\n    In this case, replace `INSERT_PALLET_REMOTE_URL` with the correct repository URL. For local paths, use the path key like so:\n\n    ```toml title=\"Cargo.toml\"\n    pallet-example = { \n        version = \"4.0.0-dev\",\n        default-features = false,\n        path = \"INSERT_PALLET_RELATIVE_PATH\",\n    }\n    ```\n\n    Ensure that you substitute `INSERT_PALLET_RELATIVE_PATH` with the appropriate local path to the pallet.\n\nNext, add this dependency to the `[dependencies]` section of the `runtime/Cargo.toml` file, so it inherits from the main `Cargo.toml` file:\n\n```toml title=\"runtime/Cargo.toml\"\npallet-examples.workspace = true\n```\n\nTo enable the `std` feature of the pallet, add the pallet to the following section:\n\n```toml title=\"runtime/Cargo.toml\"\n[features]\ndefault = [\"std\"]\nstd = [\n    ...\n    \"pallet-example/std\",\n    ...\n]\n```\n\nThis section specifies the default feature set for the runtime, which includes the `std` features for each pallet. When the runtime is compiled with the `std` feature set, the standard library features for all listed pallets are enabled. If you forget to update the features section in the `Cargo.toml` file, you might encounter `cannot find function` errors when compiling the runtime.\n\nFor more details about how the runtime is compiled as both a native binary (using `std`) and a Wasm binary (using `no_std`), refer to the [Wasm build](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/substrate/index.html#wasm-build){target=\\_blank} section in the Polkadot SDK documentation.\n\nTo ensure that the new dependencies resolve correctly for the runtime, you can run the following command:\n\n```bash\ncargo check --release\n```"}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 3, "depth": 2, "title": "Config Trait for Pallets", "anchor": "config-trait-for-pallets", "start_char": 4899, "end_char": 6296, "estimated_token_count": 286, "token_estimator": "heuristic-v1", "text": "## Config Trait for Pallets\n\nEvery Polkadot SDK pallet defines a Rust trait called `Config`. This trait specifies the types and parameters that the pallet needs to integrate with the runtime and perform its functions. The primary purpose of this trait is to act as an interface between this pallet and the runtime in which it is embedded. A type, function, or constant in this trait is essentially left to be configured by the runtime that includes this pallet.\n\nConsequently, a runtime that wants to include this pallet must implement this trait.\n\nYou can inspect any pallet’s `Config` trait by reviewing its Rust documentation or source code. The `Config` trait ensures the pallet has access to the necessary types (like events, calls, or origins) and integrates smoothly with the rest of the runtime.\n\nAt its core, the `Config` trait typically looks like this:\n\n```rust\n-#[pallet::config]\npub trait Config: frame_system::Config {\n    /// Event type used by the pallet.\n    type RuntimeEvent: From<Event> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n    /// Weight information for controlling extrinsic execution costs.\n    type WeightInfo: WeightInfo;\n}\n```\n\nThis basic structure shows that every pallet must define certain types, such as `RuntimeEvent` and `WeightInfo`, to function within the runtime. The actual implementation can vary depending on the pallet’s specific needs."}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 4, "depth": 3, "title": "Utility Pallet Example", "anchor": "utility-pallet-example", "start_char": 6296, "end_char": 7660, "estimated_token_count": 310, "token_estimator": "heuristic-v1", "text": "### Utility Pallet Example\n\nFor instance, in the [`utility`](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/utility){target=\\_blank} pallet, the `Config` trait is implemented with the following types:\n\n```rust\n-#[pallet::config]\npub trait Config: frame_system::Config {\n    /// The overarching event type.\n    type RuntimeEvent: From<Event> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n    /// The overarching call type.\n    type RuntimeCall: Parameter\n    + Dispatchable<RuntimeOrigin = Self::RuntimeOrigin, PostInfo = PostDispatchInfo>\n    + GetDispatchInfo\n    + From<frame_system::Call<Self>>\n    + UnfilteredDispatchable<RuntimeOrigin = Self::RuntimeOrigin>\n    + IsSubType<Call<Self>>\n    + IsType<<Self as frame_system::Config>::RuntimeCall>;\n\n    /// The caller origin, overarching type of all pallets origins.\n    type PalletsOrigin: Parameter +\n    Into<<Self as frame_system::Config>::RuntimeOrigin> +\n    IsType<<<Self as frame_system::Config>::RuntimeOrigin as frame_support::traits::OriginTrait>::PalletsOrigin>;\n\n    /// Weight information for extrinsics in this pallet.\n    type WeightInfo: WeightInfo;\n}\n```\n\nThis example shows how the `Config` trait defines types like `RuntimeEvent`, `RuntimeCall`, `PalletsOrigin`, and `WeightInfo`, which the pallet will use when interacting with the runtime."}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 5, "depth": 2, "title": "Parameter Configuration for Pallets", "anchor": "parameter-configuration-for-pallets", "start_char": 7660, "end_char": 9267, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "## Parameter Configuration for Pallets\n\nTraits in Rust define shared behavior, and within the Polkadot SDK, they allow runtimes to integrate and utilize a pallet's functionality by implementing its associated configuration trait and parameters. Some of these parameters may require constant values, which can be defined using the [`parameter_types!`](https://paritytech.github.io/polkadot-sdk/master/frame_support/macro.parameter_types.html){target=\\_blank} macro. This macro simplifies development by expanding the constants into the appropriate struct types with functions that the runtime can use to access their types and values in a consistent manner.\n\nFor example, the following code snippet shows how the solochain template configures certain parameters through the [`parameter_types!`](https://github.com/paritytech/polkadot-sdk-solochain-template/blob/v0.0.2/runtime/src/lib.rs#L138){target=\\_blank} macro in the `runtime/lib.rs` file:\n\n```rust\n-parameter_types! {\n    pub const BlockHashCount: BlockNumber = 2400;\n    pub const Version: RuntimeVersion = VERSION;\n    /// We allow for 2 seconds of compute with a 6 second average block time.\n    pub BlockWeights: frame_system::limits::BlockWeights =\n        frame_system::limits::BlockWeights::with_sensible_defaults(\n            Weight::from_parts(2u64 * WEIGHT_REF_TIME_PER_SECOND, u64::MAX),\n            NORMAL_DISPATCH_RATIO,\n        );\n    pub BlockLength: frame_system::limits::BlockLength = frame_system::limits::BlockLength\n        ::max_with_normal_ratio(5 * 1024 * 1024, NORMAL_DISPATCH_RATIO);\n    pub const SS58Prefix: u8 = 42;\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 6, "depth": 2, "title": "Pallet Config in the Runtime", "anchor": "pallet-config-in-the-runtime", "start_char": 9267, "end_char": 10629, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "## Pallet Config in the Runtime\n\nTo integrate a new pallet into the runtime, you must implement its `Config` trait in the `runtime/lib.rs` file. This is done by specifying the necessary types and parameters in Rust, as shown below:\n\n```rust\n-impl pallet_example::Config for Runtime {\n    type RuntimeEvent = RuntimeEvent;\n    type WeightInfo = pallet_template::weights::SubstrateWeight<Runtime>;\n    ...\n}\n```\n\nFinally, to compose the runtime, update the list of pallets in the same file by modifying the [`#[frame_support::runtime]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/attr.runtime.html){target=\\_blank} section. This Rust macro constructs the runtime with your specified name and pallets, wraps the runtime's configuration, and automatically generates boilerplate code for pallet inclusion. \n\nUse the following format when adding your pallet:\n\n```rust\n-#[frame_support::runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n        RuntimeCall,\n        RuntimeEvent,\n        RuntimeError,\n        RuntimeOrigin,\n        RuntimeFreezeReason,\n        RuntimeHoldReason,\n        RuntimeSlashReason,\n        RuntimeLockId,\n        RuntimeTask\n    )]\n    pub struct Runtime;\n\n    #[runtime::pallet_index(0)]\n    pub type System = frame_system;\n\n    #[runtime::pallet_index(1)]\n    pub type Example = pallet_example;\n```"}
{"page_id": "develop-parachains-customize-parachain-add-existing-pallets", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10629, "end_char": 11942, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nWith the pallet successfully added and configured, the runtime is ready to be compiled and used. Following this guide’s steps, you’ve integrated a new pallet into the runtime, set up its dependencies, and ensured proper configuration. You can now proceed to any of the following points:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Add Multiple Pallet Instances__\n\n    ---\n\n    Learn how to implement multiple instances of the same pallet in your Polkadot SDK-based runtime to create and interact with modular blockchain components.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/customize-parachain/add-pallet-instances/)\n\n-   <span class=\"badge guide\">Guide</span> __Make a Custom Pallet__\n\n    ---\n\n    Learn how to create custom pallets using FRAME, allowing for flexible, modular, and scalable blockchain development. Follow the step-by-step guide.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/customize-parachain/make-custom-pallet/)\n\n-   <span class=\"badge guide\">Guide</span> __Pallet Testing__\n\n    ---\n\n    Learn how to efficiently test pallets in the Polkadot SDK, ensuring the reliability and security of your pallets operations.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/testing)\n\n</div>"}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 33, "end_char": 576, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRunning multiple instances of the same pallet within a runtime is a powerful technique in Polkadot SDK development. This approach lets you reuse pallet functionality without reimplementing it, enabling diverse use cases with the same codebase. The Polkadot SDK provides developer-friendly traits for creating instantiable pallets and, in most cases, handles unique storage allocation for different instances automatically. This guide teaches you how to implement and configure multiple instances of a pallet in your runtime."}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 1, "depth": 2, "title": "Understanding Instantiable Pallets", "anchor": "understanding-instantiable-pallets", "start_char": 576, "end_char": 1493, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "## Understanding Instantiable Pallets\n\nUnlike standard pallets that exist as a single instance in a runtime, instantiable pallets require special configuration through an additional [generic parameter](https://doc.rust-lang.org/reference/items/generics.html){target=\\_blank} `I`.\nThis generic `I` creates a unique [lifetime](https://doc.rust-lang.org/rust-by-example/scope/lifetime.html){target=\\_blank} for each pallet instance, affecting the pallet's generic types and its configuration trait `T`.\n\nYou can identify an instantiable pallet by examining its `Pallet` struct definition, which will include both the standard generic `T` and the instantiation generic `I`:\n\n```rust\n#[pallet::pallet]\npub struct Pallet<T, I = ()>(PhantomData<(T, I)>);\n```\n\nThe instantiation generic also appears throughout the pallet's components, including the `Config` trait, storage items, events, errors, and genesis configuration."}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 2, "depth": 2, "title": "Adding Instantiable Pallets to Your Runtime", "anchor": "adding-instantiable-pallets-to-your-runtime", "start_char": 1493, "end_char": 1825, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Adding Instantiable Pallets to Your Runtime\n\nThe process resembles adding a standard pallet with some key differences. In this example you will see how adding two instances of the [pallet-collective](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/collective){target=\\_blank} is implemented."}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 3, "depth": 3, "title": "Define Pallet Parameters", "anchor": "define-pallet-parameters", "start_char": 1825, "end_char": 2269, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "### Define Pallet Parameters\n\nFirst, define the parameters needed to configure the pallet instances. This step is identical whether implementing single or multiple instances:\n\n```rust\nparameter_types! {\n    pub const MotionDuration: BlockNumber = 24 * HOURS;\n    pub MaxProposalWeight: Weight = Perbill::from_percent(50) * RuntimeBlockWeights::get().max_block;\n    pub const MaxProposals: u32 = 100;\n    pub const MaxMembers: u32 = 100;\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 4, "depth": 3, "title": "Configure the Pallet Instances", "anchor": "configure-the-pallet-instances", "start_char": 2269, "end_char": 4969, "estimated_token_count": 457, "token_estimator": "heuristic-v1", "text": "### Configure the Pallet Instances\n\nFor a single instance, the configuration would look like this:\n\n```rust hl_lines=\"1\"\nimpl pallet_collective::Config for Runtime {\n    type RuntimeOrigin = RuntimeOrigin;\n    type Proposal = RuntimeCall;\n    type RuntimeEvent = RuntimeEvent;\n    type MotionDuration = MotionDuration;\n    type MaxProposals = MaxProposals;\n    type MaxMembers = MaxMembers;\n    type DefaultVote = pallet_collective::MoreThanMajorityThenPrimeDefaultVote;\n    type SetMembersOrigin = EnsureRoot<AccountId>;\n    type WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\n    type MaxProposalWeight = MaxProposalWeight;\n    type DisapproveOrigin = EnsureRoot<Self::AccountId>;\n    type KillOrigin = EnsureRoot<Self::AccountId>;\n    type Consideration = ();\n}\n```\n\nFor multiple instances, you need to create a unique identifier for each instance using the `Instance` type with a number suffix, then implement the configuration for each one:\n\n```rust hl_lines=\"2-3\"\n// Configure first instance\ntype Collective1 = pallet_collective::Instance1;\nimpl pallet_collective::Config<Collective1> for Runtime {\n    type RuntimeOrigin = RuntimeOrigin;\n    type Proposal = RuntimeCall;\n    type RuntimeEvent = RuntimeEvent;\n    type MotionDuration = MotionDuration;\n    type MaxProposals = MaxProposals;\n    type MaxMembers = MaxMembers;\n    type DefaultVote = pallet_collective::MoreThanMajorityThenPrimeDefaultVote;\n    type SetMembersOrigin = EnsureRoot<AccountId>;\n    type WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\n    type MaxProposalWeight = MaxProposalWeight;\n    type DisapproveOrigin = EnsureRoot<Self::AccountId>;\n    type KillOrigin = EnsureRoot<Self::AccountId>;\n    type Consideration = ();\n}\n```\n```rust hl_lines=\"2-3\"\n// Configure second instance\ntype Collective2 = pallet_collective::Instance2;\nimpl pallet_collective::Config<Collective2> for Runtime {\n    type RuntimeOrigin = RuntimeOrigin;\n    type Proposal = RuntimeCall;\n    type RuntimeEvent = RuntimeEvent;\n    type MotionDuration = MotionDuration;\n    type MaxProposals = MaxProposals;\n    type MaxMembers = MaxMembers;\n    type DefaultVote = pallet_collective::MoreThanMajorityThenPrimeDefaultVote;\n    type SetMembersOrigin = EnsureRoot<AccountId>;\n    type WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\n    type MaxProposalWeight = MaxProposalWeight;\n    type DisapproveOrigin = EnsureRoot<Self::AccountId>;\n    type KillOrigin = EnsureRoot<Self::AccountId>;\n    type Consideration = ();\n}\n```\n\nWhile the example above uses identical configurations for both instances, you can customize each instance's parameters to serve different purposes within your runtime."}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 5, "depth": 3, "title": "Add Pallet Instances to the Runtime", "anchor": "add-pallet-instances-to-the-runtime", "start_char": 4969, "end_char": 5506, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "### Add Pallet Instances to the Runtime\n\nFinally, add both pallet instances to your runtime definition, ensuring each has:\n\n- A unique pallet index\n- The correct instance type specified\n\n```rust hl_lines=\"6-10\"\n#[frame_support::runtime]\nmod runtime {\n    #[runtime::runtime]\n    // ... other runtime configuration\n\n    #[runtime::pallet_index(16)]\n    pub type Collective1 = pallet_collective<Instance1>;\n    \n    #[runtime::pallet_index(17)]\n    pub type Collective2 = pallet_collective<Instance2>;\n    \n    // ... other pallets\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-add-pallet-instances", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5506, "end_char": 6292, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nIf you've followed all the steps correctly, you should now be able to compile your runtime and interact with both instances of the pallet. Each instance will operate independently with its own storage, events, and configured parameters.\n\nNow that you've mastered implementing multiple pallet instances, the next step is creating your own custom pallets. Explore the following resources:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Make a Custom Pallet__\n\n    ---\n\n    Learn how to create custom pallets using FRAME, allowing for flexible, modular, and scalable blockchain development. Follow the step-by-step guide.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/customize-parachain/make-custom-pallet/)\n\n</div>"}
{"page_id": "develop-parachains-customize-parachain-add-smart-contract-functionality", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 36, "end_char": 704, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhen building your custom blockchain with the Polkadot SDK, you have the flexibility to add smart contract capabilities through specialized pallets. These pallets allow blockchain users to deploy and execute smart contracts, enhancing your chain's functionality and programmability.\n\nPolkadot SDK-based blockchains support two distinct smart contract execution environments: [EVM (Ethereum Virtual Machine)](#evm-smart-contracts) and [Wasm (WebAssembly)](#wasm-smart-contracts). Each environment allows developers to deploy and execute different types of smart contracts, providing flexibility in choosing the most suitable solution for their needs."}
{"page_id": "develop-parachains-customize-parachain-add-smart-contract-functionality", "index": 1, "depth": 2, "title": "EVM Smart Contracts", "anchor": "evm-smart-contracts", "start_char": 704, "end_char": 1967, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "## EVM Smart Contracts\n\nTo enable Ethereum-compatible smart contracts in your blockchain, you'll need to integrate [Frontier](https://github.com/polkadot-evm/frontier){target=\\_blank}, the Ethereum compatibility layer for Polkadot SDK-based chains. This requires adding two essential pallets to your runtime:\n\n- **[`pallet-evm`](https://github.com/polkadot-evm/frontier/tree/master/frame/evm){target=\\_blank}**: Provides the EVM execution environment.\n- **[`pallet-ethereum`](https://github.com/polkadot-evm/frontier/tree/master/frame/ethereum){target=\\_blank}**: Handles Ethereum-formatted transactions and RPC capabilities.\n\nFor step-by-step guidance on adding these pallets to your runtime, refer to [Add a Pallet to the Runtime](/develop/parachains/customize-parachain/add-existing-pallets/){target=\\_blank}.\n\nFor a real-world example of how these pallets are implemented in production, you can check Moonbeam's implementation of [`pallet-evm`](https://github.com/moonbeam-foundation/moonbeam/blob/9e2ddbc9ae8bf65f11701e7ccde50075e5fe2790/runtime/moonbeam/src/lib.rs#L532){target=\\_blank} and [`pallet-ethereum`](https://github.com/moonbeam-foundation/moonbeam/blob/9e2ddbc9ae8bf65f11701e7ccde50075e5fe2790/runtime/moonbeam/src/lib.rs#L698){target=\\_blank}."}
{"page_id": "develop-parachains-customize-parachain-add-smart-contract-functionality", "index": 2, "depth": 2, "title": "Wasm Smart Contracts", "anchor": "wasm-smart-contracts", "start_char": 1967, "end_char": 2792, "estimated_token_count": 199, "token_estimator": "heuristic-v1", "text": "## Wasm Smart Contracts\n\nTo support Wasm-based smart contracts, you'll need to integrate:\n\n- **[`pallet-contracts`](https://docs.rs/pallet-contracts/latest/pallet_contracts/index.html#contracts-pallet){target=\\_blank}**: Provides the Wasm smart contract execution environment.\n\nThis pallet enables the deployment and execution of Wasm-based smart contracts on your blockchain. For detailed instructions on adding this pallet to your runtime, see [Add a Pallet to the Runtime](/develop/parachains/customize-parachain/add-existing-pallets/){target=\\_blank}.\n\nFor a real-world example of how this pallet is implemented in production, you can check Astar's implementation of [`pallet-contracts`](https://github.com/AstarNetwork/Astar/blob/b6f7a408d31377130c3713ed52941a06b5436402/runtime/astar/src/lib.rs#L693){target=\\_blank}."}
{"page_id": "develop-parachains-customize-parachain-add-smart-contract-functionality", "index": 3, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 2792, "end_char": 3896, "estimated_token_count": 259, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you understand how to enable smart contract functionality in your blockchain, you might want to:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Smart Contracts Overview__\n\n    ---\n\n    Learn how developers can build smart contracts on Polkadot by leveraging the PolkaVM, Wasm/ink! or EVM contracts across many parachains.\n\n    [:octicons-arrow-right-24: Reference](/develop/smart-contracts/overview/)\n\n-   <span class=\"badge guide\">Guide</span> __Wasm (ink!) Contracts__\n\n    ---\n\n    Learn to build Wasm smart contracts with ink!, a Rust-based eDSL. Explore installation, contract structure, and key features.\n\n    [:octicons-arrow-right-24: Reference](/develop/smart-contracts/overview#wasm-ink)\n    \n-   <span class=\"badge guide\">Guide</span> __EVM Contracts__\n\n    ---\n\n    Learn how Polkadot parachains such as Moonbeam, Astar, Acala, and Manta leverage the Ethereum Virtual Machine (EVM) and integrate it into their parachains.\n\n    [:octicons-arrow-right-24: Reference](/develop/smart-contracts/overview#parachain-contracts)\n\n</div>"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 1892, "estimated_token_count": 396, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nFRAME provides a powerful set of tools for blockchain development, including a library of pre-built pallets. However, its true strength lies in the ability to create custom pallets tailored to your specific needs. This section will guide you through creating your own custom pallet, allowing you to extend your blockchain's functionality in unique ways.\n\nTo get the most out of this guide, ensure you're familiar with [FRAME concepts](/develop/parachains/customize-parachain/overview/){target=\\_blank}.\n\nCreating custom pallets offers several advantages over relying on pre-built pallets:\n\n- **Flexibility**: Define runtime behavior that precisely matches your project requirements.\n- **Modularity**: Combine pre-built and custom pallets to achieve the desired blockchain functionality.\n- **Scalability**: Add or modify features as your project evolves.\n\nAs you follow this guide to create your custom pallet, you'll work with the following key sections:\n\n1. **Imports and dependencies**: Bring in necessary FRAME libraries and external modules.\n2. **Runtime configuration trait**: Specify the types and constants required for your pallet to interact with the runtime.\n3. **Runtime events**: Define events that your pallet can emit to communicate state changes.\n4. **Runtime errors**: Define the error types that can be returned from the function calls dispatched to the runtime.\n5. **Runtime storage**: Declare on-chain storage items for your pallet's state.\n6. **Extrinsics (function calls)**: Create callable functions that allow users to interact with your pallet and execute transactions.\n\nFor additional macros you can include in a pallet, beyond those covered in this guide, refer to the [pallet_macros](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/index.html){target=\\_blank} section of the Polkadot SDK Docs."}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 1, "depth": 2, "title": "Initial Setup", "anchor": "initial-setup", "start_char": 1892, "end_char": 4937, "estimated_token_count": 709, "token_estimator": "heuristic-v1", "text": "## Initial Setup\n\nThis section will guide you through the initial steps of creating the foundation for your custom FRAME pallet. You'll create a new Rust library project and set up the necessary dependencies.\n\n1. Create a new Rust library project using the following `cargo` command:\n\n    ```bash\n    cargo new --lib custom-pallet \\\n    && cd custom-pallet\n    ```\n\n    This command creates a new library project named `custom-pallet` and navigates into its directory.\n\n2.  Configure the dependencies required for FRAME pallet development in the `Cargo.toml` file as follows:\n\n    ```toml\n    -[package]\nname = \"custom-pallet\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nframe-support = { version = \"37.0.0\", default-features = false }\nframe-system = { version = \"37.0.0\", default-features = false }\ncodec = { version = \"3.6.12\", default-features = false, package = \"parity-scale-codec\", features = [\n  \"derive\",\n] }\nscale-info = { version = \"2.11.1\", default-features = false, features = [\n  \"derive\",\n] }\nsp-runtime = { version = \"39.0.0\", default-features = false }\n\n[features]\ndefault = [\"std\"]\nstd = [\n  \"frame-support/std\",\n  \"frame-system/std\",\n  \"codec/std\",\n  \"scale-info/std\",\n  \"sp-runtime/std\",\n]\n\n    ```\n\n    !!!note\n        Proper version management is crucial for ensuring compatibility and reducing potential conflicts in your project. Carefully select the versions of the packages according to your project's specific requirements:\n\n        - When developing for a specific Polkadot SDK runtime, ensure that your pallet's dependency versions match those of the target runtime.\n        - If you're creating this pallet within a Polkadot SDK workspace:\n\n            - Define the actual versions in the root `Cargo.toml` file.\n            - Use workspace inheritance in your pallet's `Cargo.toml` to maintain consistency across your project.\n\n        - Regularly check for updates to FRAME and Polkadot SDK dependencies to benefit from the latest features, performance improvements, and security patches.\n\n    For detailed information about workspace inheritance and how to properly integrate your pallet with the runtime, see the [Add an Existing Pallet to the Runtime](/develop/parachains/customize-parachain/add-existing-pallets/){target=\\_blank} page.\n\n3.  Initialize the pallet structure by replacing the contents of `src/lib.rs` with the following scaffold code:\n\n    ```rust\n    -pub use pallet::*;\n\n#[frame_support::pallet]\npub mod pallet {\n    use frame_support::pallet_prelude::*;\n    use frame_system::pallet_prelude::*;\n\n    #[pallet::pallet]\n    pub struct Pallet<T>(_);\n\n    #[pallet::config]  // snip\n    #[pallet::event]   // snip\n    #[pallet::error]   // snip\n    #[pallet::storage] // snip\n    #[pallet::call]    // snip\n}\n    ```\n\n    With this scaffold in place, you're ready to start implementing your custom pallet's specific logic and features. The subsequent sections of this guide will walk you through populating each of these components with the necessary code for your pallet's functionality."}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 2, "depth": 2, "title": "Pallet Configuration", "anchor": "pallet-configuration", "start_char": 4937, "end_char": 6573, "estimated_token_count": 368, "token_estimator": "heuristic-v1", "text": "## Pallet Configuration\n\nEvery pallet includes a Rust trait called [`Config`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html){target=\\_blank}, which exposes configurable options and links your pallet to other parts of the runtime. All types and constants the pallet depends on must be declared within this trait. These types are defined generically and made concrete when the pallet is instantiated in the `runtime/src/lib.rs` file of your blockchain.\n\nIn this step, you'll only configure the common types used by all pallets:\n\n- **`RuntimeEvent`**: Since this pallet emits events, the runtime event type is required to handle them. This ensures that events generated by the pallet can be correctly processed and interpreted by the runtime.\n- **`WeightInfo`**: This type defines the weights associated with the pallet's callable functions (also known as dispatchables). Weights help measure the computational cost of executing these functions. However, the `WeightInfo` type will be left unconfigured since setting up custom weights is outside the scope of this guide.\n\nReplace the line containing the [`#[pallet::config]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.config.html){target=\\_blank} macro with the following code block:\n\n```rust\n-#[pallet::config]\npub trait Config: frame_system::Config {\n    /// The overarching runtime event type.\n    type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n    /// A type representing the weights required by the dispatchables of this pallet.\n    type WeightInfo;\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 3, "depth": 2, "title": "Pallet Events", "anchor": "pallet-events", "start_char": 6573, "end_char": 8404, "estimated_token_count": 439, "token_estimator": "heuristic-v1", "text": "## Pallet Events\n\nAfter configuring the pallet to emit events, the next step is to define the events that can be triggered by functions within the pallet. Events provide a straightforward way to inform external entities, such as dApps, chain explorers, or users, that a significant change has occurred in the runtime. In a FRAME pallet, the details of each event and its parameters are included in the node’s metadata, making them accessible to external tools and interfaces.\n\nThe [`generate_deposit`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.generate_deposit.html){target=\\_blank} macro generates a `deposit_event` function on the `Pallet`, which converts the pallet’s event type into the [`RuntimeEvent`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html#associatedtype.RuntimeEvent){target=\\_blank} (as specified in the `Config` trait) and deposits it using [`frame_system::Pallet::deposit_event`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.deposit_event){target=\\_blank}.\n\nThis step adds an event called `SomethingStored`, which is triggered when a user successfully stores a value in the pallet. The event records both the value and the account that performed the action.\n\nTo define events, replace the [`#[pallet::event]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.event.html){target=\\_blank} line with the following code block:\n\n```rust\n-#[pallet::event]\n#[pallet::generate_deposit(pub(super) fn deposit_event)]\npub enum Event<T: Config> {\n    /// A user has successfully set a new value.\n    SomethingStored {\n        /// The new value set.\n        something: u32,\n        /// The account who set the new value.\n        who: T::AccountId,\n    },\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 4, "depth": 2, "title": "Pallet Errors", "anchor": "pallet-errors", "start_char": 8404, "end_char": 9781, "estimated_token_count": 315, "token_estimator": "heuristic-v1", "text": "## Pallet Errors\n\nWhile events signal the successful completion of calls, errors indicate when and why a call has failed. It's essential to use informative names for errors to clearly communicate the cause of failure. Like events, error documentation is included in the node's metadata, so providing helpful descriptions is crucial.\n\nErrors are defined as an enum named `Error` with a generic type. Variants can have fields or be fieldless. Any field type specified in the error must implement the [`TypeInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_prelude/trait.TypeInfo.html){target=\\_blank} trait, and the encoded size of each field should be as small as possible. Runtime errors can be up to 4 bytes in size, allowing the return of additional information when needed.\n\nThis step defines two basic errors: one for handling cases where no value has been set and another for managing arithmetic overflow.\n\nTo define errors, replace the [`#[pallet::error]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.error.html){target=\\_blank} line with the following code block:\n\n```rust\n-#[pallet::error]\npub enum Error<T> {\n    /// The value retrieved was `None` as no value was previously set.\n    NoneValue,\n    /// There was an attempt to increment the value in storage over `u32::MAX`.\n    StorageOverflow,\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 5, "depth": 2, "title": "Pallet Storage", "anchor": "pallet-storage", "start_char": 9781, "end_char": 10734, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "## Pallet Storage\n\nTo persist and store state/data within the pallet (and subsequently, the blockchain you are building), the `#[pallet::storage]` macro is used. This macro allows the definition of abstract storage within the runtime and sets metadata for that storage. It can be applied multiple times to define different storage items. Several types are available for defining storage, which you can explore in the [Polkadot SDK documentation](https://paritytech.github.io/polkadot-sdk/master/frame_support/storage/types/index.html){target=\\_blank}.\n\nThis step adds a simple storage item, `Something`, which stores a single `u32` value in the pallet's runtime storage\n\nTo define storage, replace the [`#[pallet::storage]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.storage.html){target=\\_blank} line with the following code block:\n\n```rust\n-#[pallet::storage]\npub type Something<T> = StorageValue<_, u32>;\n```"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 6, "depth": 2, "title": "Pallet Dispatchable Extrinsics", "anchor": "pallet-dispatchable-extrinsics", "start_char": 10734, "end_char": 13409, "estimated_token_count": 644, "token_estimator": "heuristic-v1", "text": "## Pallet Dispatchable Extrinsics\n\nDispatchable functions enable users to interact with the pallet and trigger state changes. These functions are represented as \"extrinsics,\" which are similar to transactions. They must return a [`DispatchResult`](https://paritytech.github.io/polkadot-sdk/master/frame_support/dispatch/type.DispatchResult.html){target=\\_blank} and be annotated with a weight and a call index.\n\nThe `#[pallet::call_index]` macro is used to explicitly define an index for calls in the `Call` enum. This is useful for maintaining backward compatibility in the event of new dispatchables being introduced, as changing the order of dispatchables would otherwise alter their index.\n\nThe `#[pallet::weight]` macro assigns a weight to each call, determining its execution cost.\n\nThis section adds two dispatchable functions:\n\n- **`do_something`**: Takes a single `u32` value, stores it in the pallet's storage, and emits an event.\n- **`cause_error`**: Checks if a value exists in storage. If the value is found, it increments and is stored back. If no value is present or an overflow occurs, a custom error is returned.\n\nTo implement these calls, replace the [`#[pallet::call]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.call.html){target=\\_blank} line with the following code block:\n\n```rust\n-#[pallet::call]\nimpl<T: Config> Pallet<T> {\n    #[pallet::call_index(0)]\n    #[pallet::weight(Weight::default())]\n    pub fn do_something(origin: OriginFor<T>, something: u32) -> DispatchResult {\n        // Check that the extrinsic was signed and get the signer.\n        let who = ensure_signed(origin)?;\n\n        // Update storage.\n        Something::<T>::put(something);\n\n        // Emit an event.\n        Self::deposit_event(Event::SomethingStored { something, who });\n\n        // Return a successful `DispatchResult`\n        Ok(())\n    }\n\n    #[pallet::call_index(1)]\n    #[pallet::weight(Weight::default())]\n    pub fn cause_error(origin: OriginFor<T>) -> DispatchResult {\n        let _who = ensure_signed(origin)?;\n\n        // Read a value from storage.\n        match Something::<T>::get() {\n            // Return an error if the value has not been set.\n            None => Err(Error::<T>::NoneValue.into()),\n            Some(old) => {\n                // Increment the value read from storage. This will cause an error in the event\n                // of overflow.\n                let new = old.checked_add(1).ok_or(Error::<T>::StorageOverflow)?;\n                // Update the value in storage with the incremented result.\n                Something::<T>::put(new);\n                Ok(())\n            },\n        }\n    }\n}\n```"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 7, "depth": 2, "title": "Pallet Implementation Overview", "anchor": "pallet-implementation-overview", "start_char": 13409, "end_char": 16371, "estimated_token_count": 661, "token_estimator": "heuristic-v1", "text": "## Pallet Implementation Overview\n\nAfter following all the previous steps, the pallet is now fully implemented. Below is the complete code, combining the configuration, events, errors, storage, and dispatchable functions:\n\n???code\n    ```rust\n    -pub use pallet::*;\n\n#[frame_support::pallet]\npub mod pallet {\n    use frame_support::pallet_prelude::*;\n    use frame_system::pallet_prelude::*;\n\n    #[pallet::pallet]\n    pub struct Pallet<T>(_);\n\n    #[pallet::config]\n    pub trait Config: frame_system::Config {\n        /// The overarching runtime event type.\n        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n        /// A type representing the weights required by the dispatchables of this pallet.\n        type WeightInfo;\n    }\n\n    #[pallet::event]\n    #[pallet::generate_deposit(pub(super) fn deposit_event)]\n    pub enum Event<T: Config> {\n        /// A user has successfully set a new value.\n        SomethingStored {\n            /// The new value set.\n            something: u32,\n            /// The account who set the new value.\n            who: T::AccountId,\n        },\n    }\n    \n    #[pallet::error]\n    pub enum Error<T> {\n        /// The value retrieved was `None` as no value was previously set.\n        NoneValue,\n        /// There was an attempt to increment the value in storage over `u32::MAX`.\n        StorageOverflow,\n    }\n\n    #[pallet::storage]\n    pub type Something<T> = StorageValue<_, u32>;\n\n    #[pallet::call]\n    impl<T: Config> Pallet<T> {\n        #[pallet::call_index(0)]\n        #[pallet::weight(Weight::default())]\n        pub fn do_something(origin: OriginFor<T>, something: u32) -> DispatchResult {\n            // Check that the extrinsic was signed and get the signer.\n            let who = ensure_signed(origin)?;\n    \n            // Update storage.\n            Something::<T>::put(something);\n    \n            // Emit an event.\n            Self::deposit_event(Event::SomethingStored { something, who });\n    \n            // Return a successful `DispatchResult`\n            Ok(())\n        }\n    \n        #[pallet::call_index(1)]\n        #[pallet::weight(Weight::default())]\n        pub fn cause_error(origin: OriginFor<T>) -> DispatchResult {\n            let _who = ensure_signed(origin)?;\n    \n            // Read a value from storage.\n            match Something::<T>::get() {\n                // Return an error if the value has not been set.\n                None => Err(Error::<T>::NoneValue.into()),\n                Some(old) => {\n                    // Increment the value read from storage. This will cause an error in the event\n                    // of overflow.\n                    let new = old.checked_add(1).ok_or(Error::<T>::StorageOverflow)?;\n                    // Update the value in storage with the incremented result.\n                    Something::<T>::put(new);\n                    Ok(())\n                },\n            }\n        }\n    }\n}\n    ```"}
{"page_id": "develop-parachains-customize-parachain-make-custom-pallet", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 16371, "end_char": 17404, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nWith the pallet implemented, the next steps involve ensuring its reliability and performance before integrating it into a runtime. Check the following sections:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Testing__\n\n    ---\n\n    Learn how to effectively test the functionality and reliability of your pallet to ensure it behaves as expected.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/testing/)\n\n-   <span class=\"badge guide\">Guide</span> __Benchmarking__\n\n    ---\n\n    Explore methods to measure the performance and execution cost of your pallet.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/testing/benchmarking)\n\n-   <span class=\"badge guide\">Guide</span> __Add a Pallet to the Runtime__\n\n    ---\n\n    Follow this guide to include your pallet in a Polkadot SDK-based runtime, making it ready for use in your blockchain.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/customize-parachain/add-existing-pallets/)\n\n</div>"}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 919, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe runtime is the heart of any Polkadot SDK-based blockchain, handling the essential logic that governs state changes and transaction processing. With Polkadot SDK’s [FRAME (Framework for Runtime Aggregation of Modularized Entities)](/polkadot-protocol/glossary/#frame-framework-for-runtime-aggregation-of-modularized-entities){target=\\_bank}, developers gain access to a powerful suite of tools for building custom blockchain runtimes. FRAME offers a modular architecture, featuring reusable pallets and support libraries, to streamline development.\n\nThis guide provides an overview of FRAME, its core components like pallets and system libraries, and demonstrates how to compose a runtime tailored to your specific blockchain use case. Whether you’re integrating pre-built modules or designing custom logic, FRAME equips you with the tools to create scalable, feature-rich blockchains."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 1, "depth": 2, "title": "FRAME Runtime Architecture", "anchor": "frame-runtime-architecture", "start_char": 919, "end_char": 1556, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "## FRAME Runtime Architecture\n\nThe following diagram illustrates how FRAME components integrate into the runtime:\n\n![](/images/develop/parachains/customize-parachain/overview/frame-overview-1.webp)\n\nAll transactions sent to the runtime are handled by the `frame_executive` pallet, which dispatches them to the appropriate pallet for execution. These runtime modules contain the logic for specific blockchain features. The `frame_system` module provides core functions, while `frame_support` libraries offer useful tools to simplify pallet development. Together, these components form the backbone of a FRAME-based blockchain's runtime."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 2, "depth": 3, "title": "Pallets", "anchor": "pallets", "start_char": 1556, "end_char": 4385, "estimated_token_count": 643, "token_estimator": "heuristic-v1", "text": "### Pallets\n\nPallets are modular components within the FRAME ecosystem that encapsulate specific blockchain functionalities. These modules offer customizable business logic for various use cases and features that can be integrated into a runtime.\n\nDevelopers have the flexibility to implement any desired behavior in the core logic of the blockchain, such as:\n\n- Exposing new transactions.\n- Storing information.\n- Enforcing business rules.\n\nPallets also include necessary wiring code to ensure proper integration and functionality within the runtime. FRAME provides a range of [pre-built pallets](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame){target=\\_blank} for standard and common blockchain functionalities, including consensus algorithms, staking mechanisms, governance systems, and more. These pre-existing pallets serve as building blocks or templates, which developers can use as-is, modify, or reference when creating custom functionalities. \n\n#### Pallet Structure\n\nPolkadot SDK heavily utilizes Rust macros, allowing developers to focus on specific functional requirements when writing pallets instead of dealing with technicalities and scaffolding code.\n\nA typical pallet skeleton looks like this:\n\n```rust\n-pub use pallet::*;\n\n#[frame_support::pallet]\npub mod pallet {\n  use frame_support::pallet_prelude::*;\n  use frame_system::pallet_prelude::*;\n\n  #[pallet::pallet]\n  #[pallet::generate_store(pub(super) trait Store)]\n  pub struct Pallet<T>(_);\n\n  #[pallet::config]  // snip\n  #[pallet::event]   // snip\n  #[pallet::error]   // snip\n  #[pallet::storage] // snip\n  #[pallet::call]    // snip\n}\n```\n\nAll pallets, including custom ones, can implement these attribute macros:\n\n- **`#[frame_support::pallet]`**: Marks the module as usable in the runtime.\n- **`#[pallet::pallet]`**: Applied to a structure used to retrieve module information easily.\n- **`#[pallet::config]`**: Defines the configuration for the pallets's data types.\n- **`#[pallet::event]`**: Defines events to provide additional information to users.\n- **`#[pallet::error]`**: Lists possible errors in an enum to be returned upon unsuccessful execution.\n- **`#[pallet::storage]`**: Defines elements to be persisted in storage.\n- **`#[pallet::call]`**: Defines functions exposed as transactions, allowing dispatch to the runtime.\n\nThese macros are applied as attributes to Rust modules, functions, structures, enums, and types and serve as the core components of a pallet. They enable the pallet to be built and added to the runtime, exposing the custom logic to the outer world.\n\nFor a comprehensive guide on these and additional macros, see the [`pallet_macros`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/index.html){target=\\_blank} section in the Polkadot SDK documentation."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 3, "depth": 3, "title": "Support Libraries", "anchor": "support-libraries", "start_char": 4385, "end_char": 5409, "estimated_token_count": 254, "token_estimator": "heuristic-v1", "text": "### Support Libraries\n\nIn addition to purpose-specific pallets, FRAME offers services and core libraries that facilitate composing and interacting with the runtime:\n\n- **[`frame_system` pallet](https://paritytech.github.io/polkadot-sdk/master/frame_system/index.html){target=\\_blank}**: Provides low-level types, storage, and functions for the runtime.\n- **[`frame_executive` pallet](https://paritytech.github.io/polkadot-sdk/master/frame_executive/index.html){target=\\_blank}**: Orchestrates the execution of incoming function calls to the respective pallets in the runtime.\n- **[`frame_support` crate](https://paritytech.github.io/polkadot-sdk/master/frame_support/index.html){target=\\_blank}**: Is a collection of Rust macros, types, traits, and modules that simplify the development of Substrate pallets.\n- **[`frame_benchmarking` crate](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/trait.Benchmark.html){target=\\_blank}**: Contains common runtime patterns for benchmarking and testing purposes."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 4, "depth": 2, "title": "Compose a Runtime with Pallets", "anchor": "compose-a-runtime-with-pallets", "start_char": 5409, "end_char": 6146, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## Compose a Runtime with Pallets\n\nThe Polkadot SDK allows developers to construct a runtime by combining various pallets, both built-in and custom-made. This modular approach enables the creation of unique blockchain behaviors tailored to specific requirements.\n\nThe following diagram illustrates the process of selecting and combining FRAME pallets to compose a runtime:\n\n![](/images/develop/parachains/customize-parachain/overview/frame-overview-2.webp)\n\nThis modular design allows developers to:\n\n- Rapidly prototype blockchain systems.\n- Easily add or remove features by including or excluding pallets.\n- Customize blockchain behavior without rebuilding core components.\n- Leverage tested and optimized code from built-in pallets."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 5, "depth": 2, "title": "Starting from Templates", "anchor": "starting-from-templates", "start_char": 6146, "end_char": 6648, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Starting from Templates\n\nUsing pre-built templates is an efficient way to begin building a custom blockchain. Templates provide a foundational setup with pre-configured modules, letting developers avoid starting from scratch and instead focus on customization. Depending on your project’s goals—whether you want a simple test chain, a standalone chain, or a parachain that integrates with Polkadot’s relay chains—there are templates designed to suit different levels of complexity and scalability."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 6, "depth": 3, "title": "Solochain Templates", "anchor": "solochain-templates", "start_char": 6648, "end_char": 7545, "estimated_token_count": 191, "token_estimator": "heuristic-v1", "text": "### Solochain Templates\n\nSolochain templates are designed for developers who want to create standalone blockchains that operate independently without connecting to a relay chain:\n\n- **[`minimal-template`](https://github.com/paritytech/polkadot-sdk/tree/master/templates/minimal){target=\\_blank}**: Includes only the essential components necessary for a functioning blockchain. It’s ideal for developers who want to gain familiarity with blockchain basics and test simple customizations before scaling up.\n\n- **[`solochain-template`](https://github.com/paritytech/polkadot-sdk/tree/master/templates/solochain){target=\\_blank}**: Provides a foundation for creating standalone blockchains with moderate features, including a simple consensus mechanism and several core FRAME pallets. It’s a solid starting point for developers who want a fully functional chain that doesn’t depend on a relay chain."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 7, "depth": 3, "title": "Parachain Templates", "anchor": "parachain-templates", "start_char": 7545, "end_char": 9097, "estimated_token_count": 338, "token_estimator": "heuristic-v1", "text": "### Parachain Templates\n\nParachain templates are specifically designed for chains that will connect to and interact with relay chains in the Polkadot ecosystem:\n\n- **[`parachain-template`](https://github.com/paritytech/polkadot-sdk/tree/master/templates/parachain){target=\\_blank}**: Designed for connecting to relay chains like Polkadot, Kusama, or Paseo, this template enables a chain to operate as a parachain. For projects aiming to integrate with Polkadot’s ecosystem, this template offers a great starting point.\n\n- **[`OpenZeppelin`](https://github.com/OpenZeppelin/polkadot-runtime-templates/tree/main){target=\\_blank}**: Offers two flexible starting points.\n    - The [`generic-runtime-template`](https://github.com/OpenZeppelin/polkadot-runtime-templates/tree/main/generic-template){target=\\_blank} provides a minimal setup with essential pallets and secure defaults, creating a reliable foundation for custom blockchain development.\n    - The [`evm-runtime-template`](https://github.com/OpenZeppelin/polkadot-runtime-templates/tree/main/evm-template){target=\\_blank} enables EVM compatibility, allowing developers to migrate Solidity contracts and EVM-based dApps. This template is ideal for Ethereum developers looking to leverage Substrate's capabilities.\n\nChoosing a suitable template depends on your project’s unique requirements, level of customization, and integration needs. Starting from a template speeds up development and lets you focus on implementing your chain’s unique features rather than the foundational blockchain setup."}
{"page_id": "develop-parachains-customize-parachain-overview", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 9097, "end_char": 9396, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor more detailed information on implementing this process, refer to the following sections:\n\n- [Add a Pallet to Your Runtime](/develop/parachains/customize-parachain/add-existing-pallets/)\n- [Create a Custom Pallet](/develop/parachains/customize-parachain/make-custom-pallet/)"}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 33, "end_char": 1201, "estimated_token_count": 203, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBy default, the Rust compiler produces optimized Wasm binaries. These binaries are suitable for working in an isolated environment, such as local development. However, the Wasm binaries the compiler builds by default aren't guaranteed to be deterministically reproducible. Each time the compiler generates the Wasm runtime, it might produce a slightly different Wasm byte code. This is problematic in a blockchain network where all nodes must use exactly the same raw chain specification file.\n\nWorking with builds that aren't guaranteed to be deterministically reproducible can cause other problems, too. For example, for automating the build processes for a blockchain, it is ideal that the same code always produces the same result (in terms of bytecode). Compiling the Wasm runtime with every push would produce inconsistent and unpredictable results without a deterministic build, making it difficult to integrate with any automation and likely to break a CI/CD pipeline continuously. Deterministic builds—code that always compiles to exactly the same bytecode—ensure that the Wasm runtime can be inspected, audited, and independently verified."}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1201, "end_char": 1327, "estimated_token_count": 37, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have [Docker](https://www.docker.com/get-started/){target=\\_blank} installed."}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 2, "depth": 2, "title": "Tooling for Wasm Runtime", "anchor": "tooling-for-wasm-runtime", "start_char": 1327, "end_char": 2108, "estimated_token_count": 173, "token_estimator": "heuristic-v1", "text": "## Tooling for Wasm Runtime\n\nTo compile the Wasm runtime deterministically, the same tooling that produces the runtime for Polkadot, Kusama, and other Polkadot SDK-based chains can be used. This tooling, referred to collectively as the Substrate Runtime Toolbox or [`srtool`](https://github.com/paritytech/srtool){target=\\_blank}, ensures that the same source code consistently compiles to an identical Wasm blob.\n\nThe core component of `srtool` is a Docker container executed as part of a Docker image. The name of the `srtool` Docker image specifies the version of the Rust compiler used to compile the code included in the image. For example, the image `paritytech/srtool:1.88.0` indicates that the code in the image was compiled with version `1.88.0` of the `rustc` compiler."}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 3, "depth": 2, "title": "Working with the Docker Container", "anchor": "working-with-the-docker-container", "start_char": 2108, "end_char": 3426, "estimated_token_count": 337, "token_estimator": "heuristic-v1", "text": "## Working with the Docker Container\n\nThe [`srtool-cli`](https://github.com/chevdor/srtool-cli){target=\\_blank} package is a command-line utility written in Rust that installs an executable program called `srtool`. This program simplifies the interactions with the `srtool` Docker container.\n\nOver time, the tooling around the `srtool` Docker image has expanded to include the following tools and helper programs:\n\n- **[`srtool-cli`](https://github.com/chevdor/srtool-cli){target=\\_blank}**: Provides a command-line interface to pull the srtool Docker image, get information about the image and tooling used to interact with it, and build the runtime using the `srtool` Docker container.\n- **[`subwasm`](https://github.com/chevdor/subwasm){target=\\_blank}**: Provides command-line options for working with the metadata and Wasm runtime built using srtool. The `subwasm` program is also used internally to perform tasks in the `srtool` image.\n- **[`srtool-actions`](https://github.com/chevdor/srtool-actions){target=\\_blank}**: Provides GitHub actions to integrate builds produced using the `srtool` image with your GitHub CI/CD pipelines.\n- **[`srtool-app`](https://gitlab.com/chevdor/srtool-app){target=\\_blank}**: Provides a simple graphical user interface for building the runtime using the `srtool` Docker image."}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 4, "depth": 2, "title": "Prepare the Environment", "anchor": "prepare-the-environment", "start_char": 3426, "end_char": 4403, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "## Prepare the Environment\n\nIt is recommended to install the `srtool-cli` program to work with the Docker image using a simple command-line interface.\n\nTo prepare the environment:\n\n1. Verify that Docker is installed by running the following command:\n\n    ```bash\n    docker --version\n    ```\n\n    If Docker is installed, the command will display version information:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>docker --version</span>\n  <span data-ty>Docker version 20.10.17, build 100c701</span>\n</div>\n\n\n2. Install the `srtool` command-line interface by running the following command:\n\n    ```bash\n    cargo install --git https://github.com/chevdor/srtool-cli\n    ```\n\n3. View usage information for the `srtool` command-line interface by running the following command:\n\n    ```bash\n    srtool help\n    ```\n\n4. Download the latest `srtool` Docker image by running the following command:\n\n    ```bash\n    srtool pull\n    ```"}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 5, "depth": 2, "title": "Start a Deterministic Build", "anchor": "start-a-deterministic-build", "start_char": 4403, "end_char": 5306, "estimated_token_count": 212, "token_estimator": "heuristic-v1", "text": "## Start a Deterministic Build\n\nAfter preparing the environment, the Wasm runtime can be compiled using the `srtool` Docker image.\n\nTo build the runtime, you need to open your Polkadot SDK-based project in a terminal shell and run the following command:\n\n```bash\nsrtool build --app --package INSERT_RUNTIME_PACKAGE_NAME --runtime-dir INSERT_RUNTIME_PATH \n```\n\n- The name specified for the `--package` should be the name defined in the `Cargo.toml` file for the runtime.\n- The path specified for the `--runtime-dir` should be the path to the `Cargo.toml` file for the runtime. For example:\n\n    ```plain\n    node/\n    pallets/\n    runtime/\n    ├──lib.rs\n    └──Cargo.toml # INSERT_RUNTIME_PATH should be the path to this file\n    ...\n    ```\n\n- If the `Cargo.toml` file for the runtime is located in a `runtime` subdirectory, for example, `runtime/kusama`, the `--runtime-dir` parameter can be omitted."}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 6, "depth": 2, "title": "Use srtool in GitHub Actions", "anchor": "use-srtool-in-github-actions", "start_char": 5306, "end_char": 6776, "estimated_token_count": 367, "token_estimator": "heuristic-v1", "text": "## Use srtool in GitHub Actions\n\nTo add a GitHub workflow for building the runtime:\n\n1. Create a `.github/workflows` directory in the chain's directory.\n2. In the `.github/workflows` directory, click **Add file**, then select **Create new file**.\n3. Copy the sample GitHub action from `basic.yml` example in the [`srtools-actions`](https://github.com/chevdor/srtool-actions){target=\\_blank} repository and paste it into the file you created in the previous step.\n\n    ??? interface \"`basic.yml`\"\n\n        ```yml\n        -name: Srtool build\n\non: push\n\njobs:\n  srtool:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        chain: [\"asset-hub-kusama\", \"asset-hub-westend\"]\n    steps:\n      - uses: actions/checkout@v3\n      - name: Srtool build\n        id: srtool_build\n        uses: chevdor/srtool-actions@v0.8.0\n        with:\n          chain: ${{ matrix.chain }}\n          runtime_dir: polkadot-parachains/${{ matrix.chain }}-runtime\n      - name: Summary\n        run: |\n          echo '${{ steps.srtool_build.outputs.json }}' | jq . > ${{ matrix.chain }}-srtool-digest.json\n          cat ${{ matrix.chain }}-srtool-digest.json\n          echo \"Runtime location: ${{ steps.srtool_build.outputs.wasm }}\"\n        ```\n\n4. Modify the settings in the sample action.\n\n    For example, modify the following settings:\n\n    - The name of the chain.\n    - The name of the runtime package.\n    - The location of the runtime.\n\n5. Type a name for the action file and commit."}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 7, "depth": 2, "title": "Use the srtool Image via Docker Hub", "anchor": "use-the-srtool-image-via-docker-hub", "start_char": 6776, "end_char": 7566, "estimated_token_count": 215, "token_estimator": "heuristic-v1", "text": "## Use the srtool Image via Docker Hub\n\nIf utilizing [`srtool-cli`](https://github.com/chevdor/srtool-cli){target=\\_blank} or [`srtool-app`](https://gitlab.com/chevdor/srtool-app){target=\\_blank} isn't an option, the `paritytech/srtool` container image can be used directly via Docker Hub.\n\nTo pull the image from Docker Hub:\n\n1. Sign in to Docker Hub.\n2. Type `paritytech/srtool` in the search field and press enter.\n3. Click **paritytech/srtool**, then click **Tags**.\n4. Copy the command for the image you want to pull.\n5. Open a terminal shell on your local computer.\n6. Paste the command you copied from the Docker Hub. For example, you might run a command similar to the following, which downloads and unpacks the image:\n\n    ```bash\n    docker pull paritytech/srtool:1.88.0\n    ```"}
{"page_id": "develop-parachains-deployment-build-deterministic-runtime", "index": 8, "depth": 3, "title": "Naming Convention for Images", "anchor": "naming-convention-for-images", "start_char": 7566, "end_char": 8262, "estimated_token_count": 156, "token_estimator": "heuristic-v1", "text": "### Naming Convention for Images\n\nKeep in mind that there is no `latest` tag for the `srtool` image. Ensure that the image selected is compatible with the locally available version of the Rust compiler.\n\nThe naming convention for `paritytech/srtool` Docker images specifies the version of the Rust compiler used to compile the code included in the image. Some images specify both a compiler version and the version of the build script used. For example, an image named `paritytech/srtool:1.62.0-0.9.19` was compiled with version `1.62.0` of the `rustc` compiler and version `0.9.19` of the build script. Images that only specify the compiler version always contain the software's latest version."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 454, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nCoretime can be purchased in bulk for a period of 28 days, providing access to Polkadot's shared security and interoperability for Polkadot parachains. The bulk purchase of coretime includes a rent-control mechanism that keeps future purchases within a predictable price range of the initial purchase. This allows cores to be renewed at a known price without competing against other participants in the open market."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 1, "depth": 2, "title": "Bulk Sale Phases", "anchor": "bulk-sale-phases", "start_char": 454, "end_char": 1474, "estimated_token_count": 218, "token_estimator": "heuristic-v1", "text": "## Bulk Sale Phases\n\nThe bulk sale process consists of three distinct phases:\n\n1. **Interlude phase**: The period between bulk sales when renewals are prioritized.\n2. **Lead-in phase**: Following the interlude phase, a new `start_price` is set, and a Dutch auction begins, lasting for `leadin_length` blocks. During this phase, prices experience downward pressure as the system aims to find market equilibrium. The final price at the end of this phase becomes the `regular_price`, which will be used in the subsequent fixed price phase.\n3. **Fixed price phase**: The final phase where remaining cores are sold at the `regular_price` established during the lead-in phase. This provides a stable and predictable pricing environment for participants who did not purchase during the price discovery period.\n\nFor more comprehensive information about the coretime sales process, refer to the [Coretime Sales](https://wiki.polkadot.com/learn/learn-agile-coretime/#coretime-sales){target=\\_blank} section in the Polkadot Wiki."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 2, "depth": 2, "title": "Renewal Timing", "anchor": "renewal-timing", "start_char": 1474, "end_char": 2107, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Renewal Timing\n\nWhile renewals can technically be made during any phase, it is strongly recommended that they be completed during the interlude phase. Delaying renewal introduces the risk that the core could be sold to another market participant, preventing successful renewal. Renewals must be initiated well in advance to avoid the scenario above. \n\nFor example, if you purchase a core in bulk sale #1, you obtain coretime for the upcoming bulk period (during which bulk sale #2 takes place).\nYour renewal must be completed during bulk sale #2, ideally during its interlude phase, to secure coretime for the subsequent period."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 3, "depth": 2, "title": "Manual Renewal", "anchor": "manual-renewal", "start_char": 2107, "end_char": 3431, "estimated_token_count": 319, "token_estimator": "heuristic-v1", "text": "## Manual Renewal\n\nCores can be renewed by issuing the [`broker.renew(core)`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.renew){target=\\_blank} extrinsic during the coretime sale period. While this process is straightforward, it requires manual action that must not be overlooked. Failure to complete this renewal step before all available cores are sold could result in your parachain being unable to secure a core for the next operational period.\n\nTo manually renew a core:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the Coretime chain, navigate to the **Developer** dropdown, and select the **Extrinsics** option.\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-1.webp)\n\n2. Submit the `broker.renew` extrinsic:\n\n    1. Select the **broker** pallet.\n    2. Choose the **renew** extrinsic.\n    3. Fill in the **core** parameter.\n    4. Click the **Submit Transaction** button.\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-2.webp)\n\nFor optimal results, the renewal should be performed during the interlude phase. Upon successful submission, your core will be renewed for the next coretime period, ensuring the continued operation of your parachain."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 4, "depth": 2, "title": "Auto-Renewal", "anchor": "auto-renewal", "start_char": 3431, "end_char": 4696, "estimated_token_count": 247, "token_estimator": "heuristic-v1", "text": "## Auto-Renewal\n\nThe coretime auto-renewal feature simplifies maintaining continuous coretime allocation by automatically renewing cores at the beginning of each sale period. This eliminates the need for parachains to manually renew their cores for each bulk period, reducing operational overhead and the risk of missing renewal deadlines.\n\nWhen auto-renewal is enabled, the system follows this process at the start of each sale:\n\n1. The system scans all registered auto-renewal records.\n2. For each record, it attempts to process renewal payments from the task's [sovereign account](/polkadot-protocol/glossary/#sovereign-account){target=\\_blank} (which is the sibling account on the Coretime chain derived from the parachain ID).\n3. Upon successful payment, the system emits a `Renewed` event and secures the core for the next period.\n4. If payment fails due to insufficient funds or other issues, the system emits an `AutoRenewalFailed` event.\n\nEven if an auto-renewal attempt fails, the auto-renewal setting remains active for subsequent sales. This means the setting persists across multiple periods once you've configured auto-renewal.\n\nTo enable auto-renewal for your parachain, you must configure several components, as detailed in the following sections."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 5, "depth": 3, "title": "Set Up an HRMP Channel", "anchor": "set-up-an-hrmp-channel", "start_char": 4696, "end_char": 5075, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### Set Up an HRMP Channel\n\nA Horizontal Relay-routed Message Passing (HRMP) channel must be opened between your parachain and the Coretime system chain before configuring auto-renewal. \n\nFor instructions on establishing this connection, consult the [Opening HRMP Channels with System Parachains](/tutorials/interoperability/xcm-channels/para-to-system/){target=\\_blank} guide."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 6, "depth": 3, "title": "Fund Sovereign Account", "anchor": "fund-sovereign-account", "start_char": 5075, "end_char": 6240, "estimated_token_count": 259, "token_estimator": "heuristic-v1", "text": "### Fund Sovereign Account\n\nThe [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=\\_blank} of your parachain on the Coretime chain needs adequate funding to cover both XCM transaction fees and the recurring coretime renewal payments.\n\nTo determine your parachain's sovereign account address, you can:\n\n- Use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=\\_blank} with the **Sibling** option selected.\n\n- Calculate it manually:\n\n    1. Identify the appropriate prefix:\n\n        - **For sibling chains**: `0x7369626c` (decodes to `b\"sibl\"`).\n         \n    2. Encode your parachain ID as a u32 [SCALE](/polkadot-protocol/parachain-basics/data-encoding#data-types){target=\\_blank} value:\n\n        - For parachain 2000, this would be `d0070000`.\n\n    3. Combine the prefix with the encoded ID to form the sovereign account address:\n\n        - **Hex**: `0x7369626cd0070000000000000000000000000000000000000000000000000000`\n        - **SS58 format**: `5Eg2fntJ27qsari4FGrGhrMqKFDRnkNSR6UshkZYBGXmSuC8`"}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 7, "depth": 3, "title": "Auto-Renewal Configuration Extrinsics", "anchor": "auto-renewal-configuration-extrinsics", "start_char": 6240, "end_char": 7918, "estimated_token_count": 385, "token_estimator": "heuristic-v1", "text": "### Auto-Renewal Configuration Extrinsics\n\nThe Coretime chain provides two primary extrinsics for managing the auto-renewal functionality:\n\n- **[`enable_auto_renew(core, task, workload_end_hint)`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.enable_auto_renew){target=\\_blank}**: Use this extrinsic to activate automatic renewals for a specific core. This transaction must originate from the sovereign account of the parachain task.\n\n    **Parameters:**\n\n    - **`core`**: The core currently assigned to the task.\n    - **`task`**: The task for which auto-renewal is being enabled.\n    - **`workload_end_hint`**: The timeslice at which the currently assigned core will stop being used. This value helps the system determine when auto-renewal should begin. It is recommended to always provide this value to avoid ambiguity.\n\n        - If the coretime expires in the current sale period, use the last timeslice of the current sale period.\n\n        - If the coretime expires at the end of the next sale period (e.g., because you've already renewed), use the last timeslice of the next sale period.\n\n        - If a lease is active, use the timeslice when the lease ends.\n\n- **[`disable_auto_renew(core, task)`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.disable_auto_renew){target=\\_blank}**: Use this extrinsic to stop automatic renewals. This extrinsic also requires that the origin is the sovereign account of the parachain task.\n\n     **Parameters:**\n\n    - **`core`**: The core currently assigned to the task.\n    - **`task`**: The task for which auto-renewal is enabled."}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 8, "depth": 3, "title": "Construct the Enable Auto-Renewal Extrinsic", "anchor": "construct-the-enable-auto-renewal-extrinsic", "start_char": 7918, "end_char": 11500, "estimated_token_count": 799, "token_estimator": "heuristic-v1", "text": "### Construct the Enable Auto-Renewal Extrinsic\n\nTo configure auto-renewal, you'll need to gather specific information for the `enable_auto_renew` extrinsic parameters:\n\n- **`core`**: Identify which core your parachain is assigned to when it expires. This requires checking both current assignments and planned future assignments.\n    - **For current period**: Query `broker.workload()`.\n    - **For next period**: Query `broker.workplan()`.\n\n    **Example for parachain `2000`:**\n    \n    - Current assignment (workload):\n\n        ```txt\n        [\n          [50]\n          [{\n            mask: 0xffffffffffffffffffff\n            assignment: {Task: 2,000}\n          }]\n        ]\n        ```\n\n    - Future assignment (workplan):\n\n        ```txt\n        [\n          [[322,845, 48]]\n          [{\n            mask: 0xffffffffffffffffffff\n            assignment: {Task: 2,000}\n          }]\n        ]\n        ```\n\n    **Note:** Use the core from workplan (`48` in this example) if your task appears there. Only use the core from workload if it's not listed in workplan.\n\n- **`task`**: Use your parachain ID, which can be verified by connecting to your parachain and querying `parachainInfo.parachainId()`.\n\n- **`workload_end_hint`**: You should always set it explicitly to avoid misbehavior. This value indicates when your assigned core will expire. Here's how to calculate the correct value based on how your core is assigned.\n    - If the parachain uses bulk coretime, query `broker.saleinfo`. You’ll get a result like:\n\n        ```json\n        {\n        \"saleStart\": 1544949,\n        \"leadinLength\": 100800,\n        \"endPrice\": 922760076,\n        \"regionBegin\": 322845,\n        \"regionEnd\": 327885,\n        \"idealCoresSold\": 18,\n        \"coresOffered\": 18,\n        \"firstCore\": 44,\n        \"selloutPrice\": 92272712073,\n        \"coresSold\": 18\n        }\n        ```\n\n        - If the core expires in the current sale, use the `regionBegin` value, which in this case is  `322845`.\n\n        - If the core has already been renewed and will expire in the next sale, use the `regionEnd` value. In this example, that would be `327885`.\n\n\n    - If the parachain has a lease, query `broker.leases`, which returns entries like:\n\n        ```json\n        [\n          {\n            \"until\": 359280,\n            \"task\": 2035\n          },\n          ...\n        ]\n        ```\n\n        - Use the `until` value of the lease that corresponds to your task. For example, `359280` would be the value for `workload_end_hint` in the case of task `2035`.\n\nOnce you have these values, construct the extrinsic:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the Coretime chain, navigate to the **Developer** dropdown, and select the **Extrinsics** option.\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-1.webp)\n\n2. Create the `broker.enable_auto_renew` extrinsic:\n\n    1. Select the **broker** pallet.\n    2. Choose the **enableAutoRenew** extrinsic.\n    3. Fill in the parameters.\n    4. Copy the encoded call data.\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-3.webp)\n\n    For parachain `2000` on core `48` with `workload_end_hint` `327885`, the **encoded call data** is:`0x32153000d007000001cd000500`.\n\n3. Check the transaction weight for executing the call. You can estimate this by executing the `transactionPaymentCallApi.queryCallInfo` runtime call with the encoded call data previously obtained.\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-4.webp)"}
{"page_id": "develop-parachains-deployment-coretime-renewal", "index": 9, "depth": 3, "title": "Submit the XCM from Your Parachain", "anchor": "submit-the-xcm-from-your-parachain", "start_char": 11500, "end_char": 13915, "estimated_token_count": 574, "token_estimator": "heuristic-v1", "text": "### Submit the XCM from Your Parachain\n\nTo activate auto-renewal, you must submit an XCM from your parachain to the Coretime chain using Root origin.  This can be done through the sudo pallet (if available) or your parachain's governance system.\n\nThe XCM needs to execute these operations:\n\n1. Withdraw DOT from your parachain's sovereign account on the Coretime chain.\n2. Buy execution to pay for transaction fees.\n3. Execute the auto-renewal extrinsic.\n4. Refund surplus DOT back to the sovereign account.\n\nHere's how to submit this XCM using Acala (Parachain 2000) as an example:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to your parachain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n2. Create a `sudo.sudo` extrinsic that executes `polkadotXcm.send`:\n    1. Use the `sudo.sudo` extrinsic to execute the following call as Root.\n    2. Select the **polkadotXcm** pallet.\n    3. Choose the **send** extrinsic.\n    4. Set the **dest** parameter as the Coretime chain (Parachain 1005).\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-5.webp)\n\n\n3. Construct the XCM and submit it:\n\n    1. Add a **WithdrawAsset** instruction.\n    2. Add a **BuyExecution** instruction.\n    3. Add a **Transact** instruction with the following parameters:\n\n        - **originKind**: Use `SovereignAccount`.\n        - **requireWeightAtMost**: Use the weight calculated previously.\n        - **call**: Use the encoded call data generated before.\n\n    4. Add a **RefundSurplus** instruction.\n    5. Add a **DepositAsset** instruction to send the remaining funds to the parachain sovereign account.\n    6. Click the **Submit Transaction** button.\n\n    ![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-6.webp)\n\nAfter successful execution, your parachain should have auto-renewal enabled. To verify this, check the events emitted in the Coretime chain. You should see a confirmation event named `broker.AutoRenewalEnabled`, which includes two parameters:\n\n- **core**: The core currently assigned to your task, in this example, `48`.\n- **task**: The task for which auto-renewal was enabled, in this example, `2000`.\n\nYou can find this event in the list of recent events. It should look similar to the following:\n\n![](/images/develop/parachains/deployment/coretime-renewal/coretime-renewal-7.webp)"}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 1227, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nA chain specification collects information that describes a Polkadot SDK-based network. A chain specification is a crucial parameter when starting a node, providing the genesis configurations, bootnodes, and other parameters relating to that particular network. It identifies the network a blockchain node connects to, the other nodes it initially communicates with, and the initial state that nodes must agree on to produce blocks.\n\nThe chain specification is defined using the [`ChainSpec`](https://paritytech.github.io/polkadot-sdk/master/sc_chain_spec/struct.GenericChainSpec.html){target=\\_blank} struct. This struct separates the information required for a chain into two parts:\n\n- **Client specification**: Contains information the _node_ uses to communicate with network participants and send data to telemetry endpoints. Many of these chain specification settings can be overridden by command-line options when starting a node or can be changed after the blockchain has started.\n\n- **Initial genesis state**: Agreed upon by all nodes in the network. It must be set when the blockchain is first started and cannot be changed after that without starting a whole new blockchain."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 1, "depth": 2, "title": "Node Settings Customization", "anchor": "node-settings-customization", "start_char": 1227, "end_char": 2003, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## Node Settings Customization\n\nFor the node, the chain specification controls information such as:\n\n- The bootnodes the node will communicate with.\n- The server endpoints for the node to send telemetry data to.\n- The human and machine-readable names for the network the node will connect to.\n\nThe chain specification can be customized to include additional information. For example, you can configure the node to connect to specific blocks at specific heights to prevent long-range attacks when syncing a new node from genesis.\n\nNote that you can customize node settings after genesis. However, nodes only add peers that use the same [`protocolId`](https://paritytech.github.io/polkadot-sdk/master/sc_service/struct.GenericChainSpec.html#method.protocol_id){target=_blank}."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 2, "depth": 2, "title": "Genesis Configuration Customization", "anchor": "genesis-configuration-customization", "start_char": 2003, "end_char": 3091, "estimated_token_count": 213, "token_estimator": "heuristic-v1", "text": "## Genesis Configuration Customization\n\nAll nodes in the network must agree on the genesis state before they can agree on any subsequent blocks. The information configured in the genesis portion of a chain specification is used to create a genesis block. When you start the first node, it takes effect and cannot be overridden with command-line options. However, you can configure some information in the genesis section of a chain specification. For example, you can customize it to include information such as:\n\n- Initial account balances.\n- Accounts that are initially part of a governance council.\n- The account that controls the `sudo` key.\n- Any other genesis state for a pallet.\n\nNodes also require the compiled Wasm to execute the runtime logic on the chain, so the initial runtime must also be supplied in the chain specification. For a more detailed look at customizing the genesis chain specification, be sure to check out the [Polkadot SDK Docs](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/chain_spec_genesis/index.html){target=_blank}."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 3, "depth": 2, "title": "Declaring Storage Items for a Runtime", "anchor": "declaring-storage-items-for-a-runtime", "start_char": 3091, "end_char": 3853, "estimated_token_count": 173, "token_estimator": "heuristic-v1", "text": "## Declaring Storage Items for a Runtime\n\nA runtime usually requires some storage items to be configured at genesis. This includes the initial state for pallets, for example, how much balance specific accounts have, or which account will have sudo permissions.\n\nThese storage values are configured in the genesis portion of the chain specification. You can create a [patch](https://paritytech.github.io/polkadot-sdk/master/sc_chain_spec/index.html#chain-spec-formats){target=_blank} file and ingest it using the [`chain-spec-builder`](https://paritytech.github.io/polkadot-sdk/master/staging_chain_spec_builder/index.html){target=_blank} utility, that is explained in the [Creating a Custom Chain Specification](#creating-a-custom-chain-specification) section."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 4, "depth": 2, "title": "Chain Specification JSON Format", "anchor": "chain-specification-json-format", "start_char": 3853, "end_char": 5715, "estimated_token_count": 475, "token_estimator": "heuristic-v1", "text": "## Chain Specification JSON Format\n\nUsers generally work with the JSON format of the chain specification. Internally, the chain specification is embedded in the [`GenericChainSpec`](https://paritytech.github.io/polkadot-sdk/master/sc_chain_spec/struct.GenericChainSpec.html){target=\\_blank} struct, with specific properties accessible through the [`ChainSpec`](https://paritytech.github.io/polkadot-sdk/master/sc_chain_spec/trait.ChainSpec.html){target=\\_blank} struct. The chain specification includes the following keys:\n\n- **`name`**: The human-readable name for the network.\n- **`id`**: The machine-readable identifier for the network.\n- **`chainType`**: The type of chain to start (refer to [`ChainType`](https://paritytech.github.io/polkadot-sdk/master/sc_chain_spec/enum.ChainType.html){target=\\_blank} for more details).\n- **`bootNodes`**: A list of multiaddresses belonging to the chain's boot nodes.\n- **`telemetryEndpoints`**: An optional list of multiaddresses for telemetry endpoints with verbosity levels ranging from 0 to 9 (0 being the lowest verbosity).\n- **`protocolId`**: The optional protocol identifier for the network.\n- **`forkId`**: An optional fork ID that should typically be left empty; it can be used to signal a fork at the network level when two chains share the same genesis hash.\n- **`properties`**: Custom properties provided as a key-value JSON object.\n- **`codeSubstitutes`**: An optional mapping of block numbers to Wasm code.\n- **`genesis`**: The genesis configuration for the chain.\n\nFor example, the following JSON shows a basic chain specification file:\n\n```json\n-{\n    \"name\": \"chainName\",\n    \"id\": \"chainId\",\n    \"chainType\": \"Local\",\n    \"bootNodes\": [],\n    \"telemetryEndpoints\": null,\n    \"protocolId\": null,\n    \"properties\": null,\n    \"codeSubstitutes\": {},\n    \"genesis\": {\n        \"code\": \"0x...\"\n    }\n}\n\n```"}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 5, "depth": 2, "title": "Creating a Custom Chain Specification", "anchor": "creating-a-custom-chain-specification", "start_char": 5715, "end_char": 6286, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "## Creating a Custom Chain Specification\n\nTo create a custom chain specification, you can use the [`chain-spec-builder`](https://paritytech.github.io/polkadot-sdk/master/staging_chain_spec_builder/index.html){target=\\_blank} tool. This is a CLI tool that is used to generate chain specifications from the runtime of a node. To install the tool, run the following command:\n\n```bash\ncargo install --git https://github.com/paritytech/polkadot-sdk --force staging-chain-spec-builder\n```\n\nTo verify the installation, run the following:\n\n```bash\nchain-spec-builder --help\n```"}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 6, "depth": 3, "title": "Plain Chain Specifications", "anchor": "plain-chain-specifications", "start_char": 6286, "end_char": 7712, "estimated_token_count": 344, "token_estimator": "heuristic-v1", "text": "### Plain Chain Specifications\n\nTo create a plain chain specification, first ensure that the runtime has been compiled and is available at the specified path. Next, you can use the following utility within your project:\n\n```bash\nchain-spec-builder create -r INSERT_RUNTIME_WASM_PATH INSERT_COMMAND\n```\n\nReplace `INSERT_RUNTIME_WASM_PATH` with the path to the runtime Wasm file and `INSERT_COMMAND` with the command to insert the runtime into the chain specification. \n\nThe available commands are:\n\n- **`patch`**: Overwrites the runtime's default genesis config with the provided patch. You can check the following [patch file](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/substrate/bin/utils/chain-spec-builder/tests/input/patch.json){target=\\_blank} as a reference.\n- **`full`**: Build the genesis config for runtime using the JSON file. No defaults will be used. As a reference, you can check the following [full file](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/substrate/bin/utils/chain-spec-builder/tests/input/full.json){target=\\_blank}.\n- **`default`**: Gets the default genesis config for the runtime and uses it in `ChainSpec`. Please note that the default genesis config may not be valid. For some runtimes, initial values should be added there (e.g., session keys, BABE epoch).\n- **`named-preset`**: Uses named preset provided by the runtime to build the chain spec."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 7, "depth": 3, "title": "Raw Chain Specifications", "anchor": "raw-chain-specifications", "start_char": 7712, "end_char": 9379, "estimated_token_count": 310, "token_estimator": "heuristic-v1", "text": "### Raw Chain Specifications\n\nWith runtime upgrades, the blockchain's runtime can be upgraded with newer business logic. Chain specifications contain information structured in a way that the node's runtime can understand. For example, consider this excerpt of a common entry for a chain specification:\n\n```json\n\"sudo\": {\n    \"key\": \"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\"\n}\n```\n\nIn the plain chain spec JSON file, the keys and associated values are in a human-readable format, which can be used to initialize the genesis storage. When the chain specification is loaded, the runtime converts these readable values into storage items within the trie. However, for long-lived networks like testnets or production chains, using the raw format for storage initialization is preferred. This avoids the need for conversion by the runtime and ensures that storage items remain consistent, even when runtime upgrades occur.\n\nTo enable a node with an upgraded runtime to synchronize with a chain from genesis, the plain chain specification is encoded in a raw format. The raw format allows the distribution of chain specifications that all nodes can use to synchronize the chain even after runtime upgrades.\n\nTo convert a plain chain specification to a raw chain specification, you can use the following utility:\n\n```bash\nchain-spec-builder convert-to-raw chain_spec.json\n```\n\nAfter the conversion to the raw format, the `sudo key` snippet looks like this:\n\n```json\n\"0x50a63a871aced22e88ee6466fe5aa5d9\": \"0xd43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d\",\n```\n\nThe raw chain specification can be used to initialize the genesis storage for a node."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 8, "depth": 2, "title": "Generate Custom Keys for Your Collator", "anchor": "generate-custom-keys-for-your-collator", "start_char": 9379, "end_char": 11741, "estimated_token_count": 463, "token_estimator": "heuristic-v1", "text": "## Generate Custom Keys for Your Collator\n\nTo securely deploy your parachain, you must generate custom cryptographic keys for your collators (block producers). Each collator requires two distinct sets of keys with different security requirements and operational purposes.\n\n- **Account keys**: Serve as the primary identity and financial controller for your collator. These keys are used to interact with the network and manage funds. They should be treated as cold storage and must never exist on the filesystem of the collator node. Secure offline backup is essential.\n\n- **Session keys**: Handle block production operations to identify your node and sign blocks on the network. These keys are stored in the parachain keystore and function as operational \"hot wallet\" keys. If compromised, an attacker could impersonate your node, potentially resulting in slashing of your funds. To minimize these risks, implement regular session key rotation and treat them with the same caution as hot wallet keys.\n\nTo perform this step, you can use [Subkey](https://docs.rs/crate/subkey/latest){target=\\_blank}, a command-line tool for generating and managing keys:\n\n```bash\ndocker run -it parity/subkey:latest generate --scheme sr25519\n```\n\nThe output should look similar to the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>docker run -it parity/subkey:latest generate --scheme sr25519</span>\n  <span> <br />Secret phrase: lemon play remain picture leopard frog mad bridge hire hazard best buddy <br />Network ID: substrate <br />Secret seed: 0xb748b501de061bae1fcab1c0b814255979d74d9637b84e06414a57a1a149c004 <br />Public key (hex): 0xf4ec62ec6e70a3c0f8dcbe0531e2b1b8916cf16d30635bbe9232f6ed3f0bf422 <br />Account ID: 0xf4ec62ec6e70a3c0f8dcbe0531e2b1b8916cf16d30635bbe9232f6ed3f0bf422 <br />Public key (SS58): 5HbqmBBJ5ALUzho7tw1k1jEgKBJM7dNsQwrtfSfUskT1a3oe <br />SS58 Address: 5HbqmBBJ5ALUzho7tw1k1jEgKBJM7dNsQwrtfSfUskT1a3oe </span>\n</div>\n\n\nEnsure that this command is executed twice to generate the keys for both the account and session keys. Save them for future reference.\n\nAfter generating the plain chain specification, you need to edit this file by inserting the account IDs and session keys in SS58 format generated for your collators in the `collatorSelection.invulnerables` and `session.keys` fields."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 9, "depth": 3, "title": "Add Invulnerables", "anchor": "add-invulnerables", "start_char": 11741, "end_char": 12517, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### Add Invulnerables\n\nIn the `collatorSelection.invulnerables` array, add the SS58 addresses (account keys) of your collators. These addresses will be automatically included in the active collator set:\n\n```json\n-    \"collatorSelection\": {\n        \"candidacyBond\": 16000000000,\n        \"desiredCandidates\": 0,\n        \"invulnerables\": [\n            \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n            \"INSERT_ACCOUNT_ID_COLLATOR_2\",\n            \"INSERT_ACCOUNT_ID_COLLATOR_3\"\n        ]\n    }\n```\n\n- **`candidacyBond`**: Minimum stake required for collator candidates (in Planck units).\n- **`desiredCandidates`**: Number of candidates beyond invulnerables (set to 0 for invulnerables-only).\n- **`invulnerables`**: Use the SS58 addresses from your generated account keys as collators."}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 10, "depth": 3, "title": "Add Session Keys", "anchor": "add-session-keys", "start_char": 12517, "end_char": 13446, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "### Add Session Keys\n\nFor each invulnerable collator, add a corresponding entry in the `session.keys` array. This maps each collator's account ID to their session keys:\n\n```json\n-    \"session\": {\n        \"keys\": [\n            [\n                \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n                \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n                {\n                    \"aura\": \"INSERT_SESSION_KEY_COLLATOR_1\"\n                }\n            ],\n            [\n                \"INSERT_ACCOUNT_ID_COLLATOR_2\",\n                \"INSERT_ACCOUNT_ID_COLLATOR_2\",\n                {\n                    \"aura\": \"INSERT_SESSION_KEY_COLLATOR_2\"\n                }\n            ],\n            [\n                \"INSERT_ACCOUNT_ID_COLLATOR_3\",\n                \"INSERT_ACCOUNT_ID_COLLATOR_3\",\n                {\n                    \"aura\": \"INSERT_SESSION_KEY_COLLATOR_3\"\n                }\n            ]\n        ],\n        \"nonAuthorityKeys\": []\n    }\n```"}
{"page_id": "develop-parachains-deployment-generate-chain-specs", "index": 11, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 13446, "end_char": 14574, "estimated_token_count": 244, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nAfter generating a chain specification, you can use it to initialize the genesis storage for a node. Refer to the following guides to learn how to proceed with the deployment of your blockchain:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Obtain Coretime__\n\n    ---\n\n    Learn how to obtain the necessary coretime configuration to synchronize your blockchain’s timestamping and enhance its performance.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/deployment/obtain-coretime/)\n\n-   <span class=\"badge guide\">Guide</span> __Deployment__\n\n    ---\n\n    Explore the steps required to deploy your chain specification, ensuring a smooth launch of your network and proper node operation.\n\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/deployment/)\n\n-   <span class=\"badge guide\">Guide</span> __Maintenance__\n\n    ---\n\n    Discover best practices for maintaining your blockchain post-deployment, including how to manage upgrades and monitor network health.\n\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/maintenance/)\n\n</div>"}
{"page_id": "develop-parachains-deployment-manage-coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 464, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nCoretime management involves manipulating [bulk coretime](/develop/parachains/deployment/obtain-coretime/#bulk-coretime){target=\\_blank} regions to optimize resource allocation and usage. Regions represent allocated computational resources on cores and can be modified through various operations to meet different project requirements. This guide covers the essential operations for managing your coretime regions effectively."}
{"page_id": "develop-parachains-deployment-manage-coretime", "index": 1, "depth": 2, "title": "Transfer", "anchor": "transfer", "start_char": 464, "end_char": 1190, "estimated_token_count": 181, "token_estimator": "heuristic-v1", "text": "## Transfer\n\n[Transfer](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.transfer){target=\\_blank} ownership of a bulk coretime region to a new owner. This operation allows you to change who controls and manages a specific region. \n\nUse this operation when you need to delegate control of computational resources to another account or when selling regions to other parties.\n\n```rust\npub fn transfer<T: Config>(region_id: RegionId, new_owner: T::AccountId)\n```\n\n**Parameters:**\n\n- **`origin`**: Must be a signed origin of the account which owns the region `region_id`.\n- **`region_id`**: The region whose ownership should change.\n- **`new_owner`**: The new owner for the region."}
{"page_id": "develop-parachains-deployment-manage-coretime", "index": 2, "depth": 2, "title": "Partition", "anchor": "partition", "start_char": 1190, "end_char": 2359, "estimated_token_count": 266, "token_estimator": "heuristic-v1", "text": "## Partition\n\nSplit a bulk coretime region into two non-overlapping regions at a specific time point. This operation divides a region temporally, creating two shorter regions that together span the same duration as the original.\n\nThe [partition](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.partition){target=\\_blank} operation removes the original region and creates two new regions with the same owner and core mask. The first new region spans from the original start time to the pivot point, while the second spans from the pivot point to the original end time.\n\nThis is useful when you want to use part of your allocated time immediately and reserve the remainder for later use or when you want to sell or transfer only a portion of your time allocation.\n\n```rust\npub fn partition<T: Config>(region_id: RegionId, pivot: Timeslice)\n```\n\n**Parameters:**\n\n- **`origin`**: Must be a signed origin of the account which owns the region `region_id`.\n- **`region_id`**: The region which should be partitioned into two non-overlapping regions.\n- **`pivot`**: The offset in time into the region at which to make the split."}
{"page_id": "develop-parachains-deployment-manage-coretime", "index": 3, "depth": 2, "title": "Interlace", "anchor": "interlace", "start_char": 2359, "end_char": 3534, "estimated_token_count": 247, "token_estimator": "heuristic-v1", "text": "## Interlace\n\nSplit a bulk coretime region into two wholly-overlapping regions with complementary interlace masks. This operation allows core sharing by dividing computational resources between two projects that run simultaneously.\n\nThe [interlace](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.interlace){target=\\_blank} operation removes the original region and creates two new regions with the same time span and owner. One region receives the specified core mask, while the other receives the XOR of the specified mask and the original region's core mask.\n\nUse interlacing when you want to share core resources between multiple tasks or when you need to optimize resource utilization by running complementary workloads simultaneously.\n\n```rust\npub fn interlace<T: Config>(region_id: RegionId, pivot: CoreMask)\n```\n\nParameters:\n\n- **`origin`**: Must be a signed origin of the account which owns the region `region_id`.\n- **`region_id`**: The region which should become two interlaced regions of incomplete regularity.\n- **`pivot`**: The interlace mask of one of the two new regions (the other is its partial complement)."}
{"page_id": "develop-parachains-deployment-manage-coretime", "index": 4, "depth": 2, "title": "Assign", "anchor": "assign", "start_char": 3534, "end_char": 4617, "estimated_token_count": 262, "token_estimator": "heuristic-v1", "text": "## Assign\n\n[Assign](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.assign){target=\\_blank} a bulk coretime region to a specific task for execution.\n\nThis operation places an item in the work plan corresponding to the region's properties and assigns it to the target task. If the region's end time has already passed, the operation becomes a no-op. If the region's beginning has passed, it effectively starts from the next schedulable timeslice.\n\nUse this operation to execute your tasks on the allocated cores. Choose a final assignment when you're certain about the task allocation or provisional when you might need flexibility for later changes.\n\n```rust\npub fn assign<T: Config>(region_id: RegionId, task: TaskId, finality: Finality)\n```\n\n**Parameters:**\n\n- **`origin`**: Must be a signed origin of the account which owns the region `region_id`.\n- **`region_id`**: The region which should be assigned to the task.\n- **`task`**: The task to assign.\n- **`finality`**: Indication of whether this assignment is final or provisional."}
{"page_id": "develop-parachains-deployment-manage-coretime", "index": 5, "depth": 2, "title": "Pool", "anchor": "pool", "start_char": 4617, "end_char": 5736, "estimated_token_count": 256, "token_estimator": "heuristic-v1", "text": "## Pool\n\nPlace a bulk coretime region into the instantaneous coretime pool to earn revenue from unused computational resources.\n\nThe [pool](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/struct.Pallet.html#method.pool){target=\\_blank} operation places the region in the workplan and assigns it to the instantaneous coretime pool. The region details are recorded to calculate a pro rata share of the instantaneous coretime sales revenue relative to other pool providers.\n\nUse pooling when you have unused coretime that you want to monetize, or when you want to contribute to the network's available computational resources while earning passive income.\n\n```rust\npub fn pool<T: Config>(region_id: RegionId, payee: T::AccountId, finality: Finality)\n```\n\n**Parameters:**\n\n- **`origin`**: Must be a signed origin of the account which owns the region `region_id`.\n- **`region_id`**: The region which should be assigned to the pool.\n- **`payee`**: The account which can collect revenue from the usage of this region.\n- **`finality`**: Indication of whether this pool assignment is final or provisional."}
{"page_id": "develop-parachains-deployment-obtain-coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 1057, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nSecuring coretime is essential for operating a parachain on Polkadot. It provides your parachain with guaranteed computational resources and access to Polkadot's shared security model, ensuring your blockchain can process transactions, maintain its state, and interact securely with other parachains in the network. Without coretime, a parachain cannot participate in the ecosystem or leverage the relay chain's validator set for security.\n\nCoretime represents the computational resources allocated to your parachain on the Polkadot network. It determines when and how often your parachain can produce blocks and have them validated by the relay chain.\n\nThere are two primary methods to obtain coretime:\n\n- **Bulk coretime**: Purchase computational resources in advance for a full month.\n- **On-demand coretime**: Buy computational resources as needed for individual block production.\n\nThis guide explains the different methods of obtaining coretime and walks through the necessary steps to get your parachain running."}
{"page_id": "develop-parachains-deployment-obtain-coretime", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1057, "end_char": 1431, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore obtaining coretime, ensure you have:\n\n- Developed your parachain runtime using the Polkadot SDK.\n- Set up and configured a parachain collator for your target relay chain.\n- Successfully compiled your parachain collator node.\n- Generated and exported your parachain's genesis state.\n- Generated and exported your parachain's validation code (Wasm)."}
{"page_id": "develop-parachains-deployment-obtain-coretime", "index": 2, "depth": 2, "title": "Initial Setup Steps", "anchor": "initial-setup-steps", "start_char": 1431, "end_char": 2324, "estimated_token_count": 211, "token_estimator": "heuristic-v1", "text": "## Initial Setup Steps\n\n1. Reserve a unique identifier, `ParaID`, for your parachain:\n\n    1. Connect to the relay chain.\n    2. Submit the [`registrar.reserve`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_common/paras_registrar/pallet/dispatchables/fn.reserve.html){target=\\_blank} extrinsic.\n\n    Upon success, you'll receive a registered `ParaID`.\n\n2. Register your parachain's essential information by submitting the [`registrar.register`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_common/paras_registrar/pallet/dispatchables/fn.register.html){target=\\_blank} extrinsic with the following parameters:\n\n    - **`id`**: Your reserved `ParaID`.\n    - **`genesisHead`**: Your exported genesis state.\n    - **`validationCode`**: Your exported Wasm validation code.\n\n3. Start your parachain collator and begin synchronization with the relay chain."}
{"page_id": "develop-parachains-deployment-obtain-coretime", "index": 3, "depth": 2, "title": "Obtaining Coretime", "anchor": "obtaining-coretime", "start_char": 2324, "end_char": 2347, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Obtaining Coretime"}
{"page_id": "develop-parachains-deployment-obtain-coretime", "index": 4, "depth": 3, "title": "Bulk Coretime", "anchor": "bulk-coretime", "start_char": 2347, "end_char": 3260, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "### Bulk Coretime\n\nBulk coretime provides several advantages:\n\n- Monthly allocation of resources\n- Guaranteed block production slots (every 12 seconds, or 6 seconds with [Asynchronous Backing](https://wiki.polkadot.com/learn/learn-async-backing/#asynchronous-backing){target=\\_blank})\n- Priority renewal rights\n- Protection against price fluctuations\n- Ability to split and resell unused coretime\n\nTo purchase bulk coretime:\n\n1. Access the Coretime system parachain.\n2. Interact with the Broker pallet.\n3. Purchase your desired amount of coretime.\n4. Assign the purchased core to your registered `ParaID`.\n\nAfter successfully obtaining coretime, your parachain will automatically start producing blocks at regular intervals.\n\nFor current marketplaces and pricing, consult the [Coretime Marketplaces](https://wiki.polkadot.com/learn/learn-guides-coretime-marketplaces/){target=\\_blank} page on the Polkadot Wiki."}
{"page_id": "develop-parachains-deployment-obtain-coretime", "index": 5, "depth": 3, "title": "On-demand Coretime", "anchor": "on-demand-coretime", "start_char": 3260, "end_char": 3713, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "### On-demand Coretime\n\nOn-demand coretime allows for flexible, as-needed block production. To purchase:\n\n1. Ensure your collator node is fully synchronized with the relay chain.\n2. Submit the `onDemand.placeOrderAllowDeath` extrinsic on the relay chain with:\n\n    - **`maxAmountFor`**: Sufficient funds for the transaction.\n    - **`paraId`**: Your registered `ParaID`.\n\nAfter successfully executing the extrinsic, your parachain will produce a block."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 0, "depth": 2, "title": "macOS", "anchor": "macos", "start_char": 324, "end_char": 463, "estimated_token_count": 25, "token_estimator": "heuristic-v1", "text": "## macOS\n\nYou can install Rust and set up a Substrate development environment on Apple macOS computers with Intel or Apple M1 processors."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 1, "depth": 3, "title": "Before You Begin", "anchor": "before-you-begin", "start_char": 463, "end_char": 1905, "estimated_token_count": 335, "token_estimator": "heuristic-v1", "text": "### Before You Begin\n\nBefore you install Rust and set up your development environment on macOS, verify that your computer meets the following basic requirements:\n\n- Operating system version is 10.7 Lion or later.\n- Processor speed of at least 2 GHz. Note that 3 GHz is recommended.\n- Memory of at least 8 GB RAM. Note that 16 GB is recommended.\n- Storage of at least 10 GB of available space.\n- Broadband Internet connection.\n\n#### Install Homebrew\n\nIn most cases, you should use Homebrew to install and manage packages on macOS computers. If you don't already have Homebrew installed on your local computer, you should download and install it before continuing.\n\nTo install Homebrew:\n\n1. Open the Terminal application.\n2. Download and install Homebrew by running the following command:\n\n    ```bash\n    /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n    ```\n\n3. Verify Homebrew has been successfully installed by running the following command:\n\n    ```bash\n    brew --version\n    ```\n\n    The command displays output similar to the following:\n\n    -<div id=\"termynal\" data-termynal markdown>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>brew --version</span>\n  <span data-ty>Homebrew 4.3.15</span>\n</div>\n\n\n#### Support for Apple Silicon\n\nProtobuf must be installed before the build process can begin. To install it, run the following command:\n\n```bash\nbrew install protobuf\n```"}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 2, "depth": 3, "title": "Install Required Packages and Rust", "anchor": "install-required-packages-and-rust", "start_char": 1905, "end_char": 3296, "estimated_token_count": 291, "token_estimator": "heuristic-v1", "text": "### Install Required Packages and Rust\n\nBecause the blockchain requires standard cryptography to support the generation of public/private key pairs and the validation of transaction signatures, you must also have a package that provides cryptography, such as `openssl`.\n\nTo install `openssl` and the Rust toolchain on macOS:\n\n1. Open the Terminal application.\n2. Ensure you have an updated version of Homebrew by running the following command:\n\n    ```bash\n    brew update\n    ```\n\n3. Install the `openssl` package by running the following command:\n\n    ```bash\n    brew install openssl\n    ```\n\n4. Download the `rustup` installation program and use it to install Rust by running the following command:\n\n    ```bash\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n\n5. Follow the prompts displayed to proceed with a default installation.\n6. Update your current shell to include Cargo by running the following command:\n\n    ```bash\n    source ~/.cargo/env\n    ```\n\n7. Configure the Rust toolchain to default to the latest stable version by running the following commands:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup target add wasm32-unknown-unknown\n    rustup component add rust-src\n    ```\n\n8. [Verify your installation](#verifying-installation).\n9. Install `cmake` using the following command:\n\n    ```bash\n    brew install cmake\n    ```"}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 3, "depth": 2, "title": "Linux", "anchor": "linux", "start_char": 3296, "end_char": 3669, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Linux\n\nRust supports most Linux distributions. Depending on the specific distribution and version of the operating system you use, you might need to add some software dependencies to your environment. In general, your development environment should include a linker or C-compatible compiler, such as `clang` and an appropriate integrated development environment (IDE)."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 4, "depth": 3, "title": "Before You Begin {: #before-you-begin-linux }", "anchor": "before-you-begin-before-you-begin-linux", "start_char": 3669, "end_char": 4421, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "### Before You Begin {: #before-you-begin-linux }\n\nCheck the documentation for your operating system for information about the installed packages and how to download and install any additional packages you might need. For example, if you use Ubuntu, you can use the Ubuntu Advanced Packaging Tool (`apt`) to install the `build-essential` package:\n\n```bash\nsudo apt install build-essential\n```\n\nAt a minimum, you need the following packages before you install Rust:\n\n```text\nclang curl git make\n```\n\nBecause the blockchain requires standard cryptography to support the generation of public/private key pairs and the validation of transaction signatures, you must also have a package that provides cryptography, such as `libssl-dev` or `openssl-devel`."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 5, "depth": 3, "title": "Install Required Packages and Rust {: #install-required-packages-and-rust-linux }", "anchor": "install-required-packages-and-rust-install-required-packages-and-rust-linux", "start_char": 4421, "end_char": 6816, "estimated_token_count": 487, "token_estimator": "heuristic-v1", "text": "### Install Required Packages and Rust {: #install-required-packages-and-rust-linux }\n\nTo install the Rust toolchain on Linux:\n\n1. Open a terminal shell.\n2. Check the packages you have installed on the local computer by running an appropriate package management command for your Linux distribution.\n3. Add any package dependencies you are missing to your local development environment by running the appropriate package management command for your Linux distribution:\n\n    === \"Ubuntu\"\n\n        ```bash\n        sudo apt install --assume-yes git clang curl libssl-dev protobuf-compiler\n        ```\n\n    === \"Debian\"\n\n        ```sh\n        sudo apt install --assume-yes git clang curl libssl-dev llvm libudev-dev make protobuf-compiler\n        ```\n\n    === \"Arch\"\n\n        ```sh\n        pacman -Syu --needed --noconfirm curl git clang make protobuf\n        ```\n\n    === \"Fedora\"\n\n        ```sh\n        sudo dnf update\n        sudo dnf install clang curl git openssl-devel make protobuf-compiler\n        ```\n\n    === \"OpenSUSE\"\n\n        ```sh\n        sudo zypper install clang curl git openssl-devel llvm-devel libudev-devel make protobuf\n        ```\n\n    Remember that different distributions might use different package managers and bundle packages in different ways. For example, depending on your installation selections, Ubuntu Desktop and Ubuntu Server might have different packages and different requirements. However, the packages listed in the command-line examples are applicable for many common Linux distributions, including Debian, Linux Mint, MX Linux, and Elementary OS.\n\n4. Download the `rustup` installation program and use it to install Rust by running the following command:\n\n    ```bash\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n\n5. Follow the prompts displayed to proceed with a default installation.\n6. Update your current shell to include Cargo by running the following command:\n\n    ```bash\n    source $HOME/.cargo/env\n    ```\n\n7. Verify your installation by running the following command:\n\n    ```bash\n    rustc --version\n    ```\n\n8. Configure the Rust toolchain to default to the latest stable version by running the following commands:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup target add wasm32-unknown-unknown\n    rustup component add rust-src\n    ```\n\n9. [Verify your installation](#verifying-installation)."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 6, "depth": 2, "title": "Windows (WSL)", "anchor": "windows-wsl", "start_char": 6816, "end_char": 7387, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## Windows (WSL)\n\nIn general, UNIX-based operating systems—like macOS or Linux—provide a better development environment for building Substrate-based blockchains.\n\nHowever, suppose your local computer uses Microsoft Windows instead of a UNIX-based operating system. In that case, you can configure it with additional software to make it a suitable development environment for building Substrate-based blockchains. To prepare a development environment on a Microsoft Windows computer, you can use Windows Subsystem for Linux (WSL) to emulate a UNIX operating environment."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 7, "depth": 3, "title": "Before You Begin {: #before-you-begin-windows }", "anchor": "before-you-begin-before-you-begin-windows", "start_char": 7387, "end_char": 7964, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "### Before You Begin {: #before-you-begin-windows }\n\nBefore installing on Microsoft Windows, verify the following basic requirements:\n\n- You have a computer running a supported Microsoft Windows operating system:\n    - **For Windows desktop**: You must be running Microsoft Windows 10, version 2004 or later, or Microsoft Windows 11 to install WSL.\n    - **For Windows server**: You must be running Microsoft Windows Server 2019, or later, to install WSL on a server operating system.\n- You have good internet connection and access to a shell terminal on your local computer."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 8, "depth": 3, "title": "Set Up Windows Subsystem for Linux", "anchor": "set-up-windows-subsystem-for-linux", "start_char": 7964, "end_char": 10245, "estimated_token_count": 496, "token_estimator": "heuristic-v1", "text": "### Set Up Windows Subsystem for Linux\n\nWSL enables you to emulate a Linux environment on a computer that uses the Windows operating system. The primary advantage of this approach for Substrate development is that you can use all of the code and command-line examples as described in the Substrate documentation. For example, you can run common commands—such as `ls` and `ps`—unmodified. By using WSL, you can avoid configuring a virtual machine image or a dual-boot operating system.\n\nTo prepare a development environment using WSL:\n\n1. Check your Windows version and build number to see if WSL is enabled by default.\n\n    If you have Microsoft Windows 10, version 2004 (Build 19041 and higher), or Microsoft Windows 11, WSL is available by default and you can continue to the next step.\n\n    If you have an older version of Microsoft Windows installed, see the [WSL manual installation steps for older versions](https://learn.microsoft.com/en-us/windows/wsl/install-manual){target=\\_blank}. If you are installing on an older version of Microsoft Windows, you can download and install WLS 2 if your computer has Windows 10, version 1903 or higher.\n\n2. Select **Windows PowerShell** or **Command Prompt** from the **Start** menu, right-click, then **Run as administrator**.\n\n3. In the PowerShell or Command Prompt terminal, run the following command:\n\n    ```bash\n    wsl --install\n    ```\n\n    This command enables the required WSL 2 components that are part of the Windows operating system, downloads the latest Linux kernel, and installs the Ubuntu Linux distribution by default.\n\n    If you want to review the other Linux distributions available, run the following command:\n\n    ```bash\n    wsl --list --online\n    ```\n\n4. After the distribution is downloaded, close the terminal.\n\n5. Click the **Start** menu, select **Shut down or sign out**, then click **Restart** to restart the computer.\n\n    Restarting the computer is required to start the installation of the Linux distribution. It can take a few minutes for the installation to complete after you restart.\n\n    For more information about setting up WSL as a development environment, see the [Set up a WSL development environment](https://learn.microsoft.com/en-us/windows/wsl/setup/environment){target=\\_blank} docs."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 9, "depth": 3, "title": "Install Required Packages and Rust {: #install-required-packages-and-rust-windows }", "anchor": "install-required-packages-and-rust-install-required-packages-and-rust-windows", "start_char": 10245, "end_char": 11807, "estimated_token_count": 346, "token_estimator": "heuristic-v1", "text": "### Install Required Packages and Rust {: #install-required-packages-and-rust-windows }\n\nTo install the Rust toolchain on WSL:\n\n1. Click the **Start** menu, then select **Ubuntu**.\n2. Type a UNIX user name to create user account.\n3. Type a password for your UNIX user, then retype the password to confirm it.\n4. Download the latest updates for the Ubuntu distribution using the Ubuntu Advanced Packaging Tool (`apt`) by running the following command:\n\n    ```bash\n    sudo apt update\n    ```\n\n5. Add the required packages for the Ubuntu distribution by running the following command:\n\n    ```bash\n    sudo apt install --assume-yes git clang curl libssl-dev llvm libudev-dev make protobuf-compiler\n    ```\n\n6. Download the `rustup` installation program and use it to install Rust for the Ubuntu distribution by running the following command:\n\n    ```bash\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n\n7. Follow the prompts displayed to proceed with a default installation.\n\n8. Update your current shell to include Cargo by running the following command:\n\n    ```bash\n    source ~/.cargo/env\n    ```\n\n9. Verify your installation by running the following command:\n\n    ```bash\n    rustc --version\n    ```\n\n10. Configure the Rust toolchain to use the latest stable version as the default toolchain by running the following commands:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup target add wasm32-unknown-unknown\n    rustup component add rust-src\n    ```\n\n11. [Verify your installation](#verifying-installation)."}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 10, "depth": 2, "title": "Verifying Installation", "anchor": "verifying-installation", "start_char": 11807, "end_char": 12499, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "## Verifying Installation\n\nVerify the configuration of your development environment by running the following command:\n\n```bash\nrustup show\n```\n\nThe command displays output similar to the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>rustup show</span>\n  <span data-ty>...</span>\n  <br />\n  <span data-ty>active toolchain</span>\n  <span data-ty>----------------</span>\n  <span data-ty>name: stable-aarch64-apple-darwin</span>\n  <span data-ty>active because: it's the default toolchain</span>\n  <span data-ty>installed targets:</span>\n  <span data-ty>  aarch64-apple-darwin</span>\n  <span data-ty>  wasm32-unknown-unknown</span>\n</div>"}
{"page_id": "develop-parachains-install-polkadot-sdk", "index": 11, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 12499, "end_char": 12748, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n- **[Parachain Zero to Hero Tutorials](/tutorials/polkadot-sdk/parachains/zero-to-hero/){target=\\_blank}**: A series of step-by-step guides to building, testing, and deploying custom pallets and runtimes using the Polkadot SDK."}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 32, "end_char": 1691, "estimated_token_count": 378, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot SDK](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506){target=\\_blank} is a powerful and versatile developer kit designed to facilitate building on the Polkadot network. It provides the necessary components for creating custom blockchains, parachains, generalized rollups, and more. Written in the Rust programming language, it puts security and robustness at the forefront of its design.\n\nWhether you're building a standalone chain or deploying a parachain on Polkadot, this SDK equips developers with the libraries and tools needed to manage runtime logic, compile the codebase, and utilize core features like staking, governance, and Cross-Consensus Messaging (XCM). It also provides a means for building generalized peer-to-peer systems beyond blockchains. The Polkadot SDK houses the following overall functionality:\n\n- Networking and peer-to-peer communication (powered by [Libp2p](/polkadot-protocol/glossary#libp2p){target=\\_blank}).\n- Consensus protocols, such as [BABE](/polkadot-protocol/glossary#blind-assignment-of-blockchain-extension-babe){target=\\_blank}, [GRANDPA](/polkadot-protocol/glossary#grandpa){target=\\_blank}, or [Aura](/polkadot-protocol/glossary#authority-round-aura){target=\\_blank}.\n- Cryptography.\n- The ability to create portable Wasm runtimes.\n- A selection of pre-built modules, called [pallets](/polkadot-protocol/glossary#pallet){target=\\_blank}.\n- Benchmarking and testing suites.\n\nFor an in-depth look at the monorepo, see the [Polkadot SDK Rust documentation](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html){target=\\_blank}."}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 1, "depth": 2, "title": "Polkadot SDK Overview", "anchor": "polkadot-sdk-overview", "start_char": 1691, "end_char": 2873, "estimated_token_count": 311, "token_estimator": "heuristic-v1", "text": "## Polkadot SDK Overview\n\nThe Polkadot SDK is composed of five major components:\n\n![](/images/develop/parachains/intro-polkadot-sdk/intro-polkadot-sdk-1.webp)\n\n- **[Substrate](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/substrate/index.html){target=\\_blank}**: A set of libraries and primitives for building blockchains.\n- **[FRAME](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank}**: A blockchain development framework built on top of Substrate.\n- **[Cumulus](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/cumulus/index.html){target=\\_blank}**: A set of libraries and pallets to add parachain capabilities to a Substrate/FRAME runtime.\n- **[XCM (Cross Consensus Messaging)](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/xcm/index.html){target=\\_blank}**: The primary format for conveying messages between parachains.\n- **[Polkadot](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/polkadot/index.html){target=\\_blank}**: The node implementation for the Polkadot protocol."}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 2, "depth": 3, "title": "Substrate", "anchor": "substrate", "start_char": 2873, "end_char": 5026, "estimated_token_count": 416, "token_estimator": "heuristic-v1", "text": "### Substrate\n\nSubstrate is a Software Development Kit (SDK) that uses Rust-based libraries and tools to enable you to build application-specific blockchains from modular and extensible components. Application-specific blockchains built with Substrate can run as standalone services or in parallel with other chains to take advantage of the shared security provided by the Polkadot ecosystem. Substrate includes default implementations of the core components of the blockchain infrastructure to allow you to focus on the application logic.\n\nEvery blockchain platform relies on a decentralized network of computers—called nodes—that communicate with each other about transactions and blocks. In general, a node in this context is the software running on the connected devices rather than the physical or virtual machine in the network. As software, Substrate-based nodes consist of two main parts with separate responsibilities:\n\n- **Client**: Services to handle network and blockchain infrastructure activity.\n\n    - Native binary.\n    - Executes the Wasm runtime.\n    - Manages components like database, networking, mempool, consensus, and others.\n    - Also known as \"Host\".\n\n- **Runtime**: Business logic for state transitions.\n\n    - Application logic.\n    - Compiled to [Wasm](https://webassembly.org/){target=\\_blank}.\n    - Stored as a part of the chain state.\n    - Also known as State Transition Function (STF).\n\n```mermaid\n%%{init: {'flowchart': {'padding': 5, 'nodeSpacing': 50, 'rankSpacing': 10}}}%%\ngraph TB\n    classDef title font-size:20px,font-weight:bold,stroke-width:0px\n    classDef clientStyle font-size:16px,font-weight:bold\n    classDef clientSubNodeStyle margin-top:10px\n    classDef runtimeCallExecutorStyle padding-top:10px\n\n    subgraph sg1[Substrate<br /> Node]\n        direction TB\n\n        I[RuntimeCall Executor]\n        B[Wasm Runtime - STF]\n\n        subgraph sg2[Client]\n            direction TB\n            C[Network and Blockchain<br/>Infrastructure Services]\n        end\n\n        I --> B\n    end\n\n    class sg1 title\n    class sg2 clientStyle\n    class C clientSubNodeStyle\n    class I runtimeCallExecutorStyle\n\n```"}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 3, "depth": 3, "title": "FRAME", "anchor": "frame", "start_char": 5026, "end_char": 6950, "estimated_token_count": 418, "token_estimator": "heuristic-v1", "text": "### FRAME\n\nFRAME provides the core modular and extensible components that make the Substrate SDK flexible and adaptable to different use cases. FRAME includes Rust-based libraries that simplify the development of application-specific logic. Most of the functionality that FRAME provides takes the form of plug-in modules called [pallets](/polkadot-protocol/glossary#pallet){target=\\_blank} that you can add and configure to suit your requirements for a custom runtime.\n\n```mermaid\ngraph LR\n    subgraph SP[\"<b style='font-size:18px;'>Runtime</b>\"]\n        direction LR\n        Timestamp ~~~ Aura ~~~ GRANDPA\n        Balances ~~~ TransactionPayment ~~~ Sudo\n        subgraph Timestamp[\"Timestamp\"]\n            SS1[Custom Config]\n        end\n        subgraph Aura[\"Aura\"]\n            SS2[Custom Config]\n        end\n        subgraph GRANDPA[\"GRANDPA\"]\n            SS3[Custom Config]\n        end\n        subgraph Balances[\"Balances\"]\n            SS4[Custom Config]\n        end\n        subgraph TransactionPayment[\"Transaction Payment\"]\n            SS5[Custom Config]\n        end\n        subgraph Sudo[\"Sudo\"]\n            SS6[Custom Config]\n        end\n        style Timestamp stroke:#FF69B4\n        style Aura stroke:#FF69B4\n        style GRANDPA stroke:#FF69B4\n        style Balances stroke:#FF69B4\n        style TransactionPayment stroke:#FF69B4\n        style Sudo stroke:#FF69B4\n        style SS1 stroke-dasharray: 5\n        style SS2 stroke-dasharray: 5\n        style SS3 stroke-dasharray: 5\n        style SS4 stroke-dasharray: 5\n        style SS5 stroke-dasharray: 5\n        style SS6 stroke-dasharray: 5\n\n    end\n    subgraph AP[\"<b style='font-size:18px;'>FRAME Pallets</b>\"]\n        direction LR\n        A1[Aura]~~~A2[BABE]~~~A3[GRANDPA]~~~A4[Transaction<br>Payment]\n        B1[Identity]~~~B2[Balances]~~~B3[Sudo]~~~B4[EVM]\n        C1[Timestamp]~~~C2[Assets]~~~C3[Contracts]~~~C4[and more...]\n    end\n    AP --> SP\n```"}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 4, "depth": 3, "title": "Cumulus", "anchor": "cumulus", "start_char": 6950, "end_char": 7232, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### Cumulus\n\nCumulus provides utilities and libraries to turn FRAME-based runtimes into runtimes that can be a parachain on Polkadot. Cumulus runtimes are still FRAME runtimes but contain the necessary functionality that allows that runtime to become a parachain on a relay chain."}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 5, "depth": 2, "title": "Why Use Polkadot SDK?", "anchor": "why-use-polkadot-sdk", "start_char": 7232, "end_char": 7666, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Why Use Polkadot SDK?\n\nUsing the Polkadot SDK, you can build application-specific blockchains without the complexity of building a blockchain from scratch or the limitations of building on a general-purpose blockchain. You can focus on crafting the business logic that makes your chain unique and innovative with the additional benefits of flexibility, upgradeability, open-source licensing, and cross-consensus interoperability."}
{"page_id": "develop-parachains-intro-polkadot-sdk", "index": 6, "depth": 2, "title": "Create a Custom Blockchain Using the SDK", "anchor": "create-a-custom-blockchain-using-the-sdk", "start_char": 7666, "end_char": 8756, "estimated_token_count": 243, "token_estimator": "heuristic-v1", "text": "## Create a Custom Blockchain Using the SDK\n\nBefore starting your blockchain development journey, you'll need to decide whether you want to build a standalone chain or a parachain that connects to the Polkadot network. Each path has its considerations and requirements. Once you've made this decision, follow these development stages:\n\n```mermaid\ngraph LR\n    A[Install the Polkadot SDK] --> B[Build the Chain]\n    B --> C[Deploy the Chain]\n```\n\n1. **[Install the Polkadot SDK](/develop/parachains/install-polkadot-sdk/)**: Set up your development environment with all necessary dependencies and tools.\n2. **[Build the chain](/develop/parachains/customize-parachain)**: Learn how to create and customize your blockchain's runtime, configure pallets, and implement your chain's unique features.\n3. **[Deploy the chain](/develop/parachains/deployment)**: Follow the steps to launch your blockchain, whether as a standalone network or as a parachain on Polkadot.\n\nEach stage is covered in detail in its respective guide, walking you through the process from initial setup to final deployment."}
{"page_id": "develop-parachains-maintenance-configure-asynchronous-backing", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 62, "end_char": 884, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis guide applies to parachain projects based on Cumulus that started in 2023 or earlier, where the backing process was synchronous, allowing parablocks to be built only on the latest relay chain block. In contrast, async backing will enable collators to build parablocks on older relay chain blocks and create pipelines of multiple pending parablocks. This parallel block generation increases efficiency and throughput.\n\n!!!note\n    When starting a new parachain project, please use an async backing-compatible template, such as the [parachain template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank}. The rollout process for async backing has three phases. Phases 1 and 2 below involve the installation of new infrastructure. Then, async backing is enabled in phase 3."}
{"page_id": "develop-parachains-maintenance-configure-asynchronous-backing", "index": 1, "depth": 2, "title": "Prerequisite", "anchor": "prerequisite", "start_char": 884, "end_char": 2421, "estimated_token_count": 365, "token_estimator": "heuristic-v1", "text": "## Prerequisite\n\nThe relay chain must have async backing enabled; therefore, double-check the relay's runtime to verify that the following three parameters are included in the relay chain configuration (especially when testing locally with tools like [Zombienet](/develop/toolkit/parachains/spawn-chains/zombienet/get-started/){target=\\_blank}):\n\n```rust title=\"runtimes/relay/polkadot/src/genesis_config_presets.rs\"\n-...\n\"async_backing_params\": {\n    \"max_candidate_depth\": 3,\n    \"allowed_ancestry_len\": 2\n},\n...\n```\n\nYou can see GitHub for an example of the Polkadot relay chain's [`async_backing_params`](https://github.com/polkadot-fellows/runtimes/blob/d49a9f33d0ea85ce51c26c84a70b61624ec06901/relay/polkadot/src/genesis_config_presets.rs#L131-L134){target=\\_blank} configuration. \n\nYou must also ensure the `lookahead` in [`schedulerParams`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/relay_chain/struct.SchedulerParams.html){target=\\_blank} is set to `3`. You can verify the setting by querying the [`scheduler_params`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/configuration/struct.HostConfiguration.html#structfield.scheduler_params){target=\\_blank} using the [`configuration.activeConfig()`](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Frpc-polkadot.helixstreet.io#/chainstate) query in Polkadot JS.\n\n!!! warning \n    If the `lookahead` field is not set to 3, parachain block times will degrade, resulting in worse performance than using synchronous backing."}
{"page_id": "develop-parachains-maintenance-configure-asynchronous-backing", "index": 2, "depth": 2, "title": "Phase 1 - Update Parachain Runtime", "anchor": "phase-1-update-parachain-runtime", "start_char": 2421, "end_char": 11066, "estimated_token_count": 1962, "token_estimator": "heuristic-v1", "text": "## Phase 1 - Update Parachain Runtime\n\nThis phase involves configuring your parachain's runtime `/runtime/src/lib.rs` to utilize an async backing system.\n\n1. Verify the constants for capacity ([`UNINCLUDED_SEGMENT_CAPACITY`](https://github.com/paritytech/polkadot-sdk/blob/b4b019e4db0ef47b0952638388eba4958e1c4004/templates/parachain/runtime/src/lib.rs#L229){target=\\_blank}) and velocity ([`BLOCK_PROCESSING_VELOCITY`](https://github.com/paritytech/polkadot-sdk/blob/b4b019e4db0ef47b0952638388eba4958e1c4004/templates/parachain/runtime/src/lib.rs#L232){target=\\_blank}) are both set to `1` in the runtime.\n\n    - `UNINCLUDED_SEGMENT_CAPACITY` will be increased to `3` later in this guide.\n\n2. Verify the constant relay chain slot duration measured in milliseconds is equal to `6000` in the runtime.\n\n    ```rust title=\"lib.rs\"\n    -// Maximum number of blocks simultaneously accepted by the runtime, not yet included into the\n// relay chain.\npub const UNINCLUDED_SEGMENT_CAPACITY: u32 = 1;\n// How many parachain blocks are processed by the relay chain per parent. Limits the number of\n// blocks authored per slot.\npub const BLOCK_PROCESSING_VELOCITY: u32 = 1;\n// Relay chain slot duration, in milliseconds.\npub const RELAY_chain_SLOT_DURATION_MILLIS: u32 = 6000;\n    ```\n\n3. Verify the constants [`MILLISECS_PER_BLOCK`](https://github.com/paritytech/polkadot-sdk/blob/b4b019e4db0ef47b0952638388eba4958e1c4004/templates/parachain/runtime/src/lib.rs#L189){target=\\_blank} and [`SLOT_DURATION`](https://github.com/paritytech/polkadot-sdk/blob/b4b019e4db0ef47b0952638388eba4958e1c4004/templates/parachain/runtime/src/lib.rs#L193){target=\\_blank} are present in the runtime.\n\n    - `MILLISECS_PER_BLOCK` will be decreased to `6000` later in this guide.\n\n    ```rust title=\"lib.rs\"\n    -// `SLOT_DURATION` is picked up by `pallet_timestamp` which is in turn picked\n// up by `pallet_aura` to implement `fn slot_duration()`.\n//\n// Change this to adjust the block time.\npub const MILLISECS_PER_BLOCK: u64 = 12000;\npub const SLOT_DURATION: u64 = MILLISECS_PER_BLOCK;\n    ```\n\n4. Configure [`cumulus_pallet_parachain_system`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/index.html){target=\\_blank} in the runtime using the following steps:\n\n    a. Define a [`FixedVelocityConsensusHook`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_aura_ext/consensus_hook/struct.FixedVelocityConsensusHook.html){target=\\_blank} using our capacity, velocity, and relay slot duration constants.\n\n        ```rust title=\"lib.rs\"\n        -type ConsensusHook = cumulus_pallet_aura_ext::FixedVelocityConsensusHook<\n    Runtime,\n    RELAY_CHAIN_SLOT_DURATION_MILLIS,\n    BLOCK_PROCESSING_VELOCITY,\n    UNINCLUDED_SEGMENT_CAPACITY,\n>;\n        ```\n\n    b. Use this to set the parachain system [`ConsensusHook`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/pallet/trait.Config.html#associatedtype.ConsensusHook){target=\\_blank} property.\n\n        ```rust title=\"lib.rs\"\n        -impl cumulus_pallet_parachain_system::Config for Runtime {\n    ...\n    type ConsensusHook = ConsensusHook;\n    ...\n}\n        ```\n\n    c. Set the parachain system property [`CheckAssociatedRelayNumber`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/pallet/trait.Config.html#associatedtype.CheckAssociatedRelayNumber){target=\\_blank} to [`RelayNumberMonotonicallyIncreases`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/struct.RelayNumberMonotonicallyIncreases.html){target=\\_blank}.\n\n        ```rust title=\"lib.rs\"\n        -impl cumulus_pallet_parachain_system::Config for Runtime {\n    ...\n    type CheckAssociatedRelayNumber = RelayNumberMonotonicallyIncreases;\n    ...\n}\n        ```\n\n5. Configure [`pallet_aura`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/index.html){target=\\_blank} in the runtime to implement Authority Round (Aura) as follows:\n\n    a. Set [`AllowMultipleBlocksPerSlot`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/pallet/trait.Config.html#associatedtype.AllowMultipleBlocksPerSlot){target=\\_blank} to `false`.\n\n        - This will be set to `true` when you activate async backing in phase 3.\n\n    b. Define [`pallet_aura::SlotDuration`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/pallet/trait.Config.html#associatedtype.SlotDuration){target=\\_blank} using our constant [`SLOT_DURATION`](https://github.com/polkadot-fellows/runtimes/blob/d49a9f33d0ea85ce51c26c84a70b61624ec06901/system-parachains/constants/src/lib.rs#L38-L40){target=\\_blank}.\n\n        ```rust title=\"lib.rs\"\n        -impl pallet_aura::Config for Runtime {\n    ...\n    type AllowMultipleBlocksPerSlot = ConstBool<false>;\n    #[cfg(feature = \"experimental\")]\n    type SlotDuration = ConstU64<SLOT_DURATION>;\n    ...\n}\n        ```\n\n    !!! note\n        Aura is a deterministic [consensus](/polkadot-protocol/glossary/#consensus){target=\\_blank} protocol where block production is limited to a rotating list of authorities that take turns creating blocks and [`pallet_timestamp`](https://paritytech.github.io/polkadot-sdk/master/pallet_timestamp/index.html){target=\\_blank} is used to track consensus rounds (via [`slots`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/pallet/trait.Config.html#associatedtype.SlotDuration){target=\\_blank}).\n\n\n6. Update `sp_consensus_aura::AuraApi::slot_duration` in `sp_api::impl_runtime_apis` to match the constant [`SLOT_DURATION`](https://github.com/polkadot-fellows/runtimes/blob/d49a9f33d0ea85ce51c26c84a70b61624ec06901/system-parachains/constants/src/lib.rs#L38-L40){target=\\_blank}.\n\n    ```rust title=\"apis.rs\"\n    -fn impl_slot_duration() -> sp_consensus_aura::SlotDuration {\n    sp_consensus_aura::SlotDuration::from_millis(SLOT_DURATION)\n}\n    ```\n\n7. Implement the [`AuraUnincludedSegmentApi`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_aura/trait.AuraUnincludedSegmentApi.html){target=\\_blank}, which allows the collator client to query its runtime to determine whether it should author a block using these steps:\n\n    a. Add the dependency [`cumulus-primitives-aura`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_aura/index.html){target=\\_blank} to the `runtime/Cargo.toml` file for your runtime.\n\n        ```rust title=\"Cargo.toml\"\n        -...\ncumulus-primitives-aura = { path = \"../../../../primitives/aura\", default-features = false }\n...\n        ```\n\n    b. In the same file, add `\"cumulus-primitives-aura/std\",` to the `std` feature.\n\n    c. Inside the [`impl_runtime_apis!`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/runtime/src/apis.rs#L87-L91){target=\\_blank} block for your runtime, implement the [`cumulus_primitives_aura::AuraUnincludedSegmentApi`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_aura/trait.AuraUnincludedSegmentApi.html){target=\\_blank} as shown below.\n        \n        ```rust title=\"apis.rs\"\n        -impl cumulus_primitives_aura::AuraUnincludedSegmentApi<Block> for Runtime {\n    fn can_build_upon(\n        included_hash: <Block as BlockT>::Hash,\n        slot: cumulus_primitives_aura::Slot,\n    ) -> bool {\n        Runtime::impl_can_build_upon(included_hash, slot)\n    }\n}\n        ```\n\n    !!!note\n        With a capacity of 1, you have an effective velocity of ½, even when velocity is configured to a larger value. Capacity will be filled after a single block is produced and will only be freed up after that block is included on the relay chain, which takes two relay blocks to accomplish. Thus, with a capacity of 1 and a velocity of 1, you achieve the customary 12-second parachain block time.\n\n8. If your `runtime/src/lib.rs` provides a [`CheckInherents`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/macro.register_validate_block.html){target=\\_blank} type to [`register_validate_block`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/macro.register_validate_block.html), remove it. [`FixedVelocityConsensusHook`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_aura_ext/consensus_hook/struct.FixedVelocityConsensusHook.html){target=\\_blank} makes it unnecessary. The following example shows how `register_validate_block` should look after removing `CheckInherents`.\n\n    ```rust title=\"lib.rs\"\n    -cumulus_pallet_parachain_system::register_validate_block! {\n    Runtime = Runtime,\n    BlockExecutor = cumulus_pallet_aura_ext::BlockExecutor::<Runtime, Executive>,\n}\n    ```"}
{"page_id": "develop-parachains-maintenance-configure-asynchronous-backing", "index": 3, "depth": 2, "title": "Phase 2 - Update Parachain Nodes", "anchor": "phase-2-update-parachain-nodes", "start_char": 11066, "end_char": 15488, "estimated_token_count": 1154, "token_estimator": "heuristic-v1", "text": "## Phase 2 - Update Parachain Nodes\n\nThis phase consists of plugging in the new lookahead collator node.\n\n1. Import [`cumulus_primitives_core::ValidationCode`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/relay_chain/struct.ValidationCode.html){target=\\_blank} to `node/src/service.rs`.\n\n    ```rust title=\"node/src/service.rs\"\n    -use cumulus_primitives_core::{\n    relay_chain::{CollatorPair, ValidationCode},\n    GetParachainInfo, ParaId,\n};\n    ```\n\n2. In `node/src/service.rs`, modify [`sc_service::spawn_tasks`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L340-L347){target=\\_blank} to use a clone of `Backend` rather than the original.\n\n    ```rust title=\"node/src/service.rs\"\n    -sc_service::spawn_tasks(sc_service::SpawnTasksParams {\n    ...\n    backend: backend.clone(),\n    ...\n})?;\n    ```\n\n3. Add `backend` as a parameter to [`start_consensus()`](https://paritytech.github.io/polkadot-sdk/master/parachain_template_node/service/fn.start_consensus.html){target=\\_blank} in `node/src/service.rs`.\n\n    ```rust title=\"node/src/service.rs\"\n    -fn start_consensus(\n    ...\n    backend: Arc<ParachainBackend>,\n    ...\n    ```\n\n    ```rust title=\"node/src/service.rs\"\n    -if validator {\n    start_consensus(\n        ...\n        backend.clone(),\n        ...\n    )?;\n}\n    ```\n\n4. In `node/src/service.rs` [import the lookahead collator](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L19){target=\\_blank} rather than the basic collator.\n\n    ```rust title=\"node/src/service.rs\"\n    -use cumulus_client_consensus_aura::collators::lookahead::{self as aura, Params as AuraParams};\n    ```\n\n5. In `start_consensus()` replace the `BasicAuraParams` struct with [`AuraParams`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L206){target=\\_blank} as follows:\n\n    a. Change the struct type from `BasicAuraParams` to `AuraParams`.\n\n    b. In the [`para_client`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L206-L225){target=\\_blank} field, pass in a cloned para client rather than the original.\n\n    c. Add a [`para_backend`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L206-L225){target=\\_blank} parameter after `para_client`, passing in our para backend.\n\n    d. Provide a [`code_hash_provider`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L206-L225){target=\\_blank} closure like that shown below.\n\n    e. Increase [`authoring_duration`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L206-L225){target=\\_blank} from 500 milliseconds to 2000.\n\n    ```rust title=\"node/src/service.rs\"\n    -let params = AuraParams {\n    ...\n    para_client: client.clone(),\n    para_backend: backend.clone(),\n    ...\n    code_hash_provider: move |block_hash| {\n        client.code_at(block_hash).ok().map(|c| ValidationCode::from(c).hash())\n    },\n    ...\n    authoring_duration: Duration::from_millis(2000),\n    ...\n};\n    ```\n\n    !!!note\n        Set [`authoring_duration`](https://paritytech.github.io/polkadot-sdk/master/cumulus_client_consensus_aura/collators/slot_based/struct.Params.html#structfield.authoring_duration){target=\\_blank} to whatever you want, taking your hardware into account. But if the backer, who should be slower than you due to reading from disk, times out at two seconds, your candidates will be rejected.\n\n6. In [`start_consensus()`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L173) replace `basic_aura::run` with [`aura::run`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/node/src/service.rs#L226){target=\\_blank}.\n\n    ```rust title=\"node/src/service.rs\"\n\t-let fut = aura::run::<Block, sp_consensus_aura::sr25519::AuthorityPair, _, _, _, _, _, _, _, _>(\n    params,\n);\ntask_manager.spawn_essential_handle().spawn(\"aura\", None, fut);\n    ```"}
{"page_id": "develop-parachains-maintenance-configure-asynchronous-backing", "index": 4, "depth": 2, "title": "Phase 3 - Activate Async Backing", "anchor": "phase-3-activate-async-backing", "start_char": 15488, "end_char": 19397, "estimated_token_count": 913, "token_estimator": "heuristic-v1", "text": "## Phase 3 - Activate Async Backing\n\nThis phase involves changes to your parachain's runtime that activate the asynchronous backing feature.\n\n1. Configure [`pallet_aura`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/index.html){target=\\_blank}, setting [`AllowMultipleBlocksPerSlot`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/pallet/trait.Config.html#associatedtype.AllowMultipleBlocksPerSlot){target=\\_blank} to true in `runtime/src/lib.rs`.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    -impl pallet_aura::Config for Runtime {\n    type AuthorityId = AuraId;\n    type DisabledValidators = ();\n    type MaxAuthorities = ConstU32<100_000>;\n    type AllowMultipleBlocksPerSlot = ConstBool<true>;\n    type SlotDuration = ConstU64<SLOT_DURATION>;\n}\n    ```\n\n2. Increase the maximum [`UNINCLUDED_SEGMENT_CAPACITY`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/runtime/src/lib.rs#L226-L235){target=\\_blank} in `runtime/src/lib.rs`.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    -mod async_backing_params {\n    /// Maximum number of blocks simultaneously accepted by the Runtime, not yet included\n    /// into the relay chain.\n    pub(crate) const UNINCLUDED_SEGMENT_CAPACITY: u32 = 3;\n    /// How many parachain blocks are processed by the relay chain per parent. Limits the\n    /// number of blocks authored per slot.\n    pub(crate) const BLOCK_PROCESSING_VELOCITY: u32 = 1;\n    /// Relay chain slot duration, in milliseconds.\n    pub(crate) const RELAY_CHAIN_SLOT_DURATION_MILLIS: u32 = 6000;\n}\n    ```\n\n3. Decrease [`MILLI_SECS_PER_BLOCK`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/runtime/src/lib.rs#L182-L194){target=\\_blank} to 6000.\n\n    !!!note\n        For a parachain that measures time in terms of its own block number, rather than by relay block number, it may be preferable to increase velocity. Changing block time may cause complications, requiring additional changes. See the section [Timing by Block Number](#timing-by-block-number){target=\\_blank}.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    -mod block_times {\n    /// This determines the average expected block time that we are targeting. Blocks will be\n    /// produced at a minimum duration defined by `SLOT_DURATION`. `SLOT_DURATION` is picked up by\n    /// `pallet_timestamp` which is in turn picked up by `pallet_aura` to implement `fn\n    /// slot_duration()`.\n    ///\n    /// Change this to adjust the block time.\n    pub const MILLI_SECS_PER_BLOCK: u64 = 6000;\n\n    // NOTE: Currently it is not possible to change the slot duration after the chain has started.\n    // Attempting to do so will brick block production.\n    pub const SLOT_DURATION: u64 = MILLI_SECS_PER_BLOCK;\n}\n    ```\n\n4. Update [`MAXIMUM_BLOCK_WEIGHT`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/runtime/src/lib.rs#L219-L223){target=\\_blank} to reflect the increased time available for block production.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    -const MAXIMUM_BLOCK_WEIGHT: Weight = Weight::from_parts(\n    WEIGHT_REF_TIME_PER_SECOND.saturating_mul(2),\n    cumulus_primitives_core::relay_chain::MAX_POV_SIZE as u64,\n);\n    ```\n\n5. For [`MinimumPeriod`](https://paritytech.github.io/polkadot-sdk/master/pallet_timestamp/pallet/trait.Config.html#associatedtype.MinimumPeriod) in [`pallet_timestamp`](https://paritytech.github.io/polkadot-sdk/master/pallet_timestamp/index.html){target=\\_blank} the type should be [`ConstU64<0>`](https://github.com/paritytech/polkadot-sdk/blob/6b17df5ae96f7970109ec3934c7d288f05baa23b/templates/parachain/runtime/src/configs/mod.rs#L141){target=\\_blank}.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    -impl pallet_timestamp::Config for Runtime {\n    ...\n    type MinimumPeriod = ConstU64<0>;\n    ...\n}\n    ```"}
{"page_id": "develop-parachains-maintenance-configure-asynchronous-backing", "index": 5, "depth": 2, "title": "Timing by Block Number", "anchor": "timing-by-block-number", "start_char": 19397, "end_char": 20328, "estimated_token_count": 197, "token_estimator": "heuristic-v1", "text": "## Timing by Block Number\n\nWith asynchronous backing, it will be possible for parachains to opt for a block time of 6 seconds rather than 12 seconds. However, modifying block duration isn't so simple for a parachain that measures time in terms of its own block number, which could result in the expected and actual time not matching up, stalling the parachain.\n\nOne strategy to address this issue is to rely on relay chain block numbers for timing instead. Relay block number is kept track of by each parachain in [`pallet-parachain-system`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/index.html){target=\\_blank} with the storage value [`LastRelaychainBlockNumber`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/pallet/type.LastRelayChainBlockNumber.html){target=\\_blank}. This value can be obtained and used wherever timing based on block number is needed."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 34, "end_char": 1966, "estimated_token_count": 404, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nMaintaining a stable, secure, and efficient network requires continuous monitoring. Polkadot SDK-based nodes are equipped with built-in telemetry components that automatically collect and transmit detailed data about node performance in real-time. This telemetry system is a core feature of the Substrate framework, allowing for easy monitoring of network health without complex setup.\n\n[Substrate's client telemetry](https://paritytech.github.io/polkadot-sdk/master/sc_telemetry/index.html){target=\\_blank} enables real-time data ingestion, which can be visualized on a client dashboard. The telemetry process uses tracing and logging to gather operational data. This data is sent through a tracing layer to a background task called the [`TelemetryWorker`](https://paritytech.github.io/polkadot-sdk/master/sc_telemetry/struct.TelemetryWorker.html){target=\\_blank}, which then forwards it to configured remote telemetry servers.\n\nIf multiple Substrate nodes run within the same process, the telemetry system uses a `tracing::Span` to distinguish data from each node. This ensures that each task, managed by the `sc-service`'s [`TaskManager`](https://paritytech.github.io/polkadot-sdk/master/sc_service/struct.TaskManager.html){target=\\_blank}, inherits a span for data consistency, making it easy to track parallel node operations. Each node can be monitored for basic metrics, such as block height, peer connections, CPU usage, and memory. Substrate nodes expose these metrics at the `host:9615/metrics` endpoint, accessible locally by default. To expose metrics on all interfaces, start a node with the `--prometheus-external` flag.\n\nAs a developer or node operator, the telemetry system handles most of the technical setup. Collected data is automatically sent to a default telemetry server, where it’s aggregated and displayed on a dashboard, making it easy to monitor network performance and identify issues."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 1, "depth": 2, "title": "Runtime Metrics", "anchor": "runtime-metrics", "start_char": 1966, "end_char": 3425, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "## Runtime Metrics\n\nSubstrate exposes a variety of metrics about the operation of your network, such as the number of peer connections, memory usage, and block production. To capture and visualize these metrics, you can configure and use tools like [Prometheus](https://prometheus.io/){target=\\_blank} and [Grafana](https://grafana.com/){target=\\_blank}. At a high level, Substrate exposes telemetry data that can be consumed by the Prometheus endpoint and then presented as visual information in a Grafana dashboard or graph. The provided diagram offers a simplified overview of how the interaction between Substrate, Prometheus, and Grafana can be configured to display information about node operations.\n\n```mermaid\ngraph TD\n  subNode([Substrate Node]) --> telemetryStream[Exposed Telemetry Stream]\n  telemetryStream --> prometheus[Prometheus]\n  prometheus --> endpoint[Endpoint: Every 1 minute]\n  endpoint --> grafana[Grafana]\n  grafana --> userOpen[User Opens a Graph]\n  prometheus --> localData[Local Prometheus Data]\n  localData --> getmetrics[Get Metrics]\n```\n\nThe diagram shows the flow of data from the Substrate node to the monitoring and visualization components. The Substrate node exposes a telemetry stream, which is consumed by Prometheus. Prometheus is configured to collect data every minute and store it. Grafana is then used to visualize the data, allowing the user to open graphs and retrieve specific metrics from the telemetry stream."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 2, "depth": 2, "title": "Visual Monitoring", "anchor": "visual-monitoring", "start_char": 3425, "end_char": 5381, "estimated_token_count": 459, "token_estimator": "heuristic-v1", "text": "## Visual Monitoring\n\nThe [Polkadot telemetry](https://telemetry.polkadot.io/){target=\\_blank} dashboard provides a real-time view of how currently online nodes are performing. This dashboard, allows users to select the network you need to check on, and also the information you want to display by turning visible columns on and off from the list of columns available. The monitoring dashboard provides the following indicators and metrics:\n\n- **Validator**: Identifies whether the node is a validator node or not.\n- **Location**: Displays the geographical location of the node.\n- **Implementation**: Shows the version of the software running on the node.\n- **Network ID**: Displays the public network identifier for the node.\n- **Peer count**: Indicates the number of peers connected to the node.\n- **Transactions in queue**: Shows the number of transactions waiting in the [`Ready` queue](https://paritytech.github.io/polkadot-sdk/master/sc_transaction_pool_api/enum.TransactionStatus.html#variant.Ready){target=\\_blank} for a block author.\n- **Upload bandwidth**: Graphs the node's recent upload activity in MB/s.\n- **Download bandwidth**: Graphs the node's recent download activity in MB/s.\n- **State cache size**: Graphs the size of the node's state cache in MB.\n- **Block**: Displays the current best block number to ensure synchronization with peers.\n- **Block hash**: Shows the block hash for the current best block number.\n- **Finalized block**: Displays the most recently finalized block number to ensure synchronization with peers.\n- **Finalized block hash**: Shows the block hash for the most recently finalized block.\n- **Block time**: Indicates the time between block executions.\n- **Block propagation time**: Displays the time it took to import the most recent block.\n- **Last block time**: Shows the time it took to author the most recent block.\n- **Node uptime**: Indicates the number of days the node has been online without restarting."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 3, "depth": 2, "title": "Displaying Network-Wide Statistics", "anchor": "displaying-network-wide-statistics", "start_char": 5381, "end_char": 5921, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Displaying Network-Wide Statistics\n\nIn addition to the details available for individual nodes, you can view statistics that provide insights into the broader network. The network statistics provide detailed information about the hardware and software configurations of the nodes in the network, including:\n\n- Software version\n- Operating system\n- CPU architecture and model\n- Number of physical CPU cores\n- Total memory\n- Whether the node is a virtual machine\n- Linux distribution and kernel version\n- CPU and memory speed\n- Disk speed"}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 4, "depth": 2, "title": "Customizing Monitoring Tools", "anchor": "customizing-monitoring-tools", "start_char": 5921, "end_char": 6399, "estimated_token_count": 72, "token_estimator": "heuristic-v1", "text": "## Customizing Monitoring Tools\n\nThe default telemetry dashboard offers core metrics without additional setup. However, many projects prefer custom telemetry setups with more advanced monitoring and alerting policies.\n\nTypically, setting up a custom telemetry solution involves establishing monitoring and alerting policies for both on-chain events and individual node operations. This allows for more tailored monitoring and reporting compared to the default telemetry setup."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 5, "depth": 3, "title": "On-Chain Activity", "anchor": "on-chain-activity", "start_char": 6399, "end_char": 6734, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "### On-Chain Activity\n\nYou can monitor specific on-chain events like transactions from certain addresses or changes in the validator set. Connecting to RPC nodes allows tracking for delays or specific event timings. Running your own RPC servers is recommended for reliable queries, as public RPC nodes may occasionally be unreliable."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 6, "depth": 2, "title": "Monitoring Tools", "anchor": "monitoring-tools", "start_char": 6734, "end_char": 7547, "estimated_token_count": 213, "token_estimator": "heuristic-v1", "text": "## Monitoring Tools\n\nTo implement customized monitoring and alerting, consider using the following stack:\n\n- **[Prometheus](https://prometheus.io/){target=\\_blank}**: Collects metrics at intervals, stores data in a time series database, and applies rules for evaluation.\n- **[Grafana](https://grafana.com/){target=\\_blank}**: Visualizes collected data through customizable dashboards.\n- **[Node exporter](https://github.com/prometheus/node_exporter){target=\\_blank}**: Reports host metrics, including CPU, memory, and bandwidth usage.\n- **[Alert manager](https://github.com/prometheus/alertmanager){target=\\_blank}**: Manages alerts, routing them based on defined rules.\n- **[Loki](https://github.com/grafana/loki){target=\\_blank}**: Scalable log aggregator for searching and viewing logs across infrastructure."}
{"page_id": "develop-parachains-maintenance-runtime-metrics-monitoring", "index": 7, "depth": 3, "title": "Change the Telemetry Server", "anchor": "change-the-telemetry-server", "start_char": 7547, "end_char": 8458, "estimated_token_count": 224, "token_estimator": "heuristic-v1", "text": "### Change the Telemetry Server\n\nOnce backend monitoring is configured, use the `--telemetry-url` flag when starting a node to specify telemetry endpoints and verbosity levels. Multiple telemetry URLs can be provided, and verbosity ranges from 0 (least verbose) to 9 (most verbose).\n\nFor instance, setting a custom telemetry server with verbosity level 5 would look like:\n\n```bash\n./target/release/node-template --dev \\\n  --telemetry-url \"wss://192.168.48.1:9616 5\" \\\n  --prometheus-port 9616 \\\n  --prometheus-external\n```\n\nFor more information on the backend components for telemetry or configuring your own server, you can refer to the [`substrate-telemetry`](https://github.com/paritytech/substrate-telemetry){target=\\_blank} project or the [Substrate Telemetry Helm Chart](https://github.com/paritytech/helm-charts/blob/main/charts/substrate-telemetry/README.md){target=\\_blank} for Kubernetes deployments."}
{"page_id": "develop-parachains-maintenance-runtime-upgrades", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 926, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nOne of the defining features of Polkadot SDK-based blockchains is the ability to perform forkless runtime upgrades. Unlike traditional blockchains, which require hard forks and node coordination for upgrades, Polkadot networks enable seamless updates without network disruption.\n\nForkless upgrades are achieved through WebAssembly (Wasm) runtimes stored on-chain, which can be securely swapped and upgraded as part of the blockchain's state. By leveraging decentralized consensus, runtime updates can happen trustlessly, ensuring continuous improvement and evolution without halting operations.\n\nThis guide explains how Polkadot's runtime versioning, Wasm deployment, and storage migrations enable these upgrades, ensuring the blockchain evolves smoothly and securely. You'll also learn how different upgrade processes apply to solo chains and parachains, depending on the network setup."}
{"page_id": "develop-parachains-maintenance-runtime-upgrades", "index": 1, "depth": 2, "title": "How Runtime Upgrades Work", "anchor": "how-runtime-upgrades-work", "start_char": 926, "end_char": 1650, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## How Runtime Upgrades Work\n\nIn FRAME, the [`system`](https://paritytech.github.io/polkadot-sdk/master/frame_system/index.html){target=\\_blank} pallet uses the [`set_code`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/enum.Call.html#variant.set_code){target=\\_blank} extrinsic to update the Wasm code for the runtime. This method allows solo chains to upgrade without disruption. \n\nFor parachains, upgrades are more complex. Parachains must first call `authorize_upgrade`, followed by `apply_authorized_upgrade`, to ensure the relay chain approves and applies the changes. Additionally, changes to current functionality that impact storage often require a [storage migration](#storage-migrations)."}
{"page_id": "develop-parachains-maintenance-runtime-upgrades", "index": 2, "depth": 3, "title": "Runtime Versioning", "anchor": "runtime-versioning", "start_char": 1650, "end_char": 4916, "estimated_token_count": 665, "token_estimator": "heuristic-v1", "text": "### Runtime Versioning\n\nThe executor is the component that selects the runtime execution environment to communicate with. Although you can override the default execution strategies for custom scenarios, in most cases, the executor selects the appropriate binary to use by evaluating and comparing key parameters from the native and Wasm runtime binaries.\n\nThe runtime includes a [runtime version struct](https://paritytech.github.io/polkadot-sdk/master/sp_version/struct.RuntimeVersion.html){target=\\_blank} to provide the needed parameter information to the executor process. A sample runtime version struct might look as follows:\n\n```rust\n-pub const VERSION: RuntimeVersion = RuntimeVersion {\n    spec_name: create_runtime_str!(\"node-template\"),\n    impl_name: create_runtime_str!(\"node-template\"),\n    authoring_version: 1,\n    spec_version: 1,\n    impl_version: 1,\n    apis: RUNTIME_API_VERSIONS,\n    transaction_version: 1,\n};\n```\n\nThe struct provides the following parameter information to the executor:\n\n- **`spec_name`**: The identifier for the different runtimes.\n- **`impl_name`**: The name of the implementation of the spec. Serves only to differentiate code of different implementation teams.\n- **`authoring_version`**: The version of the authorship interface. An authoring node won't attempt to author blocks unless this is equal to its native runtime.\n- **`spec_version`**: The version of the runtime specification. A full node won't attempt to use its native runtime in substitute for the on-chain Wasm runtime unless the `spec_name`, `spec_version`, and `authoring_version` are all the same between the Wasm and native binaries. Updates to the `spec_version` can be automated as a CI process. This parameter is typically incremented when there's an update to the `transaction_version`.\n- **`impl_version`**: The version of the implementation of the specification. Nodes can ignore this. It is only used to indicate that the code is different. As long as the `authoring_version` and the `spec_version` are the same, the code might have changed, but the native and Wasm binaries do the same thing. In general, only non-logic-breaking optimizations would result in a change of the `impl_version`.\n- **`transaction_version`**: The version of the interface for handling transactions. This parameter can be useful to synchronize firmware updates for hardware wallets or other signing devices to verify that runtime transactions are valid and safe to sign. This number must be incremented if there is a change in the index of the pallets in the `construct_runtime!` macro or if there are any changes to dispatchable functions, such as the number of parameters or parameter types. If `transaction_version` is updated, then the `spec_version` must also be updated.\n- **`apis`**: A list of supported [runtime APIs](https://paritytech.github.io/polkadot-sdk/master/sp_api/macro.impl_runtime_apis.html){target=\\_blank} along with their versions.\n\nThe executor follows the same consensus-driven logic for both the native runtime and the Wasm runtime before deciding which to execute. Because runtime versioning is a manual process, there is a risk that the executor could make incorrect decisions if the runtime version is misrepresented or incorrectly defined."}
{"page_id": "develop-parachains-maintenance-runtime-upgrades", "index": 3, "depth": 3, "title": "Accessing the Runtime Version", "anchor": "accessing-the-runtime-version", "start_char": 4916, "end_char": 5432, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "### Accessing the Runtime Version\n\nThe runtime version can be accessed through the `state.getRuntimeVersion` RPC endpoint, which accepts an optional block identifier. It can also be accessed through the runtime metadata to understand the APIs the runtime exposes and how to interact with them.\n\nThe runtime metadata should only change when the chain's [runtime `spec_version`](https://paritytech.github.io/polkadot-sdk/master/sp_version/struct.RuntimeVersion.html#structfield.spec_version){target=\\_blank} changes."}
{"page_id": "develop-parachains-maintenance-runtime-upgrades", "index": 4, "depth": 2, "title": "Storage Migrations", "anchor": "storage-migrations", "start_char": 5432, "end_char": 5838, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Storage Migrations\n\nSome runtime upgrades require updating how data is stored to match new formats or layouts. This process is called a Storage Migration. It ensures the runtime can interpret existing state correctly after an upgrade.\n\nFor detailed guidance, scenarios, and implementation patterns, see the [Storage Migrations](/develop/parachains/maintenance/storage-migrations/){target=\\_blank} page."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 1307, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nStorage migrations are a crucial part of the runtime upgrade process. They allow you to update the [storage items](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.storage.html){target=\\_blank} of your blockchain, adapting to changes in the runtime. Whenever you change the encoding or data types used to represent data in storage, you'll need to provide a storage migration to ensure the runtime can correctly interpret the existing stored values in the new runtime state.\n\nStorage migrations must be executed precisely during the runtime upgrade process to ensure data consistency and prevent [runtime panics](https://doc.rust-lang.org/std/macro.panic.html){target=\\_blank}. The migration code needs to run as follows:\n\n- After the new runtime is deployed.\n- Before any other code from the new runtime executes.\n- Before any [`on_initialize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_initialize){target=\\_blank} hooks run.\n- Before any transactions are processed.\n\nThis timing is critical because the new runtime expects data to be in the updated format. Any attempt to decode the old data format without proper migration could result in runtime panics or undefined behavior."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 1, "depth": 2, "title": "Storage Migration Scenarios", "anchor": "storage-migration-scenarios", "start_char": 1307, "end_char": 4261, "estimated_token_count": 639, "token_estimator": "heuristic-v1", "text": "## Storage Migration Scenarios\n\nA storage migration is necessary whenever a runtime upgrade changes the storage layout or the encoding/interpretation of existing data. Even if the underlying data type appears to still \"fit\" the new storage representation, a migration may be required if the interpretation of the stored values has changed.\n\nStorage migrations ensure data consistency and prevent corruption during runtime upgrades. Below are common scenarios categorized by their impact on storage and migration requirements:\n\n- Migration required:\n    - Reordering or mutating fields of an existing data type to change the encoded/decoded data representation.\n    - Removal of a pallet or storage item warrants cleaning up storage via a migration to avoid state bloat.\n\n- Migration not required:\n    - Adding a new storage item would not require any migration since no existing data needs transformation.\n    - Adding or removing an extrinsic introduces no new interpretation of preexisting data, so no migration is required.\n\nThe following are some common scenarios where a storage migration is needed:\n\n- **Changing data types**: Changing the underlying data type requires a migration to convert the existing values.\n\n    ```rust\n    -#[pallet::storage]\npub type FooValue = StorageValue<_, Foo>;\n// old\npub struct Foo(u32)\n// new\npub struct Foo(u64)\n    ```\n\n- **Changing data representation**: Modifying the representation of the stored data, even if the size appears unchanged, requires a migration to ensure the runtime can correctly interpret the existing values.\n\n    ```rust\n    -#[pallet::storage]\npub type FooValue = StorageValue<_, Foo>;\n// old\npub struct Foo(u32)\n// new\npub struct Foo(i32)\n// or\npub struct Foo(u16, u16)\n    ```\n\n- **Extending an enum**: Adding new variants to an enum requires a migration if you reorder existing variants, insert new variants between existing ones, or change the data type of existing variants. No migration is required when adding new variants at the end of the enum.\n\n    ```rust\n    -#[pallet::storage]\npub type FooValue = StorageValue<_, Foo>;\n// old\npub enum Foo { A(u32), B(u32) }\n// new (New variant added at the end. No migration required)\npub enum Foo { A(u32), B(u32), C(u128) }\n// new (Reordered variants. Requires migration)\npub enum Foo { A(u32), C(u128), B(u32) }\n    ```\n\n- **Changing the storage key**: Modifying the storage key, even if the underlying data type remains the same, requires a migration to ensure the runtime can locate the correct stored values.\n\n    ```rust\n    -#[pallet::storage]\npub type FooValue = StorageValue<_, u32>;\n// new\n#[pallet::storage]\npub type BarValue = StorageValue<_, u32>;\n    ```\n\n!!!warning\n    In general, any change to the storage layout or data encoding used in your runtime requires careful consideration of the need for a storage migration. Overlooking a necessary migration can lead to undefined behavior or data loss during a runtime upgrade."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 2, "depth": 2, "title": "Implement Storage Migrations", "anchor": "implement-storage-migrations", "start_char": 4261, "end_char": 4888, "estimated_token_count": 156, "token_estimator": "heuristic-v1", "text": "## Implement Storage Migrations\n\nThe [`OnRuntimeUpgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.OnRuntimeUpgrade.html){target=\\_blank} trait provides the foundation for implementing storage migrations in your runtime. Here's a detailed look at its essential functions:\n\n```rust\n-pub trait OnRuntimeUpgrade {\n    fn on_runtime_upgrade() -> Weight { ... }\n    fn try_on_runtime_upgrade(checks: bool) -> Result<Weight, TryRuntimeError> { ... }\n    fn pre_upgrade() -> Result<Vec<u8>, TryRuntimeError> { ... }\n    fn post_upgrade(_state: Vec<u8>) -> Result<(), TryRuntimeError> { ... }\n}\n```"}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 3, "depth": 3, "title": "Core Migration Function", "anchor": "core-migration-function", "start_char": 4888, "end_char": 5920, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Core Migration Function\n\nThe [`on_runtime_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_runtime_upgrade){target=\\_blank} function executes when the FRAME Executive pallet detects a runtime upgrade. Important considerations when using this function include:\n\n- It runs before any pallet's `on_initialize` hooks.\n- Critical storage items (like [`block_number`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.block_number){target=\\_blank}) may not be set.\n- Execution is mandatory and must be completed.\n- Careful weight calculation is required to prevent bricking the chain.\n\nWhen implementing the migration logic, your code must handle several vital responsibilities. A migration implementation must do the following to operate correctly:\n\n- Read existing storage values in their original format.\n- Transform data to match the new format.\n- Write updated values back to storage.\n- Calculate and return consumed weight."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 4, "depth": 3, "title": "Migration Testing Hooks", "anchor": "migration-testing-hooks", "start_char": 5920, "end_char": 7936, "estimated_token_count": 399, "token_estimator": "heuristic-v1", "text": "### Migration Testing Hooks\n\nThe `OnRuntimeUpgrade` trait provides some functions designed specifically for testing migrations. These functions never execute on-chain but are essential for validating migration behavior in test environments. The migration test hooks are as follows:\n\n- **[`try_on_runtime_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.OnRuntimeUpgrade.html#method.try_on_runtime_upgrade){target=\\_blank}**: This function serves as the primary orchestrator for testing the complete migration process. It coordinates the execution flow from `pre-upgrade` checks through the actual migration to `post-upgrade` verification. Handling the entire migration sequence ensures that storage modifications occur correctly and in the proper order. Preserving this sequence is particularly valuable when testing multiple dependent migrations, where the execution order matters.\n\n- **[`pre_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.pre_upgrade){target=\\_blank}**: Before a runtime upgrade begins, the `pre_upgrade` function performs preliminary checks and captures the current state. It returns encoded state data that can be used for `post-upgrade` verification. This function must never modify storage: it should only read and verify the existing state. The data it returns includes critical state values that should remain consistent or transform predictably during migration.\n\n- **[`post_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.post_upgrade){target=\\_blank}**: After the migration completes, `post_upgrade` validates its success. It receives the state data captured by `pre_upgrade` to verify that the migration was executed correctly. This function checks for storage consistency and ensures all data transformations are completed as expected. Like `pre_upgrade`, it operates exclusively in testing environments and should not modify storage."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 5, "depth": 3, "title": "Migration Structure", "anchor": "migration-structure", "start_char": 7936, "end_char": 14365, "estimated_token_count": 1640, "token_estimator": "heuristic-v1", "text": "### Migration Structure\n\nThere are two approaches to implementing storage migrations. The first method involves directly implementing `OnRuntimeUpgrade` on structs. This approach requires manually checking the on-chain storage version against the new [`StorageVersion`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/struct.StorageVersion.html){target=\\_blank} and executing the transformation logic only when the check passes. This version verification prevents multiple executions of the migration during subsequent runtime upgrades.\n\nThe recommended approach is to implement [`UncheckedOnRuntimeUpgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.UncheckedOnRuntimeUpgrade.html){target=\\_blank} and wrap it with [`VersionedMigration`](https://paritytech.github.io/polkadot-sdk/master/frame_support/migrations/struct.VersionedMigration.html){target=\\_blank}. `VersionedMigration` implements `OnRuntimeUpgrade` and handles storage version management automatically, following best practices and reducing potential errors.\n\n`VersionedMigration` requires five type parameters:\n\n- **`From`**: The source version for the upgrade.\n- **`To`**: The target version for the upgrade.\n- **`Inner`**: The `UncheckedOnRuntimeUpgrade` implementation.\n- **`Pallet`**: The pallet being upgraded.\n- **`Weight`**: The runtime's [`RuntimeDbWeight`](https://paritytech.github.io/polkadot-sdk/master/frame_support/weights/struct.RuntimeDbWeight.html){target=\\_blank} implementation.\n\nExamine the following migration example that transforms a simple `StorageValue` storing a `u32` into a more complex structure that tracks both current and previous values using the `CurrentAndPreviousValue` struct:\n\n- Old `StorageValue` format:\n\n    ```rust\n    #[pallet::storage]\n    pub type Value<T: Config> = StorageValue<_, u32>;\n    ```\n\n- New `StorageValue` format:\n\n    ```rust\n    -/// Example struct holding the most recently set [`u32`] and the\n/// second most recently set [`u32`] (if one existed).\n#[docify::export]\n#[derive(\n\tClone, Eq, PartialEq, Encode, Decode, RuntimeDebug, scale_info::TypeInfo, MaxEncodedLen,\n)]\npub struct CurrentAndPreviousValue {\n\t/// The most recently set value.\n\tpub current: u32,\n\t/// The previous value, if one existed.\n\tpub previous: Option<u32>,\n}\n\n    -#[pallet::storage]\n\tpub type Value<T: Config> = StorageValue<_, CurrentAndPreviousValue>;\n    ```\n\n- Migration:\n\n    ```rust\n    -use frame_support::{\n\tstorage_alias,\n\ttraits::{Get, UncheckedOnRuntimeUpgrade},\n};\n\n#[cfg(feature = \"try-runtime\")]\nuse alloc::vec::Vec;\n\n/// Collection of storage item formats from the previous storage version.\n///\n/// Required so we can read values in the v0 storage format during the migration.\nmod v0 {\n\tuse super::*;\n\n\t/// V0 type for [`crate::Value`].\n\t#[storage_alias]\n\tpub type Value<T: crate::Config> = StorageValue<crate::Pallet<T>, u32>;\n}\n\n/// Implements [`UncheckedOnRuntimeUpgrade`], migrating the state of this pallet from V0 to V1.\n///\n/// In V0 of the template [`crate::Value`] is just a `u32`. In V1, it has been upgraded to\n/// contain the struct [`crate::CurrentAndPreviousValue`].\n///\n/// In this migration, update the on-chain storage for the pallet to reflect the new storage\n/// layout.\npub struct InnerMigrateV0ToV1<T: crate::Config>(core::marker::PhantomData<T>);\n\nimpl<T: crate::Config> UncheckedOnRuntimeUpgrade for InnerMigrateV0ToV1<T> {\n\t/// Return the existing [`crate::Value`] so we can check that it was correctly set in\n\t/// `InnerMigrateV0ToV1::post_upgrade`.\n\t#[cfg(feature = \"try-runtime\")]\n\tfn pre_upgrade() -> Result<Vec<u8>, sp_runtime::TryRuntimeError> {\n\t\tuse codec::Encode;\n\n\t\t// Access the old value using the `storage_alias` type\n\t\tlet old_value = v0::Value::<T>::get();\n\t\t// Return it as an encoded `Vec<u8>`\n\t\tOk(old_value.encode())\n\t}\n\n\t/// Migrate the storage from V0 to V1.\n\t///\n\t/// - If the value doesn't exist, there is nothing to do.\n\t/// - If the value exists, it is read and then written back to storage inside a\n\t/// [`crate::CurrentAndPreviousValue`].\n\tfn on_runtime_upgrade() -> frame_support::weights::Weight {\n\t\t// Read the old value from storage\n\t\tif let Some(old_value) = v0::Value::<T>::take() {\n\t\t\t// Write the new value to storage\n\t\t\tlet new = crate::CurrentAndPreviousValue { current: old_value, previous: None };\n\t\t\tcrate::Value::<T>::put(new);\n\t\t\t// One read + write for taking the old value, and one write for setting the new value\n\t\t\tT::DbWeight::get().reads_writes(1, 2)\n\t\t} else {\n\t\t\t// No writes since there was no old value, just one read for checking\n\t\t\tT::DbWeight::get().reads(1)\n\t\t}\n\t}\n\n\t/// Verifies the storage was migrated correctly.\n\t///\n\t/// - If there was no old value, the new value should not be set.\n\t/// - If there was an old value, the new value should be a [`crate::CurrentAndPreviousValue`].\n\t#[cfg(feature = \"try-runtime\")]\n\tfn post_upgrade(state: Vec<u8>) -> Result<(), sp_runtime::TryRuntimeError> {\n\t\tuse codec::Decode;\n\t\tuse frame_support::ensure;\n\n\t\tlet maybe_old_value = Option::<u32>::decode(&mut &state[..]).map_err(|_| {\n\t\t\tsp_runtime::TryRuntimeError::Other(\"Failed to decode old value from storage\")\n\t\t})?;\n\n\t\tmatch maybe_old_value {\n\t\t\tSome(old_value) => {\n\t\t\t\tlet expected_new_value =\n\t\t\t\t\tcrate::CurrentAndPreviousValue { current: old_value, previous: None };\n\t\t\t\tlet actual_new_value = crate::Value::<T>::get();\n\n\t\t\t\tensure!(actual_new_value.is_some(), \"New value not set\");\n\t\t\t\tensure!(\n\t\t\t\t\tactual_new_value == Some(expected_new_value),\n\t\t\t\t\t\"New value not set correctly\"\n\t\t\t\t);\n\t\t\t},\n\t\t\tNone => {\n\t\t\t\tensure!(crate::Value::<T>::get().is_none(), \"New value unexpectedly set\");\n\t\t\t},\n\t\t};\n\t\tOk(())\n\t}\n}\n\n/// [`UncheckedOnRuntimeUpgrade`] implementation [`InnerMigrateV0ToV1`] wrapped in a\n/// [`VersionedMigration`](frame_support::migrations::VersionedMigration), which ensures that:\n/// - The migration only runs once when the on-chain storage version is 0\n/// - The on-chain storage version is updated to `1` after the migration executes\n/// - Reads/Writes from checking/settings the on-chain storage version are accounted for\npub type MigrateV0ToV1<T> = frame_support::migrations::VersionedMigration<\n\t0, // The migration will only execute when the on-chain storage version is 0\n\t1, // The on-chain storage version will be set to 1 after the migration is complete\n\tInnerMigrateV0ToV1<T>,\n\tcrate::pallet::Pallet<T>,\n\t<T as frame_system::Config>::DbWeight,\n>;\n    ```"}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 6, "depth": 3, "title": "Migration Organization", "anchor": "migration-organization", "start_char": 14365, "end_char": 15057, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "### Migration Organization\n\nBest practices recommend organizing migrations in a separate module within your pallet. Here's the recommended file structure:\n\n```plain\nmy-pallet/\n├── src/\n│   ├── lib.rs       # Main pallet implementation\n│   └── migrations/  # All migration-related code\n│       ├── mod.rs   # Migrations module definition\n│       ├── v1.rs    # V0 -> V1 migration\n│       └── v2.rs    # V1 -> V2 migration\n└── Cargo.toml\n```\n\nThis structure provides several benefits:\n\n- Separates migration logic from core pallet functionality.\n- Makes migrations easier to test and maintain.\n- Provides explicit versioning of storage changes.\n- Simplifies the addition of future migrations."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 7, "depth": 3, "title": "Scheduling Migrations", "anchor": "scheduling-migrations", "start_char": 15057, "end_char": 15633, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "### Scheduling Migrations\n\nTo execute migrations during a runtime upgrade, you must configure them in your runtime's Executive pallet. Add your migrations in `runtime/src/lib.rs`:\n\n```rust\n-/// Tuple of migrations (structs that implement `OnRuntimeUpgrade`)\ntype Migrations = (\n    pallet_my_pallet::migrations::v1::Migration,\n    // More migrations can be added here\n);\npub type Executive = frame_executive::Executive<\n    Runtime,\n    Block,\n    frame_system::ChainContext<Runtime>,\n    Runtime,\n    AllPalletsWithSystem,\n    Migrations, // Include migrations here\n>;\n\n```"}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 8, "depth": 2, "title": "Single-Block Migrations", "anchor": "single-block-migrations", "start_char": 15633, "end_char": 16721, "estimated_token_count": 196, "token_estimator": "heuristic-v1", "text": "## Single-Block Migrations\n\nSingle-block migrations execute their logic within one block immediately following a runtime upgrade. They run as part of the runtime upgrade process through the `OnRuntimeUpgrade` trait implementation and must be completed before any other runtime logic executes.\n\nWhile single-block migrations are straightforward to implement and provide immediate data transformation, they carry significant risks. The most critical consideration is that they must complete within one block's weight limits. This is especially crucial for parachains, where exceeding block weight limits will brick the chain.\n\nUse single-block migrations only when you can guarantee:\n\n- The migration has a bounded execution time.\n- Weight calculations are thoroughly tested.\n- Total weight will never exceed block limits.\n\nFor a complete implementation example of a single-block migration, refer to the [single-block migration example]( https://paritytech.github.io/polkadot-sdk/master/pallet_example_single_block_migrations/index.html){target=\\_blank} in the Polkadot SDK documentation."}
{"page_id": "develop-parachains-maintenance-storage-migrations", "index": 9, "depth": 2, "title": "Multi Block Migrations", "anchor": "multi-block-migrations", "start_char": 16721, "end_char": 18000, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Multi Block Migrations\n\nMulti-block migrations distribute the migration workload across multiple blocks, providing a safer approach for production environments. The migration state is tracked in storage, allowing the process to pause and resume across blocks.\n\nThis approach is essential for production networks and parachains as the risk of exceeding block weight limits is eliminated. Multi-block migrations can safely handle large storage collections, unbounded data structures, and complex nested data types where weight consumption might be unpredictable.\n\nMulti-block migrations are ideal when dealing with:\n\n- Large-scale storage migrations.\n- Unbounded storage items or collections.\n- Complex data structures with uncertain weight costs.\n\nThe primary trade-off is increased implementation complexity, as you must manage the migration state and handle partial completion scenarios. However, multi-block migrations' significant safety benefits and operational reliability are typically worth the increased complexity.\n\nFor a complete implementation example of multi-block migrations, refer to the [official example](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/examples/multi-block-migrations){target=\\_blank} in the Polkadot SDK."}
{"page_id": "develop-parachains-maintenance-unlock-parachain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 1071, "estimated_token_count": 182, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nParachain locks are a critical security mechanism in the Polkadot ecosystem designed to maintain decentralization during the parachain lifecycle. These locks prevent potential centralization risks that could emerge during the early stages of parachain operation.\n\nThe locking system follows strict, well-defined conditions that distribute control across multiple authorities:\n\n- Relay chain governance has the authority to lock any parachain.\n- A parachain can lock its own lock.\n- Parachain managers have permission to lock the parachain.\n- Parachains are locked automatically when they successfully produce their first block.\n\nSimilarly, unlocking a parachain follows controlled procedures:\n\n- Relay chain governance retains the authority to unlock any parachain.\n- A parachain can unlock its own lock.\n\nThis document guides you through checking a parachain's lock status and safely executing the unlock procedure from a parachain using [XCM (Cross-Consensus Messaging)](/develop/interoperability/intro-to-xcm/){target=\\_blank}."}
{"page_id": "develop-parachains-maintenance-unlock-parachain", "index": 1, "depth": 2, "title": "Check If the Parachain Is Locked", "anchor": "check-if-the-parachain-is-locked", "start_char": 1071, "end_char": 2100, "estimated_token_count": 262, "token_estimator": "heuristic-v1", "text": "## Check If the Parachain Is Locked\n\nBefore unlocking a parachain, you should verify its current lock status. This can be done through the Polkadot.js interface:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the relay chain, navigate to the **Developer** dropdown and select the **Chain State** option.\n\n2. Query the parachain locked status:\n    1. Select **`registrar`**.\n    2. Choose the **`paras`** option.\n    3. Input the parachain ID you want to check as a parameter (e.g. `2006`).\n    4. Click the **+** button to execute the query.\n    5. Check the status of the parachain lock.\n        - **`manager`**: The account that has placed a deposit for registering this parachain.\n        - **`deposit`**: The amount reserved by the `manager` account for the registration.\n        - **`locked`**: Whether the parachain registration should be locked from being controlled by the manager.\n\n    ![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-1.webp)"}
{"page_id": "develop-parachains-maintenance-unlock-parachain", "index": 2, "depth": 2, "title": "How to Unlock a Parachain", "anchor": "how-to-unlock-a-parachain", "start_char": 2100, "end_char": 2755, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## How to Unlock a Parachain\n\nUnlocking a parachain requires sending an XCM (Cross-Consensus Message) to the relay chain from the parachain itself, sending a message with Root origin, or this can be accomplished through the relay chain's governance mechanism, executing a root call.\n\nIf sending an XCM, the parachain origin must have proper authorization, typically from either the parachain's sudo pallet (if enabled) or its governance system.\n\nThis guide demonstrates the unlocking process using a parachain with the sudo pallet. For parachains using governance-based authorization instead, the process will require adjustments to how the XCM is sent."}
{"page_id": "develop-parachains-maintenance-unlock-parachain", "index": 3, "depth": 3, "title": "Prepare the Unlock Call", "anchor": "prepare-the-unlock-call", "start_char": 2755, "end_char": 4169, "estimated_token_count": 341, "token_estimator": "heuristic-v1", "text": "### Prepare the Unlock Call\n\nBefore sending the XCM, you need to construct the relay chain call that will be executed. Follow these steps to prepare the `registrar.removeLock` extrinsic:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n2. Build the `registrar.removeLock` extrinsic:\n\n    1. Select the **registrar** pallet.\n    2. Choose the **removeLock** extrinsic.\n    3. Fill in the parachain ID parameter (e.g., `2006`).\n    4. Copy the **encoded call data**.\n\n    ![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-2.webp)\n\n    To ensure your encoded call data is correct, check this [example](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fdot-rpc.stakeworld.io#/extrinsics/decode/0x4604d6070000){target=\\_blank} of a decoded `removeLock` call for parachain 2006. Your encoded data should follow the same pattern.\n\n3. Determine the transaction weight required for executing the call. You can estimate this by executing the `transactionPaymentCallApi.queryCallInfo` runtime call with the encoded call data previously obtained:\n\n    ![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-3.webp)\n\n    This weight information is crucial for properly configuring your XCM message's execution parameters in the next steps."}
{"page_id": "develop-parachains-maintenance-unlock-parachain", "index": 4, "depth": 3, "title": "Fund the Sovereign Account", "anchor": "fund-the-sovereign-account", "start_char": 4169, "end_char": 6045, "estimated_token_count": 414, "token_estimator": "heuristic-v1", "text": "### Fund the Sovereign Account\n\nFor a successful XCM execution, the [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=\\_blank} of your parachain on the relay chain must have sufficient funds to cover transaction fees. The sovereign account is a deterministic address derived from your parachain ID.\n\nYou can identify your parachain's sovereign account using either of these methods:\n\n=== \"Runtime API\"\n\n    Execute the `locationToAccountApi.convertLocation` runtime API call to convert your parachain's location into its sovereign account address on the relay chain.\n\n    ![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-7.webp)\n\n=== \"Substrate Utilities\"\n\n    Use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=\\_blank} with the **Child** option selected.\n\n=== \"Manual Calculation\"\n\n    1. Identify the appropriate prefix:\n\n        - For parent/child chains use the prefix `0x70617261` (which decodes to `b\"para\"`).\n         \n    2. Encode your parachain ID as a u32 [SCALE](/polkadot-protocol/parachain-basics/data-encoding#data-types){target=\\_blank} value:\n\n        - For parachain 2006, this would be `d6070000`.\n\n    3. Combine the prefix with the encoded ID to form the sovereign account address:\n\n        - **Hex**: `0x70617261d6070000000000000000000000000000000000000000000000000000`\n        - **SS58 format**: `5Ec4AhPW97z4ZyYkd3mYkJrSeZWcwVv4wiANES2QrJi1x17F`\n\nYou can transfer funds to this account from any account on the relay chain using a standard transfer. To calculate the amount needed, refer to the [XCM Payment API](/develop/interoperability/xcm-runtime-apis/#xcm-payment-api){target=\\_blank}. The calculation will depend on the XCM built in the next step."}
{"page_id": "develop-parachains-maintenance-unlock-parachain", "index": 5, "depth": 3, "title": "Craft and Submit the XCM", "anchor": "craft-and-submit-the-xcm", "start_char": 6045, "end_char": 9223, "estimated_token_count": 710, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM\n\nWith the call data prepared and the sovereign account funded, you can now construct and send the XCM from your parachain to the relay chain. The XCM will need to perform several operations in sequence:\n\n1. Withdraw DOT from your parachain's sovereign account.\n2. Buy execution to pay for transaction fees.\n3. Execute the `registrar.removeLock` extrinsic.\n4. Return any unused funds to your sovereign account.\n\nHere's how to submit this XCM using Astar (Parachain 2006) as an example:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the parachain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n2. Create a `sudo.sudo` extrinsic that executes `polkadotXcm.send`:\n\n    1. Use the `sudo.sudo` extrinsic to execute the following call as Root.\n    2. Select the **polkadotXcm** pallet.\n    3. Choose the **send** extrinsic.\n    4. Set the **dest** parameter as the relay chain.\n\n    ![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-4.webp)\n\n3. Construct the XCM and submit it:\n\n    1. Add a **WithdrawAsset** instruction.\n    2. Add a **BuyExecution** instruction.\n        - **fees**:\n            - **id**: The asset location to use for the fee payment. In this example, the relay chain native asset is used.\n            - **fun**: Select `Fungible` and use the same amount you withdrew from the sovereign account in the previous step.\n        - **weightLimit**: Use `Unlimited`.\n    3. Add a **Transact** instruction with the following parameters:\n        - **originKind**: Use `Native`.\n        - **requireWeightAtMost**: Use the weight calculated previously.\n        - **call**: Use the encoded call data generated before.\n    4. Add a **RefundSurplus** instruction.\n    5. Add a **DepositAsset** instruction to send the remaining funds to the parachain sovereign account.\n    6. Click the **Submit Transaction** button.\n\n    ![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-5.webp)\n\n    If the amount withdrawn in the first instruction is exactly the amount needed to pay the transaction fees, instructions 4 and 5 can be omitted.\n\n    To validate your XCM, examine the following reference [extrinsic](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fastar.public.curie.radiumblock.co%2Fws#/extrinsics/decode/0x63003300040100041400040000000700e40b5402130000000700e40b540200060042d3c91800184604d6070000140d0100000100591f){target=_blank} showing the proper instruction sequence and parameter formatting. Following this structure will help ensure successful execution of your message.\n\nAfter submitting the transaction, wait for it to be finalized and then verify that your parachain has been successfully unlocked by following the steps described in the [Check if the Parachain is Locked](#check-if-the-parachain-is-locked) section. If the parachain shows as unlocked, your operation has been successful. If it still appears locked, verify that your XCM transaction was processed correctly and consider troubleshooting the XCM built.\n\n![](/images/develop/parachains/maintenance/unlock-parachain/unlock-parachain-6.webp)"}
{"page_id": "develop-parachains-testing-benchmarking", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 1221, "estimated_token_count": 239, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBenchmarking is a critical component of developing efficient and secure blockchain runtimes. In the Polkadot ecosystem, accurately benchmarking your custom pallets ensures that each extrinsic has a precise [weight](/polkadot-protocol/glossary/#weight){target=\\_blank}, representing its computational and storage demands. This process is vital for maintaining the blockchain's performance and preventing potential vulnerabilities, such as Denial of Service (DoS) attacks.\n\nThe Polkadot SDK leverages the [FRAME](/polkadot-protocol/glossary/#frame-framework-for-runtime-aggregation-of-modularized-entities){target=\\_blank} benchmarking framework, offering tools to measure and assign weights to extrinsics. These weights help determine the maximum number of transactions or system-level calls processed within a block. This guide covers how to use FRAME's [benchmarking framework](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/index.html){target=\\_blank}, from setting up your environment to writing and running benchmarks for your custom pallets. You'll understand how to generate accurate weights by the end, ensuring your runtime remains performant and secure."}
{"page_id": "develop-parachains-testing-benchmarking", "index": 1, "depth": 2, "title": "The Case for Benchmarking", "anchor": "the-case-for-benchmarking", "start_char": 1221, "end_char": 2015, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "## The Case for Benchmarking\n\nBenchmarking helps validate that the required execution time for different functions is within reasonable boundaries to ensure your blockchain runtime can handle transactions efficiently and securely. By accurately measuring the weight of each extrinsic, you can prevent service interruptions caused by computationally intensive calls that exceed block time limits. Without benchmarking, runtime performance could be vulnerable to DoS attacks, where malicious users exploit functions with unoptimized weights.\n\nBenchmarking also ensures predictable transaction fees. Weights derived from benchmark tests accurately reflect the resource usage of function calls, allowing fair fee calculation. This approach discourages abuse while maintaining network reliability."}
{"page_id": "develop-parachains-testing-benchmarking", "index": 2, "depth": 3, "title": "Benchmarking and Weight", "anchor": "benchmarking-and-weight", "start_char": 2015, "end_char": 3682, "estimated_token_count": 322, "token_estimator": "heuristic-v1", "text": "### Benchmarking and Weight \n\nIn Polkadot SDK-based chains, weight quantifies the computational effort needed to process transactions. This weight includes factors such as:\n\n- Computational complexity.\n- Storage complexity (proof size).\n- Database reads and writes.\n- Hardware specifications.\n\nBenchmarking uses real-world testing to simulate worst-case scenarios for extrinsics. The framework generates a linear model for weight calculation by running multiple iterations with varied parameters. These worst-case weights ensure blocks remain within execution limits, enabling the runtime to maintain throughput under varying loads. Excess fees can be refunded if a call uses fewer resources than expected, offering users a fair cost model.\n  \nBecause weight is a generic unit of measurement based on computation time for a specific physical machine, the weight of any function can change based on the specifications of hardware used for benchmarking. By modeling the expected weight of each runtime function, the blockchain can calculate the number of transactions or system-level calls it can execute within a certain period.\n\nWithin FRAME, each function call that is dispatched must have a `#[pallet::weight]` annotation that can return the expected weight for the worst-case scenario execution of that function given its inputs:\n\n```rust hl_lines=\"2\"\n-#[pallet::call_index(0)]\n#[pallet::weight(T::WeightInfo::do_something())]\npub fn do_something(origin: OriginFor<T>) -> DispatchResultWithPostInfo { Ok(()) }\n```\n\nThe `WeightInfo` file is automatically generated during benchmarking. Based on these tests, this file provides accurate weights for each extrinsic."}
{"page_id": "develop-parachains-testing-benchmarking", "index": 3, "depth": 2, "title": "Benchmarking Process", "anchor": "benchmarking-process", "start_char": 3682, "end_char": 4225, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Benchmarking Process\n\nBenchmarking a pallet involves the following steps: \n\n1. Creating a `benchmarking.rs` file within your pallet's structure.\n2. Writing a benchmarking test for each extrinsic.\n3. Executing the benchmarking tool to calculate weights based on performance metrics.\n\nThe benchmarking tool runs multiple iterations to model worst-case execution times and determine the appropriate weight. By default, the benchmarking pipeline is deactivated. To activate it, compile your runtime with the `runtime-benchmarks` feature flag."}
{"page_id": "develop-parachains-testing-benchmarking", "index": 4, "depth": 3, "title": "Prepare Your Environment", "anchor": "prepare-your-environment", "start_char": 4225, "end_char": 5516, "estimated_token_count": 363, "token_estimator": "heuristic-v1", "text": "### Prepare Your Environment\n\nInstall the [`frame-omni-bencher`](https://crates.io/crates/frame-omni-bencher){target=\\_blank} command-line tool:\n\n```bash\ncargo install frame-omni-bencher\n```\n\nBefore writing benchmark tests, you need to ensure the `frame-benchmarking` crate is included in your pallet's `Cargo.toml` similar to the following:\n\n```toml title=\"Cargo.toml\"\n-frame-benchmarking = { version = \"37.0.0\", default-features = false }\nruntime-benchmarks = [\n  \"frame-benchmarking/runtime-benchmarks\",\n  \"frame-support/runtime-benchmarks\",\n  \"frame-system/runtime-benchmarks\",\n  \"sp-runtime/runtime-benchmarks\",\n]\nstd = [\n  # ...\n  \"frame-benchmarking?/std\",\n  # ...\n]\n\n```\n\nYou must also ensure that you add the `runtime-benchmarks` feature flag as follows under the `[features]` section of your pallet's `Cargo.toml`:\n\n```toml title=\"Cargo.toml\"\n-runtime-benchmarks = [\n  \"frame-benchmarking/runtime-benchmarks\",\n  \"frame-support/runtime-benchmarks\",\n  \"frame-system/runtime-benchmarks\",\n  \"sp-runtime/runtime-benchmarks\",\n]\n```\n\nLastly, ensure that `frame-benchmarking` is included in `std = []`: \n\n```toml title=\"Cargo.toml\"\n-std = [\n  # ...\n  \"frame-benchmarking?/std\",\n  # ...\n]\n```\n\nOnce complete, you have the required dependencies for writing benchmark tests for your pallet."}
{"page_id": "develop-parachains-testing-benchmarking", "index": 5, "depth": 3, "title": "Write Benchmark Tests", "anchor": "write-benchmark-tests", "start_char": 5516, "end_char": 7973, "estimated_token_count": 646, "token_estimator": "heuristic-v1", "text": "### Write Benchmark Tests\n\nCreate a `benchmarking.rs` file in your pallet's `src/`. Your directory structure should look similar to the following:\n\n```\nmy-pallet/\n├── src/\n│   ├── lib.rs          # Main pallet implementation\n│   └── benchmarking.rs # Benchmarking\n└── Cargo.toml\n```\n\nWith the directory structure set, you can use the [`polkadot-sdk-parachain-template`](https://github.com/paritytech/polkadot-sdk-parachain-template/tree/master/pallets){target=\\_blank} to get started as follows:\n\n```rust title=\"benchmarking.rs (starter template)\"\n-//! Benchmarking setup for pallet-template\n#![cfg(feature = \"runtime-benchmarks\")]\n\nuse super::*;\nuse frame_benchmarking::v2::*;\n\n#[benchmarks]\nmod benchmarks {\n\tuse super::*;\n\t#[cfg(test)]\n\tuse crate::pallet::Pallet as Template;\n\tuse frame_system::RawOrigin;\n\n\t#[benchmark]\n\tfn do_something() {\n\t\tlet caller: T::AccountId = whitelisted_caller();\n\t\t#[extrinsic_call]\n\t\tdo_something(RawOrigin::Signed(caller), 100);\n\n\t\tassert_eq!(Something::<T>::get().map(|v| v.block_number), Some(100u32.into()));\n\t}\n\n\t#[benchmark]\n\tfn cause_error() {\n\t\tSomething::<T>::put(CompositeStruct { block_number: 100u32.into() });\n\t\tlet caller: T::AccountId = whitelisted_caller();\n\t\t#[extrinsic_call]\n\t\tcause_error(RawOrigin::Signed(caller));\n\n\t\tassert_eq!(Something::<T>::get().map(|v| v.block_number), Some(101u32.into()));\n\t}\n\n\timpl_benchmark_test_suite!(Template, crate::mock::new_test_ext(), crate::mock::Test);\n}\n```\n\nIn your benchmarking tests, employ these best practices:\n\n- **Write custom testing functions**: The function `do_something` in the preceding example is a placeholder. Similar to writing unit tests, you must write custom functions to benchmark test your extrinsics. Access the mock runtime and use functions such as `whitelisted_caller()` to sign transactions and facilitate testing.\n- **Use the `#[extrinsic_call]` macro**: This macro is used when calling the extrinsic itself and is a required part of a benchmarking function. See the [`extrinsic_call`](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/index.html#extrinsic_call-and-block){target=\\_blank} docs for more details.\n- **Validate extrinsic behavior**: The `assert_eq` expression ensures that the extrinsic is working properly within the benchmark context.\n\nAdd the `benchmarking` module to your pallet. In the pallet `lib.rs` file add the following:\n\n```rust\n#[cfg(feature = \"runtime-benchmarks\")]\nmod benchmarking;\n```"}
{"page_id": "develop-parachains-testing-benchmarking", "index": 6, "depth": 3, "title": "Add Benchmarks to Runtime", "anchor": "add-benchmarks-to-runtime", "start_char": 7973, "end_char": 10370, "estimated_token_count": 468, "token_estimator": "heuristic-v1", "text": "### Add Benchmarks to Runtime\n\nBefore running the benchmarking tool, you must integrate benchmarks with your runtime as follows:\n\n1. Navigate to your `runtime/src` directory and check if a `benchmarks.rs` file exists. If not, create one. This file will contain the macro that registers all pallets for benchmarking along with their respective configurations:\n\n    ```rust title=\"benchmarks.rs\"\n    -frame_benchmarking::define_benchmarks!(\n    [frame_system, SystemBench::<Runtime>]\n    [pallet_parachain_template, TemplatePallet]\n    [pallet_balances, Balances]\n    [pallet_session, SessionBench::<Runtime>]\n    [pallet_timestamp, Timestamp]\n    [pallet_message_queue, MessageQueue]\n    [pallet_sudo, Sudo]\n    [pallet_collator_selection, CollatorSelection]\n    [cumulus_pallet_parachain_system, ParachainSystem]\n    [cumulus_pallet_xcmp_queue, XcmpQueue]\n);\n    ```\n\n    For example, to add a new pallet named `pallet_parachain_template` for benchmarking, include it in the macro as shown:\n    ```rust title=\"benchmarks.rs\" hl_lines=\"3\"\n    -frame_benchmarking::define_benchmarks!(\n    [frame_system, SystemBench::<Runtime>]\n    [pallet_parachain_template, TemplatePallet]\n    [pallet_balances, Balances]\n    [pallet_session, SessionBench::<Runtime>]\n    [pallet_timestamp, Timestamp]\n    [pallet_message_queue, MessageQueue]\n    [pallet_sudo, Sudo]\n    [pallet_collator_selection, CollatorSelection]\n    [cumulus_pallet_parachain_system, ParachainSystem]\n    [cumulus_pallet_xcmp_queue, XcmpQueue]\n);\n    );\n    ```\n\n    !!!warning \"Updating `define_benchmarks!` macro is required\"\n        Any pallet that needs to be benchmarked must be included in the [`define_benchmarks!`](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/macro.define_benchmarks.html){target=\\_blank} macro. The CLI will only be able to access and benchmark pallets that are registered here.\n\n2. Check your runtime's `lib.rs` file to ensure the `benchmarks` module is imported. The import should look like this:\n\n    ```rust title=\"lib.rs\"\n    #[cfg(feature = \"runtime-benchmarks\")]\n    mod benchmarks;\n    ```\n\n    The `runtime-benchmarks` feature gate ensures benchmark tests are isolated from production runtime code.\n\n3. Enable runtime benchmarking for your pallet in `runtime/Cargo.toml`:\n\n    ```toml\n    -runtime-benchmarks = [\n  # ...\n  \"pallet_parachain_template/runtime-benchmarks\",\n]\n\n    ```"}
{"page_id": "develop-parachains-testing-benchmarking", "index": 7, "depth": 3, "title": "Run Benchmarks", "anchor": "run-benchmarks", "start_char": 10370, "end_char": 14704, "estimated_token_count": 1104, "token_estimator": "heuristic-v1", "text": "### Run Benchmarks\n\nYou can now compile your runtime with the `runtime-benchmarks` feature flag. This feature flag is crucial as the benchmarking tool will look for this feature being enabled to know when it should run benchmark tests. Follow these steps to compile the runtime with benchmarking enabled:\n\n1. Run `build` with the feature flag included:\n\n    ```bash\n    cargo build --features runtime-benchmarks --release\n    ```\n\n2. Create a `weights.rs` file in your pallet's `src/` directory. This file will store the auto-generated weight calculations:\n\n    ```bash\n    touch weights.rs\n    ```\n\n3. Before running the benchmarking tool, you'll need a template file that defines how weight information should be formatted. Download the official template from the Polkadot SDK repository and save it in your project folders for future use:\n\n    ```bash\n    curl https://raw.githubusercontent.com/paritytech/polkadot-sdk/refs/tags/polkadot-stable2412/substrate/.maintain/frame-weight-template.hbs \\\n    --output ./pallets/benchmarking/frame-weight-template.hbs\n    ```\n\n4. Run the benchmarking tool to measure extrinsic weights:\n\n    ```bash\n    frame-omni-bencher v1 benchmark pallet \\\n    --runtime INSERT_PATH_TO_WASM_RUNTIME \\\n    --pallet INSERT_NAME_OF_PALLET \\\n    --extrinsic \"\" \\\n    --template ./frame-weight-template.hbs \\\n    --output weights.rs\n    ```\n\n    !!! tip \"Flag definitions\"\n        - **`--runtime`**: The path to your runtime's Wasm.\n        - **`--pallet`**: The name of the pallet you wish to benchmark. This pallet must be configured in your runtime and defined in `define_benchmarks`.\n        - **`--extrinsic`**: Which extrinsic to test. Using `\"\"` implies all extrinsics will be benchmarked.\n        - **`--template`**: Defines how weight information should be formatted.\n        - **`--output`**: Where the output of the auto-generated weights will reside.\n\nThe generated `weights.rs` file contains weight annotations for your extrinsics, ready to be added to your pallet. The output should be similar to the following. Some output is omitted for brevity:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>frame-omni-bencher v1 benchmark pallet \\</span>\n  <span data-ty>--runtime INSERT_PATH_TO_WASM_RUNTIME \\</span>\n  <span data-ty>--pallet \"INSERT_NAME_OF_PALLET\" \\</span>\n  <span data-ty>--extrinsic \"\" \\</span>\n  <span data-ty>--template ./frame-weight-template.hbs \\</span>\n  <span data-ty>--output ./weights.rs</span>\n  <span data-ty>...</span>\n  <span data-ty>2025-01-15T16:41:33.557045Z INFO polkadot_sdk_frame::benchmark::pallet: [ 0 % ] Starting benchmark: pallet_parachain_template::do_something</span>\n  <span data-ty>2025-01-15T16:41:33.564644Z INFO polkadot_sdk_frame::benchmark::pallet: [ 50 % ] Starting benchmark: pallet_parachain_template::cause_error</span>\n  <span data-ty>...</span>\n  <span data-ty>Created file: \"weights.rs\"</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>\n\n\n#### Add Benchmark Weights to Pallet\n\nOnce the `weights.rs` is generated, you must integrate it with your pallet. \n\n1. To begin the integration, import the `weights` module and the `WeightInfo` trait, then add both to your pallet's `Config` trait. Complete the following steps to set up the configuration:\n\n    ```rust title=\"lib.rs\"\n    -pub mod weights;\nuse crate::weights::WeightInfo;\n\n/// Configure the pallet by specifying the parameters and types on which it depends.\n#[pallet::config]\npub trait Config: frame_system::Config {\n    // ...\n    /// A type representing the weights required by the dispatchables of this pallet.\n    type WeightInfo: WeightInfo;\n}\n    ```\n\n2. Next, you must add this to the `#[pallet::weight]` annotation in all the extrinsics via the `Config` as follows:\n\n    ```rust hl_lines=\"2\" title=\"lib.rs\"\n    -#[pallet::call_index(0)]\n#[pallet::weight(T::WeightInfo::do_something())]\npub fn do_something(origin: OriginFor<T>) -> DispatchResultWithPostInfo { Ok(()) }\n    ```\n\n3. Finally, configure the actual weight values in your runtime. In `runtime/src/config/mod.rs`, add the following code:\n\n    ```rust title=\"mod.rs\"\n    -// Configure pallet.\nimpl pallet_parachain_template::Config for Runtime {\n    // ...\n    type WeightInfo = pallet_parachain_template::weights::SubstrateWeight<Runtime>;\n}\n    ```"}
{"page_id": "develop-parachains-testing-benchmarking", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 14704, "end_char": 15187, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n- View the Rust Docs for a more comprehensive, low-level view of the [FRAME V2 Benchmarking Suite](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/index.html){target=_blank}.\n- Read the [FRAME Benchmarking and Weights](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/frame_benchmarking_weight/index.html){target=_blank} reference document, a concise guide which details how weights and benchmarking work."}
{"page_id": "develop-parachains-testing-mock-runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 474, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nTesting is essential in Polkadot SDK development to ensure your blockchain operates as intended and effectively handles various potential scenarios. This guide walks you through setting up an environment to test pallets within the [runtime](/polkadot-protocol/glossary#runtime){target=_blank}, allowing you to evaluate how different pallets, their configurations, and system components interact to ensure reliable blockchain functionality."}
{"page_id": "develop-parachains-testing-mock-runtime", "index": 1, "depth": 2, "title": "Configuring a Mock Runtime", "anchor": "configuring-a-mock-runtime", "start_char": 474, "end_char": 505, "estimated_token_count": 6, "token_estimator": "heuristic-v1", "text": "## Configuring a Mock Runtime"}
{"page_id": "develop-parachains-testing-mock-runtime", "index": 2, "depth": 3, "title": "Testing Module", "anchor": "testing-module", "start_char": 505, "end_char": 2266, "estimated_token_count": 350, "token_estimator": "heuristic-v1", "text": "### Testing Module\n\nThe mock runtime includes all the necessary pallets and configurations needed for testing. To ensure proper testing, you must create a module that integrates all components, enabling assessment of interactions between pallets and system elements.\n\nHere's a simple example of how to create a testing module that simulates these interactions:\n\n```rust\n-pub mod tests {\n    use crate::*;\n    // ...\n}\n```\n\nThe `crate::*;` snippet imports all the components from your crate (including runtime configurations, pallet modules, and utility functions) into the `tests` module. This allows you to write tests without manually importing each piece, making the code more concise and readable. You can opt to instead create a separate `mock.rs` file to define the configuration for your mock runtime and a companion `tests.rs` file to house the specific logic for each test.\n\nOnce the testing module is configured, you can craft your mock runtime using the [`frame_support::runtime`](https://paritytech.github.io/polkadot-sdk/master/frame_support/attr.runtime.html){target=\\_blank} macro. This macro allows you to define a runtime environment that will be created for testing purposes:\n\n```rust\n-pub mod tests {\n    use crate::*;\n\n    #[frame_support::runtime]\n    mod runtime {\n        #[runtime::runtime]\n        #[runtime::derive(\n            RuntimeCall,\n            RuntimeEvent,\n            RuntimeError,\n            RuntimeOrigin,\n            RuntimeFreezeReason,\n            RuntimeHoldReason,\n            RuntimeSlashReason,\n            RuntimeLockId,\n            RuntimeTask\n        )]\n        pub struct Test;\n\n        #[runtime::pallet_index(0)]\n        pub type System = frame_system::Pallet<Test>;\n\n        // Other pallets...\n    }\n}\n```"}
{"page_id": "develop-parachains-testing-mock-runtime", "index": 3, "depth": 3, "title": "Genesis Storage", "anchor": "genesis-storage", "start_char": 2266, "end_char": 5782, "estimated_token_count": 769, "token_estimator": "heuristic-v1", "text": "### Genesis Storage\n\nThe next step is configuring the genesis storage—the initial state of your runtime. Genesis storage sets the starting conditions for the runtime, defining how pallets are configured before any blocks are produced. You can only customize the initial state only of those items that implement the [`[pallet::genesis_config]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.genesis_config.html){target=\\_blank} and [`[pallet::genesis_build]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.genesis_build.html){target=\\_blank} macros within their respective pallets.\n\nIn Polkadot SDK, you can create this storage using the [`BuildStorage`](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/trait.BuildStorage.html){target=\\_blank} trait from the [`sp_runtime`](https://paritytech.github.io/polkadot-sdk/master/sp_runtime){target=\\_blank} crate. This trait is essential for building the configuration that initializes the blockchain's state. \n\nThe function `new_test_ext()` demonstrates setting up this environment. It uses `frame_system::GenesisConfig::<Test>::default()` to generate a default genesis configuration for the runtime, followed by `.build_storage()` to create the initial storage state. This storage is then converted into a format usable by the testing framework, [`sp_io::TestExternalities`](https://paritytech.github.io/polkadot-sdk/master/sp_io/type.TestExternalities.html){target=\\_blank}, allowing tests to be executed in a simulated blockchain environment.\n\nHere's the code that sets the genesis storage configuration:\n\n```rust\n-pub mod tests {\n    use crate::*;\n    use sp_runtime::BuildStorage;\n\n    #[frame_support::runtime]\n    mod runtime {\n        #[runtime::runtime]\n        #[runtime::derive(\n            RuntimeCall,\n            RuntimeEvent,\n            RuntimeError,\n            RuntimeOrigin,\n            RuntimeFreezeReason,\n            RuntimeHoldReason,\n            RuntimeSlashReason,\n            RuntimeLockId,\n            RuntimeTask\n        )]\n        pub struct Test;\n\n        #[runtime::pallet_index(0)]\n        pub type System = frame_system::Pallet<Test>;\n\n        // Other pallets...\n    }\n\n    pub fn new_test_ext() -> sp_io::TestExternalities {\n        frame_system::GenesisConfig::<Test>::default()\n            .build_storage()\n            .unwrap()\n            .into()\n    }\n}\n```\n\nYou can also customize the genesis storage to set initial values for your runtime pallets. For example, you can set the initial balance for accounts like this:\n\n```rust\n-// Build genesis storage according to the runtime's configuration\npub fn new_test_ext() -> sp_io::TestExternalities {\n    // Define the initial balances for accounts\n    let initial_balances: Vec<(AccountId32, u128)> = vec![\n        (AccountId32::from([0u8; 32]), 1_000_000_000_000),\n        (AccountId32::from([1u8; 32]), 2_000_000_000_000),\n    ];\n\n    let mut t = frame_system::GenesisConfig::<Test>::default()\n        .build_storage()\n        .unwrap();\n\n    // Adding balances configuration to the genesis config\n    pallet_balances::GenesisConfig::<Test> {\n        balances: initial_balances,\n    }\n    .assimilate_storage(&mut t)\n    .unwrap();\n\n    t.into()\n}\n```\n\nFor a more idiomatic approach, see the [Your First Pallet](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/your_first_pallet/index.html#better-test-setup){target=\\_blank} guide from the Polkadot SDK Rust documentation."}
{"page_id": "develop-parachains-testing-mock-runtime", "index": 4, "depth": 3, "title": "Pallet Configuration", "anchor": "pallet-configuration", "start_char": 5782, "end_char": 6785, "estimated_token_count": 208, "token_estimator": "heuristic-v1", "text": "### Pallet Configuration\n\nEach pallet in the mocked runtime requires an associated configuration, specifying the types and values it depends on to function. These configurations often use basic or primitive types (e.g., u32, bool) instead of more complex types like structs or traits, ensuring the setup remains straightforward and manageable.\n\n```rust\n-#[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\nimpl frame_system::Config for Test {\n    ...\n    type Index = u64;\n    type BlockNumber = u64;\n    type Hash = H256;\n    type Hashing = BlakeTwo256;\n    type AccountId = u64;\n    ...\n}\n\nimpl pallet_template::Config for Test {\n\ttype RuntimeEvent = RuntimeEvent;\n\ttype WeightInfo = ();\n    ...\n}\n```\n\nThe configuration should be set for each pallet existing in the mocked runtime. The simplification of types is for simplifying the testing process. For example, `AccountId` is `u64`, meaning a valid account address can be an unsigned integer:\n\n```rust\nlet alice_account: u64 = 1;\n```"}
{"page_id": "develop-parachains-testing-mock-runtime", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6785, "end_char": 7498, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nWith the mock environment in place, developers can now test and explore how pallets interact and ensure they work seamlessly together. For further details about mocking runtimes, see the following [Polkadot SDK docs guide](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/your_first_pallet/index.html#your-first-test-runtime){target=\\_blank}.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Pallet Testing__\n\n    ---\n\n    Learn how to efficiently test pallets in the Polkadot SDK, ensuring your pallet operations are reliable and secure.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/testing/pallet-testing/)\n\n</div>"}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 651, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUnit testing in the Polkadot SDK helps ensure that the functions provided by a pallet behave as expected. It also confirms that data and events associated with a pallet are processed correctly during interactions. The Polkadot SDK offers a set of APIs to create a test environment to simulate runtime and mock transaction execution for extrinsics and queries.\n\nTo begin unit testing, you must first set up a mock runtime that simulates blockchain behavior, incorporating the necessary pallets. For a deeper understanding, consult the [Mock Runtime](/develop/parachains/testing/mock-runtime/){target=\\_blank} guide."}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 1, "depth": 2, "title": "Writing Unit Tests", "anchor": "writing-unit-tests", "start_char": 651, "end_char": 2174, "estimated_token_count": 285, "token_estimator": "heuristic-v1", "text": "## Writing Unit Tests\n\nOnce the mock runtime is in place, the next step is to write unit tests that evaluate the functionality of your pallet. Unit tests allow you to test specific pallet features in isolation, ensuring that each function behaves correctly under various conditions. These tests typically reside in your pallet module's `test.rs` file.\n\nUnit tests in the Polkadot SDK use the Rust testing framework, and the mock runtime you've defined earlier will serve as the test environment. Below are the typical steps involved in writing unit tests for a pallet.\n\nThe tests confirm that:\n\n- **Pallets initialize correctly**: At the start of each test, the system should initialize with block number 0, and the pallets should be in their default states.\n- **Pallets modify each other's state**: The second test shows how one pallet can trigger changes in another pallet's internal state, confirming proper cross-pallet interactions.\n- **State transitions between blocks are seamless**: By simulating block transitions, the tests validate that the runtime responds correctly to changes in the block number.\n\nTesting pallet interactions within the runtime is critical for ensuring the blockchain behaves as expected under real-world conditions. Writing integration tests allows validation of how pallets function together, preventing issues that might arise when the system is fully assembled.\n\nThis approach provides a comprehensive view of the runtime's functionality, ensuring the blockchain is stable and reliable."}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 2, "depth": 3, "title": "Test Initialization", "anchor": "test-initialization", "start_char": 2174, "end_char": 2487, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### Test Initialization\n\nEach test starts by initializing the runtime environment, typically using the `new_test_ext()` function, which sets up the mock storage and environment.\n\n```rust\n-#[test]\nfn test_pallet_functionality() {\n    new_test_ext().execute_with(|| {\n        // Test logic goes here\n    });\n}\n```"}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 3, "depth": 3, "title": "Function Call Testing", "anchor": "function-call-testing", "start_char": 2487, "end_char": 3261, "estimated_token_count": 168, "token_estimator": "heuristic-v1", "text": "### Function Call Testing\n\nCall the pallet's extrinsics or functions to simulate user interaction or internal logic. Use the `assert_ok!` macro to check for successful execution and `assert_err!` to verify that errors are correctly handled.\n\n```rust\n-#[test]\nfn it_works_for_valid_input() {\n    new_test_ext().execute_with(|| {\n        // Call an extrinsic or function\n        assert_ok!(TemplateModule::some_function(Origin::signed(1), valid_param));\n    });\n}\n\n#[test]\nfn it_fails_for_invalid_input() {\n    new_test_ext().execute_with(|| {\n        // Call an extrinsic with invalid input and expect an error\n        assert_err!(\n            TemplateModule::some_function(Origin::signed(1), invalid_param),\n            Error::<Test>::InvalidInput\n        );\n    });\n}\n```"}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 4, "depth": 3, "title": "Storage Testing", "anchor": "storage-testing", "start_char": 3261, "end_char": 4111, "estimated_token_count": 191, "token_estimator": "heuristic-v1", "text": "### Storage Testing\n\nAfter calling a function or extrinsic in your pallet, it's essential to verify that the state changes in the pallet's storage match the expected behavior to ensure data is updated correctly based on the actions taken.\n\nThe following example shows how to test the storage behavior before and after the function call:\n\n```rust\n-#[test]\nfn test_storage_update_on_extrinsic_call() {\n    new_test_ext().execute_with(|| {\n        // Check the initial storage state (before the call)\n        assert_eq!(Something::<Test>::get(), None);\n\n        // Dispatch a signed extrinsic, which modifies storage\n        assert_ok!(TemplateModule::do_something(RuntimeOrigin::signed(1), 42));\n\n        // Validate that the storage has been updated as expected (after the call)\n        assert_eq!(Something::<Test>::get(), Some(42));\n    });\n}\n\n```"}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 5, "depth": 3, "title": "Event Testing", "anchor": "event-testing", "start_char": 4111, "end_char": 6133, "estimated_token_count": 520, "token_estimator": "heuristic-v1", "text": "### Event Testing\n\nIt's also crucial to test the events that your pallet emits during execution. By default, events generated in a pallet using the [`#generate_deposit`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.generate_deposit.html){target=\\_blank} macro are stored under the system's event storage key (system/events) as [`EventRecord`](https://paritytech.github.io/polkadot-sdk/master/frame_system/struct.EventRecord.html){target=\\_blank} entries. These can be accessed using [`System::events()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.events){target=\\_blank} or verified with specific helper methods provided by the system pallet, such as [`assert_has_event`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.assert_has_event){target=\\_blank} and [`assert_last_event`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.assert_last_event){target=\\_blank}.\n\nHere's an example of testing events in a mock runtime:\n\n```rust\n-#[test]\nfn it_emits_events_on_success() {\n    new_test_ext().execute_with(|| {\n        // Call an extrinsic or function\n        assert_ok!(TemplateModule::some_function(Origin::signed(1), valid_param));\n\n        // Verify that the expected event was emitted\n        assert!(System::events().iter().any(|record| {\n            record.event == Event::TemplateModule(TemplateEvent::SomeEvent)\n        }));\n    });\n}\n```\n\nSome key considerations are:\n\n- **Block number**: Events are not emitted on the genesis block, so you need to set the block number using [`System::set_block_number()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.set_block_number){target=\\_blank} to ensure events are triggered.\n- **Converting events**: Use `.into()` when instantiating your pallet's event to convert it into a generic event type, as required by the system's event storage."}
{"page_id": "develop-parachains-testing-pallet-testing", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6133, "end_char": 6875, "estimated_token_count": 211, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n- Dive into the full implementation of the [`mock.rs`](https://github.com/paritytech/polkadot-sdk/blob/master/templates/solochain/pallets/template/src/mock.rs){target=\\_blank} and [`test.rs`](https://github.com/paritytech/polkadot-sdk/blob/master/templates/solochain/pallets/template/src/tests.rs){target=\\_blank} files in the [Solochain Template](https://github.com/paritytech/polkadot-sdk/tree/master/templates/solochain){target=_blank}.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Benchmarking__\n\n    ---\n\n    Explore methods to measure the performance and execution cost of your pallet.\n\n    [:octicons-arrow-right-24: Reference](/develop/parachains/testing/benchmarking)\n\n</div>"}
{"page_id": "develop-smart-contracts-connect-to-kusama", "index": 0, "depth": 2, "title": "Networks Details", "anchor": "networks-details", "start_char": 1212, "end_char": 1845, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "## Networks Details\n\nDevelopers can leverage smart contracts on Kusama Hub for live production deployments. This section outlines the network specifications and connection details.\n\n=== \"Kusama Hub\"\n\n    Network name\n\n    ```text\n    Kusama Hub\n    ```\n\n    ---\n    \n    Currency symbol\n    \n    ```text\n    KSM\n    ```\n    \n    ---\n    \n    Chain ID\n    \n    ```text\n    420420418\n    ```\n    \n    ---\n    \n    RPC URL\n    \n    ```text\n    https://kusama-asset-hub-eth-rpc.polkadot.io\n    ```\n    ---\n    \n    Block explorer URL\n    \n    ```text\n    https://blockscout-kusama-asset-hub.parity-chains-scw.parity.io/\n    ```\n    ---"}
{"page_id": "develop-smart-contracts-connect-to-kusama", "index": 1, "depth": 2, "title": "Important Deployment Considerations", "anchor": "important-deployment-considerations", "start_char": 1845, "end_char": 2719, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Important Deployment Considerations\n\nWhile the compatibility with regular EVM codebases is still being maximized, some recommendations include:\n    \n- Leverage [Hardhat](/develop/smart-contracts/dev-environments/hardhat){target=\\_blank} to compile, deploy, and interact with your contract.\n- Use MetaMask to interact with your dApp (note that using MetaMask can sometimes lead to `Invalid transaction` errors. This is actively being worked on and will be fixed soon).\n- Avoid Remix for deployment as MetaMask enforces a 48kb size limit when using the [Remix IDE](/develop/smart-contracts/dev-environments/remix){target=\\_blank}, which is why Hardhat Polkadot is recommended for deployment.\n\nKusama Hub is a live environment. Ensure your contracts are thoroughly tested before deployment, as transactions on Kusama Hub involve real KSM tokens and **cannot be reversed**."}
{"page_id": "develop-smart-contracts-connect-to-kusama", "index": 2, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 2719, "end_char": 3592, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor your next steps, explore the various smart contract guides demonstrating how to use and integrate different tools and development environments into your workflow.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> **Deploy your first contract with Hardhat**\n    \n    ---\n    \n    Explore the recommended smart contract development and deployment process on Kusama Hub using Hardhat.\n    \n    [:octicons-arrow-right-24: Build with HardHat](/develop/smart-contracts/dev-environments/hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> **Interact with the blockchain using viem**\n    \n    ---\n    \n    Use viem for interacting with Ethereum-compatible chains to deploy and interact with smart contracts on Kusama Hub.\n    \n    [:octicons-arrow-right-24: Build with viem](/develop/smart-contracts/libraries/viem/)\n\n</div>"}
{"page_id": "develop-smart-contracts-connect-to-polkadot", "index": 0, "depth": 2, "title": "Networks Details", "anchor": "networks-details", "start_char": 948, "end_char": 1601, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "## Networks Details\n\nDevelopers can leverage smart contracts across diverse networks, from TestNets to MainNet. This section outlines the network specifications and connection details for each environment.\n\n=== \"Polkadot Hub TestNet\"\n\n    Network name\n\n    ```text\n    Polkadot Hub TestNet\n    ```\n\n    ---\n\n    Currency symbol\n    \n    ```text\n    PAS\n    ```\n\n    ---\n    \n    Chain ID\n    \n    ```text\n    420420422\n    ```\n\n    ---\n    \n    RPC URL\n    \n    ```text\n    https://testnet-passet-hub-eth-rpc.polkadot.io\n    ```\n\n    ---\n    \n    Block explorer URL\n    \n    ```text\n    https://blockscout-passet-hub.parity-testnet.parity.io/\n    ```"}
{"page_id": "develop-smart-contracts-connect-to-polkadot", "index": 1, "depth": 2, "title": "Test Tokens", "anchor": "test-tokens", "start_char": 1601, "end_char": 2653, "estimated_token_count": 245, "token_estimator": "heuristic-v1", "text": "## Test Tokens\n\nYou will need testnet tokens to perform transactions and engage with smart contracts on any chain. Here's how to obtain Paseo (PAS) tokens for testing purposes:\n\n1. Navigate to the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}. If the desired network is not already selected, choose it from the Network drop-down.\n\n2. Copy your address linked to the TestNet and paste it into the designated field.\n\n    ![](/images/develop/smart-contracts/connect-to-polkadot/connect-to-polkadot-1.webp)\n\n3. Click the **Get Some PASs** button to request free test PAS tokens. These tokens will be sent to your wallet shortly.\n\n    ![](/images/develop/smart-contracts/connect-to-polkadot/connect-to-polkadot-2.webp)\n\nNow that you have obtained PAS tokens in your wallet, you’re ready to deploy and interact with smart contracts on Polkadot Hub TestNet! These tokens will allow you to pay for gas fees when executing transactions, deploying contracts, and testing your dApp functionality in a secure testnet environment."}
{"page_id": "develop-smart-contracts-connect-to-polkadot", "index": 2, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 2653, "end_char": 3498, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor your next steps, explore the various smart contract guides demonstrating how to use and integrate different tools and development environments into your workflow.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy your first contract with Remix__\n\n    ---\n\n    Explore the smart contract development and deployment process on Polkadot Hub using the Remix IDE.\n\n    [:octicons-arrow-right-24: Build with Remix IDE](/develop/smart-contracts/dev-environments/remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Interact with the blockchain with viem__\n\n    ---\n\n    Use viem for interacting with Ethereum-compatible chains, to deploy and interact with smart contracts on Polkadot Hub.\n\n    [:octicons-arrow-right-24: Build with viem](/develop/smart-contracts/libraries/viem/)\n\n</div>"}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 0, "depth": 2, "title": "Overview", "anchor": "overview", "start_char": 182, "end_char": 918, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "## Overview\n\nFoundry is a fast, modular, and extensible toolkit for Ethereum application development written in Rust. It provides a suite of command-line tools, including `forge` for compiling, testing, and deploying smart contracts and `cast` for interacting with blockchains.\n\n[`foundry-polkadot`](https://github.com/paritytech/foundry-polkadot/){target=\\_blank} is an adaptation explicitly engineered for the Polkadot Hub, tailored for developers already familiar with Foundry who seek to leverage its capabilities within the Polkadot ecosystem. Additionally, this guide offers detailed information on the `forge` and `cast` commands supported within `foundry-polkadot`, complete with simple, runnable examples for quick reference."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 1, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 918, "end_char": 1764, "estimated_token_count": 175, "token_estimator": "heuristic-v1", "text": "## Installation\n\nThe installation process is tailored for the Polkadot variant:\n\n- `foundry-polkadot` is installed via `foundryup-polkadot`, its dedicated installer. To get started, open your terminal and execute:\n\n    ```bash\n    curl -L https://raw.githubusercontent.com/paritytech/foundry-polkadot/refs/heads/master/foundryup/install | bash\n    ```\n\n    This command starts the installation of `foundryup-polkadot`. After installation, run the following command to download the precompiled `foundry-polkadot` binaries:\n\n    ```bash\n    foundryup-polkadot\n    ```\n\n    This command will install the `forge` and `cast` binaries, which are explained below. Windows users must use a Unix-like terminal environment such as Git BASH or Windows Subsystem for Linux (WSL), as PowerShell and Command Prompt are not currently supported by `foundryup`."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 2, "depth": 2, "title": "Compiler Integration", "anchor": "compiler-integration", "start_char": 1764, "end_char": 3194, "estimated_token_count": 317, "token_estimator": "heuristic-v1", "text": "## Compiler Integration\n\nA core divergence lies in the underlying Solidity compiler.\n\n- `foundry` is built to interface with the `solc` compiler, which targets Ethereum's Ethereum Virtual Machine (EVM).\n- `foundry-polkadot`, in contrast, introduces and primarily utilizes the `resolc` compiler to compile down Solidity contracts into PolkaVM bytecode. \n\n    - **Command-Line Flag**: For commands that involve compilation (e.g., `forge build`), you can use the `--resolc` flag to enable `resolc` compilation. For example:\n\n        ```bash\n        forge build --resolc\n        ```\n\n        This command instructs Forge to use `resolc` instead of `solc`, generating bytecode compatible with PolkaVM.\n\n    - **Configuration File**: Alternatively, you can configure `resolc` usage in the `foundry.toml` file. Add the following:\n\n        ```toml\n        [profile.default.resolc]\n        resolc_compile = true\n        ```\n\n        Setting `resolc_compile = false` reverts to using `solc`, ensuring compatibility with Ethereum projects. By default, `foundry-polkadot` uses `solc` unless `resolc` is explicitly enabled. `resolc` also exposes specific options for fine-tuning the compilation process, such as `--use-resolc <RESOLC_VERSION>` for specifying a compiler version or path, `-O, --resolc-optimizer-mode <LEVEL>` for setting optimization levels, and `--heap-size <SIZE>` and `--stack-size <SIZE>` for configuring contract memory."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 3, "depth": 2, "title": "Command-Line Interface (CLI)", "anchor": "command-line-interface-cli", "start_char": 3194, "end_char": 3571, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "## Command-Line Interface (CLI)\n\n`foundry-polkadot` preserves the familiar `forge` and `cast` subcommand structure. However, it's crucial to note that commands which involve compilation (such as `create`, `bind`, `build`, and `inspect`) will yield different output when `resolc` is utilized, as the generated bytecode is specifically designed for PolkaVM rather than the EVM."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 4, "depth": 2, "title": "Unsupported or Modified Features", "anchor": "unsupported-or-modified-features", "start_char": 3571, "end_char": 4537, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "## Unsupported or Modified Features\n\nNot all functionalities from the original Foundry are present or behave identically in `foundry-polkadot`:\n\n- **Currently unsupported**:\n    - Compilation of Yul code is not yet supported.\n    - Support for factory contracts deployment is a known issue that is currently unresolved.\n- **Broader feature limitations**: Integration with `Anvil` and `Chisel` (Foundry's local blockchain and EVM toolkit, respectively) is not available. This limitation directly impacts the support for several key commands, including `forge test` for running tests, `forge snapshot` for creating blockchain state snapshots, and `forge script` for complex deployment and interaction scripts.\n- **Modified feature**: The most notable modification is in the **compilation output**. When ``resolc`` is employed, the resulting bytecode will fundamentally differ from that generated by ``solc``, reflecting PolkaVM's distinct architectural requirements."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 5, "depth": 2, "title": "Set up a Project", "anchor": "set-up-a-project", "start_char": 4537, "end_char": 5517, "estimated_token_count": 223, "token_estimator": "heuristic-v1", "text": "## Set up a Project\n\nInitialize a new project using `forge init`:\n\n```bash\nforge init my-polkadot-project\ncd my-polkadot-project\n```\n\nThis command creates a complete project structure with the following components:\n\n- **`src/`**: Contains the Solidity smart contracts (includes a sample `Counter.sol` contract by default).\n- **`lib/`**: Houses external dependencies and libraries (`forge-std` testing library is included).\n- **`script/`**: Stores deployment and interaction scripts (includes `Counter.s.sol` deployment script by default).\n- **`test/`**: Contains your contract tests (includes `Counter.t.sol` test file by default).\n- **`foundry.toml`**: Main configuration file for compiler settings, network configurations, and project preferences.\n\nThe default project includes a simple `Counter` contract that demonstrates basic state management through increment and decrement functions, along with corresponding tests and deployment scripts to help you get started quickly."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 6, "depth": 2, "title": "Compile a Project", "anchor": "compile-a-project", "start_char": 5517, "end_char": 6262, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Compile a Project\n\nCompile contracts using `forge build`:\n\n```bash\nforge build --resolc\n```\n\n!!!note \n    You can still use `forge build` for compiling to regular EVM bytecode.\n\nPolkaVM bytecode starts with `0x505` prefix. Inspect compiled artifacts with:\n\n```bash\nforge inspect Counter bytecode --resolc\n```\n\nIf successful, you will see the following output:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>forge inspect Counter bytecode --resolc</span>\n  <span data-ty>0x50564d00008213000000000000010700c13000c0008004808f08000000000e0000001c0000002a0000003500000040000000520000005d00000063616c6c5f646174615f636f707963616c6c5f646174615f6c6f616463616c6c5f646174615f73697a65676574...</span>\n</div>"}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 7, "depth": 2, "title": "Deploy a Contract", "anchor": "deploy-a-contract", "start_char": 6262, "end_char": 7394, "estimated_token_count": 330, "token_estimator": "heuristic-v1", "text": "## Deploy a Contract\n\nDeploy contracts using `forge create`:\n\n```bash\nforge create Counter \\\n    --rpc-url <INSERT_RPC_URL> \\\n    --private-key <INSERT_PRIVATE_KEY> \\\n    --resolc\n```\n\nIf the operation completes successfully, you'll see the following output (for example, to deploy to the Passet Hub chain):\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>forge create Counter &bsol;</span>\n  <span data-ty>&nbsp;&nbsp;--rpc-url https://testnet-passet-hub-eth-rpc.polkadot.io &bsol;</span>\n  <span data-ty>&nbsp;&nbsp;--private-key &lt;INSERT_PRIVATE_KEY&gt; &bsol;</span>\n  <span data-ty>&nbsp;&nbsp;--resolc</span>\n  <br />\n  <span data-ty>[:] Compiling...</span>\n  <span data-ty>Compiler run successful!</span>\n</div>\n\n\nFor contracts with constructor arguments:\n\n```bash\nforge create MyToken \\\n    --rpc-url <INSERT_RPC_URL> \\\n    --private-key <INSERT_PRIVATE_KEY> \\\n    --constructor-args \"MyToken\" \"MTK\" 1000000 \\\n    --resolc\n```\n\n!!! note \"Network Compatibility\"\n    Use the `--resolc` flag when deploying to PolkaVM-compatible networks. Omit it for Ethereum-compatible networks."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 8, "depth": 2, "title": "Supported `foundry-polkadot` Commands", "anchor": "supported-foundry-polkadot-commands", "start_char": 7394, "end_char": 7548, "estimated_token_count": 33, "token_estimator": "heuristic-v1", "text": "## Supported `foundry-polkadot` Commands\n\nThis section provides a detailed breakdown of the `forge` and `cast` commands supported in `foundry-polkadot`."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 9, "depth": 3, "title": "Forge Commands", "anchor": "forge-commands", "start_char": 7548, "end_char": 13036, "estimated_token_count": 1502, "token_estimator": "heuristic-v1", "text": "### Forge Commands\n\n- **`init`**:\n    - **Command**: `forge init <PROJECT_NAME>`.\n    - **Description**: Initializes a new Foundry project in the current directory, setting up the basic project structure and installing standard libraries.\n\n- **`bind`**:\n    - **Command**: `forge bind [--resolc]`.\n    - **Description**: Generates type-safe Rust bindings for your Solidity contracts. Use `--resolc` to ensure compilation with the `resolc` compiler for PolkaVM compatibility.\n\n- **`bind-json`**:\n    - **Command**: `forge bind-json [--resolc]`.\n    - **Description**: Generates JSON bindings for your Solidity contracts. Use `--resolc` for `resolc`-based compilation.\n\n- **`build`**:\n    - **Command**: `forge build [--resolc]`.\n    - **Description**: Compiles all Solidity contracts in your project. Specify `--resolc` to compile for PolkaVM.\n\n- **`cache clean`**:\n    - **Command**: `forge cache clean`.\n    - **Description**: Clears the Foundry cache directory.\n\n- **`cache ls`**:\n    - **Command**: `forge cache ls`.\n    - **Description**: Lists the contents of the Foundry cache.\n\n- **`clean`**:\n    - **Command**: `forge clean`.\n    - **Description**: Removes all build artifacts from the project's `out` directory.\n\n- **`compiler resolve`**:\n    - **Command**: `forge compiler resolve [--resolc]`.\n    - **Description**: Resolves and displays the versions of Solidity compilers Foundry is using. Use `--resolc` to also check for `resolc`.\n\n- **`config`**:\n    - **Command**: `forge config`.\n    - **Description**: Displays the current Foundry project configuration, including settings from `foundry.toml`.\n\n- **`create`**:\n    - **Command**: `forge create [OPTIONS] <CONTRACT>`.\n    - **Required Parameters**: `<CONTRACT>` (the name of the contract to deploy).\n    - **Description**: Deploys a new contract to a specified blockchain network. The `--resolc` flag ensures it's compiled for PolkaVM. You'll typically need to provide an RPC URL, a private key for the deployer account, and potentially constructor arguments.\n\n- **`doc`**:\n    - **Command**: `forge doc`.\n    - **Description**: Generates documentation for your Solidity contracts.\n\n- **`flatten`**:\n    - **Command**: `forge flatten [OPTIONS] <PATH>`.\n    - **Required Parameters**: `<PATH>` (the path to the Solidity file).\n    - **Description**: Combines all imports of a Solidity file into a single file, useful for deployment or verification.\n\n- **`fmt`**:\n    - **Command**: `forge fmt`.\n    - **Description**: Formats Solidity code according to a predefined style.\n\n- **`geiger`**:\n    - **Command**: `forge geiger <PATH>`.\n    - **Required Parameters**: `<PATH>` (the path to the Solidity file).\n    - **Description**: Analyzes Solidity code for potential security vulnerabilities and gas inefficiencies.\n\n- **`generate test`**:\n    - **Command**: `forge generate test --contract-name <CONTRACT_NAME>`.\n    - **Required Parameters**: `--contract-name <CONTRACT_NAME>` (the name of the contract for which to generate a test).\n    - **Description**: Creates a new test file with boilerplate code for a specified contract.\n\n- **`generate-fig-spec`**:\n    - **Command**: `forge generate-fig-spec`.\n    - **Description**: Generates a Fig specification for CLI autocompletion tools.\n\n- **`inspect`**:\n    - **Command**: `forge inspect <CONTRACT_NAME> <ARTIFACT> [--resolc]`.\n    - **Required Parameters**: `<CONTRACT_NAME>` (the contract to inspect), `<ARTIFACT>` (e.g., `bytecode`, `abi`, `methods`, `events`).\n    - **Description**: Displays various artifacts of a compiled contract. Use `--resolc` to inspect `resolc`-compiled artifacts; the bytecode will start with `0x505`.\n\n- **`install`**:\n    - **Command**: `forge install <REPOSITORY>`.\n    - **Description**: Installs a Solidity library or dependency from a Git repository.\n\n- **`update`**:\n    - **Command**: `forge update [<REPOSITORY>]`.\n    - **Description**: Updates installed dependencies. If a repository is specified, only that one is updated.\n\n- **`remappings`**:\n    - **Command**: `forge remappings`.\n    - **Description**: Lists the currently configured Solidity compiler remappings.\n\n- **`remove`**:\n    - **Command**: `forge remove <REPOSITORY>`.\n    - **Description**: Removes an installed Solidity dependency. Use `--force` to remove without confirmation.\n\n- **`selectors upload`**:\n    - **Command**: `forge selectors upload [--all]`.\n    - **Description**: Uploads function selectors from compiled contracts to OpenChain. Use `--all` to upload for all contracts.\n\n- **`selectors list`**:\n    - **Command**: `forge selectors list`.\n    - **Description**: Lists all known function selectors for contracts in the project.\n\n- **`selectors find`**:\n    - **Command**: `forge selectors find <SELECTOR>`.\n    - **Description**: Searches for a function signature given its 4-byte selector.\n\n- **`selectors cache`**:\n    - **Command**: `forge selectors cache`.\n    - **Description**: Caches function selectors for faster lookup.\n\n- **`tree`**:\n    - **Command**: `forge tree`.\n    - **Description**: Displays the dependency tree of your Solidity contracts.\n\n!!!warning \"Non-working Commands\"\n\n    Consider that some foundry commands are not yet supported in `foundry-polkadot`:\n\n    - **`clone`**: This command is not supported in `foundry-polkadot`.\n    - **`coverage`**: Code coverage analysis is not supported.\n    - **`snapshot`**: Creating blockchain state snapshots is not supported.\n    - **`test`**: Running Solidity tests is not supported."}
{"page_id": "develop-smart-contracts-dev-environments-foundry", "index": 10, "depth": 3, "title": "Cast Commands", "anchor": "cast-commands", "start_char": 13036, "end_char": 23402, "estimated_token_count": 3084, "token_estimator": "heuristic-v1", "text": "### Cast Commands\n\n- **`4byte`**:\n    - **Command**: `cast 4byte [OPTIONS] [TOPIC_0]`.\n    - **Description**: Decodes a 4-byte function selector into its human-readable function signature.\n\n- **`4byte-event`**:\n    - **Command**: `cast 4byte-event [OPTIONS] [TOPIC_0]`.\n    - **Description**: Decodes a 4-byte event topic into its human-readable event signature.\n\n- **`abi-encode`**:\n    - **Command**: `cast abi-encode <SIG> [ARGS]...`.\n    - **Required Parameters**: `<SIG>` (the function signature), `[ARGS]` (arguments to encode).\n    - **Description**: ABI-encodes function arguments according to a given signature.\n\n- **`address-zero`**:\n    - **Command**: `cast address-zero`.\n    - **Description**: Returns the zero address (0x00...00).\n\n- **`age`**:\n    - **Command**: `cast age [OPTIONS] [BLOCK]`.\n    - **Description**: Converts a block number or tag (e.g., `latest`) into its timestamp.\n\n- **`balance`**:\n    - **Command**: `cast balance [OPTIONS] <WHO>`.\n    - **Required Parameters**: `<WHO>` (the address to check).\n    - **Description**: Retrieves the native token balance of a given address on the specified RPC network.\n\n- **`base-fee`**:\n    - **Command**: `cast base-fee [OPTIONS] [BLOCK]`.\n    - **Description**: Retrieves the base fee per gas for a specific block (defaults to `latest`).\n\n- **`block`**:\n    - **Command**: `cast block [OPTIONS] [BLOCK]`.\n    - **Description**: Retrieves comprehensive details about a specific block (defaults to `latest`).\n\n- **`block-number`**:\n    - **Command**: `cast block-number [OPTIONS] [BLOCK]`.\n    - **Description**: Retrieves the number of the latest or a specified block.\n\n- **`call`**:\n    - **Command**: `cast call [OPTIONS] <TO> <SIG> [ARGS]...`.\n    - **Description**: Executes a read-only (constant) function call on a contract. No transaction is sent to the network.\n\n- **`chain`**:\n    - **Command**: `cast chain [OPTIONS]`.\n    - **Description**: Displays the human-readable name of the connected blockchain.\n\n- **`chain-id`**:\n    - **Command**: `cast chain-id [OPTIONS]`.\n    - **Description**: Displays the chain ID of the connected blockchain.\n\n- **`client`**:\n    - **Command**: `cast client [OPTIONS]`.\n    - **Description**: Retrieves information about the connected RPC client (node software).\n\n- **`code`**:\n    - **Command**: `cast code [OPTIONS] <WHO>`.\n    - **Required Parameters**: `<WHO>` (the contract address).\n    - **Description**: Retrieves the bytecode deployed at a given contract address.\n\n- **`codesize`**:\n    - **Command**: `cast codesize [OPTIONS] <WHO>`.\n    - **Required Parameters**: `<WHO>` (the contract address).\n    - **Description**: Retrieves the size of the bytecode deployed at a given contract address.\n\n- **`compute-address`**:\n    - **Command**: `cast compute-address [OPTIONS] <WHO>`.\n    - **Required Parameters**: `<WHO>` (the deployer's address).\n    - **Description**: Computes the predicted contract address based on the deployer's address and nonce.\n\n- **`decode-abi`**:\n    - **Command**: `cast decode-abi <SIG> <CALLDATA>`.\n    - **Required Parameters**: `<SIG>` (the function signature), `<CALLDATA>` (the ABI-encoded data).\n    - **Description**: Decodes ABI-encoded output data from a contract call given its signature.\n\n- **`decode-calldata`**:\n    - **Command**: `cast decode-calldata <SIG> <CALLDATA>`.\n    - **Required Parameters**: `<SIG>` (the function signature), `<CALLDATA>` (the raw calldata).\n    - **Description**: Decodes raw calldata into human-readable arguments using a function signature.\n\n- **`decode-error`**:\n    - **Command**: `cast decode-error <DATA> [--sig <SIGNATURE>]`.\n    - **Required Parameters**: `<DATA>` (the error data).\n    - **Description**: Decodes a custom error message from a transaction revert. You may need to provide the error signature.\n\n- **`decode-event`**:\n    - **Command**: `cast decode-event <DATA> [--sig <SIGNATURE>]`.\n    - **Required Parameters**: `<DATA>` (the event data).\n    - **Description**: Decodes event data from a transaction log.\n\n- **`estimate`**:\n    - **Command**: `cast estimate [OPTIONS] [TO] [SIG] [ARGS]...`.\n    - **Required Parameters**: `[TO]` (the recipient address or contract), `[SIG]` (function signature), `[ARGS]` (arguments).\n    - **Description**: Estimates the gas cost for a transaction or function call.\n\n- **`find-block`**:\n    - **Command**: `cast find-block [OPTIONS] <TIMESTAMP>`.\n    - **Required Parameters**: `<TIMESTAMP>` (a Unix timestamp).\n    - **Description**: Finds the closest block number to a given Unix timestamp.\n\n- **`gas-price`**:\n    - **Command**: `cast gas-price [OPTIONS]`.\n    - **Description**: Retrieves the current average gas price on the network.\n\n- **`generate-fig-spec`**:\n    - **Command**: `cast generate-fig-spec`.\n    - **Description**: Generates a Fig specification for CLI autocompletion.\n\n- **`index-string`**:\n    - **Command**: `cast index-string <STRING> <INDEX>`.\n    - **Description**: Computes the Keccak-256 hash of a string, useful for event topics.\n\n- **`index-erc7201`**:\n    - **Command**: `cast index-erc7201 <VALUE>`.\n    - **Description**: Computes the hash for an ERC-7201 identifier.\n\n- **`logs`**:\n    - **Command**: `cast logs [OPTIONS] [SIG_OR_TOPIC] [TOPICS_OR_ARGS]...`.\n    - **Required Parameters**: `[SIG_OR_TOPIC]` (a signature or topic hash).\n    - **Description**: Filters and displays event logs from transactions.\n\n- **`max-int`**:\n    - **Command**: `cast max-int`.\n    - **Description**: Displays the maximum value for a signed 256-bit integer.\n\n- **`max-uint`**:\n    - **Command**: `cast max-uint`.\n    - **Description**: Displays the maximum value for an unsigned 256-bit integer.\n\n- **`min-int`**:\n    - **Command**: `cast min-int`.\n    - **Description**: Displays the minimum value for a signed 256-bit integer.\n\n- **`mktx`**:\n    - **Command**: `cast mktx [OPTIONS] [TO] [SIG] [ARGS]...`.\n    - **Required Parameters**: `[TO]` (the recipient address or contract).\n    - **Description**: Creates a raw, signed transaction that can be broadcast later.\n\n- **`decode-transaction`**:\n    - **Command**: `cast decode-transaction [OPTIONS] [TX]`.\n    - **Required Parameters**: `[TX]` (the raw transaction hex string).\n    - **Description**: Decodes a raw transaction hex string into its human-readable components.\n\n- **`namehash increment`**:\n    - **Command**: `cast namehash <NAME>`.\n    - **Description**: Computes the ENS (Ethereum Name Service) namehash for a given name.\n\n- **`nonce`**:\n    - **Command**: `cast nonce [OPTIONS] <WHO>`.\n    - **Required Parameters**: `<WHO>` (the address to check).\n    - **Description**: Retrieves the transaction count (nonce) for a given address.\n\n- **`parse-bytes32-address`**:\n    - **Command**: `cast parse-bytes32-address <VALUE>`.\n    - **Description**: Parses a 32-byte hex string (e.g., from `bytes32`) into an Ethereum address.\n\n- **`parse-bytes32-string`**:\n    - **Command**: `cast parse-bytes32-string <VALUE>`.\n    - **Description**: Parses a 32-byte hex string into a human-readable string.\n\n- **`parse-units`**:\n    - **Command**: `cast parse-units <AMOUNT> [UNIT]`.\n    - **Description**: Converts a human-readable amount into its smallest unit (e.g., Ether to Wei). Defaults to `ether`.\n\n- **`pretty-calldata`**:\n    - **Command**: `cast pretty-calldata [OPTIONS] <DATA>`.\n    - **Required Parameters**: `<DATA>` (the calldata hex string).\n    - **Description**: Attempts to pretty-print and decode a raw calldata string into possible function calls.\n\n- **`publish`**:\n    - **Command**: `cast publish [OPTIONS] <RAW_TX>`.\n    - **Description**: Broadcasts a raw, signed transaction to the network.\n\n- **`receipt`**:\n    - **Command**: `cast receipt [OPTIONS] <TX_HASH>`.\n    - **Description**: Retrieves the transaction receipt for a given transaction hash, including status, gas usage, and logs.\n\n- **`rpc`**:\n    - **Command**: `cast rpc [OPTIONS] <METHOD> [PARAMS]...`.\n    - **Required Parameters**: `<METHOD>` (the RPC method to call), `[PARAMS]` (parameters for the method).\n    - **Description**: Makes a direct RPC call to the connected blockchain node.\n\n- **`send`**:\n    - **Command**: `cast send [OPTIONS] <TO> <SIG> [ARGS]...`.\n    - **Required Parameters**: `<TO>` (the recipient address or contract).\n    - **Description**: Sends a transaction to a contract or address, executing a function or transferring value.\n\n- **`sig`**:\n    - **Command**: `cast sig <FUNCTION_SIGNATURE>`.\n    - **Required Parameters**: `<FUNCTION_SIGNATURE>` (the full function signature string).\n    - **Description**: Computes the 4-byte function selector for a given function signature.\n\n- **`sig-event`**:\n    - **Command**: `cast sig-event <EVENT_SIGNATURE>`.\n    - **Required Parameters**: `<EVENT_SIGNATURE>` (the full event signature string).\n    - **Description**: Computes the Keccak-256 hash (topic) for a given event signature.\n\n- **`storage`**:\n    - **Command**: `cast storage [OPTIONS] <ADDRESS> [SLOT]`.\n    - **Required Parameters**: `<ADDRESS>` (the contract address).\n    - **Description**: Retrieves the raw value stored at a specific storage slot of a contract.\n\n- **`tx`**:\n    - **Command**: `cast tx [OPTIONS] <TX_HASH>`.\n    - **Description**: Retrieves comprehensive details about a specific transaction.\n\n- **`upload-signature`**:\n    - **Command**: `cast upload-signature [OPTIONS] <SIGNATURE_STRING>`.\n    - **Required Parameters**: `<SIGNATURE_STRING>` (the function or event signature).\n    - **Description**: Uploads a function or event signature to the OpenChain registry.\n\n- **`wallet`**:\n    - **Command**: `cast wallet new`.\n    - **Description**: Generates a new random Ethereum keypair (private key and address).\n\n- **`wallet new-mnemonic`**:\n    - **Command**: `cast wallet new-mnemonic`.\n    - **Description**: Generates a new BIP-39 mnemonic phrase and derives the first account from it.\n\n- **`wallet address`**:\n    - **Command**: `cast wallet address [OPTIONS]`.\n    - **Description**: Derives and displays the Ethereum address from a private key or mnemonic (if provided).\n\n!!!warning \"Non-working Commands\"\n\n    Consider that some foundry commands are not yet supported in `foundry-polkadot`:\n\n    - **`proof`**: This command, used for generating Merkle proofs, is not supported.\n    - **`storage-root`**: This command, used for retrieving the storage root of a contract, is not supported."}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 0, "depth": 2, "title": "Overview", "anchor": "overview", "start_char": 1000, "end_char": 1274, "estimated_token_count": 47, "token_estimator": "heuristic-v1", "text": "## Overview\n\nHardhat is a robust development environment for Ethereum-compatible chains that makes smart contract development more efficient. This guide walks you through the essentials of using Hardhat to create, compile, test, and deploy smart contracts on Polkadot Hub."}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1274, "end_char": 1770, "estimated_token_count": 136, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have:\n\n- [Node.js](https://nodejs.org/){target=\\_blank} (v16.0.0 or later) and npm installed.\n- Basic understanding of Solidity programming.\n- Some PAS test tokens to cover transaction fees (easily obtainable from the [Polkadot faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}). To learn how to get test tokens, check out the [Test Tokens](/develop/smart-contracts/connect-to-polkadot#test-tokens){target=\\_blank} section."}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 2, "depth": 2, "title": "Set Up Hardhat", "anchor": "set-up-hardhat", "start_char": 1770, "end_char": 3187, "estimated_token_count": 317, "token_estimator": "heuristic-v1", "text": "## Set Up Hardhat\n\n1. Create a new directory for your project and navigate into it:\n\n    ```bash\n    mkdir hardhat-example\n    cd hardhat-example\n    ```\n\n2. Initialize a new npm project:\n\n    ```bash\n    npm init -y\n    ```\n\n3. To interact with Polkadot, Hardhat requires the following plugin to compile contracts to PolkaVM bytecode and to spawn a local node compatible with PolkaVM:\n\n    ```bash\n    npm install --save-dev @parity/hardhat-polkadot@0.1.9\n    ```\n\n4. Create a Hardhat project:\n\n    ```bash\n    npx hardhat-polkadot init\n    ```\n\n    Select **Create a JavaScript project** when prompted and follow the instructions. After that, your project will be created with three main folders:\n\n    - **`contracts`**: Where your Solidity smart contracts live.\n    - **`test`**: Contains your test files that validate contract functionality.\n    - **`ignition`**: Deployment modules for safely deploying your contracts to various networks.\n\n5. Add the following folder to the `.gitignore` file if it is not already there:\n\n    ```bash\n    echo '/ignition/deployments/' >> .gitignore\n    ```\n\n6. Finish the setup by installing all the dependencies:\n\n    ```bash\n    npm install\n    ```\n\n    !!! note\n        This last step is needed to set up the `hardhat-polkadot` plugin. It will install the `@parity/hardhat-polkadot` package and all its dependencies. In the future, the plugin will handle this automatically."}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 3, "depth": 2, "title": "Compile Your Contract", "anchor": "compile-your-contract", "start_char": 3187, "end_char": 6357, "estimated_token_count": 767, "token_estimator": "heuristic-v1", "text": "## Compile Your Contract\n\nThe plugin will compile your Solidity contracts for Solidity versions `0.8.0` and higher to be PolkaVM compatible. When compiling your contract, there are two ways to configure your compilation process:\n\n- **npm compiler**: Uses library [@parity/resolc](https://www.npmjs.com/package/@parity/resolc){target=\\_blank} for simplicity and ease of use.\n- **Binary compiler**: Uses your local `resolc` binary directly for more control and configuration options.\n\nTo compile your project, follow these instructions:\n\n1. Modify your Hardhat configuration file to specify which compilation process you will be using and activate the `polkavm` flag in the Hardhat network:\n\n    === \"npm Configuration\"\n\n        ```javascript title=\"hardhat.config.js\" hl_lines=\"9-11 14\"\n        -// hardhat.config.js\nrequire('@nomicfoundation/hardhat-toolbox');\n\nrequire('@parity/hardhat-polkadot');\n\n/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n  solidity: '0.8.28',\n  resolc: {\n    compilerSource: 'npm',\n  },\n  networks: {\n    hardhat: {\n      polkavm: true,\n        -    },\n  },\n};\n        ```\n\n    === \"Binary Configuration\"\n\n        ```javascript title=\"hardhat.config.js\" hl_lines=\"9-14 17\"\n        -// hardhat.config.js\nrequire('@nomicfoundation/hardhat-toolbox');\n\nrequire('@parity/hardhat-polkadot');\n\n/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n  solidity: '0.8.28',\n  resolc: {\n    compilerSource: 'binary',\n    settings: {\n      compilerPath: 'INSERT_PATH_TO_RESOLC_COMPILER',\n    },\n  },\n  networks: {\n    hardhat: {\n      polkavm: true,\n        -    },\n  },\n};\n        ```\n\n    For the binary configuration, replace `INSERT_PATH_TO_RESOLC_COMPILER` with the proper path to the binary. To obtain the binary, check the [releases](https://github.com/paritytech/revive/releases){target=\\_blank} section of the `resolc` compiler, and download the latest version.\n\n    The default settings used can be found in the [`constants.ts`](https://github.com/paritytech/hardhat-polkadot/blob/v0.1.5/packages/hardhat-polkadot-resolc/src/constants.ts#L8-L23){target=\\_blank} file of the `hardhat-polkadot` source code. You can change them according to your project needs. Generally, the recommended settings for optimized outputs are the following:\n\n    ```javascript title=\"hardhat.config.js\" hl_lines=\"4-10\"\n    resolc: {\n      ...\n      settings: {\n        optimizer: {\n          enabled: true,\n          parameters: 'z',\n          fallbackOz: true,\n          runs: 200,\n        },\n        standardJson: true,\n      },\n      ...\n    }\n    ```\n\n    You can check the [`ResolcConfig`](https://github.com/paritytech/hardhat-polkadot/blob/v0.1.5/packages/hardhat-polkadot-resolc/src/types.ts#L26){target=\\_blank} for more information about compilation settings.\n\n2. Compile the contract with Hardhat:\n\n    ```bash\n    npx hardhat compile\n    ```\n\n3. After successful compilation, you'll see the artifacts generated in the `artifacts-pvm` directory:\n\n    ```bash\n    ls artifacts-pvm/contracts/*.sol/\n    ```\n\n    You should see JSON files containing the contract ABI and bytecode of the contracts you compiled."}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 4, "depth": 2, "title": "Set Up a Testing Environment", "anchor": "set-up-a-testing-environment", "start_char": 6357, "end_char": 10366, "estimated_token_count": 1071, "token_estimator": "heuristic-v1", "text": "## Set Up a Testing Environment\n\nHardhat allows you to spin up a local testing environment to test and validate your smart contract functionalities before deploying to live networks. The `hardhat-polkadot` plugin provides the possibility to spin up a local node with an ETH-RPC adapter for running local tests.\n\nFor complete isolation and control over the testing environment, you can configure Hardhat to work with a fresh local Substrate node. This approach is ideal when you want to test in a clean environment without any existing state or when you need specific node configurations.\n\nConfigure a local node setup by adding the node binary path along with the ETH-RPC adapter path:\n\n```javascript title=\"hardhat.config.js\" hl_lines=\"12-20\"\n-// hardhat.config.js\nrequire('@nomicfoundation/hardhat-toolbox');\n\nrequire('@parity/hardhat-polkadot');\n\n-/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n    ...\n    -  networks: {\n    hardhat: {\n      polkavm: true,\n      nodeConfig: {\n        nodeBinaryPath: 'INSERT_PATH_TO_SUBSTRATE_NODE',\n        rpcPort: 8000,\n        dev: true,\n      },\n      adapterConfig: {\n        adapterBinaryPath: 'INSERT_PATH_TO_ETH_RPC_ADAPTER',\n        dev: true,\n      },\n    },\n-  },\n};\n```\n\nReplace `INSERT_PATH_TO_SUBSTRATE_NODE` and `INSERT_PATH_TO_ETH_RPC_ADAPTER` with the actual paths to your compiled binaries. The `dev: true` flag configures both the node and adapter for development mode. To obtain these binaries, check the [Installation](/develop/smart-contracts/local-development-node#install-the-substrate-node-and-eth-rpc-adapter){target=\\_blank} section on the Local Development Node page.\n\n!!! warning\n    If you're using the default `hardhat.config.js` created by the `hardhat-polkadot` plugin, it includes a `forking` section pointing to the Polkadot Hub TestNet. When you run `npx hardhat node`, Hardhat will start a fork of that network. To use your local node instead, comment out the `forking` section; otherwise, `npx hardhat node` will continue to use the forked network even if a local node is defined in the configuration.\n\nOnce configured, start your chosen testing environment with:\n\n```bash\nnpx hardhat node\n```\n\nThis command will launch either the forked network or local node (depending on your configuration) along with the ETH-RPC adapter, providing you with a complete testing environment ready for contract deployment and interaction. By default, the Substrate node will be running on `localhost:8000` and the ETH-RPC adapter on `localhost:8545`.\n\nThe output will be something like this:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat node</span>\n  <br />\n  <span data-ty>Starting server at 127.0.0.1:8000</span>\n  <span data-ty>../bin/substrate-node --rpc-port=8000 --dev</span>\n  <span data-ty>Starting the Eth RPC Adapter at 127.0.0.1:8545</span>\n  <span data-ty>../bin/eth-rpc --node-rpc-url=ws://localhost:8000 --dev</span>\n  <span data-ty>2025-05-29 13:00:32 Running in --dev mode, RPC CORS has been disabled.</span>\n  <span data-ty>2025-05-29 13:00:32 Running in --dev mode, RPC CORS has been disabled.</span>\n  <span data-ty>2025-05-29 13:00:32 🌐 Connecting to node at: ws://localhost:8000 ...</span>\n  <span data-ty>2025-05-29 13:00:32 Substrate Node</span>\n  <span data-ty>2025-05-29 13:00:32 ✌️ version 3.0.0-dev-f73c228b7a1</span>\n  <span data-ty>2025-05-29 13:00:32 ❤️ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2025</span>\n  <span data-ty>2025-05-29 13:00:32 📋 Chain specification: Development</span>\n  <span data-ty>2025-05-29 13:00:32 🏷 Node name: electric-activity-4221</span>\n  <span data-ty>2025-05-29 13:00:32 👤 Role: AUTHORITY</span>\n  <span data-ty>2025-05-29 13:00:32 💾 Database: RocksDb at /var/folders/f4/7rdt2m9d7j361dm453cpggbm0000gn/T/substrateOaoecu/chains/dev/db/full</span>\n  <span data-ty>2025-05-29 13:00:36 [0] 💸 generated 1 npos voters, 1 from validators and 0 nominators</span>\n  <span data-ty>...</span>\n</div>"}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 5, "depth": 2, "title": "Test Your Contract", "anchor": "test-your-contract", "start_char": 10366, "end_char": 11265, "estimated_token_count": 224, "token_estimator": "heuristic-v1", "text": "## Test Your Contract\n\nWhen testing your contract, be aware that [`@nomicfoundation/hardhat-toolbox/network-helpers`](https://hardhat.org/hardhat-network-helpers/docs/overview){target=\\_blank} is not fully compatible with Polkadot Hub's available RPCs. Specifically, Hardhat-only helpers like `time` and `loadFixture` may not work due to missing RPC calls in the node. For more details, refer to the [Compatibility](https://github.com/paritytech/hardhat-polkadot/tree/main/packages/hardhat-polkadot-node#compatibility){target=\\_blank} section in the `hardhat-revive` docs. You should avoid using helpers like `time` and `loadFixture` when writing tests.\n\nTo run your test:\n\n1. Update the `hardhat.config.js` file accordingly to the [Set Up a Testing Environment](#set-up-a-testing-environment) section.\n\n2. Execute the following command to run your tests:\n\n    ```bash\n    npx hardhat test\n    ```"}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 6, "depth": 2, "title": "Deploy to a Local Node", "anchor": "deploy-to-a-local-node", "start_char": 11265, "end_char": 12341, "estimated_token_count": 272, "token_estimator": "heuristic-v1", "text": "## Deploy to a Local Node\n\nBefore deploying to a live network, you can deploy your contract to a local node using [Ignition](https://hardhat.org/ignition/docs/getting-started#overview){target=\\_blank} modules:\n\n1. Update the Hardhat configuration file to add the local network as a target for local deployment:\n\n    ```javascript title=\"hardhat.config.js\" hl_lines=\"13-16\"\n    -// hardhat.config.js\nrequire('@nomicfoundation/hardhat-toolbox');\n\nrequire('@parity/hardhat-polkadot');\n\n    -/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n        ...\n        -  networks: {\n    hardhat: {\n            ...\n          -    },\n    localNode: {\n      polkavm: true,\n      url: `http://127.0.0.1:8545`,\n    },\n    -    },\n  },\n};\n    ```\n\n2. Start a local node:\n\n    ```bash\n    npx hardhat node\n    ```\n\n    This command will spawn a local Substrate node along with the ETH-RPC adapter.\n\n3. In a new terminal window, deploy the contract using Ignition:\n\n    ```bash\n    npx hardhat ignition deploy ./ignition/modules/MyToken.js --network localNode\n    ```"}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 7, "depth": 2, "title": "Deploying to a Live Network", "anchor": "deploying-to-a-live-network", "start_char": 12341, "end_char": 14487, "estimated_token_count": 496, "token_estimator": "heuristic-v1", "text": "## Deploying to a Live Network\n\nAfter testing your contract locally, you can deploy it to a live network. This guide will use the Polkadot Hub TestNet as the target network. Here's how to configure and deploy:\n\n1. Fund your deployment account with enough tokens to cover gas fees. In this case, the needed tokens are PAS (on Polkadot Hub TestNet). You can use the [Polkadot faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank} to obtain testing tokens.\n\n2. Export your private key and save it in your Hardhat environment:\n\n    ```bash\n    npx hardhat vars set PRIVATE_KEY \"INSERT_PRIVATE_KEY\"\n    ```\n\n    Replace `INSERT_PRIVATE_KEY` with your actual private key. For further details on private key exportation, refer to the article [How to export an account's private key](https://support.metamask.io/configure/accounts/how-to-export-an-accounts-private-key/){target=\\_blank}.\n\n    !!! warning\n        Never reveal your private key, otherwise anyone with access to it can control your wallet and steal your funds. Store it securely and never share it publicly or commit it to version control systems.\n\n3. Check that your private key has been set up successfully by running:\n\n    ```bash\n    npx hardhat vars get PRIVATE_KEY\n    ```\n\n4. Update your Hardhat configuration file with network settings for the Polkadot network you want to target:\n\n    ```javascript title=\"hardhat.config.js\" hl_lines=\"18-22\"\n    -// hardhat.config.js\nrequire('@nomicfoundation/hardhat-toolbox');\n\nrequire('@parity/hardhat-polkadot');\n\n    const { vars } = require('hardhat/config');\n\n    -/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n        ...\n        -  networks: {\n    hardhat: {\n            ...\n          -    },\n          -    localNode: {\n            ...\n          -    },\n    polkadotHubTestnet: {\n      polkavm: true,\n      url: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      accounts: [vars.get('PRIVATE_KEY')],\n    },\n    -    },\n  },\n};\n    ```\n\n6. Deploy your contract using Ignition:\n\n    ```bash\n    npx hardhat ignition deploy ./ignition/modules/MyToken.js --network polkadotHubTestnet\n    ```"}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 8, "depth": 2, "title": "Interacting with Your Contract", "anchor": "interacting-with-your-contract", "start_char": 14487, "end_char": 16288, "estimated_token_count": 427, "token_estimator": "heuristic-v1", "text": "## Interacting with Your Contract\n\nOnce deployed, you can create a script to interact with your contract. To do so, create a file called `scripts/interact.js` and add some logic to interact with the contract.\n\nFor example, for the default `MyToken.sol` contract, you can use the following file that connects to the contract at its address and retrieves the `unlockTime`, which represents when funds can be withdrawn. The script converts this timestamp into a readable date and logs it. It then checks the contract's balance and displays it. Finally, it attempts to call the withdrawal function on the contract, but it catches and logs the error message if the withdrawal is not yet allowed (e.g., before `unlockTime`).\n\n```javascript title=\"interact.js\"\n-const hre = require('hardhat');\n\nasync function main() {\n  // Get the contract factory\n  const MyToken = await hre.ethers.getContractFactory('MyToken');\n\n  // Replace with your deployed contract address\n  const contractAddress = 'INSERT_CONTRACT_ADDRESS';\n\n  // Attach to existing contract\n  const token = await MyToken.attach(contractAddress);\n\n  // Get signers\n  const [deployer] = await hre.ethers.getSigners();\n\n  // Read contract state\n  const name = await token.name();\n  const symbol = await token.symbol();\n  const totalSupply = await token.totalSupply();\n  const balance = await token.balanceOf(deployer.address);\n\n  console.log(`Token: ${name} (${symbol})`);\n  console.log(\n    `Total Supply: ${hre.ethers.formatUnits(totalSupply, 18)} tokens`,\n  );\n  console.log(\n    `Deployer Balance: ${hre.ethers.formatUnits(balance, 18)} tokens`,\n  );\n}\n\nmain().catch((error) => {\n  console.error(error);\n  process.exitCode = 1;\n});\n\n```\n\nRun your interaction script:\n\n```bash\nnpx hardhat run scripts/interact.js --network polkadotHubTestnet\n```"}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 9, "depth": 2, "title": "Upgrading the Plugin", "anchor": "upgrading-the-plugin", "start_char": 16288, "end_char": 16948, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## Upgrading the Plugin\n\nIf you already have a Hardhat Polkadot project and want to upgrade to a newer version of the plugin, to avoid errors (for example, `Cannot find module 'run-container'`), you can clean your dependencies by running the following commands:\n\n```bash\nrm -rf node_modules package-lock.json\n```\n\nAfter that, you can upgrade the plugin to the latest version by running the following commands:\n\n```bash\nnpm install --save-dev @parity/hardhat-polkadot@latest\nnpm install\n```\n\nConsider using [Node.js](https://nodejs.org/){target=\\_blank} 22.18+ and [npm](https://www.npmjs.com/){target=\\_blank} version 10.9.0+ to avoid issues with the plugin."}
{"page_id": "develop-smart-contracts-dev-environments-hardhat", "index": 10, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 16948, "end_char": 18028, "estimated_token_count": 249, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nHardhat provides a powerful environment for developing, testing, and deploying smart contracts on Polkadot Hub. Its plugin architecture allows seamless integration with PolkaVM through the `hardhat-resolc` and `hardhat-revive-node` plugins.\n\nExplore more about smart contracts through these resources:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Smart Contracts on Polkadot__\n\n    ---\n\n    Dive into advanced smart contract concepts.\n\n    [:octicons-arrow-right-24: Get Started](/develop/smart-contracts/)\n\n-   <span class=\"badge external\">External</span> __Hardhat Documentation__\n\n    ---\n\n    Learn more about Hardhat's advanced features and best practices.\n\n    [:octicons-arrow-right-24: Get Started](https://hardhat.org/docs){target=\\_blank}\n\n-   <span class=\"badge external\">External</span> __OpenZeppelin Contracts__\n\n    ---\n\n    Test your skills by deploying contracts with prebuilt templates.\n\n    [:octicons-arrow-right-24: Get Started](https://www.openzeppelin.com/solidity-contracts){target=\\_blank}\n\n</div>"}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 0, "depth": 2, "title": "Overview", "anchor": "overview", "start_char": 1056, "end_char": 1369, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "## Overview\n\nRemix IDE is a robust browser-based development environment for smart contracts. This guide will walk you through the essentials of the [Polkadot Remix IDE](https://remix.polkadot.io/){target=\\_blank} to understand the processes of compiling, developing, and deploying smart contracts on Asset Hub."}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1369, "end_char": 1733, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have:\n\n- A web browser with [Talisman](https://talisman.xyz/){target=\\_blank} extension installed.\n- Basic understanding of Solidity programming.\n- Some WND test tokens to cover transaction fees (easily obtainable from the [Polkadot faucet](https://faucet.polkadot.io/westend?parachain=1000){target=\\_blank})."}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 2, "depth": 2, "title": "Accessing Remix IDE", "anchor": "accessing-remix-ide", "start_char": 1733, "end_char": 2143, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "## Accessing Remix IDE\n\nNavigate to [https://remix.polkadot.io/](https://remix.polkadot.io/){target=\\_blank}. The interface will load with a default workspace containing sample contracts.\n\n![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-1.webp)\n\nIn this interface, you can access a file explorer, edit your code, interact with various plugins for development, and use a terminal."}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 3, "depth": 2, "title": "Creating a New Contract", "anchor": "creating-a-new-contract", "start_char": 2143, "end_char": 3149, "estimated_token_count": 255, "token_estimator": "heuristic-v1", "text": "## Creating a New Contract\n\nTo create a new contract using the Polkadot Remix IDE, you can follow these steps:\n\n1. Select the **Create a new file** button in the `contracts` folder.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-2.webp)\n\n2. Name your file with a `.sol` extension, in this case, `Counter.sol`.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-3.webp)\n\n3. Write your Solidity code in the editor.\n\n    You can use the following code as an example:\n\n    ???- \"Counter.sol\"\n        \n        ```solidity\n        -// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract Counter {\n    int256 private count;\n\n    function increment() public {\n        count += 1;\n    }\n\n    function decrement() public {\n        count -= 1;\n    }\n\n    function getCount() public view returns (int256) {\n        return count;\n    }\n}\n        ```\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-4.webp)"}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 4, "depth": 2, "title": "Compiling Your Contract", "anchor": "compiling-your-contract", "start_char": 3149, "end_char": 3915, "estimated_token_count": 192, "token_estimator": "heuristic-v1", "text": "## Compiling Your Contract\n\n1. To compile your contract, you need to:\n\n    1. Navigate to the **Solidity Compiler** tab (third icon in the left sidebar).\n    2. Select **Compile** or use `Ctrl+S`.\n\n        ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-5.webp)\n    \n        !!! note\n            Compilation errors and warnings appear in the terminal panel at the bottom of the screen.\n\n1. After compiling your contract, you can navigate to the **File Explorer** tab (first icon in the left sidebar) and check that:\n    1. The `artifact` folder is present.\n    2. The `Counter_metadata.json` and the `Counter.json` files have been generated.\n\n        ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-6.webp)"}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 5, "depth": 2, "title": "Deploying Contracts", "anchor": "deploying-contracts", "start_char": 3915, "end_char": 4953, "estimated_token_count": 285, "token_estimator": "heuristic-v1", "text": "## Deploying Contracts\n\n1. To deploy your contract, you need to:\n\n    1. Navigate to the **Deploy & Run Transactions** tab (fourth icon in the left sidebar).\n    2. Click the **Environment** dropdown.\n    3. Select **Customize this list**.\n\n        ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-7.webp)\n\n2. Enable the **Injected Provider - Talisman** option.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-8.webp)\n\n4. Click again the **Environment** dropdown and select **Injected Provider - Talisman**.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-9.webp)\n\n4. Click the **Deploy** button and then click **Approve** in the Talisman wallet popup.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-10.webp)\n\n5. Once your contract is deployed successfully, you will see the following output in the Remix terminal:\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-11.webp)"}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 6, "depth": 2, "title": "Interacting with Contracts", "anchor": "interacting-with-contracts", "start_char": 4953, "end_char": 5769, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Interacting with Contracts\n\nOnce deployed, your contract appears in the **Deployed/Unpinned Contracts** section:\n\n1. Expand the contract to view available methods.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-12.webp)\n\n    !!! tip\n        Pin your frequently used contracts to the **Pinned Contracts** section for easy access.\n\n2. To interact with the contract, you can select any of the exposed methods.\n\n    ![](/images/develop/smart-contracts/evm-toolkit/dev-environments/remix/remix-13.webp)\n\n    In this way, you can interact with your deployed contract by reading its state or writing to it. The button color indicates the type of interaction available:\n\n    - **Red**: Modifies state and is payable.\n    - **Orange**: Modifies state only.\n    - **Blue**: Reads state."}
{"page_id": "develop-smart-contracts-dev-environments-remix", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5769, "end_char": 6631, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nThe Polkadot Remix IDE offers an environment for developing, compiling, and deploying smart contracts on Asset Hub. Its intuitive interface allows developers to easily write Solidity code, compile contracts, and interact with them directly in the browser.\n\nExplore more about smart contracts through these resources:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Smart Contracts on Polkadot__\n\n    ---\n\n    Dive into advanced smart contract concepts.\n\n    [:octicons-arrow-right-24: Get Started](/develop/smart-contracts/)\n\n-   <span class=\"badge external\">External</span> __OpenZeppelin Contracts__\n\n    ---\n\n    Test your skills by deploying a simple contracts with prebuilt templates.\n\n    [:octicons-arrow-right-24: Get Started](https://www.openzeppelin.com/solidity-contracts){target=\\_blank}\n\n</div>"}
{"page_id": "develop-smart-contracts-faqs", "index": 0, "depth": 2, "title": "General Questions", "anchor": "general-questions", "start_char": 454, "end_char": 476, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## General Questions"}
{"page_id": "develop-smart-contracts-faqs", "index": 1, "depth": 3, "title": "What are the different types of smart contracts I can build on Polkadot?", "anchor": "what-are-the-different-types-of-smart-contracts-i-can-build-on-polkadot", "start_char": 476, "end_char": 919, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "### What are the different types of smart contracts I can build on Polkadot?\n\nPolkadot supports three main smart contract environments:\n\n1. **PolkaVM contracts**: Available on Polkadot Hub, using a RISC-V-based virtual machine with Solidity compatibility.\n2. **EVM contracts**: Available on parachains like Moonbeam, Astar, and Acala via the Frontier framework.\n3. **Wasm contracts**: Using ink! (Rust-based) or Solidity via Solang compiler."}
{"page_id": "develop-smart-contracts-faqs", "index": 2, "depth": 3, "title": "Should I build a smart contract or a parachain?", "anchor": "should-i-build-a-smart-contract-or-a-parachain", "start_char": 919, "end_char": 1466, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "### Should I build a smart contract or a parachain?\n\nChoose smart contracts if:\n\n- You want to deploy quickly without managing consensus.\n- Your application fits within existing chain functionality.\n- You prefer familiar development tools (Ethereum ecosystem).\n- You need to interact with other contracts easily.\n\nChoose a parachain if:\n\n- You need custom logic that doesn't fit smart contract limitations.\n- You want full control over governance and upgrades.\n- You require specialized consensus mechanisms.\n- You need optimized fee structures."}
{"page_id": "develop-smart-contracts-faqs", "index": 3, "depth": 3, "title": "What's the difference between Polkadot Hub smart contracts and other EVM chains?", "anchor": "whats-the-difference-between-polkadot-hub-smart-contracts-and-other-evm-chains", "start_char": 1466, "end_char": 2046, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "### What's the difference between Polkadot Hub smart contracts and other EVM chains?\n\nPolkadot Hub contracts run on [PolkaVM](/polkadot-protocol/smart-contract-basics/polkavm-design){target=\\_blank} instead of EVM:\n\n- **Performance**: RISC-V register-based architecture vs. stack-based EVM.\n- **Resource metering**: Three dimensions (`ref_time`, `proof_size`, `storage_deposit`) vs. single gas metric.\n- **Memory management**: Hard memory limits per contract vs. gas-based soft limits.\n- **Account system**: Polkadot's 32-byte accounts with automatic 20-byte address conversion."}
{"page_id": "develop-smart-contracts-faqs", "index": 4, "depth": 2, "title": "Development Environment", "anchor": "development-environment", "start_char": 2046, "end_char": 2074, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Development Environment"}
{"page_id": "develop-smart-contracts-faqs", "index": 5, "depth": 3, "title": "Can I use my existing Ethereum development tools?", "anchor": "can-i-use-my-existing-ethereum-development-tools", "start_char": 2074, "end_char": 2411, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "### Can I use my existing Ethereum development tools?\n\nYes, check out the [Wallets](/develop/smart-contracts/wallets){target=\\_blank} page, the [Development Environments](/develop/smart-contracts/dev-environments/){target=\\_blank}, and the [Libraries](/develop/smart-contracts/libraries/){target=\\_blank} sections for more information."}
{"page_id": "develop-smart-contracts-faqs", "index": 6, "depth": 3, "title": "How do I set up local development?", "anchor": "how-do-i-set-up-local-development", "start_char": 2411, "end_char": 2578, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "### How do I set up local development?\n\nCheck the [Local Development Node](/develop/smart-contracts/local-development-node){target=\\_blank} for further instructions."}
{"page_id": "develop-smart-contracts-faqs", "index": 7, "depth": 3, "title": "What networks are available for testing and deployment?", "anchor": "what-networks-are-available-for-testing-and-deployment", "start_char": 2578, "end_char": 2745, "estimated_token_count": 38, "token_estimator": "heuristic-v1", "text": "### What networks are available for testing and deployment?\n\n- **Local Development**: Kitchensink node with Ethereum RPC proxy.\n- **TestNets**: Polkadot Hub TestNet."}
{"page_id": "develop-smart-contracts-faqs", "index": 8, "depth": 2, "title": "Technical Implementation", "anchor": "technical-implementation", "start_char": 2745, "end_char": 2774, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Technical Implementation"}
{"page_id": "develop-smart-contracts-faqs", "index": 9, "depth": 3, "title": "How do Ethereum addresses work on Polkadot?", "anchor": "how-do-ethereum-addresses-work-on-polkadot", "start_char": 2774, "end_char": 3259, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "### How do Ethereum addresses work on Polkadot?\n\nPolkadot uses a [dual-address system](/polkadot-protocol/smart-contract-basics/evm-vs-polkavm#account-management-comparison){target=\\_blank}:\n\n- _20-byte Ethereum addresses_ are padded with `0xEE` bytes to create 32-byte Polkadot accounts.\n- _32-byte Polkadot accounts_ can register mappings to 20-byte addresses.\n- _Automatic conversion_ happens behind the scenes.\n- _MetaMask compatibility_ is maintained through the mapping system."}
{"page_id": "develop-smart-contracts-faqs", "index": 10, "depth": 3, "title": "What are the key differences in the gas model?", "anchor": "what-are-the-key-differences-in-the-gas-model", "start_char": 3259, "end_char": 3765, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "### What are the key differences in the gas model?\n\nPolkaVM uses three resource dimensions:\n\n- **`ref_time`**: Computational time (similar to traditional gas).\n- **`proof_size`**: State proof size for validator verification.\n- **`storage_deposit`**: Refundable deposit for state storage.\n\nKey implications:\n\n- Gas values are dynamically scaled based on performance benchmarks.\n- Cross-contract calls don't respect gas limits (use reentrancy protection).\n- Storage costs are separate from execution costs."}
{"page_id": "develop-smart-contracts-faqs", "index": 11, "depth": 3, "title": "How does contract deployment work?", "anchor": "how-does-contract-deployment-work", "start_char": 3765, "end_char": 4097, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "### How does contract deployment work?\n\nPolkaVM deployment differs from EVM:\n\n- _Code must be pre-uploaded_ to the chain before instantiation.\n- _Factory contracts_ need modification to work with pre-uploaded code hashes.\n- _Two-step process_: Upload code, then instantiate contracts.\n- _Runtime code generation_ is not supported."}
{"page_id": "develop-smart-contracts-faqs", "index": 12, "depth": 3, "title": "Which Solidity features are not supported?", "anchor": "which-solidity-features-are-not-supported", "start_char": 4097, "end_char": 4506, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "### Which Solidity features are not supported?\n\nLimited support for:\n\n- **`EXTCODECOPY`**: Only works in constructor code.\n- **Runtime code modification**: Use on-chain constructors instead.\n- **Gas stipends**: `address.send()` and `address.transfer()` don't provide reentrancy protection.\n\nUnsupported operations:\n\n- `pc`, `extcodecopy`, `selfdestruct`\n- `blobhash`, `blobbasefee` (blob-related operations)"}
{"page_id": "develop-smart-contracts-faqs", "index": 13, "depth": 3, "title": "How do I handle the existential deposit requirement?", "anchor": "how-do-i-handle-the-existential-deposit-requirement", "start_char": 4506, "end_char": 4986, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "### How do I handle the existential deposit requirement?\n\nWhat it means:\n\n- Accounts need a minimum balance, also known as an existential deposit (ED), to remain active.\n- Accounts below this threshold are automatically deleted.\n\nHow it's handled:\n\n- _Balance queries_ via Ethereum RPC automatically deduct the ED.\n- _New account transfers_ automatically include ED with transaction fees.\n- _Contract-to-contract transfers_ draw ED from transaction signer, not sending contract."}
{"page_id": "develop-smart-contracts-faqs", "index": 14, "depth": 2, "title": "Migration and Compatibility", "anchor": "migration-and-compatibility", "start_char": 4986, "end_char": 5018, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Migration and Compatibility"}
{"page_id": "develop-smart-contracts-faqs", "index": 15, "depth": 3, "title": "Can I migrate my existing Ethereum contracts?", "anchor": "can-i-migrate-my-existing-ethereum-contracts", "start_char": 5018, "end_char": 5425, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "### Can I migrate my existing Ethereum contracts?\n\nMost contracts work without changes:\n\n- Standard ERC-20, ERC-721, ERC-1155 tokens.\n- DeFi protocols and DEXs.\n- DAOs and governance contracts.\n\nMay need modifications:\n\n- Factory contracts that create other contracts at runtime.\n- Contracts using `EXTCODECOPY` for runtime code manipulation.\n- Contracts relying on gas stipends for reentrancy protection."}
{"page_id": "develop-smart-contracts-faqs", "index": 16, "depth": 2, "title": "Troubleshooting", "anchor": "troubleshooting", "start_char": 5425, "end_char": 5445, "estimated_token_count": 3, "token_estimator": "heuristic-v1", "text": "## Troubleshooting"}
{"page_id": "develop-smart-contracts-faqs", "index": 17, "depth": 3, "title": "Why are my gas calculations different?", "anchor": "why-are-my-gas-calculations-different", "start_char": 5445, "end_char": 5707, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Why are my gas calculations different?\n\nPolkaVM uses dynamic gas scaling:\n\n- Gas values reflect actual performance benchmarks.\n- Don't hardcode gas values—use flexible calculations.\n- Cross-contract calls ignore gas limits—implement proper access controls."}
{"page_id": "develop-smart-contracts-faqs", "index": 18, "depth": 3, "title": "I deployed a contract with MetaMask, and got a `code size` error - why?", "anchor": "i-deployed-a-contract-with-metamask-and-got-a-code-size-error-why", "start_char": 5707, "end_char": 5964, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### I deployed a contract with MetaMask, and got a `code size` error - why?\n\nThe latest MetaMask update affects the extension’s ability to deploy large contracts. Check the [Wallets](/develop/smart-contracts/wallets){target=\\_blank} page for more details."}
{"page_id": "develop-smart-contracts-faqs", "index": 19, "depth": 3, "title": "I found a bug, where can I log it?", "anchor": "i-found-a-bug-where-can-i-log-it", "start_char": 5964, "end_char": 6188, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### I found a bug, where can I log it?\n\nPlease log any bugs in the [`contracts-issues`](https://github.com/paritytech/contract-issues/issues){target=\\_blank} repository so developers are aware of them and can address them."}
{"page_id": "develop-smart-contracts-faqs", "index": 20, "depth": 2, "title": "Known Issues", "anchor": "known-issues", "start_char": 6188, "end_char": 6205, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Known Issues"}
{"page_id": "develop-smart-contracts-faqs", "index": 21, "depth": 3, "title": "Runtime Behavior", "anchor": "runtime-behavior", "start_char": 6205, "end_char": 6833, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "### Runtime Behavior\n\n- **`creationCode` returns hash instead of bytecode**: The Solidity keyword returns a `keccak256` hash rather than the actual creation bytecode.\n    - [Issue #45](https://github.com/paritytech/contract-issues/issues/45){target=\\_blank}\n- **Non-deterministic gas usage**: Gas consumption varies slightly for identical transactions.\n    - [Issue #49](https://github.com/paritytech/contract-issues/issues/49){target=\\_blank}\n- **Precompiles not recognized**: Precompile addresses return `Contract not found` error.\n    - [Issue #111](https://github.com/paritytech/contract-issues/issues/111){target=\\_blank}"}
{"page_id": "develop-smart-contracts-faqs", "index": 22, "depth": 3, "title": "Development Tools", "anchor": "development-tools", "start_char": 6833, "end_char": 7063, "estimated_token_count": 61, "token_estimator": "heuristic-v1", "text": "### Development Tools\n\n- **`hardhat-polkadot` plugin compilation issues**: Plugin interferes with standard `npx hardhat compile` command.\n    - [Issue #44](https://github.com/paritytech/contract-issues/issues/44){target=\\_blank}"}
{"page_id": "develop-smart-contracts-faqs", "index": 23, "depth": 3, "title": "Contract Patterns", "anchor": "contract-patterns", "start_char": 7063, "end_char": 7283, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "### Contract Patterns\n\n- **Minimal proxy (EIP-1167) deployment fails**: Standard proxy contracts cannot be deployed on PolkaVM.\n    - [Issue #86](https://github.com/paritytech/contract-issues/issues/86){target=\\_blank}"}
{"page_id": "develop-smart-contracts-faqs", "index": 24, "depth": 3, "title": "Compilation", "anchor": "compilation", "start_char": 7283, "end_char": 7471, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "### Compilation\n\n- **`SDIV` opcode crash**: Compiler crashes with `Unsupported SDIV` assertion failure.\n    - [Issue #342](https://github.com/paritytech/revive/issues/342){target=\\_blank}"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 189, "end_char": 684, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub provides Ethereum compatibility through its JSON-RPC interface, allowing developers to interact with the chain using familiar Ethereum tooling and methods. This document outlines the supported [Ethereum JSON-RPC methods](https://ethereum.org/en/developers/docs/apis/json-rpc/#json-rpc-methods){target=\\_blank} and provides examples of how to use them.\n\nThis guide uses the Polkadot Hub TestNet endpoint:\n\n```text\nhttps://testnet-passet-hub-eth-rpc.polkadot.io\n```"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 1, "depth": 2, "title": "Available Methods", "anchor": "available-methods", "start_char": 684, "end_char": 706, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Available Methods"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 2, "depth": 3, "title": "eth_accounts", "anchor": "eth_accounts", "start_char": 706, "end_char": 1140, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "### eth_accounts\n\nReturns a list of addresses owned by the client. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_accounts){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_accounts\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_accounts\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 3, "depth": 3, "title": "eth_blockNumber", "anchor": "eth_blocknumber", "start_char": 1140, "end_char": 1582, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### eth_blockNumber\n\nReturns the number of the most recent block. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_blocknumber){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_blockNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_blockNumber\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 4, "depth": 3, "title": "eth_call", "anchor": "eth_call", "start_char": 1582, "end_char": 3833, "estimated_token_count": 725, "token_estimator": "heuristic-v1", "text": "### eth_call\n\nExecutes a new message call immediately without creating a transaction. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_call){target=\\_blank}.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction call object.\n    - **`to` ++\"string\"++**: Recipient address of the call. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: Hash of the method signature and encoded parameters. Must be a [data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`from` ++\"string\"++**: (Optional) Sender's address for the call. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (Optional) Gas limit to execute the call. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit of gas. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Value in wei to send with the call. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) Block tag or block number to execute the call at. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_call\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_call\",\n    \"params\":[{\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"data\": \"INSERT_ENCODED_CALL\"\n    }, \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_RECIPIENT_ADDRESS`, `INSERT_ENCODED_CALL`, and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 5, "depth": 3, "title": "eth_chainId", "anchor": "eth_chainid", "start_char": 3833, "end_char": 4266, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### eth_chainId\n\nReturns the chain ID used for signing transactions. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_chainid){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_chainId\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_chainId\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 6, "depth": 3, "title": "eth_estimateGas", "anchor": "eth_estimategas", "start_char": 4266, "end_char": 6479, "estimated_token_count": 712, "token_estimator": "heuristic-v1", "text": "### eth_estimateGas\n\nEstimates gas required for a transaction. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_estimategas){target=\\_blank}.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction call object.\n    - **`to` ++\"string\"++**: Recipient address of the call. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: Hash of the method signature and encoded parameters. Must be a [data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`from` ++\"string\"++**: (Optional) Sender's address for the call. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (Optional) Gas limit to execute the call. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit of gas. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Value in wei to send with the call. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) Block tag or block number to execute the call at. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_estimateGas\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_estimateGas\",\n    \"params\":[{\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"data\": \"INSERT_ENCODED_FUNCTION_CALL\"\n    }],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_RECIPIENT_ADDRESS` and `INSERT_ENCODED_CALL` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 7, "depth": 3, "title": "eth_gasPrice", "anchor": "eth_gasprice", "start_char": 6479, "end_char": 6902, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "### eth_gasPrice\n\nReturns the current gas price in Wei. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gasprice){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_gasPrice\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_gasPrice\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 8, "depth": 3, "title": "eth_getBalance", "anchor": "eth_getbalance", "start_char": 6902, "end_char": 7956, "estimated_token_count": 338, "token_estimator": "heuristic-v1", "text": "### eth_getBalance\n\nReturns the balance of a given address. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getbalance){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Address to query balance. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_getBalance\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBalance\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS` and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 9, "depth": 3, "title": "eth_getBlockByHash", "anchor": "eth_getblockbyhash", "start_char": 7956, "end_char": 8857, "estimated_token_count": 270, "token_estimator": "heuristic-v1", "text": "### eth_getBlockByHash\n\nReturns information about a block by its hash. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getblockbyhash){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockHash` ++\"string\"++**: The hash of the block to retrieve. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`fullTransactions` ++\"boolean\"++**: If `true`, returns full transaction details; if `false`, returns only transaction hashes.\n\n**Example**:\n\n```bash title=\"eth_getBlockByHash\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockByHash\",\n    \"params\":[\"INSERT_BLOCK_HASH\", INSERT_BOOLEAN],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_HASH` and `INSERT_BOOLEAN` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 10, "depth": 3, "title": "eth_getBlockByNumber", "anchor": "eth_getblockbynumber", "start_char": 8857, "end_char": 9885, "estimated_token_count": 307, "token_estimator": "heuristic-v1", "text": "### eth_getBlockByNumber\n\nReturns information about a block by its number. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getblockbynumber){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`fullTransactions` ++\"boolean\"++**: If `true`, returns full transaction details; if `false`, returns only transaction hashes.\n\n**Example**:\n\n```bash title=\"eth_getBlockByNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockByNumber\",\n    \"params\":[\"INSERT_BLOCK_VALUE\", INSERT_BOOLEAN],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_VALUE` and `INSERT_BOOLEAN` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 11, "depth": 3, "title": "eth_getBlockTransactionCountByNumber", "anchor": "eth_getblocktransactioncountbynumber", "start_char": 9885, "end_char": 10817, "estimated_token_count": 266, "token_estimator": "heuristic-v1", "text": "### eth_getBlockTransactionCountByNumber\n\nReturns the number of transactions in a block from a block number. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getblocktransactioncountbynumber){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_getBlockTransactionCountByNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockTransactionCountByNumber\",\n    \"params\":[\"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 12, "depth": 3, "title": "eth_getBlockTransactionCountByHash", "anchor": "eth_getblocktransactioncountbyhash", "start_char": 10817, "end_char": 11633, "estimated_token_count": 232, "token_estimator": "heuristic-v1", "text": "### eth_getBlockTransactionCountByHash\n\nReturns the number of transactions in a block from a block hash. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getblocktransactioncountbyhash){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockHash` ++\"string\"++**: The hash of the block to retrieve. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getBlockTransactionCountByHash\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockTransactionCountByHash\",\n    \"params\":[\"INSERT_BLOCK_HASH\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_HASH` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 13, "depth": 3, "title": "eth_getCode", "anchor": "eth_getcode", "start_char": 11633, "end_char": 12673, "estimated_token_count": 335, "token_estimator": "heuristic-v1", "text": "### eth_getCode\n\nReturns the code at a given address. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getcode){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Contract or account address to query code. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block).\n\n**Example**:\n\n```bash title=\"eth_getCode\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getCode\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS` and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 14, "depth": 3, "title": "eth_getLogs", "anchor": "eth_getlogs", "start_char": 12673, "end_char": 14648, "estimated_token_count": 646, "token_estimator": "heuristic-v1", "text": "### eth_getLogs\n\nReturns an array of all logs matching a given filter object. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getlogs){target=\\_blank}.\n\n**Parameters**:\n\n- **`filter` ++\"object\"++**: The filter object.\n    - **`fromBlock` ++\"string\"++**: (Optional) Block number or tag to start from. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n    - **`toBlock` ++\"string\"++**: (Optional) Block number or tag to end at. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n    - **`address` ++\"string\" or \"array of strings\"++**: (Optional) Contract address or a list of addresses from which to get logs. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`topics` ++\"array of strings\"++**: (Optional) Array of topics for filtering logs. Each topic can be a single [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string or an array of such strings (meaning OR).\n    - **`blockhash` ++\"string\"++**: (Optional) Hash of a specific block. Cannot be used with `fromBlock` or `toBlock`. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getLogs\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getLogs\",\n    \"params\":[{\n        \"fromBlock\": \"latest\",\n        \"toBlock\": \"latest\"\n    }],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 15, "depth": 3, "title": "eth_getStorageAt", "anchor": "eth_getstorageat", "start_char": 14648, "end_char": 15975, "estimated_token_count": 412, "token_estimator": "heuristic-v1", "text": "### eth_getStorageAt\n\nReturns the value from a storage position at a given address. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getstorageat){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Contract or account address to query code. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`storageKey` ++\"string\"++**: Position in storage to retrieve data from. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block).\n\n**Example**:\n\n```bash title=\"eth_getStorageAt\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getStorageAt\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_STORAGE_KEY\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS`, `INSERT_STORAGE_KEY`, and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 16, "depth": 3, "title": "eth_getTransactionCount", "anchor": "eth_gettransactioncount", "start_char": 15975, "end_char": 17074, "estimated_token_count": 337, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionCount\n\nReturns the number of transactions sent from an address (nonce). [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactioncount){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Address to query balance. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block).\n\n**Example**:\n\n```bash title=\"eth_getTransactionCount\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionCount\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS` and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 17, "depth": 3, "title": "eth_getTransactionByHash", "anchor": "eth_gettransactionbyhash", "start_char": 17074, "end_char": 17850, "estimated_token_count": 226, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionByHash\n\nReturns information about a transaction by its hash. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactionbyhash){target=\\_blank}.\n\n**Parameters**:\n\n- **`transactionHash` ++\"string\"++**: The hash of the transaction. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionByHash\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionByHash\",\n    \"params\":[\"INSERT_TRANSACTION_HASH\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_TRANSACTION_HASH` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 18, "depth": 3, "title": "eth_getTransactionByBlockNumberAndIndex", "anchor": "eth_gettransactionbyblocknumberandindex", "start_char": 17850, "end_char": 19068, "estimated_token_count": 338, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionByBlockNumberAndIndex\n\nReturns information about a transaction by block number and transaction index. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactionbyblocknumberandindex){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: The block value to be fetched. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`transactionIndex` ++\"string\"++**: The index of the transaction in the block. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionByBlockNumberAndIndex\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionByBlockNumberAndIndex\",\n    \"params\":[\"INSERT_BLOCK_VALUE\", \"INSERT_TRANSACTION_INDEX\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_VALUE` and `INSERT_TRANSACTION_INDEX` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 19, "depth": 3, "title": "eth_getTransactionByBlockHashAndIndex", "anchor": "eth_gettransactionbyblockhashandindex", "start_char": 19068, "end_char": 20158, "estimated_token_count": 302, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionByBlockHashAndIndex\n\nReturns information about a transaction by block hash and transaction index. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactionbyblockhashandindex){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockHash` ++\"string\"++**: The hash of the block. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`transactionIndex` ++\"string\"++**: The index of the transaction in the block. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionByBlockHashAndIndex\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionByBlockHashAndIndex\",\n    \"params\":[\"INSERT_BLOCK_HASH\", \"INSERT_TRANSACTION_INDEX\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_HASH` and `INSERT_TRANSACTION_INDEX` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 20, "depth": 3, "title": "eth_getTransactionReceipt", "anchor": "eth_gettransactionreceipt", "start_char": 20158, "end_char": 20943, "estimated_token_count": 227, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionReceipt\n\nReturns the receipt of a transaction by transaction hash. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactionreceipt){target=\\_blank}.\n\n**Parameters**:\n\n- **`transactionHash` ++\"string\"++**: The hash of the transaction. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionReceipt\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionReceipt\",\n    \"params\":[\"INSERT_TRANSACTION_HASH\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_TRANSACTION_HASH` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 21, "depth": 3, "title": "eth_maxPriorityFeePerGas", "anchor": "eth_maxpriorityfeepergas", "start_char": 20943, "end_char": 21358, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "### eth_maxPriorityFeePerGas\n\nReturns an estimate of the current priority fee per gas, in Wei, to be included in a block.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_maxPriorityFeePerGas\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_maxPriorityFeePerGas\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 22, "depth": 3, "title": "eth_sendRawTransaction", "anchor": "eth_sendrawtransaction", "start_char": 21358, "end_char": 22067, "estimated_token_count": 218, "token_estimator": "heuristic-v1", "text": "### eth_sendRawTransaction\n\nSubmits a raw transaction. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_sendrawtransaction){target=\\_blank}.\n\n**Parameters**:\n\n- **`callData` ++\"string\"++**: Signed transaction data. Must be a [data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_sendRawTransaction\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_sendRawTransaction\",\n    \"params\":[\"INSERT_CALL_DATA\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_CALL_DATA` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 23, "depth": 3, "title": "eth_sendTransaction", "anchor": "eth_sendtransaction", "start_char": 22067, "end_char": 24446, "estimated_token_count": 730, "token_estimator": "heuristic-v1", "text": "### eth_sendTransaction\n\nCreates and sends a new transaction. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_sendtransaction){target=\\_blank}.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction object.\n    - **`from` ++\"string\"++**: Address sending the transaction. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`to` ++\"string\"++**: (Optional) Recipient address. No need to provide this value when deploying a contract. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (optional, default: `90000`) gas limit for execution. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Amount of Ether to send. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: (Optional) Contract bytecode or encoded method call. Must be a [data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`nonce` ++\"string\"++**: (Optional) Transaction nonce. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_sendTransaction\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_sendTransaction\",\n    \"params\":[{\n        \"from\": \"INSERT_SENDER_ADDRESS\",\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"gas\": \"INSERT_GAS_LIMIT\",\n        \"gasPrice\": \"INSERT_GAS_PRICE\",\n        \"value\": \"INSERT_VALUE\",\n        \"input\": \"INSERT_INPUT_DATA\",\n        \"nonce\": \"INSERT_NONCE\"\n    }],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_SENDER_ADDRESS`, `INSERT_RECIPIENT_ADDRESS`, `INSERT_GAS_LIMIT`, `INSERT_GAS_PRICE`, `INSERT_VALUE`, `INSERT_INPUT_DATA`, and `INSERT_NONCE` with the proper values.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 24, "depth": 3, "title": "eth_syncing", "anchor": "eth_syncing", "start_char": 24446, "end_char": 24890, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "### eth_syncing\n\nReturns an object with syncing data or `false` if not syncing. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_syncing){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_syncing\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_syncing\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 25, "depth": 3, "title": "net_listening", "anchor": "net_listening", "start_char": 24890, "end_char": 25375, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "### net_listening\n\nReturns `true` if the client is currently listening for network connections, otherwise `false`. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#net_listening){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"net_listening\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"net_listening\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 26, "depth": 3, "title": "net_peerCount", "anchor": "net_peercount", "start_char": 25375, "end_char": 25728, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "### net_peerCount\n\nReturns the number of peers currently connected to the client.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"net_peerCount\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"net_peerCount\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 27, "depth": 3, "title": "net_version", "anchor": "net_version", "start_char": 25728, "end_char": 26153, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### net_version\n\nReturns the current network ID as a string. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#net_version){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"net_version\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"net_version\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 28, "depth": 3, "title": "system_health", "anchor": "system_health", "start_char": 26153, "end_char": 26495, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "### system_health\n\nReturns information about the health of the system.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"system_health\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"system_health\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 29, "depth": 3, "title": "web3_clientVersion", "anchor": "web3_clientversion", "start_char": 26495, "end_char": 26940, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### web3_clientVersion\n\nReturns the current client version. [Reference](https://ethereum.org/en/developers/docs/apis/json-rpc/#web3_clientversion){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"web3_clientVersion\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"web3_clientVersion\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 30, "depth": 3, "title": "debug_traceBlockByNumber", "anchor": "debug_traceblockbynumber", "start_char": 26940, "end_char": 28022, "estimated_token_count": 328, "token_estimator": "heuristic-v1", "text": "### debug_traceBlockByNumber \n\nTraces a block's execution by its number and returns a detailed execution trace for each transaction.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: The block number or tag to trace. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`options` ++\"object\"++**: (Optional) An object containing tracer options.\n    - **`tracer` ++\"string\"++**: The name of the tracer to use (e.g., `\"callTracer\"`, `\"opTracer\"`).\n    - Other tracer-specific options may be supported.\n\n**Example**:\n\n```bash title=\"debug_traceBlockByNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"debug_traceBlockByNumber\",\n    \"params\":[\"INSERT_BLOCK_VALUE\", {\"tracer\": \"callTracer\"}],\n    \"id\":1\n}'\n```\n\nEnsure to replace `INSERT_BLOCK_VALUE` with a proper block number if needed.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 31, "depth": 3, "title": "debug_traceTransaction", "anchor": "debug_tracetransaction", "start_char": 28022, "end_char": 28869, "estimated_token_count": 251, "token_estimator": "heuristic-v1", "text": "### debug_traceTransaction\n\nTraces the execution of a single transaction by its hash and returns a detailed execution trace.\n\n**Parameters**:\n\n- **`transactionHash` ++\"string\"++**: The hash of the transaction to trace. Must be a [32 byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`options` ++\"object\"++**: (Optional) An object containing tracer options (e.g., `tracer: \"callTracer\"`).\n\n**Example**:\n\n```bash title=\"debug_traceTransaction\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"debug_traceTransaction\",\n    \"params\":[\"INSERT_TRANSACTION_HASH\", {\"tracer\": \"callTracer\"}],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_TRANSACTION_HASH` with the proper value.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 32, "depth": 3, "title": "debug_traceCall", "anchor": "debug_tracecall", "start_char": 28869, "end_char": 31326, "estimated_token_count": 767, "token_estimator": "heuristic-v1", "text": "### debug_traceCall\n\nExecutes a new message call and returns a detailed execution trace without creating a transaction on the blockchain.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction call object, similar to `eth_call` parameters.\n    - **`to` ++\"string\"++**: Recipient address of the call. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: Hash of the method signature and encoded parameters. Must be a [data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`from` ++\"string\"++**: (Optional) Sender's address for the call. Must be a [20-byte data](https://ethereum.org/en/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (Optional) Gas limit to execute the call. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit of gas. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Value in wei to send with the call. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) Block tag or block number to execute the call at. Must be a [quantity](https://ethereum.org/en/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/en/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`options` ++\"object\"++**: (Optional) An object containing tracer options (e.g., `tracer: \"callTracer\"`).\n\n**Example**:\n\n```bash title=\"debug_traceCall\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"debug_traceCall\",\n    \"params\":[{\n        \"from\": \"INSERT_SENDER_ADDRESS\",\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"data\": \"INSERT_ENCODED_CALL\"\n    }, \"INSERT_BLOCK_VALUE\", {\"tracer\": \"callTracer\"}],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_SENDER_ADDRESS`, `INSERT_RECIPIENT_ADDRESS`, `INSERT_ENCODED_CALL`, and `INSERT_BLOCK_VALUE` with the proper value.\n\n---"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 33, "depth": 2, "title": "Response Format", "anchor": "response-format", "start_char": 31326, "end_char": 31509, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Response Format\n\nAll responses follow the standard JSON-RPC 2.0 format:\n\n```json\n{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"result\": ... // The return value varies by method\n}\n```"}
{"page_id": "develop-smart-contracts-json-rpc-apis", "index": 34, "depth": 2, "title": "Error Handling", "anchor": "error-handling", "start_char": 31509, "end_char": 31728, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "## Error Handling\n\nIf an error occurs, the response will include an error object:\n\n```json\n{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"error\": {\n        \"code\": -32000,\n        \"message\": \"Error message here\"\n    }\n}\n```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 185, "end_char": 711, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Ethers.js](https://docs.ethers.org/v6/){target=\\_blank} is a lightweight library that enables interaction with Ethereum Virtual Machine (EVM)-compatible blockchains through JavaScript. Ethers is widely used as a toolkit to establish connections and read and write blockchain data. This article demonstrates using Ethers.js to interact and deploy smart contracts to Polkadot Hub.\n\nThis guide is intended for developers who are familiar with JavaScript and want to interact with Polkadot Hub using Ethers.js."}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 711, "end_char": 1067, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following installed:\n\n- **Node.js**: v22.13.1 or later, check the [Node.js installation guide](https://nodejs.org/en/download/current/){target=\\_blank}.\n- **npm**: v6.13.4 or later (comes bundled with Node.js).\n- **Solidity**: This guide uses Solidity `^0.8.9` for smart contract development."}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 2, "depth": 2, "title": "Project Structure", "anchor": "project-structure", "start_char": 1067, "end_char": 1579, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "## Project Structure\n\nThis project organizes contracts, scripts, and compiled artifacts for easy development and deployment.\n\n```text title=\"Ethers.js Polkadot Hub\"\nethers-project\n├── contracts\n│   ├── Storage.sol\n├── scripts\n│   ├── connectToProvider.js\n│   ├── fetchLastBlock.js\n│   ├── compile.js\n│   ├── deploy.js\n│   ├── checkStorage.js\n├── abis\n│   ├── Storage.json\n├── artifacts\n│   ├── Storage.polkavm\n├── contract-address.json\n├── node_modules/\n├── package.json\n├── package-lock.json\n└── README.md\n```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1579, "end_char": 1800, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nTo start working with Ethers.js, create a new folder and initialize your project by running the following commands in your terminal:\n\n```bash\nmkdir ethers-project\ncd ethers-project\nnpm init -y\n```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 4, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 1800, "end_char": 1924, "estimated_token_count": 28, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nNext, run the following command to install the Ethers.js library:\n\n```bash\nnpm install ethers\n```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 5, "depth": 2, "title": "Set Up the Ethers.js Provider", "anchor": "set-up-the-ethersjs-provider", "start_char": 1924, "end_char": 4410, "estimated_token_count": 576, "token_estimator": "heuristic-v1", "text": "## Set Up the Ethers.js Provider\n\nA [`Provider`](https://docs.ethers.org/v6/api/providers/#Provider){target=\\_blank} is an abstraction of a connection to the Ethereum network, allowing you to query blockchain data and send transactions. It serves as a bridge between your application and the blockchain.\n\nTo interact with Polkadot Hub, you must set up an Ethers.js provider. This provider connects to a blockchain node, allowing you to query blockchain data and interact with smart contracts. In the root of your project, create a file named `connectToProvider.js` and add the following code:\n\n```js title=\"scripts/connectToProvider.js\"\n-const { JsonRpcProvider } = require('ethers');\n\nconst createProvider = (rpcUrl, chainId, chainName) => {\n  const provider = new JsonRpcProvider(rpcUrl, {\n    chainId: chainId,\n    name: chainName,\n  });\n\n  return provider;\n};\n\nconst PROVIDER_RPC = {\n  rpc: 'INSERT_RPC_URL',\n  chainId: 'INSERT_CHAIN_ID',\n  name: 'INSERT_CHAIN_NAME',\n};\n\ncreateProvider(PROVIDER_RPC.rpc, PROVIDER_RPC.chainId, PROVIDER_RPC.name);\n\n```\n\n!!! note\n    Replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, and `INSERT_CHAIN_NAME` with the appropriate values. For example, to connect to Polkadot Hub TestNet's Ethereum RPC instance, you can use the following parameters:\n\n    ```js\n    const PROVIDER_RPC = {\n        rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n        chainId: 420420422,\n        name: 'polkadot-hub-testnet'\n    };\n    ```\n\nTo connect to the provider, execute:\n\n```bash\nnode connectToProvider\n```\n\nWith the provider set up, you can start querying the blockchain. For instance, to fetch the latest block number:\n\n??? code \"Fetch Last Block code\"\n\n    ```js title=\"scripts/fetchLastBlock.js\"\n    -const { JsonRpcProvider } = require('ethers');\n\nconst createProvider = (rpcUrl, chainId, chainName) => {\n  const provider = new JsonRpcProvider(rpcUrl, {\n    chainId: chainId,\n    name: chainName,\n  });\n\n  return provider;\n};\n\nconst PROVIDER_RPC = {\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n  name: 'polkadot-hub-testnet',\n};\n\nconst main = async () => {\n  try {\n    const provider = createProvider(\n      PROVIDER_RPC.rpc,\n      PROVIDER_RPC.chainId,\n      PROVIDER_RPC.name,\n    );\n    const latestBlock = await provider.getBlockNumber();\n    console.log(`Latest block: ${latestBlock}`);\n  } catch (error) {\n    console.error('Error connecting to Polkadot Hub TestNet: ' + error.message);\n  }\n};\n\nmain();\n\n    ```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 6, "depth": 2, "title": "Compile Contracts", "anchor": "compile-contracts", "start_char": 4410, "end_char": 5139, "estimated_token_count": 156, "token_estimator": "heuristic-v1", "text": "## Compile Contracts\n\n-!!! note \"Contracts Code Blob Size Disclaimer\"\n    The maximum contract code blob size on Polkadot Hub networks is _100 kilobytes_, significantly larger than Ethereum’s EVM limit of 24 kilobytes.\n\n    For detailed comparisons and migration guidelines, see the [EVM vs. PolkaVM](/polkadot-protocol/smart-contract-basics/evm-vs-polkavm/#current-memory-limits){target=\\_blank} documentation page.\n\n\nThe `revive` compiler transforms Solidity smart contracts into [PolkaVM](/develop/smart-contracts/overview#native-smart-contracts){target=\\_blank} bytecode for deployment on Polkadot Hub. Revive's Ethereum RPC interface allows you to use familiar tools like Ethers.js and MetaMask to interact with contracts."}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 7, "depth": 3, "title": "Install the Revive Library", "anchor": "install-the-revive-library", "start_char": 5139, "end_char": 5499, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "### Install the Revive Library\n\nThe [`@parity/resolc`](https://www.npmjs.com/package/@parity/resolc){target=\\_blank} library will compile your Solidity code for deployment on Polkadot Hub. Run the following command in your terminal to install the library:\n\n```bash\nnpm install --save-dev @parity/resolc \n```\n\nThis guide uses `@parity/resolc` version `0.2.0`."}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 8, "depth": 3, "title": "Sample Storage Smart Contract", "anchor": "sample-storage-smart-contract", "start_char": 5499, "end_char": 6325, "estimated_token_count": 172, "token_estimator": "heuristic-v1", "text": "### Sample Storage Smart Contract\n\nThis example demonstrates compiling a `Storage.sol` Solidity contract for deployment to Polkadot Hub. The contract's functionality stores a number and permits users to update it with a new value.\n\n```solidity title=\"contracts/Storage.sol\"\n-//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 9, "depth": 3, "title": "Compile the Smart Contract", "anchor": "compile-the-smart-contract", "start_char": 6325, "end_char": 8815, "estimated_token_count": 568, "token_estimator": "heuristic-v1", "text": "### Compile the Smart Contract\n\nTo compile this contract, use the following script:\n\n```js title=\"scripts/compile.js\"\n-const { compile } = require('@parity/resolc');\nconst { readFileSync, writeFileSync } = require('fs');\nconst { basename, join } = require('path');\n\nconst compileContract = async (solidityFilePath, outputDir) => {\n  try {\n    // Read the Solidity file\n    const source = readFileSync(solidityFilePath, 'utf8');\n\n    // Construct the input object for the compiler\n    const input = {\n      [basename(solidityFilePath)]: { content: source },\n    };\n\n    console.log(`Compiling contract: ${basename(solidityFilePath)}...`);\n\n    // Compile the contract\n    const out = await compile(input);\n\n    for (const contracts of Object.values(out.contracts)) {\n      for (const [name, contract] of Object.entries(contracts)) {\n        console.log(`Compiled contract: ${name}`);\n\n        // Write the ABI\n        const abiPath = join(outputDir, `${name}.json`);\n        writeFileSync(abiPath, JSON.stringify(contract.abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n\n        // Write the bytecode\n        const bytecodePath = join(outputDir, `${name}.polkavm`);\n        writeFileSync(\n          bytecodePath,\n          Buffer.from(contract.evm.bytecode.object, 'hex'),\n        );\n        console.log(`Bytecode saved to ${bytecodePath}`);\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath = join(__dirname, '../contracts/Storage.sol');\nconst outputDir = join(__dirname, '../contracts');\n\ncompileContract(solidityFilePath, outputDir);\n\n```\n\n!!! note \n     The script above is tailored to the `Storage.sol` contract. It can be adjusted for other contracts by changing the file name or modifying the ABI and bytecode paths.\n\nThe ABI (Application Binary Interface) is a JSON representation of your contract's functions, events, and their parameters. It serves as the interface between your JavaScript code and the deployed smart contract, allowing your application to know how to format function calls and interpret returned data.\n\nExecute the script above by running:\n\n```bash\nnode compile\n```\n\nAfter executing the script, the Solidity contract will be compiled into the required PolkaVM bytecode format. The ABI and bytecode will be saved into files with `.json` and `.polkavm` extensions, respectively. You can now proceed with deploying the contract to Polkadot Hub, as outlined in the next section."}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 10, "depth": 2, "title": "Deploy the Compiled Contract", "anchor": "deploy-the-compiled-contract", "start_char": 8815, "end_char": 15868, "estimated_token_count": 1610, "token_estimator": "heuristic-v1", "text": "## Deploy the Compiled Contract\n\nTo deploy your compiled contract to Polkadot Hub, you'll need a wallet with a private key to sign the deployment transaction.\n\nYou can create a `deploy.js` script in the root of your project to achieve this. The deployment script can be divided into key components:\n\n1. Set up the required imports and utilities:\n\n    ```js title=\"scripts/deploy.js\"\n    -// Deploy an EVM-compatible smart contract using ethers.js\nconst { writeFileSync, existsSync, readFileSync } = require('fs');\nconst { join } = require('path');\nconst { ethers, JsonRpcProvider } = require('ethers');\n\nconst codegenDir = join(__dirname);\n    ```\n\n2. Create a provider to connect to Polkadot Hub:\n\n    ```js title=\"scripts/deploy.js\"\n    -\n// Creates an Ethereum provider with specified RPC URL and chain details\nconst createProvider = (rpcUrl, chainId, chainName) => {\n  const provider = new JsonRpcProvider(rpcUrl, {\n    chainId: chainId,\n    name: chainName,\n  });\n  return provider;\n};\n    ```\n \n3. Set up functions to read contract artifacts:\n\n    ```js title=\"scripts/deploy.js\"\n    -// Reads and parses the ABI file for a given contract\nconst getAbi = (contractName) => {\n  try {\n    return JSON.parse(\n      readFileSync(join(codegenDir, `${contractName}.json`), 'utf8'),\n    );\n  } catch (error) {\n    console.error(\n      `Could not find ABI for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n\n// Reads the compiled bytecode for a given contract\nconst getByteCode = (contractName) => {\n  try {\n    const bytecodePath = join(\n      codegenDir,\n      '../contracts',\n      `${contractName}.polkavm`,\n    );\n    return `0x${readFileSync(bytecodePath).toString('hex')}`;\n  } catch (error) {\n    console.error(\n      `Could not find bytecode for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n    ```\n\n4. Create the main deployment function:\n\n    ```js title=\"scripts/deploy.js\"\n    -\nconst deployContract = async (contractName, mnemonic, providerConfig) => {\n  console.log(`Deploying ${contractName}...`);\n\n  try {\n    // Step 1: Set up provider and wallet\n    const provider = createProvider(\n      providerConfig.rpc,\n      providerConfig.chainId,\n      providerConfig.name,\n    );\n    const walletMnemonic = ethers.Wallet.fromPhrase(mnemonic);\n    const wallet = walletMnemonic.connect(provider);\n\n    // Step 2: Create and deploy the contract\n    const factory = new ethers.ContractFactory(\n      getAbi(contractName),\n      getByteCode(contractName),\n      wallet,\n    );\n    const contract = await factory.deploy();\n    await contract.waitForDeployment();\n\n    // Step 3: Save deployment information\n    const address = await contract.getAddress();\n    console.log(`Contract ${contractName} deployed at: ${address}`);\n\n    const addressesFile = join(codegenDir, 'contract-address.json');\n    const addresses = existsSync(addressesFile)\n      ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n      : {};\n    addresses[contractName] = address;\n    writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n  } catch (error) {\n    console.error(`Failed to deploy contract ${contractName}:`, error);\n  }\n};\n    ```\n\n5. Configure and execute the deployment:\n\n    ```js title=\"scripts/deploy.js\"\n    -const providerConfig = {\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n  name: 'polkadot-hub-testnet',\n};\n\nconst mnemonic = 'INSERT_MNEMONIC';\n\ndeployContract('Storage', mnemonic, providerConfig);\n    ```\n\n    !!! note\n        A mnemonic (seed phrase) is a series of words that can generate multiple private keys and their corresponding addresses. It's used here to derive the wallet that will sign and pay for the deployment transaction. **Always keep your mnemonic secure and never share it publicly**.\n\n        Ensure to replace the `INSERT_MNEMONIC` placeholder with your actual mnemonic.\n\n??? code \"View complete script\"\n\n    ```js title=\"scripts/deploy.js\"\n    -// Deploy an EVM-compatible smart contract using ethers.js\nconst { writeFileSync, existsSync, readFileSync } = require('fs');\nconst { join } = require('path');\nconst { ethers, JsonRpcProvider } = require('ethers');\n\nconst codegenDir = join(__dirname);\n\n// Creates an Ethereum provider with specified RPC URL and chain details\nconst createProvider = (rpcUrl, chainId, chainName) => {\n  const provider = new JsonRpcProvider(rpcUrl, {\n    chainId: chainId,\n    name: chainName,\n  });\n  return provider;\n};\n\n// Reads and parses the ABI file for a given contract\nconst getAbi = (contractName) => {\n  try {\n    return JSON.parse(\n      readFileSync(join(codegenDir, `${contractName}.json`), 'utf8'),\n    );\n  } catch (error) {\n    console.error(\n      `Could not find ABI for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n\n// Reads the compiled bytecode for a given contract\nconst getByteCode = (contractName) => {\n  try {\n    const bytecodePath = join(\n      codegenDir,\n      '../contracts',\n      `${contractName}.polkavm`,\n    );\n    return `0x${readFileSync(bytecodePath).toString('hex')}`;\n  } catch (error) {\n    console.error(\n      `Could not find bytecode for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n\nconst deployContract = async (contractName, mnemonic, providerConfig) => {\n  console.log(`Deploying ${contractName}...`);\n\n  try {\n    // Step 1: Set up provider and wallet\n    const provider = createProvider(\n      providerConfig.rpc,\n      providerConfig.chainId,\n      providerConfig.name,\n    );\n    const walletMnemonic = ethers.Wallet.fromPhrase(mnemonic);\n    const wallet = walletMnemonic.connect(provider);\n\n    // Step 2: Create and deploy the contract\n    const factory = new ethers.ContractFactory(\n      getAbi(contractName),\n      getByteCode(contractName),\n      wallet,\n    );\n    const contract = await factory.deploy();\n    await contract.waitForDeployment();\n\n    // Step 3: Save deployment information\n    const address = await contract.getAddress();\n    console.log(`Contract ${contractName} deployed at: ${address}`);\n\n    const addressesFile = join(codegenDir, 'contract-address.json');\n    const addresses = existsSync(addressesFile)\n      ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n      : {};\n    addresses[contractName] = address;\n    writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n  } catch (error) {\n    console.error(`Failed to deploy contract ${contractName}:`, error);\n  }\n};\n\nconst providerConfig = {\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n  name: 'polkadot-hub-testnet',\n};\n\nconst mnemonic = 'INSERT_MNEMONIC';\n\ndeployContract('Storage', mnemonic, providerConfig);\n\n    ```\n\nTo run the script, execute the following command:\n\n```bash\nnode deploy\n```\n\nAfter running this script, your contract will be deployed to Polkadot Hub, and its address will be saved in `contract-address.json` within your project directory. You can use this address for future contract interactions."}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 11, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 15868, "end_char": 19130, "estimated_token_count": 713, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nOnce the contract is deployed, you can interact with it by calling its functions. For example, to set a number, read it and then modify that number by its double, you can create a file named `checkStorage.js` in the root of your project and add the following code:\n\n```js title=\"scripts/checkStorage.js\"\n-const { ethers } = require('ethers');\nconst { readFileSync } = require('fs');\nconst { join } = require('path');\n\nconst createProvider = (providerConfig) => {\n  return new ethers.JsonRpcProvider(providerConfig.rpc, {\n    chainId: providerConfig.chainId,\n    name: providerConfig.name,\n  });\n};\n\nconst createWallet = (mnemonic, provider) => {\n  return ethers.Wallet.fromPhrase(mnemonic).connect(provider);\n};\n\nconst loadContractAbi = (contractName, directory = __dirname) => {\n  const contractPath = join(directory, `${contractName}.json`);\n  const contractJson = JSON.parse(readFileSync(contractPath, 'utf8'));\n  return contractJson.abi || contractJson; // Depending on JSON structure\n};\n\nconst createContract = (contractAddress, abi, wallet) => {\n  return new ethers.Contract(contractAddress, abi, wallet);\n};\n\nconst interactWithStorageContract = async (\n  contractName,\n  contractAddress,\n  mnemonic,\n  providerConfig,\n  numberToSet,\n) => {\n  try {\n    console.log(`Setting new number in Storage contract: ${numberToSet}`);\n\n    // Create provider and wallet\n    const provider = createProvider(providerConfig);\n    const wallet = createWallet(mnemonic, provider);\n\n    // Load the contract ABI and create the contract instance\n    const abi = loadContractAbi(contractName);\n    const contract = createContract(contractAddress, abi, wallet);\n\n    // Send a transaction to set the stored number\n    const tx1 = await contract.setNumber(numberToSet);\n    await tx1.wait(); // Wait for the transaction to be mined\n    console.log(`Number successfully set to ${numberToSet}`);\n\n    // Retrieve the updated number\n    const storedNumber = await contract.storedNumber();\n    console.log(`Retrieved stored number:`, storedNumber.toString());\n\n    // Send a transaction to set the stored number\n    const tx2 = await contract.setNumber(numberToSet * 2);\n    await tx2.wait(); // Wait for the transaction to be mined\n    console.log(`Number successfully set to ${numberToSet * 2}`);\n\n    // Retrieve the updated number\n    const updatedNumber = await contract.storedNumber();\n    console.log(`Retrieved stored number:`, updatedNumber.toString());\n  } catch (error) {\n    console.error('Error interacting with Storage contract:', error.message);\n  }\n};\n\nconst providerConfig = {\n  name: 'asset-hub-smart-contracts',\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n};\n\nconst mnemonic = 'INSERT_MNEMONIC';\nconst contractName = 'Storage';\nconst contractAddress = 'INSERT_CONTRACT_ADDRESS';\nconst newNumber = 42;\n\ninteractWithStorageContract(\n  contractName,\n  contractAddress,\n  mnemonic,\n  providerConfig,\n  newNumber,\n);\n\n```\n\nEnsure you replace the `INSERT_MNEMONIC`, `INSERT_CONTRACT_ADDRESS`, and `INSERT_ADDRESS_TO_CHECK` placeholders with actual values. Also, ensure the contract ABI file (`Storage.json`) is correctly referenced.\n\nTo interact with the contract, run:\n\n```bash\nnode checkStorage\n```"}
{"page_id": "develop-smart-contracts-libraries-ethers-js", "index": 12, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 19130, "end_char": 19735, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundational knowledge to use Ethers.js with Polkadot Hub, you can:\n\n- **Dive into Ethers.js utilities**: Discover additional Ethers.js features, such as wallet management, signing messages, etc.\n- **Implement batch transactions**: Use Ethers.js to execute batch transactions for efficient multi-step contract interactions.\n- **Build scalable applications**: Combine Ethers.js with frameworks like [`Next.js`](https://nextjs.org/docs){target=\\_blank} or [`Node.js`](https://nodejs.org/en){target=\\_blank} to create full-stack decentralized applications (dApps)."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 180, "end_char": 457, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[viem](https://viem.sh/){target=\\_blank} is a lightweight TypeScript library designed for interacting with Ethereum-compatible blockchains. This comprehensive guide will walk you through using viem to interact with and deploy smart contracts to Polkadot Hub."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 457, "end_char": 813, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following installed:\n\n- **Node.js**: v22.13.1 or later, check the [Node.js installation guide](https://nodejs.org/en/download/current/){target=\\_blank}.\n- **npm**: v6.13.4 or later (comes bundled with Node.js).\n- **Solidity**: This guide uses Solidity `^0.8.9` for smart contract development."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 2, "depth": 2, "title": "Project Structure", "anchor": "project-structure", "start_char": 813, "end_char": 1233, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Project Structure\n\nThis project organizes contracts, scripts, and compiled artifacts for easy development and deployment.\n\n```text\nviem-project/\n├── package.json\n├── tsconfig.json\n├── src/\n│   ├── chainConfig.ts\n│   ├── createClient.ts\n│   ├── createWallet.ts\n│   ├── compile.ts\n│   ├── deploy.ts\n│   └── interact.ts\n├── contracts/\n│   └── Storage.sol\n└── artifacts/\n    ├── Storage.json\n    └── Storage.polkavm\n```"}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1233, "end_char": 1373, "estimated_token_count": 36, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nFirst, create a new folder and initialize your project:\n\n```bash\nmkdir viem-project\ncd viem-project\nnpm init -y\n```"}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 4, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 1373, "end_char": 1865, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nInstall viem along with other necessary dependencies, including [@parity/resolc](https://www.npmjs.com/package/@parity/resolc){target=\\_blank}, which enables to compile smart contracts to [PolkaVM](/polkadot-protocol/smart-contract-basics/polkavm-design/#polkavm){target=\\_blank} bytecode:\n\n```bash\n# Install viem and resolc\nnpm install viem @parity/resolc\n\n# Install TypeScript and development dependencies\nnpm install --save-dev typescript ts-node @types/node\n```"}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 5, "depth": 2, "title": "Initialize Project", "anchor": "initialize-project", "start_char": 1865, "end_char": 2375, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "## Initialize Project\n\nInitialize a TypeScript project by running the following command:\n\n```bash\nnpx tsc --init\n```\n\nAdd the following scripts to your `package.json` file to enable running TypeScript files:\n\n```json\n{\n    \"scripts\": {\n        \"client\": \"ts-node src/createClient.ts\",\n        \"compile\": \"ts-node src/compile.ts\",\n        \"deploy\": \"ts-node src/deploy.ts\",\n        \"interact\": \"ts-node src/interact.ts\"\n    },\n}\n```\n\nCreate a directory for your TypeScript source files:\n\n```bash\nmkdir src\n```"}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 6, "depth": 2, "title": "Set Up the Chain Configuration", "anchor": "set-up-the-chain-configuration", "start_char": 2375, "end_char": 3350, "estimated_token_count": 211, "token_estimator": "heuristic-v1", "text": "## Set Up the Chain Configuration\n\nThe first step is to set up the chain configuration. Create a new file at `src/chainConfig.ts`:\n\n```typescript title=\"src/chainConfig.ts\"\n-import { http } from 'viem';\n\nexport const TRANSPORT = http('INSERT_RPC_URL');\n\n// Configure the Polkadot Hub chain\nexport const POLKADOT_HUB = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n```\n\nEnsure to replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, `INSERT_CHAIN_NAME`, `INSERT_NETWORK_NAME`, `INSERT_CHAIN_DECIMALS`, `INSERT_CURRENCY_NAME`, and `INSERT_CURRENCY_SYMBOL` with the proper values. Check the [Connect to Polkadot](/develop/smart-contracts/connect-to-polkadot){target=\\_blank} page for more information on the possible values."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 7, "depth": 2, "title": "Set Up the viem Client", "anchor": "set-up-the-viem-client", "start_char": 3350, "end_char": 5344, "estimated_token_count": 485, "token_estimator": "heuristic-v1", "text": "## Set Up the viem Client\n\nTo interact with the chain, you need to create a client that is used solely for reading data. To accomplish this, create a new file at `src/createClient.ts`:\n\n```typescript title=\"src/createClient.ts\"\n-import { createPublicClient, createWalletClient, http } from 'viem';\n\nconst transport = http('INSERT_RPC_URL');\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n\n// Create a public client for reading data\nexport const publicClient = createPublicClient({\n  chain: assetHub,\n  transport,\n});\n\n```\n\nAfter setting up the [Public Client](https://viem.sh/docs/clients/public#public-client){target=\\_blank}, you can begin querying the blockchain. Here's an example of fetching the latest block number:\n\n??? code \"Fetch Last Block code\"\n\n    ```js title=\"src/fetchLastBlock.ts\"\n    -import { createPublicClient, http } from 'viem';\n\nconst transport = http('https://testnet-passet-hub-eth-rpc.polkadot.io');\n\n// Configure the Polkadot Hub chain\nconst polkadotHubTestnet = {\n  id: 420420422,\n  name: 'Polkadot Hub TestNet',\n  network: 'polkadot-hub-testnet',\n  nativeCurrency: {\n    decimals: 18,\n    name: 'PAS',\n    symbol: 'PAS',\n  },\n  rpcUrls: {\n    default: {\n      http: ['https://testnet-passet-hub-eth-rpc.polkadot.io'],\n    },\n  },\n} as const;\n\n// Create a public client for reading data\nexport const publicClient = createPublicClient({\n  chain: polkadotHubTestnet,\n  transport,\n});\n\nconst main = async () => {\n  try {\n    const block = await publicClient.getBlock();\n    console.log('Last block: ' + block.number.toString());\n  } catch (error: unknown) {\n    console.error('Error connecting to Polkadot Hub TestNet: ' + error);\n  }\n};\n\nmain();\n    ```"}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 8, "depth": 2, "title": "Set Up a Wallet", "anchor": "set-up-a-wallet", "start_char": 5344, "end_char": 6702, "estimated_token_count": 300, "token_estimator": "heuristic-v1", "text": "## Set Up a Wallet\n\nIn case you need to sign transactions, you will need to instantiate a [Wallet Client](https://viem.sh/docs/clients/wallet#wallet-client){target=\\_blank} object within your project. To do so, create `src/createWallet.ts`:\n\n```typescript title=\"src/createWallet.ts\"\n-import { privateKeyToAccount } from 'viem/accounts';\nimport { createWalletClient, http } from 'viem';\n\nconst transport = http('INSERT_RPC_URL');\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n    public: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n\n// Create a wallet client for writing data\nexport const createWallet = (privateKey: `0x${string}`) => {\n  const account = privateKeyToAccount(privateKey);\n  return createWalletClient({\n    account,\n    chain: assetHub,\n    transport,\n  });\n};\n```\n\n!!!note\n    The wallet you import with your private key must have sufficient funds to pay for transaction fees when deploying contracts or interacting with them. Make sure to fund your wallet with the appropriate native tokens for the network you're connecting to."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 9, "depth": 2, "title": "Sample Smart Contract", "anchor": "sample-smart-contract", "start_char": 6702, "end_char": 7684, "estimated_token_count": 205, "token_estimator": "heuristic-v1", "text": "## Sample Smart Contract\n\nThis example demonstrates compiling a `Storage.sol` Solidity contract for deployment to Polkadot Hub. The contract's functionality stores a number and permits users to update it with a new value.\n\n```bash\nmkdir contracts artifacts\n```\n\nYou can use the following contract to interact with the blockchain. Paste the following contract in `contracts/Storage.sol`:\n\n```solidity title=\"contracts/Storage.sol\"\n-//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```"}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 10, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 7684, "end_char": 10411, "estimated_token_count": 623, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\n-!!! note \"Contracts Code Blob Size Disclaimer\"\n    The maximum contract code blob size on Polkadot Hub networks is _100 kilobytes_, significantly larger than Ethereum’s EVM limit of 24 kilobytes.\n\n    For detailed comparisons and migration guidelines, see the [EVM vs. PolkaVM](/polkadot-protocol/smart-contract-basics/evm-vs-polkavm/#current-memory-limits){target=\\_blank} documentation page.\n\n\nCreate a new file at `src/compile.ts` for handling contract compilation:\n\n```typescript title=\"src/compile.ts\"\n-import { compile } from '@parity/resolc';\nimport { readFileSync, writeFileSync } from 'fs';\nimport { basename, join } from 'path';\n\nconst compileContract = async (\n  solidityFilePath: string,\n  outputDir: string\n): Promise<void> => {\n  try {\n    // Read the Solidity file\n    const source: string = readFileSync(solidityFilePath, 'utf8');\n\n    // Construct the input object for the compiler\n    const input: Record<string, { content: string }> = {\n      [basename(solidityFilePath)]: { content: source },\n    };\n\n    console.log(`Compiling contract: ${basename(solidityFilePath)}...`);\n\n    // Compile the contract\n    const out = await compile(input);\n\n    for (const contracts of Object.values(out.contracts)) {\n      for (const [name, contract] of Object.entries(contracts)) {\n        console.log(`Compiled contract: ${name}`);\n\n        // Write the ABI\n        const abiPath = join(outputDir, `${name}.json`);\n        writeFileSync(abiPath, JSON.stringify(contract.abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n\n        // Write the bytecode\n        if (\n          contract.evm &&\n          contract.evm.bytecode &&\n          contract.evm.bytecode.object\n        ) {\n          const bytecodePath = join(outputDir, `${name}.polkavm`);\n          writeFileSync(\n            bytecodePath,\n            Buffer.from(contract.evm.bytecode.object, 'hex')\n          );\n          console.log(`Bytecode saved to ${bytecodePath}`);\n        } else {\n          console.warn(`No bytecode found for contract: ${name}`);\n        }\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath: string = './contracts/Storage.sol';\nconst outputDir: string = './artifacts/';\n\ncompileContract(solidityFilePath, outputDir);\n```\n\nTo compile your contract:\n\n```bash\nnpm run compile\n```\n\nAfter executing this script, you will see the compilation results including the generated `Storage.json` (containing the contract's ABI) and `Storage.polkavm` (containing the compiled bytecode) files in the `artifacts` folder. These files contain all the necessary information for deploying and interacting with your smart contract on Polkadot Hub."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 11, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 10411, "end_char": 12597, "estimated_token_count": 505, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nCreate a new file at `src/deploy.ts` for handling contract deployment:\n\n```typescript title=\"src/deploy.ts\"\n-import { readFileSync } from 'fs';\nimport { join } from 'path';\nimport { createWallet } from './createWallet';\nimport { publicClient } from './createClient';\n\nconst deployContract = async (\n  contractName: string,\n  privateKey: `0x${string}`\n) => {\n  try {\n    console.log(`Deploying ${contractName}...`);\n\n    // Read contract artifacts\n    const abi = JSON.parse(\n      readFileSync(\n        join(__dirname, '../artifacts', `${contractName}.json`),\n        'utf8'\n      )\n    );\n    const bytecode = `0x${readFileSync(\n      join(__dirname, '../artifacts', `${contractName}.polkavm`)\n    ).toString('hex')}` as `0x${string}`;\n\n    // Create wallet\n    const wallet = createWallet(privateKey);\n\n    // Deploy contract\n    const hash = await wallet.deployContract({\n      abi,\n      bytecode,\n      args: [], // Add constructor arguments if needed\n    });\n\n    // Wait for deployment\n    const receipt = await publicClient.waitForTransactionReceipt({ hash });\n    const contractAddress = receipt.contractAddress;\n\n    console.log(`Contract deployed at: ${contractAddress}`);\n    return contractAddress;\n  } catch (error) {\n    console.error('Deployment failed:', error);\n    throw error;\n  }\n};\n\nconst privateKey = 'INSERT_PRIVATE_KEY';\ndeployContract('Storage', privateKey);\n```\n\nEnsure to replace `INSERT_PRIVATE_KEY` with the proper value. For further details on private key exportation, refer to the article [How to export an account's private key](https://support.metamask.io/configure/accounts/how-to-export-an-accounts-private-key/){target=\\_blank}.\n\n!!! warning\n    Never commit or share your private key. Exposed keys can lead to immediate theft of all associated funds. Use environment variables instead.\n\nTo deploy, run the following command:\n\n```bash\nnpm run deploy\n```\n\nIf everything is successful, you will see the address of your deployed contract displayed in the terminal. This address is unique to your contract on the network you defined in the chain configuration, and you'll need it for any future interactions with your contract."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 12, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 12597, "end_char": 14764, "estimated_token_count": 456, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nCreate a new file at `src/interact.ts` for interacting with your deployed contract:\n\n```typescript title=\"src/interact.ts\"\n-import { publicClient } from './createClient';\nimport { createWallet } from './createWallet';\nimport { readFileSync } from 'fs';\n\nconst STORAGE_ABI = JSON.parse(\n  readFileSync('./artifacts/Storage.json', 'utf8')\n);\n\nconst interactWithStorage = async (\n  contractAddress: `0x${string}`,\n  privateKey: `0x${string}`\n) => {\n  try {\n    const wallet = createWallet(privateKey);\n    const currentNumber = await publicClient.readContract({\n      address: contractAddress,\n      abi: STORAGE_ABI,\n      functionName: 'storedNumber',\n      args: [],\n    });\n    console.log(`Stored number: ${currentNumber}`);\n\n    const newNumber = BigInt(42);\n    const { request } = await publicClient.simulateContract({\n      address: contractAddress,\n      abi: STORAGE_ABI,\n      functionName: 'setNumber',\n      args: [newNumber],\n      account: wallet.account,\n    });\n\n    const hash = await wallet.writeContract(request);\n    await publicClient.waitForTransactionReceipt({ hash });\n    console.log(`Number updated to ${newNumber}`);\n\n    const updatedNumber = await publicClient.readContract({\n      address: contractAddress,\n      abi: STORAGE_ABI,\n      functionName: 'storedNumber',\n      args: [],\n    });\n    console.log('Updated stored number:', updatedNumber);\n  } catch (error) {\n    console.error('Interaction failed:', error);\n  }\n};\n\nconst PRIVATE_KEY = 'INSERT_PRIVATE_KEY';\nconst CONTRACT_ADDRESS = 'INSERT_CONTRACT_ADDRESS';\n\ninteractWithStorage(CONTRACT_ADDRESS, PRIVATE_KEY);\n\n```\n\nEnsure to replace `INSERT_PRIVATE_KEY` and `INSERT_CONTRACT_ADDRESS` with the proper values.\n\nTo interact with the contract:\n\n```bash\nnpm run interact\n```\n\nFollowing a successful interaction, you will see the stored value before and after the transaction. The output will show the initial stored number (0 if you haven't modified it yet), confirm when the transaction to set the number to 42 is complete, and then display the updated stored number value. This demonstrates both reading from and writing to your smart contract."}
{"page_id": "develop-smart-contracts-libraries-viem", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 14764, "end_char": 16533, "estimated_token_count": 545, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundation for using viem with Polkadot Hub, consider exploring:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Advanced viem Features__\n\n    ---\n    Explore viem's documentation:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Multi call](https://viem.sh/docs/contract/multicall#multicall){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Batch transactions](https://viem.sh/docs/clients/transports/http#batch-json-rpc){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Custom actions](https://viem.sh/docs/clients/custom#extending-with-actions-or-configuration){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Test Frameworks__\n\n    ---\n\n    Integrate viem with the following frameworks for comprehensive testing:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Hardhat](https://hardhat.org/){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Foundry](https://getfoundry.sh/){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Event Handling__\n\n    ---\n\n    Learn how to subscribe to and process contract events:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Event subscription](https://viem.sh/docs/actions/public/watchEvent#watchevent){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Building dApps__\n\n    ---\n\n    Combine viem the following technologies to create full-stack applications:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Next.js](https://nextjs.org/docs){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Node.js](https://nodejs.org/en){target=\\_blank}</li>\n    </ul>\n\n</div>"}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 181, "end_char": 609, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Wagmi](https://wagmi.sh/){target=\\_blank} is a collection of [React Hooks](https://wagmi.sh/react/api/hooks){target=\\_blank} for interacting with Ethereum-compatible blockchains, focusing on developer experience, feature richness, and reliability.\n\nThis guide demonstrates how to use Wagmi to interact with and deploy smart contracts to Polkadot Hub, providing a seamless frontend integration for your dApps."}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 1, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 609, "end_char": 877, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nTo start working with Wagmi, create a new React project and initialize it by running the following commands in your terminal:\n\n```bash\n# Create a new React project using Next.js\nnpx create-next-app@latest wagmi-asset-hub\ncd wagmi-asset-hub\n```"}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 2, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 877, "end_char": 1039, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nInstall Wagmi and its peer dependencies:\n\n```bash\n# Install Wagmi and its dependencies\nnpm install wagmi viem @tanstack/react-query\n```"}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 3, "depth": 2, "title": "Configure Wagmi for Polkadot Hub", "anchor": "configure-wagmi-for-polkadot-hub", "start_char": 1039, "end_char": 2637, "estimated_token_count": 383, "token_estimator": "heuristic-v1", "text": "## Configure Wagmi for Polkadot Hub\n\nCreate a configuration file to initialize Wagmi with Polkadot Hub. In your project, create a file named `src/lib/wagmi.ts` and add the code below. Be sure to replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, `INSERT_CHAIN_NAME`, `INSERT_NETWORK_NAME`, `INSERT_CHAIN_DECIMALS`, `INSERT_CURRENCY_NAME`, and `INSERT_CURRENCY_SYMBOL` with your specific values.\n\n```typescript title=\"src/lib/wagmi.ts\"\n-import { http, createConfig } from 'wagmi'\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n\n// Create Wagmi config\nexport const config = createConfig({\n  chains: [assetHub],\n  transports: {\n    [assetHub.id]: http(),\n  },\n})\n```\n\n??? code \"Example Polkadot Hub TestNet Configuration\"\n\n    ```typescript title=\"src/lib/wagmi.ts\"\n    -import { http, createConfig } from 'wagmi';\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: 420420422,\n  name: 'polkadot-hub-testnet',\n  network: 'polkadot-hub-testnet',\n  nativeCurrency: {\n    decimals: 18,\n    name: 'PAS',\n    symbol: 'PAS',\n  },\n  rpcUrls: {\n    default: {\n      http: ['https://testnet-passet-hub-eth-rpc.polkadot.io'],\n    },\n  },\n} as const;\n\n// Create wagmi config\nexport const config = createConfig({\n  chains: [assetHub],\n  transports: {\n    [assetHub.id]: http(),\n  },\n});\n    ```"}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 4, "depth": 2, "title": "Set Up the Wagmi Provider", "anchor": "set-up-the-wagmi-provider", "start_char": 2637, "end_char": 3682, "estimated_token_count": 264, "token_estimator": "heuristic-v1", "text": "## Set Up the Wagmi Provider\n\nTo enable Wagmi in your React application, you need to wrap your app with the [`WagmiProvider`](https://wagmi.sh/react/api/WagmiProvider#wagmiprovider){target=\\_blank}. Update your `app/layout.tsx` file (for Next.js app router) with the following code:\n\n```typescript title=\"app/layout.tsx\"\n-// For app router (src/app/layout.tsx)\n\"use client\";\n\nimport { WagmiProvider } from \"wagmi\";\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { config } from \"./lib/wagmi\";\n\n// Create a query client\nconst queryClient = new QueryClient();\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body>\n        <WagmiProvider config={config}>\n          <QueryClientProvider client={queryClient}>\n            {children}\n          </QueryClientProvider>\n        </WagmiProvider>\n      </body>\n    </html>\n  );\n}\n\n```\n\n!!!note\n    If you are using a Next.js pages router, you should modify the `src/pages/_app.tsx` instead."}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 5, "depth": 2, "title": "Connect a Wallet", "anchor": "connect-a-wallet", "start_char": 3682, "end_char": 5134, "estimated_token_count": 368, "token_estimator": "heuristic-v1", "text": "## Connect a Wallet\n\nCreate a component to connect wallets to your dApp. Create a file named `app/components/ConnectWallet.tsx`:\n\n```typescript title=\"app/components/ConnectWallet.tsx\"\n-\"use client\";\n\nimport React from \"react\";\nimport { useConnect, useAccount, useDisconnect } from \"wagmi\";\nimport { injected } from \"wagmi/connectors\";\n\nexport function ConnectWallet() {\n  const { connect } = useConnect();\n  const { address, isConnected } = useAccount();\n  const { disconnect } = useDisconnect();\n\n  if (isConnected) {\n    return (\n      <div>\n        <div>Connected to {address}</div>\n        <button onClick={() => disconnect()}>Disconnect</button>\n      </div>\n    );\n  }\n\n  return (\n    <button onClick={() => connect({ connector: injected() })}>\n      Connect Wallet\n    </button>\n  );\n}\n\n```\n\nThis component uses the following React hooks:\n\n- **[`useConnect`](https://wagmi.sh/react/api/hooks/useConnect#useconnect){target=\\_blank}**: Provides functions and state for connecting the user's wallet to your dApp. The `connect` function initiates the connection flow with the specified connector.\n- **[`useDisconnect`](https://wagmi.sh/react/api/hooks/useDisconnect#usedisconnect){target=\\_blank}**: Provides a function to disconnect the currently connected wallet.\n- **[`useAccount`](https://wagmi.sh/react/api/hooks/useAccount#useaccount){target=\\_blank}**: Returns data about the connected account, including the address and connection status."}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 6, "depth": 2, "title": "Fetch Blockchain Data", "anchor": "fetch-blockchain-data", "start_char": 5134, "end_char": 6615, "estimated_token_count": 360, "token_estimator": "heuristic-v1", "text": "## Fetch Blockchain Data\n\nWagmi provides various hooks to fetch blockchain data. Here's an example component that demonstrates some of these hooks:\n\n```typescript title=\"app/components/BlockchainInfo.tsx\"\n-\"use client\";\n\nimport { useBlockNumber, useBalance, useAccount } from \"wagmi\";\n\nexport function BlockchainInfo() {\n  const { address } = useAccount();\n  // Get the latest block number\n  const { data: blockNumber } = useBlockNumber({ watch: true });\n\n  // Get balance for the connected wallet\n  const { data: balance } = useBalance({\n    address,\n  });\n\n  return (\n    <div>\n      <h2>Blockchain Information</h2>\n      <div>\n        <p>Current Block: {blockNumber?.toString() || \"Loading...\"}</p>\n\n        {address && balance && (\n          <p>\n            Balance:{\" \"}\n            {(\n              BigInt(balance.value) / BigInt(10 ** balance.decimals)\n            ).toLocaleString()}{\" \"}\n            {balance.symbol}\n          </p>\n        )}\n      </div>\n    </div>\n  );\n}\n\n```\n\nThis component uses the following React hooks:\n\n- **[`useBlockNumber`](https://wagmi.sh/react/api/hooks/useBlockNumber#useBlockNumber){target=\\_blank}**: Fetches the current block number of the connected chain. The `watch` parameter enables real-time updates when new blocks are mined.\n- **[`useBalance`](https://wagmi.sh/react/api/hooks/useBalance#useBalance){target=\\_blank}**: Retrieves the native token balance for a specified address, including value, symbol, and decimals information."}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 7, "depth": 2, "title": "Interact with Deployed Contract", "anchor": "interact-with-deployed-contract", "start_char": 6615, "end_char": 11058, "estimated_token_count": 991, "token_estimator": "heuristic-v1", "text": "## Interact with Deployed Contract\n\nThis guide uses a simple Storage contract already deployed to the Polkadot Hub TestNet (`0x58053f0e8ede1a47a1af53e43368cd04ddcaf66f`). The code of that contract is:\n\n??? code \"Storage.sol\"\n\n    ```solidity title=\"Storage.sol\"\n    -//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n    ```\n\nCreate a component to interact with your deployed contract. Create a file named `app/components/StorageContract.tsx`:\n\n```typescript title=\"app/components/StorageContract.tsx\"\n-\"use client\";\n\nimport { useState } from \"react\";\nimport {\n  useReadContract,\n  useWriteContract,\n  useWaitForTransactionReceipt,\n} from \"wagmi\";\n\nconst CONTRACT_ADDRESS =\n  \"0xabBd46Ef74b88E8B1CDa49BeFb5057710443Fd29\" as `0x${string}`;\n\nexport function StorageContract() {\n  const [number, setNumber] = useState<string>(\"42\");\n\n  // Contract ABI (should match your compiled contract)\n  const abi = [\n    {\n      inputs: [],\n      name: \"storedNumber\",\n      outputs: [{ internalType: \"uint256\", name: \"\", type: \"uint256\" }],\n      stateMutability: \"view\",\n      type: \"function\",\n    },\n    {\n      inputs: [\n        { internalType: \"uint256\", name: \"_newNumber\", type: \"uint256\" },\n      ],\n      name: \"setNumber\",\n      outputs: [],\n      stateMutability: \"nonpayable\",\n      type: \"function\",\n    },\n  ];\n\n  // Read the current stored number\n  const { data: storedNumber, refetch } = useReadContract({\n    address: CONTRACT_ADDRESS,\n    abi,\n    functionName: \"storedNumber\",\n  });\n\n  // Write to the contract\n  const { writeContract, data: hash, error, isPending } = useWriteContract();\n\n  // Wait for transaction to be mined\n  const { isLoading: isConfirming, isSuccess: isConfirmed } =\n    useWaitForTransactionReceipt({\n      hash,\n    });\n\n  const handleSetNumber = () => {\n    writeContract({\n      address: CONTRACT_ADDRESS,\n      abi,\n      functionName: \"setNumber\",\n      args: [BigInt(number)],\n    });\n  };\n\n  return (\n    <div>\n      <h2>Storage Contract Interaction</h2>\n      <div>\n        <p>Contract Address: {CONTRACT_ADDRESS}</p>\n        <p>Current Stored Number: {storedNumber?.toString() || \"Loading...\"}</p>\n      </div>\n\n      <div>\n        <input\n          type=\"number\"\n          value={number}\n          onChange={(e) => setNumber(e.target.value)}\n          disabled={isPending || isConfirming}\n        />\n        <button onClick={handleSetNumber} disabled={isPending || isConfirming}>\n          {isPending\n            ? \"Waiting for approval...\"\n            : isConfirming\n            ? \"Confirming...\"\n            : \"Set Number\"}\n        </button>\n      </div>\n\n      {error && <div className=\"error-message\">Error: {error.message}</div>}\n\n      {isConfirmed && (\n        <div className=\"success-message\">\n          Successfully updated!{\" \"}\n          <button onClick={() => refetch()}>Refresh</button>\n        </div>\n      )}\n    </div>\n  );\n}\n\n```\n\nThis component demonstrates how to interact with a smart contract using Wagmi's hooks:\n\n- **[`useReadContract`](https://wagmi.sh/react/api/hooks/useReadContract#useReadContract){target=\\_blank}**: Calls a read-only function on your smart contract to retrieve data without modifying the blockchain state.\n- **[`useWriteContract`](https://wagmi.sh/react/api/hooks/useWriteContract#useWriteContract){target=\\_blank}**: Calls a state-modifying function on your smart contract, which requires a transaction to be signed and sent.\n- **[`useWaitForTransactionReceipt`](https://wagmi.sh/react/api/hooks/useWaitForTransactionReceipt#useWaitForTransactionReceipt){target=\\_blank}**: Tracks the status of a transaction after it's been submitted, allowing you to know when it's been confirmed.\n\nThe component also includes proper state handling to:\n\n- Show the current value stored in the contract.\n- Allow users to input a new value.\n- Display transaction status (pending, confirming, or completed).\n- Handle errors.\n- Provide feedback when a transaction is successful."}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 8, "depth": 2, "title": "Integrate Components", "anchor": "integrate-components", "start_char": 11058, "end_char": 11811, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Integrate Components\n\nUpdate your main page to combine all the components. Create or update the file `src/app/page.tsx`:\n\n```typescript title=\"src/app/page.tsx\"\n-\"use client\";\n\nimport { BlockchainInfo } from \"./components/BlockchainInfo\";\nimport { ConnectWallet } from \"./components/ConnectWallet\";\nimport { StorageContract } from \"./components/StorageContract\";\nimport { useAccount } from \"wagmi\";\n\nexport default function Home() {\n  const { isConnected } = useAccount();\n\n  return (\n    <main>\n      <h1>Wagmi - Polkadot Hub Smart Contracts</h1>\n      <ConnectWallet />\n      {isConnected ? <BlockchainInfo /> : <span>Connect your wallet</span>}\n      {isConnected ? <StorageContract /> : <span>Connect your wallet</span>}\n    </main>\n  );\n}\n\n```"}
{"page_id": "develop-smart-contracts-libraries-wagmi", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 11811, "end_char": 13454, "estimated_token_count": 512, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundational knowledge to use Wagmi with Polkadot Hub, consider exploring:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Advanced Wagmi__\n\n    ---\n\n    Explore Wagmi's advanced features:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Watch Contract Events](https://wagmi.sh/core/api/actions/watchContractEvent#eventname){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Different Transports](https://wagmi.sh/react/api/transports){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Actions](https://wagmi.sh/react/api/actions){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Wallet Integration__\n\n    ---\n\n    Connect your dApp with popular wallet providers:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: MetaMask](https://wagmi.sh/core/api/connectors/metaMask){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: WalletConnect](https://wagmi.sh/core/api/connectors/walletConnect){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Coinbase Wallet](https://wagmi.sh/core/api/connectors/coinbaseWallet){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Testing & Development__\n\n    ---\n\n    Enhance your development workflow:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Test Suite](https://wagmi.sh/dev/contributing#_6-running-the-test-suite){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Dev Playground](https://wagmi.sh/dev/contributing#_5-running-the-dev-playgrounds){target=\\_blank}</li>\n    </ul>\n</div>"}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 539, "end_char": 1098, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nInteracting with blockchains typically requires an interface between your application and the network. [Web3.js](https://web3js.readthedocs.io/){target=\\_blank} offers this interface through a comprehensive collection of libraries, facilitating seamless interaction with the nodes using HTTP or WebSocket protocols. This guide illustrates how to utilize Web3.js specifically for interactions with Polkadot Hub.\n\nThis guide is intended for developers who are familiar with JavaScript and want to interact with the Polkadot Hub using Web3.js."}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1098, "end_char": 1454, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following installed:\n\n- **Node.js**: v22.13.1 or later, check the [Node.js installation guide](https://nodejs.org/en/download/current/){target=\\_blank}.\n- **npm**: v6.13.4 or later (comes bundled with Node.js).\n- **Solidity**: This guide uses Solidity `^0.8.9` for smart contract development."}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 2, "depth": 2, "title": "Project Structure", "anchor": "project-structure", "start_char": 1454, "end_char": 1939, "estimated_token_count": 136, "token_estimator": "heuristic-v1", "text": "## Project Structure\n\nThis project organizes contracts, scripts, and compiled artifacts for easy development and deployment.\n\n```text title=\"Web3.js Polkadot Hub\"\nweb3js-project\n├── contracts\n│   ├── Storage.sol\n├── scripts\n│   ├── connectToProvider.js\n│   ├── fetchLastBlock.js\n│   ├── compile.js\n│   ├── deploy.js\n│   ├── updateStorage.js\n├── abis\n│   ├── Storage.json\n├── artifacts\n│   ├── Storage.polkavm\n├── node_modules/\n├── package.json\n├── package-lock.json\n└── README.md\n```"}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1939, "end_char": 2055, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nTo start working with Web3.js, begin by initializing your project:\n\n```bash\nnpm init -y\n```"}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 4, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 2055, "end_char": 2188, "estimated_token_count": 38, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nNext, install the Web3.js library:\n\n```bash\nnpm install web3\n```\n\nThis guide uses `web3` version `4.16.0`."}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 5, "depth": 2, "title": "Set Up the Web3 Provider", "anchor": "set-up-the-web3-provider", "start_char": 2188, "end_char": 3947, "estimated_token_count": 427, "token_estimator": "heuristic-v1", "text": "## Set Up the Web3 Provider\n\nThe provider configuration is the foundation of any Web3.js application. The following example establishes a connection to Polkadot Hub. To use the example script, replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, and `INSERT_CHAIN_NAME` with the appropriate values. The provider connection script should look something like this:\n\n```javascript title=\"scripts/connectToProvider.js\"\n-const { Web3 } = require('web3');\n\nconst createProvider = (rpcUrl) => {\n  const web3 = new Web3(rpcUrl);\n  return web3;\n};\n\nconst PROVIDER_RPC = {\n  rpc: 'INSERT_RPC_URL',\n  chainId: 'INSERT_CHAIN_ID',\n  name: 'INSERT_CHAIN_NAME',\n};\n\ncreateProvider(PROVIDER_RPC.rpc);\n\n```\n\nFor example, for the Polkadot Hub TestNet, use these specific connection parameters:\n\n```js\nconst PROVIDER_RPC = {\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n  name: 'polkadot-hub-testnet'\n};\n```\n\nWith the Web3 provider set up, you can start querying the blockchain.\n\nFor instance, to fetch the latest block number of the chain, you can use the following code snippet:\n\n???+ code \"View complete script\"\n\n    ```javascript title=\"scripts/fetchLastBlock.js\"\n    -const { Web3 } = require('web3');\n\nconst createProvider = (rpcUrl) => {\n  const web3 = new Web3(rpcUrl);\n  return web3;\n};\n\nconst PROVIDER_RPC = {\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n  name: 'polkadot-hub-testnet',\n};\n\nconst main = async () => {\n  try {\n    const web3 = createProvider(PROVIDER_RPC.rpc);\n    const latestBlock = await web3.eth.getBlockNumber();\n    console.log('Last block: ' + latestBlock);\n  } catch (error) {\n    console.error('Error connecting to Polkadot Hub TestNet: ' + error.message);\n  }\n};\n\nmain();\n\n    ```"}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 6, "depth": 2, "title": "Compile Contracts", "anchor": "compile-contracts", "start_char": 3947, "end_char": 7444, "estimated_token_count": 841, "token_estimator": "heuristic-v1", "text": "## Compile Contracts\n\n-!!! note \"Contracts Code Blob Size Disclaimer\"\n    The maximum contract code blob size on Polkadot Hub networks is _100 kilobytes_, significantly larger than Ethereum’s EVM limit of 24 kilobytes.\n\n    For detailed comparisons and migration guidelines, see the [EVM vs. PolkaVM](/polkadot-protocol/smart-contract-basics/evm-vs-polkavm/#current-memory-limits){target=\\_blank} documentation page.\n\n\nPolkadot Hub requires contracts to be compiled to [PolkaVM](/polkadot-protocol/smart-contract-basics/polkavm-design/){target=\\_blank} bytecode. This is achieved using the [`revive`](https://github.com/paritytech/revive/tree/v0.2.0/js/resolc){target=\\_blank} compiler. Install the [`@parity/resolc`](https://github.com/paritytech/revive){target=\\_blank} library as a development dependency:\n\n```bash\nnpm install --save-dev @parity/resolc\n```\n\nThis guide uses `@parity/resolc` version `0.2.0`.\n\nHere's a simple storage contract that you can use to follow the process:\n\n```solidity title=\"contracts/Storage.sol\"\n-//SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```\n\nWith that, you can now create a `compile.js` snippet that transforms your solidity code into PolkaVM bytecode:\n\n```javascript title=\"scripts/compile.js\"\n-const { compile } = require('@parity/resolc');\nconst { readFileSync, writeFileSync } = require('fs');\nconst { basename, join } = require('path');\n\nconst compileContract = async (solidityFilePath, outputDir) => {\n  try {\n    // Read the Solidity file\n    const source = readFileSync(solidityFilePath, 'utf8');\n\n    // Construct the input object for the compiler\n    const input = {\n      [basename(solidityFilePath)]: { content: source },\n    };\n\n    console.log(`Compiling contract: ${basename(solidityFilePath)}...`);\n\n    // Compile the contract\n    const out = await compile(input);\n\n    for (const contracts of Object.values(out.contracts)) {\n      for (const [name, contract] of Object.entries(contracts)) {\n        console.log(`Compiled contract: ${name}`);\n\n        // Write the ABI\n        const abiPath = join(outputDir, `${name}.json`);\n        writeFileSync(abiPath, JSON.stringify(contract.abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n\n        // Write the bytecode\n        const bytecodePath = join(outputDir, `${name}.polkavm`);\n        writeFileSync(\n          bytecodePath,\n          Buffer.from(contract.evm.bytecode.object, 'hex'),\n        );\n        console.log(`Bytecode saved to ${bytecodePath}`);\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath = './Storage.sol';\nconst outputDir = '.';\n\ncompileContract(solidityFilePath, outputDir);\n\n```\n\nTo compile your contract, simply run the following command:\n\n```bash\nnode compile\n```\n\nAfter compilation, you'll have two key files: an ABI (`.json`) file, which provides a JSON interface describing the contract's functions and how to interact with it, and a bytecode (`.polkavm`) file, which contains the low-level machine code executable on PolkaVM that represents the compiled smart contract ready for blockchain deployment."}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 7, "depth": 2, "title": "Contract Deployment", "anchor": "contract-deployment", "start_char": 7444, "end_char": 10388, "estimated_token_count": 675, "token_estimator": "heuristic-v1", "text": "## Contract Deployment\n\nTo deploy your compiled contract to Polkadot Hub using Web3.js, you'll need an account with a private key to sign the deployment transaction. The deployment process is exactly the same as for any Ethereum-compatible chain, involving creating a contract instance, estimating gas, and sending a deployment transaction. Here's how to deploy the contract, ensure replacing the `INSERT_RPC_URL`, `INSERT_PRIVATE_KEY`, and `INSERT_CONTRACT_NAME` with the appropriate values:\n\n```javascript title=\"scripts/deploy.js\"\n-import { readFileSync } from 'fs';\nimport { Web3 } from 'web3';\n\nconst getAbi = (contractName) => {\n  try {\n    return JSON.parse(readFileSync(`${contractName}.json`), 'utf8');\n  } catch (error) {\n    console.error(\n      `❌ Could not find ABI for contract ${contractName}:`,\n      error.message\n    );\n    throw error;\n  }\n};\n\nconst getByteCode = (contractName) => {\n  try {\n    return `0x${readFileSync(`${contractName}.polkavm`).toString('hex')}`;\n  } catch (error) {\n    console.error(\n      `❌ Could not find bytecode for contract ${contractName}:`,\n      error.message\n    );\n    throw error;\n  }\n};\n\nexport const deploy = async (config) => {\n  try {\n    // Initialize Web3 with RPC URL\n    const web3 = new Web3(config.rpcUrl);\n\n    // Prepare account\n    const account = web3.eth.accounts.privateKeyToAccount(config.privateKey);\n    web3.eth.accounts.wallet.add(account);\n\n    // Load abi\n    const abi = getAbi('Storage');\n\n    // Create contract instance\n    const contract = new web3.eth.Contract(abi);\n\n    // Prepare deployment\n    const deployTransaction = contract.deploy({\n      data: getByteCode('Storage'),\n      arguments: [], // Add constructor arguments if needed\n    });\n\n    // Estimate gas\n    const gasEstimate = await deployTransaction.estimateGas({\n      from: account.address,\n    });\n\n    // Get current gas price\n    const gasPrice = await web3.eth.getGasPrice();\n\n    // Send deployment transaction\n    const deployedContract = await deployTransaction.send({\n      from: account.address,\n      gas: gasEstimate,\n      gasPrice: gasPrice,\n    });\n\n    // Log and return contract details\n    console.log(`Contract deployed at: ${deployedContract.options.address}`);\n    return deployedContract;\n  } catch (error) {\n    console.error('Deployment failed:', error);\n    throw error;\n  }\n};\n\n// Example usage\nconst deploymentConfig = {\n  rpcUrl: 'INSERT_RPC_URL',\n  privateKey: 'INSERT_PRIVATE_KEY',\n  contractName: 'INSERT_CONTRACT_NAME',\n};\n\ndeploy(deploymentConfig)\n  .then((contract) => console.log('Deployment successful'))\n  .catch((error) => console.error('Deployment error'));\n\n```\n\nFor further details on private key exportation, refer to the article [How to export an account's private key](https://support.metamask.io/configure/accounts/how-to-export-an-accounts-private-key/){target=\\_blank}.\n\nTo deploy your contract, run the following command:\n\n```bash\nnode deploy\n```"}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 8, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 10388, "end_char": 12772, "estimated_token_count": 549, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nOnce deployed, you can interact with your contract using Web3.js methods. Here's how to set a number and read it back, ensure replacing `INSERT_RPC_URL`, `INSERT_PRIVATE_KEY`, and `INSERT_CONTRACT_ADDRESS` with the appropriate values:\n\n```javascript title=\"scripts/updateStorage.js\"\n-import { readFileSync } from 'fs';\nimport { Web3 } from 'web3';\n\nconst getAbi = (contractName) => {\n  try {\n    return JSON.parse(readFileSync(`${contractName}.json`), 'utf8');\n  } catch (error) {\n    console.error(\n      `❌ Could not find ABI for contract ${contractName}:`,\n      error.message\n    );\n    throw error;\n  }\n};\n\nconst updateStorage = async (config) => {\n  try {\n    // Initialize Web3 with RPC URL\n    const web3 = new Web3(config.rpcUrl);\n\n    // Prepare account\n    const account = web3.eth.accounts.privateKeyToAccount(config.privateKey);\n    web3.eth.accounts.wallet.add(account);\n\n    // Load abi\n    const abi = getAbi('Storage');\n\n    // Create contract instance\n    const contract = new web3.eth.Contract(abi, config.contractAddress);\n\n    // Get initial value\n    const initialValue = await contract.methods.storedNumber().call();\n    console.log('Current stored value:', initialValue);\n\n    // Prepare transaction\n    const updateTransaction = contract.methods.setNumber(1);\n\n    // Estimate gas\n    const gasEstimate = await updateTransaction.estimateGas({\n      from: account.address,\n    });\n\n    // Get current gas price\n    const gasPrice = await web3.eth.getGasPrice();\n\n    // Send update transaction\n    const receipt = await updateTransaction.send({\n      from: account.address,\n      gas: gasEstimate,\n      gasPrice: gasPrice,\n    });\n\n    // Log transaction details\n    console.log(`Transaction hash: ${receipt.transactionHash}`);\n\n    // Get updated value\n    const newValue = await contract.methods.storedNumber().call();\n    console.log('New stored value:', newValue);\n\n    return receipt;\n  } catch (error) {\n    console.error('Update failed:', error);\n    throw error;\n  }\n};\n\n// Example usage\nconst config = {\n  rpcUrl: 'INSERT_RPC_URL',\n  privateKey: 'INSERT_PRIVATE_KEY',\n  contractAddress: 'INSERT_CONTRACT_ADDRESS',\n};\n\nupdateStorage(config)\n  .then((receipt) => console.log('Update successful'))\n  .catch((error) => console.error('Update error'));\n\n```\n\nTo execute the logic above, run:\n\n```bash\nnode updateStorage\n```"}
{"page_id": "develop-smart-contracts-libraries-web3-js", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 12772, "end_char": 13281, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you’ve learned how to use Web3.js with Polkadot Hub, explore more advanced topics:\n\n- **Utilize Web3.js utilities**: Learn about additional [Web3.js](https://docs.web3js.org/){target=\\_blank} features such as signing transactions, managing wallets, and subscribing to events.\n- **Build full-stack dApps**: [integrate Web3.js](https://docs.web3js.org/guides/dapps/intermediate-dapp){target=\\_blank} with different libraries and frameworks to build decentralized web applications."}
{"page_id": "develop-smart-contracts-libraries-web3-py", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 183, "end_char": 607, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nInteracting with blockchains typically requires an interface between your application and the network. [Web3.py](https://web3py.readthedocs.io/en/stable/index.html){target=\\_blank} offers this interface through a collection of libraries, facilitating seamless interaction with the nodes using HTTP or WebSocket protocols. \n\nThis guide illustrates how to utilize Web3.py for interactions with Polkadot Hub."}
{"page_id": "develop-smart-contracts-libraries-web3-py", "index": 1, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 607, "end_char": 988, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\n1. To start working with Web3.py, begin by initializing your project:\n\n    ```bash\n    mkdir web3py-project\n    cd web3py-project\n    ```\n\n2. Create and activate a virtual environment for your project:\n\n    ```bash\n    python -m venv venv\n    source venv/bin/activate\n    ```\n\n3. Next, install the Web3.py library:\n\n    ```bash\n    pip install web3\n    ```"}
{"page_id": "develop-smart-contracts-libraries-web3-py", "index": 2, "depth": 2, "title": "Set Up the Web3 Provider", "anchor": "set-up-the-web3-provider", "start_char": 988, "end_char": 2929, "estimated_token_count": 426, "token_estimator": "heuristic-v1", "text": "## Set Up the Web3 Provider\n\nThe [provider](https://web3py.readthedocs.io/en/stable/providers.html){target=\\_blank} configuration is the foundation of any Web3.py application. The following example establishes a connection to Polkadot Hub. Follow these steps to use the provider configuration:\n\n1. Replace `INSERT_RPC_URL` with the appropriate value. For instance, to connect to Polkadot Hub TestNet, use the following parameter:\n\n    ```python\n    PROVIDER_RPC = 'https://testnet-passet-hub-eth-rpc.polkadot.io'\n    ```\n\n    The provider connection script should look something like this:\n\n    ```python title=\"connect_to_provider.py\"\n    -from web3 import Web3\n\ndef create_provider(rpc_url):\n    web3 = Web3(Web3.HTTPProvider(rpc_url))\n    return web3\n\nPROVIDER_RPC = 'INSERT_RPC_URL'\n\ncreate_provider(PROVIDER_RPC)\n    ```\n\n1. With the Web3 provider set up, start querying the blockchain. For instance, you can use the following code snippet to fetch the latest block number of the chain:\n\n    ```python title=\"fetch_last_block.py\"\n    -def main():\n    try:\n        web3 = create_provider(PROVIDER_RPC)\n        latest_block = web3.eth.block_number\n        print('Last block: ' + str(latest_block))\n    except Exception as error:\n        print('Error connecting to Polkadot Hub TestNet: ' + str(error))\n\nif __name__ == \"__main__\":\n    main()\n    ```\n\n    ??? code \"View complete script\"\n\n        ```python title=\"fetch_last_block.py\"\n        -from web3 import Web3\n\ndef create_provider(rpc_url):\n    web3 = Web3(Web3.HTTPProvider(rpc_url))\n    return web3\n\nPROVIDER_RPC = 'https://testnet-passet-hub-eth-rpc.polkadot.io'\n\ndef main():\n    try:\n        web3 = create_provider(PROVIDER_RPC)\n        latest_block = web3.eth.block_number\n        print('Last block: ' + str(latest_block))\n    except Exception as error:\n        print('Error connecting to Polkadot Hub TestNet: ' + str(error))\n\nif __name__ == \"__main__\":\n    main()\n        ```"}
{"page_id": "develop-smart-contracts-libraries-web3-py", "index": 3, "depth": 2, "title": "Contract Deployment", "anchor": "contract-deployment", "start_char": 2929, "end_char": 7072, "estimated_token_count": 828, "token_estimator": "heuristic-v1", "text": "## Contract Deployment\n\nBefore deploying your contracts, make sure you've compiled them and obtained two key files:\n\n- An ABI (.json) file, which provides a JSON interface describing the contract's functions and how to interact with it.\n- A bytecode (.polkavm) file, which contains the low-level machine code executable on [PolkaVM](/polkadot-protocol/smart-contract-basics/polkavm-design#polkavm){target=\\_blank} that represents the compiled smart contract ready for blockchain deployment.\n\nTo follow this guide, you can use the following solidity contract as an example:\n\n```solidity title=\"Storage.sol\"\n-//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```\n\nTo deploy your compiled contract to Polkadot Hub using Web3.py, you'll need an account with a private key to sign the deployment transaction. The deployment process is exactly the same as for any Ethereum-compatible chain, involving creating a contract instance, estimating gas, and sending a deployment transaction. Here's how to deploy the contract. Replace `INSERT_RPC_URL` and `INSERT_PRIVATE_KEY` with the appropriate values:\n\n```python title=\"deploy.py\"\n-from web3 import Web3\nimport json\n\ndef get_abi(contract_name):\n    try:\n        with open(f\"{contract_name}.json\", 'r') as file:\n            return json.load(file)\n    except Exception as error:\n        print(f\"❌ Could not find ABI for contract {contract_name}: {error}\")\n        raise error\n\ndef get_bytecode(contract_name):\n    try:\n        with open(f\"{contract_name}.polkavm\", 'rb') as file:\n            return '0x' + file.read().hex()\n    except Exception as error:\n        print(f\"❌ Could not find bytecode for contract {contract_name}: {error}\")\n        raise error\n\nasync def deploy(config):\n    try:\n        # Initialize Web3 with RPC URL\n        web3 = Web3(Web3.HTTPProvider(config[\"rpc_url\"]))\n        \n        # Prepare account\n        account = web3.eth.account.from_key(config[\"private_key\"])\n        print(f\"address: {account.address}\")\n        \n        # Load ABI\n        abi = get_abi('Storage')\n        \n        # Create contract instance\n        contract = web3.eth.contract(abi=abi, bytecode=get_bytecode('Storage'))\n        \n        # Get current nonce\n        nonce = web3.eth.get_transaction_count(account.address)\n        \n        # Prepare deployment transaction\n        transaction = {\n            'from': account.address,\n            'nonce': nonce,\n        }\n        \n        # Build and sign transaction\n        construct_txn = contract.constructor().build_transaction(transaction)\n        signed_txn = web3.eth.account.sign_transaction(construct_txn, private_key=config[\"private_key\"])\n        \n        # Send transaction\n        tx_hash = web3.eth.send_raw_transaction(signed_txn.raw_transaction)\n        print(f\"Transaction hash: {tx_hash.hex()}\")\n        \n        # Wait for transaction receipt\n        tx_receipt = web3.eth.wait_for_transaction_receipt(tx_hash)\n        contract_address = tx_receipt.contractAddress\n        \n        # Log and return contract details\n        print(f\"Contract deployed at: {contract_address}\")\n        return web3.eth.contract(address=contract_address, abi=abi)\n    \n    except Exception as error:\n        print('Deployment failed:', error)\n        raise error\n\nif __name__ == \"__main__\":\n    # Example usage\n    import asyncio\n    \n    deployment_config = {\n        \"rpc_url\": \"INSERT_RPC_URL\",\n        \"private_key\": \"INSERT_PRIVATE_KEY\",\n    }\n    \n    asyncio.run(deploy(deployment_config))\n```\n\n!!!warning\n    Never commit or share your private key. Exposed keys can lead to immediate theft of all associated funds. Use environment variables instead."}
{"page_id": "develop-smart-contracts-libraries-web3-py", "index": 4, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 7072, "end_char": 9530, "estimated_token_count": 465, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nAfter deployment, interact with your contract using Web3.py methods. The example below demonstrates how to set and retrieve a number. Be sure to replace the `INSERT_RPC_URL`, `INSERT_PRIVATE_KEY`, and `INSERT_CONTRACT_ADDRESS` placeholders with your specific values:\n\n```python title=\"update_storage.py\"\n-from web3 import Web3\nimport json\n\ndef get_abi(contract_name):\n    try:\n        with open(f\"{contract_name}.json\", 'r') as file:\n            return json.load(file)\n    except Exception as error:\n        print(f\"❌ Could not find ABI for contract {contract_name}: {error}\")\n        raise error\n\nasync def update_storage(config):\n    try:\n        # Initialize Web3 with RPC URL\n        web3 = Web3(Web3.HTTPProvider(config[\"rpc_url\"]))\n        \n        # Prepare account\n        account = web3.eth.account.from_key(config[\"private_key\"])\n        \n        # Load ABI\n        abi = get_abi('Storage')\n        \n        # Create contract instance\n        contract = web3.eth.contract(address=config[\"contract_address\"], abi=abi)\n        \n        # Get initial value\n        initial_value = contract.functions.storedNumber().call()\n        print('Current stored value:', initial_value)\n        \n        # Get current nonce\n        nonce = web3.eth.get_transaction_count(account.address)\n        \n        # Prepare transaction\n        transaction = contract.functions.setNumber(1).build_transaction({\n            'from': account.address,\n            'nonce': nonce\n        })\n        \n        # Sign transaction\n        signed_txn = web3.eth.account.sign_transaction(transaction, private_key=config[\"private_key\"])\n        \n        # Send transaction\n        tx_hash = web3.eth.send_raw_transaction(signed_txn.raw_transaction)\n        print(f\"Transaction hash: {tx_hash.hex()}\")\n        \n        # Wait for receipt\n        receipt = web3.eth.wait_for_transaction_receipt(tx_hash)\n        \n        # Get updated value\n        new_value = contract.functions.storedNumber().call()\n        print('New stored value:', new_value)\n        \n        return receipt\n    \n    except Exception as error:\n        print('Update failed:', error)\n        raise error\n\nif __name__ == \"__main__\":\n    # Example usage\n    import asyncio\n    \n    config = {\n        \"rpc_url\": \"INSERT_RPC_URL\",\n        \"private_key\": \"INSERT_PRIVATE_KEY\",\n        \"contract_address\": \"INSERT_CONTRACT_ADDRESS\",\n    }\n    \n    asyncio.run(update_storage(config))\n```"}
{"page_id": "develop-smart-contracts-libraries-web3-py", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 9530, "end_char": 11504, "estimated_token_count": 628, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundation for using Web3.py with Polkadot Hub, consider exploring:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Advanced Web3.py Features__\n  \n    ---\n    Explore Web3.py's documentation:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Middleware](https://web3py.readthedocs.io/en/stable/middleware.html){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Filters & Events](https://web3py.readthedocs.io/en/stable/filters.html){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: ENS](https://web3py.readthedocs.io/en/stable/ens_overview.html){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Testing Frameworks__\n\n    ---\n    Integrate Web3.py with Python testing frameworks:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Pytest](https://docs.pytest.org/){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Brownie](https://eth-brownie.readthedocs.io/){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Transaction Management__\n\n    ---\n    Learn advanced transaction handling:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Gas Strategies](https://web3py.readthedocs.io/en/stable/gas_price.html){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Account Management](https://web3py.readthedocs.io/en/stable/web3.eth.account.html){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Building dApps__\n\n    ---\n    Combine Web3.py with these frameworks to create full-stack applications:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Flask](https://flask.palletsprojects.com/){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Django](https://www.djangoproject.com/){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: FastAPI](https://fastapi.tiangolo.com/){target=\\_blank}</li>\n    </ul>\n\n</div>"}
{"page_id": "develop-smart-contracts-local-development-node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 198, "end_char": 701, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nA local development node provides an isolated blockchain environment where you can deploy, test, and debug smart contracts without incurring network fees or waiting for block confirmations. This guide demonstrates how to set up a local Polkadot SDK-based node with smart contract capabilities.\n\nBy the end of this guide, you'll have:\n\n- A running node with smart contract support.\n- An ETH-RPC adapter for Ethereum-compatible tooling integration accessible at `http://localhost:8545`."}
{"page_id": "develop-smart-contracts-local-development-node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 701, "end_char": 1042, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have done the following:\n\n- Completed the [Install Polkadot SDK Dependencies](/develop/parachains/install-polkadot-sdk/){target=\\_blank} guide and successfully installed [Rust](https://www.rust-lang.org/){target=\\_blank} and the required packages to set up your development environment."}
{"page_id": "develop-smart-contracts-local-development-node", "index": 2, "depth": 2, "title": "Install the Revive Dev Node and ETH-RPC Adapter", "anchor": "install-the-revive-dev-node-and-eth-rpc-adapter", "start_char": 1042, "end_char": 2575, "estimated_token_count": 343, "token_estimator": "heuristic-v1", "text": "## Install the Revive Dev Node and ETH-RPC Adapter\n\nThe Polkadot SDK repository contains both the [Revive Dev node](https://github.com/paritytech/polkadot-sdk/tree/8e2b6f742a38bb13688e12abacded0aab2dbbb23/substrate/frame/revive/dev-node){target=\\_blank} implementation and the [ETH-RPC adapter](https://github.com/paritytech/polkadot-sdk/tree/8e2b6f742a38bb13688e12abacded0aab2dbbb23/substrate/frame/revive/rpc){target=\\_blank} required for Ethereum compatibility. Start by cloning the repository and navigating to the project directory:\n\n```bash\ngit clone https://github.com/paritytech/polkadot-sdk.git\ncd polkadot-sdk\ngit checkout 8e2b6f742a38bb13688e12abacded0aab2dbbb23\n```\n\nNext, you need to compile the two essential components for your development environment. The Substrate node provides the core blockchain runtime with smart contract support, while the ETH-RPC adapter enables Ethereum JSON-RPC compatibility for existing tooling:\n\n```bash\ncargo build -p revive-dev-node --bin revive-dev-node --release\ncargo build -p pallet-revive-eth-rpc --bin eth-rpc --release\n```\n\nThe compilation process may take some time depending on your system specifications, potentially up to 30 minutes. Release builds are optimized for performance but take longer to compile than debug builds. After successful compilation, you can verify the binaries are available in the `target/release` directory:\n\n- **Revive Dev node path**: `polkadot-sdk/target/release/revive-dev-node`\n- **ETH-RPC adapter path**: `polkadot-sdk/target/release/eth-rpc`"}
{"page_id": "develop-smart-contracts-local-development-node", "index": 3, "depth": 2, "title": "Run the Local Node", "anchor": "run-the-local-node", "start_char": 2575, "end_char": 9070, "estimated_token_count": 1914, "token_estimator": "heuristic-v1", "text": "## Run the Local Node\n\nWith the binaries compiled, you can now start your local development environment. The setup requires running two processes.\n\nStart the node first, which will initialize a local blockchain with the `dev` chain specification. This configuration includes `pallet-revive` for smart contract functionality and uses pre-funded development accounts for testing:\n\n```bash\n./target/release/revive-dev-node --dev\n```\n\nThe node will begin producing blocks immediately and display initialization logs:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>./target/release/revive-dev-node --dev</span>\n  <br />\n  <span data-ty>2025-05-29 10:42:35 Substrate Node</span>\n  <span data-ty>2025-05-29 10:42:35 ✌️ version 3.0.0-dev-38b7581fc04</span>\n  <span data-ty>2025-05-29 10:42:35 ❤️ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2025</span>\n  <span data-ty>2025-05-29 10:42:35 📋 Chain specification: Development</span>\n  <span data-ty>2025-05-29 10:42:35 🏷 Node name: annoyed-aunt-3163</span>\n  <span data-ty>2025-05-29 10:42:35 👤 Role: AUTHORITY</span>\n  <span data-ty>2025-05-29 10:42:35 💾 Database: RocksDb at /var/folders/x0/xl_kjddj3ql3bx7752yr09hc0000gn/T/substrate2P85EF/chains/dev/db/full</span>\n  <span data-ty>2025-05-29 10:42:40 🔨 Initializing Genesis block/state (state: 0xfc05…482e, header-hash: 0x1ae1…b8b4)</span>\n  <span data-ty>2025-05-29 10:42:40 Creating transaction pool txpool_type=SingleState ready=Limit { count: 8192, total_bytes: 20971520 } future=Limit { count: 819, total_bytes: 2097152 }</span>\n  <span data-ty>2025-05-29 10:42:40 👴 Loading GRANDPA authority set from genesis on what appears to be first startup.</span>\n  <span data-ty>2025-05-29 10:42:40 👶 Creating empty BABE epoch changes on what appears to be first startup.</span>\n  <span data-ty>2025-05-29 10:42:40 Using default protocol ID \"sup\" because none is configured in the chain specs</span>\n  <span data-ty>2025-05-29 10:42:40 🏷 Local node identity is: 12D3KooWAH8fgJv3hce7Yv4yKG4YXQiRqESFu6755DBnfZQU8Znm</span>\n  <span data-ty>2025-05-29 10:42:40 Running libp2p network backend</span>\n  <span data-ty>2025-05-29 10:42:40 local_peer_id=12D3KooWAH8fgJv3hce7Yv4yKG4YXQiRqESFu6755DBnfZQU8Znm</span>\n  <span data-ty>2025-05-29 10:42:40 💻 Operating system: macos</span>\n  <span data-ty>2025-05-29 10:42:40 💻 CPU architecture: aarch64</span>\n  <span data-ty>2025-05-29 10:42:40 📦 Highest known block at #0</span>\n  <span data-ty>2025-05-29 10:42:40 Error binding to '127.0.0.1:9615': Os { code: 48, kind: AddrInUse, message: \"Address already in use\" }</span>\n  <span data-ty>2025-05-29 10:42:40 Running JSON-RPC server: addr=127.0.0.1:63333,[::1]:63334</span>\n  <span data-ty>2025-05-29 10:42:40 🏁 CPU single core score: 1.24 GiBs, parallelism score: 1.08 GiBs with expected cores: 8</span>\n  <span data-ty>2025-05-29 10:42:40 🏁 Memory score: 49.42 GiBs</span>\n  <span data-ty>2025-05-29 10:42:40 🏁 Disk score (seq. writes): 1.91 GiBs</span>\n  <span data-ty>2025-05-29 10:42:40 🏁 Disk score (rand. writes): 529.02 MiBs</span>\n  <span data-ty>2025-05-29 10:42:40 👶 Starting BABE Authorship worker</span>\n  <span data-ty>2025-05-29 10:42:40 🥩 BEEFY gadget waiting for BEEFY pallet to become available...</span>\n  <span data-ty>2025-05-29 10:42:40 Failed to trigger bootstrap: No known peers.</span>\n  <span data-ty>2025-05-29 10:42:42 🙌 Starting consensus session on top of parent 0x1ae19030b13592b5e6fd326f26efc7b31a4f588303d348ef89ae9ebca613b8b4 (#0)</span>\n  <span data-ty>2025-05-29 10:42:42 🎁 Prepared block for proposing at 1 (5 ms) hash: 0xe046f22307fba58a3bd0cc21b1a057843d4342da8876fd44aba206f124528df0; parent_hash: 0x1ae1…b8b4; end: NoMoreTransactions; extrinsics_count: 2</span>\n  <span data-ty>2025-05-29 10:42:42 🔖 Pre-sealed block for proposal at 1. Hash now 0xa88d36087e7bf8ee59c1b17e0003092accf131ff8353a620410d7283657ce36a, previously 0xe046f22307fba58a3bd0cc21b1a057843d4342da8876fd44aba206f124528df0.</span>\n  <span data-ty>2025-05-29 10:42:42 👶 New epoch 0 launching at block 0xa88d…e36a (block slot 582842054 >= start slot 582842054).</span>\n  <span data-ty>2025-05-29 10:42:42 👶 Next epoch starts at slot 582842254</span>\n  <span data-ty>2025-05-29 10:42:42 🏆 Imported #1 (0x1ae1…b8b4 → 0xa88d…e36a)</span>\n</div>\n\n\nFor debugging purposes or to monitor low-level operations, you can enable detailed logging by setting environment variables before running the command:\n\n```bash\nRUST_LOG=\"error,evm=debug,sc_rpc_server=info,runtime::revive=debug\" ./target/release/revive-dev-node --dev\n```\n\nOnce the node is running, open a new terminal window and start the ETH-RPC adapter. This component translates Ethereum JSON-RPC calls into Substrate-compatible requests, allowing you to use familiar Ethereum tools like MetaMask, Hardhat, or Ethers.js:\n\n```bash\n./target/release/eth-rpc --dev\n```\n\nYou should see logs indicating that the adapter is ready to accept connections:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>./target/release/eth-rpc --dev</span>\n  <br />\n  <span data-ty>2025-05-29 10:48:48 Running in --dev mode, RPC CORS has been disabled.</span>\n  <span data-ty>2025-05-29 10:48:48 Running in --dev mode, RPC CORS has been disabled.</span>\n  <span data-ty>2025-05-29 10:48:48 🌐 Connecting to node at: ws://127.0.0.1:9944 ...</span>\n  <span data-ty>2025-05-29 10:48:48 🌟 Connected to node at: ws://127.0.0.1:9944</span>\n  <span data-ty>2025-05-29 10:48:48 💾 Using in-memory database, keeping only 256 blocks in memory</span>\n  <span data-ty>2025-05-29 10:48:48 〽️ Prometheus exporter started at 127.0.0.1:9616</span>\n  <span data-ty>2025-05-29 10:48:48 Running JSON-RPC server: addr=127.0.0.1:8545,[::1]:8545</span>\n  <span data-ty>2025-05-29 10:48:48 🔌 Subscribing to new blocks (BestBlocks)</span>\n  <span data-ty>2025-05-29 10:48:48 🔌 Subscribing to new blocks (FinalizedBlocks)</span>\n</div>\n\n\nSimilar to the Revive Dev node, you can enable detailed logging for the ETH-RPC adapter to troubleshoot issues:\n\n```bash\nRUST_LOG=\"info,eth-rpc=debug\" ./target/release/eth-rpc --dev\n```\n\nYour local development environment is now active and accessible at `http://localhost:8545`. This endpoint accepts standard Ethereum JSON-RPC requests, enabling seamless integration with existing Ethereum development tools and workflows. \n\nYou can connect wallets, deploy contracts using Remix or Hardhat, and interact with your smart contracts as you would on any Ethereum-compatible network."}
{"page_id": "develop-smart-contracts-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 203, "end_char": 1425, "estimated_token_count": 238, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot offers developers multiple approaches to building and deploying smart contracts within its ecosystem. As a multi-chain network designed for interoperability, Polkadot provides various environments optimized for different developer preferences and application requirements. From native smart contract support on Polkadot Hub to specialized parachain environments, developers can choose the platform that best suits their technical needs while benefiting from Polkadot's shared security model and cross-chain messaging capabilities.\n\nWhether you're looking for Ethereum compatibility through EVM-based parachains like [Moonbeam](https://docs.moonbeam.network/){target=\\_blank}, [Astar](https://docs.astar.network/){target=\\_blank}, and [Acala](https://evmdocs.acala.network/){target=\\_blank} or prefer PolkaVM-based development with [ink!](https://use.ink/docs/v6/){target=\\_blank}, the Polkadot ecosystem accommodates a range of diverse developers.\n\nThese guides explore the diverse smart contract options available in the Polkadot ecosystem, helping developers understand the unique advantages of each approach and make informed decisions about where to deploy their decentralized applications."}
{"page_id": "develop-smart-contracts-overview", "index": 1, "depth": 2, "title": "Native Smart Contracts", "anchor": "native-smart-contracts", "start_char": 1425, "end_char": 1452, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Native Smart Contracts"}
{"page_id": "develop-smart-contracts-overview", "index": 2, "depth": 3, "title": "Introduction", "anchor": "introduction-2", "start_char": 1452, "end_char": 1813, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "### Introduction\n\nPolkadot Hub enables smart contract deployment and execution through PolkaVM, a cutting-edge virtual machine designed specifically for the Polkadot ecosystem. This native integration allows developers to deploy smart contracts directly on Polkadot's system chain while maintaining compatibility with Ethereum development tools and workflows."}
{"page_id": "develop-smart-contracts-overview", "index": 3, "depth": 3, "title": "Smart Contract Development", "anchor": "smart-contract-development", "start_char": 1813, "end_char": 2440, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "### Smart Contract Development\n\nThe smart contract platform on Polkadot Hub combines _Polkadot's robust security and scalability_ with the extensive Ethereum development ecosystem. Developers can utilize familiar Ethereum libraries for contract interactions and leverage industry-standard development environments for writing and testing smart contracts.\n\nPolkadot Hub provides _full Ethereum JSON-RPC API compatibility_, ensuring seamless integration with existing development tools and services. This compatibility enables developers to maintain their preferred workflows while building on Polkadot's native infrastructure."}
{"page_id": "develop-smart-contracts-overview", "index": 4, "depth": 3, "title": "Technical Architecture", "anchor": "technical-architecture", "start_char": 2440, "end_char": 2848, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "### Technical Architecture\n\nPolkaVM, the underlying virtual machine, utilizes a RISC-V-based register architecture _optimized for the Polkadot ecosystem_. This design choice offers several advantages:\n\n- Enhanced performance for smart contract execution.\n- Improved gas efficiency for complex operations.\n- Native compatibility with Polkadot's runtime environment.\n- Optimized storage and state management."}
{"page_id": "develop-smart-contracts-overview", "index": 5, "depth": 3, "title": "Development Tools and Resources", "anchor": "development-tools-and-resources", "start_char": 2848, "end_char": 3388, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "### Development Tools and Resources\n\nPolkadot Hub supports a comprehensive suite of development tools familiar to Ethereum developers. The platform integrates with popular development frameworks, testing environments, and deployment tools. Key features include:\n\n- Contract development in Solidity or Rust.\n- Support for standard Ethereum development libraries.\n- Integration with widely used development environments.\n- Access to blockchain explorers and indexing solutions.\n- Compatibility with contract monitoring and management tools."}
{"page_id": "develop-smart-contracts-overview", "index": 6, "depth": 3, "title": "Cross-Chain Capabilities", "anchor": "cross-chain-capabilities", "start_char": 3388, "end_char": 3880, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "### Cross-Chain Capabilities\n\nSmart contracts deployed on Polkadot Hub can leverage Polkadot's [cross-consensus messaging (XCM) protocol](/develop/interoperability/intro-to-xcm/){target=\\_blank} protocol to seamlessly _transfer tokens and call functions on other blockchain networks_ within the Polkadot ecosystem, all without complex bridging infrastructure or third-party solutions. For further references, check the [Interoperability](/develop/interoperability/){target=\\_blank} section."}
{"page_id": "develop-smart-contracts-overview", "index": 7, "depth": 3, "title": "Use Cases", "anchor": "use-cases", "start_char": 3880, "end_char": 4223, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### Use Cases\n\nPolkadot Hub's smart contract platform is suitable for a wide range of applications:\n\n- DeFi protocols leveraging _cross-chain capabilities_.\n- NFT platforms utilizing Polkadot's native token standards.\n- Governance systems integrated with Polkadot's democracy mechanisms.\n- Cross-chain bridges and asset management solutions."}
{"page_id": "develop-smart-contracts-overview", "index": 8, "depth": 2, "title": "Other Smart Contract Environments", "anchor": "other-smart-contract-environments", "start_char": 4223, "end_char": 5346, "estimated_token_count": 227, "token_estimator": "heuristic-v1", "text": "## Other Smart Contract Environments\n\nBeyond Polkadot Hub's native PolkaVM support, the ecosystem offers two main alternatives for smart contract development:\n\n- **EVM-compatible parachains**: Provide access to Ethereum's extensive developer ecosystem, smart contract portability, and established tooling like Hardhat, Remix, Foundry, and OpenZeppelin. The main options include Moonbeam (the first full Ethereum-compatible parachain serving as an interoperability hub), Astar (featuring dual VM support for both EVM and WebAssembly contracts), and Acala (DeFi-focused with enhanced Acala EVM+ offering advanced DeFi primitives).\n\n- **Rust (ink!)**: ink! is a Rust-based framework that can compile to PolkaVM. It uses [`#[ink(...)]`](https://use.ink/docs/v6/macros-attributes/){target=\\_blank} attribute macros to create Polkadot SDK-compatible PolkaVM bytecode, offering strong memory safety from Rust, an advanced type system, high-performance PolkaVM execution, and platform independence with sandboxed security.\n\n\nEach environment provides unique advantages based on developer preferences and application requirements."}
{"page_id": "develop-smart-contracts-overview", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5346, "end_char": 6296, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nDevelopers can use their existing Ethereum development tools and connect to Polkadot Hub's RPC endpoints. The platform's Ethereum compatibility layer ensures a smooth transition for teams already building on Ethereum-compatible chains.\n\nSubsequent sections of this guide provide detailed information about specific development tools, advanced features, and best practices for building on Polkadot Hub.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Libraries__\n\n    ---\n\n    Explore essential libraries to optimize smart contract development and interaction.\n\n    [:octicons-arrow-right-24: Reference](/develop/smart-contracts/libraries/)\n\n-   <span class=\"badge guide\">Guide</span> __Dev Environments__\n\n    ---\n\n    Set up your development environment for seamless contract deployment and testing.\n\n    [:octicons-arrow-right-24: Reference](/develop/smart-contracts/dev-environments/)\n\n</div>"}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 201, "end_char": 723, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPrecompiles offer Polkadot Hub developers access to high-performance native functions directly from their smart contracts. Each precompile has a specific address and accepts a particular input data format. When called correctly, they execute optimized, native implementations of commonly used functions much more efficiently than equivalent contract-based implementations.\n\nThis guide demonstrates how to interact with each standard precompile available in Polkadot Hub through Solidity smart contracts."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 1, "depth": 2, "title": "Basic Precompile Interaction Pattern", "anchor": "basic-precompile-interaction-pattern", "start_char": 723, "end_char": 1663, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Basic Precompile Interaction Pattern\n\nAll precompiles follow a similar interaction pattern:\n\n```solidity\n// Generic pattern for calling precompiles\nfunction callPrecompile(address precompileAddress, bytes memory input)\n    internal\n    returns (bool success, bytes memory result)\n{\n    // Direct low-level call to the precompile address\n    (success, result) = precompileAddress.call(input);\n\n    // Ensure the call was successful\n    require(success, \"Precompile call failed\");\n\n    return (success, result);\n}\n```\n\nFeel free to check the [`precompiles-hardhat`](https://github.com/polkadot-developers/polkavm-hardhat-examples/tree/v0.0.3/precompiles-hardhat){target=\\_blank} repository to check all the precompiles examples. The repository contains a set of example contracts and test files demonstrating how to interact with each precompile in Polkadot Hub.\n\nNow, you'll explore how to use each precompile available in Polkadot Hub."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 2, "depth": 2, "title": "ECRecover (0x01)", "anchor": "ecrecover-0x01", "start_char": 1663, "end_char": 3164, "estimated_token_count": 326, "token_estimator": "heuristic-v1", "text": "## ECRecover (0x01)\n\nECRecover recovers an Ethereum address associated with the public key used to sign a message.\n\n```solidity title=\"ECRecover.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract ECRecoverExample {\n    event ECRecovered(bytes result);\n\n    // Address of the ECRecover precompile\n    address constant EC_RECOVER_ADDRESS = address(0x01);\n    bytes public result;\n\n    function callECRecover(bytes calldata input) public {\n        bool success;\n        bytes memory resultInMemory;\n\n        (success, resultInMemory) = EC_RECOVER_ADDRESS.call{value: 0}(input);\n\n        if (success) {\n            emit ECRecovered(resultInMemory);\n        }\n\n        result = resultInMemory;\n    }\n\n    function getRecoveredAddress() public view returns (address) {\n        require(result.length == 32, \"Invalid result length\");\n        return address(uint160(uint256(bytes32(result))));\n    }\n}\n```\n\nTo interact with the ECRecover precompile, you can deploy the `ECRecoverExample` contract in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment. The `callECRecover` function takes a 128-byte input combining the message `hash`, `v`, `r`, and `s` signature values. Check this [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/ECRecover.js){target=\\_blank} that shows how to format this input and verify that the recovered address matches the expected result."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 3, "depth": 2, "title": "SHA-256 (0x02)", "anchor": "sha-256-0x02", "start_char": 3164, "end_char": 4403, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "## SHA-256 (0x02)\n\nThe SHA-256 precompile computes the SHA-256 hash of the input data.\n\n```solidity title=\"SHA256.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract SHA256Example {\n    event SHA256Called(bytes result);\n\n    // Address of the SHA256 precompile\n    address constant SHA256_PRECOMPILE = address(0x02);\n\n    bytes public result;\n\n    function callH256(bytes calldata input) public {\n        bool success;\n        bytes memory resultInMemory;\n\n        (success, resultInMemory) = SHA256_PRECOMPILE.call{value: 0}(input);\n\n        if (success) {\n            emit SHA256Called(resultInMemory);\n        }\n\n        result = resultInMemory;\n    }\n}\n```\n\nTo use it, you can deploy the `SHA256Example` contract in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call callH256 with arbitrary bytes. Check out this [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/SHA256.js){target=\\_blank} shows how to pass a UTF-8 string, hash it using the precompile, and compare it with the expected hash from Node.js's [crypto](https://www.npmjs.com/package/crypto-js){target=\\_blank} module."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 4, "depth": 2, "title": "RIPEMD-160 (0x03)", "anchor": "ripemd-160-0x03", "start_char": 4403, "end_char": 5793, "estimated_token_count": 300, "token_estimator": "heuristic-v1", "text": "## RIPEMD-160 (0x03)\n\nThe RIPEMD-160 precompile computes the RIPEMD-160 hash of the input data.\n\n```solidity title=\"RIPEMD160.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract RIPEMD160Example {\n    // RIPEMD-160 precompile address\n    address constant RIPEMD160_PRECOMPILE = address(0x03);\n\n    bytes32 public result;\n\n    event RIPEMD160Called(bytes32 result);\n\n    function calculateRIPEMD160(bytes calldata input) public returns (bytes32) {\n        (bool success, bytes memory returnData) = RIPEMD160_PRECOMPILE.call(\n            input\n        );\n        require(success, \"RIPEMD-160 precompile call failed\");\n        // return full 32 bytes, no assembly extraction\n        bytes32 fullHash;\n        assembly {\n            fullHash := mload(add(returnData, 32))\n        }\n        result = fullHash;\n        emit RIPEMD160Called(fullHash);\n        return fullHash;\n    }\n}\n```\n\nTo use it, you can deploy the `RIPEMD160Example` contract in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call `calculateRIPEMD160` with arbitrary bytes. This [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/RIPEMD160.js){target=\\_blank} shows how to hash a UTF-8 string, pad the 20-byte result to 32 bytes, and verify it against the expected output."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 5, "depth": 2, "title": "Identity (Data Copy) (0x04)", "anchor": "identity-data-copy-0x04", "start_char": 5793, "end_char": 7030, "estimated_token_count": 260, "token_estimator": "heuristic-v1", "text": "## Identity (Data Copy) (0x04)\n\nThe Identity precompile simply returns the input data as output. While seemingly trivial, it can be useful for testing and certain specialized scenarios.\n\n```solidity title=\"Identity.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract IdentityExample {\n    event IdentityCalled(bytes result);\n\n    // Address of the Identity precompile\n    address constant IDENTITY_PRECOMPILE = address(0x04);\n\n    bytes public result;\n\n    function callIdentity(bytes calldata input) public {\n        bool success;\n        bytes memory resultInMemory;\n\n        (success, resultInMemory) = IDENTITY_PRECOMPILE.call(input);\n\n        if (success) {\n            emit IdentityCalled(resultInMemory);\n        }\n\n        result = resultInMemory;\n    }\n}\n```\n\nTo use it, you can deploy the `IdentityExample` contract in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call `callIdentity` with arbitrary bytes. This [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/Identity.js){target=\\_blank} shows how to pass input data and verify that the precompile returns it unchanged."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 6, "depth": 2, "title": "Modular Exponentiation (0x05)", "anchor": "modular-exponentiation-0x05", "start_char": 7030, "end_char": 8513, "estimated_token_count": 310, "token_estimator": "heuristic-v1", "text": "## Modular Exponentiation (0x05)\n\nThe ModExp precompile performs modular exponentiation, which is an operation commonly needed in cryptographic algorithms.\n\n```solidity title=\"ModExp.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract ModExpExample {\n    address constant MODEXP_ADDRESS = address(0x05);\n\n    function modularExponentiation(\n        bytes memory base,\n        bytes memory exponent,\n        bytes memory modulus\n    ) public view returns (bytes memory) {\n        bytes memory input = abi.encodePacked(\n            toBytes32(base.length),\n            toBytes32(exponent.length),\n            toBytes32(modulus.length),\n            base,\n            exponent,\n            modulus\n        );\n\n        (bool success, bytes memory result) = MODEXP_ADDRESS.staticcall(input);\n        require(success, \"ModExp precompile call failed\");\n\n        return result;\n    }\n\n    function toBytes32(uint256 value) internal pure returns (bytes32) {\n        return bytes32(value);\n    }\n}\n```\n\nTo use it, you can deploy the `ModExpExample` contract in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call `modularExponentiation` with encoded `base`, `exponent`, and `modulus` bytes. This [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/ModExp.js){target=\\_blank} shows how to test modular exponentiation like (4 ** 13) % 497 = 445."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 7, "depth": 2, "title": "BN128 Addition (0x06)", "anchor": "bn128-addition-0x06", "start_char": 8513, "end_char": 10028, "estimated_token_count": 344, "token_estimator": "heuristic-v1", "text": "## BN128 Addition (0x06)\n\nThe BN128Add precompile performs addition on the alt_bn128 elliptic curve, which is essential for zk-SNARK operations.\n\n```solidity title=\"BN128Add.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n\ncontract BN128AddExample {\n    address constant BN128_ADD_PRECOMPILE = address(0x06);\n\n    event BN128Added(uint256 x3, uint256 y3);\n\n    uint256 public resultX;\n    uint256 public resultY;\n\n    function callBN128Add(uint256 x1, uint256 y1, uint256 x2, uint256 y2) public {\n        bytes memory input = abi.encodePacked(\n            bytes32(x1), bytes32(y1), bytes32(x2), bytes32(y2)\n        );\n\n        bool success;\n        bytes memory output;\n\n        (success, output) = BN128_ADD_PRECOMPILE.call{value: 0}(input);\n\n        require(success, \"BN128Add precompile call failed\");\n        require(output.length == 64, \"Invalid output length\");\n\n        (uint256 x3, uint256 y3) = abi.decode(output, (uint256, uint256));\n\n        resultX = x3;\n        resultY = y3;\n\n        emit BN128Added(x3, y3);\n    }\n}\n```\n\nTo use it, you can deploy the `BN128AddExample` contract in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call `callBN128Add` with valid `alt_bn128` points. This [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/BN128Add.js){target=\\_blank} demonstrates a valid curve addition and checks the result against known expected values."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 8, "depth": 2, "title": "BN128 Scalar Multiplication (0x07)", "anchor": "bn128-scalar-multiplication-0x07", "start_char": 10028, "end_char": 11765, "estimated_token_count": 370, "token_estimator": "heuristic-v1", "text": "## BN128 Scalar Multiplication (0x07)\n\nThe BN128Mul precompile performs scalar multiplication on the alt_bn128 curve.\n\n```solidity title=\"BN128Mul.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract BN128MulExample {\n    // Precompile address for BN128Mul\n    address constant BN128_MUL_ADDRESS = address(0x07);\n\n    bytes public result;\n\n    // Performs scalar multiplication of a point on the alt_bn128 curve\n    function bn128ScalarMul(uint256 x1, uint256 y1, uint256 scalar) public {\n        // Format: [x, y, scalar] - each 32 bytes\n        bytes memory input = abi.encodePacked(\n            bytes32(x1),\n            bytes32(y1),\n            bytes32(scalar)\n        );\n\n        (bool success, bytes memory resultInMemory) = BN128_MUL_ADDRESS.call{\n            value: 0\n        }(input);\n        require(success, \"BN128Mul precompile call failed\");\n\n        result = resultInMemory;\n    }\n\n    // Helper to decode result from `result` storage\n    function getResult() public view returns (uint256 x2, uint256 y2) {\n        bytes memory tempResult = result;\n        require(tempResult.length >= 64, \"Invalid result length\");\n        assembly {\n            x2 := mload(add(tempResult, 32))\n            y2 := mload(add(tempResult, 64))\n        }\n    }\n}\n```\n\nTo use it, deploy `BN128MulExample` in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call `bn128ScalarMul` with a valid point and scalar. This [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/BN128Mul.js){target=\\_blank} shows how to test the operation and verify the expected scalar multiplication result on `alt_bn128`."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 9, "depth": 2, "title": "BN128 Pairing Check (0x08)", "anchor": "bn128-pairing-check-0x08", "start_char": 11765, "end_char": 13274, "estimated_token_count": 314, "token_estimator": "heuristic-v1", "text": "## BN128 Pairing Check (0x08)\n\nThe BN128Pairing precompile verifies a pairing equation on the alt_bn128 curve, which is critical for zk-SNARK verification.\n\n```solidity title=\"BN128Pairing.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract BN128PairingExample {\n    // Precompile address for BN128Pairing\n    address constant BN128_PAIRING_ADDRESS = address(0x08);\n\n    bytes public result;\n\n    // Performs a pairing check on the alt_bn128 curve\n    function bn128Pairing(bytes memory input) public {\n        // Call the precompile\n        (bool success, bytes memory resultInMemory) = BN128_PAIRING_ADDRESS\n            .call{value: 0}(input);\n        require(success, \"BN128Pairing precompile call failed\");\n\n        result = resultInMemory;\n    }\n\n    // Helper function to decode the result from `result` storage\n    function getResult() public view returns (bool isValid) {\n        bytes memory tempResult = result;\n        require(tempResult.length == 32, \"Invalid result length\");\n\n        uint256 output;\n        assembly {\n            output := mload(add(tempResult, 32))\n        }\n\n        isValid = (output == 1);\n    }\n}\n```\n\nYou can deploy `BN128PairingExample` in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or your preferred environment. Check out this [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/BN128Pairing.js){target=\\_blank} contains these tests with working examples."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 10, "depth": 2, "title": "Blake2F (0x09)", "anchor": "blake2f-0x09", "start_char": 13274, "end_char": 17402, "estimated_token_count": 946, "token_estimator": "heuristic-v1", "text": "## Blake2F (0x09)\n\nThe Blake2F precompile performs the Blake2 compression function F, which is the core of the Blake2 hash function.\n\n```solidity title=\"Blake2F.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract Blake2FExample {\n    // Precompile address for Blake2F\n    address constant BLAKE2F_ADDRESS = address(0x09);\n\n    bytes public result;\n\n    function blake2F(bytes memory input) public {\n        // Input must be exactly 213 bytes\n        require(input.length == 213, \"Invalid input length - must be 213 bytes\");\n\n        // Call the precompile\n        (bool success, bytes memory resultInMemory) = BLAKE2F_ADDRESS.call{\n            value: 0\n        }(input);\n        require(success, \"Blake2F precompile call failed\");\n\n        result = resultInMemory;\n    }\n\n    // Helper function to decode the result from `result` storage\n    function getResult() public view returns (bytes32[8] memory output) {\n        bytes memory tempResult = result;\n        require(tempResult.length == 64, \"Invalid result length\");\n\n        for (uint i = 0; i < 8; i++) {\n            assembly {\n                mstore(add(output, mul(32, i)), mload(add(add(tempResult, 32), mul(32, i))))\n            }\n        }\n    }\n\n\n    // Helper function to create Blake2F input from parameters\n    function createBlake2FInput(\n        uint32 rounds,\n        bytes32[8] memory h,\n        bytes32[16] memory m,\n        bytes8[2] memory t,\n        bool f\n    ) public pure returns (bytes memory) {\n        // Start with rounds (4 bytes, big-endian)\n        bytes memory input = abi.encodePacked(rounds);\n\n        // Add state vector h (8 * 32 = 256 bytes)\n        for (uint i = 0; i < 8; i++) {\n            input = abi.encodePacked(input, h[i]);\n        }\n\n        // Add message block m (16 * 32 = 512 bytes, but we need to convert to 16 * 8 = 128 bytes)\n        // Blake2F expects 64-bit words in little-endian format\n        for (uint i = 0; i < 16; i++) {\n            // Take only the first 8 bytes of each bytes32 and reverse for little-endian\n            bytes8 word = bytes8(m[i]);\n            input = abi.encodePacked(input, word);\n        }\n\n        // Add offset counters t (2 * 8 = 16 bytes)\n        input = abi.encodePacked(input, t[0], t[1]);\n\n        // Add final block flag (1 byte)\n        input = abi.encodePacked(input, f ? bytes1(0x01) : bytes1(0x00));\n\n        return input;\n    }\n\n    // Simplified function that works with raw hex input\n    function blake2FFromHex(string memory hexInput) public {\n        bytes memory input = hexStringToBytes(hexInput);\n        blake2F(input);\n    }\n\n    // Helper function to convert hex string to bytes\n    function hexStringToBytes(string memory hexString) public pure returns (bytes memory) {\n        bytes memory hexBytes = bytes(hexString);\n        require(hexBytes.length % 2 == 0, \"Invalid hex string length\");\n        \n        bytes memory result = new bytes(hexBytes.length / 2);\n        \n        for (uint i = 0; i < hexBytes.length / 2; i++) {\n            result[i] = bytes1(\n                (hexCharToByte(hexBytes[2 * i]) << 4) | \n                hexCharToByte(hexBytes[2 * i + 1])\n            );\n        }\n        \n        return result;\n    }\n\n    function hexCharToByte(bytes1 char) internal pure returns (uint8) {\n        uint8 c = uint8(char);\n        if (c >= 48 && c <= 57) return c - 48;      // 0-9\n        if (c >= 65 && c <= 70) return c - 55;      // A-F\n        if (c >= 97 && c <= 102) return c - 87;     // a-f\n        revert(\"Invalid hex character\");\n    }\n}\n```\n\nTo use it, deploy `Blake2FExample` in [Remix](/develop/smart-contracts/dev-environments/remix){target=\\_blank} or any Solidity-compatible environment and call `callBlake2F` with the properly formatted input parameters for rounds, state vector, message block, offset counters, and final block flag. This [test file](https://github.com/polkadot-developers/polkavm-hardhat-examples/blob/v0.0.3/precompiles-hardhat/test/Blake2.js){target=\\_blank} demonstrates how to perform Blake2 compression with different rounds and verify the correctness of the output against known test vectors."}
{"page_id": "develop-smart-contracts-precompiles-interact-with-precompiles", "index": 11, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 17402, "end_char": 18020, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nPrecompiles in Polkadot Hub provide efficient, native implementations of cryptographic functions and other commonly used operations. By understanding how to interact with these precompiles from your Solidity contracts, you can build more efficient and feature-rich applications on the Polkadot ecosystem.\n\nThe examples provided in this guide demonstrate the basic patterns for interacting with each precompile. Developers can adapt these patterns to their specific use cases, leveraging the performance benefits of native implementations while maintaining the flexibility of smart contract development."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 913, "estimated_token_count": 191, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [XCM (Cross-Consensus Message)](/develop/interoperability/intro-to-xcm){target=\\_blank} precompile enables Polkadot Hub developers to access XCM functionality directly from their smart contracts using a Solidity interface.\n\nLocated at the fixed address `0x00000000000000000000000000000000000a0000`, the XCM precompile offers three primary functions:\n\n- **`execute`**: For local XCM execution.\n- **`send`**: For cross-chain message transmission.\n- **`weighMessage`**: For cost estimation.\n\nThis guide demonstrates how to interact with the XCM precompile through Solidity smart contracts using [Remix IDE](/develop/smart-contracts/dev-environments/remix){target=\\_blank}.\n\n!!!note\n    The XCM precompile provides the barebones XCM functionality. While it provides a lot of flexibility, it doesn't provide abstractions to hide away XCM details. These have to be built on top."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 1, "depth": 2, "title": "Precompile Interface", "anchor": "precompile-interface", "start_char": 913, "end_char": 4065, "estimated_token_count": 709, "token_estimator": "heuristic-v1", "text": "## Precompile Interface\n\nThe XCM precompile implements the `IXcm` interface, which defines the structure for interacting with XCM functionality. The source code for the interface is as follows:\n\n```solidity title=\"IXcm.sol\"\n-// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n\n/// @dev The on-chain address of the XCM (Cross-Consensus Messaging) precompile.\naddress constant XCM_PRECOMPILE_ADDRESS = address(0xA0000);\n\n/// @title XCM Precompile Interface\n/// @notice A low-level interface for interacting with `pallet_xcm`.\n/// It forwards calls directly to the corresponding dispatchable functions,\n/// providing access to XCM execution and message passing.\n/// @dev Documentation:\n/// @dev - XCM: https://docs.polkadot.com/develop/interoperability\n/// @dev - SCALE codec: https://docs.polkadot.com/polkadot-protocol/parachain-basics/data-encoding\n/// @dev - Weights: https://docs.polkadot.com/polkadot-protocol/parachain-basics/blocks-transactions-fees/fees/#transactions-weights-and-fees\ninterface IXcm {\n    /// @notice Weight v2 used for measurement for an XCM execution\n    struct Weight {\n        /// @custom:property The computational time used to execute some logic based on reference hardware.\n        uint64 refTime;\n        /// @custom:property The size of the proof needed to execute some logic.\n        uint64 proofSize;\n    }\n\n    /// @notice Executes an XCM message locally on the current chain with the caller's origin.\n    /// @dev Internally calls `pallet_xcm::execute`.\n    /// @param message A SCALE-encoded Versioned XCM message.\n    /// @param weight The maximum allowed `Weight` for execution.\n    /// @dev Call @custom:function weighMessage(message) to ensure sufficient weight allocation.\n    function execute(bytes calldata message, Weight calldata weight) external;\n\n    /// @notice Sends an XCM message to another parachain or consensus system.\n    /// @dev Internally calls `pallet_xcm::send`.\n    /// @param destination SCALE-encoded destination MultiLocation.\n    /// @param message SCALE-encoded Versioned XCM message.\n    function send(bytes calldata destination, bytes calldata message) external;\n\n    /// @notice Estimates the `Weight` required to execute a given XCM message.\n    /// @param message SCALE-encoded Versioned XCM message to analyze.\n    /// @return weight Struct containing estimated `refTime` and `proofSize`.\n    function weighMessage(bytes calldata message) external view returns (Weight memory weight);\n}\n```\n\nThe interface defines a `Weight` struct that represents the computational cost of XCM operations. Weight has two components: \n\n- **`refTime`**: Computational time on reference hardware.\n- **`proofSize`**: The size of the proof required for execution.\n\nAll XCM messages must be encoded using the [SCALE codec](/polkadot-protocol/parachain-basics/data-encoding/#data-encoding){target=\\_blank}, Polkadot's standard serialization format.\n\nFor further information, check the [`precompiles/IXCM.sol`](https://github.com/paritytech/polkadot-sdk/blob/cb629d46ebf00aa65624013a61f9c69ebf02b0b4/polkadot/xcm/pallet-xcm/src/precompiles/IXcm.sol){target=\\_blank} file present in `pallet-xcm`."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 2, "depth": 2, "title": "Interact with the XCM Precompile", "anchor": "interact-with-the-xcm-precompile", "start_char": 4065, "end_char": 5304, "estimated_token_count": 306, "token_estimator": "heuristic-v1", "text": "## Interact with the XCM Precompile\n\nTo interact with the XCM precompile, you can use the precompile interface directly in [Remix IDE](/develop/smart-contracts/dev-environments/remix/){target=\\_blank}:\n\n1. Create a new file called `IXcm.sol` in Remix.\n2. Copy and paste the `IXcm` interface code into the file.\n3. Compile the interface by selecting the button or using **Ctrl +S** keys:\n\n    ![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-01.webp)\n\n4. In the **Deploy & Run Transactions** tab, select the `IXcm` interface from the contract dropdown.\n5. Enter the precompile address `0x00000000000000000000000000000000000a0000` in the **At Address** input field.\n6. Select the **At Address** button to connect to the precompile.\n\n    ![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-02.webp)\n\n7. Once connected, you can use the Remix interface to interact with the XCM precompile's  `execute`, `send`, and `weighMessage` functions.\n\n    ![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-03.webp)\n\nThe main entrypoint of the precompile is the `execute` function. However, it's necessary to first call `weighMessage` to fill in the required parameters."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 3, "depth": 3, "title": "Weigh a Message", "anchor": "weigh-a-message", "start_char": 5304, "end_char": 7543, "estimated_token_count": 485, "token_estimator": "heuristic-v1", "text": "### Weigh a Message\n\nThe `weighMessage` function estimates the computational cost required to execute an XCM message. This estimate is crucial for understanding the resources needed before actually executing or sending a message.\n\nTo test this functionality in Remix, you can call `callWeighMessage` with a SCALE-encoded XCM message. For example, for testing, you can use the following encoded XCM message:\n\n```text title=\"encoded-xcm-message-example\"\n0x050c000401000003008c86471301000003008c8647000d010101000000010100368e8759910dab756d344995f1d3c79374ca8f70066d3a709e48029f6bf0ee7e\n```\n\n![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-04.webp)\n\nThis encoded message represents a sequence of XCM instructions:\n\n- **[Withdraw Asset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#withdrawasset){target=\\_blank}**: This instruction removes assets from the local chain's sovereign account or the caller's account, making them available for use in subsequent XCM instructions.\n- **[Buy Execution](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#buyexecution){target=\\_blank}**: This instruction purchases execution time on the destination chain using the withdrawn assets, ensuring the message can be processed.\n- **[Deposit Asset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#depositasset){target=\\_blank}**: This instruction deposits the remaining assets into a specified account on the destination chain after execution costs have been deducted.\n\nThis encoded message is provided as an example. You can craft your own XCM message tailored to your specific use case as needed.\n\nThe function returns a `Weight` struct containing `refTime` and `proofSize` values, which indicate the estimated computational cost of executing this message. If successful, after calling the `callWeighMessage` function, you should see the `refTime` and `proofSize` of the message:\n\n![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-05.webp)\n\n!!!note\n    You can find many more examples of XCMs in this [gist](https://gist.github.com/franciscoaguirre/a6dea0c55e81faba65bedf700033a1a2){target=\\_blank}, which connects to the Polkadot Hub TestNet."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 4, "depth": 3, "title": "Execute a Message", "anchor": "execute-a-message", "start_char": 7543, "end_char": 9049, "estimated_token_count": 315, "token_estimator": "heuristic-v1", "text": "### Execute a Message\n\nThe `execute` function runs an XCM message locally using the caller's origin.\nThis function is the main entrypoint to cross-chain interactions.\n\nFollow these steps to execute a message:\n\n1. Call `weighMessage` with your message to get the required weight.\n2. Pass the same message bytes and the weight obtained from the previous step to `execute`.\nFor example, using the same message from the weighing example, you would call `execute` with:\n\n    - **`message`**: The encoded XCM message bytes.\n    - **`weight`**: The `Weight` struct returned from `weighMessage`.\n\n    You can use the [papi console](https://dev.papi.how/extrinsics#networkId=localhost&endpoint=wss%3A%2F%2Ftestnet-passet-hub.polkadot.io&data=0x1f03050c000401000003008c86471301000003008c8647000d010101000000010100368e8759910dab756d344995f1d3c79374ca8f70066d3a709e48029f6bf0ee7e0750c61e2901daad0600){target=\\_blank} to examine the complete extrinsic structure for this operation.\n\n3. On Remix, click on the **Transact** button to execute the XCM message:\n  \n    ![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-06.webp)\n\n    If successful, you will see the following output in the Remix terminal:\n\n    ![](/images/develop/smart-contracts/precompiles/xcm-precompile/xcm-precompile-07.webp)\n\nAdditionally, you can verify that the execution of this specific message was successful by checking that the beneficiary account associated with the XCM message has received the funds accordingly."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 5, "depth": 3, "title": "Send a Message", "anchor": "send-a-message", "start_char": 9049, "end_char": 9775, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "### Send a Message\n\nWhile most cross-chain operations can be performed via `execute`, `send` is sometimes necessary, for example, when opening HRMP channels.\n\nTo send a message:\n\n1. Prepare your destination location encoded in XCM format.\n2. Prepare your XCM message (similar to the execute example).\n3. Call `send` with both parameters.\n\nThe destination parameter must be encoded according to XCM's location format, specifying the target parachain or consensus system. The message parameter contains the XCM instructions to be executed on the destination chain.\n\nUnlike `execute`, the `send` function doesn't require a weight parameter since the destination chain will handle execution costs according to its fee structure."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 6, "depth": 2, "title": "Cross Contract Calls", "anchor": "cross-contract-calls", "start_char": 9775, "end_char": 10273, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Cross Contract Calls\n\nBeyond direct interaction and wrapper contracts, you can integrate XCM functionality directly into your existing smart contracts by inheriting from or importing the `IXcm` interface. This approach enables you to embed cross-chain capabilities into your application logic seamlessly.\n\nWhether you're building DeFi protocols, governance systems, or any application requiring cross-chain coordination, you can incorporate XCM calls directly within your contract's functions."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 7, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 10273, "end_char": 10580, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThe XCM precompile provides a simple yet powerful interface for cross-chain interactions within the Polkadot ecosystem and beyond.\nBy building and executing XCM programs, developers can build cross-chain applications that leverage the full potential of Polkadot's interoperability features."}
{"page_id": "develop-smart-contracts-precompiles-xcm-precompile", "index": 8, "depth": 2, "title": "Next steps", "anchor": "next-steps", "start_char": 10580, "end_char": 10770, "estimated_token_count": 36, "token_estimator": "heuristic-v1", "text": "## Next steps\n\nHead to the Polkadot Hub TestNet and start playing around with the precompile using Hardhat or Foundry.\n\nYou can use PAPI to build XCM programs and test them with Chopsticks."}
{"page_id": "develop-smart-contracts-wallets", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 200, "end_char": 667, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nConnecting a compatible wallet is the first essential step for interacting with the Polkadot Hub ecosystem. This guide explores wallet options that support both Substrate and Ethereum compatible layers, enabling transactions and smart contract interactions. Whether you're a developer testing on Polkadot Hub or a user accessing the MainNet, understanding wallet configuration is crucial for accessing the full range of Polkadot Hub's capabilities."}
{"page_id": "develop-smart-contracts-wallets", "index": 1, "depth": 2, "title": "Connect Your Wallet", "anchor": "connect-your-wallet", "start_char": 667, "end_char": 691, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Connect Your Wallet"}
{"page_id": "develop-smart-contracts-wallets", "index": 2, "depth": 3, "title": "MetaMask", "anchor": "metamask", "start_char": 691, "end_char": 2384, "estimated_token_count": 408, "token_estimator": "heuristic-v1", "text": "### MetaMask\n\n[MetaMask](https://metamask.io/){target=\\_blank} is a popular wallet for interacting with Ethereum-compatible chains. It allows users to connect to test networks that support Ethereum-based smart contracts. However, it's important to emphasize that MetaMask primarily facilitates interactions with smart contracts, giving users access to various chain functionalities. \n\nTo get started with MetaMask, you need to install the [MetaMask extension](https://metamask.io/download/){target=\\_blank} and add it to the browser. Once you install MetaMask, you can set up a new wallet and securely store your seed phrase. This phrase is crucial for recovery in case you lose access.\n\nFor example, to connect to the Polkadot Hub TestNet via MetaMask, you need to follow these steps:\n\n1. Open the MetaMask extension and click on the network icon to switch to the Polkadot Hub TestNet.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-1.webp){: .browser-extension}\n\n2. Click on the **Add a custom network** button.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-2.webp){: .browser-extension}\n\n3. Complete the necessary fields, then click the **Save** button (refer to the [Networks](/develop/smart-contracts/connect-to-polkadot#networks-details){target=\\_blank} section for copy and paste parameters).\n\n    ![](/images/develop/smart-contracts/wallets/wallets-3.webp){: .browser-extension}\n\n4. Click on **Polkadot Hub TestNet** to switch the network.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-4.webp){: .browser-extension}\n\nThe steps in the preceding section can be used to connect to any chain by modifying the network specification and endpoint parameters."}
{"page_id": "develop-smart-contracts-wallets", "index": 3, "depth": 3, "title": "SubWallet", "anchor": "subwallet", "start_char": 2384, "end_char": 4965, "estimated_token_count": 619, "token_estimator": "heuristic-v1", "text": "### SubWallet\n\n[SubWallet](https://www.subwallet.app/){target=\\_blank} is a popular non-custodial wallet solution for Polkadot and Ethereum ecosystems. It offers seamless integration with Polkadot SDK-based networks while maintaining Ethereum compatibility, making the wallet an ideal choice for users and developers to interact with Polkadot Hub.\n\nSubWallet now fully supports the [Polkadot Hub TestNet](/polkadot-protocol/smart-contract-basics/networks/#test-networks){target=\\_blank} where developers can deploy and interact with Ethereum-compatible, Solidity smart contracts.\n\nYou can easily view and manage your Paseo native token (PAS) using the Ethereum RPC endpoint (Passet Hub EVM) or the Substrate node RPC endpoint (passet-hub).\n\n??? code \"Polkadot Hub TestNet\"\n    You can see support here for Polkadot Hub's TestNet. The **Passet Hub EVM** network uses an ETH RPC endpoint, and the **passet-hub** uses a Substrate endpoint.\n    The ETH RPC endpoint will let you send transactions that follow an ETH format, while the Substrate endpoint will follow a Substrate transaction format.\n    Note the PAS token, which is the native token of the Polkadot Hub TestNet.\n\n    ![](/images/develop/smart-contracts/wallets/subwallet-PAS.webp){: .browser-extension}\n\nTo connect to Polkadot Hub TestNet using SubWallet, follow these steps:\n\n1. Install the [SubWallet browser extension](https://chromewebstore.google.com/detail/subwallet-polkadot-wallet/onhogfjeacnfoofkfgppdlbmlmnplgbn?hl=en){target=\\_blank} and set up your wallet by following the on-screen instructions, or refer to our [step-by-step guide](https://docs.subwallet.app/main/extension-user-guide/getting-started/install-subwallet){target=\\_blank} for assistance.\n\n2. After setting up your wallet, click the List icon at the top left corner of the extension window to open **Settings**.\n\n    ![](/images/develop/smart-contracts/wallets/subwallet-01.webp){: .browser-extension}\n\n3. Scroll down and select **Manage networks**.\n\n    ![](/images/develop/smart-contracts/wallets/subwallet-02.webp){: .browser-extension}\n\n4. In the Manage network screen, either scroll down or type in the search bar to find the networks. Once done, enable the toggle next to the network name.\n\n    ![](/images/develop/smart-contracts/wallets/subwallet-03.webp){: .browser-extension}\n\n   You are now ready to use SubWallet to interact with [Polkadot Hub TestNet](/develop/smart-contracts/connect-to-polkadot/#networks-details){target=\\_blank} seamlessly!\n\n![](/images/develop/smart-contracts/wallets/subwallet-04.webp){: .browser-extension}"}
{"page_id": "develop-smart-contracts-wallets", "index": 4, "depth": 3, "title": "Talisman", "anchor": "talisman", "start_char": 4965, "end_char": 6677, "estimated_token_count": 431, "token_estimator": "heuristic-v1", "text": "### Talisman\n\n[Talisman](https://talisman.xyz/){target=\\_blank} is a specialized wallet for the Polkadot ecosystem that supports both Substrate and EVM accounts, making it an excellent choice for Polkadot Hub interactions. Talisman offers a more integrated experience for Polkadot-based chains while still providing Ethereum compatibility.\n\nTo use Talisman with Polkadot Hub TestNet:\n\n1. Install the [Talisman extension](https://talisman.xyz/download){target=\\_blank} and set up your wallet by following the on-screen instructions.\n\n2. Once installed, click on the Talisman icon in your browser extensions and click on the **Settings** button.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-5.webp){: .browser-extension}\n\n3. Click the button **All settings**.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-6.webp){: .browser-extension}\n\n4. Go to the **Networks & Tokens** section.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-7.webp)\n\n5. Click the **Manage networks** button.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-8.webp)\n\n6. Click the **+ Add network** button.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-9.webp)\n\n7. Fill in the form with the required parameters and click the **Add network** button.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-10.webp)\n\n8. After that, you can switch to the Polkadot Hub TestNet by clicking on the network icon and selecting **Polkadot Hub TestNet**.\n\n    ![](/images/develop/smart-contracts/wallets/wallets-11.webp)\n\nAfter selecting the network, Talisman will automatically configure the necessary RPC URL and chain ID for you. You can now use Talisman to interact with the Polkadot Hub TestNet."}
{"page_id": "develop-smart-contracts-wallets", "index": 5, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 6677, "end_char": 7301, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nChoosing the right wallet for Polkadot Hub interactions depends on your specific requirements and familiarity with different interfaces. MetaMask provides a familiar entry point for developers with Ethereum experience, while Talisman offers deeper integration with Polkadot's unique features and native support for both EVM and Substrate accounts. By properly configuring your wallet connection, you gain access to the full spectrum of Polkadot Hub's capabilities.\n\n!!!info\n    Remember to always verify network parameters when connecting to ensure a secure and reliable connection to the Polkadot ecosystem."}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 9, "end_char": 445, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Dedot](https://github.com/dedotdev/dedot){target=\\_blank} is a next-generation JavaScript client for Polkadot and Polkadot SDK-based blockchains. Designed to elevate the dApp development experience, Dedot is built and optimized to be lightweight and tree-shakable, offering precise types and APIs suggestions for individual Polkadot SDK-based blockchains and [ink! smart contracts](https://use.ink/){target=\\_blank}."}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 1, "depth": 3, "title": "Key Features", "anchor": "key-features", "start_char": 445, "end_char": 1529, "estimated_token_count": 298, "token_estimator": "heuristic-v1", "text": "### Key Features\n\n- **Lightweight and tree-shakable**: No more bn.js or WebAssembly blobs, optimized for dapps bundle size.\n- **Fully typed API**: Comprehensive TypeScript support for seamless on-chain interaction and ink! smart contract integration.\n- **Multi-version JSON-RPC support**: Compatible with both [legacy](https://github.com/w3f/PSPs/blob/master/PSPs/drafts/psp-6.md){target=\\_blank} and [new](https://paritytech.github.io/json-rpc-interface-spec/introduction.html){target=\\_blank} JSON-RPC APIs for broad ecosystem interoperability.\n- **Light client support**: Designed to work with light clients such as [Smoldot](https://github.com/smol-dot/smoldot){target=\\_blank}.\n- **Native TypeScript for scale codec**: Implements scale codec parsing directly in TypeScript without relying on custom wrappers.\n- **Wallet integration**: Works out-of-the-box with [@polkadot/extension-based](https://github.com/polkadot-js/extension?tab=readme-ov-file#api-interface){target=\\_blank} wallets.\n- **Familiar API design**: Similar API style to Polkadot.js for easy and fast migration."}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 2, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1529, "end_char": 2152, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo add Dedot to your project, use the following command:\n\n=== \"npm\"\n\n    ```bash\n    npm i dedot\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add dedot\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add dedot\n    ```\n\nTo enable auto-completion/IntelliSense for individual chains, install the [`@dedot/chaintypes`](https://www.npmjs.com/package/@dedot/chaintypes){target=\\_blank} package as a development dependency:\n\n=== \"npm\"\n\n    ```bash\n    npm i -D @dedot/chaintypes\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add -D @dedot/chaintypes\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add -D @dedot/chaintypes\n    ```"}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 3, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 2152, "end_char": 2168, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 4, "depth": 3, "title": "Initialize a Client Instance", "anchor": "initialize-a-client-instance", "start_char": 2168, "end_char": 4189, "estimated_token_count": 525, "token_estimator": "heuristic-v1", "text": "### Initialize a Client Instance\n\nTo connect to and interact with different networks, Dedot provides two client options depending on your needs:\n\n- **[`DedotClient`](https://docs.dedot.dev/clients-and-providers/clients#dedotclient){target=\\_blank}**: Interacts with chains via the [new JSON-RPC APIs](https://paritytech.github.io/json-rpc-interface-spec/introduction.html){target=\\_blank}.\n- **[`LegacyClient`](https://docs.dedot.dev/clients-and-providers/clients#legacyclient){target=\\_blank}**: Interacts with chains via the [legacy JSON-RPC APIs](https://github.com/w3f/PSPs/blob/master/PSPs/drafts/psp-6.md){target=\\_blank}.\n\nUse the following snippets to connect to Polkadot using `DedotClient`:\n\n=== \"WebSocket\"\n\n    ```typescript\n    -import { DedotClient, WsProvider } from 'dedot';\nimport type { PolkadotApi } from '@dedot/chaintypes';\n\n// Initialize providers & clients\nconst provider = new WsProvider('wss://rpc.polkadot.io');\nconst client = await DedotClient.new<PolkadotApi>(provider);\n\n    ```\n\n=== \"Light Client (Smoldot)\"\n\n    ```typescript\n    -import { DedotClient, SmoldotProvider } from 'dedot';\nimport type { PolkadotApi } from '@dedot/chaintypes';\nimport * as smoldot from 'smoldot';\n\n// import `polkadot` chain spec to connect to Polkadot\nimport { polkadot } from '@substrate/connect-known-chains';\n\n// Start smoldot instance & initialize a chain\nconst client = smoldot.start();\nconst chain = await client.addChain({ chainSpec: polkadot });\n\n// Initialize providers & clients\nconst provider = new SmoldotProvider(chain);\nconst client = await DedotClient.new<PolkadotApi>(provider);\n\n    ```\n\nIf the node doesn't support new JSON-RPC APIs yet, you can connect to the network using the `LegacyClient`, which is built on top of the legacy JSON-RPC APIs.\n\n```typescript\n-import { LegacyClient, WsProvider } from 'dedot';\nimport type { PolkadotApi } from '@dedot/chaintypes';\n\nconst provider = new WsProvider('wss://rpc.polkadot.io');\nconst client = await LegacyClient.new<PolkadotApi>(provider);\n\n```"}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 5, "depth": 3, "title": "Enable Type and API Suggestions", "anchor": "enable-type-and-api-suggestions", "start_char": 4189, "end_char": 5610, "estimated_token_count": 378, "token_estimator": "heuristic-v1", "text": "### Enable Type and API Suggestions\n\nIt is recommended to specify the `ChainApi` interface (e.g., `PolkadotApi` in the example in the previous section) of the chain you want to interact with. This enables type and API suggestions/autocompletion for that particular chain (via IntelliSense). If you don't specify a `ChainApi` interface, a default `SubstrateApi` interface will be used.\n\n```typescript\n-import { DedotClient, WsProvider } from 'dedot';\nimport type { PolkadotApi, KusamaApi } from '@dedot/chaintypes';\n\nconst polkadotClient = await DedotClient.new<PolkadotApi>(\n  new WsProvider('wss://rpc.polkadot.io')\n);\nconst kusamaClient = await DedotClient.new<KusamaApi>(\n  new WsProvider('wss://kusama-rpc.polkadot.io')\n);\nconst genericClient = await DedotClient.new(\n  new WsProvider('ws://localhost:9944')\n);\n\n```\n\nIf you don't find the `ChainApi` for the network you're working with in [the list](https://github.com/dedotdev/chaintypes?tab=readme-ov-file#supported-networks){target=\\_blank}, you can generate the `ChainApi` (types and APIs) using the built-in [`dedot` cli](https://docs.dedot.dev/cli){target=\\_blank}.\n\n```bash\n# Generate ChainApi interface for Polkadot network via rpc endpoint: wss://rpc.polkadot.io\nnpx dedot chaintypes -w wss://rpc.polkadot.io\n```\n\nOr open a pull request to add your favorite network to the [`@dedot/chaintypes`](https://github.com/dedotdev/chaintypes){target=\\_blank} repo."}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 6, "depth": 3, "title": "Read On-Chain Data", "anchor": "read-on-chain-data", "start_char": 5610, "end_char": 6918, "estimated_token_count": 353, "token_estimator": "heuristic-v1", "text": "### Read On-Chain Data\n\nDedot provides several ways to read data from the chain:\n\n- **Access runtime constants**: Use the syntax `client.consts.<pallet>.<constantName>` to inspect runtime constants (parameter types).\n\n    ```typescript\n    -const ss58Prefix = client.consts.system.ss58Prefix;\nconsole.log('Polkadot ss58Prefix:', ss58Prefix);\n\n    ```\n\n- **Storage queries**: Use the syntax `client.query.<pallet>.<storgeEntry>` to query on-chain storage.\n\n    ```typescript\n    -const balance = await client.query.system.account('INSERT_ADDRESS');\nconsole.log('Balance:', balance.data.free);\n\n    ```\n\n- **Subscribe to storage changes**:\n\n    ```typescript\n    -const unsub = await client.query.system.number((blockNumber) => {\n  console.log(`Current block number: ${blockNumber}`);\n});\n\n    ```\n\n- **Call Runtime APIs**: Use the syntax `client.call.<runtimeApi>.<methodName>` to execute Runtime APIs.\n\n    ```typescript\n    -const metadata = await client.call.metadata.metadataAtVersion(15);\nconsole.log('Metadata V15', metadata);\n\n    ```\n\n- **Watch on-chain events**: Use the syntax `client.events.<pallet>.<eventName>` to access pallet events.\n    \n    ```typescript\n    -const unsub = await client.events.system.NewAccount.watch((events) => {\n  console.log('New Account Created', events);\n});\n\n    ```"}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 7, "depth": 3, "title": "Sign and Send Transactions", "anchor": "sign-and-send-transactions", "start_char": 6918, "end_char": 8646, "estimated_token_count": 441, "token_estimator": "heuristic-v1", "text": "### Sign and Send Transactions\n\nSign the transaction using `IKeyringPair` from Keyring ([`@polkadot/keyring`](https://polkadot.js.org/docs/keyring/start/sign-verify/){target=\\_blank}) and send the transaction.\n\n```typescript\n-import { cryptoWaitReady } from '@polkadot/util-crypto';\nimport { Keyring } from '@polkadot/keyring';\n// Setup keyring\nawait cryptoWaitReady();\nconst keyring = new Keyring({ type: 'sr25519' });\nconst alice = keyring.addFromUri('//Alice');\n// Send transaction\nconst unsub = await client.tx.balances\n  .transferKeepAlive('INSERT_DEST_ADDRESS', 2_000_000_000_000n)\n  .signAndSend(alice, async ({ status }) => {\n    console.log('Transaction status', status.type);\n    if (status.type === 'BestChainBlockIncluded') {\n      console.log(`Transaction is included in best block`);\n    }\n    if (status.type === 'Finalized') {\n      console.log(\n        `Transaction completed at block hash ${status.value.blockHash}`\n      );\n      await unsub();\n    }\n  });\n\n```\n\nYou can also use `Signer` from wallet extensions:\n\n```typescript\n-const injected = await window.injectedWeb3['polkadot-js'].enable('My dApp');\nconst account = (await injected.accounts.get())[0];\nconst signer = injected.signer;\nconst unsub = await client.tx.balances\n  .transferKeepAlive('INSERT_DEST_ADDRESS', 2_000_000_000_000n)\n  .signAndSend(account.address, { signer }, async ({ status }) => {\n    console.log('Transaction status', status.type);\n    if (status.type === 'BestChainBlockIncluded') {\n      console.log(`Transaction is included in best block`);\n    }\n    if (status.type === 'Finalized') {\n      console.log(\n        `Transaction completed at block hash ${status.value.blockHash}`\n      );\n      await unsub();\n    }\n  });\n\n```"}
{"page_id": "develop-toolkit-api-libraries-dedot", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 8646, "end_char": 8782, "estimated_token_count": 36, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor more detailed information about Dedot, check the [official documentation](https://dedot.dev/){target=\\_blank}."}
{"page_id": "develop-toolkit-api-libraries-papi", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 1133, "estimated_token_count": 207, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Polkadot-API](https://github.com/polkadot-api/polkadot-api){target=\\_blank} (PAPI) is a set of libraries built to be modular, composable, and grounded in a “light-client first” approach. Its primary aim is to equip dApp developers with an extensive toolkit for building fully decentralized applications.\n\nPAPI is optimized for light-client functionality, using the new JSON-RPC spec to support decentralized interactions fully. It provides strong TypeScript support with types and documentation generated directly from on-chain metadata, and it offers seamless access to storage reads, constants, transactions, events, and runtime calls. Developers can connect to multiple chains simultaneously and prepare for runtime updates through multi-descriptor generation and compatibility checks. PAPI is lightweight and performant, leveraging native BigInt, dynamic imports, and modular subpaths to avoid bundling unnecessary assets. It supports promise-based and observable-based APIs, integrates easily with Polkadot.js extensions, and offers signing options through browser extensions or private keys."}
{"page_id": "develop-toolkit-api-libraries-papi", "index": 1, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 1133, "end_char": 1149, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "develop-toolkit-api-libraries-papi", "index": 2, "depth": 3, "title": "API Instantiation", "anchor": "api-instantiation", "start_char": 1149, "end_char": 5958, "estimated_token_count": 1166, "token_estimator": "heuristic-v1", "text": "### API Instantiation\n\nTo instantiate the API, you can install the package by using the following command:\n\n=== \"npm\"\n\n    ```bash\n    npm i polkadot-api@1.16.2\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add polkadot-api@1.16.2\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add polkadot-api@1.16.2\n    ```\n\nThen, obtain the latest metadata from the target chain and generate the necessary types:\n\n```bash\n# Add the target chain\nnpx papi add dot -n polkadot\n```\n\nThe `papi add` command initializes the library by generating the corresponding types needed for the chain used. It assigns the chain a custom name and specifies downloading metadata from the Polkadot chain. You can replace `dot` with the name you prefer or with another chain if you want to add a different one. Once the latest metadata is downloaded, generate the required types:\n\n```bash\n# Generate the necessary types\nnpx papi\n```\n\nYou can now set up a [`PolkadotClient`](https://github.com/polkadot-api/polkadot-api/blob/main/packages/client/src/types.ts#L153){target=\\_blank} with your chosen provider to begin interacting with the API. Choose from Smoldot via WebWorker, Node.js, or direct usage, or connect through the WSS provider. The examples below show how to configure each option for your setup.\n\n=== \"Smoldot (WebWorker)\"\n\n    ```typescript\n    -// `dot` is the identifier assigned during `npx papi add`\nimport { dot } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { getSmProvider } from 'polkadot-api/sm-provider';\nimport { chainSpec } from 'polkadot-api/chains/polkadot';\nimport { startFromWorker } from 'polkadot-api/smoldot/from-worker';\nimport SmWorker from 'polkadot-api/smoldot/worker?worker';\n\nconst worker = new SmWorker();\nconst smoldot = startFromWorker(worker);\nconst chain = await smoldot.addChain({ chainSpec });\n\n// Establish connection to the Polkadot relay chain\nconst client = createClient(getSmProvider(chain));\n\n// To interact with the chain, obtain the `TypedApi`, which provides\n// the necessary types for every API call on this chain\nconst dotApi = client.getTypedApi(dot);\n\n    ```\n\n=== \"Smoldot (Node.js)\"\n\n    ```typescript\n    -// `dot` is the alias assigned during `npx papi add`\nimport { dot } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { getSmProvider } from 'polkadot-api/sm-provider';\nimport { chainSpec } from 'polkadot-api/chains/polkadot';\nimport { startFromWorker } from 'polkadot-api/smoldot/from-node-worker';\nimport { fileURLToPath } from 'url';\nimport { Worker } from 'worker_threads';\n\n// Get the path for the worker file in ESM\nconst workerPath = fileURLToPath(\n  import.meta.resolve('polkadot-api/smoldot/node-worker'),\n);\n\nconst worker = new Worker(workerPath);\nconst smoldot = startFromWorker(worker);\nconst chain = await smoldot.addChain({ chainSpec });\n\n// Set up a client to connect to the Polkadot relay chain\nconst client = createClient(getSmProvider(chain));\n\n// To interact with the chain's API, use `TypedApi` for access to\n// all the necessary types and calls associated with this chain\nconst dotApi = client.getTypedApi(dot);\n\n    ```\n\n=== \"Smoldot\"\n\n    ```typescript\n    -// `dot` is the alias assigned when running `npx papi add`\nimport { dot } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { getSmProvider } from 'polkadot-api/sm-provider';\nimport { chainSpec } from 'polkadot-api/chains/polkadot';\nimport { start } from 'polkadot-api/smoldot';\n\n// Initialize Smoldot client\nconst smoldot = start();\nconst chain = await smoldot.addChain({ chainSpec });\n\n// Set up a client to connect to the Polkadot relay chain\nconst client = createClient(getSmProvider(chain));\n\n// Access the `TypedApi` to interact with all available chain calls and types\nconst dotApi = client.getTypedApi(dot);\n\n    ```\n\n=== \"WSS\"\n\n    ```typescript\n    -// `dot` is the identifier assigned when executing `npx papi add`\nimport { dot } from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\n// Use this import for Node.js environments\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\n\n// Establish a connection to the Polkadot relay chain\nconst client = createClient(\n  // The Polkadot SDK nodes may have compatibility issues; using this enhancer is recommended.\n  // Refer to the Requirements page for additional details\n  withPolkadotSdkCompat(getWsProvider('wss://dot-rpc.stakeworld.io')),\n);\n\n// To interact with the chain, obtain the `TypedApi`, which provides\n// the types for all available calls in that chain\nconst dotApi = client.getTypedApi(dot);\n\n    ```\n\nNow that you have set up the client, you can interact with the chain by reading and sending transactions."}
{"page_id": "develop-toolkit-api-libraries-papi", "index": 3, "depth": 3, "title": "Reading Chain Data", "anchor": "reading-chain-data", "start_char": 5958, "end_char": 6908, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Reading Chain Data\n\nThe `TypedApi` provides a streamlined way to read blockchain data through three main interfaces, each designed for specific data access patterns:\n\n- **Constants**: Access fixed values or configurations on the blockchain using the `constants` interface.\n\n    ```typescript\n    const version = await typedApi.constants.System.Version();\n    ```\n\n- **Storage queries**: Retrieve stored values by querying the blockchain’s storage via the `query` interface.\n\n    ```typescript\n    const asset = await api.query.ForeignAssets.Asset.getValue(\n      token.location,\n      { at: 'best' },\n    );\n    ```\n\n- **Runtime APIs**: Interact directly with runtime APIs using the `apis` interface.\n\n    ```typescript\n    const metadata = await typedApi.apis.Metadata.metadata();\n    ```\n\nTo learn more about the different actions you can perform with the `TypedApi`, refer to the [TypedApi reference](https://papi.how/typed){target=\\_blank}."}
{"page_id": "develop-toolkit-api-libraries-papi", "index": 4, "depth": 3, "title": "Sending Transactions", "anchor": "sending-transactions", "start_char": 6908, "end_char": 8568, "estimated_token_count": 356, "token_estimator": "heuristic-v1", "text": "### Sending Transactions\n\nIn PAPI, the `TypedApi` provides the `tx` and `txFromCallData` methods to send transactions. \n\n- The `tx` method allows you to directly send a transaction with the specified parameters by using the `typedApi.tx.Pallet.Call` pattern:\n\n    ```typescript\n    const tx: Transaction = typedApi.tx.Pallet.Call({arg1, arg2, arg3});\n    ``` \n\n    For instance, to execute the `balances.transferKeepAlive` call, you can use the following snippet:\n\n    ```typescript\n    -import { MultiAddress } from '@polkadot-api/descriptors';\n\nconst tx: Transaction = typedApi.tx.Balances.transfer_keep_alive({\n  dest: MultiAddress.Id('INSERT_DESTINATION_ADDRESS'),\n  value: BigInt(INSERT_VALUE),\n});\n\n    ```\n\n    Ensure you replace `INSERT_DESTINATION_ADDRESS` and `INSERT_VALUE` with the actual destination address and value, respectively.\n\n- The `txFromCallData` method allows you to send a transaction using the call data. This option accepts binary call data and constructs the transaction from it. It validates the input upon creation and will throw an error if invalid data is provided. The pattern is as follows:\n\n    ```typescript\n    const callData = Binary.fromHex('0x...');\n    const tx: Transaction = typedApi.txFromCallData(callData);\n    ``` \n\n    For instance, to execute a transaction using the call data, you can use the following snippet:\n\n    ```typescript\n    const callData = Binary.fromHex('0x00002470617065726d6f6f6e');\n    const tx: Transaction = typedApi.txFromCallData(callData);\n    ```\n\nFor more information about sending transactions, refer to the [Transactions](https://papi.how/typed/tx#transactions){target=\\_blank} page."}
{"page_id": "develop-toolkit-api-libraries-papi", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 8568, "end_char": 8710, "estimated_token_count": 43, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor an in-depth guide on how to use PAPI, refer to the official [PAPI](https://papi.how/){target=\\_blank} documentation."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 385, "end_char": 669, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot.js API](https://github.com/polkadot-js/api){target=\\_blank} uses JavaScript/TypeScript to interact with Polkadot SDK-based chains. It allows you to query nodes, read chain state, and submit transactions through a dynamic, auto-generated API interface."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 1, "depth": 3, "title": "Dynamic API Generation", "anchor": "dynamic-api-generation", "start_char": 669, "end_char": 1033, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "### Dynamic API Generation\n\nUnlike traditional static APIs, the Polkadot.js API generates its interfaces automatically when connecting to a node. Here's what happens when you connect:\n\n1. The API connects to your node.\n2. It retrieves the chain's metadata.\n3. Based on this metadata, it creates specific endpoints in this format: `api.<type>.<module>.<section>`."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 2, "depth": 3, "title": "Available API Categories", "anchor": "available-api-categories", "start_char": 1033, "end_char": 1888, "estimated_token_count": 248, "token_estimator": "heuristic-v1", "text": "### Available API Categories\n\nYou can access three main categories of chain interactions:\n\n- **[Runtime constants](https://polkadot.js.org/docs/api/start/api.consts){target=\\_blank}** (`api.consts`):\n\n    - Access runtime constants directly.\n    - Returns values immediately without function calls.\n    - **Example**: `api.consts.balances.existentialDeposit`\n\n- **[State queries](https://polkadot.js.org/docs/api/start/api.query/){target=\\_blank}** (`api.query`):\n\n    - Read chain state.\n    - **Example**: `api.query.system.account(accountId)`\n\n- **[Transactions](https://polkadot.js.org/docs/api/start/api.tx/){target=\\_blank}** (`api.tx`):\n    - Submit extrinsics (transactions).\n    - **Example**: `api.tx.balances.transfer(accountId, value)`\n\nThe available methods and interfaces will automatically reflect what's possible on your connected chain."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 3, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1888, "end_char": 2441, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo add the Polkadot.js API to your project, use the following command to install the version `16.4.5` which supports any Polkadot SDK-based chain:\n\n=== \"npm\"\n    ```bash\n    npm i @polkadot/api@16.4.5\n    ```\n\n=== \"pnpm\"\n    ```bash\n    pnpm add @polkadot/api@16.4.5\n    ```\n\n=== \"yarn\"\n    ```bash\n    yarn add @polkadot/api@16.4.5\n    ```\n\nFor more detailed information about installation, see the [Installation](https://polkadot.js.org/docs/api/start/install/){target=\\_blank} section in the official Polkadot.js API documentation."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 4, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 2441, "end_char": 2457, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 5, "depth": 3, "title": "Creating an API Instance", "anchor": "creating-an-api-instance", "start_char": 2457, "end_char": 3227, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "### Creating an API Instance\n\nTo interact with a Polkadot SDK-based chain, you must establish a connection through an API instance. The API provides methods for querying chain state, sending transactions, and subscribing to updates.\n\nTo create an API connection:\n\n```js\n-import { ApiPromise, WsProvider } from '@polkadot/api';\n\n// Create a WebSocket provider\nconst wsProvider = new WsProvider('wss://rpc.polkadot.io');\n\n// Initialize the API\nconst api = await ApiPromise.create({ provider: wsProvider });\n\n// Verify the connection by getting the chain's genesis hash\nconsole.log('Genesis Hash:', api.genesisHash.toHex());\n\n```\n\n!!!warning\n    All `await` operations must be wrapped in an async function or block since the API uses promises for asynchronous operations."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 6, "depth": 3, "title": "Reading Chain Data", "anchor": "reading-chain-data", "start_char": 3227, "end_char": 4025, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "### Reading Chain Data\n\nThe API provides several ways to read data from the chain. You can access:\n\n- **Constants**: Values that are fixed in the runtime and don't change without a runtime upgrade.\n\n    ```js\n    -// Get the minimum balance required for a new account\nconst minBalance = api.consts.balances.existentialDeposit.toNumber();\n\n    ```\n\n- **State**: Current chain state that updates with each block.\n\n    ```js\n    -// Example address\nconst address = '5DTestUPts3kjeXSTMyerHihn1uwMfLj8vU8sqF7qYrFabHE';\n\n// Get current timestamp\nconst timestamp = await api.query.timestamp.now();\n\n// Get account information\nconst { nonce, data: balance } = await api.query.system.account(address);\n\nconsole.log(`\n  Timestamp: ${timestamp}\n  Free Balance: ${balance.free}\n  Nonce: ${nonce}\n`);\n\n    ```"}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 7, "depth": 3, "title": "Sending Transactions", "anchor": "sending-transactions", "start_char": 4025, "end_char": 4841, "estimated_token_count": 195, "token_estimator": "heuristic-v1", "text": "### Sending Transactions\n\nTransactions (also called extrinsics) modify the chain state. Before sending a transaction, you need:\n\n- A funded account with sufficient balance to pay transaction fees.\n- The account's keypair for signing.\n\nTo make a transfer:\n\n```js\n-// Assuming you have an `alice` keypair from the Keyring\nconst recipient = 'INSERT_RECIPIENT_ADDRESS';\nconst amount = 'INSERT_VALUE'; // Amount in the smallest unit (e.g., Planck for DOT)\n\n// Sign and send a transfer\nconst txHash = await api.tx.balances\n  .transfer(recipient, amount)\n  .signAndSend(alice);\n\nconsole.log('Transaction Hash:', txHash);\n\n```\n\nThe `alice` keypair in the example comes from a `Keyring` object. For more details about managing keypairs, see the [Keyring documentation](https://polkadot.js.org/docs/keyring){target=\\_blank}."}
{"page_id": "develop-toolkit-api-libraries-polkadot-js-api", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4841, "end_char": 5002, "estimated_token_count": 44, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor more detailed information about the Polkadot.js API, check the [official documentation](https://polkadot.js.org/docs/){target=\\_blank}."}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 30, "end_char": 484, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Python Substrate Interface](https://github.com/polkascan/py-substrate-interface){target=\\_blank} is a powerful library that enables interaction with Polkadot SDK-based chains. It provides essential functionality for:\n\n- Querying on-chain storage.\n- Composing and submitting extrinsics.\n- SCALE encoding/decoding.\n- Interacting with Substrate runtime metadata.\n- Managing blockchain interactions through convenient utility methods."}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 1, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 484, "end_char": 791, "estimated_token_count": 72, "token_estimator": "heuristic-v1", "text": "## Installation\n\nInstall the library using `pip`:\n\n```py\npip install substrate-interface\n```\n\nFor more installation details, see the [Installation](https://jamdottech.github.io/py-polkadot-sdk/getting-started/installation/){target=\\_blank} section in the official Python Substrate Interface documentation."}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 2, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 791, "end_char": 971, "estimated_token_count": 32, "token_estimator": "heuristic-v1", "text": "## Get Started\n\nThis guide will walk you through the basic operations with the Python Substrate Interface: connecting to a node, reading chain state, and submitting transactions."}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 3, "depth": 3, "title": "Establishing Connection", "anchor": "establishing-connection", "start_char": 971, "end_char": 1489, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "### Establishing Connection\n\nThe first step is to establish a connection to a Polkadot SDK-based node. You can connect to either a local or remote node:\n\n```py\n-from substrateinterface import SubstrateInterface\n\n# Connect to a node using websocket\nsubstrate = SubstrateInterface(\n    # For local node: \"ws://127.0.0.1:9944\"\n    # For Polkadot: \"wss://rpc.polkadot.io\"\n    # For Kusama: \"wss://kusama-rpc.polkadot.io\"\n    url=\"INSERT_WS_URL\"\n)\n\n# Verify connection\nprint(f\"Connected to chain: {substrate.chain}\")\n\n```"}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 4, "depth": 3, "title": "Reading Chain State", "anchor": "reading-chain-state", "start_char": 1489, "end_char": 2508, "estimated_token_count": 243, "token_estimator": "heuristic-v1", "text": "### Reading Chain State\n\nYou can query various on-chain storage items. To retrieve data, you need to specify three key pieces of information:\n\n- **Pallet name**: Module or pallet that contains the storage item you want to access.\n- **Storage item**: Specific storage entry you want to query within the pallet.\n- **Required parameters**: Any parameters needed to retrieve the desired data.\n\nHere's an example of how to check an account's balance and other details:\n\n```py\n-# ...\n\n# Query account balance and info\naccount_info = substrate.query(\n    module=\"System\",  # The pallet name\n    storage_function=\"Account\",  # The storage item\n    params=[\"INSERT_ADDRESS\"],  # Account address in SS58 format\n)\n\n# Access account details from the result\nfree_balance = account_info.value[\"data\"][\"free\"]\nreserved = account_info.value[\"data\"][\"reserved\"]\nnonce = account_info.value[\"nonce\"]\n\nprint(\n    f\"\"\"\n    Account Details:\n    - Free Balance: {free_balance}\n    - Reserved: {reserved} \n    - Nonce: {nonce}\n    \"\"\"\n)\n\n```"}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 5, "depth": 3, "title": "Submitting Transactions", "anchor": "submitting-transactions", "start_char": 2508, "end_char": 3902, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "### Submitting Transactions\n\nTo modify the chain state, you need to submit transactions (extrinsics). Before proceeding, ensure you have:\n\n- A funded account with sufficient balance to pay transaction fees.\n- Access to the account's keypair.\n\nHere's how to create and submit a balance transfer:\n\n```py\n-#...\n\n# Compose the transfer call\ncall = substrate.compose_call(\n    call_module=\"Balances\",  # The pallet name\n    call_function=\"transfer_keep_alive\",  # The extrinsic function\n    call_params={\n        'dest': 'INSERT_ADDRESS',  # Recipient's address\n        'value': 'INSERT_VALUE'  # Amount in smallest unit (e.g., Planck for DOT)\n    }\n)\n\n# Create a signed extrinsic\nextrinsic = substrate.create_signed_extrinsic(\n    call=call, keypair=keypair  # Your keypair for signing\n)\n\n# Submit and wait for inclusion\nreceipt = substrate.submit_extrinsic(\n    extrinsic, wait_for_inclusion=True  # Wait until the transaction is in a block\n)\n\nif receipt.is_success:\n    print(\n        f\"\"\"\n        Transaction successful:\n        - Extrinsic Hash: {receipt.extrinsic_hash}\n        - Block Hash: {receipt.block_hash}\n        \"\"\"\n    )\nelse:\n    print(f\"Transaction failed: {receipt.error_message}\")\n\n```\n\nThe `keypair` object is essential for signing transactions. See the [Keypair](https://jamdottech.github.io/py-polkadot-sdk/reference/keypair/){target=\\_blank} documentation for more details."}
{"page_id": "develop-toolkit-api-libraries-py-substrate-interface", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3902, "end_char": 4305, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you understand the basics, you can:\n\n- Explore more complex queries and transactions.\n- Learn about batch transactions and utility functions.\n- Discover how to work with custom pallets and types.\n\nFor comprehensive reference materials and advanced features, see the [Python Substrate Interface](https://jamdottech.github.io/py-polkadot-sdk/){target=\\_blank} documentation."}
{"page_id": "develop-toolkit-api-libraries-sidecar", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 15, "end_char": 1185, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Sidecar Rest API](https://github.com/paritytech/substrate-api-sidecar){target=\\_blank} is a service that provides a REST interface for interacting with Polkadot SDK-based blockchains. With this API, developers can easily access a broad range of endpoints for nodes, accounts, transactions, parachains, and more.\n\nSidecar functions as a caching layer between your application and a Polkadot SDK-based node, offering standardized REST endpoints that simplify interactions without requiring complex, direct RPC calls. This approach is especially valuable for developers who prefer REST APIs or build applications in languages with limited WebSocket support.\n\nSome of the key features of the Sidecar API include:\n\n- **REST API interface**: Provides a familiar REST API interface for interacting with Polkadot SDK-based chains.\n- **Standardized endpoints**: Offers consistent endpoint formats across different chain implementations.\n- **Caching layer**: Acts as a caching layer to improve performance and reduce direct node requests.\n- **Multiple chain support**: Works with any Polkadot SDK-based chain, including Polkadot, Kusama, and custom chains."}
{"page_id": "develop-toolkit-api-libraries-sidecar", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1185, "end_char": 1484, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nSidecar API requires Node.js version 18.14 LTS or higher. Verify your Node.js version:\n\n```bash\nnode --version\n```\n\nIf you need to install or update Node.js, visit the [official Node.js website](https://nodejs.org/){target=\\_blank} to download and install the latest LTS version."}
{"page_id": "develop-toolkit-api-libraries-sidecar", "index": 2, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1484, "end_char": 2137, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo install Substrate API Sidecar, use one of the following commands:\n\n=== \"npm\"\n\n    ```bash\n    npm install -g @substrate/api-sidecar\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm install -g @substrate/api-sidecar\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn global add @substrate/api-sidecar\n    ```\n\nYou can confirm the installation by running:\n\n```bash\nsubstrate-api-sidecar --version\n```\n\nFor more information about the Sidecar API installation, see the [installation and usage](https://github.com/paritytech/substrate-api-sidecar?tab=readme-ov-file#npm-package-installation-and-usage){target=\\_blank} section of the Sidecar API README."}
{"page_id": "develop-toolkit-api-libraries-sidecar", "index": 3, "depth": 2, "title": "Usage", "anchor": "usage", "start_char": 2137, "end_char": 5690, "estimated_token_count": 1006, "token_estimator": "heuristic-v1", "text": "## Usage\n\nTo use the Sidecar API, you have two options:\n\n- **Local node**: Run a node locally, which Sidecar will connect to by default, requiring no additional configuration. To start, run the following:\n\n    ```bash\n    substrate-api-sidecar\n    ```\n\n- **Remote node**: Connect Sidecar to a remote node by specifying the RPC endpoint for that chain. For example, to gain access to the Polkadot Asset Hub associated endpoints.\n\n    ```bash\n    SAS_SUBSTRATE_URL=wss://polkadot-asset-hub-rpc.polkadot.io substrate-api-sidecar\n    ```\n\n    For more configuration details, see the [Configuration](https://github.com/paritytech/substrate-api-sidecar?tab=readme-ov-file#configuration){target=\\_blank} section of the Sidecar API documentation.\n\nOnce the Sidecar API is running, you’ll see output similar to this:\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty='input'><span class='file-path'></span>SAS_SUBSTRATE_URL=wss://polkadot-asset-hub-rpc.polkadot.io substrate-api-sidecar</span>\n    <br>\n    <span data-ty>SAS:</span>\n    <span data-ty>📦 LOG:</span>\n    <span data-ty>   ✅ LEVEL: \"info\"</span>\n    <span data-ty>   ✅ JSON: false</span>\n    <span data-ty>   ✅ FILTER_RPC: false</span>\n    <span data-ty>   ✅ STRIP_ANSI: false</span>\n    <span data-ty>   ✅ WRITE: false</span>\n    <span data-ty>   ✅ WRITE_PATH: \"/opt/homebrew/lib/node_modules/@substrate/api-sidecar/build/src/logs\"</span>\n    <span data-ty>   ✅ WRITE_MAX_FILE_SIZE: 5242880</span>\n    <span data-ty>   ✅ WRITE_MAX_FILES: 5</span>\n    <span data-ty>📦 SUBSTRATE:</span>\n    <span data-ty>   ✅ URL: \"wss://polkadot-asset-hub-rpc.polkadot.io\"</span>\n    <span data-ty>   ✅ TYPES_BUNDLE: undefined</span>\n    <span data-ty>   ✅ TYPES_CHAIN: undefined</span>\n    <span data-ty>   ✅ TYPES_SPEC: undefined</span>\n    <span data-ty>   ✅ TYPES: undefined</span>\n    <span data-ty>   ✅ CACHE_CAPACITY: undefined</span>\n    <span data-ty>📦 EXPRESS:</span>\n    <span data-ty>   ✅ BIND_HOST: \"127.0.0.1\"</span>\n    <span data-ty>   ✅ PORT: 8080</span>\n    <span data-ty>   ✅ KEEP_ALIVE_TIMEOUT: 5000</span>\n    <span data-ty>📦 METRICS:</span>\n    <span data-ty>   ✅ ENABLED: false</span>\n    <span data-ty>   ✅ PROM_HOST: \"127.0.0.1\"</span>\n    <span data-ty>   ✅ PROM_PORT: 9100</span>\n    <span data-ty>   ✅ LOKI_HOST: \"127.0.0.1\"</span>\n    <span data-ty>   ✅ LOKI_PORT: 3100</span>\n    <span data-ty>   ✅ INCLUDE_QUERYPARAMS: false</span>\n    <br>\n    <span data-ty>2024-11-06 08:06:01 info: Version: 19.3.0</span>\n    <span data-ty>2024-11-06 08:06:02 warn: API/INIT: RPC methods not decorated: chainHead_v1_body, chainHead_v1_call, chainHead_v1_continue, chainHead_v1_follow, chainHead_v1_header, chainHead_v1_stopOperation, chainHead_v1_storage, chainHead_v1_unfollow, chainHead_v1_unpin, chainSpec_v1_chainName, chainSpec_v1_genesisHash, chainSpec_v1_properties, transactionWatch_v1_submitAndWatch, transactionWatch_v1_unwatch, transaction_v1_broadcast, transaction_v1_stop</span>\n    <span data-ty>2024-11-06 08:06:02 info: Connected to chain Polkadot Asset Hub on the statemint client at wss://polkadot-asset-hub-rpc.polkadot.io</span>\n    <span data-ty>2024-11-06 08:06:02 info: Listening on http://127.0.0.1:8080/</span>\n    <span data-ty>2024-11-06 08:06:02 info: Check the root endpoint (http://127.0.0.1:8080/) to see the available endpoints for the current node</span>\n</div>\n\nWith Sidecar running, you can access the exposed endpoints via a browser, [`Postman`](https://www.postman.com/){target=\\_blank}, [`curl`](https://curl.se/){target=\\_blank}, or your preferred tool."}
{"page_id": "develop-toolkit-api-libraries-sidecar", "index": 4, "depth": 3, "title": "Endpoints", "anchor": "endpoints", "start_char": 5690, "end_char": 7033, "estimated_token_count": 396, "token_estimator": "heuristic-v1", "text": "### Endpoints\n\nSidecar API provides a set of REST endpoints that allow you to query different aspects of the chain, including blocks, accounts, and transactions. Each endpoint offers specific insights into the chain’s state and activities.\n\nFor example, to retrieve the version of the node, use the `/node/version` endpoint:\n\n```bash\n-curl -X 'GET' \\\n  'http://127.0.0.1:8080/node/version' \\\n  -H 'accept: application/json'\n```\n\nAlternatively, you can access `http://127.0.0.1:8080/node/version` directly in a browser since it’s a `GET` request.\n\nIn response, you’ll see output similar to this (assuming you’re connected to Polkadot Asset Hub):\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>curl -X 'GET' 'http://127.0.0.1:8080/node/version' -H 'accept: application/json'</span>\n    <br>\n    <span data-ty>{</span>\n    <span data-ty>    \"clientVersion\": \"1.16.1-835e0767fe8\",</span>\n    <span data-ty>    \"clientImplName\": \"statemint\",</span>\n    <span data-ty>    \"chain\": \"Polkadot Asset Hub\"</span>\n    <span data-ty>}</span>\n</div>\n\nFor a complete list of available endpoints and their documentation, visit the [Sidecar API list endpoints](https://paritytech.github.io/substrate-api-sidecar/dist/){target=\\_blank}. You can learn about the endpoints and how to use them in your applications."}
{"page_id": "develop-toolkit-api-libraries-sidecar", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 7033, "end_char": 7314, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nTo dive deeper, refer to the [official Sidecar documentation](https://github.com/paritytech/substrate-api-sidecar?tab=readme-ov-file#substrateapi-sidecar){target=\\_blank}. This provides a comprehensive guide to the available configurations and advanced usage."}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 403, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nSubxt is a Rust library designed to interact with Polkadot SDK-based blockchains. It provides a type-safe interface for submitting transactions, querying on-chain state, and performing other blockchain interactions. By leveraging Rust's strong type system, subxt ensures that your code is validated at compile time, reducing runtime errors and improving reliability."}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 403, "end_char": 734, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore using subxt, ensure you have the following requirements:\n\n- Rust and Cargo installed on your system. You can install them using [Rustup](https://rustup.rs/){target=\\_blank}.\n- A Rust project initialized. If you don't have one, create it with:\n    ```bash\n    cargo new my_project && cd my_project\n    ```"}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 2, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 734, "end_char": 2769, "estimated_token_count": 511, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo use subxt in your project, you must install the necessary dependencies. Each plays a specific role in enabling interaction with the blockchain:\n\n1. **Install the subxt CLI**: [`subxt-cli`](https://crates.io/crates/subxt-cli){target=\\_blank} is a command-line tool that provides utilities for working with Polkadot SDK metadata. In the context of subxt, it is essential to download chain metadata, which is required to generate type-safe Rust interfaces for interacting with the blockchain. Install it using the following:\n\n    ```bash\n    cargo install subxt-cli@0.43.0\n    ```\n\n2. **Add core dependencies**: These dependencies are essential for interacting with the blockchain.\n\n    - **[subxt](https://crates.io/crates/subxt){target=\\_blank}**: The main library for communicating with Polkadot SDK nodes. It handles RPC requests, encoding/decoding, and type generation.\n\n        ```bash\n        cargo add subxt@0.43.0\n        ```\n\n    - **[subxt-signer](https://crates.io/crates/subxt-signer){target=\\_blank}**: Provides cryptographic functionality for signing transactions. Without this, you can only read data but cannot submit transactions.\n\n        ```bash\n        cargo add subxt-signer@0.43.0\n        ```\n\n    - **[tokio](https://crates.io/crates/tokio){target=\\_blank}**: An asynchronous runtime for Rust. Since blockchain operations are async, Tokio enables the efficient handling of network requests. The `rt` feature enables Tokio's runtime, including the current-thread single-threaded scheduler, which is necessary for async execution. The `macros` feature provides procedural macros like `#[tokio::main]` to simplify runtime setup.\n\n        ```bash\n        cargo add tokio@1.44.2 --features rt,macros\n        ```\n\n    After adding the dependencies, your `Cargo.toml` should look like this:\n\n    ```toml\n    -[package]\nname = \"my_project\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nsubxt = \"0.41.0\"\nsubxt-signer = \"0.41.0\"\ntokio = { version = \"1.44.2\", features = [\"rt\", \"macros\"] }\n\n    ```"}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 3, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 2769, "end_char": 2946, "estimated_token_count": 29, "token_estimator": "heuristic-v1", "text": "## Get Started\n\nThis guide will walk you through the fundamental operations of subxt, from setting up your environment to executing transactions and querying blockchain state."}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 4, "depth": 3, "title": "Download Chain Metadata", "anchor": "download-chain-metadata", "start_char": 2946, "end_char": 3337, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### Download Chain Metadata\n\nBefore interacting with a blockchain, you need to retrieve its metadata. This metadata defines storage structures, extrinsics, and other runtime details. Use the `subxt-cli` tool to download the metadata, replacing `INSERT_NODE_URL` with the URL of the node you want to interact with:\n\n```bash\nsubxt metadata --url INSERT_NODE_URL > polkadot_metadata.scale\n```"}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 5, "depth": 3, "title": "Generate Type-Safe Interfaces", "anchor": "generate-type-safe-interfaces", "start_char": 3337, "end_char": 5203, "estimated_token_count": 530, "token_estimator": "heuristic-v1", "text": "### Generate Type-Safe Interfaces\n\nUse the `#[subxt::subxt]` macro to generate a type-safe Rust interface from the downloaded metadata:\n\n```rust\n-// Generate an interface that we can use from the node's metadata.\n#[subxt::subxt(runtime_metadata_path = \"./polkadot_metadata.scale\")]\npub mod polkadot {}\n```\n\nOnce subxt interfaces are generated, you can interact with your node in the following ways. You can use the links below to view the related subxt documentation:\n\n- **[Transactions](https://docs.rs/subxt/latest/subxt/book/usage/transactions/index.html){target=\\_blank}**: Builds and submits transactions, monitors their inclusion in blocks, and retrieves associated events.\n- **[Storage](https://docs.rs/subxt/latest/subxt/book/usage/storage/index.html){target=\\_blank}**: Enables querying of node storage data.\n- **[Events](https://docs.rs/subxt/latest/subxt/book/usage/events/index.html){target=\\_blank}**: Retrieves events emitted from recent blocks.\n- **[Constants](https://docs.rs/subxt/latest/subxt/book/usage/constants/index.html){target=\\_blank}**: Accesses constant values stored in nodes that remain unchanged across a specific runtime version.\n- **[Blocks](https://docs.rs/subxt/latest/subxt/book/usage/blocks/index.html){target=\\_blank}**: Loads recent blocks or subscribes to new/finalized blocks, allowing examination of extrinsics, events, and storage at those blocks.\n- **[Runtime APIs](https://docs.rs/subxt/latest/subxt/book/usage/runtime_apis/index.html){target=\\_blank}**: Makes calls into pallet runtime APIs to fetch data.\n- **[Custom values](https://docs.rs/subxt/latest/subxt/book/usage/custom_values/index.html){target=\\_blank}**: Accesses \"custom values\" contained within metadata.\n- **[Raw RPC calls](https://docs.rs/subxt/latest/subxt/book/usage/rpc/index.html){target=\\_blank}**: Facilitates raw RPC requests to compatible nodes."}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 6, "depth": 3, "title": "Initialize the Subxt Client", "anchor": "initialize-the-subxt-client", "start_char": 5203, "end_char": 8028, "estimated_token_count": 667, "token_estimator": "heuristic-v1", "text": "### Initialize the Subxt Client\n\nTo interact with a blockchain node using subxt, create an asynchronous main function and initialize the client. Replace `INSERT_NODE_URL` with the URL of your target node:\n\n```rust\n-use std::str::FromStr;\nuse subxt::utils::AccountId32;\nuse subxt::{OnlineClient, PolkadotConfig};\nuse subxt_signer::{bip39::Mnemonic,sr25519::Keypair};\n\n// Generate an interface that we can use from the node's metadata.\n#[subxt::subxt(runtime_metadata_path = \"./polkadot_metadata.scale\")]\npub mod polkadot {}\n\n#[tokio::main(flavor = \"current_thread\")]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Define the node URL.\n    const NODE_URL: &str = \"INSERT_NODE_URL\";\n\n    // Initialize the Subxt client to interact with the blockchain.\n    let api = OnlineClient::<PolkadotConfig>::from_url(NODE_URL).await?;\n\n    // A query to obtain some constant.\n    let constant_query = polkadot::constants().balances().existential_deposit();\n\n    // Obtain the value.\n    let value = api.constants().at(&constant_query)?;\n\n    println!(\"Existential deposit: {:?}\", value);\n\n    // Define the target account address.\n    const ADDRESS: &str = \"INSERT_ADDRESS\";\n    let account = AccountId32::from_str(ADDRESS).unwrap();\n\n    // Build a storage query to access account information.\n    let storage_query = polkadot::storage().system().account(&account.into());\n\n    // Fetch the latest state for the account.\n    let result = api\n        .storage()\n        .at_latest()\n        .await?\n        .fetch(&storage_query)\n        .await?\n        .unwrap();\n\n    println!(\"Account info: {:?}\", result);\n\n    // Define the recipient address and transfer amount.\n    const DEST_ADDRESS: &str = \"INSERT_DEST_ADDRESS\";\n    const AMOUNT: u128 = INSERT_AMOUNT;\n\n    // Convert the recipient address into an `AccountId32`.\n    let dest = AccountId32::from_str(DEST_ADDRESS).unwrap();\n\n    // Build the balance transfer extrinsic.\n    let balance_transfer_tx = polkadot::tx()\n        .balances()\n        .transfer_allow_death(dest.into(), AMOUNT);\n\n    // Load the sender's keypair from a mnemonic phrase.\n    const SECRET_PHRASE: &str = \"INSERT_SECRET_PHRASE\";\n    let mnemonic = Mnemonic::parse(SECRET_PHRASE).unwrap();\n    let sender_keypair = Keypair::from_phrase(&mnemonic, None).unwrap();\n\n    // Sign and submit the extrinsic, then wait for it to be finalized.\n    let events = api\n        .tx()\n        .sign_and_submit_then_watch_default(&balance_transfer_tx, &sender_keypair)\n        .await?\n        .wait_for_finalized_success()\n        .await?;\n\n    // Check for a successful transfer event.\n    if let Some(event) = events.find_first::<polkadot::balances::events::Transfer>()? {\n        println!(\"Balance transfer successful: {:?}\", event);\n    }\n\n    Ok(())\n}\n    // Your code here...\n-\n    Ok(())\n}\n```"}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 7, "depth": 3, "title": "Read Chain Data", "anchor": "read-chain-data", "start_char": 8028, "end_char": 9317, "estimated_token_count": 298, "token_estimator": "heuristic-v1", "text": "### Read Chain Data\n\nsubxt provides multiple ways to access on-chain data:\n\n- **Constants**: Constants are predefined values in the runtime that remain unchanged unless modified by a runtime upgrade.\n\n    For example, to retrieve the existential deposit, use:\n    \n    ```rust\n    -    // A query to obtain some constant.\n    let constant_query = polkadot::constants().balances().existential_deposit();\n\n    // Obtain the value.\n    let value = api.constants().at(&constant_query)?;\n\n    println!(\"Existential deposit: {:?}\", value);\n    ```\n\n- **State**: State refers to the current chain data, which updates with each block.\n\n    To fetch account information, replace `INSERT_ADDRESS` with the address you want to fetch data from and use:\n\n    ```rust\n    -    // Define the target account address.\n    const ADDRESS: &str = \"INSERT_ADDRESS\";\n    let account = AccountId32::from_str(ADDRESS).unwrap();\n\n    // Build a storage query to access account information.\n    let storage_query = polkadot::storage().system().account(&account.into());\n\n    // Fetch the latest state for the account.\n    let result = api\n        .storage()\n        .at_latest()\n        .await?\n        .fetch(&storage_query)\n        .await?\n        .unwrap();\n\n    println!(\"Account info: {:?}\", result);\n    ```"}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 8, "depth": 3, "title": "Submit Transactions", "anchor": "submit-transactions", "start_char": 9317, "end_char": 10792, "estimated_token_count": 312, "token_estimator": "heuristic-v1", "text": "### Submit Transactions\n\nTo submit a transaction, you must construct an extrinsic, sign it with your private key, and send it to the blockchain. Replace `INSERT_DEST_ADDRESS` with the recipient's address, `INSERT_AMOUNT` with the amount to transfer, and `INSERT_SECRET_PHRASE` with the sender's mnemonic phrase:\n\n```rust\n-    // Define the recipient address and transfer amount.\n    const DEST_ADDRESS: &str = \"INSERT_DEST_ADDRESS\";\n    const AMOUNT: u128 = INSERT_AMOUNT;\n\n    // Convert the recipient address into an `AccountId32`.\n    let dest = AccountId32::from_str(DEST_ADDRESS).unwrap();\n\n    // Build the balance transfer extrinsic.\n    let balance_transfer_tx = polkadot::tx()\n        .balances()\n        .transfer_allow_death(dest.into(), AMOUNT);\n\n    // Load the sender's keypair from a mnemonic phrase.\n    const SECRET_PHRASE: &str = \"INSERT_SECRET_PHRASE\";\n    let mnemonic = Mnemonic::parse(SECRET_PHRASE).unwrap();\n    let sender_keypair = Keypair::from_phrase(&mnemonic, None).unwrap();\n\n    // Sign and submit the extrinsic, then wait for it to be finalized.\n    let events = api\n        .tx()\n        .sign_and_submit_then_watch_default(&balance_transfer_tx, &sender_keypair)\n        .await?\n        .wait_for_finalized_success()\n        .await?;\n\n    // Check for a successful transfer event.\n    if let Some(event) = events.find_first::<polkadot::balances::events::Transfer>()? {\n        println!(\"Balance transfer successful: {:?}\", event);\n    }\n```"}
{"page_id": "develop-toolkit-api-libraries-subxt", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10792, "end_char": 11022, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you've covered the basics dive into the official [subxt documentation](https://docs.rs/subxt/latest/subxt/book/index.html){target=\\_blank} for comprehensive reference materials and advanced features."}
{"page_id": "develop-toolkit-integrations-indexers", "index": 0, "depth": 2, "title": "The Challenge of Blockchain Data Access", "anchor": "the-challenge-of-blockchain-data-access", "start_char": 12, "end_char": 649, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## The Challenge of Blockchain Data Access\n\nBlockchain data is inherently sequential and distributed, with information stored chronologically across numerous blocks. While retrieving data from a single block through JSON-RPC API calls is straightforward, more complex queries that span multiple blocks present significant challenges:\n\n- Data is scattered and unorganized across the blockchain.\n- Retrieving large datasets can take days or weeks to sync.\n- Complex operations (like aggregations, averages, or cross-chain queries) require additional processing.\n- Direct blockchain queries can impact dApp performance and responsiveness."}
{"page_id": "develop-toolkit-integrations-indexers", "index": 1, "depth": 2, "title": "What is a Blockchain Indexer?", "anchor": "what-is-a-blockchain-indexer", "start_char": 649, "end_char": 1211, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## What is a Blockchain Indexer?\n\nA blockchain indexer is a specialized infrastructure tool that processes, organizes, and stores blockchain data in an optimized format for efficient querying. Think of it as a search engine for blockchain data that:\n\n- Continuously monitors the blockchain for new blocks and transactions.\n- Processes and categorizes this data according to predefined schemas.\n- Stores the processed data in an easily queryable database.\n- Provides efficient APIs (typically [GraphQL](https://graphql.org/){target=\\_blank}) for data retrieval."}
{"page_id": "develop-toolkit-integrations-indexers", "index": 2, "depth": 2, "title": "Indexer Implementations", "anchor": "indexer-implementations", "start_char": 1211, "end_char": 2230, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "## Indexer Implementations\n\n<div class=\"grid cards\" markdown>\n\n-   __Subsquid__\n\n    ---\n\n    Subsquid is a data network that allows rapid and cost-efficient retrieval of blockchain data from 100+ chains using Subsquid's decentralized data lake and open-source SDK. In simple terms, Subsquid can be considered an ETL (extract, transform, and load) tool with a GraphQL server included. It enables comprehensive filtering, pagination, and even full-text search capabilities. Subsquid has native and full support for EVM and Substrate data, even within the same project.\n\n    [:octicons-arrow-right-24: Reference](https://www.sqd.ai/){target=\\_blank}\n\n-   __Subquery__\n\n    ---\n\n    SubQuery is a fast, flexible, and reliable open-source data decentralised infrastructure network that provides both RPC and indexed data to consumers worldwide.\n    It provides custom APIs for your web3 project across multiple supported chains.\n\n    [:octicons-arrow-right-24: Reference](https://subquery.network/){target=\\_blank}\n\n</div>"}
{"page_id": "develop-toolkit-integrations-oracles", "index": 0, "depth": 2, "title": "What is a Blockchain Oracle?", "anchor": "what-is-a-blockchain-oracle", "start_char": 11, "end_char": 749, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## What is a Blockchain Oracle?\n\nOracles enable blockchains to access external data sources. Since blockchains operate as isolated networks, they cannot natively interact with external systems - this limitation is known as the \"blockchain oracle problem.\" Oracles solves this by extracting data from external sources (like APIs, IoT devices, or other blockchains), validating it, and submitting it on-chain.\n\nWhile simple oracle implementations may rely on a single trusted provider, more sophisticated solutions use decentralized networks where multiple providers stake assets and reach consensus on data validity. Typical applications include DeFi price feeds, weather data for insurance contracts, and cross-chain asset verification."}
{"page_id": "develop-toolkit-integrations-oracles", "index": 1, "depth": 2, "title": "Oracle Implementations", "anchor": "oracle-implementations", "start_char": 749, "end_char": 1343, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Oracle Implementations\n\n<div class=\"grid cards\" markdown>\n\n-   __Acurast__\n\n    ---\n\n    Acurast is a decentralized, serverless cloud platform that uses a distributed network of mobile devices for oracle services, addressing centralized trust and data ownership issues. In the Polkadot ecosystem, it allows developers to define off-chain data and computation needs, which are processed by these devices acting as decentralized oracle nodes, delivering results to Substrate (Wasm) and EVM environments.\n\n    [:octicons-arrow-right-24: Reference](https://acurast.com/){target=\\_blank}\n\n</div>"}
{"page_id": "develop-toolkit-integrations-storage", "index": 0, "depth": 2, "title": "Key Storage Solutions", "anchor": "key-storage-solutions", "start_char": 398, "end_char": 1036, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "## Key Storage Solutions\n\nBy leveraging decentralized storage, you can enhance the security, reliability, and censorship resistance of your dApps. Polkadot's ecosystem provides several options, enabling you to select the best fit for your specific needs.\n\nSome of the storage solutions available for Polkadot dApp builders are:\n\n- **[Crust Network](#crust-network):** A decentralized storage network that provides an incentive layer for IPFS.\n- **[IPFS](#ipfs):** A foundational peer-to-peer protocol for decentralized file storage.\n- **[Other Solutions](#other-solutions):** A brief overview of other storage options in the ecosystem."}
{"page_id": "develop-toolkit-integrations-storage", "index": 1, "depth": 2, "title": "Crust Network", "anchor": "crust-network", "start_char": 1036, "end_char": 1342, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## Crust Network\n\n[Crust Network](https://crust.network/){target=\\_blank} is a decentralized storage protocol built using the Polkadot SDK serving as an incentive layer for IPFS. As a parachain in the Polkadot ecosystem, Crust provides a comprehensive set of tools and services for decentralized storage."}
{"page_id": "develop-toolkit-integrations-storage", "index": 2, "depth": 3, "title": "Key Features of Crust", "anchor": "key-features-of-crust", "start_char": 1342, "end_char": 2181, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "### Key Features of Crust\n\n-   **Decentralized and Immutable:** Crust leverages a global network of nodes to provide a truly decentralized storage layer, ensuring data immutability and high availability.\n-   **IPFS-based:** Crust is built on top of IPFS, providing a robust and widely used foundation for file storage. It enhances IPFS with an incentive layer, guaranteeing data persistence and replication.\n-   **Cross-Chain Interoperability:** Through Polkadot's XCM, Crust can offer storage services to other parachains, and it also supports EVM-compatible chains, enabling seamless integration with a wide range of dApps.\n-   **Developer-Friendly:** Crust offers a suite of tools, including an S3-compatible gateway, a GitHub-like application for decentralized code repositories, and various SDKs to simplify the integration process."}
{"page_id": "develop-toolkit-integrations-storage", "index": 3, "depth": 3, "title": "Use Cases", "anchor": "use-cases", "start_char": 2181, "end_char": 2531, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### Use Cases\n\n-   **dApp Hosting:** Deploy your dApp's front end on Crust for a fully decentralized solution.\n-   **NFT Storage:** Store NFT metadata and assets in a persistent and decentralized manner.\n-   **File Storage and Sharing:** Build decentralized applications for file storage and sharing, similar to traditional cloud storage services."}
{"page_id": "develop-toolkit-integrations-storage", "index": 4, "depth": 2, "title": "IPFS", "anchor": "ipfs", "start_char": 2531, "end_char": 3117, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## IPFS\n\nThe [InterPlanetary File System (IPFS)](https://ipfs.tech/){target=\\_blank} is a peer-to-peer hypermedia protocol designed to make the web faster, safer, and more open. It is a foundational technology for the decentralized web, and many storage solutions, including Crust, are built upon it.\n\nIPFS uses content-based rather than location-based addresses. When you add a file to IPFS, it is assigned a unique cryptographic hash, known as a Content Identifier (CID). This hashing process means that the content itself determines its address, making it verifiable and permanent."}
{"page_id": "develop-toolkit-integrations-storage", "index": 5, "depth": 3, "title": "Using IPFS with Polkadot", "anchor": "using-ipfs-with-polkadot", "start_char": 3117, "end_char": 3868, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "### Using IPFS with Polkadot\n\nWhile IPFS is a standalone protocol, it can be integrated into your Polkadot dApp in several ways:\n\n-   **Off-Chain Data Storage:** Store large files, such as images, videos, and documents, off-chain on IPFS to reduce on-chain storage costs and improve performance.\n-   **Front-end Hosting:** Host your dApp's front end on IPFS to ensure that it remains accessible and censorship-resistant.\n-   **Integration with Storage Networks:** Use services like Crust Network or other pinning services to ensure your IPFS data is always available and replicated across multiple nodes.\n-   **Run your own IPFS Node:** Since IPFS is a P2P Network, you can optionally run your own IPFS node and have complete control over your data"}
{"page_id": "develop-toolkit-integrations-storage", "index": 6, "depth": 2, "title": "Other Solutions", "anchor": "other-solutions", "start_char": 3868, "end_char": 4369, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Other Solutions\n\nIn addition to Crust and IPFS, the Polkadot ecosystem is home to other emerging storage solutions. Projects like **[Aleph Cloud](https://aleph.cloud){target=\\_blank}** and **[Chainsafe's Files](https://files.chainsafe.io){target=\\_blank}** also offer decentralized storage services that can be integrated with your Polkadot dApp. As the ecosystem continues to grow, more storage options will become available, providing developers with a wide range of choices to meet their needs."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 472, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis page will discuss the transaction format in Polkadot and how to create, sign, and broadcast transactions, as well as highlight some of the commands and tools available for integrators.\n\nAlways refer to each tool's documentation when integrating.\n\nFor further reading, refer to [blocks, transactions, and fees](/polkadot-protocol/parachain-basics/blocks-transactions-fees/){target=\\_blank} to learn more about the basics."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 1, "depth": 2, "title": "Transaction Format", "anchor": "transaction-format", "start_char": 472, "end_char": 3362, "estimated_token_count": 696, "token_estimator": "heuristic-v1", "text": "## Transaction Format\n\nPolkadot has some basic transaction information that is common to all transactions.\n\n- **Address**: The [SS58-encoded address](/polkadot-protocol/glossary/#ss58-address-format){target=\\_blank} of the sending account.\n- **Block hash**: The hash of the [checkpoint](/polkadot-protocol/parachain-basics/blocks-transactions-fees/transactions/#transaction-mortality){target=\\_blank} block.\n- **Block number**: The number of the checkpoint block.\n- **Genesis hash**: The genesis hash of the chain.\n- **Metadata**: The [SCALE-encoded](/polkadot-protocol/parachain-basics/data-encoding/){target=\\_blank} metadata for the runtime when submitted.\n- **Nonce**: The nonce for this transaction.\n- **Spec version**: The current spec version for the runtime.\n- **Transaction version**: The current version of the transaction format.\n- **Tip**: The [tip](/polkadot-protocol/parachain-basics/blocks-transactions-fees/fees/#how-fees-are-calculated){target=\\_blank} to increase transaction priority. This is optional when constructing the transaction.\n- **Mode**: The flag indicating whether to verify the metadata hash or not.\n- **Era period**: The number of blocks after the checkpoint for which a transaction is valid. If zero, the transaction is [immortal](/polkadot-protocol/parachain-basics/blocks-transactions-fees/transactions/#transaction-mortality){target=\\_blank}. This is optional when constructing the transaction.\n- **Metadata hash**: The metadata hash which should match the [`RUNTIME_METADATA_HASH`](https://paritytech.github.io/polkadot-sdk/master/frame_metadata_hash_extension/struct.CheckMetadataHash.html){target=\\_blank} environment variable. This is optional when constructing the transaction.\n\n!!!warning\n    There are risks to making a transaction immortal. If an account is reaped and a user refunds the account, then they could replay an immortal transaction. Always default to using a mortal extrinsic.\n    \nThe nonce queried from the [System module](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/index.html){target=\\_blank} does not account for pending transactions. You must manually track and increment the nonce if you want to submit multiple valid transactions simultaneously.\n\nEach transaction will have its own parameters, or it may have none to add. For example, the [`transferKeepAlive`](https://paritytech.github.io/polkadot-sdk/master/pallet_balances/pallet/enum.Call.html#variant.transfer_keep_alive){target=\\_blank}  function from the [Balances pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_balances/index.html){target=\\_blank} will take:\n\n- `dest`: Destination address\n- `#[compact] value`: Number of tokens (compact encoding)\n\nRefer to [the protocol specifications](https://spec.polkadot.network/id-extrinsics){target=\\_blank} for the concrete specifications and types required to build a transaction."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 2, "depth": 3, "title": "Mode and Metadata Hash", "anchor": "mode-and-metadata-hash", "start_char": 3362, "end_char": 4529, "estimated_token_count": 309, "token_estimator": "heuristic-v1", "text": "### Mode and Metadata Hash\n\nThe [`mode`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/enable_metadata_hash/index.html){target=\\_blank} and [`metadata hash`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/enable_metadata_hash/index.html){target=\\_blank} fields were introduced in transaction construction to support the optional [`CheckMetadataHash` Signed Extension](https://github.com/polkadot-fellows/RFCs/blob/main/text/0078-merkleized-metadata.md){target=\\_blank}. This enables trustless metadata verification by allowing the chain to verify the correctness of the metadata used without the need of a trusted party. This functionality was included in [v1.2.5](https://github.com/polkadot-fellows/runtimes/releases/tag/v1.2.5){target=\\_blank} runtime release by the [Fellowship](https://github.com/polkadot-fellows/manifesto){target=\\_blank}. A user may opt out of this functionality by setting the `mode` to `0`. When the mode is `0`, the [`metadata hash`](https://paritytech.github.io/polkadot-sdk/master/frame_metadata_hash_extension/struct.CheckMetadataHash.html){target=\\_blank} field is empty/`None`."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 3, "depth": 3, "title": "Serialized Transactions and Metadata", "anchor": "serialized-transactions-and-metadata", "start_char": 4529, "end_char": 5164, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### Serialized Transactions and Metadata\n\nBefore being submitted, transactions are serialized. Serialized transactions are hex encoded SCALE-encoded bytes. The relay chain runtimes are upgradable, and therefore, any interfaces are subject to change. The metadata allows developers to structure any extrinsics or storage entries accordingly and provides you with all of the information required to construct the serialized call data specific to your transaction. You can read more about the metadata, its format and how to get it in the [Subxt documentation](/polkadot-protocol/parachain-basics/chain-data/#use-subxt){target=\\_blank}."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 4, "depth": 3, "title": "Transaction Flow", "anchor": "transaction-flow", "start_char": 5164, "end_char": 5468, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "### Transaction Flow\n\nThe typical transaction workflow is as follows:\n\n1. Construct an unsigned transaction.\n2. Create a signing payload.\n3. Sign the payload.\n4. Serialize the signed payload into a transaction.\n5. Submit the serialized transaction.\n\nThere are several tools to help perform these steps."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 5, "depth": 2, "title": "Polkadot-JS Tools", "anchor": "polkadot-js-tools", "start_char": 5468, "end_char": 6599, "estimated_token_count": 289, "token_estimator": "heuristic-v1", "text": "## Polkadot-JS Tools\n\n[Polkadot-JS Tools](https://www.npmjs.com/package/@polkadot/signer-cli){target=\\_blank} contains a set of command-line tools for interacting with a Polkadot SDK client, including one called \"Signer CLI\" to create, sign, and broadcast transactions.\n\nThis example will use the `signer submit` command, which creates and submits the transaction. The `signer sendOffline` command has the same API, but will not broadcast the transaction. The `submit` and `sendOffline` must be connected to a node to fetch the current metadata and construct a valid transaction.\n\nStart by installing the Signer CLI.\n\n```bash\nnpm install -g @polkadot/signer-cli\n```\n\nTo create a transaction, you need to connect to a chain, enabling the creation of a transaction using the chain's metadata. \n\nHere is the format for `submit` or `sendOffline`:\n\n```bash\npolkadot-js-signer <submit|sendOffline> --account <from-account-ss58> --ws <endpoint> <module.method> [param1] [...] [paramX]\n```\n\nAnd for signing a transaction:\n\n```bash\npolkadot-js-signer sign --account <from-account-ss58> --seed <seed> --type <sr25519|ed25519> <payload>\n```"}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 6, "depth": 3, "title": "Creating a Transaction, Signing, and Submitting", "anchor": "creating-a-transaction-signing-and-submitting", "start_char": 6599, "end_char": 22384, "estimated_token_count": 3701, "token_estimator": "heuristic-v1", "text": "### Creating a Transaction, Signing, and Submitting\n\nFor the sake of this example, create two accounts using the [Subkey](/polkadot-protocol/parachain-basics/accounts/#using-subkey){target=\\_blank} CLI tool.\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\">subkey generate</span>\n    <span data-ty>Secret phrase:       south ladder exile ... grape rival settle coil</span>\n    <span data-ty>  Network ID:        substrate</span>\n    <span data-ty>  Secret seed:       0x60b875ea64f33b23093b8f8af542d5360ea121dd017d3053957c64cb73097def</span>\n    <span data-ty>  Public key (hex):  0x84a16fd4762cb944569d5b0a0deb4897fcb9d0a7bc153602f7b908c1b994222a</span>\n    <span data-ty>  Account ID:        0x84a16fd4762cb944569d5b0a0deb4897fcb9d0a7bc153602f7b908c1b994222a</span>\n    <span data-ty>  Public key (SS58): 5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2</span>\n    <span data-ty>  SS58 Address:      5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2</span>\n    <span data-ty></span>\n    <span data-ty=\"input\">subkey generate</span>\n    <span data-ty>Secret phrase:       car blood garden ... bomb armed potato</span>\n    <span data-ty>  Network ID:        substrate</span>\n    <span data-ty>  Secret seed:       0xced7bd306e992e7fce7efb3e4e1f6b196c402173d23c55ece35f1ca685d8e4eb</span>\n    <span data-ty>  Public key (hex):  0xa4e4a64dcabae6f6f95de52a81d42361926443e26efede9c7cd9d6034e43c761</span>\n    <span data-ty>  Account ID:        0xa4e4a64dcabae6f6f95de52a81d42361926443e26efede9c7cd9d6034e43c761</span>\n    <span data-ty>  Public key (SS58): 5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD</span>\n    <span data-ty>  SS58 Address:      5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD</span>\n</div>\n\nLet's say you want to send 1 WND from `5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2` to `5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD` on [Westend's Asset Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fasset-hub-westend-rpc.n.dwellir.com#/accounts){target=\\_blank} using `polkadot-js-signer`.\n\nFirst, fund the sending account. You can use the [Westend Faucet](https://faucet.polkadot.io/westend){target=\\_blank} to do so.\nRequest some tokens for `5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2`.\n\nNext, call `submit` to create the transaction, which will give you the payload to sign.\n\n```bash\npolkadot-js-signer submit --account 5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2 --ws wss://asset-hub-westend-rpc.n.dwellir.com balances.transferKeepAlive 5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD 1000000000000\n```\n\nThis will return a payload to sign and an input waiting for a signature.\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot-js-signer submit --account 5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2 --ws wss://asset-hub-westend-rpc.n.dwellir.com balances.transferKeepAlive 5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD 1000000000000</span>\n    <span data-ty>Payload: 0x040300ff4a83f1...a8239139ff3ff7c3f6</span>\n    <span data-ty>Signature></span>\n</div>\n\nTake this payload and use your normal signing environment (e.g., air-gapped machine, VM, etc.). In a separate tab of your terminal, sign the payload.\n\n```bash\npolkadot-js-signer sign --account 5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2 --seed \"south ladder exile ... grape rival settle coil\" --type sr25519 0x040300ff4a83f1...a8239139ff3ff7c3f6\n```\n\nThis will output the transaction's signature. \n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot-js-signer sign --account 5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2 --seed \"south ladder exile ... grape rival settle coil\" --type sr25519 0x040300ff4a83f1...a8239139ff3ff7c3f6</span>\n    <span data-ty>Signature: 0xe6facf194a8e...413ce3155c2d1240b</span>\n</div>\n\nPaste this signature into the `submit` signature field, and send the transaction (or just return the serialized transaction if using `sendOffline`).\n\nBy default, submit will create a mortal extrinsic with a lifetime of 50 blocks. \n\nAssuming a six-second block time, you will have five minutes to go offline, sign the transaction, paste the signature, and submit the signed transaction.\n\nYou will get useful output in the terminal with details like the events that were fired off, as well as the block in which the extrinsic is in. \n\n??? code \"Full example output\"\n    -<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot-js-signer submit --account 5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2 --ws wss://westend-asset-hub-rpc.polkadot.io balances.transferKeepAlive 5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD 1000000000000</span>\n    <span data-ty>    2025-07-16 16:00:12        REGISTRY: Unknown signed extensions AuthorizeCall, StorageWeightReclaim found, treating them as no-effect</span>\n    <span data-ty>    2025-07-16 16:00:12        API/INIT: RPC methods not decorated: archive_v1_body, archive_v1_call, archive_v1_finalizedHeight, archive_v1_genesisHash, archive_v1_hashByHeight, archive_v1_header, archive_v1_stopStorage, archive_v1_storage, archive_v1_storageDiff, archive_v1_storageDiff_stopStorageDiff, chainHead_v1_body, chainHead_v1_call, chainHead_v1_continue, chainHead_v1_follow, chainHead_v1_header, chainHead_v1_stopOperation, chainHead_v1_storage, chainHead_v1_unfollow, chainHead_v1_unpin, chainSpec_v1_chainName, chainSpec_v1_genesisHash, chainSpec_v1_properties, transactionWatch_v1_submitAndWatch, transactionWatch_v1_unwatch, transaction_v1_broadcast, transaction_v1_stop</span>\n    <span data-ty>    Payload: 0x0a0300a4e4a64dcabae6f6f95de52a81d42361926443e26efede9c7cd9d6034e43c761070010a5d4e8f503000000009d880f001000000067f9723393ef76214df0118c34bbbd3dbebc8ed46a10973a8c969d48fe7598c949f8bd6deece0f1717c444d4323c255962b627b615b18de8316c5a47d960402c00</span>\n    <span data-ty>    Signature> 0x01960389b87612cda987189e21143e83907cad9bba0a0990b377df915b9e3df561dbe953cf2f20f11a5e8ad80c0d0da2dcc6bc5bc85967116c9f3ecd9f613a5e82</span>\n    <span data-ty>    {</span>\n    <span data-ty>      \"events\": [],</span>\n    <span data-ty>      \"status\": \"Ready\"</span>\n    <span data-ty>    }</span>\n    <span data-ty>    {</span>\n    <span data-ty>      \"events\": [],</span>\n    <span data-ty>      \"status\": {</span>\n    <span data-ty>        \"Broadcast\": [</span>\n    <span data-ty>          \"12D3KooWDoq4PVdWm5nzRSvEz3DSSKjVgRhWVUaKyi5JMKwJKYbk\",</span>\n    <span data-ty>          \"12D3KooWRZBHqijn91FMnihg3oN487oXLFoumr6SoN886Dxdu3yU\",</span>\n    <span data-ty>          \"12D3KooWSQvp4JByYRdieqhqoDEZ6NL2g2wttivrRuQH2KPGCWfh\",</span>\n    <span data-ty>          \"12D3KooWSKSHBXBAs7QvUKwDkFheuyL22KpHPS26q371iZ3WFQuF\",</span>\n    <span data-ty>          \"12D3KooWDkgKu9ibY92EfC2YBhVWSmnTuwE5d4M7AoSphZ7YbkSP\",</span>\n    <span data-ty>          \"12D3KooWLHHS5UtH6QCdWdDu92915k5Ka8H9uJW4SpCEuT7wJycg\",</span>\n    <span data-ty>          \"12D3KooWG4YUe7AfSxVwyLQBRRMU99krssmGAUghqUFoVY1iPkQs\",</span>\n    <span data-ty>          \"12D3KooWJaAfPyiye7ZQBuHengTJJoMrcaz7Jj1UzHiKdNxA1Nkd\",</span>\n    <span data-ty>          \"12D3KooWGD9caunL5KZuqMuHHFR6xv7gLqJH8cLrb9Q23yDy9JG1\",</span>\n    <span data-ty>          \"12D3KooWN7MjtEfEnS9FZHgRdfZcxQ9RPppeDqBLKQ4VQ1QWPtSC\",</span>\n    <span data-ty>          \"12D3KooWDfepM7kqUHMXdGqJw3ZmtvAcE2CjPcnYjT2tTfAw3ZBd\",</span>\n    <span data-ty>          \"12D3KooWCUYurDvauYyjLQH81LSj9hCdkcKtYYMEJWfLsJWZENs2\",</span>\n    <span data-ty>          \"12D3KooWJbrCd1v9i21bY7hbtnUkhmkHct62331kxRTdZDPF2U8D\",</span>\n    <span data-ty>          \"12D3KooWSVSxmf8BNTqwb9gZDVWJGho7Sy84QiAcArQUeTgkePyV\",</span>\n    <span data-ty>          \"12D3KooWLjaXWhNTSiRVFbTJCKLRWt9XXHLGVnAFtxvnExKkVPqn\",</span>\n    <span data-ty>          \"12D3KooWPPVazRmxrWK4AGYFuwNdJXzZshiLU73tw9ikpv8VhsP7\",</span>\n    <span data-ty>          \"12D3KooWE4UDXqgtTcMCyUQ8S4uvaT8VMzzTBA6NWmKuYwTacWuN\",</span>\n    <span data-ty>          \"12D3KooWJwsogNonEiY9PJUX9Gk564KJ1NfHAiTDPtL7rh7djf3A\",</span>\n    <span data-ty>          \"12D3KooWDUPyF2q8b6fVFEuwxBbRV3coAy1kzuCPU3D9TRiLnUfE\",</span>\n    <span data-ty>          \"12D3KooWFLR2UN6PMAUwNAjiWBAiEDoYcWRrtjDrUfRkdUssge4v\",</span>\n    <span data-ty>          \"12D3KooWHpoHiCNYJAcfwe8uiqybx5wX25a2YAPr9A5nq5Htg223\",</span>\n    <span data-ty>          \"12D3KooWLgfaWf4uBJkGv3MRq2x7zxgBwQ6yHVCerF3dU8FncWkX\",</span>\n    <span data-ty>          \"12D3KooWK13Bi57EgkxxiJV2RsPCWoaEWRyq6kuAPwMq39Y4WLQj\",</span>\n    <span data-ty>          \"12D3KooWFGswsMTKSrbPyRRTjcjjCVJVANKu1aLSZzxH5gSk4xhs\",</span>\n    <span data-ty>          \"12D3KooWE7C5Tebbccm76xzJY61LhqGhp9CLHyTtfDetLAURHpDJ\",</span>\n    <span data-ty>          \"12D3KooWLG4V41JQw12GXqXXmKe6w68LvyzEYcAhUmeZTf67Cs6P\",</span>\n    <span data-ty>          \"12D3KooWQKMXaeDjgWyvkBECeYF6Zz2r8YrtuvYeQ4ir9KazpqXP\",</span>\n    <span data-ty>          \"12D3KooWHU4qqSyqKdbXdrCTMXUJxxueaZjqpqSaQqYiFPw6XqEx\"</span>\n    <span data-ty>        ]</span>\n    <span data-ty>      }</span>\n    <span data-ty>    }</span>\n    <span data-ty>    {</span>\n    <span data-ty>      \"dispatchInfo\": {</span>\n    <span data-ty>        \"weight\": {</span>\n    <span data-ty>          \"refTime\": \"383,866,000\",</span>\n    <span data-ty>          \"proofSize\": \"4,261\"</span>\n    <span data-ty>        },</span>\n    <span data-ty>        \"class\": \"Normal\",</span>\n    <span data-ty>        \"paysFee\": \"Yes\"</span>\n    <span data-ty>      },</span>\n    <span data-ty>      \"events\": [</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"Withdraw\",</span>\n    <span data-ty>            \"section\": \"balances\",</span>\n    <span data-ty>            \"index\": \"0x0a08\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"who\": \"5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2\",</span>\n    <span data-ty>              \"amount\": \"2,933,772,732\"</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        },</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"NewAccount\",</span>\n    <span data-ty>            \"section\": \"system\",</span>\n    <span data-ty>            \"index\": \"0x0003\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"account\": \"5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD\"</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        },</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"Endowed\",</span>\n    <span data-ty>            \"section\": \"balances\",</span>\n    <span data-ty>            \"index\": \"0x0a00\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"account\": \"5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD\",</span>\n    <span data-ty>              \"freeBalance\": \"1,000,000,000,000\"</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        },</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"Transfer\",</span>\n    <span data-ty>            \"section\": \"balances\",</span>\n    <span data-ty>            \"index\": \"0x0a02\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"from\": \"5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2\",</span>\n    <span data-ty>              \"to\": \"5FnudgwK8xJvmujsXXP35pF2xwskhHQzBSRM8KZhXjnEz5gD\",</span>\n    <span data-ty>              \"amount\": \"1,000,000,000,000\"</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        },</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"Deposit\",</span>\n    <span data-ty>            \"section\": \"balances\",</span>\n    <span data-ty>            \"index\": \"0x0a07\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"who\": \"5EYCAe5cKPAoFh2HnQQvpKqRYZGqBpaA87u4Zzw89qPE58is\",</span>\n    <span data-ty>              \"amount\": \"2,933,772,732\"</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        },</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"TransactionFeePaid\",</span>\n    <span data-ty>            \"section\": \"transactionPayment\",</span>\n    <span data-ty>            \"index\": \"0x0b00\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"who\": \"5F4c8mNz6schf2WMXQZiz1eyR1GGxrMf2coXpAn8mNjxyzp2\",</span>\n    <span data-ty>              \"actualFee\": \"2,933,772,732\",</span>\n    <span data-ty>              \"tip\": \"0\"</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        },</span>\n    <span data-ty>        {</span>\n    <span data-ty>          \"phase\": {</span>\n    <span data-ty>            \"ApplyExtrinsic\": \"2\"</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"event\": {</span>\n    <span data-ty>            \"method\": \"ExtrinsicSuccess\",</span>\n    <span data-ty>            \"section\": \"system\",</span>\n    <span data-ty>            \"index\": \"0x0000\",</span>\n    <span data-ty>            \"data\": {</span>\n    <span data-ty>              \"dispatchInfo\": {</span>\n    <span data-ty>                \"weight\": {</span>\n    <span data-ty>                  \"refTime\": \"383,866,000\",</span>\n    <span data-ty>                  \"proofSize\": \"4,261\"</span>\n    <span data-ty>                },</span>\n    <span data-ty>                \"class\": \"Normal\",</span>\n    <span data-ty>                \"paysFee\": \"Yes\"</span>\n    <span data-ty>              }</span>\n    <span data-ty>            }</span>\n    <span data-ty>          },</span>\n    <span data-ty>          \"topics\": []</span>\n    <span data-ty>        }</span>\n    <span data-ty>      ],</span>\n    <span data-ty>      \"status\": {</span>\n    <span data-ty>        \"InBlock\": \"0x08cc8737961b31d7e9e8877e289bad780c08ac92ac09037871688e6761a8e793\"</span>\n    <span data-ty>      }</span>\n    <span data-ty>    }</span>\n</div>\n\n!!!note \"Submitting Pre-Signed Transaction\"\n    You can also submit pre-signed transactions, e.g., generated using the `sendOffline` command.\n    ```bash\n    polkadot-js-signer submit --tx <signedTransaction> --ws <endpoint>\n    ```"}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 7, "depth": 2, "title": "Txwrapper", "anchor": "txwrapper", "start_char": 22384, "end_char": 22923, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "## Txwrapper\n\nIf you do not want to use the CLI for signing operations, Parity provides an SDK called [txwrapper-core](https://github.com/paritytech/txwrapper-core){target=\\_blank} to generate and sign transactions offline. For Polkadot, Kusama, and select parachains, use the `txwrapper-polkadot` package. Other Polkadot SDK-based chains will have their own `txwrapper-{chain}` implementations. See the [examples](https://github.com/paritytech/txwrapper-core/blob/main/packages/txwrapper-examples/README.md){target=\\_blank} for a guide."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 8, "depth": 3, "title": "Creating a Transaction, Signing, and Submitting", "anchor": "creating-a-transaction-signing-and-submitting-2", "start_char": 22923, "end_char": 26184, "estimated_token_count": 694, "token_estimator": "heuristic-v1", "text": "### Creating a Transaction, Signing, and Submitting\n\nYou will need a network to test the transaction.\nLet's use [chopsticks](/tutorials/polkadot-sdk/testing/fork-live-chains/){target=\\_blank} for this:\n\n```bash\nnpx @acala-network/chopsticks --config=polkadot -p 9944\n```\n\nYou should get a Polkadot network running on port 9944.\n\nThe [`txwrapper` example script](https://github.com/paritytech/txwrapper-core/blob/main/packages/txwrapper-examples/polkadot/src/polkadot.ts){target=\\_blank} will then be used to create and sign transactions.\n\nFor this, you will need the [`txwrapper`](https://github.com/paritytech/txwrapper-core){target=\\_blank} library. Let's clone [`txwrapper`](https://github.com/paritytech/txwrapper-core){target=\\_blank}:\n\n```bash\ngit clone https://github.com/paritytech/txwrapper-core\ncd txwrapper-core\nyarn install && yarn build\ncd packages/txwrapper-examples\n```\n\nBuild and run the [Polkadot `txwrapper` example script](https://github.com/paritytech/txwrapper-core/blob/main/packages/txwrapper-examples/polkadot/src/polkadot.ts){target=\\_blank}:\n\n```bash\nyarn run build\nyarn run polkadot\n```\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>yarn run polkadot</span>\n    <span data-ty>Alice's SS58-Encoded Address: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY</span>\n    <span data-ty></span>\n    <span data-ty>Decoded Transaction</span>\n    <span data-ty>  To: 14E5nqKAp3oAJcmzgZhUD2RcptBeUBScxKHgJKU4HPNcKVf3</span>\n    <span data-ty>  Amount: \"10000000000\"</span>\n    <span data-ty></span>\n    <span data-ty>Payload to Sign: 0xa40503008eaf04151687736326c9fea17e25fc5287613693c912909cb226aa4794f26a480700e40b54028500000000b1590f001a00000091b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3843125cd049613a7edf44b55a01efbabffcd1b962068a82070cff82314b67bbc00</span>\n    <span data-ty></span>\n    <span data-ty>Decoded Transaction</span>\n    <span data-ty>  To: 14E5nqKAp3oAJcmzgZhUD2RcptBeUBScxKHgJKU4HPNcKVf3</span>\n    <span data-ty>  Amount: \"10000000000\"</span>\n    <span data-ty></span>\n    <span data-ty>Signature: 0x01ae703e667b3b444e3613a5f06d16bedf2460a18e52075b47c6442ebc1d316917c6d12e3aa7bbd2f8db76cc859b43134cecb4495613d8d504901de776d0642b82</span>\n    <span data-ty></span>\n    <span data-ty>Transaction to Submit: 0x45028400d43593c715fdd31c61141abd04a99fd6822c8558854ccde39a5684e7a56da27d01ae703e667b3b444e3613a5f06d16bedf2460a18e52075b47c6442ebc1d316917c6d12e3aa7bbd2f8db76cc859b43134cecb4495613d8d504901de776d0642b8285000000000503008eaf04151687736326c9fea17e25fc5287613693c912909cb226aa4794f26a480700e40b5402</span>\n    <span data-ty></span>\n    <span data-ty>Expected Tx Hash: 0xa12126a095b38f0c70331be78743329a851e33839f9b2f93a7ecc34541507891</span>\n    <span data-ty>Actual Tx Hash: 0xa12126a095b38f0c70331be78743329a851e33839f9b2f93a7ecc34541507891</span>\n    <span data-ty></span>\n    <span data-ty>Decoded Transaction</span>\n    <span data-ty>  To: 14E5nqKAp3oAJcmzgZhUD2RcptBeUBScxKHgJKU4HPNcKVf3</span>\n    <span data-ty>  Amount: \"10000000000\"</span>\n</div>\n\nThe [`txwrapper` example script](https://github.com/paritytech/txwrapper-core/blob/main/packages/txwrapper-examples/polkadot/src/polkadot.ts){target=\\_blank} includes several reference examples."}
{"page_id": "develop-toolkit-integrations-transaction-construction", "index": 9, "depth": 2, "title": "Additional Libraries for Submitting a Transaction", "anchor": "additional-libraries-for-submitting-a-transaction", "start_char": 26184, "end_char": 27106, "estimated_token_count": 220, "token_estimator": "heuristic-v1", "text": "## Additional Libraries for Submitting a Transaction\n\nOther than Polkadot JS Tools and txwrapper, there are several other libraries that can also be used to submit a signed payload, such as the [Sidecar API](/develop/toolkit/api-libraries/sidecar/#sidecar-api){target=\\_blank} or using RPC calls with [`author_submitExtrinsic`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/author/trait.AuthorApiServer.html#tymethod.submit_extrinsic){target=\\_blank} or [`author_submitAndWatchExtrinsic`](https://github.com/paritytech/polkadot-sdk/blob/0ae5c5bbd96a600aed81358339be2f16bade4a81/substrate/client/rpc-api/src/author/mod.rs#L69-L78){target=\\_blank}, the latter of which will subscribe you to events to be notified as a transaction gets validated and included in the chain. You can see all the available libraries in the [API Libraries](/develop/toolkit/api-libraries/){target=\\_blank} section of the Polkadot Docs."}
{"page_id": "develop-toolkit-integrations-wallets", "index": 0, "depth": 2, "title": "What is a Blockchain Wallet?", "anchor": "what-is-a-blockchain-wallet", "start_char": 11, "end_char": 656, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "## What is a Blockchain Wallet?\n\nA wallet serves as your gateway to interacting with blockchain networks. Rather than storing funds, wallets secure your private keys, controlling access to your blockchain assets. Your private key provides complete control over all permitted transactions on your blockchain account, making it essential to keep it secure.\n\nWallet types fall into two categories based on their connection to the internet:\n\n- **[Hot wallets](#hot-wallets)**: Online storage through websites, browser extensions or smartphone apps.\n- **[Cold wallets](#cold-wallets)**: Offline storage using hardware devices or air-gapped systems."}
{"page_id": "develop-toolkit-integrations-wallets", "index": 1, "depth": 2, "title": "Hot Wallets", "anchor": "hot-wallets", "start_char": 656, "end_char": 2224, "estimated_token_count": 342, "token_estimator": "heuristic-v1", "text": "## Hot Wallets\n\n<div class=\"grid cards\" markdown>\n\n-   __Nova Wallet__\n\n    ---\n\n    A non-custodial, mobile-first wallet for managing assets and interacting with the Polkadot and Kusama ecosystems. It supports staking, governance, cross-chain transfers, and crowdloans. With advanced features, seamless multi-network support, and strong security, Nova Wallet empowers users to explore the full potential of Polkadot parachains on the go.\n\n    [:octicons-arrow-right-24: Reference](https://novawallet.io/){target=\\_blank}\n\n-   __Talisman__\n\n    ---\n\n    A non-custodial web browser extension that allows you to manage your portfolio and interact with Polkadot and Ethereum applications. It supports Web3 apps, asset storage, and account management across over 150 Polkadot SDK-based and EVM networks. Features include NFT management, Ledger support, fiat on-ramp, and portfolio tracking.\n\n    [:octicons-arrow-right-24: Reference](https://talisman.xyz/){target=\\_blank}\n\n-  __Subwallet__\n\n    ---\n\n    A non-custodial web browser extension and mobile wallet for Polkadot and Ethereum. Track, send, receive, and monitor multi-chain assets on 150+ networks. Import account with seed phrase, private key, QR code, and JSON file. Import token & NFT, attach read-only account. XCM Transfer, NFT Management, Parity Signer & Ledger support, light clients support, EVM dApp support, MetaMask compatibility, custom endpoints, fiat on-ramp, phishing detection, transaction history.\n\n    [:octicons-arrow-right-24: Reference](https://www.subwallet.app/){target=\\_blank}\n\n</div>"}
{"page_id": "develop-toolkit-integrations-wallets", "index": 2, "depth": 2, "title": "Cold Wallets", "anchor": "cold-wallets", "start_char": 2224, "end_char": 2921, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "## Cold Wallets\n\n<div class=\"grid cards\" markdown>\n\n-   __Ledger__\n\n    ---\n\n    A hardware wallet that securely stores cryptocurrency private keys offline, protecting them from online threats. Using a secure chip and the Ledger Live app allows safe transactions and asset management while keeping keys secure.\n\n    [:octicons-arrow-right-24: Reference](https://www.ledger.com/){target=\\_blank}\n\n-   __Polkadot Vault__\n\n    ---\n\n    This cold storage solution lets you use a phone in airplane mode as an air-gapped wallet, turning any spare phone, tablet, or iOS/Android device into a hardware wallet.\n\n    [:octicons-arrow-right-24: Reference](https://vault.novasama.io/){target=\\_blank}\n\n</div>"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 882, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Asset Transfer API](https://github.com/paritytech/asset-transfer-api){target=\\_blank}, a tool developed and maintained by [Parity](https://www.parity.io/){target=\\_blank}, is a specialized library designed to streamline asset transfers for Polkadot SDK-based blockchains. This API provides a simplified set of methods for users to:\n\n- Execute asset transfers to other parachains or locally within the same chain.\n- Facilitate transactions involving system parachains like Asset Hub (Polkadot and Kusama).\n\nUsing this API, developers can manage asset transfers more efficiently, reducing the complexity of cross-chain transactions and enabling smoother operations within the ecosystem.\n\nFor additional support and information, please reach out through [GitHub Issues](https://github.com/paritytech/asset-transfer-api/issues){target=\\_blank}."}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 882, "end_char": 1334, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- [Node.js](https://nodejs.org/en/){target=\\_blank} (recommended version 21 or greater).\n- A package manager like [npm](https://www.npmjs.com/){target=\\_blank} should be installed with Node.js by default. Alternatively, you can use other package managers like [Yarn](https://yarnpkg.com/){target=\\_blank}.\n\nThis documentation covers version `1.0.0` of Asset Transfer API."}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 2, "depth": 2, "title": "Install Asset Transfer API", "anchor": "install-asset-transfer-api", "start_char": 1334, "end_char": 1974, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "## Install Asset Transfer API\n\nTo use `asset-transfer-api`, you need a TypeScript project. If you don't have one, you can create a new one:\n\n1. Create a new directory for your project:\n\n    ```bash\n    mkdir my-asset-transfer-project \\\n    && cd my-asset-transfer-project\n    ```\n\n2. Initialize a new TypeScript project:\n\n    ```bash\n    npm init -y \\\n    && npm install typescript ts-node @types/node --save-dev \\\n    && npx tsc --init\n    ```\n\nOnce you have a project set up, you can install the `asset-transfer-api` package. Run the following command to install the package:\n\n```bash\nnpm install @substrate/asset-transfer-api@1.0.0\n```"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 3, "depth": 2, "title": "Set Up Asset Transfer API", "anchor": "set-up-asset-transfer-api", "start_char": 1974, "end_char": 2159, "estimated_token_count": 41, "token_estimator": "heuristic-v1", "text": "## Set Up Asset Transfer API\n\nTo initialize the Asset Transfer API, you need three key components:\n\n- A Polkadot.js API instance\n- The `specName` of the chain\n- The XCM version to use"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 4, "depth": 3, "title": "Using Helper Function from Library", "anchor": "using-helper-function-from-library", "start_char": 2159, "end_char": 3318, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "### Using Helper Function from Library\n\nLeverage the `constructApiPromise` helper function provided by the library for the simplest setup process. It not only constructs a Polkadot.js `ApiPromise` but also automatically retrieves the chain's `specName` and fetches a safe XCM version. By using this function, developers can significantly reduce boilerplate code and potential configuration errors, making the initial setup both quicker and more robust.\n\n```ts\n-import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'INSERT_WEBSOCKET_URL',\n  );\n\n  const assetsApi = new AssetTransferApi(api, specName, safeXcmVersion);\n\n  // Your code using assetsApi goes here\n}\n\nmain();\n\n```\n\n!!!warning\n    The code example is enclosed in an async main function to provide the necessary asynchronous context. However, you can use the code directly if you're already working within an async environment. The key is to ensure you're in an async context when working with these asynchronous operations, regardless of your specific setup."}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 5, "depth": 2, "title": "Asset Transfer API Reference", "anchor": "asset-transfer-api-reference", "start_char": 3318, "end_char": 3728, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Asset Transfer API Reference\n\nFor detailed information on the Asset Transfer API, including available methods, data types, and functionalities, refer to the [Asset Transfer API Reference](/develop/toolkit/interoperability/asset-transfer-api/reference){target=\\_blank} section. This resource provides in-depth explanations and technical specifications to help you integrate and utilize the API effectively."}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 6, "depth": 2, "title": "Examples", "anchor": "examples", "start_char": 3728, "end_char": 3741, "estimated_token_count": 3, "token_estimator": "heuristic-v1", "text": "## Examples"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 7, "depth": 3, "title": "Relay to System Parachain Transfer", "anchor": "relay-to-system-parachain-transfer", "start_char": 3741, "end_char": 8103, "estimated_token_count": 1227, "token_estimator": "heuristic-v1", "text": "### Relay to System Parachain Transfer\n\nThis example demonstrates how to initiate a cross-chain token transfer from a relay chain to a system parachain. Specifically, 1 WND will be transferred from a Westend (relay chain) account to a Westmint (system parachain) account.\n\n```ts\n-import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://westend-rpc.polkadot.io',\n  );\n  const assetApi = new AssetTransferApi(api, specName, safeXcmVersion);\n  let callInfo;\n  try {\n    callInfo = await assetApi.createTransferTransaction(\n      '1000',\n      '5EWNeodpcQ6iYibJ3jmWVe85nsok1EDG8Kk3aFg8ZzpfY1qX',\n      ['WND'],\n      ['1000000000000'],\n      {\n        format: 'call',\n        xcmVersion: safeXcmVersion,\n      },\n    );\n\n    console.log(`Call data:\\n${JSON.stringify(callInfo, null, 4)}`);\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n\n  const decoded = assetApi.decodeExtrinsic(callInfo.tx, 'call');\n  console.log(`\\nDecoded tx:\\n${JSON.stringify(JSON.parse(decoded), null, 4)}`);\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n```\n\nAfter running the script, you'll see the following output in the terminal, which shows the call data for the cross-chain transfer and its decoded extrinsic details:\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>ts-node relayToSystem.ts</span>\n    <br>\n\t<span data-ty>Call data:</span>\n\t<span data-ty>{</span>\n\t<span data-ty>    \"origin\": \"westend\",</span>\n\t<span data-ty>    \"dest\": \"westmint\",</span>\n\t<span data-ty>    \"direction\": \"RelayToSystem\",</span>\n\t<span data-ty>    \"xcmVersion\": 3,</span>\n\t<span data-ty>    \"method\": \"transferAssets\",</span>\n\t<span data-ty>    \"format\": \"call\",</span>\n\t<span data-ty>    \"tx\": \"0x630b03000100a10f03000101006c0c32faf970eacb2d4d8e538ac0dab3642492561a1be6f241c645876c056c1d030400000000070010a5d4e80000000000\"</span>\n\t<span data-ty>}</span>\n\t<span data-ty></span>\n\t<span data-ty>Decoded tx:</span>\n\t<span data-ty>{</span>\n\t<span data-ty>    \"args\": {</span>\n\t<span data-ty>        \"dest\": {</span>\n\t<span data-ty>            \"V3\": {</span>\n\t<span data-ty>                \"parents\": \"0\",</span>\n\t<span data-ty>                \"interior\": {</span>\n\t<span data-ty>                    \"X1\": {</span>\n\t<span data-ty>                        \"Parachain\": \"1,000\"</span>\n\t<span data-ty>                    }</span>\n\t<span data-ty>                }</span>\n\t<span data-ty>            }</span>\n\t<span data-ty>        },</span>\n\t<span data-ty>        \"beneficiary\": {</span>\n\t<span data-ty>            \"V3\": {</span>\n\t<span data-ty>                \"parents\": \"0\",</span>\n\t<span data-ty>                \"interior\": {</span>\n\t<span data-ty>                    \"X1\": {</span>\n\t<span data-ty>                        \"AccountId32\": {</span>\n\t<span data-ty>                            \"network\": null,</span>\n\t<span data-ty>                            \"id\": \"0x6c0c32faf970eacb2d4d8e538ac0dab3642492561a1be6f241c645876c056c1d\"</span>\n\t<span data-ty>                        }</span>\n\t<span data-ty>                    }</span>\n\t<span data-ty>                }</span>\n\t<span data-ty>            }</span>\n\t<span data-ty>        },</span>\n\t<span data-ty>        \"assets\": {</span>\n\t<span data-ty>            \"V3\": [</span>\n\t<span data-ty>                {</span>\n\t<span data-ty>                    \"id\": {</span>\n\t<span data-ty>                        \"Concrete\": {</span>\n\t<span data-ty>                            \"parents\": \"0\",</span>\n\t<span data-ty>                            \"interior\": \"Here\"</span>\n\t<span data-ty>                        }</span>\n\t<span data-ty>                    },</span>\n\t<span data-ty>                    \"fun\": {</span>\n\t<span data-ty>                        \"Fungible\": \"1,000,000,000,000\"</span>\n\t<span data-ty>                    }</span>\n\t<span data-ty>                }</span>\n\t<span data-ty>            ]</span>\n\t<span data-ty>        },</span>\n\t<span data-ty>        \"fee_asset_item\": \"0\",</span>\n\t<span data-ty>        \"weight_limit\": \"Unlimited\"</span>\n\t<span data-ty>    },</span>\n\t<span data-ty>    \"method\": \"transferAssets\",</span>\n\t<span data-ty>    \"section\": \"xcmPallet\"</span>\n\t<span data-ty>}</span>\n</div>"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 8, "depth": 3, "title": "Local Parachain Transfer", "anchor": "local-parachain-transfer", "start_char": 8103, "end_char": 10546, "estimated_token_count": 694, "token_estimator": "heuristic-v1", "text": "### Local Parachain Transfer\n\nThe following example demonstrates a local GLMR transfer within Moonbeam, using the `balances` pallet. It transfers 1 GLMR token from one account to another account, where both the sender and recipient accounts are located on the same parachain.\n\n```ts\n-import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://wss.api.moonbeam.network',\n  );\n  const assetApi = new AssetTransferApi(api, specName, safeXcmVersion);\n\n  let callInfo;\n  try {\n    callInfo = await assetApi.createTransferTransaction(\n      '2004',\n      '0xF977814e90dA44bFA03b6295A0616a897441aceC',\n      [],\n      ['1000000000000000000'],\n      {\n        format: 'call',\n        keepAlive: true,\n      },\n    );\n\n    console.log(`Call data:\\n${JSON.stringify(callInfo, null, 4)}`);\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n\n  const decoded = assetApi.decodeExtrinsic(callInfo.tx, 'call');\n  console.log(`\\nDecoded tx:\\n${JSON.stringify(JSON.parse(decoded), null, 4)}`);\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n```\n\nUpon executing this script, the terminal will display the following output, illustrating the encoded extrinsic for the cross-chain message and its corresponding decoded format:\n\n-<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>ts-node localParachainTx.ts</span>\n    <br>\n\t<span data-ty>Call data:</span>\n\t<span data-ty>{</span>\n\t<span data-ty>    \"origin\": \"moonbeam\",</span>\n\t<span data-ty>    \"dest\": \"moonbeam\",</span>\n\t<span data-ty>    \"direction\": \"local\",</span>\n\t<span data-ty>    \"xcmVersion\": null,</span>\n\t<span data-ty>    \"method\": \"balances::transferKeepAlive\",</span>\n\t<span data-ty>    \"format\": \"call\",</span>\n\t<span data-ty>    \"tx\": \"0x0a03f977814e90da44bfa03b6295a0616a897441acec821a0600\"</span>\n\t<span data-ty>}</span>\n\t<span data-ty></span>\n\t<span data-ty>Decoded tx:</span>\n\t<span data-ty>{</span>\n\t<span data-ty>    \"args\": {</span>\n\t<span data-ty>        \"dest\": \"0xF977814e90dA44bFA03b6295A0616a897441aceC\",</span>\n\t<span data-ty>        \"value\": \"1,000,000,000,000,000,000\"</span>\n\t<span data-ty>    },</span>\n\t<span data-ty>    \"method\": \"transferKeepAlive\",</span>\n\t<span data-ty>    \"section\": \"balances\"</span>\n\t<span data-ty>}</span>\n</div>"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-overview", "index": 9, "depth": 3, "title": "Parachain to Parachain Transfer", "anchor": "parachain-to-parachain-transfer", "start_char": 10546, "end_char": 16972, "estimated_token_count": 1570, "token_estimator": "heuristic-v1", "text": "### Parachain to Parachain Transfer\n\nThis example demonstrates creating a cross-chain asset transfer between two parachains. It shows how to send vMOVR and vBNC from a Moonriver account to a Bifrost Kusama account using the safe XCM version. It connects to Moonriver, initializes the API, and uses the `createTransferTransaction` method to prepare a transaction.\n\n```ts\n-import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://moonriver.public.blastapi.io',\n  );\n  const assetApi = new AssetTransferApi(api, specName, safeXcmVersion);\n  let callInfo;\n  try {\n    callInfo = await assetApi.createTransferTransaction(\n      '2001',\n      '0xc4db7bcb733e117c0b34ac96354b10d47e84a006b9e7e66a229d174e8ff2a063',\n      ['vMOVR', '72145018963825376852137222787619937732'],\n      ['1000000', '10000000000'],\n      {\n        format: 'call',\n        xcmVersion: safeXcmVersion,\n      },\n    );\n\n    console.log(`Call data:\\n${JSON.stringify(callInfo, null, 4)}`);\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n\n  const decoded = assetApi.decodeExtrinsic(callInfo.tx, 'call');\n  console.log(`\\nDecoded tx:\\n${JSON.stringify(JSON.parse(decoded), null, 4)}`);\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n```\n\nAfter running this script, you'll see the following output in your terminal. This output presents the encoded extrinsic for the cross-chain message, along with its decoded format, providing a clear view of the transaction details.\n\n-<div id='termynal' data-termynal>\n    <span data-ty='input'><span class='file-path'></span>ts-node paraToPara.ts</span>\n\n    <br>\n    <span data-ty>Call data:</span>\n    <span data-ty>{</span>\n    <span data-ty>    \"origin\": \"moonriver\",</span>\n    <span data-ty>    \"dest\": \"bifrost\",</span>\n    <span data-ty>    \"direction\": \"ParaToPara\",</span>\n    <span data-ty>    \"xcmVersion\": 2,</span>\n    <span data-ty>    \"method\": \"transferMultiassets\",</span>\n    <span data-ty>    \"format\": \"call\",</span>\n    <span data-ty>    \"tx\": \"0x6a05010800010200451f06080101000700e40b540200010200451f0608010a0002093d000000000001010200451f0100c4db7bcb733e117c0b34ac96354b10d47e84a006b9e7e66a229d174e8ff2a06300\"</span>\n    <span data-ty>}</span>\n    <span data-ty></span>\n    <span data-ty>Decoded tx:</span>\n    <span data-ty>{</span>\n    <span data-ty>    \"args\": {</span>\n    <span data-ty>        \"assets\": {</span>\n    <span data-ty>            \"V2\": [</span>\n    <span data-ty>                {</span>\n    <span data-ty>                    \"id\": {</span>\n    <span data-ty>                        \"Concrete\": {</span>\n    <span data-ty>                            \"parents\": \"1\",</span>\n    <span data-ty>                            \"interior\": {</span>\n    <span data-ty>                                \"X2\": [</span>\n    <span data-ty>                                    {</span>\n    <span data-ty>                                        \"Parachain\": \"2,001\"</span>\n    <span data-ty>                                    },</span>\n    <span data-ty>                                    {</span>\n    <span data-ty>                                        \"GeneralKey\": \"0x0101\"</span>\n    <span data-ty>                                    }</span>\n    <span data-ty>                                ]</span>\n    <span data-ty>                            }</span>\n    <span data-ty>                        }</span>\n    <span data-ty>                    },</span>\n    <span data-ty>                    \"fun\": {</span>\n    <span data-ty>                        \"Fungible\": \"10,000,000,000\"</span>\n    <span data-ty>                    }</span>\n    <span data-ty>                },</span>\n    <span data-ty>                {</span>\n    <span data-ty>                    \"id\": {</span>\n    <span data-ty>                        \"Concrete\": {</span>\n    <span data-ty>                            \"parents\": \"1\",</span>\n    <span data-ty>                            \"interior\": {</span>\n    <span data-ty>                                \"X2\": [</span>\n    <span data-ty>                                    {</span>\n    <span data-ty>                                        \"Parachain\": \"2,001\"</span>\n    <span data-ty>                                    },</span>\n    <span data-ty>                                    {</span>\n    <span data-ty>                                        \"GeneralKey\": \"0x010a\"</span>\n    <span data-ty>                                    }</span>\n    <span data-ty>                                ]</span>\n    <span data-ty>                            }</span>\n    <span data-ty>                        }</span>\n    <span data-ty>                    },</span>\n    <span data-ty>                    \"fun\": {</span>\n    <span data-ty>                        \"Fungible\": \"1,000,000\"</span>\n    <span data-ty>                    }</span>\n    <span data-ty>                }</span>\n    <span data-ty>            ]</span>\n    <span data-ty>        },</span>\n    <span data-ty>        \"fee_item\": \"0\",</span>\n    <span data-ty>        \"dest\": {</span>\n    <span data-ty>            \"V2\": {</span>\n    <span data-ty>                \"parents\": \"1\",</span>\n    <span data-ty>                \"interior\": {</span>\n    <span data-ty>                    \"X2\": [</span>\n    <span data-ty>                        {</span>\n    <span data-ty>                            \"Parachain\": \"2,001\"</span>\n    <span data-ty>                        },</span>\n    <span data-ty>                        {</span>\n    <span data-ty>                            \"AccountId32\": {</span>\n    <span data-ty>                                \"network\": \"Any\",</span>\n    <span data-ty>                                \"id\": \"0xc4db7bcb733e117c0b34ac96354b10d47e84a006b9e7e66a229d174e8ff2a063\"</span>\n    <span data-ty>                            }</span>\n    <span data-ty>                        }</span>\n    <span data-ty>                    ]</span>\n    <span data-ty>                }</span>\n    <span data-ty>            }</span>\n    <span data-ty>        },</span>\n    <span data-ty>        \"dest_weight_limit\": \"Unlimited\"</span>\n    <span data-ty>    },</span>\n    <span data-ty>    \"method\": \"transferMultiassets\",</span>\n    <span data-ty>    \"section\": \"xTokens\"</span>\n    <span data-ty>}</span>\n</div>"}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-reference", "index": 0, "depth": 2, "title": "Asset Transfer API Class", "anchor": "asset-transfer-api-class", "start_char": 775, "end_char": 1148, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Asset Transfer API Class\n\nHolds open an API connection to a specified chain within the `ApiPromise` to help construct transactions for assets and estimate fees.\n\nFor a more in-depth explanation of the Asset Transfer API class structure, check the [source code](https://github.com/paritytech/asset-transfer-api/blob/v1.0.0/src/AssetTransferApi.ts#L128){target=\\_blank}."}
{"page_id": "develop-toolkit-interoperability-asset-transfer-api-reference", "index": 1, "depth": 3, "title": "Methods", "anchor": "methods", "start_char": 1148, "end_char": 27698, "estimated_token_count": 6252, "token_estimator": "heuristic-v1", "text": "### Methods\n\n#### Create Transfer Transaction\n\nGenerates an XCM transaction for transferring assets between chains. It simplifies the process by inferring what type of transaction is required given the inputs, ensuring that the assets are valid, and that the transaction details are correctly formatted.\n\nAfter obtaining the transaction, you must handle the signing and submission process separately.\n\n```ts\n-public async createTransferTransaction<T extends Format>(\n\t\tdestChainId: string,\n\t\tdestAddr: string,\n\t\tassetIds: string[],\n\t\tamounts: string[],\n\t\topts: TransferArgsOpts<T> = {},\n\t): Promise<TxResult<T>> {\n```\n\n??? interface \"Request parameters\"\n\n    `destChainId` ++\"string\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    ID of the destination chain (`'0'` for relay chain, other values for parachains).\n\n    ---\n\n    `destAddr` ++\"string\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Address of the recipient account on the destination chain.\n\n    ---\n\n    `assetIds` ++\"string[]\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Array of asset IDs to be transferred.\n\n    When asset IDs are provided, the API dynamically selects the appropriate pallet for the current chain to handle these specific assets. If the array is empty, the API defaults to using the `balances` pallet.\n\n    ---\n\n    `amounts` ++\"string[]\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Array of amounts corresponding to each asset in `assetIds`.\n\n    ---\n\n    `opts` ++\"TransferArgsOpts<T>\"++\n\n    -Options for customizing the claim assets transaction. These options allow you to specify the transaction format, fee payment details, weight limits, XCM versions, and more.\n\n??? child \"Show more\"\n\n    `format` ++\"T extends Format\"++ \n        \n    Specifies the format for returning a transaction.\n\n    ??? child \"Type `Format`\"\n\n        ```ts\n        -export type Format = 'payload' | 'call' | 'submittable';\n        ```\n\n    ---\n\n    `paysWithFeeOrigin` ++\"string\"++\n    \n    The Asset ID to pay fees on the current common good parachain. The defaults are as follows:\n\n    - **Polkadot Asset Hub**: `'DOT'`\n    - **Kusama Asset Hub**: `'KSM'`\n\n    ---\n\n    `paysWithFeeDest` ++\"string\"++\n    \n    Asset ID to pay fees on the destination parachain.\n\n    ---\n\n    `weightLimit` ++\"{ refTime?: string, proofSize?: string }\"++\n    \n    Custom weight limit option. If not provided, it will default to unlimited.\n\n    ---\n\n    `xcmVersion` ++\"number\"++\n    \n    Sets the XCM version for message construction. If this is not present a supported version will be queried, and if there is no supported version a safe version will be queried.\n\n    ---\n\n    `keepAlive` ++\"boolean\"++\n    \n    Enables `transferKeepAlive` for local asset transfers. For creating local asset transfers, if `true` this will allow for a `transferKeepAlive` as opposed to a `transfer`.\n\n    ---\n\n    `transferLiquidToken` ++\"boolean\"++\n    \n    Declares if this will transfer liquidity tokens. Default is `false`.\n\n    ---\n\n    `assetTransferType` ++\"string\"++\n    \n    The XCM transfer type used to transfer assets. The `AssetTransferType` type defines the possible values for this parameter.\n\n    ??? child \"Type `AssetTransferType`\"\n\n        ```ts\n        -export type AssetTransferType = LocalReserve | DestinationReserve | Teleport | RemoteReserve;\n        ```\n        \n        !!! note\n            To use the `assetTransferType` parameter, which is a string, you should use the `AssetTransferType` type as if each of its variants are strings. For example: `assetTransferType = 'LocalReserve'`.\n\n\n    ---\n\n    `remoteReserveAssetTransferTypeLocation` ++\"string\"++\n    \n    The remove reserve location for the XCM transfer. Should be provided when specifying an `assetTransferType` of `RemoteReserve`.\n\n    ---\n\n    `feesTransferType` ++\"string\"++\n    \n    XCM TransferType used to pay fees for XCM transfer. The `AssetTransferType` type defines the possible values for this parameter.\n\n    ??? child \"Type `AssetTransferType`\"\n\n        ```ts\n        -export type AssetTransferType = LocalReserve | DestinationReserve | Teleport | RemoteReserve;\n        ```\n        \n        !!! note\n            To use the `feesTransferType` parameter, which is a string, you should use the `AssetTransferType` type as if each of its variants are strings. For example: `feesTransferType = 'LocalReserve'`.\n\n    ---\n\n    `remoteReserveFeesTransferTypeLocation` ++\"string\"++\n    \n    The remote reserve location for the XCM transfer fees. Should be provided when specifying a `feesTransferType` of `RemoteReserve`.\n\n    ---\n\n    `customXcmOnDest` ++\"string\"++\n    \n    A custom XCM message to be executed on the destination chain. Should be provided if a custom XCM message is needed after transferring assets. Defaults to:\n\n    ```bash\n    Xcm(vec![DepositAsset { assets: Wild(AllCounted(assets.len())), beneficiary }])\n    ```\n\n\n??? interface \"Response parameters\"\n\n    ++\"Promise<TxResult<T>\"++\n\n    -A promise containing the result of constructing the transaction.\n\n??? child \"Show more\"\n\n    `dest` ++\"string\"++\n\n    The destination `specName` of the transaction.\n\n    ---\n\n    `origin` ++\"string\"++\n\n    The origin `specName` of the transaction.\n\n    ---\n\n    `format` ++\"Format | 'local'\"++\n\n    The format type the transaction is outputted in.\n\n    ??? child \"Type `Format`\"\n\n        ```ts\n        -export type Format = 'payload' | 'call' | 'submittable';\n        ```\n\n    ---\n\n    `xcmVersion` ++\"number | null\"++\n\n    The XCM version that was used to construct the transaction.\n\n    ---\n\n    `direction` ++\"Direction | 'local'\"++\n\n    The direction of the cross-chain transfer.\n\n    ??? child \"Enum `Direction` values\"\n\n        `Local`\n\n        Local transaction.\n\n        ---\n\n        `SystemToPara`\n\n        System parachain to parachain.\n\n        ---\n\n        `SystemToRelay`\n\n        System paracahin to system relay chain.\n\n        ---\n\n        `SystemToSystem`\n\n        System parachain to System parachain chain.\n\n        ---\n\n        `SystemToBridge`\n\n        System parachain to an external `GlobalConsensus` chain.\n        \n        ---\n\n        `ParaToPara`\n\n        Parachain to Parachain.\n\n        ---\n\n        `ParaToRelay`\n\n        Parachain to Relay chain.\n\n        ---\n        \n        `ParaToSystem`\n\n        Parachain to System parachain.\n\n        ---\n\n        `RelayToSystem`\n\n        Relay to System Parachain.\n\n        ---\n\n        `RelayToPara`\n\n        Relay chain to Parachain.\n\n        ---\n\n        `RelayToBridge`\n\n        Relay chain to an external `GlobalConsensus` chain.\n\n    `method` ++\"Methods\"++\n\n    The method used in the transaction.\n\n    ??? child \"Type `Methods`\"\n\n        ```ts\n        -export type Methods =\n\t| LocalTransferTypes\n\t| 'transferAssets'\n\t| 'transferAssetsUsingTypeAndThen'\n\t| 'limitedReserveTransferAssets'\n\t| 'limitedTeleportAssets'\n\t| 'transferMultiasset'\n\t| 'transferMultiassets'\n\t| 'transferMultiassetWithFee'\n\t| 'claimAssets';\n        ```\n\n        ??? child \"Type `LocalTransferTypes`\"\n\n\n            ```ts\n            -export type LocalTransferTypes =\n\t| 'assets::transfer'\n\t| 'assets::transferKeepAlive'\n\t| 'assets::transferAll'\n\t| 'foreignAssets::transfer'\n\t| 'foreignAssets::transferKeepAlive'\n\t| 'foreignAssets::transferAll'\n\t| 'balances::transfer'\n\t| 'balances::transferKeepAlive'\n\t| 'balances::transferAll'\n\t| 'poolAssets::transfer'\n\t| 'poolAssets::transferKeepAlive'\n\t| 'poolAssets::transferAll'\n\t| 'tokens::transfer'\n\t| 'tokens::transferKeepAlive'\n\t| 'tokens::transferAll';\n            ```\n\n    ---\n\n    `tx` ++\"ConstructedFormat<T>\"++\n\n    The constructed transaction.\n\n    ??? child \"Type `ConstructedFormat<T>`\"\n\n        ```ts\n        -export type ConstructedFormat<T> = T extends 'payload'\n\t? GenericExtrinsicPayload\n\t: T extends 'call'\n\t\t? `0x${string}`\n\t\t: T extends 'submittable'\n\t\t\t? SubmittableExtrinsic<'promise', ISubmittableResult>\n\t\t\t: never;\n        ```\n\n        The `ConstructedFormat` type is a conditional type that returns a specific type based on the value of the TxResult `format` field.\n\n        - **Payload format**: If the format field is set to `'payload'`, the `ConstructedFormat` type will return a [`GenericExtrinsicPayload`](https://github.com/polkadot-js/api/blob/v15.8.1/packages/types/src/extrinsic/ExtrinsicPayload.ts#L87){target=\\_blank}.\n        - **Call format**: If the format field is set to `'call'`, the `ConstructedFormat` type will return a hexadecimal string (`0x${string}`). This is the encoded representation of the extrinsic call.\n        - **Submittable format**: If the format field is set to `'submittable'`, the `ConstructedFormat` type will return a [`SubmittableExtrinsic`](https://github.com/polkadot-js/api/blob/v15.8.1/packages/api-base/src/types/submittable.ts#L56){target=\\_blank}. This is a Polkadot.js type that represents a transaction that can be submitted to the blockchain.\n\n\n??? interface \"Example\"\n\n    ***Request***\n\n    ```ts\n    -import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://wss.api.moonbeam.network',\n  );\n  const assetsApi = new AssetTransferApi(api, specName, safeXcmVersion);\n\n  let callInfo;\n  try {\n    callInfo = await assetsApi.createTransferTransaction(\n      '2004',\n      '0xF977814e90dA44bFA03b6295A0616a897441aceC',\n      [],\n      ['1000000000000000000'],\n      {\n        format: 'call',\n        keepAlive: true,\n      },\n    );\n\n    console.log(`Call data:\\n${JSON.stringify(callInfo, null, 4)}`);\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n    ```\n\n    ***Response***\n\n    -<div id=\"termynal\" data-termynal>\n    <span data-ty>Call data:</span>\n    <span data-ty>{</span>\n    <span data-ty>    \"origin\": \"moonbeam\",</span>\n    <span data-ty>    \"dest\": \"moonbeam\",</span>\n    <span data-ty>    \"direction\": \"local\",</span>\n    <span data-ty>    \"xcmVersion\": null,</span>\n    <span data-ty>    \"method\": \"balances::transferKeepAlive\",</span>\n    <span data-ty>    \"format\": \"call\",</span>\n    <span data-ty>    \"tx\": \"0x0a03f977814e90da44bfa03b6295a0616a897441acec821a0600\"</span>\n    <span data-ty>}</span>\n<div>\n\n#### Claim Assets\n\nCreates a local XCM transaction to retrieve trapped assets. This function can be used to claim assets either locally on a system parachain, on the relay chain, or on any chain that supports the `claimAssets` runtime call.\n\n\n```ts\n-public async claimAssets<T extends Format>(\n\t\tassetIds: string[],\n\t\tamounts: string[],\n\t\tbeneficiary: string,\n\t\topts: TransferArgsOpts<T>,\n\t): Promise<TxResult<T>> {\n```\n\n??? interface \"Request parameters\"\n\n    `assetIds` ++\"string[]\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Array of asset IDs to be claimed from the `AssetTrap`.\n\n    ---\n\n    `amounts` ++\"string[]\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Array of amounts corresponding to each asset in `assetIds`.\n\n    ---\n\n    `beneficiary` ++\"string\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Address of the account to receive the trapped assets.\n\n    ---\n\n    `opts` ++\"TransferArgsOpts<T>\"++\n\n    -Options for customizing the claim assets transaction. These options allow you to specify the transaction format, fee payment details, weight limits, XCM versions, and more.\n\n??? child \"Show more\"\n\n    `format` ++\"T extends Format\"++ \n        \n    Specifies the format for returning a transaction.\n\n    ??? child \"Type `Format`\"\n\n        ```ts\n        -export type Format = 'payload' | 'call' | 'submittable';\n        ```\n\n    ---\n\n    `paysWithFeeOrigin` ++\"string\"++\n    \n    The Asset ID to pay fees on the current common good parachain. The defaults are as follows:\n\n    - **Polkadot Asset Hub**: `'DOT'`\n    - **Kusama Asset Hub**: `'KSM'`\n\n    ---\n\n    `paysWithFeeDest` ++\"string\"++\n    \n    Asset ID to pay fees on the destination parachain.\n\n    ---\n\n    `weightLimit` ++\"{ refTime?: string, proofSize?: string }\"++\n    \n    Custom weight limit option. If not provided, it will default to unlimited.\n\n    ---\n\n    `xcmVersion` ++\"number\"++\n    \n    Sets the XCM version for message construction. If this is not present a supported version will be queried, and if there is no supported version a safe version will be queried.\n\n    ---\n\n    `keepAlive` ++\"boolean\"++\n    \n    Enables `transferKeepAlive` for local asset transfers. For creating local asset transfers, if `true` this will allow for a `transferKeepAlive` as opposed to a `transfer`.\n\n    ---\n\n    `transferLiquidToken` ++\"boolean\"++\n    \n    Declares if this will transfer liquidity tokens. Default is `false`.\n\n    ---\n\n    `assetTransferType` ++\"string\"++\n    \n    The XCM transfer type used to transfer assets. The `AssetTransferType` type defines the possible values for this parameter.\n\n    ??? child \"Type `AssetTransferType`\"\n\n        ```ts\n        -export type AssetTransferType = LocalReserve | DestinationReserve | Teleport | RemoteReserve;\n        ```\n        \n        !!! note\n            To use the `assetTransferType` parameter, which is a string, you should use the `AssetTransferType` type as if each of its variants are strings. For example: `assetTransferType = 'LocalReserve'`.\n\n\n    ---\n\n    `remoteReserveAssetTransferTypeLocation` ++\"string\"++\n    \n    The remove reserve location for the XCM transfer. Should be provided when specifying an `assetTransferType` of `RemoteReserve`.\n\n    ---\n\n    `feesTransferType` ++\"string\"++\n    \n    XCM TransferType used to pay fees for XCM transfer. The `AssetTransferType` type defines the possible values for this parameter.\n\n    ??? child \"Type `AssetTransferType`\"\n\n        ```ts\n        -export type AssetTransferType = LocalReserve | DestinationReserve | Teleport | RemoteReserve;\n        ```\n        \n        !!! note\n            To use the `feesTransferType` parameter, which is a string, you should use the `AssetTransferType` type as if each of its variants are strings. For example: `feesTransferType = 'LocalReserve'`.\n\n    ---\n\n    `remoteReserveFeesTransferTypeLocation` ++\"string\"++\n    \n    The remote reserve location for the XCM transfer fees. Should be provided when specifying a `feesTransferType` of `RemoteReserve`.\n\n    ---\n\n    `customXcmOnDest` ++\"string\"++\n    \n    A custom XCM message to be executed on the destination chain. Should be provided if a custom XCM message is needed after transferring assets. Defaults to:\n\n    ```bash\n    Xcm(vec![DepositAsset { assets: Wild(AllCounted(assets.len())), beneficiary }])\n    ```\n\n\n??? interface \"Response parameters\"\n\n    ++\"Promise<TxResult<T>>\"++\n\n    -A promise containing the result of constructing the transaction.\n\n??? child \"Show more\"\n\n    `dest` ++\"string\"++\n\n    The destination `specName` of the transaction.\n\n    ---\n\n    `origin` ++\"string\"++\n\n    The origin `specName` of the transaction.\n\n    ---\n\n    `format` ++\"Format | 'local'\"++\n\n    The format type the transaction is outputted in.\n\n    ??? child \"Type `Format`\"\n\n        ```ts\n        -export type Format = 'payload' | 'call' | 'submittable';\n        ```\n\n    ---\n\n    `xcmVersion` ++\"number | null\"++\n\n    The XCM version that was used to construct the transaction.\n\n    ---\n\n    `direction` ++\"Direction | 'local'\"++\n\n    The direction of the cross-chain transfer.\n\n    ??? child \"Enum `Direction` values\"\n\n        `Local`\n\n        Local transaction.\n\n        ---\n\n        `SystemToPara`\n\n        System parachain to parachain.\n\n        ---\n\n        `SystemToRelay`\n\n        System paracahin to system relay chain.\n\n        ---\n\n        `SystemToSystem`\n\n        System parachain to System parachain chain.\n\n        ---\n\n        `SystemToBridge`\n\n        System parachain to an external `GlobalConsensus` chain.\n        \n        ---\n\n        `ParaToPara`\n\n        Parachain to Parachain.\n\n        ---\n\n        `ParaToRelay`\n\n        Parachain to Relay chain.\n\n        ---\n        \n        `ParaToSystem`\n\n        Parachain to System parachain.\n\n        ---\n\n        `RelayToSystem`\n\n        Relay to System Parachain.\n\n        ---\n\n        `RelayToPara`\n\n        Relay chain to Parachain.\n\n        ---\n\n        `RelayToBridge`\n\n        Relay chain to an external `GlobalConsensus` chain.\n\n    `method` ++\"Methods\"++\n\n    The method used in the transaction.\n\n    ??? child \"Type `Methods`\"\n\n        ```ts\n        -export type Methods =\n\t| LocalTransferTypes\n\t| 'transferAssets'\n\t| 'transferAssetsUsingTypeAndThen'\n\t| 'limitedReserveTransferAssets'\n\t| 'limitedTeleportAssets'\n\t| 'transferMultiasset'\n\t| 'transferMultiassets'\n\t| 'transferMultiassetWithFee'\n\t| 'claimAssets';\n        ```\n\n        ??? child \"Type `LocalTransferTypes`\"\n\n\n            ```ts\n            -export type LocalTransferTypes =\n\t| 'assets::transfer'\n\t| 'assets::transferKeepAlive'\n\t| 'assets::transferAll'\n\t| 'foreignAssets::transfer'\n\t| 'foreignAssets::transferKeepAlive'\n\t| 'foreignAssets::transferAll'\n\t| 'balances::transfer'\n\t| 'balances::transferKeepAlive'\n\t| 'balances::transferAll'\n\t| 'poolAssets::transfer'\n\t| 'poolAssets::transferKeepAlive'\n\t| 'poolAssets::transferAll'\n\t| 'tokens::transfer'\n\t| 'tokens::transferKeepAlive'\n\t| 'tokens::transferAll';\n            ```\n\n    ---\n\n    `tx` ++\"ConstructedFormat<T>\"++\n\n    The constructed transaction.\n\n    ??? child \"Type `ConstructedFormat<T>`\"\n\n        ```ts\n        -export type ConstructedFormat<T> = T extends 'payload'\n\t? GenericExtrinsicPayload\n\t: T extends 'call'\n\t\t? `0x${string}`\n\t\t: T extends 'submittable'\n\t\t\t? SubmittableExtrinsic<'promise', ISubmittableResult>\n\t\t\t: never;\n        ```\n\n        The `ConstructedFormat` type is a conditional type that returns a specific type based on the value of the TxResult `format` field.\n\n        - **Payload format**: If the format field is set to `'payload'`, the `ConstructedFormat` type will return a [`GenericExtrinsicPayload`](https://github.com/polkadot-js/api/blob/v15.8.1/packages/types/src/extrinsic/ExtrinsicPayload.ts#L87){target=\\_blank}.\n        - **Call format**: If the format field is set to `'call'`, the `ConstructedFormat` type will return a hexadecimal string (`0x${string}`). This is the encoded representation of the extrinsic call.\n        - **Submittable format**: If the format field is set to `'submittable'`, the `ConstructedFormat` type will return a [`SubmittableExtrinsic`](https://github.com/polkadot-js/api/blob/v15.8.1/packages/api-base/src/types/submittable.ts#L56){target=\\_blank}. This is a Polkadot.js type that represents a transaction that can be submitted to the blockchain.\n\n\n??? interface \"Example\"\n\n    ***Request***\n\n    ```ts\n    -import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://westend-rpc.polkadot.io',\n  );\n  const assetsApi = new AssetTransferApi(api, specName, safeXcmVersion);\n\n  let callInfo;\n  try {\n    callInfo = await assetsApi.claimAssets(\n      [\n        `{\"parents\":\"0\",\"interior\":{\"X2\":[{\"PalletInstance\":\"50\"},{\"GeneralIndex\":\"1984\"}]}}`,\n      ],\n      ['1000000000000'],\n      '0xf5d5714c084c112843aca74f8c498da06cc5a2d63153b825189baa51043b1f0b',\n      {\n        format: 'call',\n        xcmVersion: 2,\n      },\n    );\n\n    console.log(`Call data:\\n${JSON.stringify(callInfo, null, 4)}`);\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n    ```\n\n    ***Response***\n\n    -<div id=\"termynal\" data-termynal>\n    <span data-ty>Call data:</span>\n    <span data-ty>{</span>\n    <span data-ty>    \"origin\": \"0\",</span>\n    <span data-ty>    \"dest\": \"westend\",</span>\n    <span data-ty>    \"direction\": \"local\",</span>\n    <span data-ty>    \"xcmVersion\": 2,</span>\n    <span data-ty>    \"method\": \"claimAssets\",</span>\n    <span data-ty>    \"format\": \"call\",</span>\n    <span data-ty>    \"tx\": \"0x630c0104000002043205011f00070010a5d4e80100010100f5d5714c084c112843aca74f8c498da06cc5a2d63153b825189baa51043b1f0b\"</span>\n    <span data-ty>}</span>\n<div>\n\n\n#### Decode Extrinsic\n\nDecodes the hex of an extrinsic into a string readable format.\n\n```ts\n-public decodeExtrinsic<T extends Format>(encodedTransaction: string, format: T): string {\n```\n\n??? interface \"Request parameters\"\n\n    `encodedTransaction` ++\"string\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    A hex encoded extrinsic.\n\n    ---\n\n    `format` ++\"T extends Format\"++ <span class=\"required\" markdown>++\"required\"++</span>\n    \n    Specifies the format for returning a transaction.\n\n    ??? child \"Type `Format`\"\n\n        ```ts\n        -export type Format = 'payload' | 'call' | 'submittable';\n        ```\n\n??? interface \"Response parameters\"\n\n    ++\"string\"++\n\n    Decoded extrinsic in string readable format.\n\n??? interface \"Example\"\n\n    ***Request***\n\n    ```ts\n    -import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://wss.api.moonbeam.network',\n  );\n  const assetsApi = new AssetTransferApi(api, specName, safeXcmVersion);\n\n  const encodedExt = '0x0a03f977814e90da44bfa03b6295a0616a897441acec821a0600';\n\n  try {\n    const decodedExt = assetsApi.decodeExtrinsic(encodedExt, 'call');\n    console.log(\n      `Decoded tx:\\n ${JSON.stringify(JSON.parse(decodedExt), null, 4)}`,\n    );\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n    ```\n\n    ***Response***\n\n    -<div id='termynal' data-termynal>\n\t<span data-ty>Decoded tx:</span>\n\t<span data-ty> {</span>\n\t<span data-ty>    \"args\": {</span>\n\t<span data-ty>        \"dest\": \"0xF977814e90dA44bFA03b6295A0616a897441aceC\",</span>\n\t<span data-ty>        \"value\": \"100,000\"</span>\n\t<span data-ty>    },</span>\n\t<span data-ty>    \"method\": \"transferKeepAlive\",</span>\n\t<span data-ty>    \"section\": \"balances\"</span>\n\t<span data-ty>}</span>\n</div>\n\n#### Fetch Fee Info\n\nFetch estimated fee information for an extrinsic.\n\n```ts\n-public async fetchFeeInfo<T extends Format>(\n\t\ttx: ConstructedFormat<T>,\n\t\tformat: T,\n\t): Promise<RuntimeDispatchInfo | RuntimeDispatchInfoV1 | null> {\n```\n\n??? interface \"Request parameters\"\n\n    `tx` ++\"ConstructedFormat<T>\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    The constructed transaction.\n\n    ??? child \"Type `ConstructedFormat<T>`\"\n\n        ```ts\n        -export type ConstructedFormat<T> = T extends 'payload'\n\t? GenericExtrinsicPayload\n\t: T extends 'call'\n\t\t? `0x${string}`\n\t\t: T extends 'submittable'\n\t\t\t? SubmittableExtrinsic<'promise', ISubmittableResult>\n\t\t\t: never;\n        ```\n\n        The `ConstructedFormat` type is a conditional type that returns a specific type based on the value of the TxResult `format` field.\n\n        - **Payload format**: If the format field is set to `'payload'`, the `ConstructedFormat` type will return a [`GenericExtrinsicPayload`](https://github.com/polkadot-js/api/blob/v16.2.2/packages/types/src/extrinsic/ExtrinsicPayload.ts#L87){target=\\_blank}.\n        - **Call format**: If the format field is set to `'call'`, the `ConstructedFormat` type will return a hexadecimal string (`0x${string}`). This is the encoded representation of the extrinsic call.\n        - **Submittable format**: If the format field is set to `'submittable'`, the `ConstructedFormat` type will return a [`SubmittableExtrinsic`](https://github.com/polkadot-js/api/blob/v16.2.2/packages/api-base/src/types/submittable.ts#L56){target=\\_blank}. This is a Polkadot.js type that represents a transaction that can be submitted to the blockchain.\n\n    ---\n\n    `format` ++\"T extends Format\"++ <span class=\"required\" markdown>++\"required\"++</span>\n\n    Specifies the format for returning a transaction.\n\n    ??? child \"Type `Format`\"\n\n        ```ts\n        -export type Format = 'payload' | 'call' | 'submittable';\n        ```\n\n??? interface \"Response parameters\"\n\n    ++\"Promise<RuntimeDispatchInfo | RuntimeDispatchInfoV1 | null>\"++\n\n    A promise containing the estimated fee information for the provided extrinsic.\n\n    ??? child \"Type `RuntimeDispatchInfo`\"\n\n        ```ts\n        export interface RuntimeDispatchInfo extends Struct {\n          readonly weight: Weight;\n          readonly class: DispatchClass;\n          readonly partialFee: Balance;\n        }\n        ```\n\n        For more information on the underlying types and fields of `RuntimeDispatchInfo`, check the [`RuntimeDispatchInfo`](https://github.com/polkadot-js/api/blob/v16.2.2/packages/types/src/interfaces/payment/types.ts#L21){target=\\_blank} source code.\n\n    ??? child \"Type `RuntimeDispatchInfoV1`\"\n\n        ```ts\n        export interface RuntimeDispatchInfoV1 extends Struct {\n          readonly weight: WeightV1;\n          readonly class: DispatchClass;\n          readonly partialFee: Balance;\n        }\n        ```\n\n        For more information on the underlying types and fields of `RuntimeDispatchInfoV1`, check the [`RuntimeDispatchInfoV1`](https://github.com/polkadot-js/api/blob/v16.2.2/packages/types/src/interfaces/payment/types.ts#L28){target=\\_blank} source code.\n\n??? interface \"Example\"\n\n    ***Request***\n\n    ```ts\n    -import {\n  AssetTransferApi,\n  constructApiPromise,\n} from '@substrate/asset-transfer-api';\n\nasync function main() {\n  const { api, specName, safeXcmVersion } = await constructApiPromise(\n    'wss://wss.api.moonbeam.network',\n  );\n  const assetsApi = new AssetTransferApi(api, specName, safeXcmVersion);\n\n  const encodedExt = '0x0a03f977814e90da44bfa03b6295a0616a897441acec821a0600';\n\n  try {\n    const decodedExt = await assetsApi.fetchFeeInfo(encodedExt, 'call');\n    console.log(`Fee info:\\n${JSON.stringify(decodedExt, null, 4)}`);\n  } catch (e) {\n    console.error(e);\n    throw Error(e as string);\n  }\n}\n\nmain()\n  .catch((err) => console.error(err))\n  .finally(() => process.exit());\n\n    ```\n\n    ***Response***\n\n    -<div id='termynal' data-termynal>\n    <span data-ty>Fee info:</span>\n    <span data-ty>{</span>\n    <span data-ty>    \"weight\": {</span>\n    <span data-ty>        \"refTime\": 163777000,</span>\n    <span data-ty>        \"proofSize\": 3581</span>\n    <span data-ty>    },</span>\n    <span data-ty>    \"class\": \"Normal\",</span>\n    <span data-ty>    \"partialFee\": 0</span>\n    <span data-ty>}</span>\n</div>"}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 48, "end_char": 783, "estimated_token_count": 173, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis guide will walk you through the process of teleporting tokens from the Asset Hub to the Bridge Hub system parachain using the [ParaSpell XCM SDK](https://paraspell.github.io/docs/){target=\\_blank}.\n\nFor development purposes, this guide will use the [Paseo TestNet](/develop/networks/#paseo){target=\\_blank}, so the teleport will be from Paseo's Asset Hub to Paseo's Bridge Hub.\n\nYou’ll learn how to:\n\n- Build a teleport transaction.\n- Perform a dry run to validate it.\n- Verify the [Existential Deposit (ED)](/polkadot-protocol/glossary/#existential-deposit){target=\\_blank} requirement on the destination chain.\n- Retrieve information regarding the transfer, along with fee estimates.\n- Submit the transaction."}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 1, "depth": 3, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 783, "end_char": 950, "estimated_token_count": 37, "token_estimator": "heuristic-v1", "text": "### Prerequisites\n\n- Basic familiarity with JavaScript/TypeScript\n- Knowledge of the [fundamentals of Polkadot](/polkadot-protocol/parachain-basics/){target=\\_blank}"}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 2, "depth": 2, "title": "Initialize Your Project", "anchor": "initialize-your-project", "start_char": 950, "end_char": 2614, "estimated_token_count": 367, "token_estimator": "heuristic-v1", "text": "## Initialize Your Project\n\nCreate the project folder:\n\n```bash\nmkdir paraspell-teleport\ncd paraspell-teleport\n```\n\nInitialize the JavaScript project:\n\n```bash\nbun init -y\n```\n\nInstall the required dependencies:\n\n```bash\nbun add @paraspell/sdk polkadot-api @polkadot-labs/hdkd-helpers @polkadot-labs/hdkd\n```\n\nNow add the following setup code to `index.ts`:\n\n```ts title=\"index.ts\"\n-import { Builder, hasDryRunSupport } from '@paraspell/sdk';\nimport {\n  entropyToMiniSecret,\n  mnemonicToEntropy,\n  ss58Address,\n} from '@polkadot-labs/hdkd-helpers';\nimport { getPolkadotSigner } from 'polkadot-api/signer';\nimport { sr25519CreateDerive } from '@polkadot-labs/hdkd';\nimport { inspect } from 'util';\n\n// DOT/PAS has 10 decimals\nconst PAS_UNITS = 10_000_000_000n;\n\nconst SEED_PHRASE =\n  'INSERT_YOUR_SEED_PHRASE';\n\n// Create Sr25519 signer from mnemonic\nfunction getSigner() {\n  const entropy = mnemonicToEntropy(SEED_PHRASE);\n  const miniSecret = entropyToMiniSecret(entropy);\n  const derive = sr25519CreateDerive(miniSecret);\n  const keyPair = derive('');\n  return getPolkadotSigner(keyPair.publicKey, 'Sr25519', keyPair.sign);\n}\n\nconst RECIPIENT_ADDRESS = ss58Address(getSigner().publicKey);\nconst SENDER_ADDRESS = ss58Address(getSigner().publicKey);\n```\n\nReplace the `INSERT_YOUR_SEED_PHRASE ` with the seed phrase from your Polkadot development account.\n\nBe sure to fund this account with some PAS tokens on Passeo's Asset Hub using the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=1000){target=\\_blank}.\n\n!!!note \"Security Warning\"\n    Never commit your mnemonic phrase in production code. Use environment variables or secure key management systems."}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 3, "depth": 2, "title": "Build a Teleport Transaction", "anchor": "build-a-teleport-transaction", "start_char": 2614, "end_char": 3504, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "## Build a Teleport Transaction\n\nThe next step is to build the transaction that you intend to execute.\n\nIn this example, you will teleport 10 PAS tokens from Paseo's Asset Hub to Paseo's Bridge Hub system parachain.\n\nAdd the ParaSpell transaction code to your `index.ts` file:\n\n```ts title=\"index.ts\"\n-async function teleport() {\n  const signer = getSigner();\n\n  const tx = await Builder()\n    .from('AssetHubPaseo')\n    .to('BridgeHubPaseo')\n    .currency({\n      symbol: 'PAS',\n      amount: 10n * PAS_UNITS, // 10 PAS\n    })\n    .address(RECIPIENT_ADDRESS)\n    .build();\n\n  console.log('Built transaction:', inspect(tx, { colors: true, depth: null }));\n\n  const result = await tx.signAndSubmit(signer);\n  console.log(inspect(result, { colors: true, depth: null }));\n}\n```\n\nDo not execute it just yet. You will perform a dry run of this transaction first to ensure it works as expected."}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 4, "depth": 2, "title": "Perform a Dry Run", "anchor": "perform-a-dry-run", "start_char": 3504, "end_char": 7513, "estimated_token_count": 731, "token_estimator": "heuristic-v1", "text": "## Perform a Dry Run\n\nDry runs simulate the transaction without broadcasting it, allowing you to confirm success in advance.\n\nAdd the following dry run code to your `index.ts` script:\n\n```ts title=\"index.ts\"\n-async function dryRunTeleport() {\n  if (!hasDryRunSupport('AssetHubPaseo')) {\n    console.log('Dry run is not supported on AssetHubPaseo.');\n    return;\n  }\n\n  const tx = await Builder()\n    .from('AssetHubPaseo')\n    .to('BridgeHubPaseo')\n    .currency({\n      symbol: 'PAS',\n      amount: 10n * PAS_UNITS,\n    })\n    .address(RECIPIENT_ADDRESS)\n    .senderAddress(SENDER_ADDRESS)\n    .dryRun();\n\n  console.log(inspect(tx, { colors: true, depth: null }));\n}\n\ndryRunTeleport();\n```\nGo ahead and run the script.\n\n```bash\nbun run index.ts\n```\n\nThe result of the dry run will be similar to this:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>bun run index.ts</span>\n  <span data-ty>{\n  failureReason: undefined,\n  failureChain: undefined,\n  origin: {\n    success: true,\n    fee: 17965000n,\n    weight: undefined,\n    forwardedXcms: [\n      {\n        type: 'V3',\n        value: {\n          parents: 1,\n          interior: { type: 'X1', value: { type: 'Parachain', value: 1002 } }\n        }\n      },\n      [\n        {\n          type: 'V3',\n          value: [\n            {\n              type: 'ReceiveTeleportedAsset',\n              value: [\n                {\n                  id: {\n                    type: 'Concrete',\n                    value: {\n                      parents: 1,\n                      interior: { type: 'Here', value: undefined }\n                    }\n                  },\n                  fun: { type: 'Fungible', value: 100000000000n }\n                }\n              ]\n            },\n            { type: 'ClearOrigin', value: undefined },\n            {\n              type: 'BuyExecution',\n              value: {\n                fees: {\n                  id: {\n                    type: 'Concrete',\n                    value: {\n                      parents: 1,\n                      interior: { type: 'Here', value: undefined }\n                    }\n                  },\n                  fun: { type: 'Fungible', value: 100000000000n }\n                },\n                weight_limit: { type: 'Unlimited', value: undefined }\n              }\n            },\n            {\n              type: 'DepositAsset',\n              value: {\n                assets: {\n                  type: 'Wild',\n                  value: { type: 'AllCounted', value: 1 }\n                },\n                beneficiary: {\n                  parents: 0,\n                  interior: {\n                    type: 'X1',\n                    value: {\n                      type: 'AccountId32',\n                      value: {\n                        network: undefined,\n                        id: FixedSizeBinary {\n                          asText: [Function (anonymous)],\n                          asHex: [Function (anonymous)],\n                          asOpaqueHex: [Function (anonymous)],\n                          asBytes: [Function (anonymous)],\n                          asOpaqueBytes: [Function (anonymous)]\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            },\n            {\n              type: 'SetTopic',\n              value: FixedSizeBinary {\n                asText: [Function (anonymous)],\n                asHex: [Function (anonymous)],\n                asOpaqueHex: [Function (anonymous)],\n                asBytes: [Function (anonymous)],\n                asOpaqueBytes: [Function (anonymous)]\n              }\n            }\n          ]\n        }\n      ]\n    ],\n    destParaId: 1002,\n    currency: 'PAS'\n  },\n  assetHub: undefined,\n  bridgeHub: undefined,\n  destination: {\n    success: true,\n    fee: 17965000n,\n    weight: { refTime: 164770000n, proofSize: 3593n },\n    forwardedXcms: [],\n    destParaId: undefined,\n    currency: 'PAS'\n  },\n  hops: []\n}</span>\n</div>"}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 5, "depth": 2, "title": "Verify the Existential Deposit", "anchor": "verify-the-existential-deposit", "start_char": 7513, "end_char": 8554, "estimated_token_count": 291, "token_estimator": "heuristic-v1", "text": "## Verify the Existential Deposit\n\nCheck if the recipient account meets the [Existential Deposit (ED)](/polkadot-protocol/glossary/#existential-deposit){target=\\_blank} requirement before sending by using [`verifyEdOnDestination`](https://paraspell.github.io/docs/sdk/xcmUtils.html#verify-ed-on-destination){target=\\_blank}:\n\n```ts title=\"index.ts\"\n-async function verifyED() {\n  const isValid = await Builder()\n    .from('AssetHubPaseo')\n    .to('BridgeHubPaseo')\n    .currency({\n      symbol: 'PAS',\n      amount: 10n * PAS_UNITS,\n    })\n    .address(RECIPIENT_ADDRESS)\n    .senderAddress(SENDER_ADDRESS)\n    .verifyEdOnDestination();\n\n  console.log(`ED verification ${isValid ? 'successful' : 'failed'}.`);\n}\n\nverifyED();\n```\nExecute the code by running:\n\n```bash\nbun run index.ts\n```\n\nAfter that, you will get output confirming the ED:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>bun run index.ts</span>\n  <span data-ty>...</span>\n  <span data-ty>ED verification successful.</span>\n</div>"}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 6, "depth": 2, "title": "Get Transfer Info and Fee Estimates", "anchor": "get-transfer-info-and-fee-estimates", "start_char": 8554, "end_char": 20704, "estimated_token_count": 2302, "token_estimator": "heuristic-v1", "text": "## Get Transfer Info and Fee Estimates\n\nBefore sending an XCM transaction, it is helpful to estimate the fees associated with executing and delivering the cross-chain message.\n\nParaSpell has a helpful function for this: [`getTransferInfo()`](https://paraspell.github.io/docs/sdk/xcmUtils.html#xcm-transfer-info){target=\\_blank}. This function returns an estimate of the associated XCM fees, along with the account's balance before and after the fees are paid.\n\n```ts title=\"index.ts\"\n-async function XcmTransferInfo() {\n  const info = await Builder()\n    .from('AssetHubPaseo')\n    .to('BridgeHubPaseo')\n    .currency({\n      symbol: 'PAS',\n      amount: 10n * PAS_UNITS,\n    })\n    .address(RECIPIENT_ADDRESS)\n    .senderAddress(SENDER_ADDRESS)\n    .getTransferInfo();\n\n  console.log('Transfer Info:', info);\n}\n\nXcmTransferInfo();\n```\n\nGo ahead and execute the script:\n\n```bash\nbun run index.ts\n```\n\nYou should be able to see all the information for your transfer:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>bun run index.ts</span>\n  <span data-ty>...</span>\n  <span data-ty>Transfer Info: {\n  chain: {\n    origin: 'AssetHubPaseo',\n    destination: 'BridgeHubPaseo',\n    ecosystem: 'PAS'\n  },\n  origin: {\n    selectedCurrency: {\n      sufficient: true,\n      balance: 9899002813408n,\n      balanceAfter: 9799002813408n,\n      currencySymbol: 'PAS',\n      existentialDeposit: 100000000n\n    },\n    xcmFee: {\n      sufficient: true,\n      fee: 17965000n,\n      balance: 9899002813408n,\n      balanceAfter: 9898984848408n,\n      currencySymbol: 'PAS'\n    }\n  },\n  assetHub: undefined,\n  bridgeHub: undefined,\n  hops: [],\n  destination: {\n    receivedCurrency: {\n      sufficient: true,\n      receivedAmount: 99982035000n,\n      balance: 0n,\n      balanceAfter: 99982035000n,\n      currencySymbol: 'PAS',\n      existentialDeposit: 1000000000n\n    },\n    xcmFee: {\n      fee: 17965000n,\n      balance: 0n,\n      balanceAfter: 99982035000n,\n      currencySymbol: 'PAS'\n    }\n  }\n}</span>\n</div>\n\nNow that you have:\n\n- Completed a successful dry run of the transaction\n- Verified the existential deposit on the recipient account\n- Obtained an estimate of the associated XCM fees\n\nNow you can execute the teleport function by adding the following statement:\n\nAdd the following code:\n\n```typescript title=\"index.ts\"\n-teleport();\n```\n\nAnd execute your teleport:\n\n```bash\nbun run index.ts\n```\n\nYour `teleport` function will submit the transaction, and you will get the following output:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>bun run index.ts</span>\n  <span data-ty>...</span>\n  <span data-ty>Built transaction: {\n  getPaymentInfo: [AsyncFunction: getPaymentInfo],\n  getEstimatedFees: [AsyncFunction: getEstimatedFees],\n  decodedCall: {\n    type: 'PolkadotXcm',\n    value: {\n      type: 'limited_teleport_assets',\n      value: {\n        dest: {\n          type: 'V5',\n          value: {\n            parents: 1,\n            interior: { type: 'X1', value: { type: 'Parachain', value: 1002 } }\n          }\n        },\n        beneficiary: {\n          type: 'V5',\n          value: {\n            parents: 0,\n            interior: {\n              type: 'X1',\n              value: {\n                type: 'AccountId32',\n                value: {\n                  network: undefined,\n                  id: FixedSizeBinary {\n                    asText: [Function (anonymous)],\n                    asHex: [Function (anonymous)],\n                    asOpaqueHex: [Function (anonymous)],\n                    asBytes: [Function (anonymous)],\n                    asOpaqueBytes: [Function (anonymous)]\n                  }\n                }\n              }\n            }\n          }\n        },\n        assets: {\n          type: 'V5',\n          value: [\n            {\n              id: { parents: 1, interior: { type: 'Here', value: null } },\n              fun: { type: 'Fungible', value: 100000000000n }\n            }\n          ]\n        },\n        fee_asset_item: 0,\n        weight_limit: { type: 'Unlimited' }\n      }\n    }\n  },\n  getEncodedData: [Function: getEncodedData],\n  sign: [Function: sign],\n  signSubmitAndWatch: [Function: signSubmitAndWatch],\n  signAndSubmit: [Function: signAndSubmit]\n}</span>\n</div>\n\nOnce the transaction is successfully included in a block, you will see the recipient's account balance updated, and you will receive output similar to the one below.\n\n???- code \"Successful Transaction Submission\"\n    This output will be returned once the transaction has been successfully included in a block.\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty>...</span>\n  <span data-ty>{\n  txHash: '0x6fbecc0b284adcff46ab39872659c2567395c865adef5f8cbea72f25b6042609',\n  block: {\n    index: 2,\n    number: 2524809,\n    hash: '0xa39a96d5921402c6e8f67e48b8395d6b21382c72d4d30f8497a0e9f890bc0d4c'\n  },\n  ok: true,\n  events: [\n    {\n      type: 'Balances',\n      value: {\n        type: 'Withdraw',\n        value: {\n          who: '15DMtB5BDCJqw4uZtByTWXGqViAVx7XjRsxWbTH5tfrHLe8j',\n          amount: 15668864n\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'Balances',\n      value: {\n        type: 'Burned',\n        value: {\n          who: '15DMtB5BDCJqw4uZtByTWXGqViAVx7XjRsxWbTH5tfrHLe8j',\n          amount: 100000000000n\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'PolkadotXcm',\n      value: {\n        type: 'Attempted',\n        value: {\n          outcome: {\n            type: 'Complete',\n            value: { used: { ref_time: 190990000n, proof_size: 3593n } }\n          }\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'Balances',\n      value: {\n        type: 'Burned',\n        value: {\n          who: '15DMtB5BDCJqw4uZtByTWXGqViAVx7XjRsxWbTH5tfrHLe8j',\n          amount: 304850000n\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'Balances',\n      value: {\n        type: 'Minted',\n        value: {\n          who: '14xmwinmCEz6oRrFdczHKqHgWNMiCysE2KrA4jXXAAM1Eogk',\n          amount: 304850000n\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'PolkadotXcm',\n      value: {\n        type: 'FeesPaid',\n        value: {\n          paying: {\n            parents: 0,\n            interior: {\n              type: 'X1',\n              value: {\n                type: 'AccountId32',\n                value: {\n                  network: { type: 'Polkadot', value: undefined },\n                  id: FixedSizeBinary {\n                    asText: [Function (anonymous)],\n                    asHex: [Function (anonymous)],\n                    asOpaqueHex: [Function (anonymous)],\n                    asBytes: [Function (anonymous)],\n                    asOpaqueBytes: [Function (anonymous)]\n                  }\n                }\n              }\n            }\n          },\n          fees: [\n            {\n              id: {\n                parents: 1,\n                interior: { type: 'Here', value: undefined }\n              },\n              fun: { type: 'Fungible', value: 304850000n }\n            }\n          ]\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'XcmpQueue',\n      value: {\n        type: 'XcmpMessageSent',\n        value: {\n          message_hash: FixedSizeBinary {\n            asText: [Function (anonymous)],\n            asHex: [Function (anonymous)],\n            asOpaqueHex: [Function (anonymous)],\n            asBytes: [Function (anonymous)],\n            asOpaqueBytes: [Function (anonymous)]\n          }\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'PolkadotXcm',\n      value: {\n        type: 'Sent',\n        value: {\n          origin: {\n            parents: 0,\n            interior: {\n              type: 'X1',\n              value: {\n                type: 'AccountId32',\n                value: {\n                  network: { type: 'Polkadot', value: undefined },\n                  id: FixedSizeBinary {\n                    asText: [Function (anonymous)],\n                    asHex: [Function (anonymous)],\n                    asOpaqueHex: [Function (anonymous)],\n                    asBytes: [Function (anonymous)],\n                    asOpaqueBytes: [Function (anonymous)]\n                  }\n                }\n              }\n            }\n          },\n          destination: {\n            parents: 1,\n            interior: { type: 'X1', value: { type: 'Parachain', value: 1002 } }\n          },\n          message: [\n            {\n              type: 'ReceiveTeleportedAsset',\n              value: [\n                {\n                  id: {\n                    parents: 1,\n                    interior: { type: 'Here', value: undefined }\n                  },\n                  fun: { type: 'Fungible', value: 100000000000n }\n                }\n              ]\n            },\n            { type: 'ClearOrigin', value: undefined },\n            {\n              type: 'BuyExecution',\n              value: {\n                fees: {\n                  id: {\n                    parents: 1,\n                    interior: { type: 'Here', value: undefined }\n                  },\n                  fun: { type: 'Fungible', value: 100000000000n }\n                },\n                weight_limit: { type: 'Unlimited', value: undefined }\n              }\n            },\n            {\n              type: 'DepositAsset',\n              value: {\n                assets: {\n                  type: 'Wild',\n                  value: { type: 'AllCounted', value: 1 }\n                },\n                beneficiary: {\n                  parents: 0,\n                  interior: {\n                    type: 'X1',\n                    value: {\n                      type: 'AccountId32',\n                      value: {\n                        network: undefined,\n                        id: FixedSizeBinary {\n                          asText: [Function (anonymous)],\n                          asHex: [Function (anonymous)],\n                          asOpaqueHex: [Function (anonymous)],\n                          asBytes: [Function (anonymous)],\n                          asOpaqueBytes: [Function (anonymous)]\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          ],\n          message_id: FixedSizeBinary {\n            asText: [Function (anonymous)],\n            asHex: [Function (anonymous)],\n            asOpaqueHex: [Function (anonymous)],\n            asBytes: [Function (anonymous)],\n            asOpaqueBytes: [Function (anonymous)]\n          }\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'Balances',\n      value: {\n        type: 'Deposit',\n        value: {\n          who: '13UVJyLgBASGhE2ok3TvxUfaQBGUt88JCcdYjHvUhvQkFTTx',\n          amount: 15668864n\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'TransactionPayment',\n      value: {\n        type: 'TransactionFeePaid',\n        value: {\n          who: '15DMtB5BDCJqw4uZtByTWXGqViAVx7XjRsxWbTH5tfrHLe8j',\n          actual_fee: 15668864n,\n          tip: 0n\n        }\n      },\n      topics: []\n    },\n    {\n      type: 'System',\n      value: {\n        type: 'ExtrinsicSuccess',\n        value: {\n          dispatch_info: {\n            weight: { ref_time: 952851000n, proof_size: 13382n },\n            class: { type: 'Normal', value: undefined },\n            pays_fee: { type: 'Yes', value: undefined }\n          }\n        }\n      },\n      topics: []\n    }\n  ]\n}</span>\n</div>\n\nAfter executing the teleport, check the account balance on [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fsys.turboflakes.io%2Fasset-hub-paseo){target=\\_blank} for [Paseo's Asset Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fsys.turboflakes.io%2Fasset-hub-paseo#/accounts){target=\\_blank} and [Paseo's Bridge Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fbridge-hub-paseo.dotters.network#/accounts){target=\\_blank}.\n\nYou should see:\n\n- The recipient account now has 10 more PAS tokens.\n- The sender account has the transfer amount (10 PAS) + the fees amount debited from their account balance.\n\nYou have now successfully created and sent a cross-chain transfer using the ParaSpell XCM SDK!"}
{"page_id": "develop-toolkit-interoperability-paraspell-xcm-sdk-teleport-from-asset-hub-to-bridge-hub", "index": 7, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 20704, "end_char": 21173, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\n- Explore other transfers: \n    - Try a parachain-to-parachain transfer or a transfer from a parachain back to the Relay chain.\n\n- Read the Docs: Dive deeper into the features of the [ParaSpell XCM SDK](https://paraspell.github.io/docs/sdk/getting-started.html){target=\\_blank} documentation.\n\n- Learn about XCM: Understand the underlying protocol by visiting the [Introduction to XCM page](/develop/interoperability/intro-to-xcm/) in the Polkadot Docs."}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 787, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAs described in the [Interoperability](/develop/interoperability){target=\\_blank} section, XCM (Cross-Consensus Messaging) is a protocol used in the Polkadot and Kusama ecosystems to enable communication and interaction between chains. It facilitates cross-chain communication, allowing assets, data, and messages to flow seamlessly across the ecosystem.\n\nAs XCM is central to enabling communication between blockchains, developers need robust tools to help interact with, build, and test XCM messages. Several XCM tools simplify working with the protocol by providing libraries, frameworks, and utilities that enhance the development process, ensuring that applications built within the Polkadot ecosystem can efficiently use cross-chain functionalities."}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 1, "depth": 2, "title": "Popular XCM Tools", "anchor": "popular-xcm-tools", "start_char": 787, "end_char": 809, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Popular XCM Tools"}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 2, "depth": 3, "title": "Moonsong Labs XCM Tools", "anchor": "moonsong-labs-xcm-tools", "start_char": 809, "end_char": 2190, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "### Moonsong Labs XCM Tools\n\n[Moonsong Labs XCM Tools](https://github.com/Moonsong-Labs/xcm-tools){target=\\_blank} provides a collection of scripts for managing and testing XCM operations between Polkadot SDK-based runtimes. These tools allow performing tasks like asset registration, channel setup, and XCM initialization. Key features include:\n\n- **Asset registration**: Registers assets, setting units per second (up-front fees), and configuring error (revert) codes.\n- **XCM initializer**: Initializes XCM, sets default XCM versions, and configures revert codes for XCM-related precompiles.\n- **HRMP manipulator**: Manages HRMP channel actions, including opening, accepting, or closing channels.\n- **XCM-Transactor-Info-Setter**: Configures transactor information, including extra weight and fee settings.\n- **Decode XCM**: Decodes XCM messages on the relay chain or parachains to help interpret cross-chain communication.\n\nTo get started, clone the repository and install the required dependencies:\n\n```bash\ngit clone https://github.com/Moonsong-Labs/xcm-tools && \ncd xcm-tools &&\nyarn install\n```\n\nFor a full overview of each script, visit the [scripts](https://github.com/Moonsong-Labs/xcm-tools/tree/main/scripts){target=\\_blank} directory or refer to the [official documentation](https://github.com/Moonsong-Labs/xcm-tools/blob/main/README.md){target=\\_blank} on GitHub."}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 3, "depth": 3, "title": "ParaSpell", "anchor": "paraspell", "start_char": 2190, "end_char": 4045, "estimated_token_count": 409, "token_estimator": "heuristic-v1", "text": "### ParaSpell\n\n[ParaSpell](https://paraspell.xyz/){target=\\_blank} is a collection of open-source XCM tools designed to streamline cross-chain asset transfers and interactions within the Polkadot and Kusama ecosystems. It equips developers with an intuitive interface to manage and optimize XCM-based functionalities. Some key points included by ParaSpell are:\n\n- **[XCM SDK](https://paraspell.xyz/#xcm-sdk){target=\\_blank}**: Provides a unified layer to incorporate XCM into decentralized applications, simplifying complex cross-chain interactions.\n- **[XCM API](https://paraspell.xyz/#xcm-api){target=\\_blank}**: Offers an efficient, package-free approach to integrating XCM functionality while offloading heavy computing tasks, minimizing costs and improving application performance.\n- **[XCM router](https://paraspell.xyz/#xcm-router){target=\\_blank}**: Enables cross-chain asset swaps in a single command, allowing developers to send one asset type (such as DOT on Polkadot) and receive a different asset on another chain (like ASTR on Astar).\n- **[XCM analyser](https://paraspell.xyz/#xcm-analyser){target=\\_blank}**: Decodes and translates complex XCM multilocation data into readable information, supporting easier troubleshooting and debugging.\n- **[XCM visualizator](https://paraspell.xyz/#xcm-visualizator){target=\\_blank}**: A tool designed to give developers a clear, interactive view of XCM activity across the Polkadot ecosystem, providing insights into cross-chain communication flow.\n\nParaSpell's tools make it simple for developers to build, test, and deploy cross-chain solutions without needing extensive knowledge of the XCM protocol. With features like message composition, decoding, and practical utility functions for parachain interactions, ParaSpell is especially useful for debugging and optimizing cross-chain communications."}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 4, "depth": 3, "title": "Astar XCM Tools", "anchor": "astar-xcm-tools", "start_char": 4045, "end_char": 5585, "estimated_token_count": 369, "token_estimator": "heuristic-v1", "text": "### Astar XCM Tools\n\nThe [Astar parachain](https://github.com/AstarNetwork/Astar/tree/master){target=\\_blank} offers a crate with a set of utilities for interacting with the XCM protocol. The [xcm-tools](https://github.com/AstarNetwork/Astar/tree/master/bin/xcm-tools){target=\\_blank} crate provides a straightforward method for users to locate a sovereign account or calculate an XC20 asset ID. Some commands included by the xcm-tools crate allow users to perform the following tasks:\n\n- **Sovereign accounts**: Obtain the sovereign account address for any parachain, either on the Relay Chain or for sibling parachains, using a simple command.\n- **XC20 EVM addresses**: Generate XC20-compatible Ethereum addresses for assets by entering the asset ID, making it easy to integrate assets across Ethereum-compatible environments.\n- **Remote accounts**: Retrieve remote account addresses needed for multi-location compatibility, using flexible options to specify account types and parachain IDs.\n\nTo start using these tools, clone the [Astar repository](https://github.com/AstarNetwork/Astar){target=\\_blank} and compile the xcm-tools package:\n\n```bash\ngit clone https://github.com/AstarNetwork/Astar &&\ncd Astar &&\ncargo build --release -p xcm-tools\n```\n\nAfter compiling, verify the setup with the following command:\n\n```bash\n./target/release/xcm-tools --help\n```\nFor more details on using Astar xcm-tools, consult the [official documentation](https://docs.astar.network/docs/learn/interoperability/xcm/integration/tools/){target=\\_blank}."}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 5, "depth": 3, "title": "Chopsticks", "anchor": "chopsticks", "start_char": 5585, "end_char": 5895, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "### Chopsticks\n\nThe Chopsticks library provides XCM functionality for testing XCM messages across networks, enabling you to fork multiple parachains along with a relay chain. For further details, see the [Chopsticks documentation](/tutorials/polkadot-sdk/testing/fork-live-chains/){target=\\_blank} about XCM."}
{"page_id": "develop-toolkit-interoperability-xcm-tools", "index": 6, "depth": 3, "title": "Moonbeam XCM SDK", "anchor": "moonbeam-xcm-sdk", "start_char": 5895, "end_char": 7524, "estimated_token_count": 385, "token_estimator": "heuristic-v1", "text": "### Moonbeam XCM SDK\n\nThe [Moonbeam XCM SDK](https://github.com/moonbeam-foundation/xcm-sdk){target=\\_blank} enables developers to easily transfer assets between chains, either between parachains or between a parachain and the relay chain, within the Polkadot/Kusama ecosystem. With the SDK, you don't need to worry about determining the [Multilocation](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#7-universal-consensus-location-identifiers){target=\\_blank} of the origin or destination assets or which extrinsics are used on which networks.\n\nThe SDK consists of two main packages:\n\n- **[XCM SDK](https://github.com/moonbeam-foundation/xcm-sdk/tree/main/packages/sdk){target=\\_blank}**: Core SDK for executing XCM transfers between chains in the Polkadot/Kusama ecosystem.\n- **[MRL SDK](https://github.com/moonbeam-foundation/xcm-sdk/tree/main/packages/mrl){target=\\_blank}**: Extension of the XCM SDK for transferring liquidity into and across the Polkadot ecosystem from other ecosystems like Ethereum.\n\nKey features include:\n\n- **Simplified asset transfers**: Abstracts away complex multilocation determinations and extrinsic selection.\n- **Cross-ecosystem support**: Enables transfers between Polkadot/Kusama chains and external ecosystems.\n- **Developer-friendly API**: Provides intuitive interfaces for cross-chain functionality.\n- **Comprehensive documentation**: Includes usage guides and API references for both packages.\n\nFor detailed usage examples and API documentation, visit the [official Moonbeam XCM SDK documentation](https://moonbeam-foundation.github.io/xcm-sdk/latest/){target=\\_blank}."}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 29, "end_char": 786, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nMoonwall is an end-to-end testing framework designed explicitly for Polkadot SDK-based blockchain networks. It addresses one of the most significant challenges in blockchain development: managing complex test environments and network configurations.\n\nMoonwall consolidates this complexity by providing the following:\n\n- A centralized configuration management system that explicitly defines all network parameters.\n- A standardized approach to environment setup across different Substrate-based chains.\n- Built-in utilities for common testing scenarios and network interactions.\n\nDevelopers can focus on writing meaningful tests rather than managing infrastructure complexities or searching through documentation for configuration options."}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 786, "end_char": 1110, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- [Node.js](https://nodejs.org/en/){target=\\_blank} (version 20.10 or higher).\n- A package manager such as [npm](https://www.npmjs.com/){target=\\_blank}, [yarn](https://yarnpkg.com/){target=\\_blank}, or [pnpm](https://pnpm.io/){target=\\_blank}."}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 2, "depth": 2, "title": "Install Moonwall", "anchor": "install-moonwall", "start_char": 1110, "end_char": 1450, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## Install Moonwall\n\nMoonwall can be installed globally for system-wide access or locally within specific projects. This section covers both installation methods.\n\n!!! tip\n    This documentation corresponds to Moonwall version `5.13.5`. To avoid compatibility issues with the documented features, ensure you're using the matching version."}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 3, "depth": 3, "title": "Global Installation", "anchor": "global-installation", "start_char": 1450, "end_char": 1955, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Global Installation\n\nGlobal installation provides system-wide access to the Moonwall CLI, making it ideal for developers working across multiple blockchain projects. Install it by running one of the following commands:\n\n=== \"npm\"\n\n    ```bash\n    npm install -g @moonwall/cli@5.13.5\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm -g install @moonwall/cli@5.13.5\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn global add @moonwall/cli@5.13.5\n    ```\n\nNow, you can run the `moonwall` command from your terminal."}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 4, "depth": 3, "title": "Local Installation", "anchor": "local-installation", "start_char": 1955, "end_char": 2448, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "### Local Installation\n\nLocal installation is recommended for better dependency management and version control within a specific project. First, initialize your project:\n\n```bash\nmkdir my-moonwall-project\ncd my-moonwall-project\nnpm init -y\n```\n\nThen, install it as a local dependency:\n\n=== \"npm\"\n\n    ```bash\n    npm install @moonwall/cli@5.13.5\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm install @moonwall/cli@5.13.5\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add @moonwall/cli@5.13.5\n    ```"}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 5, "depth": 2, "title": "Initialize Moonwall", "anchor": "initialize-moonwall", "start_char": 2448, "end_char": 5877, "estimated_token_count": 770, "token_estimator": "heuristic-v1", "text": "## Initialize Moonwall\n\nThe `moonwall init` command launches an interactive wizard to create your configuration file:\n\n```bash\nmoonwall init\n```\n\nDuring setup, you will see prompts for the following parameters:\n\n- **`label`**: Identifies your test configuration.\n- **`global timeout`**: Maximum time (ms) for test execution.\n- **`environment name`**: Name for your testing environment.\n- **`network foundation`**: Type of blockchain environment to use.\n- **`tests directory`**: Location of your test files.\n\nSelect `Enter` to accept defaults or input custom values. You should see something like this:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>moonwall init</span>\n  <span data-ty>✔ Provide a label for the config file moonwall_config</span>\n  <span data-ty>✔ Provide a global timeout value 30000</span>\n  <span data-ty>✔ Provide a name for this environment default_env</span>\n  <span data-ty>✔ What type of network foundation is this? dev</span>\n  <span data-ty>✔ Provide the path for where tests for this environment are kept tests/</span>\n  <span data-ty>? Would you like to generate this config? (no to restart from beginning) (Y/n)</span>\n</div>\n\n\nThe wizard generates a `moonwall.config` file:\n\n```json\n-{\n    \"label\": \"moonwall_config\",\n    \"defaultTestTimeout\": 30000,\n    \"environments\": [\n        {\n            \"name\": \"default_env\",\n            \"testFileDir\": [\"tests/\"],\n            \"foundation\": {\n                \"type\": \"dev\"\n            }\n        }\n    ]\n}\n\n```\n\nThe default configuration requires specific details about your blockchain node and test requirements:\n\n- The `foundation` object defines how your test blockchain node will be launched and managed. The dev foundation, which runs a local node binary, is used for local development.\n\n    For more information about available options, check the [Foundations](https://moonsong-labs.github.io/moonwall/guide/intro/foundations.html){target=\\_blank} section.\n\n- The `connections` array specifies how your tests will interact with the blockchain node. This typically includes provider configuration and endpoint details.\n\n    A provider is a tool that allows you or your application to connect to a blockchain network and simplifies the low-level details of the process. A provider handles submitting transactions, reading state, and more. For more information on available providers, check the [Providers supported](https://moonsong-labs.github.io/moonwall/guide/intro/providers.html#providers-supported){target=\\_blank} page in the Moonwall documentation.\n\nHere's a complete configuration example for testing a local node using Polkadot.js as a provider:\n\n```json\n-{\n    \"label\": \"moonwall_config\",\n    \"defaultTestTimeout\": 30000,\n    \"environments\": [\n        {\n            \"name\": \"default_env\",\n            \"testFileDir\": [\"tests/\"],\n            \"foundation\": {\n                \"launchSpec\": [\n                    {\n                        \"binPath\": \"./node-template\",\n                        \"newRpcBehaviour\": true,\n                        \"ports\": { \"rpcPort\": 9944 }\n                    }\n                ],\n                \"type\": \"dev\"\n            },\n            \"connections\": [\n                {\n                    \"name\": \"myconnection\",\n                    \"type\": \"polkadotJs\",\n                    \"endpoints\": [\"ws://127.0.0.1:9944\"]\n                }\n            ]\n        }\n    ]\n}\n\n```"}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 6, "depth": 2, "title": "Writing Tests", "anchor": "writing-tests", "start_char": 5877, "end_char": 8607, "estimated_token_count": 650, "token_estimator": "heuristic-v1", "text": "## Writing Tests\n\nMoonwall uses the [`describeSuite`](https://github.com/Moonsong-Labs/moonwall/blob/7568048c52e9f7844f38fb4796ae9e1b9205fdaa/packages/cli/src/lib/runnerContext.ts#L65){target=\\_blank} function to define test suites, like using [Mocha](https://mochajs.org/){target=\\_blank}. Each test suite requires the following:\n\n- **`id`**: Unique identifier for the suite.\n- **`title`**: Descriptive name for the suite.\n- **`foundationMethods`**: Specifies the testing environment (e.g., `dev` for local node testing).\n- **`testCases`**: A callback function that houses the individual test cases of this suite.\n\nThe following example shows how to test a balance transfer between two accounts:\n\n```ts\n-import '@polkadot/api-augment';\nimport { describeSuite, expect } from '@moonwall/cli';\nimport { Keyring } from '@polkadot/api';\n\ndescribeSuite({\n  id: 'D1',\n  title: 'Demo suite',\n  foundationMethods: 'dev',\n  testCases: ({ it, context, log }) => {\n    it({\n      id: 'T1',\n      title: 'Test Case',\n      test: async () => {\n        // Set up polkadot.js API and testing accounts\n        let api = context.polkadotJs();\n        let alice = new Keyring({ type: 'sr25519' }).addFromUri('//Alice');\n        let charlie = new Keyring({ type: 'sr25519' }).addFromUri('//Charlie');\n\n        // Query Charlie's account balance before transfer\n        const balanceBefore = (await api.query.system.account(charlie.address))\n          .data.free;\n\n        // Before transfer, Charlie's account balance should be 0\n        expect(balanceBefore.toString()).toEqual('0');\n        log('Balance before: ' + balanceBefore.toString());\n\n        // Transfer from Alice to Charlie\n        const amount = 1000000000000000;\n        await api.tx.balances\n          .transferAllowDeath(charlie.address, amount)\n          .signAndSend(alice);\n\n        // Wait for the transaction to be included in a block.\n        // This is necessary because the balance is not updated immediately.\n        // Block time is 6 seconds.\n        await new Promise((resolve) => setTimeout(resolve, 6000));\n\n        // Query Charlie's account balance after transfer\n        const balanceAfter = (await api.query.system.account(charlie.address))\n          .data.free;\n\n        // After transfer, Charlie's account balance should be 1000000000000000\n        expect(balanceAfter.toString()).toEqual(amount.toString());\n        log('Balance after: ' + balanceAfter.toString());\n      },\n    });\n  },\n});\n\n```\n\nThis test demonstrates several key concepts:\n\n- Initializing the Polkadot.js API through Moonwall's context and setting up test accounts.\n- Querying on-chain state.\n- Executing transactions.\n- Waiting for block inclusion.\n- Verifying results using assertions."}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 7, "depth": 2, "title": "Running the Tests", "anchor": "running-the-tests", "start_char": 8607, "end_char": 10019, "estimated_token_count": 427, "token_estimator": "heuristic-v1", "text": "## Running the Tests\n\nExecute your tests using the `test` Moonwall CLI command. For the default environment setup run:\n\n```bash\nmoonwall test default_env -c moonwall.config\n```\n\nThe test runner will output detailed results showing:\n\n- Test suite execution status.\n- Individual test case results.\n- Execution time.\n- Detailed logs and error messages (if any).\n\nExample output:\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>moonwall test default_env -c moonwall.config</span>\n  <span data-ty>stdout | tests/test1.ts > 🗃️ D1 Demo suite > 📁 D1T1 Test Case</span>\n  <span data-ty>2025-01-21T19:27:55.624Z test:default_env Balance before: 0</span>\n  <span data-ty></span>\n  <span data-ty>stdout | tests/test1.ts > 🗃️ D1 Demo suite > 📁 D1T1 Test Case</span>\n  <span data-ty>2025-01-21T19:28:01.637Z test:default_env Balance after: 1000000000000000</span>\n  <span data-ty></span>\n  <span data-ty> ✓ default_env tests/test1.ts (1 test) 6443ms</span>\n  <span data-ty> ✓ 🗃️ D1 Demo suite > 📁 D1T1 Test Case 6028ms</span>\n  <span data-ty></span>\n  <span data-ty> Test Files 1 passed (1)</span>\n  <span data-ty> Tests 1 passed (1)</span>\n  <span data-ty> Start at 16:27:53</span>\n  <span data-ty> Duration 7.95s (transform 72ms, setup 0ms, collect 1.31s, tests 6.44s, environment 0ms, prepare 46ms)</span>\n  <span data-ty></span>\n  <span data-ty>✅ All tests passed</span>\n</div>"}
{"page_id": "develop-toolkit-parachains-e2e-testing-moonwall", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10019, "end_char": 10247, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor a comprehensive guide to Moonwall's full capabilities, available configurations, and advanced usage, see the official [Moonwall](https://moonsong-labs.github.io/moonwall/){target=\\_blank} documentation."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 15, "end_char": 1193, "estimated_token_count": 242, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Chopsticks](https://github.com/AcalaNetwork/chopsticks/){target=\\_blank}, developed by the [Acala Foundation](https://github.com/AcalaNetwork){target=\\_blank}, is a versatile tool tailored for developers working on Polkadot SDK-based blockchains. With Chopsticks, you can fork live chains locally, replay blocks to analyze extrinsics, and simulate complex scenarios like XCM interactions all without deploying to a live network.\n\nThis guide walks you through installing Chopsticks and provides information on configuring a local blockchain fork. By streamlining testing and experimentation, Chopsticks empowers developers to innovate and accelerate their blockchain projects within the Polkadot ecosystem.\n\nFor additional support and information, please reach out through [GitHub Issues](https://github.com/AcalaNetwork/chopsticks/issues){target=_blank}.\n\n!!! warning\n    Chopsticks uses [Smoldot](https://github.com/smol-dot/smoldot){target=_blank} light client, which only supports the native Polkadot SDK API. Consequently, a Chopsticks-based fork doesn't support Ethereum JSON-RPC calls, meaning you cannot use it to fork your chain and connect Metamask."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1193, "end_char": 1500, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- [Node.js](https://nodejs.org/en/){target=\\_blank}.\n- A package manager such as [npm](https://www.npmjs.com/){target=\\_blank}, which should be installed with Node.js by default, or [Yarn](https://yarnpkg.com/){target=\\_blank}."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 2, "depth": 2, "title": "Install Chopsticks", "anchor": "install-chopsticks", "start_char": 1500, "end_char": 1792, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Install Chopsticks\n\nYou can install Chopsticks globally or locally in your project. Choose the option that best fits your development workflow. This documentation explains the features of Chopsticks version `1.2.1`. Make sure you're using the correct version to match these instructions."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 3, "depth": 3, "title": "Global Installation", "anchor": "global-installation", "start_char": 1792, "end_char": 2035, "estimated_token_count": 61, "token_estimator": "heuristic-v1", "text": "### Global Installation\n\nTo install Chopsticks globally, allowing you to use it across multiple projects, run:\n\n```bash\nnpm i -g @acala-network/chopsticks@1.2.1\n```\n\nNow, you should be able to run the `chopsticks` command from your terminal."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 4, "depth": 3, "title": "Local Installation", "anchor": "local-installation", "start_char": 2035, "end_char": 2524, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "### Local Installation\n\nTo use Chopsticks in a specific project, first create a new directory and initialize a Node.js project:\n\n```bash\nmkdir my-chopsticks-project\ncd my-chopsticks-project\nnpm init -y\n```\n\nThen, install Chopsticks as a local dependency:\n\n```bash\nnpm i @acala-network/chopsticks@1.2.1\n```\n\nFinally, you can run Chopsticks using the `npx` command. To see all available options and commands, run it with the `--help` flag:\n\n```bash\nnpx @acala-network/chopsticks --help\n```"}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 5, "depth": 2, "title": "Configure Chopsticks", "anchor": "configure-chopsticks", "start_char": 2524, "end_char": 3873, "estimated_token_count": 360, "token_estimator": "heuristic-v1", "text": "## Configure Chopsticks\n\nTo run Chopsticks, you need to configure some parameters. This can be set either through using a configuration file or the command line interface (CLI). The parameters that can be configured are as follows:\n\n- **`genesis`**: The link to a parachain's raw genesis file to build the fork from, instead of an endpoint.\n- **`timestamp`**: Timestamp of the block to fork from.\n- **`endpoint`**: The endpoint of the parachain to fork.\n- **`block`**: Use to specify at which block hash or number to replay the fork.\n- **`wasm-override`**: Path of the Wasm to use as the parachain runtime, instead of an endpoint's runtime.\n- **`db`**: Path to the name of the file that stores or will store the parachain's database.\n- **`config`**: Path or URL of the config file.\n- **`port`**: The port to expose an endpoint on.\n- **`build-block-mode`**: How blocks should be built in the fork: batch, manual, instant.\n- **`import-storage`**: A pre-defined JSON/YAML storage path to override in the parachain's storage.\n- **`allow-unresolved-imports`**: Whether to allow Wasm unresolved imports when using a Wasm to build the parachain.\n- **`html`**: Include to generate storage diff preview between blocks.\n- **`mock-signature-host`**: Mock signature host so that any signature starts with `0xdeadbeef` and filled by `0xcd` is considered valid."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 6, "depth": 3, "title": "Configuration File", "anchor": "configuration-file", "start_char": 3873, "end_char": 5050, "estimated_token_count": 262, "token_estimator": "heuristic-v1", "text": "### Configuration File\n\nThe Chopsticks source repository includes a collection of [YAML](https://yaml.org/){target=\\_blank} files that can be used to set up various Polkadot SDK chains locally. You can download these configuration files from the [repository's `configs` folder](https://github.com/AcalaNetwork/chopsticks/tree/master/configs){target=\\_blank}.\n\nAn example of a configuration file for Polkadot is as follows:\n\n```yaml\n-endpoint:\n  - wss://rpc.ibp.network/polkadot\n  - wss://polkadot-rpc.dwellir.com\nmock-signature-host: true\nblock: ${env.POLKADOT_BLOCK_NUMBER}\ndb: ./db.sqlite\nruntime-log-level: 5\n\nimport-storage:\n  System:\n    Account:\n      - - - 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\n        - providers: 1\n          data:\n            free: '10000000000000000000'\n  ParasDisputes:\n    $removePrefix: ['disputes'] # those can makes block building super slow\n\n```\n\nThe configuration file allows you to modify the storage of the forked network by rewriting the pallet, state component and value that you want to change. For example, Polkadot's file rewrites Alice's `system.Account` storage so that the free balance is set to `10000000000000000000`."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 7, "depth": 3, "title": "CLI Flags", "anchor": "cli-flags", "start_char": 5050, "end_char": 5231, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "### CLI Flags\n\nAlternatively, all settings (except for genesis and timestamp) can be configured via command-line flags, providing a comprehensive method to set up the environment."}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 8, "depth": 2, "title": "WebSocket Commands", "anchor": "websocket-commands", "start_char": 5231, "end_char": 10121, "estimated_token_count": 1278, "token_estimator": "heuristic-v1", "text": "## WebSocket Commands\n\nChopstick's internal WebSocket server has special endpoints that allow the manipulation of the local Polkadot SDK chain.\n\nThese are the methods that can be invoked and their parameters:\n\n- **dev_newBlock** (newBlockParams): Generates one or more new blocks.\n\n    === \"Parameters\"\n\n        - **`newBlockParams` ++\"NewBlockParams\"++**: The parameters to build the new block with. Where the `NewBlockParams` interface includes the following properties.\n\n            - **`count` ++\"number\"++**: The number of blocks to build.\n            - **`dmp` ++\"{ msg: string, sentAt: number }[]\"++**: The downward messages to include in the block.\n            - **`hrmp` ++\"Record<string | number, { data: string, sentAt: number }[]>\"++**: The horizontal messages to include in the block.\n            - **`to` ++\"number\"++**: The block number to build to.\n            - **`transactions` ++\"string[]\"++**: The transactions to include in the block.\n            - **`ump` ++\"Record<number, string[]>\"++**: The upward messages to include in the block.\n            - **`unsafeBlockHeight` ++\"number\"++**: Build block using a specific block height (unsafe).\n\n    === \"Example\"\n\n        ```js\n        -import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function main() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n\nmain();\n\n        ```\n\n- **dev_setBlockBuildMode** (buildBlockMode): Sets block build mode.\n\n    === \"Parameter\"\n    \n        - **`buildBlockMode` ++\"BuildBlockMode\"++**: The build mode. Can be any of the following modes:\n\n            ```ts\n            export enum BuildBlockMode {\n              Batch = 'Batch', /** One block per batch (default) */\n              Instant = 'Instant', /** One block per transaction */\n              Manual = 'Manual', /** Only build when triggered */\n            }\n            ```\n            \n    === \"Example\"\n\n        ```js\n        -import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function main() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  await api.rpc('dev_setBlockBuildMode', 'Instant');\n}\n\nmain();\n\n        ```\n\n- **dev_setHead** (hashOrNumber): Sets the head of the blockchain to a specific hash or number.\n\n    === \"Parameter\"\n\n        - **`hashOrNumber` ++\"string | number\"++**: The block hash or number to set as head.\n\n    === \"Example\"\n\n        ```js\n        -import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function main() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  await api.rpc('dev_setHead', 500);\n}\n\nmain();\n\n        ```\n\n- **dev_setRuntimeLogLevel** (runtimeLogLevel): Sets the runtime log level.\n\n    === \"Parameter\"\n\n        - **`runtimeLogLevel` ++\"number\"++**: The runtime log level to set.\n\n    === \"Example\"\n\n        ```js\n        -import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function main() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  await api.rpc('dev_setRuntimeLogLevel', 1);\n}\n\nmain();\n\n        ```\n\n- **dev_setStorage** (values, blockHash): Creates or overwrites the value of any storage.\n\n    === \"Parameters\"\n\n        - **`values` ++\"object\"++**: JSON object resembling the path to a storage value.\n        - **`blockHash` ++\"string\"++**: The block hash to set the storage value.\n\n    === \"Example\"\n\n        ```js\n        -import { ApiPromise, WsProvider } from '@polkadot/api';\n\nimport { Keyring } from '@polkadot/keyring';\nasync function main() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  const keyring = new Keyring({ type: 'ed25519' });\n  const bob = keyring.addFromUri('//Bob');\n  const storage = {\n    System: {\n      Account: [[[bob.address], { data: { free: 100000 }, nonce: 1 }]],\n    },\n  };\n  await api.rpc('dev_setStorage', storage);\n}\n\nmain();\n\n        ```\n\n- **dev_timeTravel** (date): Sets the timestamp of the block to a specific date\".\n\n    === \"Parameter\"\n\n        - **`date` ++\"string\"++**: Timestamp or date string to set. All future blocks will be sequentially created after this point in time.\n\n    === \"Example\"\n\n        ```js\n        -import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function main() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  await api.rpc('dev_timeTravel', '2030-08-15T00:00:00');\n}\n\nmain();\n\n        ```"}
{"page_id": "develop-toolkit-parachains-fork-chains-chopsticks-get-started", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10121, "end_char": 10478, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Fork a Chain with Chopsticks__\n\n    ---\n\n    Visit this guide for step-by-step instructions for configuring and interacting with your forked chain.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/polkadot-sdk/testing/fork-live-chains/)\n\n</div>"}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 994, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nLight clients enable secure and efficient blockchain interaction without running a full node. They provide a trust-minimized alternative to JSON-RPC by verifying data through cryptographic proofs rather than blindly trusting remote nodes.\n\nThis guide covers:\n\n- What light clients are and how they work.\n- Their advantages compared to full nodes and JSON-RPC.\n- Available implementations in the Polkadot ecosystem.\n- How to use light clients in your applications.\n\nLight clients are particularly valuable for resource-constrained environments and applications requiring secure, decentralized blockchain access without the overhead of maintaining full nodes.\n\n!!!note \"Light node or light client?\"\n    The terms _light node_ and _light client_ are interchangeable. Both refer to a blockchain client that syncs without downloading the entire blockchain state. All nodes in a blockchain network are fundamentally clients, engaging in peer-to-peer communication."}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 1, "depth": 2, "title": "Light Clients Workflow", "anchor": "light-clients-workflow", "start_char": 994, "end_char": 2625, "estimated_token_count": 359, "token_estimator": "heuristic-v1", "text": "## Light Clients Workflow\n\nUnlike JSON-RPC interfaces, where an application must maintain a list of providers or rely on a single node, light clients are not limited to or dependent on a single node. They use cryptographic proofs to verify the blockchain's state, ensuring it is up-to-date and accurate. By verifying only block headers, light clients avoid syncing the entire state, making them ideal for resource-constrained environments.\n\n```mermaid\nflowchart LR\nDAPP([dApp])-- Query Account Info -->LC([Light Client])\nLC -- Request --> FN(((Full Node)))\nLC -- Response --> DAPP\nFN -- Response (validated via Merkle proof) --> LC\n```\n\nIn the diagram above, the decentralized application queries on-chain account information through the light client. The light client runs as part of the application and requires minimal memory and computational resources. It uses Merkle proofs to verify the state retrieved from a full node in a trust-minimized manner. Polkadot-compatible light clients utilize [warp syncing](https://spec.polkadot.network/sect-lightclient#sect-sync-warp-lightclient){target=\\_blank}, which downloads only block headers.\n\nLight clients can quickly verify the blockchain's state, including [GRANDPA finality](/polkadot-protocol/glossary#grandpa){target=\\_blank} justifications.\n\n!!!note \"What does it mean to be trust-minimized?\"\n    _Trust-minimized_ means that the light client does not need to fully trust the full node from which it retrieves the state. This is achieved through the use of Merkle proofs, which allow the light client to verify the correctness of the state by checking the Merkle tree root."}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 2, "depth": 2, "title": "JSON-RPC and Light Client Comparison", "anchor": "json-rpc-and-light-client-comparison", "start_char": 2625, "end_char": 4478, "estimated_token_count": 442, "token_estimator": "heuristic-v1", "text": "## JSON-RPC and Light Client Comparison\n\nAnother common method of communication between a user interface (UI) and a node is through the JSON-RPC protocol. Generally, the UI retrieves information from the node, fetches network or [pallet](/polkadot-protocol/glossary#pallet){target=\\_blank} data, and interacts with the blockchain. This is typically done in one of two ways:\n\n- **User-controlled nodes**: The UI connects to a node client installed on the user's machine.\n    - These nodes are secure, but installation and maintenance can be inconvenient.\n- **Publicly accessible nodes**: The UI connects to a third-party-owned publicly accessible node client.\n    - These nodes are convenient but centralized and less secure. Applications must maintain a list of backup nodes in case the primary node becomes unavailable.\n\nWhile light clients still communicate with [full nodes](/polkadot-protocol/glossary#full-node), they offer significant advantages for applications requiring a secure alternative to running a full node:\n\n| Full Node                                                                                       | Light Client                                                   |\n| :---------------------------------------------------------------------------------------------: | :------------------------------------------------------------: |\n| Fully verifies all blocks of the chain                                                          | Verifies only the authenticity of blocks                       |\n| Stores previous block data and the chain's storage in a database                                | Does not require a database                                    |\n| Installation, maintenance, and execution are resource-intensive and require technical expertise | No installation is typically included as part of the application |"}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 3, "depth": 2, "title": "Using Light Clients", "anchor": "using-light-clients", "start_char": 4478, "end_char": 4799, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Using Light Clients\n\nThe [`smoldot`](https://github.com/smol-dot/smoldot){target=\\_blank} client is the cornerstone of light client implementation for Polkadot SDK-based chains. It provides the primitives needed to build light clients and is also integrated into libraries such as [PAPI](#papi-light-client-support)."}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 4, "depth": 3, "title": "PAPI Light Client Support", "anchor": "papi-light-client-support", "start_char": 4799, "end_char": 5131, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "### PAPI Light Client Support\n\nThe [Polkadot API (PAPI)](/develop/toolkit/api-libraries/papi){target=\\_blank} library natively supports light client configurations powered by [`smoldot`](https://github.com/smol-dot/smoldot){target=\\_blank}. This allows developers to connect to multiple chains simultaneously using a light client."}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 5, "depth": 3, "title": "Substrate Connect - Browser Extension", "anchor": "substrate-connect-browser-extension", "start_char": 5131, "end_char": 5902, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "### Substrate Connect - Browser Extension\n\nThe [Substrate Connect browser extension](https://www.npmjs.com/package/@substrate/connect-extension-protocol){target=\\_blank} enables end-users to interact with applications connected to multiple blockchains or to connect their own blockchains to supported applications.\n\nEstablishing a sufficient number of peers can be challenging due to browser limitations on WebSocket connections from HTTPS pages, as many nodes require TLS. The Substrate Connect browser extension addresses this limitation by keeping chains synced in the background, enabling faster application performance.\n\nSubstrate Connect automatically detects whether the user has the extension installed. If not, an in-page Wasm light client is created for them."}
{"page_id": "develop-toolkit-parachains-light-clients", "index": 6, "depth": 2, "title": "Resources", "anchor": "resources", "start_char": 5902, "end_char": 6490, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## Resources\n\n- [What is a light client and why you should care?](https://medium.com/paritytech/what-is-a-light-client-and-why-you-should-care-75f813ae2670){target=\\_blank}\n- [Introducing Substrate Connect: Browser-Based Light Clients for Connecting to Substrate Chains](https://www.parity.io/blog/introducing-substrate-connect){target=\\_blank}\n- [Substrate Connect GitHub Repository](https://github.com/paritytech/substrate-connect/tree/master/projects/extension){target=\\_blank}\n- [Light Clients - Polkadot Specification](https://spec.polkadot.network/sect-lightclient){target=\\_blank}"}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 985, "estimated_token_count": 205, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [`polkadot-omni-node`](https://crates.io/crates/polkadot-omni-node/0.7.0){target=\\_blank} crate is a versatile, pre-built binary designed to simplify running parachains in the Polkadot ecosystem. Unlike traditional node binaries that are tightly coupled to specific runtime code, the `polkadot-omni-node` operates using an external [chain specification](/polkadot-protocol/glossary#chain-specification){target=\\_blank} file, allowing it to adapt dynamically to different parachains.\n\nThis approach enables it to act as a white-labeled node binary, capable of running most parachains that do not require custom node-level logic or extensions. Developers can leverage this flexibility to test, deploy, or operate parachain nodes without maintaining a dedicated codebase for each network.\n\nThis guide provides step-by-step instructions for installing the `polkadot-omni-node`, obtaining a chain specification, and spinning up a parachain node."}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 985, "end_char": 1310, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following prerequisites:\n\n- **[Rust](https://www.rust-lang.org/tools/install){target=\\_blank}**: Required to build and install the `polkadot-omni-node` binary.\n\nEnsure Rust's `cargo` command is available in your terminal by running:\n\n```bash\ncargo --version\n```"}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 2, "depth": 2, "title": "Install Polkadot Omni Node", "anchor": "install-polkadot-omni-node", "start_char": 1310, "end_char": 1748, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "## Install Polkadot Omni Node\n\nTo install `polkadot-omni-node` globally using `cargo`, run:\n\n```bash\ncargo install --locked polkadot-omni-node@0.7.0\n```\n\nThis command downloads and installs version 0.7.0 of the binary, making it available system-wide.\n\nTo confirm the installation, run:\n\n```bash\npolkadot-omni-node --version\n```\n\nYou should see the installed version number printed to the terminal, confirming a successful installation."}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 3, "depth": 2, "title": "Obtain Chain Specifications", "anchor": "obtain-chain-specifications", "start_char": 1748, "end_char": 2584, "estimated_token_count": 202, "token_estimator": "heuristic-v1", "text": "## Obtain Chain Specifications\n\nThe `polkadot-omni-node` binary uses a chain specification file to configure and launch a parachain node. This file defines the parachain's genesis state and network settings.\n\nThe most common source for official chain specifications is the [`paritytech/chainspecs`](https://github.com/paritytech/chainspecs){target=\\_blank} repository. These specifications are also browsable in a user-friendly format via the [Chainspec Collection](https://paritytech.github.io/chainspecs/){target=\\_blank} website.\n\nTo obtain a chain specification:\n\n1. Visit the [Chainspec Collection](https://paritytech.github.io/chainspecs/){target=\\_blank} website.\n2. Find the parachain you want to run.\n3. Click the chain spec to open it.\n4. Copy the JSON content and save it locally as a `.json` file, e.g., `chain_spec.json`."}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 4, "depth": 2, "title": "Run a Parachain Full Node", "anchor": "run-a-parachain-full-node", "start_char": 2584, "end_char": 3715, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "## Run a Parachain Full Node\n\nOnce you've installed `polkadot-omni-node` and saved the appropriate chain specification file, you can start a full node for your chosen parachain.\n\nTo see all available flags and configuration options, run:\n\n```bash\npolkadot-omni-node --help\n```\n\nTo launch the node, run the following command, replacing `./INSERT_PARACHAIN_CHAIN_SPEC.json` with the actual path to your saved chain spec file.\n\nThis command will:\n\n- Load the chain specification.\n- Initialize the node using the provided network configuration.\n- Begin syncing with the parachain network.\n\n```bash\npolkadot-omni-node --chain ./INSERT_PARACHAIN_CHAIN_SPEC.json --sync warp\n```\n\n- The `--chain` flag tells the `polkadot-omni-node` which parachain to run by pointing to its chain specification file.\n- The `--sync warp` flag enables warp sync, allowing the node to quickly catch up to the latest finalized state. Historical blocks are fetched in the background as the node continues operating.\n\nOnce started, the node will begin connecting to peers and syncing with the network. You’ll see logs in your terminal reflecting its progress."}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 5, "depth": 2, "title": "Interact with the Node", "anchor": "interact-with-the-node", "start_char": 3715, "end_char": 4277, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "## Interact with the Node\n\nBy default, `polkadot-omni-node` exposes a WebSocket endpoint at `ws://localhost:9944`,  which you can use to interact with the running node. You can connect using:\n\n- **[Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}**: A web-based interface for exploring and interacting with Polkadot SDK-based chains.\n- Custom scripts using compatible [libraries](/develop/toolkit/api-libraries/){target=\\_blank}.\n\nOnce connected, you can review blocks, call extrinsics, inspect storage, and interact with the runtime."}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 6, "depth": 2, "title": "Parachain Compatibility", "anchor": "parachain-compatibility", "start_char": 4277, "end_char": 5091, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Parachain Compatibility\n\nThe `polkadot-omni-node` is designed to work with most parachains out of the box; however, your parachain's runtime must meet specific requirements and follow certain conventions to be compatible. This section outlines what your runtime needs to implement and configure to work seamlessly with the `polkadot-omni-node`:\n\n- Your runtime must implement the required runtime APIs (see below).\n- Your runtime must include and configure the required pallets.\n\nThe [`parachain-template`](https://github.com/paritytech/polkadot-sdk-parachain-template/tree/v0.0.4){target=_blank} provides a complete reference implementation that is fully compatible with the `polkadot-omni-node`. You can use it as a starting point or reference for ensuring your runtime meets all compatibility requirements."}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 7, "depth": 3, "title": "Required Runtime APIs", "anchor": "required-runtime-apis", "start_char": 5091, "end_char": 6427, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "### Required Runtime APIs\n\nYour parachain runtime must implement the following runtime APIs for the `polkadot-omni-node` to function properly:\n\n- **GetParachainInfo Runtime API**: The omni-node requires the [`GetParachainInfo`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/trait.GetParachainInfo.html){target=\\_blank} runtime API to identify and configure the parachain correctly. This API provides the parachain ID to the node.\n\n    ```rust title=\"runtime/src/apis.rs\"\n    impl cumulus_primitives_core::GetParachainInfo<Block> for Runtime {\n        fn parachain_id() -> cumulus_primitives_core::ParaId {\n            // Return your parachain ID\n            ParachainInfo::parachain_id()\n        }\n    }\n    ```\n\n- **Aura Runtime API**: For consensus, the `polkadot-omni-node` expects the [Aura runtime API](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/runtime/apis/trait.AuraApi.html){target=\\_blank} to be implemented.\n\n    ```rust title=\"runtime/src/apis.rs\"\n    impl sp_consensus_aura::AuraApi<Block, AuraId> for Runtime {\n        fn slot_duration() -> sp_consensus_aura::SlotDuration {\n            sp_consensus_aura::SlotDuration::from_millis(SLOT_DURATION)\n        }\n\n        fn authorities() -> Vec<AuraId> {\n            Aura::authorities().into_inner()\n        }\n    }\n    ```"}
{"page_id": "develop-toolkit-parachains-polkadot-omni-node", "index": 8, "depth": 3, "title": "Required Pallets", "anchor": "required-pallets", "start_char": 6427, "end_char": 8916, "estimated_token_count": 566, "token_estimator": "heuristic-v1", "text": "### Required Pallets\n\nYour runtime must include and properly configure the following pallets:\n\n- **System Pallet**: The System pallet ([`frame-system`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/prelude/frame_system/index.html){target=\\_blank}) is fundamental and must be configured with appropriate types.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    #[frame_support::runtime]\n    impl frame_system::Config for Runtime {\n        type Block = Block;\n        type BlockNumber = BlockNumber;\n        // ... other configurations\n    }\n\n    // Must be named \"System\" for omni-node compatibility\n    pub type System = frame_system::Pallet<Runtime>;\n    ```\n\n- **ParachainSystem Pallet**: This pallet ([`cumulus-pallet-parachain-system`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/index.html){target=\\_blank}) enables parachain functionality and handles low-level details of being a parachain.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    impl cumulus_pallet_parachain_system::Config for Runtime {\n        type RuntimeEvent = RuntimeEvent;\n        type OnSystemEvent = ();\n        // ... other configurations\n    }\n\n    // Must be named \"ParachainSystem\" for omni-node compatibility  \n    pub type ParachainSystem = cumulus_pallet_parachain_system::Pallet<Runtime>;\n    ```\n\n- **Aura Pallet**: For block authoring consensus ([`pallet-aura`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/index.html){target=\\_blank}).\n\n    ```rust title=\"runtime/src/lib.rs\"\n    impl pallet_aura::Config for Runtime {\n        type AuthorityId = AuraId;\n        type DisabledValidators = ();\n        type MaxAuthorities = MaxAuthorities;\n        type AllowMultipleBlocksPerSlot = ConstBool<false>;\n    }\n\n    pub type Aura = pallet_aura::Pallet<Runtime>;\n    ```\n\n- **ParachainInfo Pallet**: Provides parachain metadata ([`parachain-info`](https://paritytech.github.io/polkadot-sdk/master/staging_parachain_info/index.html){target=\\_blank}).\n\n    ```rust title=\"runtime/src/lib.rs\"\n    impl parachain_info::Config for Runtime {}\n\n    pub type ParachainInfo = parachain_info::Pallet<Runtime>;\n    ```\n\nIf you're migrating an existing parachain to use the `polkadot-omni-node`, you may need to perform runtime upgrades to add the required runtime APIs and pallets. Follow the standard parachain [runtime upgrade](/develop/parachains/maintenance/runtime-upgrades/){target=\\_blank} procedures to implement these changes on your live network."}
{"page_id": "develop-toolkit-parachains-quickstart-pop-cli", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 49, "end_char": 745, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Pop CLI](https://onpop.io/cli/){target=\\_blank} is a powerful command-line tool designed explicitly for rapid parachain development within the Polkadot ecosystem. It addresses essential developer needs by providing streamlined commands to set up development environments, scaffold parachain templates, and manage local blockchain networks.\n\nPop CLI simplifies parachain development with features like:\n\n- Quick initialization of parachain development environments.\n- Project scaffolding from predefined parachain templates.\n- Easy deployment and management of local development networks.\n\nDevelopers can quickly begin coding and testing, significantly reducing setup overhead."}
{"page_id": "develop-toolkit-parachains-quickstart-pop-cli", "index": 1, "depth": 3, "title": "Install Pop CLI", "anchor": "install-pop-cli", "start_char": 745, "end_char": 967, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "### Install Pop CLI\n\nTo install Pop CLI, run the following command:\n\n```bash\ncargo install --force --locked pop-cli\n```\n\nConfirm that Pop CLI is installed by running `pop --help` in your terminal:\n\n```bash\npop --help\n```"}
{"page_id": "develop-toolkit-parachains-quickstart-pop-cli", "index": 2, "depth": 3, "title": "Set Up Your Development Environment", "anchor": "set-up-your-development-environment", "start_char": 967, "end_char": 2255, "estimated_token_count": 338, "token_estimator": "heuristic-v1", "text": "### Set Up Your Development Environment\n\nTo develop and build Polkadot SDK-based chains, preparing your local environment with the necessary tools and dependencies is essential. The [Install Polkadot SDK Dependencies](/develop/parachains/install-polkadot-sdk/){target=\\_blank} guide walks you through this setup step-by-step.\n\nHowever, you can automate this entire process by running:\n\n```bash\npop install\n```\n\nThis command provides an interactive experience that checks and installs all necessary dependencies for you. It’s the fastest and easiest way to prepare your development environment for building parachains with Pop CLI.\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>pop install</span>\n  <span data-ty>┌ Pop CLI : Install dependencies for development</span>\n  <span data-ty>│ </span>\n  <span data-ty></span>\n  <span data-ty>⚙ ℹ️ Mac OS (Darwin) detected.</span>\n  <span data-ty>│ </span>\n  <span data-ty>⚙ More information about the packages to be installed here: https://docs.substrate.io/install/macos/</span>\n  <span data-ty>│ </span>\n  <span data-ty>◆ 📦 Do you want to proceed with the installation of the following packages: homebrew, protobuf, openssl, rustup and cmake ?</span>\n  <span data-ty>│ ● Yes / ○ No </span>\n</div>"}
{"page_id": "develop-toolkit-parachains-quickstart-pop-cli", "index": 3, "depth": 3, "title": "Initialize a Project", "anchor": "initialize-a-project", "start_char": 2255, "end_char": 3876, "estimated_token_count": 398, "token_estimator": "heuristic-v1", "text": "### Initialize a Project\n\nStart a new project quickly using Pop CLI's `pop new parachain` command:\n\n-<div id=\"termynal\" data-termynal>\n  <img src=\"/images/develop/toolkit/parachains/quickstart/pop-new.gif\" alt=\"pop new\" style=\"max-width: 100%\" />\n</div>\n\n\nThe command above scaffolds a new parachain project using the default template included with Pop CLI. For more specialized implementations, additional templates are available; you can explore them by running `pop new parachain --help`.\n\nOnce the project is generated, move into the new directory and build your parachain:\n\n```\ncd my-parachain\npop build --release\n```\n\n!!! note\n    Under the hood, `pop build --release` runs `cargo build --release`, but `pop build` adds functionality specific to Polkadot SDK projects, such as [deterministic runtime builds](/develop/parachains/deployment/build-deterministic-runtime/){target=\\_blank} and automatic management of feature flags like `benchmark` or `try-runtime`.\n\nPop CLI integrates the [Zombienet SDK](https://github.com/paritytech/zombienet-sdk){target=\\_blank} allowing you to easily launch ephemeral local networks for development and testing. To start a network, simply run the following:\n\n```bash\npop up network -f ./network.toml\n```\n\nThis command will automatically fetch the necessary binaries and spin up a Polkadot network with your configured parachains.\n\nYou can also interact with your local network using Pop CLI's `pop call chain` command:\n\n-<div id=\"termynal\" data-termynal>\n  <img src=\"/images/develop/toolkit/parachains/quickstart/call-chain.gif\" alt=\"pop call\" style=\"max-width: 100%\" />\n</div>"}
{"page_id": "develop-toolkit-parachains-quickstart-pop-cli", "index": 4, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3876, "end_char": 4250, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor a comprehensive guide to all Pop CLI features and advanced usage, see the official [Pop CLI](https://learn.onpop.io/appchains) documentation.\n\n!!! tip\n    Pop CLI also offers powerful solutions for smart contract developers. If you're interested in that path, check out the [Pop CLI Smart Contracts](https://learn.onpop.io/contracts) documentation."}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 313, "end_char": 1414, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRemote proxies enable cross-chain proxy functionality within the Polkadot ecosystem, allowing proxy accounts defined on one chain to execute transactions on different chains through cryptographic storage proofs. This functionality extends the traditional [proxy system](https://wiki.polkadot.com/learn/learn-proxies/){target=\\_blank} beyond single-chain boundaries.\n\nThis guide covers:\n\n- Understanding remote proxy mechanics and architecture.\n- Implementation workflow and timing constraints.\n- Practical examples using Polkadot.js.\n- Advanced use cases and security considerations.\n\nRemote proxies are particularly valuable for maintaining unified security models across multiple parachains while avoiding the complexity of managing separate proxy setups on each chain.\n\n!!!note \"Traditional vs Remote Proxies\"\n    Traditional proxies work within a single chain, where both the proxy and proxied accounts exist on the same blockchain. Remote proxies extend this concept across chains, using cryptographic proofs to verify proxy relationships without requiring account replication."}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 1, "depth": 2, "title": "Remote Proxy Architecture", "anchor": "remote-proxy-architecture", "start_char": 1414, "end_char": 2639, "estimated_token_count": 244, "token_estimator": "heuristic-v1", "text": "## Remote Proxy Architecture\n\nRemote proxies operate through a trust and verification model using storage proofs. The target chain verifies the existence of proxy relationships on the source chain without requiring direct replication of proxy data.\n\n```mermaid\nflowchart LR\nRC([Relay Chain])-- Proxy Definition -->AH([Asset Hub])\nRC -- Storage Proof --> AH\nAH -- Verify Proof --> TX([Execute Transaction])\nAH -- Trust Relationship --> RC\n```\n\nIn this architecture, Asset Hub trusts proxy definitions from the Relay Chain. When a remote proxy transaction is initiated, Asset Hub verifies the storage proof against its stored block roots from the Relay Chain, ensuring the proxy relationship is authentic and current.\n\nThe verification process utilizes [Merkle proofs](/polkadot-protocol/glossary/#trie-patricia-merkle-tree){target=\\_blank} to confirm proxy permissions exist on the source chain at a specific block height.\n\n!!!note \"What makes remote proxies secure?\"\n    Remote proxies maintain security through cryptographic storage proofs that cannot be forged. The target chain verifies these proofs against trusted block roots, ensuring proxy relationships are authentic without requiring blind trust in external nodes."}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 2, "depth": 2, "title": "Implementation Workflow", "anchor": "implementation-workflow", "start_char": 2639, "end_char": 3896, "estimated_token_count": 262, "token_estimator": "heuristic-v1", "text": "## Implementation Workflow\n\nRemote proxy execution follows a time-constrained workflow requiring coordination between multiple chains. The remote proxy workflow consists of several critical steps that must be completed within a narrow time window.\n\n1. **Block Synchronization**: Query the target chain for recognized source chain blocks.\n2. **Storage Proof Creation**: Generate cryptographic proof of proxy relationship. \n3. **Transaction Construction**: Build the wrapped transaction with proof data.\n4. **Execution**: Submit the transaction before proof expiration.\n\nRemote proxies operate under strict timing limitations.\n\n- **Proof Validity**: Storage proofs expire after approximately **1 minute**.\n- **Block Recognition**: Target chains maintain only recent source chain block roots.\n- **Execution Window**: Transactions must be submitted immediately after proof generation.\n\nThese constraints exist to prevent replay attacks and ensure proof freshness while maintaining system security.\n\n| Constraint Type | Duration | Purpose |\n| :-------------: | :------: | :-----: |\n| Proof Validity | ~1 minute | Prevent replay attacks |\n| Block Storage | ~10 minutes | Balance security and usability |\n| Execution Window | Immediate | Ensure proof freshness |"}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 3, "depth": 2, "title": "Practical Implementation", "anchor": "practical-implementation", "start_char": 3896, "end_char": 3925, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Practical Implementation"}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 4, "depth": 3, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 3925, "end_char": 4198, "estimated_token_count": 52, "token_estimator": "heuristic-v1", "text": "### Prerequisites\n\nBefore implementing remote proxies, ensure you have:\n\n- Active proxy relationship on the source chain (Kusama).\n- Access to both source and target chain RPC endpoints.\n- Compatible proxy types between chains.\n- Node.js environment for script execution."}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 5, "depth": 3, "title": "Installation and Setup", "anchor": "installation-and-setup", "start_char": 4198, "end_char": 4547, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "### Installation and Setup\n\nTo implement remote proxies, you need to install the [`@polkadot/api`](/develop/toolkit/api-libraries/polkadot-js-api/){target=\\_blank} package and create a script to execute the remote proxy transaction:\n\n```bash\npnpm add @polkadot/api\n```\n\nCreate your implementation script:\n\n```bash\ntouch remote-proxy-example.js\n```"}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 6, "depth": 3, "title": "Implementation Example", "anchor": "implementation-example", "start_char": 4547, "end_char": 8686, "estimated_token_count": 885, "token_estimator": "heuristic-v1", "text": "### Implementation Example\n\nHere is a complete implementation example of a remote proxy transaction:\n\n```javascript title=\"remote-proxy-example.js\"\n-import { ApiPromise, WsProvider } from '@polkadot/api';\n\n// Account configuration - replace with your addresses\nconst RECIPIENT_ACCOUNT = 'INSERT_RECIPIENT_ACCOUNT';\nconst PROXIED_ACCOUNT = 'INSERT_PROXIED_ACCOUNT';\n\nasync function executeRemoteProxyTransaction() {\n  try {\n    // Establish connections to both chains\n    console.log('Connecting to Kusama relay chain...');\n    const kusamaProvider = new WsProvider(\n      'wss://kusama.public.curie.radiumblock.co/ws',\n    );\n    const kusamaApi = await ApiPromise.create({ provider: kusamaProvider });\n\n    console.log('Connecting to Kusama Asset Hub...');\n    const assetHubProvider = new WsProvider(\n      'wss://kusama-asset-hub-rpc.polkadot.io',\n    );\n    const assetHubApi = await ApiPromise.create({ provider: assetHubProvider });\n\n    // Step 1: Generate storage key for proxy definition\n    const proxyStorageKey = kusamaApi.query.proxy.proxies.key(PROXIED_ACCOUNT);\n    console.log(`Proxy storage key: ${proxyStorageKey}`);\n\n    // Step 2: Identify latest recognized block\n    const blockToRootMapping = JSON.parse(\n      await assetHubApi.query.remoteProxyRelayChain.blockToRoot(),\n    );\n    const latestRecognizedBlock =\n      blockToRootMapping[blockToRootMapping.length - 1][0];\n    const blockHash = await kusamaApi.rpc.chain.getBlockHash(\n      latestRecognizedBlock,\n    );\n\n    console.log(`Generating proof for block ${latestRecognizedBlock}`);\n\n    // Step 3: Create storage proof\n    const storageProof = JSON.parse(\n      await kusamaApi.rpc.state.getReadProof([proxyStorageKey], blockHash),\n    );\n\n    // Step 4: Define target transaction\n    const targetTransaction = assetHubApi.tx.balances.transferAll(\n      RECIPIENT_ACCOUNT,\n      false,\n    );\n\n    // Step 5: Construct remote proxy call\n    const remoteProxyCall = assetHubApi.tx.remoteProxyRelayChain.remoteProxy(\n      PROXIED_ACCOUNT,\n      null, // Proxy type filter (null accepts any compatible type)\n      targetTransaction.method,\n      {\n        RelayChain: {\n          proof: storageProof.proof,\n          block: latestRecognizedBlock,\n        },\n      },\n    );\n\n    console.log('\\n✅ Remote proxy transaction constructed successfully!');\n    console.log('\\n📋 Next steps:');\n    console.log('1. Copy the URL below');\n    console.log('2. Open in Polkadot.js Apps');\n    console.log('3. Submit the transaction within 1 minute');\n    console.log('\\n🔗 Polkadot.js Apps URL:');\n    console.log(\n      `https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama-asset-hub-rpc.polkadot.io#/extrinsics/decode/${remoteProxyCall.method.toHex()}`,\n    );\n\n    // Cleanup connections\n    await kusamaApi.disconnect();\n    await assetHubApi.disconnect();\n  } catch (error) {\n    console.error('❌ Remote proxy execution failed:', error.message);\n  }\n}\n\n// Execute the remote proxy workflow\nexecuteRemoteProxyTransaction();\n\n```\n\nEnsure to replace the `RECIPIENT_ACCOUNT` and `PROXIED_ACCOUNT` with your accounts. For a concrete example, check out the [Sending a remote proxy transaction via Polkadot-JS](https://blog.kchr.de/polkadot/guides/remote-proxies-for-the-braves/#sending-a-remote-proxy-transaction-via-polkadot-js){target=\\_blank} section in the Remote Proxies article.\n\nThe code snippet above is a complete implementation example of a remote proxy transaction. It demonstrates how to:\n\n- **Storage Key Generation**: The `proxyStorageKey` identifies where proxy relationship data is stored on Kusama. This key is used to create a proof that the relationship exists.\n- **Block Synchronization**: Asset Hub maintains a mapping of recent Kusama block numbers to their storage roots to enable proof verification without requiring full blockchain synchronization.\n- **Proof Creation**: The `getReadProof` RPC call generates a cryptographic proof that specific data exists in Kusama's state at a given block height.\n- **Transaction Wrapping**: The target transaction is wrapped within a `remoteProxy` call that includes both the proof data and the block anchor."}
{"page_id": "develop-toolkit-parachains-remote-proxies", "index": 7, "depth": 2, "title": "Resources", "anchor": "resources", "start_char": 8686, "end_char": 9086, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "## Resources\n\n- **[Remote Proxies for Braves](https://blog.kchr.de/polkadot/guides/remote-proxies-for-the-braves){target=\\_blank}**\n- **[Ecosystem Proxy](https://blog.kchr.de/ecosystem-proxy/){target=\\_blank}**\n- **[RFC: Pure Proxy Replication](https://github.com/polkadot-fellows/RFCs/pull/111){target=\\_blank}**\n- **[Learn Proxies](https://wiki.polkadot.com/learn/learn-proxies/){target=\\_blank}**"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 888, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Remote Procedure Call](https://en.wikipedia.org/wiki/Remote_procedure_call){target=\\_blank} (RPC) interfaces are the primary way to interact programmatically with Polkadot SDK-based parachains and relay chains. RPC calls allow you to query chain state, submit transactions, and monitor network health from external applications or scripts.\n\nThis guide covers:\n\n- What RPC calls are and how they work in the Polkadot SDK.\n- How to make RPC calls using `curl` or similar tools.\n- The most useful and commonly used RPC methods.\n\nRPC endpoints are available on every node and can be accessed via HTTP and WebSocket. Most developer tools, dashboards, and libraries (like [Polkadot.js](/develop/toolkit/api-libraries/polkadot-js-api){target=\\_blank}, [Subxt](/develop/toolkit/api-libraries/subxt){target=\\_blank}, and others) utilize these endpoints internally."}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 1, "depth": 2, "title": "How Do RPC Calls Work?", "anchor": "how-do-rpc-calls-work", "start_char": 888, "end_char": 1596, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## How Do RPC Calls Work?\n\nRPC (Remote Procedure Call) is a protocol that allows you to invoke functions on a remote server (in this case, a blockchain node) as if they were local. Polkadot SDK nodes implement the [JSON-RPC 2.0](https://www.jsonrpc.org/specification){target=\\_blank} standard, making it easy to interact with them using standard HTTP requests.\n\n```mermaid\nflowchart LR\nCLIENT([Client Application])-- JSON-RPC Request -->NODE([Node])\nNODE -- JSON Response --> CLIENT\n```\n\nRPC calls are stateless and can be used to:\n\n- Query chain state (e.g., block number, storage values).\n- Submit extrinsics (transactions).\n- Monitor node and network health.\n- Retrieve metadata and runtime information."}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 2, "depth": 2, "title": "Making RPC Calls with Curl", "anchor": "making-rpc-calls-with-curl", "start_char": 1596, "end_char": 2466, "estimated_token_count": 280, "token_estimator": "heuristic-v1", "text": "## Making RPC Calls with Curl\n\nYou can make RPC calls to a node using [`curl`](https://curl.se/){target=\\_blank} or any HTTP client. The general format that the RPC calls stick to is the following:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n  -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"INSERT_METHOD_NAME\", \"params\": [INSERT_PARAMS]}' \\\n  NODE_ENDPOINT\n```\n\n- **`method`**: The RPC method you want to call (e.g., `system_health`).\n- **`params`**: Parameters for the method (if any).\n- **`NODE_ENDPOINT`**: The HTTP endpoint of your node (e.g., `http://localhost:9933` or a public endpoint).\n\nHere's a simple example to get the latest block number of the Polkadot relay chain; you can use the following node endpoint:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n  -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"chain_getBlock\"}' \\\n  https://rpc.polkadot.io\n```"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 3, "depth": 2, "title": "Essential RPC Methods", "anchor": "essential-rpc-methods", "start_char": 2466, "end_char": 2665, "estimated_token_count": 40, "token_estimator": "heuristic-v1", "text": "## Essential RPC Methods\n\nBelow are some of the most useful and commonly used RPC methods for Polkadot SDK-based chains. Each method includes a description, parameters, and an example request.\n\n---"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 4, "depth": 3, "title": "system_health", "anchor": "system_health", "start_char": 2665, "end_char": 2941, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "### system_health\n\nChecks the health of your node.\n\n**Parameters:**\n\nNone.\n\n**Example:**\n\n```bash title=\"system_health\"\ncurl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_health\", \"params\":[]}' \\\n    http://localhost:9933\n```\n\n---"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 5, "depth": 3, "title": "chain_getBlock", "anchor": "chain_getblock", "start_char": 2941, "end_char": 3346, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "### chain_getBlock\n\nReturns the latest block or a specific block by hash.\n\n**Parameters:**\n\n- `blockHash` *(optional, string)* – The hash of the block to retrieve. If omitted, returns the latest block.\n\n**Example:**\n\n```bash title=\"chain_getBlock\"\ncurl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"chain_getBlock\", \"params\":[]}' \\\n    http://localhost:9933\n```\n\n---"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 6, "depth": 3, "title": "state_getStorage", "anchor": "state_getstorage", "start_char": 3346, "end_char": 3806, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "### state_getStorage\n\nQueries on-chain storage by key (requires [SCALE-encoded](/polkadot-protocol/parachain-basics/data-encoding){target=_blank} storage key).\n\n**Parameters:**\n\n- `storageKey` *(string)* – The SCALE-encoded storage key to query.\n\n**Example:**\n\n```bash title=\"state_getStorage\"\ncurl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"state_getStorage\", \"params\":[\"0x...\"]}' \\\n    http://localhost:9933\n```\n\n---"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 7, "depth": 3, "title": "author_submitExtrinsic", "anchor": "author_submitextrinsic", "start_char": 3806, "end_char": 4210, "estimated_token_count": 126, "token_estimator": "heuristic-v1", "text": "### author_submitExtrinsic\n\nSubmits a signed extrinsic (transaction) to the node.\n\n**Parameters:**\n\n- `extrinsic` *(string)* – The SCALE-encoded, signed extrinsic (transaction).\n\n**Example:**\n\n```bash title=\"author_submitExtrinsic\"\ncurl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"author_submitExtrinsic\", \"params\":[\"0x...\"]}' \\\n    http://localhost:9933\n```\n\n---"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 8, "depth": 3, "title": "state_getMetadata", "anchor": "state_getmetadata", "start_char": 4210, "end_char": 4541, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "### state_getMetadata\n\nFetches the runtime metadata (needed for decoding storage and extrinsics).\n\n**Parameters:**\n\nNone.\n\n**Example:**\n\n```bash title=\"state_getMetadata\"\ncurl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"state_getMetadata\", \"params\":[]}' \\\n    http://localhost:9933\n```\n\n---"}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 9, "depth": 2, "title": "Check Available RPC Calls", "anchor": "check-available-rpc-calls", "start_char": 4541, "end_char": 4938, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Check Available RPC Calls\n\nTo check all the RPC methods exposed by your node, you can use the `rpc_methods` call to get a comprehensive list of available methods. This is particularly useful when working with different chain implementations or custom runtimes that may have additional RPC endpoints. You can do this via [`curl`](#using-curl) or the [Polkadot.Js Apps](#using-polkadotjs-apps)."}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 10, "depth": 3, "title": "Using curl", "anchor": "using-curl", "start_char": 4938, "end_char": 5279, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Using curl\n\nTo check the available RPC methods using `curl`, you can use the following command:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n  -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"rpc_methods\", \"params\":[]}' \\\n  https://rpc.polkadot.io\n```\n\nYou can replace `https://rpc.polkadot.io` with the node endpoint you need to query."}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 11, "depth": 3, "title": "Using Polkadot.js Apps", "anchor": "using-polkadotjs-apps", "start_char": 5279, "end_char": 6118, "estimated_token_count": 251, "token_estimator": "heuristic-v1", "text": "### Using Polkadot.js Apps\n\n1. Go to the [Polkadot.js Apps UI](https://polkadot.js.org/apps){target=\\_blank} and navigate to the RPC calls section.\n\n    ![](/images/develop/toolkit/parachains/rpc-calls/rpc-calls-01.webp)\n\n2. Select **`rpc`** from the dropdown menu.\n\n    ![](/images/develop/toolkit/parachains/rpc-calls/rpc-calls-02.webp)\n\n3. Choose the **`methods`** method.\n\n    ![](/images/develop/toolkit/parachains/rpc-calls/rpc-calls-03.webp)\n\n4. Submit the call to get a list of all available RPC methods.\n\n    ![](/images/develop/toolkit/parachains/rpc-calls/rpc-calls-04.webp)\n\nThis will return a JSON response containing all the RPC methods supported by your node.\n\n![](/images/develop/toolkit/parachains/rpc-calls/rpc-calls-05.webp)\n\nFrom this interface, you can also query the RPC methods directly, as you would do with curl."}
{"page_id": "develop-toolkit-parachains-rpc-calls", "index": 12, "depth": 2, "title": "Resources", "anchor": "resources", "start_char": 6118, "end_char": 6496, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Resources\n\n- [Polkadot JSON-RPC API Reference](https://polkadot.js.org/docs/substrate/rpc/){target=\\_blank}\n- [Parity DevOps: Important Flags for Running an RPC Node](https://paritytech.github.io/devops-guide/guides/rpc_index.html?#important-flags-for-running-an-rpc-node){target=\\_blank}\n- [Polkadot.js Apps RPC Explorer](https://polkadot.js.org/apps/#/rpc){target=\\_blank}"}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 15, "end_char": 767, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nZombienet is a robust testing framework designed for Polkadot SDK-based blockchain networks. It enables developers to efficiently deploy and test ephemeral blockchain environments on platforms like Kubernetes, Podman, and native setups. With its simple and versatile CLI, Zombienet provides an all-in-one solution for spawning networks, running tests, and validating performance.\n\nThis guide will outline the different installation methods for Zombienet, provide step-by-step instructions for setting up on various platforms, and highlight essential provider-specific features and requirements.\n\nBy following this guide, Zombienet will be up and running quickly, ready to streamline your blockchain testing and development workflows."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 1, "depth": 2, "title": "Install Zombienet", "anchor": "install-zombienet", "start_char": 767, "end_char": 5021, "estimated_token_count": 901, "token_estimator": "heuristic-v1", "text": "## Install Zombienet\n\nZombienet releases are available on the [Zombienet repository](https://github.com/paritytech/zombienet){target=\\_blank}.\n\nMultiple options are available for installing Zombienet, depending on the user's preferences and the environment where it will be used. The following section will guide you through the installation process for each option.\n\n=== \"Use the executable\"\n\n    Install Zombienet using executables by visiting the [latest release](https://github.com/paritytech/zombienet/releases){target=\\_blank} page and selecting the appropriate asset for your operating system. You can download the executable and move it to a directory in your PATH. \n\n    Each release includes executables for Linux and macOS. Executables are generated using [pkg](https://github.com/vercel/pkg){target=\\_blank}, which allows the Zombienet CLI to operate without requiring Node.js to be installed. \n\n    Then, ensure the downloaded file is executable:\n\n    ```bash\n    chmod +x zombienet-macos-arm64\n    ```\n\n    Finally, you can run the following command to check if the installation was successful. If so, it will display the version of the installed Zombienet:\n\n    ```bash\n    ./zombienet-macos-arm64 version\n    ```\n\n    If you want to add the `zombienet` executable to your PATH, you can move it to a directory in your PATH, such as `/usr/local/bin`:\n\n    ```bash\n    mv zombienet-macos-arm64 /usr/local/bin/zombienet\n    ```\n\n    Now you can refer to the `zombienet` executable directly.\n\n    ```bash\n    zombienet version\n    ```\n\n=== \"Use Nix\"\n\n    For Nix users, the Zombienet repository provides a [`flake.nix`](https://github.com/paritytech/zombienet/blob/main/flake.nix){target=\\_blank} file to install Zombienet making it easy to incorporate Zombienet into Nix-based projects.\n    \n    To install Zombienet utilizing Nix, users can run the following command, triggering the fetching of the flake and subsequently installing the Zombienet package:\n\n    ```bash\n    nix run github:paritytech/zombienet/INSERT_ZOMBIENET_VERSION -- \\\n    spawn INSERT_ZOMBIENET_CONFIG_FILE_NAME.toml\n    ```\n\n    Replace the `INSERT_ZOMBIENET_VERSION` with the desired version of Zombienet and the `INSERT_ZOMBIENET_CONFIG_FILE_NAME` with the name of the configuration file you want to use.\n\n    To run the command above, you need to have [Flakes](https://nixos.wiki/wiki/Flakes#Enable_flakes){target=\\_blank} enabled.\n\n    Alternatively, you can also include the Zombienet binary in the PATH for the current shell using the following command:\n    \n    ```bash\n    nix shell github:paritytech/zombienet/INSERT_ZOMBIENET_VERSION\n    ```\n\n=== \"Use Docker\"\n\n    Zombienet can also be run using Docker. The Zombienet repository provides a Docker image that can be used to run the Zombienet CLI. To run Zombienet using Docker, you can use the following command:\n\n    ```bash\n    docker run -it --rm \\\n    -v $(pwd):/home/nonroot/zombie-net/host-current-files \\\n    paritytech/zombienet\n    ```\n\n    The command above will run the Zombienet CLI inside a Docker container and mount the current directory to the `/home/nonroot/zombie-net/host-current-files` directory. This allows Zombienet to access the configuration file and other files in the current directory. If you want to mount a different directory, replace `$(pwd)` with the desired directory path.\n\n    Inside the Docker container, you can run the Zombienet CLI commands. First, you need to set up Zombienet to download the necessary binaries:\n\n    ```bash\n    npm run zombie -- setup polkadot polkadot-parachain\n    ```\n\n    After that, you need to add those binaries to the PATH:\n\n    ```bash\n    export PATH=/home/nonroot/zombie-net:$PATH\n    ```\n\n    Finally, you can run the Zombienet CLI commands. For example, to spawn a network using a specific configuration file, you can run the following command:\n\n    ```bash\n    npm run zombie -- -p native spawn host-current-files/minimal.toml\n    ```\n\n    The command above mounts the current directory to the `/workspace` directory inside the Docker container, allowing Zombienet to access the configuration file and other files in the current directory. If you want to mount a different directory, replace `$(pwd)` with the desired directory path."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 2, "depth": 2, "title": "Providers", "anchor": "providers", "start_char": 5021, "end_char": 5804, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "## Providers\n\nZombienet supports different backend providers for running the nodes. At this moment, [Kubernetes](https://kubernetes.io/){target=\\_blank}, [Podman](https://podman.io/){target=\\_blank}, and local providers are supported, which can be declared as `kubernetes`, `podman`, or `native`, respectively.\n\nTo use a particular provider, you can specify it in the network file or use the `--provider` flag in the CLI:\n\n```bash\nzombienet spawn network.toml --provider INSERT_PROVIDER\n```\n\nAlternatively, you can set the provider in the network file:\n\n```toml\n[settings]\nprovider = \"INSERT_PROVIDER\"\n...\n```\n\nIt's important to note that each provider has specific requirements and associated features. The following sections cover each provider's requirements and added features."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 3, "depth": 3, "title": "Kubernetes", "anchor": "kubernetes", "start_char": 5804, "end_char": 7333, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "### Kubernetes\n\nKubernetes is a portable, extensible, open-source platform for managing containerized workloads and services. Zombienet is designed to be compatible with a variety of Kubernetes clusters, including: \n\n- [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine){target=\\_blank}\n- [Docker Desktop](https://docs.docker.com/desktop/features/kubernetes/){target=\\_blank}\n- [kind](https://kind.sigs.k8s.io/){target=\\_blank}\n\n#### Requirements\n    \nTo effectively interact with your cluster, you'll need to ensure that [`kubectl`](https://kubernetes.io/docs/reference/kubectl/){target=\\_blank} is installed on your system. This Kubernetes command-line tool allows you to run commands against Kubernetes clusters. If you don't have `kubectl` installed, you can follow the instructions provided in the [Kubernetes documentation](https://kubernetes.io/docs/tasks/tools/#kubectl){target=\\_blank}.\n\nTo create resources such as namespaces, pods, and CronJobs within the target cluster, you must grant your user or service account the appropriate permissions. These permissions are essential for managing and deploying applications effectively within Kubernetes.\n\n#### Features\n    \nIf available, Zombienet uses the Prometheus operator to oversee monitoring and visibility. This configuration ensures that only essential networking-related pods are deployed. Using the Prometheus operator, Zombienet improves its ability to monitor and manage network activities within the Kubernetes cluster efficiently."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 4, "depth": 3, "title": "Podman", "anchor": "podman", "start_char": 7333, "end_char": 8929, "estimated_token_count": 374, "token_estimator": "heuristic-v1", "text": "### Podman\n\nPodman is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers and container images on Linux-based systems. Zombienet supports Podman rootless as a provider on Linux machines. Although Podman has support for macOS through an internal virtual machine (VM), the Zombienet provider code requires Podman to run natively on Linux.\n\n#### Requirements\n     \nTo use Podman as a provider, you need to have Podman installed on your system. You can install Podman by following the instructions provided on the [Podman website](https://podman.io/getting-started/installation){target=\\_blank}.\n\n#### Features\n    \nUsing Podman, Zombienet deploys additional pods to enhance the monitoring and visibility of the active network. Specifically, pods for [Prometheus](https://prometheus.io/){target=\\_blank}, [Tempo](https://grafana.com/docs/tempo/latest/operations/monitor/){target=\\_blank}, and [Grafana](https://grafana.com/){target=\\_blank} are included in the deployment. Grafana is configured with Prometheus and Tempo as data sources.\n\nUpon launching Zombienet, access to these monitoring services is facilitated through specific URLs provided in the output:\n\n- **Prometheus**: `http://127.0.0.1:34123`\n- **Tempo**: `http://127.0.0.1:34125`\n- **Grafana**: `http://127.0.0.1:41461`\n\nIt's important to note that Grafana is deployed with default administrator access. \n    \nWhen network operations cease, either from halting a running spawn with the `Ctrl+C` command or test completion, Zombienet automatically removes all associated pods."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 5, "depth": 3, "title": "Local Provider", "anchor": "local-provider", "start_char": 8929, "end_char": 10889, "estimated_token_count": 420, "token_estimator": "heuristic-v1", "text": "### Local Provider\n\nThe Zombienet local provider, also called native, enables you to run nodes as local processes in your environment.\n\n#### Requirements\n     \nYou must have the necessary binaries for your network (such as `polkadot` and `polkadot-parachain`). These binaries should be available in your PATH, allowing Zombienet to spawn the nodes as local processes.\n\nTo install the necessary binaries, you can use the Zombienet CLI command:\n\n```bash\nzombienet setup polkadot polkadot-parachain\n```\n\nThis command will download and prepare the necessary binaries for Zombienet's use.\n\nIf you need to use a custom binary, ensure the binary is available in your PATH. You can also specify the binary path in the network configuration file. The following example uses the custom [OpenZeppelin template](https://github.com/OpenZeppelin/polkadot-runtime-templates){target=\\_blank}:\n\nFirst, clone the OpenZeppelin template repository using the following command:\n\n```bash\ngit clone https://github.com/OpenZeppelin/polkadot-runtime-templates \\\n&& cd polkadot-runtime-templates/generic-template\n```\n\nNext, run the command to build the custom binary:\n\n```bash\ncargo build --release\n```\n\nFinally, add the custom binary to your PATH as follows:\n\n```bash\nexport PATH=$PATH:INSERT_PATH_TO_RUNTIME_TEMPLATES/parachain-template-node/target/release\n```\n\nAlternatively, you can specify the binary path in the network configuration file. The local provider exclusively utilizes the command configuration for nodes, which supports both relative and absolute paths. You can employ the `default_command` configuration to specify the binary for spawning all nodes in the relay chain.\n\n```toml\n[relaychain]\nchain = \"rococo-local\"\ndefault_command = \"./bin-v1.6.0/polkadot\"\n\n[parachain]\nid = 1000\n\n    [parachain.collators]\n    name = \"collator01\"\n    command = \"./target/release/parachain-template-node\"\n```\n\n#### Features\n\nThe local provider does not offer any additional features."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 6, "depth": 2, "title": "Configure Zombienet", "anchor": "configure-zombienet", "start_char": 10889, "end_char": 11501, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Configure Zombienet\n\nEffective network configuration is crucial for deploying and managing blockchain systems. Zombienet simplifies this process by offering versatile configuration options in both JSON and TOML formats. Whether setting up a simple test network or a complex multi-node system, Zombienet's tools provide the flexibility to customize every aspect of your network's setup.\n\nThe following sections will explore the structure and usage of Zombienet configuration files, explain key settings for network customization, and walk through CLI commands and flags to optimize your development workflow."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 7, "depth": 3, "title": "Configuration Files", "anchor": "configuration-files", "start_char": 11501, "end_char": 11979, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "### Configuration Files\n\nThe network configuration file can be either JSON or TOML format. The Zombienet repository also provides a collection of [example configuration files](https://github.com/paritytech/zombienet/tree/main/examples){target=\\_blank} that can be used as a reference.\n\nEach section may include provider-specific keys that aren't recognized by other providers. For example, if you use the local provider, any references to images for nodes will be disregarded."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 8, "depth": 3, "title": "CLI Usage", "anchor": "cli-usage", "start_char": 11979, "end_char": 13771, "estimated_token_count": 502, "token_estimator": "heuristic-v1", "text": "### CLI Usage\n\nZombienet provides a CLI that allows interaction with the tool. The CLI can receive commands and flags to perform different kinds of operations. These operations use the following syntax:\n\n```bash\nzombienet <arguments> <commands>\n```\n\nThe following sections will guide you through the primary usage of the Zombienet CLI and the available commands and flags.\n\n#### CLI Commands\n\n- **`spawn <networkConfig>`**: Spawn the network defined in the [configuration file](#configuration-files).\n- **`test <testFile>`**: Run tests on the spawned network using the assertions and tests defined in the [test file](/develop/toolkit/parachains/spawn-chains/zombienet/write-tests/#the-test-file){target=\\_blank}.\n- **`setup <binaries>`**: Set up the Zombienet development environment to download and use the `polkadot` or `polkadot-parachain` executable.\n- **`convert <filePath>`**: Transforms a [polkadot-launch](https://github.com/paritytech/polkadot-launch){target=\\_blank} configuration file with a `.js` or `.json` extension into a Zombienet configuration file.\n- **`version`**: Prints Zombienet version.\n- **`help`**: Prints help information.\n\n#### CLI Flags\n\nYou can use the following flags to customize the behavior of the CLI:\n\n- **`-p`, `--provider`**: Override the [provider](#providers) to use.\n- **`-d`, `--dir`**: Specify a directory path for placing the network files instead of using the default temporary path.\n- **`-f`, `--force`**: Force override all prompt commands.\n- **`-l`, `--logType`**: Type of logging on the console. Defaults to `table`.\n- **`-m`, `--monitor`**: Start as monitor and don't auto clean up network.\n- **`-c`, `--spawn-concurrency`**: Number of concurrent spawning processes to launch. Defaults to `1`.\n- **`-h`, `--help`**: Display help for command."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 9, "depth": 3, "title": "Settings", "anchor": "settings", "start_char": 13771, "end_char": 16910, "estimated_token_count": 868, "token_estimator": "heuristic-v1", "text": "### Settings\n\nThrough the keyword `settings`, it's possible to define the general settings for the network. The available keys are:\n\n- **`global_volumes?`** ++\"GlobalVolume[]\"++: A list of global volumes to use.\n\n    ??? child \"`GlobalVolume` interface definition\"\n        ```js\n        export interface GlobalVolume {\n          name: string;\n          fs_type: string;\n          mount_path: string;\n        }\n        ```\n\n- **`bootnode`** ++\"boolean\"++: Add bootnode to network. Defaults to `true`.\n- **`bootnode_domain?`** ++\"string\"++: Domain to use for bootnode.\n- **`timeout`** ++\"number\"++: Global timeout to use for spawning the whole network.\n- **`node_spawn_timeout?`** ++\"number\"++: Timeout to spawn pod/process.\n- **`grafana?`** ++\"boolean\"++: Deploy an instance of Grafana.\n- **`prometheus?`** ++\"boolean\"++: Deploy an instance of Prometheus.\n- **`telemetry?`** ++\"boolean\"++: Enable telemetry for the network.\n- **`jaeger_agent?`** ++\"string\"++: The Jaeger agent endpoint passed to the nodes. Only available on Kubernetes.\n- **`tracing_collator_url?`** ++\"string\"++: The URL of the tracing collator used to query by the tracing assertion. Should be tempo query compatible.\n- **`tracing_collator_service_name?`** ++\"string\"++: Service name for tempo query frontend. Only available on Kubernetes. Defaults to `tempo-tempo-distributed-query-frontend`.\n- **`tracing_collator_service_namespace?`** ++\"string\"++: Namespace where tempo is running. Only available on Kubernetes. Defaults to `tempo`.\n- **`tracing_collator_service_port?`** ++\"number\"++: Port of the query instance of tempo. Only available on Kubernetes. Defaults to `3100`.\n- **`enable_tracing?`** ++\"boolean\"++: Enable the tracing system. Only available on Kubernetes. Defaults to `true`.\n- **`provider`** ++\"string\"++: Provider to use. Default is `kubernetes`\".\n- **`polkadot_introspector?`** ++\"boolean\"++: Deploy an instance of polkadot-introspector. Only available on Podman and Kubernetes. Defaults to `false`.\n- **`backchannel?`** ++\"boolean\"++: Deploy an instance of backchannel server. Only available on Kubernetes. Defaults to `false`.\n- **`image_pull_policy?`** ++\"string\"++: Image pull policy to use in the network. Possible values are `Always`, `IfNotPresent`, and `Never`.\n- **`local_ip?`** ++\"string\"++: IP used for exposing local services (rpc/metrics/monitors). Defaults to `\"127.0.0.1\"`.\n- **`global_delay_network_global_settings?`** ++\"number\"++: Delay in seconds to apply to the network.\n- **`node_verifier?`** ++\"string\"++: Specify how to verify node readiness or deactivate by using `None`. Possible values are `None` and `Metric`. Defaults to `Metric`.\n\nFor example, the following configuration file defines a minimal example for the settings:\n\n=== \"TOML\"\n\n    ```toml title=\"base-example.toml\"\n    -[settings]\ntimeout = 1000\nbootnode = false\nprovider = \"kubernetes\"\nbackchannel = false\n# ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"base-example.json\"\n    -{\n    \"settings\": {\n        \"timeout\": 1000,\n        \"bootnode\": false,\n        \"provider\": \"kubernetes\",\n        \"backchannel\": false,\n        \"...\": {}\n    },\n    \"...\": {}\n}\n\n    ```"}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 10, "depth": 3, "title": "Relay Chain Configuration", "anchor": "relay-chain-configuration", "start_char": 16910, "end_char": 28208, "estimated_token_count": 2798, "token_estimator": "heuristic-v1", "text": "### Relay Chain Configuration\n\nYou can use the `relaychain` keyword to define further parameters for the relay chain at start-up. The available keys are:\n\n- **`default_command?`** ++\"string\"++: The default command to run. Defaults to `polkadot`.\n- **`default_image?`** ++\"string\"++: The default Docker image to use.\n- **`default_resources?`** ++\"Resources\"++: Represents the resource limits/reservations the nodes need by default. Only available on Kubernetes.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`default_db_snapshot?`** ++\"string\"++: The default database snapshot to use.\n- **`default_prometheus_prefix`** ++\"string\"++: A parameter for customizing the metric's prefix. Defaults to `substrate`.\n- **`default_substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`default_keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`chain`** ++\"string\"++: The chain name.\n- **`chain_spec_path?`** ++\"string\"++: Path to the chain spec file. Should be the plain version to allow customizations.\n- **`chain_spec_command?`** ++\"string\"++: Command to generate the chain spec. It can't be used in combination with `chain_spec_path`.\n- **`default_args?`** ++\"string[]\"++: An array of arguments to use as default to pass to the command.\n- **`default_overrides?`** ++\"Override[]\"++: An array of overrides to upload to the node.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        } \n        ```\n\n- **`random_nominators_count?`** ++\"number\"++: If set and the stacking pallet is enabled, Zombienet will generate the input quantity of nominators and inject them into the genesis.\n- **`max_nominations`** ++\"number\"++: The max number of nominations allowed by a nominator. Should match the value set in the runtime. Defaults to `24`.\n- **`nodes?`** ++\"Node[]\"++: An array of nodes to spawn. It is further defined in the [Node Configuration](#node-configuration) section.\n- **`node_groups?`** ++\"NodeGroup[]\"++: An array of node groups to spawn. It is further defined in the [Node Group Configuration](#node-group-configuration) section.\n- **`total_node_in_group?`** ++\"number\"++: The total number of nodes in the group. Defaults to `1`.\n- **`genesis`** ++\"JSON\"++: The genesis configuration.\n- **`default_delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\n#### Node Configuration\n\nOne specific key capable of receiving more subkeys is the `nodes` key. This key is used to define further parameters for the nodes. The available keys:\n\n- **`name`** ++\"string\"++: Name of the node. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Override default Docker image to use for this node.\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`command_with_args?`** ++\"string\"++: Override default command and arguments.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n\n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`validator`** ++\"boolean\"++: Pass the `--validator` flag to the command. Defaults to `true`.\n- **`invulnerable`** ++\"boolean\"++: If true, add the node to invulnerables in the chain spec. Defaults to `false`.\n- **`balance`** ++\"number\"++: Balance to set in balances for node's account. Defaults to `2000000000000`.\n- **`bootnodes?`** ++\"string[]\"++: Array of bootnodes to use.\n- **`add_to_bootnodes?`** ++\"boolean\"++: Add this node to the bootnode list. Defaults to `false`.\n- **`ws_port?`** ++\"number\"++: WS port to use.\n- **`rpc_port?`** ++\"number\"++: RPC port to use.\n- **`prometheus_port?`** ++\"number\"++: Prometheus port to use.\n- **`p2p_cert_hash?`** ++\"string\"++: Libp2p certhash to use with webRTC transport.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\nThe following configuration file defines a minimal example for the relay chain, including the `nodes` key:\n\n=== \"TOML\"\n\n    ```toml title=\"relaychain-example-nodes.toml\"\n    -[relaychain]\ndefault_command = \"polkadot\"\ndefault_image = \"polkadot-debug:master\"\nchain = \"rococo-local\"\nchain_spec_path = \"INSERT_PATH_TO_CHAIN_SPEC\"\ndefault_args = [\"--chain\", \"rococo-local\"]\n\n[[relaychain.nodes]]\nname = \"alice\"\nvalidator = true\nbalance = 1000000000000\n\n[[relaychain.nodes]]\nname = \"bob\"\nvalidator = true\nbalance = 1000000000000\n# ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"relaychain-example-nodes.json\"\n    -{\n    \"relaychain\": {\n        \"default_command\": \"polkadot\",\n        \"default_image\": \"polkadot-debug:master\",\n        \"chain\": \"rococo-local\",\n        \"chain_spec_path\": \"INSERT_PATH_TO_CHAIN-SPEC.JSON\",\n        \"default_args\": [\"--chain\", \"rococo-local\"],\n        \"nodes\": [\n            {\n                \"name\": \"alice\",\n                \"validator\": true,\n                \"balance\": 1000000000000\n            },\n            {\n                \"name\": \"bob\",\n                \"validator\": true,\n                \"balance\": 1000000000000\n            }\n        ]\n    }\n}\n\n    ```\n\n#### Node Group Configuration\n\nThe `node_groups` key defines further parameters for the node groups. The available keys are:\n\n- **`name`** ++\"string\"++: Name of the node. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Override default Docker image to use for this node.\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n    \n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`overrides?`** ++\"Override[]\"++: Array of overrides definitions.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`count`** ++\"number | string\"++: Number of nodes to launch for this group.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\nThe following configuration file defines a minimal example for the relay chain, including the `node_groups` key:\n\n=== \"TOML\"\n\n    ```toml title=\"relaychain-example-node-groups.toml\"\n    -[relaychain]\ndefault_command = \"polkadot\"\ndefault_image = \"polkadot-debug:master\"\nchain = \"rococo-local\"\nchain_spec_path = \"INSERT_PATH_TO_CHAIN_SPEC\"\ndefault_args = [\"--chain\", \"rococo-local\"]\n\n[[relaychain.node_groups]]\nname = \"group-1\"\ncount = 2\nimage = \"polkadot-debug:master\"\ncommand = \"polkadot\"\nargs = [\"--chain\", \"rococo-local\"]\n# ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"relaychain-example-node-groups.json\"\n    -{\n    \"relaychain\": {\n        \"default_command\": \"polkadot\",\n        \"default_image\": \"polkadot-debug:master\",\n        \"chain\": \"rococo-local\",\n        \"chain_spec_path\": \"INSERT_PATH_TO_CHAIN-SPEC.JSON\",\n        \"default_args\": [\"--chain\", \"rococo-local\"],\n        \"node_groups\": [\n            {\n                \"name\": \"group-1\",\n                \"count\": 2,\n                \"image\": \"polkadot-debug:master\",\n                \"command\": \"polkadot\",\n                \"args\": [\"--chain\", \"rococo-local\"]\n            }\n        ],\n        \"...\": {}\n    },\n    \"...\": {}\n}\n\n    ```"}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 11, "depth": 3, "title": "Parachain Configuration", "anchor": "parachain-configuration", "start_char": 28208, "end_char": 39099, "estimated_token_count": 2722, "token_estimator": "heuristic-v1", "text": "### Parachain Configuration\n\nThe `parachain` keyword defines further parameters for the parachain. The available keys are:\n\n- **`id`** ++\"number\"++: The id to assign to this parachain. Must be unique.\n- **`chain?`** ++\"string\"++: The chain name.\n- **`force_decorator?`** ++\"string\"++: Force the use of a specific decorator.\n- **`genesis?`** ++\"JSON\"++: The genesis configuration.\n- **`balance?`** ++\"number\"++: Balance to set in balances for parachain's account.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\n- **`add_to_genesis?`** ++\"boolean\"++: Flag to add parachain to genesis or register in runtime. Defaults to `true`.\n- **`register_para?`** ++\"boolean\"++: Flag to specify whether the para should be registered. The `add_to_genesis` flag must be set to false for this flag to have any effect. Defaults to `true`.\n- **`onboard_as_parachain?`** ++\"boolean\"++: Flag to specify whether the para should be onboarded as a parachain, rather than remaining a parathread. Defaults to `true`.\n- **`genesis_wasm_path?`** ++\"string\"++: Path to the Wasm file to use.\n- **`genesis_wasm_generator?`** ++\"string\"++: Command to generate the Wasm file.\n- **`genesis_state_path?`** ++\"string\"++: Path to the state file to use.\n- **`genesis_state_generator?`** ++\"string\"++: Command to generate the state file.\n- **`chain_spec_path?`** ++\"string\"++: Path to the chain spec file.\n- **`chain_spec_command?`** ++\"string\"++: Command to generate the chain spec.\n- **`cumulus_based?`** ++\"boolean\"++: Flag to use cumulus command generation. Defaults to `true`.\n- **`bootnodes?`** ++\"string[]\"++: Array of bootnodes to use.\n- **`prometheus_prefix?`** ++\"string\"++: Parameter for customizing the metric's prefix for all parachain nodes/collators. Defaults to `substrate`.\n- **`collator?`** ++\"Collator\"++: Further defined in the [Collator Configuration](#collator-configuration) section.\n- **`collator_groups?`** ++\"CollatorGroup[]\"++: An array of collator groups to spawn. It is further defined in the [Collator Groups Configuration](#collator-groups-configuration) section.\n \nFor example, the following configuration file defines a minimal example for the parachain:\n\n=== \"TOML\"\n\n    ```toml title=\"parachain-example.toml\"\n    -[parachain]\nid = 100\nadd_to_genesis = true\ncumulus_based = true\ngenesis_wasm_path = \"INSERT_PATH_TO_WASM\"\ngenesis_state_path = \"INSERT_PATH_TO_STATE\"\n# ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"parachain-example.json\"\n    -{\n    \"parachain\": {\n        \"id\": 100,\n        \"add_to_genesis\": true,\n        \"cumulus_based\": true,\n        \"genesis_wasm_path\": \"INSERT_PATH_TO_WASM\",\n        \"genesis_state_path\": \"INSERT_PATH_TO_STATE\",\n        \"...\": {}\n    },\n    \"...\": {}\n}\n\n    ```\n\n#### Collator Configuration\n\nOne specific key capable of receiving more subkeys is the `collator` key. This key defines further parameters for the nodes. The available keys are:\n\n- **`name`** ++\"string\"++: Name of the collator. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Image to use for the collator.\n- **`command_with_args?`** ++\"string\"++: Overrides both command and arguments for the collator.\n- **`validator`** ++\"boolean\"++: Pass the `--validator` flag to the command. Defaults to `true`.\n- **`invulnerable`** ++\"boolean\"++: If true, add the collator to invulnerables in the chain spec. Defaults to `false`.\n- **`balance`** ++\"number\"++: Balance to set in balances for collator's account. Defaults to `2000000000000`.\n- **`bootnodes?`** ++\"string[]\"++: Array of bootnodes to use.\n- **`add_to_bootnodes?`** ++\"boolean\"++: Add this collator to the bootnode list. Defaults to `false`.\n- **`ws_port?`** ++\"number\"++: WS port to use.\n- **`rpc_port?`** ++\"number\"++: RPC port to use.\n- **`prometheus_port?`** ++\"number\"++: Prometheus port to use.\n- **`p2p_port?`** ++\"number\"++: P2P port to use.\n- **`p2p_cert_hash?`** ++\"string\"++: Libp2p certhash to use with webRTC transport.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n\n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`overrides?`** ++\"Override[]\"++: Array of overrides definitions.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n\nThe configuration file below defines a minimal example for the collator:\n\n=== \"TOML\"\n\n    ```toml title=\"collator-example.toml\"\n    -[parachain]\nid = 100\nadd_to_genesis = true\ncumulus_based = true\ngenesis_wasm_path = \"INSERT_PATH_TO_WASM\"\ngenesis_state_path = \"INSERT_PATH_TO_STATE\"\n\n[[parachain.collators]]\nname = \"alice\"\nimage = \"polkadot-parachain\"\ncommand = \"polkadot-parachain\"\n# ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"collator-example.json\"\n    -{\n    \"parachain\": {\n        \"id\": 100,\n        \"add_to_genesis\": true,\n        \"cumulus_based\": true,\n        \"genesis_wasm_path\": \"INSERT_PATH_TO_WASM\",\n        \"genesis_state_path\": \"INSERT_PATH_TO_STATE\",\n        \"collators\": [\n            {\n                \"name\": \"alice\",\n                \"image\": \"polkadot-parachain\",\n                \"command\": \"polkadot-parachain\",\n                \"...\": {}\n            }\n        ]\n    },\n    \"...\": {}\n}\n\n    ```\n\n#### Collator Groups Configuration\n\nThe `collator_groups` key defines further parameters for the collator groups. The available keys are:\n\n- **`name`** ++\"string\"++: Name of the node. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Override default Docker image to use for this node.\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n\n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`overrides?`** ++\"Override[]\"++: Array of overrides definitions.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`count`** ++\"number | string\"++: Number of nodes to launch for this group.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\nFor instance, the configuration file below defines a minimal example for the collator groups:\n\n=== \"TOML\"\n\n    ```toml title=\"collator-groups-example.toml\"\n    -[parachain]\nid = 100\nadd_to_genesis = true\ncumulus_based = true\ngenesis_wasm_path = \"INSERT_PATH_TO_WASM\"\ngenesis_state_path = \"INSERT_PATH_TO_STATE\"\n\n[[parachain.collator_groups]]\nname = \"group-1\"\ncount = 2\nimage = \"polkadot-parachain\"\ncommand = \"polkadot-parachain\"\n# ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"collator-groups-example.json\"\n    -{\n    \"parachain\": {\n        \"id\": 100,\n        \"add_to_genesis\": true,\n        \"cumulus_based\": true,\n        \"genesis_wasm_path\": \"INSERT_PATH_TO_WASM\",\n        \"genesis_state_path\": \"INSERT_PATH_TO_STATE\",\n        \"collator_groups\": [\n            {\n                \"name\": \"group-1\",\n                \"count\": 2,\n                \"image\": \"polkadot-parachain\",\n                \"command\": \"polkadot-parachain\",\n                \"...\": {}\n            }\n        ]\n    },\n    \"...\": {}\n}\n\n    ```"}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 12, "depth": 3, "title": "XCM Configuration", "anchor": "xcm-configuration", "start_char": 39099, "end_char": 40030, "estimated_token_count": 206, "token_estimator": "heuristic-v1", "text": "### XCM Configuration\n\nYou can use the `hrmp_channels` keyword to define further parameters for the XCM channels at start-up. The available keys are:\n\n- **`hrmp_channels`** ++\"HrmpChannelsConfig[]\"++: Array of Horizontal Relay-routed Message Passing (HRMP) channel configurations.\n\n    ??? child \"`HrmpChannelsConfig` interface definition\"\n        ```js\n        export interface HrmpChannelsConfig {\n          sender: number;\n          recipient: number;\n          max_capacity: number;\n          max_message_size: number;\n        }\n        ```\n        Each of the `HrmpChannelsConfig` keys are defined as follows:\n\n        - **`sender` ++\"number\"++**: Parachain ID of the sender.\n        - **`recipient` ++\"number\"++**: Parachain ID of the recipient.\n        - **`max_capacity` ++\"number\"++**: Maximum capacity of the HRMP channel.\n        - **`max_message_size` ++\"number\"++**: Maximum message size allowed in the HRMP channel."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-get-started", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 40030, "end_char": 41044, "estimated_token_count": 254, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-  <span class=\"badge external\">External</span> __Zombienet Support__\n\n    ---\n\n    [Parity Technologies](https://www.parity.io/){target=\\_blank} has designed and developed this framework, now maintained by the Zombienet team. \n\n    For further support and information, refer to the following contact points:\n\n    [:octicons-arrow-right-24: Zombienet repository](https://github.com/paritytech/zombienet){target=\\_blank}\n\n    [:octicons-arrow-right-24: Element public channel](https://matrix.to/#/!FWyuEyNvIFygLnWNMh:parity.io?via=parity.io&via=matrix.org&via=web3.foundation){target=\\_blank}\n\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Spawn a Basic Chain with Zombienet__\n\n    ---\n\n    Learn to spawn, connect to and monitor a basic blockchain network with Zombienet, using customizable configurations for streamlined development and debugging.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/polkadot-sdk/testing/spawn-basic-chain/)\n\n</div>"}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 15, "end_char": 604, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nTesting is a critical step in blockchain development, ensuring reliability, performance, and security. Zombienet simplifies this process with its intuitive Domain Specific Language (DSL), enabling developers to write natural-language test scripts tailored to their network needs.\n\nThis guide provides an in-depth look at how to create and execute test scenarios using Zombienet's flexible testing framework. You’ll learn how to define tests for metrics, logs, events, and more, allowing for comprehensive evaluation of your blockchain network’s behavior and performance."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 1, "depth": 2, "title": "Testing DSL", "anchor": "testing-dsl", "start_char": 604, "end_char": 1990, "estimated_token_count": 303, "token_estimator": "heuristic-v1", "text": "## Testing DSL\n\nZombienet provides a Domain Specific Language (DSL) for writing tests. The DSL is designed to be human-readable and allows you to write tests using natural language expressions. You can define assertions and tests against the spawned network using this DSL. This way, users can evaluate different metrics, such as:\n\n- **On-chain storage**: The storage of each of the chains running via Zombienet.\n- **Metrics**: The metrics provided by the nodes.\n- **Histograms**: Visual representations of metrics data.\n- **Logs**: Detailed records of system activities and events.\n- **System events**: Notifications of significant occurrences within the network.\n- **Tracing**: Detailed analysis of execution paths and operations.\n- **Custom API calls (through Polkadot.js)**: Personalized interfaces for interacting with the network.\n- **Commands**: Instructions or directives executed by the network.\n\nThese abstractions are expressed by sentences defined in a natural language style. Therefore, each test line will be mapped to a test to run. Also, the test file (`*.zndsl`) includes pre-defined header fields used to define information about the suite, such as network configuration and credentials location.\n\nFor more details about the Zombienet DSL, see the [Testing DSL](https://paritytech.github.io/zombienet/cli/test-dsl-definition-spec.html){target=\\_blank} specification."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 2, "depth": 2, "title": "The Test File", "anchor": "the-test-file", "start_char": 1990, "end_char": 2874, "estimated_token_count": 221, "token_estimator": "heuristic-v1", "text": "## The Test File\n\nThe test file is a text file with the extension `.zndsl`. It is divided into two parts: the header and the body. The header contains the network configuration and the credentials to use, while the body contains the tests to run.\n\nThe header is defined by the following fields:\n\n- **`description`** ++\"string\"++: Long description of the test suite (optional).\n- **`network`** ++\"string\"++: Path to the network definition file, supported in both `.json` and `.toml` formats.\n- **`creds`** ++\"string\"++: Credentials filename or path to use (available only with Kubernetes provider). Looks in the current directory or `$HOME/.kube/` if a filename is passed.\n\nThe body contains the tests to run. Each test is defined by a sentence in the DSL, which is mapped to a test to run. Each test line defines an assertion or a command to be executed against the spawned network."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 3, "depth": 3, "title": "Name", "anchor": "name", "start_char": 2874, "end_char": 3176, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "### Name\n\nThe test name in Zombienet is derived from the filename by removing any leading numeric characters before the first hyphen. For example, a file named `0001-zombienet-test.zndsl` will result in a test name of `zombienet-test`, which will be displayed in the test report output of the runner."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 4, "depth": 3, "title": "Assertions", "anchor": "assertions", "start_char": 3176, "end_char": 6928, "estimated_token_count": 904, "token_estimator": "heuristic-v1", "text": "### Assertions\n\nAssertions are defined by sentences in the DSL that evaluate different metrics, such as on-chain storage, metrics, histograms, logs, system events, tracing, and custom API calls. Each assertion is defined by a sentence in the DSL, which is mapped to a test to run.\n\n- **`Well known functions`**: Already mapped test function.\n\n    === \"Syntax\"\n\n        `node-name well-known_defined_test [within x seconds]`\n\n    === \"Examples\"\n\n        ```bash\n        alice: is up\n        alice: parachain 100 is registered within 225 seconds\n        alice: parachain 100 block height is at least 10 within 250 seconds\n        \n        ```\n\n- **`Histogram`**: Get metrics from Prometheus, calculate the histogram, and assert on the target value.\n\n    === \"Syntax\"\n\n        `node-name reports histogram metric_name has comparator target_value samples in buckets [\"bucket\",\"bucket\",...] [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: reports histogram polkadot_pvf_execution_time has at least 2 samples in buckets [\"0.1\", \"0.25\", \"0.5\", \"+Inf\"] within 100 seconds\n        \n        ```\n\n- **`Metric`**: Get metric from Prometheus and assert on the target value.\n\n    === \"Syntax\"\n\n        `node-name reports metric_name comparator target_value (e.g \"is at least x\", \"is greater than x\") [within x seconds]`\n\n    === \"Examples\"\n\n        ```bash\n        alice: reports node_roles is 4\n        alice: reports sub_libp2p_is_major_syncing is 0\n        \n        ```\n\n- **`Log line`**: Get logs from nodes and assert on the matching pattern.\n\n    === \"Syntax\"\n\n        `node-name log line (contains|matches) (regex|glob) \"pattern\" [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: log line matches glob \"rted #1\" within 10 seconds\n        \n        ```\n\n- **`Count of log lines`**: Get logs from nodes and assert on the number of lines matching pattern.\n\n    === \"Syntax\"\n\n        `node-name count of log lines (containing|matching) (regex|glob) \"pattern\" [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: count of log lines matching glob \"rted #1\" within 10 seconds\n        ```\n\n- **`System events`**: Find a system event from subscription by matching a pattern.\n\n    === \"Syntax\"\n\n        `node-name system event (contains|matches)(regex| glob) \"pattern\" [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: system event matches \"\"paraId\":[0-9]+\" within 10 seconds\n        ```\n\n- **`Tracing`**: Match an array of span names from the supplied `traceID`.\n\n    === \"Syntax\"\n\n        `node-name trace with traceID contains [\"name\", \"name2\",...]`\n\n    === \"Example\"\n\n        ```bash\n        alice: trace with traceID 94c1501a78a0d83c498cc92deec264d9 contains [\"answer-chunk-request\", \"answer-chunk-request\"]\n        ```\n\n- **`Custom JS scripts`**: Run a custom JavaScript script and assert on the return value.\n\n    === \"Syntax\"\n\n        `node-name js-script script_relative_path [return is comparator target_value] [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: js-script ./0008-custom.js return is greater than 1 within 200 seconds\n        ```\n\n- **`Custom TS scripts`**: Run a custom TypeScript script and assert on the return value.\n\n    === \"Syntax\"\n\n        `node-name ts-script script_relative_path [return is comparator target_value] [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: ts-script ./0008-custom-ts.ts return is greater than 1 within 200 seconds\n        ```\n\n- **`Backchannel`**: Wait for a value and register to use.\n\n    === \"Syntax\"\n\n        `node-name wait for var name and use as X [within x seconds]`\n\n    === \"Example\"\n\n        ```bash\n        alice: wait for name and use as X within 30 seconds\n        ```"}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 5, "depth": 3, "title": "Commands", "anchor": "commands", "start_char": 6928, "end_char": 7347, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Commands\n\nCommands allow interaction with the nodes and can run pre-defined commands or an arbitrary command in the node. Commonly used commands are as follows:\n\n- **`restart`**: Stop the process and start again after the `X` amount of seconds or immediately.\n- **`pause`**: Pause (SIGSTOP) the process.\n- **`resume`**: Resume (SIGCONT) the process.\n- **`sleep`**: Sleep the test-runner for `x` amount of seconds."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 6, "depth": 2, "title": "Running a Test", "anchor": "running-a-test", "start_char": 7347, "end_char": 9214, "estimated_token_count": 447, "token_estimator": "heuristic-v1", "text": "## Running a Test\n\nTo run a test against the spawned network, you can use the [Zombienet DSL](#testing-dsl) to define the test scenario. Follow these steps to create an example test:\n\n1. Create a file named `spawn-a-basic-network-test.zndsl`.\n\n    ```bash\n    touch spawn-a-basic-network-test.zndsl\n    ```\n\n2. Add the following code to the file you just created.\n\n    ```toml title=\"spawn-a-basic-network-test.zndsl\"\n    -Description = \"Test the basic functionality of the network (minimal example)\"\nNetwork = \"./spawn-a-basic-network.toml\"\nCreds = \"config\"\n\n# Alice's tasks\n[[tasks]]\nname = \"alice\"\nis_up = true\nparachain_100_registered = { condition = \"within\", timeout = 225 }\nparachain_100_block_height = { condition = \"at least 10\", timeout = 250 }\n\n# Bob's tasks\n[[tasks]]\nname = \"bob\"\nis_up = true\nparachain_100_registered = { condition = \"within\", timeout = 225 }\nparachain_100_block_height = { condition = \"at least 10\", timeout = 250 }\n\n# Metrics\n[[metrics]]\nname = \"alice\"\nnode_roles = 4\nsub_libp2p_is_major_syncing = 0\n\n[[metrics]]\nname = \"bob\"\nnode_roles = 4\n\n[[metrics]]\nname = \"collator01\"\nnode_roles = 4\n\n    ```\n\nThis test scenario checks to verify the following:\n\n- Nodes are running.\n- The parachain with ID 100 is registered within a certain timeframe (255 seconds in this example).\n- Parachain block height is at least a certain number within a timeframe (in this case, 10 within 255 seconds).\n- Nodes are reporting metrics.\n\nYou can define any test scenario you need following the Zombienet DSL syntax.\n\nTo run the test, execute the following command:\n\n```bash\nzombienet -p native test spawn-a-basic-network-test.zndsl\n```\n\nThis command will execute the test scenario defined in the `spawn-a-basic-network-test.zndsl` file on the network. If successful, the terminal will display the test output, indicating whether the test passed or failed."}
{"page_id": "develop-toolkit-parachains-spawn-chains-zombienet-write-tests", "index": 7, "depth": 2, "title": "Example Test Files", "anchor": "example-test-files", "start_char": 9214, "end_char": 11200, "estimated_token_count": 506, "token_estimator": "heuristic-v1", "text": "## Example Test Files\n\nThe following example test files define two tests, a small network test and a big network test. Each test defines a network configuration file and credentials to use.\n\nThe tests define assertions to evaluate the network’s metrics and logs. The assertions are defined by sentences in the DSL, which are mapped to tests to run.\n\n```toml title=\"small-network-test.zndsl\"\n-Description = \"Small Network test\"\nNetwork = \"./0000-test-config-small-network.toml\"\nCreds = \"config\"\n\n# Metrics\n[[metrics]]\nnode_roles = 4\nsub_libp2p_is_major_syncing = 0\n\n# Logs\n[[logs]]\nbob_log_line_glob = \"*rted #1*\"\nbob_log_line_regex = \"Imported #[0-9]+\"\n\n```\n\nAnd the second test file:\n\n```toml title=\"big-network-test.zndsl\"\n-Description = \"Big Network test\"\nNetwork = \"./0001-test-config-big-network.toml\"\nCreds = \"config\"\n\n# Metrics\n[[metrics]]\nnode_roles = 4\nsub_libp2p_is_major_syncing = 0\n\n# Logs\n[[logs]]\nbob_log_line_glob = \"*rted #1*\"\nbob_log_line_regex = \"Imported #[0-9]+\"\n\n# Custom JS script\n[[custom_scripts]]\nalice_js_script = { path = \"./0008-custom.js\", condition = \"return is greater than 1\", timeout = 200 }\n\n# Custom TS script\n[[custom_scripts]]\nalice_ts_script = { path = \"./0008-custom-ts.ts\", condition = \"return is greater than 1\", timeout = 200 }\n\n# Backchannel\n[[backchannel]]\nalice_wait_for_name = { use_as = \"X\", timeout = 30 }\n\n# Well-known functions\n[[functions]]\nalice_is_up = true\nalice_parachain_100_registered = { condition = \"within\", timeout = 225 }\nalice_parachain_100_block_height = { condition = \"at least 10\", timeout = 250 }\n\n# Histogram\n[[histogram]]\nalice_polkadot_pvf_execution_time = { min_samples = 2, buckets = [\n  \"0.1\",\n  \"0.25\",\n  \"0.5\",\n  \"+Inf\",\n], timeout = 100 }\n\n# System events\n[[system_events]]\nalice_system_event_matches = { pattern = \"\\\"paraId\\\":[0-9]+\", timeout = 10 }\n\n# Tracing\n[[tracing]]\nalice_trace = { traceID = \"94c1501a78a0d83c498cc92deec264d9\", contains = [\n  \"answer-chunk-request\",\n  \"answer-chunk-request\",\n] }\n\n```"}
{"page_id": "get-support-ai-ready-docs", "index": 0, "depth": 2, "title": "Download LLM Files", "anchor": "download-llm-files", "start_char": 443, "end_char": 5881, "estimated_token_count": 1468, "token_estimator": "heuristic-v1", "text": "## Download LLM Files\n\n| Category           | Description                                                                                                                                         | File                         | Actions                                                                                                                                                                                              |\n|--------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Index              | Navigation index of all Polkadot documentation pages.                                                                                               | `llms.txt`                   | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms.txt\" } [:octicons-download-16:](/llms.txt){ download=\"llms.txt\" }                                                                  |\n| Full Documentation | Full content of all documentation pages.                                                                                                            | `llms-full.txt`              | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-full.txt\" } [:octicons-download-16:](/llms-full.txt){ download=\"llms-full.txt\" }                                                   |\n| Basics             | Polkadot general knowledge base to provide context around overview and beginner level content.                                                      | `llms-basics.txt`            | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-basics.txt\" } [:octicons-download-16:](/llms-files/llms-basics.txt){ download=\"llms-basics.txt\" }                                  |\n| Reference          | Reference material including key functions and glossary.                                                                                            | `llms-reference.txt`         | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-reference.txt\"} [:octicons-download-16:](/llms-files/llms-reference.txt){ download=\"llms-reference.txt\" }                          |\n| Smart Contracts    | How to develop and deploy Solidity smart contracts on Polkadot Hub.                                                                                 | `llms-smart-contracts.txt`   | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-smart-contracts.txt\" } [:octicons-download-16:](/llms-files/llms-smart-contracts.txt){ download=\"llms-smart-contracts.txt\" }       |\n| Parachains         | How to guides related to building, customizing, deploying, and maintaining a parachain.                                                             | `llms-parachains.txt`        | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-parachains.txt\" } [:octicons-download-16:](/llms-files/llms-parachains.txt){ download=\"llms-parachains.txt\" }                      |\n| DApps              | Information and tutorials for application developers.                                                                                               | `llms-dapps.txt`             | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-dapps.txt\" } [:octicons-download-16:](/llms-files/llms-dapps.txt){ download=\"llms-dapps.txt\" }                                     |\n| Networks           | Information about the various Polkadot networks (Polkadot, Kusama, Westend, Paseo), their purposes, and how they fit into the development workflow. | `llms-networks.txt`          | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-networks.txt\" } [:octicons-download-16:](/llms-files/llms-networks.txt){ download=\"llms-networks.txt\" }                            |\n| Polkadot Protocol  | Polkadot's core architecture, including the relay chain, parachains, system chains, interoperability, and main actors.                              | `llms-polkadot-protocol.txt` | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-polkadot-protocol.txt\" } [:octicons-download-16:](/llms-files/llms-polkadot-protocol.txt){ download=\"llms-polkadot-protocol.txt\" } |\n| Infrastructure     | Operational aspects of supporting the Polkadot network including how to run a node or validator and staking mechanics.                              | `llms-infrastructure.txt`    | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-infrastructure.txt\" } [:octicons-download-16:](/llms-files/llms-infrastructure.txt){ download=\"llms-infrastructure.txt\" }          |\n| Tooling            | An overview of various development tools available for Polkadot development.                                                                        | `llms-tooling.txt`           | [:octicons-copy-16:](){ .llms data-action=\"copy\" data-value=\"llms-tooling.txt\" } [:octicons-download-16:](/llms-files/llms-tooling.txt){ download=\"llms-tooling.txt\" }                               |\n\n!!! note\n    The `llms-full.txt` file may exceed the input limits of some language models due to its size. If you encounter limitations, consider using the files by category."}
{"page_id": "get-support-explore-resources", "index": 0, "depth": 2, "title": "🧠 Stack Exchange", "anchor": "stack-exchange", "start_char": 178, "end_char": 403, "estimated_token_count": 53, "token_estimator": "heuristic-v1", "text": "## 🧠 Stack Exchange\n\n- Browse commonly asked technical questions.\n- Ask your own and get detailed responses from experienced devs.\n\n👉 **[Visit Polkadot Stack Exchange](https://substrate.stackexchange.com/){target=\\_blank}**"}
{"page_id": "get-support-explore-resources", "index": 1, "depth": 2, "title": "🧵 Reddit: r/Polkadot", "anchor": "reddit-rpolkadot", "start_char": 403, "end_char": 631, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "## 🧵 Reddit: r/Polkadot\n\n- General Polkadot discussions and community perspectives.\n- Developer questions are welcome — just tag them appropriately.\n\n👉 **[Visit r/Polkadot](https://www.reddit.com/r/Polkadot/){target=\\_blank}**"}
{"page_id": "get-support-explore-resources", "index": 2, "depth": 2, "title": "💬 Discord (Community Threads Only)", "anchor": "discord-community-threads-only", "start_char": 631, "end_char": 900, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## 💬 Discord (Community Threads Only)\n\n- Beyond the official support threads, most channels are community-driven.\n- Great place to connect with fellow builders and share insights.\n\n👉 **[Join the Polkadot Discord](https://polkadot-discord.w3f.tools/){target=\\_blank}**"}
{"page_id": "get-support-explore-resources", "index": 3, "depth": 2, "title": "🎥 YouTube: @PolkadotNetwork", "anchor": "youtube-polkadotnetwork", "start_char": 900, "end_char": 1098, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## 🎥 YouTube: @PolkadotNetwork\n\n- Developer tutorials\n- Ecosystem interviews\n- Event recordings and walkthroughs\n\n👉 **[Watch on YouTube](https://www.youtube.com/@PolkadotNetwork){target=\\_blank}**"}
{"page_id": "get-support-explore-resources", "index": 4, "depth": 2, "title": "Community-Led Platforms and Ecosystem Updates", "anchor": "community-led-platforms-and-ecosystem-updates", "start_char": 1098, "end_char": 1298, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Community-Led Platforms and Ecosystem Updates\n\nStay in sync with what's happening across the Polkadot ecosystem — from official announcements to community-driven insights and governance activity."}
{"page_id": "get-support-explore-resources", "index": 5, "depth": 3, "title": "🔷 X (Twitter): Official Accounts", "anchor": "x-twitter-official-accounts", "start_char": 1298, "end_char": 1717, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### 🔷 X (Twitter): Official Accounts\n\n- [@PolkadotDevs](https://twitter.com/PolkadotDevs){target=\\_blank}: Updates for developers\n- [@Polkadot](https://twitter.com/Polkadot){target=\\_blank}: Network-wide news\n- [@Kusamanetwork](https://twitter.com/kusamanetwork){target=\\_blank}: Kusama-specific updates\n- [@Web3Foundation](https://twitter.com/web3foundation){target=\\_blank}: Grants, research, and ecosystem programs"}
{"page_id": "get-support-explore-resources", "index": 6, "depth": 3, "title": "🔁 X (Twitter): Community Accounts", "anchor": "x-twitter-community-accounts", "start_char": 1717, "end_char": 1882, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "### 🔁 X (Twitter): Community Accounts\n\n- [@PolkadotDeploy](https://twitter.com/PolkadotDeploy){target=\\_blank}: News from the deployment portal and tooling updates"}
{"page_id": "get-support-explore-resources", "index": 7, "depth": 3, "title": "🗣️ Polkadot Forum", "anchor": "polkadot-forum", "start_char": 1882, "end_char": 2057, "estimated_token_count": 47, "token_estimator": "heuristic-v1", "text": "### 🗣️ Polkadot Forum\n\n- Join community discussions around the direction of the ecosystem.\n\n👉 **[Visit the Polkadot Forum](https://forum.polkadot.network/){target=\\_blank}**"}
{"page_id": "get-support-explore-resources", "index": 8, "depth": 3, "title": "🧑‍⚖️ Polkassembly: OpenGov", "anchor": "polkassembly-opengov", "start_char": 2057, "end_char": 2282, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "### 🧑‍⚖️ Polkassembly: OpenGov\n\n- Explore and vote on governance proposals for Polkadot and Kusama.\n- Help shape the future of the network.\n\n👉 **[Explore on Polkassembly](https://polkadot.polkassembly.io/){target=\\_blank}**"}
{"page_id": "get-support-explore-resources", "index": 9, "depth": 3, "title": "📸 Instagram", "anchor": "instagram", "start_char": 2282, "end_char": 2456, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### 📸 Instagram\n\n- **[@Polkadotnetwork](https://www.instagram.com/polkadotnetwork){target=\\_blank}**: Visual highlights from the ecosystem\n  _(Note: not developer-specific)_"}
{"page_id": "get-support-get-in-touch", "index": 0, "depth": 2, "title": "Need Help Fast?", "anchor": "need-help-fast", "start_char": 25, "end_char": 546, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "## Need Help Fast?\n  \nUse one of the channels below to get live technical support or ask questions.\n\n<div class=\"button-wrapper\" style=\"display: flex; justify-content: flex-start;\">\n  <a href=\"https://t.me/substratedevs\" class=\"md-button\" style=\"margin-right: 1rem; text-decoration: none;\">\n    Connect to Telegram\n  </a>\n  <a href=\"https://polkadot-discord.w3f.tools/\" class=\"md-button\" style=\"text-decoration: none;\">\n    Connect to Discord\n  </a>\n</div>\n\nPrefer to see all available channels? Below are your options."}
{"page_id": "get-support-get-in-touch", "index": 1, "depth": 2, "title": "📱 Telegram: Polkadot Developer Support", "anchor": "telegram-polkadot-developer-support", "start_char": 546, "end_char": 876, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## 📱 Telegram: Polkadot Developer Support\n\nThe fastest way to get support.\n\n- **Who’s there:** DevRel team and active developer community.\n- **Response time:** Within **2 business days (usually faster)**.\n- **Topics:** Any developer-related question is welcome.\n\n👉 **[Join Telegram](https://t.me/substratedevs){target=\\_blank}**"}
{"page_id": "get-support-get-in-touch", "index": 2, "depth": 2, "title": "🔌 Discord: Polkadot Official Server", "anchor": "discord-polkadot-official-server", "start_char": 876, "end_char": 1328, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## 🔌 Discord: Polkadot Official Server\n\nFocused support for smart contracts and general developer chat.\n\n- **Smart contracts:** Ask in `#solidity-smart-contracts` and `#ink_smart-contracts`.\n- **General developer support:** Ask in `#solidity-smart-contracts`.\n- **Response time:** Within **1 business day (usually faster)**.\n- **Other topics:** Community-led discussion only.\n\n👉 **[Join Discord](https://polkadot-discord.w3f.tools/){target=\\_blank}**"}
{"page_id": "get-support-get-in-touch", "index": 3, "depth": 2, "title": "🧬 Matrix: Polkadot Developer Support", "anchor": "matrix-polkadot-developer-support", "start_char": 1328, "end_char": 1949, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "## 🧬 Matrix: Polkadot Developer Support\n\nThis is the **support channel** staffed by engineers from **Parity**, **Web3 Foundation**, and **Polkadot DevRel**.\n\n- **Who’s there:** Parity, W3F, DevRel, and community contributors.\n- **Response time:** Within **1 business day (usually faster)**.\n- **Topics:** Full-spectrum developer support.\n- Bridged with Telegram (all messages synced).\n\n👉 **[Join Matrix](https://matrix.to/#/#substratedevs:matrix.org){target=\\_blank}**\n\n---\n\nNot sure where to start?  \n\n**Join [Telegram](#telegram-polkadot-developer-support)**: Let us know what you need, and we’ll help you get unstuck."}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 613, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBootnodes are essential for helping blockchain nodes discover peers and join the network. When a node starts, it needs to find other nodes, and bootnodes provide an initial point of contact. Once connected, a node can expand its peer connections and play its role in the network, like participating as a validator.\n\nThis guide will walk you through setting up a Polkadot bootnode, configuring P2P, WebSocket (WS), secure WSS connections, and managing network keys. You'll also learn how to test your bootnode to ensure it is running correctly and accessible to other nodes."}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 613, "end_char": 986, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you start, you need to have the following prerequisites:\n\n- Verify a working Polkadot (`polkadot`) binary is available on your machine.\n- Ensure you have nginx installed. Please refer to the [Installation Guide](https://nginx.org/en/docs/install.html){target=\\_blank} for help with installation if needed.\n- A VPS or other dedicated server setup."}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 2, "depth": 2, "title": "Accessing the Bootnode", "anchor": "accessing-the-bootnode", "start_char": 986, "end_char": 1573, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "## Accessing the Bootnode\n\nBootnodes must be accessible through three key channels to connect with other nodes in the network:\n\n- **P2P**: A direct peer-to-peer connection, set by.\n\n    ```bash\n\n    --listen-addr /ip4/0.0.0.0/tcp/INSERT_PORT\n\n    ```\n    \n    This is not enabled by default on non-validator nodes like archive RPC nodes.\n\n- **P2P/WS**: A WebSocket (WS) connection, also configured via `--listen-addr`.\n- **P2P/WSS**: A secure WebSocket (WSS) connection using SSL, often required for light clients. An SSL proxy is needed, as the node itself cannot handle certificates."}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 3, "depth": 2, "title": "Node Key", "anchor": "node-key", "start_char": 1573, "end_char": 2240, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "## Node Key\n\nA node key is the ED25519 key used by `libp2p` to assign your node an identity or peer ID. Generating a known node key for a bootnode is crucial, as it gives you a consistent key that can be placed in chain specifications as a known, reliable bootnode.\n\nStarting a node creates its node key in the `chains/INSERT_CHAIN/network/secret_ed25519` file.\n\nYou can create a node key using:\n\n ``` bash\n polkadot key generate-node-key\n ``` \n \nThis key can be used in the startup command line.\n\nIt is imperative that you backup the node key. If it is included in the `polkadot` binary, it is hardcoded into the binary, which must be recompiled to change the key."}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 4, "depth": 2, "title": "Running the Bootnode", "anchor": "running-the-bootnode", "start_char": 2240, "end_char": 3334, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "## Running the Bootnode\n\nA bootnode can be run as follows:\n\n ``` bash\n polkadot --chain polkadot \\\n --name dot-bootnode \\\n --listen-addr /ip4/0.0.0.0/tcp/30310 \\\n --listen-addr /ip4/0.0.0.0/tcp/30311/ws\n ```\n\nThis assigns the p2p to port 30310 and p2p/ws to port 30311. For the p2p/wss port, a proxy must be set up with a DNS name and a corresponding certificate. The following example is for the popular nginx server and enables p2p/wss on port 30312 by adding a proxy to the p2p/ws port 30311:\n\n``` conf title=\"/etc/nginx/sites-enabled/dot-bootnode\"\n-server {\n       listen       30312 ssl http2 default_server;\n       server_name  dot-bootnode.stakeworld.io;\n       root         /var/www/html;\n\n       ssl_certificate \"INSERT_YOUR_CERT\";\n       ssl_certificate_key \"INSERT_YOUR_KEY\";\n\n       location / {\n         proxy_buffers 16 4k;\n         proxy_buffer_size 2k;\n         proxy_pass http://localhost:30311;\n         proxy_http_version 1.1;\n         proxy_set_header Upgrade $http_upgrade;\n         proxy_set_header Connection \"Upgrade\";\n         proxy_set_header Host $host;\n   }\n\n}\n```"}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 5, "depth": 2, "title": "Testing Bootnode Connection", "anchor": "testing-bootnode-connection", "start_char": 3334, "end_char": 3728, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Testing Bootnode Connection\n\nIf the preceding node is running with DNS name `dot-bootnode.stakeworld.io`, which contains a proxy with a valid certificate and node-id `12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg` then the following commands should output `syncing 1 peers`.\n\n!!!tip\n    You can add `-lsub-libp2p=trace` on the end to get libp2p trace logging for debugging purposes."}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 6, "depth": 3, "title": "P2P", "anchor": "p2p", "start_char": 3728, "end_char": 3994, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### P2P\n\n```bash\npolkadot --chain polkadot \\\n--base-path /tmp/node \\\n--name \"Bootnode testnode\" \\\n--reserved-only \\\n--reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30310/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" \\\n--no-hardware-benchmarks\n```"}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 7, "depth": 3, "title": "P2P/WS", "anchor": "p2pws", "start_char": 3994, "end_char": 4266, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### P2P/WS\n\n```bash\npolkadot --chain polkadot \\\n--base-path /tmp/node \\\n--name \"Bootnode testnode\" \\\n--reserved-only \\\n--reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30311/ws/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" \\\n--no-hardware-benchmarks\n```"}
{"page_id": "infrastructure-running-a-node-setup-bootnode", "index": 8, "depth": 3, "title": "P2P/WSS", "anchor": "p2pwss", "start_char": 4266, "end_char": 4539, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### P2P/WSS\n\n```bash\npolkadot --chain polkadot \\\n--base-path /tmp/node \\\n--name \"Bootnode testnode\" \\\n--reserved-only \\\n--reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30312/wss/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" \\\n--no-hardware-benchmarks\n```"}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 945, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRunning a node on Polkadot provides direct interaction with the network, enhanced privacy, and full control over RPC requests, transactions, and data queries. As the backbone of the network, nodes ensure decentralized data propagation, transaction validation, and seamless communication across the ecosystem.\n\nPolkadot supports multiple node types, including pruned, archive, and light nodes, each suited to specific use cases. During setup, you can use configuration flags to choose the node type you wish to run.\n\nThis guide walks you through configuring, securing, and maintaining a node on Polkadot or any Polkadot SDK-based chain. It covers instructions for the different node types and how to safely expose your node's RPC server for external access. Whether you're building a local development environment, powering dApps, or supporting network decentralization, this guide provides all the essentials."}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 1, "depth": 2, "title": "Set Up a Node", "anchor": "set-up-a-node", "start_char": 945, "end_char": 1150, "estimated_token_count": 43, "token_estimator": "heuristic-v1", "text": "## Set Up a Node\n\nNow that you're familiar with the different types of nodes, this section will walk you through configuring, securing, and maintaining a node on Polkadot or any Polkadot SDK-based chain."}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 2, "depth": 3, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1150, "end_char": 1686, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "### Prerequisites\n\nBefore getting started, ensure the following prerequisites are met:\n\n- Ensure [Rust](https://www.rust-lang.org/tools/install){target=\\_blank} is installed on your operating system.\n- [Install the necessary dependencies for the Polkadot SDK](/develop/parachains/install-polkadot-sdk/){target=\\_blank}.\n\n!!! warning\n    This setup is not recommended for validators. If you plan to run a validator, refer to the [Running a Validator](/infrastructure/running-a-validator/){target=\\_blank} guide for proper instructions."}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 3, "depth": 3, "title": "Install and Build the Polkadot Binary", "anchor": "install-and-build-the-polkadot-binary", "start_char": 1686, "end_char": 8066, "estimated_token_count": 1562, "token_estimator": "heuristic-v1", "text": "### Install and Build the Polkadot Binary\n\nThis section will walk you through installing and building the Polkadot binary for different operating systems and methods.\n\n??? interface \"macOS\"\n\n    To get started, update and configure the Rust toolchain by running the following commands:\n\n    ```bash\n    source ~/.cargo/env\n\n    rustup default stable\n    rustup update\n\n    rustup update nightly\n    rustup target add wasm32-unknown-unknown --toolchain nightly\n    rustup component add rust-src --toolchain stable-aarch64-apple-darwin\n    ```\n\n    You can verify your installation by running:\n\n    ```bash\n    rustup show\n    rustup +nightly show\n    ```\n\n    You should see output similar to the following:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"\n    ><span class=\"file-path\"></span>rustup show <br />\n    rustup +nightly show</span\n  >\n  <span data-ty>active toolchain</span>\n  <span data-ty>----------------</span>\n  <span data-ty></span>\n  <span data-ty>stable-aarch64-apple-darwin (default)</span>\n  <span data-ty>rustc 1.82.0 (f6e511eec 2024-10-15)</span>\n  <span data-ty></span>\n  <span data-ty>active toolchain</span>\n  <span data-ty>----------------</span>\n  <span data-ty></span>\n  <span data-ty>nightly-aarch64-apple-darwin (overridden by +toolchain on the command line) </span>\n  <span data-ty>rustc 1.84.0-nightly (03ee48451 2024-11-18)</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>\n\n\n    Then, run the following commands to clone and build the Polkadot binary:\n  \n    ```bash\n    git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\n    cd polkadot-sdk\n    cargo build --release\n    ```\n\n    Depending upon the specs of your machine, compiling the binary may take an hour or more. After building the Polkadot node from source, the executable binary will be located in the `./target/release/polkadot` directory.\n\n??? interface \"Windows\"\n\n    To get started, make sure that you have [WSL and Ubuntu](https://learn.microsoft.com/en-us/windows/wsl/install){target=\\_blank} installed on your Windows machine.\n\n    Once installed, you have a couple options for installing the Polkadot binary:\n\n    - If Rust is installed, then `cargo` can be used similar to the macOS instructions.\n    - Or, the instructions in the Linux section can be used.\n\n??? interface \"Linux (pre-built binary)\"\n\n    To grab the [latest release of the Polkadot binary](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank}, you can use `wget`:\n\n    ```bash\n    wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-INSERT_VERSION/polkadot\n    ```\n    \n    Ensure you note the executable binary's location, as you'll need to use it when running the start-up command. If you prefer, you can specify the output location of the executable binary with the `-O` flag, for example:\n\n    ```bash\n    wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-INSERT_VERSION/polkadot \\\n    - O /var/lib/polkadot-data/polkadot\n    ```\n\n    !!!tip\n        The nature of pre-built binaries means that they may not work on your particular architecture or Linux distribution. If you see an error like `cannot execute binary file: Exec format error` it likely means the binary is incompatible with your system. You will either need to compile the binary or use [Docker](#use-docker).\n\n    Ensure that you properly configure the permissions to make the Polkadot release binary executable:\n\n    ```bash\n    sudo chmod +x polkadot\n    ```\n\n??? interface \"Linux (compile binary)\"\n\n    The most reliable (although perhaps not the fastest) way of launching a full node is to compile the binary yourself. Depending on your machine's specs, this may take an hour or more.\n\n    To get started, run the following commands to configure the Rust toolchain:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup update nightly\n    rustup target add wasm32-unknown-unknown --toolchain nightly\n    rustup target add wasm32-unknown-unknown --toolchain stable-x86_64-unknown-linux-gnu\n    rustup component add rust-src --toolchain stable-x86_64-unknown-linux-gnu\n    ```\n\n    You can verify your installation by running:\n\n    ```bash\n    rustup show\n    ```\n\n    You should see output similar to the following:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"\n    ><span class=\"file-path\"></span>rustup show <br />\n    rustup +nightly show</span\n  >\n  <span data-ty>active toolchain</span>\n  <span data-ty>----------------</span>\n  <span data-ty></span>\n  <span data-ty>stable-x86_64-unknown-linux-gnu (default)</span>\n  <span data-ty>rustc 1.82.0 (f6e511eec 2024-10-15)</span>\n</div>\n\n\n    Once Rust is configured, run the following commands to clone and build Polkadot:\n  \n    ```bash\n    git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\n    cd polkadot-sdk\n    cargo build --release\n    ```\n\n    Compiling the binary may take an hour or more, depending on your machine's specs. After building the Polkadot node from the source, the executable binary will be located in the `./target/release/polkadot` directory.\n\n??? interface \"Linux (snap package)\"\n\n    Polkadot can be installed as a [snap package](https://snapcraft.io/polkadot){target=\\_blank}. If you don't already have Snap installed, take the following steps to install it:\n\n    ```bash\n    sudo apt update\n    sudo apt install snapd\n    ```\n\n    Install the Polkadot snap package:\n\n    ```bash\n    sudo snap install polkadot\n    ```\n    \n    Before continuing on with the following instructions, check out the [Configure and Run Your Node](#configure-and-run-your-node) section to learn more about the configuration options.\n\n    To configure your Polkadot node with your desired options, you'll run a command similar to the following:\n\n    ```bash\n    sudo snap set polkadot service-args=\"--name=MyName --chain=polkadot\"\n    ```\n\n    Then to start the node service, run:\n\n    ```bash\n    sudo snap start polkadot\n    ```\n\n    You can review the logs to check on the status of the node: \n\n    ```bash\n    snap logs polkadot -f\n    ```\n\n    And at any time, you can stop the node service:\n\n    ```bash\n    sudo snap stop polkadot\n    ```\n\n    You can optionally prevent the service from stopping when snap is updated with the following command:\n\n    ```bash\n    sudo snap set polkadot endure=true\n    ```"}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 4, "depth": 3, "title": "Use Docker", "anchor": "use-docker", "start_char": 8066, "end_char": 9133, "estimated_token_count": 293, "token_estimator": "heuristic-v1", "text": "### Use Docker\n\nAs an additional option, you can use Docker to run your node in a container. Doing this is more advanced, so it's best left up to those already familiar with Docker or who have completed the other set-up instructions in this guide. You can review the latest versions on [DockerHub](https://hub.docker.com/r/parity/polkadot/tags){target=\\_blank}.\n\nBe aware that when you run Polkadot in Docker, the process only listens on `localhost` by default. If you would like to connect to your node's services (RPC and Prometheus) you need to ensure that you run the node with the `--rpc-external`, and `--prometheus-external` commands.\n\n```bash\ndocker run -p 9944:9944 -p 9615:9615 parity/polkadot:v1.16.2 --name \"my-polkadot-node-calling-home\" --rpc-external --prometheus-external\n```\n\nIf you're running Docker on an Apple Silicon machine (e.g. M4), you'll need to adapt the command slightly:\n\n```bash\ndocker run --platform linux/amd64 -p 9944:9944 -p 9615:9615 parity/polkadot:v1.16.2 --name \"kearsarge-calling-home\" --rpc-external --prometheus-external\n```"}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 5, "depth": 2, "title": "Configure and Run Your Node", "anchor": "configure-and-run-your-node", "start_char": 9133, "end_char": 11075, "estimated_token_count": 464, "token_estimator": "heuristic-v1", "text": "## Configure and Run Your Node\n\nNow that you've installed and built the Polkadot binary, the next step is to configure the start-up command depending on the type of node that you want to run. You'll need to modify the start-up command accordingly based on the location of the binary. In some cases, it may be located within the `./target/release/` folder, so you'll need to replace polkadot with `./target/release/polkadot` in the following commands.\n\nAlso, note that you can use the same binary for Polkadot as you would for Kusama or any other relay chain. You'll need to use the `--chain` flag to differentiate between chains.\n\nIf you aren't sure which type of node to run, see the [Types of Full Nodes](/infrastructure/running-a-node/#types-of-nodes){target=\\_blank} section.\n\nThe base commands for running a Polkadot node are as follows:\n\n=== \"Default pruned node\"\n\n    This uses the default pruning value of the last 256 blocks:\n\n    ```bash\n    polkadot --chain polkadot \\\n    --name \"INSERT_NODE_NAME\"\n    ```\n\n=== \"Custom pruned node\"\n\n    You can customize the pruning value, for example, to the last 1000 finalized blocks:\n\n    ```bash\n    polkadot --chain polkadot \\\n    --name INSERT_YOUR_NODE_NAME \\\n    --state-pruning 1000 \\\n    --blocks-pruning archive \\\n    --rpc-cors all \\\n    --rpc-methods safe\n    ```\n\n=== \"Archive node\"\n\n    To support the full state, use the `archive` option:\n\n    ```bash\n    polkadot --chain polkadot \\\n    --name INSERT_YOUR_NODE_NAME \\\n    --state-pruning archive \\\n    --blocks-pruning archive \\\n    ```\n\nIf you want to run an RPC node, please refer to the following [RPC Configurations](#rpc-configurations) section.\n\nTo review a complete list of the available commands, flags, and options, you can use the `--help` flag:\n\n```bash\npolkadot --help\n```\n\nOnce you've fully configured your start-up command, you can execute it in your terminal and your node will start [syncing](#sync-your-node)."}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 6, "depth": 3, "title": "RPC Configurations", "anchor": "rpc-configurations", "start_char": 11075, "end_char": 11934, "estimated_token_count": 221, "token_estimator": "heuristic-v1", "text": "### RPC Configurations\n\nThe node startup settings allow you to choose what to expose, how many connections to expose, and which systems should be granted access through the RPC server.\n\n- You can limit the methods to use with `--rpc-methods`; an easy way to set this to a safe mode is `--rpc-methods safe`.\n- You can set your maximum connections through `--rpc-max-connections`, for example, `--rpc-max-connections 200`.\n- By default, localhost and Polkadot.js can access the RPC server. You can change this by setting `--rpc-cors`. To allow access from everywhere, you can use `--rpc-cors all`.\n\nFor a list of important flags when running RPC nodes, refer to the Parity DevOps documentation: [Important Flags for Running an RPC Node](https://paritytech.github.io/devops-guide/guides/rpc_index.html?#important-flags-for-running-an-rpc-node){target=\\_blank}."}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 7, "depth": 2, "title": "Sync Your Node", "anchor": "sync-your-node", "start_char": 11934, "end_char": 15604, "estimated_token_count": 1236, "token_estimator": "heuristic-v1", "text": "## Sync Your Node\n\nThe syncing process will take a while, depending on your capacity, processing power, disk speed, and RAM. The process may be completed on a $10 DigitalOcean droplet in about ~36 hours. While syncing, your node name should be visible in gray on Polkadot Telemetry, and once it is fully synced, your node name will appear in white on [Polkadot Telemetry](https://telemetry.polkadot.io/#list/Polkadot){target=_blank}.\n\nA healthy node syncing blocks will output logs like the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty>2024-11-19 23:49:57 Parity Polkadot</span>\n  <span data-ty>2024-11-19 23:49:57 ✌️ version 1.14.1-7c4cd60da6d</span>\n  <span data-ty>2024-11-19 23:49:57 ❤️ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2024</span>\n  <span data-ty>2024-11-19 23:49:57 📋 Chain specification: Polkadot</span>\n  <span data-ty>2024-11-19 23:49:57 🏷 Node name: myPolkadotNode</span>\n  <span data-ty>2024-11-19 23:49:57 👤 Role: FULL</span>\n  <span data-ty>2024-11-19 23:49:57 💾 Database: RocksDb at /home/ubuntu/.local/share/polkadot/chains/polkadot/db/full</span>\n  <span data-ty>2024-11-19 23:50:00 🏷 Local node identity is: 12D3KooWDmhHEgPRJUJnUpJ4TFWn28EENqvKWH4dZGCN9TS51y9h</span>\n  <span data-ty>2024-11-19 23:50:00 Running libp2p network backend</span>\n  <span data-ty>2024-11-19 23:50:00 💻 Operating system: linux</span>\n  <span data-ty>2024-11-19 23:50:00 💻 CPU architecture: x86_64</span>\n  <span data-ty>2024-11-19 23:50:00 💻 Target environment: gnu</span>\n  <span data-ty>2024-11-19 23:50:00 💻 CPU: Intel(R) Xeon(R) CPU E3-1245 V2 @ 3.40GHz</span>\n  <span data-ty>2024-11-19 23:50:00 💻 CPU cores: 4</span>\n  <span data-ty>2024-11-19 23:50:00 💻 Memory: 32001MB</span>\n  <span data-ty>2024-11-19 23:50:00 💻 Kernel: 5.15.0-113-generic</span>\n  <span data-ty>2024-11-19 23:50:00 💻 Linux distribution: Ubuntu 22.04.5 LTS</span>\n  <span data-ty>2024-11-19 23:50:00 💻 Virtual machine: no</span>\n  <span data-ty>2024-11-19 23:50:00 📦 Highest known block at #9319</span>\n  <span data-ty>2024-11-19 23:50:00 〽️ Prometheus exporter started at 127.0.0.1:9615</span>\n  <span data-ty>2024-11-19 23:50:00 Running JSON-RPC server: addr=127.0.0.1:9944, allowed origins=[\"http://localhost:*\", \"http://127.0.0.1:*\", \"https://localhost:*\", \"https://127.0.0.1:*\", \"https://polkadot.js.org\"]</span>\n  <span data-ty>2024-11-19 23:50:00 🏁 CPU score: 671.67 MiBs</span>\n  <span data-ty>2024-11-19 23:50:00 🏁 Memory score: 7.96 GiBs</span>\n  <span data-ty>2024-11-19 23:50:00 🏁 Disk score (seq. writes): 377.87 MiBs</span>\n  <span data-ty>2024-11-19 23:50:00 🏁 Disk score (rand. writes): 147.92 MiBs</span>\n  <span data-ty>2024-11-19 23:50:00 🥩 BEEFY gadget waiting for BEEFY pallet to become available...</span>\n  <span data-ty>2024-11-19 23:50:00 🔍 Discovered new external address for our node: /ip4/37.187.93.17/tcp/30333/ws/p2p/12D3KooWDmhHEgPRJUJnUpJ4TFWn28EENqvKWH4dZGCN9TS51y9h</span>\n  <span data-ty>2024-11-19 23:50:01 🔍 Discovered new external address for our node: /ip6/2001:41d0:a:3511::1/tcp/30333/ws/p2p/12D3KooWDmhHEgPRJUJnUpJ4TFWn28EENqvKWH4dZGCN9TS51y9h</span>\n  <span data-ty>2024-11-19 23:50:05 ⚙️ Syncing, target=#23486325 (5 peers), best: #12262 (0x8fb5…f310), finalized #11776 (0x9de1…32fb), ⬇ 430.5kiB/s ⬆ 17.8kiB/s</span>\n  <span data-ty>2024-11-19 23:50:10 ⚙️ Syncing 628.8 bps, target=#23486326 (6 peers), best: #15406 (0x9ce1…2d76), finalized #15360 (0x0e41…a064), ⬇ 255.0kiB/s ⬆ 1.8kiB/s</span>\n</div>\n\n\nCongratulations, you're now syncing a Polkadot full node! Remember that the process is identical when using any other Polkadot SDK-based chain, although individual chains may have chain-specific flag requirements."}
{"page_id": "infrastructure-running-a-node-setup-full-node", "index": 8, "depth": 3, "title": "Connect to Your Node", "anchor": "connect-to-your-node", "start_char": 15604, "end_char": 15957, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "### Connect to Your Node\n\nOpen [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/explorer){target=\\_blank} and click the logo in the top left to switch the node. Activate the **Development** toggle and input your node's domain or IP address. The default WSS endpoint for a local node is:\n\n```bash\nws://127.0.0.1:9944\n```"}
{"page_id": "infrastructure-running-a-node-setup-secure-wss", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 27, "end_char": 600, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEnsuring secure WebSocket communication is crucial for maintaining the integrity and security of a Polkadot or Kusama node when interacting with remote clients. This guide walks you through setting up a secure WebSocket (WSS) connection for your node by leveraging SSL encryption with popular web server proxies like nginx or Apache.\n\nBy the end of this guide, you'll be able to secure your node's WebSocket port, enabling safe remote connections without exposing your node to unnecessary risks. The instructions in this guide are for UNIX-based systems."}
{"page_id": "infrastructure-running-a-node-setup-secure-wss", "index": 1, "depth": 2, "title": "Secure a WebSocket Port", "anchor": "secure-a-websocket-port", "start_char": 600, "end_char": 1053, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "## Secure a WebSocket Port\n\nYou can convert a non-secured WebSocket port to a secure WSS port by placing it behind an SSL-enabled proxy. This approach can be used to secure a bootnode or RPC server. The SSL-enabled apache2/nginx/other proxy server redirects requests to the internal WebSocket and converts it to a secure (WSS) connection. You can use a service like [LetsEncrypt](https://letsencrypt.org/){target=\\_blank} to obtain an SSL certificate."}
{"page_id": "infrastructure-running-a-node-setup-secure-wss", "index": 2, "depth": 3, "title": "Obtain an SSL Certificate", "anchor": "obtain-an-ssl-certificate", "start_char": 1053, "end_char": 5479, "estimated_token_count": 1086, "token_estimator": "heuristic-v1", "text": "### Obtain an SSL Certificate\n\nLetsEncrypt suggests using the [Certbot ACME client](https://letsencrypt.org/getting-started/#with-shell-access/){target=\\_blank} for your respective web server implementation to get a free SSL certificate:\n\n- [nginx](https://certbot.eff.org/instructions?ws=nginx&os=ubuntufocal){target=\\_blank}\n- [apache2](https://certbot.eff.org/instructions?ws=apache&os=ubuntufocal){target=\\_blank}\n \nLetsEncrypt will auto-generate an SSL certificate and include it in your configuration.\n\nWhen connecting, you can generate a self-signed certificate and rely on your node's raw IP address. However, self-signed certificates aren't optimal because you must include the certificate in an allowlist to access it from a browser.\n\nUse the following command to generate a self-signed certificate using OpenSSL:\n\n-```bash\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/selfsigned.key -out /etc/ssl/certs/selfsigned.crt\nsudo openssl dhparam -out /etc/ssl/certs/dhparam.pem 2048\n```\n\n## Install a Proxy Server\n\nThere are a lot of different implementations of a WebSocket proxy; some of the more widely used are [nginx](https://www.f5.com/go/product/welcome-to-nginx){target=\\_blank} and [apache2](https://httpd.apache.org/){target=\\_blank}, both of which are commonly used web server implementations. See the following section for configuration examples for both implementations.\n\n### Use nginx\n\n1. Install the `nginx` web server: \n    ```bash\n    apt install nginx\n    ```\n\n2. In an SSL-enabled virtual host, add:\n    -```conf\nserver {\n    (...)\n    location / {\n    proxy_buffers 16 4k;\n    proxy_buffer_size 2k;\n    proxy_pass http://localhost:9944;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"Upgrade\";\n    proxy_set_header Host $host;\n    }\n}\n```\n\n3. Optionally, you can introduce some form of rate limiting:\n    -```conf\nhttp {\n    limit_req_zone  \"$http_x_forwarded_for\" zone=zone:10m rate=2r/s;\n    (...)\n}\nlocation / {\n    limit_req zone=zone burst=5;\n    (...)\n}\n```\n\n### Use Apache2\n\nApache2 can run in various modes, including `prefork`, `worker`, and `event`. In this example, the [`event`](https://httpd.apache.org/docs/2.4/mod/event.html){target=\\_blank} mode is recommended for handling higher traffic loads, as it is optimized for performance in such environments. However, depending on the specific requirements of your setup, other modes like `prefork` or `worker` may also be appropriate.\n\n1. Install the `apache2` web server:\n    -```bash\napt install apache2\na2dismod mpm_prefork\na2enmod mpm_event proxy proxy_html proxy_http proxy_wstunnel rewrite ssl\n```\n\n2. The [`mod_proxy_wstunnel`](https://httpd.apache.org/docs/2.4/mod/mod_proxy_wstunnel.html){target=\\_blank} provides support for the tunneling of WebSocket connections to a backend WebSocket server. The connection is automatically upgraded to a WebSocket connection. In an SSL-enabled virtual host add:\n\n    -```apacheconf\n# (...)\nSSLProxyEngine on\nProxyRequests off\nProxyPass / ws://localhost:9944\nProxyPassReverse / ws://localhost:9944\n```\n\n    !!!warning \n        Older versions of `mod_proxy_wstunnel` don't upgrade the connection automatically and will need the following config added:\n        ```apacheconf\n        RewriteEngine on\n        RewriteCond %{HTTP:Upgrade} websocket [NC]\n        RewriteRule /(.*) ws://localhost:9944/$1 [P,L]\n        RewriteRule /(.*) http://localhost:9944/$1 [P,L]\n        ```\n\n3. Optionally, some form of rate limiting can be introduced by first running the following command:\n\n    ```bash\n    apt install libapache2-mod-qos\n    a2enmod qos\n    ```\n\n    Then edit `/etc/apache2/mods-available/qos.conf` as follows:\n\n    ```conf\n    # allows max 50 connections from a single IP address:\n    QS_SrvMaxConnPerIP                                 50\n    ```\n\n## Connect to the Node\n\n1. Open [Polkadot.js Apps interface](https://polkadot.js.org/apps){target=\\_blank} and click the logo in the top left to switch the node.\n2. Activate the **Development** toggle and input either your node's domain or IP address. Remember to prefix with `wss://` and, if you're using the 443 port, append `:443` as follows:\n\n    ```bash\n    wss://example.com:443\n    ```\n\n![A sync-in-progress chain connected to Polkadot.js UI](/images/infrastructure/running-a-validator/running-a-node/setup-secure-wss/setup-secure-wss-1.webp)"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 574, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter setting up your node environment as shown in the [Setup](/infrastructure/running-a-validator/onboarding-and-offboarding/set-up-validator){target=\\_blank} section, you'll need to configure multiple keys for your validator to operate properly. This includes setting up session keys, which are essential for participating in the consensus process, and configuring a node key that maintains a stable network identity. This guide walks you through the key management process, showing you how to generate, store, and register these keys."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 1, "depth": 2, "title": "Set Session Keys", "anchor": "set-session-keys", "start_char": 574, "end_char": 1104, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "## Set Session Keys\n\nSetting up your validator's session keys is essential to associate your node with your stash account on the Polkadot network. Validators use session keys to participate in the consensus process. Your validator can only perform its role in the network by properly setting session keys which consist of several key pairs for different parts of the protocol (e.g., GRANDPA, BABE). These keys must be registered on-chain and associated with your validator node to ensure it can participate in validating blocks."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 2, "depth": 3, "title": "Generate Session Keys", "anchor": "generate-session-keys", "start_char": 1104, "end_char": 4073, "estimated_token_count": 645, "token_estimator": "heuristic-v1", "text": "### Generate Session Keys\n\nThere are multiple ways to create the session keys. It can be done by interacting with the [Polkadot.js Apps UI](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, using the curl command or by using [Subkey](https://paritytech.github.io/polkadot-sdk/master/subkey/index.html){target=\\_blank}.\n\n=== \"Polkadot.js Apps UI\"\n\n    1. In Polkadot.js Apps, connect to your local node, navigate to the **Developer** dropdown, and select the **RPC Calls** option.\n\n    2. Construct an `author_rotateKeys` RPC call and execute it:\n\n        1. Select the **author** endpoint.\n        2. Choose the **rotateKeys()** call.\n        3. Click the **Submit RPC Call** button.\n        4. Copy the hex-encoded public key from the response.\n\n        ![](/images/infrastructure/running-a-validator/onboarding-and-offboarding/key-management/key-management-1.webp)\n\n=== \"Curl\"\n\n    Generate session keys by running the following command on your validator node:\n\n    ``` bash\n    curl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"author_rotateKeys\", \"params\":[]}' \\\n    http://localhost:9944\n    ```\n\n    This command will return a JSON object. The `result` key is the hex-encoded public part of the newly created session key. Save this for later use.\n    \n    ```json\n    {\"jsonrpc\":\"2.0\",\"result\":\"0xda3861a45e0197f3ca145c2c209f9126e5053fas503e459af4255cf8011d51010\",\"id\":1}\n    ```\n\n=== \"Subkey\"\n\n    To create a keypair for your node's session keys, use the `subkey generate` command. This generates a set of cryptographic keys that must be stored in your node's keystore directory.\n\n    When you run the command, it produces output similar to this example:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>subkey generate</span>\n  <pre>\nSecret phrase:       twist buffalo mixture excess device drastic vague mammal fitness punch match hammer\n  Network ID:        substrate\n  Secret seed:       0x5faa9e5defe42b201388d5c2b8202d6625a344abc9aa52943a71f12cb90b88a9\n  Public key (hex):  0x28cc2fdb6e28835e2bbac9a16feb65c23d448c9314ef12fe083b61bab8fc2755\n  Account ID:        0x28cc2fdb6e28835e2bbac9a16feb65c23d448c9314ef12fe083b61bab8fc2755\n  Public key (SS58): 5CzCRpXzHYhuo6G3gYFR3cgV6X3qCNwVt51m8q14ZcChsSXQ\n  SS58 Address:      5CzCRpXzHYhuo6G3gYFR3cgV6X3qCNwVt51m8q14ZcChsSXQ\n  </pre>\n</div>\n\n\n    To properly store these keys, create a file in your keystore directory with a specific naming convention. The filename must consist of the hex string `61757261` (which represents \"aura\" in hex) followed by the public key without its `0x` prefix.\n\n    Using the example above, you would create a file named:\n\n    ```\n    ./keystores/6175726128cc2fdb6e28835e2bbac9a16feb65c23d448c9314ef12fe083b61bab8fc2755\n    ```\n\n    And store only the secret phrase in the file:\n\n    ```\n    \"twist buffalo mixture excess device drastic vague mammal fitness punch match hammer\"\n    ```"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 3, "depth": 3, "title": "Submit Transaction to Set Keys", "anchor": "submit-transaction-to-set-keys", "start_char": 4073, "end_char": 4706, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "### Submit Transaction to Set Keys\n\nNow that you have generated your session keys, you must submit them to the chain. Follow these steps:\n\n1. Go to the **Network > Staking > Accounts** section on Polkadot.js Apps.\n2. Select **Set Session Key** on the bonding account you generated earlier.\n3. Paste the hex-encoded session key string you generated (from either the UI or CLI) into the input field and submit the transaction.\n\n![](/images/infrastructure/running-a-validator/onboarding-and-offboarding/key-management/key-management-2.webp)\n\nOnce the transaction is signed and submitted, your session keys will be registered on-chain."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 4, "depth": 3, "title": "Verify Session Key Setup", "anchor": "verify-session-key-setup", "start_char": 4706, "end_char": 5251, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Verify Session Key Setup\n\nTo verify that your session keys are properly set, you can use one of two RPC calls:\n\n- **`hasKey`**: Checks if the node has a specific key by public key and key type.\n- **`hasSessionKeys`**: Verifies if your node has the full session key string associated with the validator.\n\nFor example, you can [check session keys on the Polkadot.js Apps](https://polkadot.js.org/apps/#/rpc){target=\\_blank} interface or by running an RPC query against your node. Once this is done, your validator node is ready for its role."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 5, "depth": 2, "title": "Set the Node Key", "anchor": "set-the-node-key", "start_char": 5251, "end_char": 6895, "estimated_token_count": 409, "token_estimator": "heuristic-v1", "text": "## Set the Node Key\n\nValidators on Polkadot need a static network key (also known as the node key) to maintain a stable node identity. This key ensures that your validator can maintain a consistent peer ID, even across restarts, which is crucial for maintaining reliable network connections.\n\nStarting with Polkadot version 1.11, validators without a stable network key may encounter the following error on startup:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot --validator --name \"INSERT_NAME_FROM_TELEMETRY\"</span>\n  <span data-ty>Error:</span>\n  <span data-ty>0: Starting an authority without network key</span>\n  <span data-ty>This is not a safe operation because other authorities in the network may depend on your node having a stable identity.</span>\n  <span data-ty>Otherwise these other authorities may not being able to reach you.</span>\n  <span data-ty>If it is the first time running your node you could use one of the following methods:</span>\n  <span data-ty>1. [Preferred] Separately generate the key with: INSERT_NODE_BINARY key generate-node-key --base-path INSERT_YOUR_BASE_PATH</span>\n  <span data-ty>2. [Preferred] Separately generate the key with: INSERT_NODE_BINARY key generate-node-key --file INSERT_YOUR_PATH_TO_NODE_KEY</span>\n  <span data-ty>3. [Preferred] Separately generate the key with: INSERT_NODE_BINARY key generate-node-key --default-base-path</span>\n  <span data-ty>4. [Unsafe] Pass --unsafe-force-node-key-generation and make sure you remove it for subsequent node restarts</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 6, "depth": 3, "title": "Generate the Node Key", "anchor": "generate-the-node-key", "start_char": 6895, "end_char": 7556, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### Generate the Node Key\n\nUse one of the following methods to generate your node key:\n\n=== \"Save to file\"\n\n    The recommended solution is to generate a node key and save it to a file using the following command:\n\n    ``` bash\n    polkadot key generate-node-key --file INSERT_PATH_TO_NODE_KEY\n    ```\n    \n=== \"Use default path\"\n\n    You can also generate the node key with the following command, which will automatically save the key to the base path of your node:\n\n    ``` bash\n    polkadot key generate-node-key --default-base-path\n    ```\n\nSave the file path for reference. You will need it in the next step to configure your node with a static identity."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-key-management", "index": 7, "depth": 3, "title": "Set Node Key", "anchor": "set-node-key", "start_char": 7556, "end_char": 8178, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Set Node Key\n\nAfter generating the node key, configure your node to use it by specifying the path to the key file when launching your node. Add the following flag to your validator node's startup command:\n\n``` bash\npolkadot --node-key-file INSERT_PATH_TO_NODE_KEY\n```\n\nFollowing these steps ensures that your node retains its identity, making it discoverable by peers without the risk of conflicting identities across sessions. For further technical background, see Polkadot SDK [Pull Request #3852](https://github.com/paritytech/polkadot-sdk/pull/3852){target=\\_blank} for the rationale behind requiring static keys."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 642, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nSetting up a Polkadot validator node is essential for securing the network and earning staking rewards. This guide walks you through the technical steps to set up a validator, from installing the necessary software to managing keys and synchronizing your node with the chain.\n\nRunning a validator requires a commitment to maintaining a stable, secure infrastructure. Validators are responsible for their own stakes and those of nominators who trust them with their tokens. Proper setup and ongoing management are critical to ensuring smooth operation and avoiding potential penalties such as slashing."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 642, "end_char": 1706, "estimated_token_count": 246, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo get the most from this guide, ensure you've done the following before going forward:\n\n- Read [Validator Requirements](/infrastructure/running-a-validator/requirements/){target=\\_blank} and understand the recommended minimum skill level and hardware needs.\n- Read [General Management](/infrastructure/running-a-validator/operational-tasks/general-management){target=\\_blank}, [Upgrade Your Node](/infrastructure/running-a-validator/operational-tasks/upgrade-your-node/){target=\\_blank}, and [Pause Validating](/infrastructure/running-a-validator/onboarding-and-offboarding/stop-validating/){target=\\_blank} and understand the tasks required to keep your validator operational.\n- Read [Rewards Payout](/infrastructure/staking-mechanics/rewards-payout/){target=\\_blank} and understand how validator rewards are determined and paid out.\n- Read [Offenses and Slashes](/infrastructure/staking-mechanics/offenses-and-slashes/){target=\\_blank} and understand how validator performance and security can affect tokens staked by you or your nominators."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 2, "depth": 2, "title": "Initial Setup", "anchor": "initial-setup", "start_char": 1706, "end_char": 2262, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Initial Setup\n\nBefore running your validator, you must configure your server environment to meet the operational and security standards required for validating.\n\nYou must use a Linux-based operating system with Kernel 5.16 or later. Configuration includes setting up time synchronization, ensuring critical security features are active, and installing the necessary binaries. Proper setup at this stage is essential to prevent issues like block production errors or being penalized for downtime. Below are the essential steps to get your system ready."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 3, "depth": 3, "title": "Install Network Time Protocol Client", "anchor": "install-network-time-protocol-client", "start_char": 2262, "end_char": 3374, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "### Install Network Time Protocol Client\n\nAccurate timekeeping is critical to ensure your validator is synchronized with the network. Validators need local clocks in sync with the blockchain to avoid missing block authorship opportunities. Using [Network Time Protocol (NTP)](https://en.wikipedia.org/wiki/Network_Time_Protocol){target=\\_blank} is the standard solution to keep your system's clock accurate.\n\nIf you are using Ubuntu version 18.04 or newer, the NTP Client should be installed by default. You can check whether you have the NTP client by running:\n\n```sh\ntimedatectl\n```\n\nIf NTP is running, you should see a message like the following:\n\n``` sh\nSystem clock synchronized: yes\n```\n\nIf NTP is not installed or running, you can install it using:\n\n```sh\nsudo apt-get install ntp\n```\n\nAfter installation, NTP will automatically start. To check its status:\n\n```sh\nsudo ntpq -p\n```\n\nThis command will return a message with the status of the NTP synchronization. Skipping this step could result in your validator node missing blocks due to minor clock drift, potentially affecting its network performance."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 4, "depth": 3, "title": "Verify Landlock is Activated", "anchor": "verify-landlock-is-activated", "start_char": 3374, "end_char": 4971, "estimated_token_count": 319, "token_estimator": "heuristic-v1", "text": "### Verify Landlock is Activated\n\n[Landlock](https://docs.kernel.org/userspace-api/landlock.html){target=\\_blank} is an important security feature integrated into Linux kernels starting with version 5.13. It allows processes, even those without special privileges, to limit their access to the system to reduce the machine's attack surface. This feature is crucial for validators, as it helps ensure the security and stability of the node by preventing unauthorized access or malicious behavior.\n\nTo use Landlock, ensure you use the reference kernel or newer versions. Most Linux distributions should already have Landlock activated. You can check if Landlock is activated on your machine by running the following command as root:\n\n```sh\ndmesg | grep landlock || journalctl -kg landlock\n```\n\nIf Landlock is not activated, your system logs won't show any related output. In this case, you will need to activate it manually or ensure that your Linux distribution supports it. Most modern distributions with the required kernel version should have Landlock activated by default. However, if your system lacks support, you may need to build the kernel with Landlock activated. For more information on doing so, refer to the [official kernel documentation](https://docs.kernel.org/userspace-api/landlock.html#kernel-support){target=\\_blank}.\n\nImplementing Landlock ensures your node operates in a restricted, self-imposed sandbox, limiting potential damage from security breaches or bugs. While not a mandatory requirement, enabling this feature greatly improves the security of your validator setup."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 5, "depth": 2, "title": "Install the Polkadot Binaries", "anchor": "install-the-polkadot-binaries", "start_char": 4971, "end_char": 5397, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Install the Polkadot Binaries\n\nYou must install the Polkadot binaries required to run your validator node. These binaries include the main `polkadot`, `polkadot-prepare-worker`, and `polkadot-execute-worker` binaries. All three are needed to run a fully functioning validator node.\n\nDepending on your preference and operating system setup, there are multiple methods to install these binaries. Below are the main options:"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 6, "depth": 3, "title": "Install from Official Releases", "anchor": "install-from-official-releases", "start_char": 5397, "end_char": 8175, "estimated_token_count": 610, "token_estimator": "heuristic-v1", "text": "### Install from Official Releases\n\nThe preferred, most straightforward method to install the required binaries is downloading the latest versions from the official releases. You can visit the [Github Releases](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank} page for the most current versions of the `polkadot`, `polkadot-prepare-worker`, and `polkadot-execute-worker` binaries.\n\nYou can also download the binaries by using the following direct links:\n\n=== \"`polkadot`\"\n\n    ``` bash\n    # Download the binary\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506/polkadot\n\n    # Verify signature\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506/polkadot.asc\n    \n    gpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\n\n    gpg --verify polkadot.asc\n    ```\n\n=== \"`polkadot-prepare-worker`\"\n\n    ``` bash\n    # Download the binary\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506/polkadot-prepare-worker\n\n    # Verify signature\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506/polkadot-prepare-worker.asc\n\n    gpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\n\n    gpg --verify polkadot-prepare-worker.asc\n    ```\n\n=== \"`polkadot-execute-worker`\"\n\n    ``` bash\n    # Download the binary\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506/polkadot-execute-worker\n\n    # Verify signature\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506/polkadot-execute-worker.asc\n\n    gpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\n\n    gpg --verify polkadot-execute-worker.asc\n    ```\n\n\nSignature verification cryptographically ensures the downloaded binaries are authentic and have not been tampered with by using GPG signing keys. Polkadot releases use two different signing keys:\n\n- ParityReleases (release-team@parity.io) with key [`90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE`](https://keyserver.ubuntu.com/pks/lookup?search=9D4B2B6EB8F97156D19669A9FF0812D491B96798&fingerprint=on&op=index){target=\\_blank} for current and new releases.\n- Parity Security Team (security@parity.io) with key [`9D4B2B6EB8F97156D19669A9FF0812D491B96798`](https://keyserver.ubuntu.com/pks/lookup?search=90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE&fingerprint=on&op=index){target=\\_blank} for old releases.\n\n    !!!warning\n        When verifying a signature, a \"Good signature\" message indicates successful verification, while any other output signals a potential security risk."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 7, "depth": 3, "title": "Install with Package Managers", "anchor": "install-with-package-managers", "start_char": 8175, "end_char": 9242, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "### Install with Package Managers\n\nUsers running Debian-based distributions like Ubuntu can install the binaries using the [APT](https://wiki.debian.org/Apt){target=\\_blank} package manager.\n\nExecute the following commands as root to add the official repository and install the binaries:\n\n```bash\n# Import the release-team@parity.io GPG key\ngpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\ngpg --export 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE > /usr/share/keyrings/parity.gpg\n\n# Add the Parity repository and update the package index\necho 'deb [signed-by=/usr/share/keyrings/parity.gpg] https://releases.parity.io/deb release main' > /etc/apt/sources.list.d/parity.list\napt update\n\n# Install the `parity-keyring` package - This will ensure the GPG key\n# used by APT remains up-to-date\napt install parity-keyring\n\n# Install polkadot\napt install polkadot\n```\n\nOnce installation completes, verify the binaries are correctly installed by following the steps in the [verify installation](#verify-installation) section."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 8, "depth": 3, "title": "Install with Ansible", "anchor": "install-with-ansible", "start_char": 9242, "end_char": 9599, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "### Install with Ansible\n\nYou can also manage Polkadot installations using Ansible. This approach can be beneficial for users managing multiple validator nodes or requiring automated deployment. The [Parity chain operations Ansible collection](https://github.com/paritytech/ansible-galaxy/){target=\\_blank} provides a Substrate node role for this purpose."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 9, "depth": 3, "title": "Install with Docker", "anchor": "install-with-docker", "start_char": 9599, "end_char": 9880, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Install with Docker\n\nIf you prefer using Docker or an OCI-compatible container runtime, the official Polkadot Docker image can be pulled directly from Docker Hub.\n\nTo pull the latest stable image, run the following command:\n\n```bash\ndocker pull parity/polkadot:stable2506\n```"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 10, "depth": 3, "title": "Build from Sources", "anchor": "build-from-sources", "start_char": 9880, "end_char": 10111, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "### Build from Sources\n\nYou may build the binaries from source by following the instructions on the [Polkadot SDK repository](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/polkadot#building){target=\\_blank}."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-set-up-validator", "index": 11, "depth": 2, "title": "Verify Installation", "anchor": "verify-installation", "start_char": 10111, "end_char": 11845, "estimated_token_count": 431, "token_estimator": "heuristic-v1", "text": "## Verify Installation\n\nOnce the Polkadot binaries are installed, it's essential to verify that everything is set up correctly and that all the necessary components are in place. Follow these steps to ensure the binaries are installed and functioning as expected.\n\n1. **Check the versions**: Run the following commands to verify the versions of the installed binaries.\n\n    ```bash\n    polkadot --version\n    polkadot-execute-worker --version\n    polkadot-prepare-worker --version\n    ```\n\n    The output should show the version numbers for each of the binaries. Ensure that the versions match and are consistent, similar to the following example (the specific version may vary):\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot --version polkadot-execute-worker --version polkadot-prepare-worker --version</span>\n  <span data-ty>1.16.1-36264cb36db</span>\n  <span data-ty>1.16.1-36264cb36db</span>\n  <span data-ty>1.16.1-36264cb36db</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>\n\n\n    If the versions do not match or if there is an error, double-check that all the binaries were correctly installed and are accessible within your `$PATH`.\n\n2. **Ensure all binaries are in the same directory**: All the binaries must be in the same directory for the Polkadot validator node to function properly. If the binaries are not in the same location, move them to a unified directory and ensure this directory is added to your system's `$PATH`.\n\n    To verify the `$PATH`, run the following command:\n\n    ```bash\n    echo $PATH\n    ```\n\n    If necessary, you can move the binaries to a shared location, such as `/usr/local/bin/`, and add it to your `$PATH`."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 446, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter configuring your node keys as shown in the [Key Management](/infrastructure/running-a-validator/onboarding-and-offboarding/key-management){target=\\_blank} section and ensuring your system is set up, you're ready to begin the validator setup process. This guide will walk you through choosing a network, synchronizing your node with the blockchain, bonding your DOT tokens, and starting your validator."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 1, "depth": 2, "title": "Choose a Network", "anchor": "choose-a-network", "start_char": 446, "end_char": 1435, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Choose a Network\n\nRunning your validator on a test network like Westend or Kusama is a smart way to familiarize yourself with the process and identify any setup issues in a lower-stakes environment before joining the Polkadot MainNet.\n\n- **Westend**: Polkadot's primary TestNet is open to anyone for testing purposes. Validator slots are intentionally limited to keep the network stable for the Polkadot release process, so it may not support as many validators at any given time.\n- **Kusama**: Often called Polkadot's \"canary network,\" Kusama has real economic value but operates with a faster and more experimental approach. Running a validator here provides an experience closer to MainNet with the benefit of more frequent validation opportunities with an era time of 6 hours vs 24 hours for Polkadot.\n- **Polkadot**: The main network, where validators secure the Polkadot relay chain. It has a slower era time of 24 hours and requires a higher minimum bond amount to participate."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 2, "depth": 2, "title": "Synchronize Chain Data", "anchor": "synchronize-chain-data", "start_char": 1435, "end_char": 4655, "estimated_token_count": 858, "token_estimator": "heuristic-v1", "text": "## Synchronize Chain Data\n\nThe next step is to sync your node with the chosen blockchain network. Synchronization is necessary to download and validate the blockchain data, ensuring your node is ready to participate as a validator. Follow these steps to sync your node:\n\n1. **Start syncing**: You can run a full or warp sync.\n\n    === \"Full sync\"\n\n        Polkadot defaults to using a full sync, which downloads and validates the entire blockchain history from the genesis block. Start the syncing process by running the following command:\n\n        ```sh\n        polkadot\n        ```\n\n        This command starts your Polkadot node in non-validator mode, allowing you to synchronize the chain data.\n\n    === \"Warp sync\"\n\n        You can opt to use warp sync which initially downloads only GRANDPA finality proofs and the latest finalized block's state. Use the following command to start a warp sync:\n\n        ``` bash\n        polkadot --sync warp\n        ```\n\n        Warp sync ensures that your node quickly updates to the latest finalized state. The historical blocks are downloaded in the background as the node continues to operate.\n\n    If you're planning to run a validator on a TestNet, you can specify the chain using the `--chain` flag. For example, the following will run a validator on Kusama:\n\n    ```sh\n    polkadot --chain=kusama\n    ```\n\n2. **Monitor sync progress**: Once the sync starts, you will see a stream of logs providing information about the node's status and progress. Here's an example of what the output might look like:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot</span>\n  <span data-ty>2021-06-17 03:07:07 Parity Polkadot</span>\n  <span data-ty>2021-06-17 03:07:07 ✌️ version 0.9.5-95f6aa201-x86_64-linux-gnu</span>\n  <span data-ty>2021-06-17 03:07:07 ❤️ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2021</span>\n  <span data-ty>2021-06-17 03:07:07 📋 Chain specification: Polkadot</span>\n  <span data-ty>2021-06-17 03:07:07 🏷 Node name: boiling-pet-7554</span>\n  <span data-ty>2021-06-17 03:07:07 👤 Role: FULL</span>\n  <span data-ty>2021-06-17 03:07:07 💾 Database: RocksDb at /root/.local/share/polkadot/chains/polkadot/db</span>\n  <span data-ty>2021-06-17 03:07:07 ⛓ Native runtime: polkadot-9050 (parity-polkadot-0.tx7.au0)</span>\n  <span data-ty>2021-06-17 03:07:10 🏷 Local node identity is: 12D3KooWLtXFWf1oGrnxMGmPKPW54xWCHAXHbFh4Eap6KXmxoi9u</span>\n  <span data-ty>2021-06-17 03:07:10 📦 Highest known block at #17914</span>\n  <span data-ty>2021-06-17 03:07:10 〽️ Prometheus server started at 127.0.0.1:9615</span>\n  <span data-ty>2021-06-17 03:07:10 Listening for new connections on 127.0.0.1:9944</span>\n  <span data-ty>...</span>\n</div>\n\n\n    The output logs provide information such as the current block number, node name, and network connections. Monitor the sync progress and any errors that might occur during the process. Look for information about the latest processed block and compare it with the current highest block using tools like [Telemetry](https://telemetry.polkadot.io/#list/Polkadot%20CC1){target=\\_blank} or [Polkadot.js Apps Explorer](https://polkadot.js.org/apps/#/explorer){target=\\_blank}."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 3, "depth": 3, "title": "Database Snapshot Services", "anchor": "database-snapshot-services", "start_char": 4655, "end_char": 6624, "estimated_token_count": 629, "token_estimator": "heuristic-v1", "text": "### Database Snapshot Services\n\nIf you'd like to speed up the process further, you can use a database snapshot. Snapshots are compressed backups of the blockchain's database directory and can significantly reduce the time required to sync a new node. Here are a few public snapshot providers:\n\n- [Stakeworld](https://stakeworld.io/snapshot){target=\\_blank}\n- [Polkachu](https://polkachu.com/substrate_snapshots){target=\\_blank}\n- [Polkashots](https://polkashots.io/){target=\\_blank}\n- [ITRocket](https://itrocket.net/services/mainnet/polkadot/#snapshot){target=\\_blank}\n\n!!!warning\n    Although snapshots are convenient, syncing from scratch is recommended for security purposes. If snapshots become corrupted and most nodes rely on them, the network could inadvertently run on a non-canonical chain.\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot</span>\n  <span data-ty>2021-06-17 03:07:07 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), ⬇ 2.9kiB/s ⬆ 3.7kiB/s</span>\n  <span data-ty>2021-06-17 03:07:12 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), ⬇ 1.7kiB/s ⬆ 2.0kiB/s</span>\n  <span data-ty>2021-06-17 03:07:17 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), ⬇ 0.9kiB/s ⬆ 1.2kiB/s</span>\n  <span data-ty>2021-06-17 03:07:19 Libp2p => Random Kademlia query has yielded empty results</span>\n  <span data-ty>2021-06-17 03:08:00 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), ⬇ 1.6kiB/s ⬆ 1.9kiB/s</span>\n  <span data-ty>2021-06-17 03:08:05 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), ⬇ 0.6kiB/s ⬆ 0.9kiB/s</span>\n  <span data-ty>...</span>\n</div>\n\n\nIf you see terminal output similar to the preceding, and you are unable to synchronize the chain due to having zero peers, make sure you have libp2p port `30333` activated. It will take some time to discover other peers over the network."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 4, "depth": 2, "title": "Bond DOT", "anchor": "bond-dot", "start_char": 6624, "end_char": 7190, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Bond DOT\n\nOnce your validator node is synced, the next step is bonding DOT. A bonded account, or stash, holds your staked tokens (DOT) that back your validator node. Bonding your DOT means locking it for a period, during which it cannot be transferred or spent but is used to secure your validator's role in the network. Visit the [Minimum Bond Requirement](/infrastructure/running-a-validator/requirements/#minimum-bond-requirement) section for details on how much DOT is required.\n\nThe following sections will guide you through bonding DOT for your validator."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 5, "depth": 3, "title": "Bonding DOT on Polkadot.js Apps", "anchor": "bonding-dot-on-polkadotjs-apps", "start_char": 7190, "end_char": 8791, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "### Bonding DOT on Polkadot.js Apps\n\nOnce you're ready to bond your DOT, head over to the [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} staking page by clicking the **Network** dropdown at the top of the page and selecting [**Staking**](https://polkadot.js.org/apps/#/staking/actions){target=\\_blank}.\n\nTo get started with the bond submission, click on the **Accounts** tab, then the **+ Stash** button, and then enter the following information:\n\n1. **Stash account**: Select your stash account (which is the account with the DOT/KSM balance).\n2. **Value bonded**: Enter how much DOT from the stash account you want to bond/stake. You are not required to bond all of the DOT in that account and you may bond more DOT at a later time. Be aware, withdrawing any bonded amount requires waiting for the unbonding period. The unbonding period is seven days for Kusama and 28 days for Polkadot.\n3. **Payment destination**: Add the recipient account for validator rewards. If you'd like to redirect payments to an account that is not the stash account, you can do it by entering the address here. Note that it is extremely unsafe to set an exchange address as the recipient of the staking rewards.\n\nOnce everything is filled in properly, select **Bond** and sign the transaction with your stash account. If successful, you should see an `ExtrinsicSuccess` message.\n\nYour bonded account will be available under **Stashes**. After refreshing the screen, you should now see a card with all your accounts. The bonded amount on the right corresponds to the funds bonded by the stash account."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 6, "depth": 2, "title": "Validate", "anchor": "validate", "start_char": 8791, "end_char": 9019, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## Validate\n\nOnce your validator node is fully synced and ready, the next step is to ensure it's visible on the network and performing as expected. Below are steps for monitoring and managing your node on the Polkadot network."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 7, "depth": 3, "title": "Verify Sync via Telemetry", "anchor": "verify-sync-via-telemetry", "start_char": 9019, "end_char": 10041, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "### Verify Sync via Telemetry\n\nTo confirm that your validator is live and synchronized with the Polkadot network, visit the [Telemetry](https://telemetry.polkadot.io/#list/Polkadot%20CC1){target=\\_blank} page. Telemetry provides real-time information on node performance and can help you check if your validator is connected properly. Search for your node by name. You can search all nodes currently active on the network, which is why you should use a unique name for easy recognition. Now, confirm that your node is fully synced by comparing the block height of your node with the network's latest block. Nodes that are fully synced will appear white in the list, while nodes that are not yet fully synced will appear gray.\n\nIn the following example, a node named `techedtest` is successfully located and synchronized, ensuring it's prepared to participate in the network:\n\n![Polkadot telemetry dashboard](/images/infrastructure/running-a-validator/onboarding-and-offboarding/start-validating/start-validating-01.webp)"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 8, "depth": 3, "title": "Activate using Polkadot.js Apps", "anchor": "activate-using-polkadotjs-apps", "start_char": 10041, "end_char": 11459, "estimated_token_count": 328, "token_estimator": "heuristic-v1", "text": "### Activate using Polkadot.js Apps\n\nFollow these steps to use Polkadot.js Apps to activate your validator:\n\n1. Go to the **Validator** tab in the Polkadot.js Apps UI and locate the section where you input the keys generated from `rotateKeys`. Paste the output from `author_rotateKeys`, which is a hex-encoded key that links your validator with its session keys:\n\n    ![](/images/infrastructure/running-a-validator/onboarding-and-offboarding/start-validating/start-validating-02.webp)\n\n2. Set a reward commission percentage if desired. You can set a percentage of the rewards to pay to your validator and the remainder pays to your nominators. A 100% commission rate indicates the validator intends to keep all rewards and is seen as a signal the validator is not seeking nominators.\n\n3. Toggle the **allows new nominations** option if your validator is open to more nominations from DOT holders.\n\n4. Once everything is configured, select **Bond & Validate** to activate your validator status.\n\n    ![](/images/infrastructure/running-a-validator/onboarding-and-offboarding/start-validating/start-validating-03.webp)\n\n5. Edit the **commission** and the **blocked** option via `staking.validate` extrinsic. By default, the blocked option is set to FALSE (i.e., the validator accepts nominations).\n\n    ![](/images/infrastructure/running-a-validator/onboarding-and-offboarding/start-validating/start-validating-04.webp)"}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 9, "depth": 3, "title": "Monitor Validation Status and Slots", "anchor": "monitor-validation-status-and-slots", "start_char": 11459, "end_char": 12411, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "### Monitor Validation Status and Slots\n\nOn the [**Staking**](https://polkadot.js.org/apps/#/staking){target=\\_blank} tab in Polkadot.js Apps, you can see your validator's status, the number of available validator slots, and the nodes that have signaled their intent to validate. Your node may initially appear in the waiting queue, especially if the validator slots are full. The following is an example view of the **Staking** tab:\n\n![staking queue](/images/infrastructure/running-a-validator/onboarding-and-offboarding/start-validating/start-validating-05.webp)\n\nThe validator set refreshes each era. If there's an available slot in the next era, your node may be selected to move from the waiting queue to the active validator set, allowing it to start validating blocks. If your validator is not selected, it remains in the waiting queue. Increasing your stake or gaining more nominators may improve your chance of being selected in future eras."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 10, "depth": 2, "title": "Run a Validator Using Systemd", "anchor": "run-a-validator-using-systemd", "start_char": 12411, "end_char": 13435, "estimated_token_count": 218, "token_estimator": "heuristic-v1", "text": "## Run a Validator Using Systemd\n\nRunning your Polkadot validator as a [systemd](https://en.wikipedia.org/wiki/Systemd){target=\\_blank} service is an effective way to ensure its high uptime and reliability. Using systemd allows your validator to automatically restart after server reboots or unexpected crashes, significantly reducing the risk of slashing due to downtime.\n\nThis following sections will walk you through creating and managing a systemd service for your validator, allowing you to seamlessly monitor and control it as part of your Linux system. \n\nEnsure the following requirements are met before proceeding with the systemd setup:\n\n- Confirm your system meets the [requirements](/infrastructure/running-a-validator/requirements/){target=\\_blank} for running a validator.\n- Ensure you meet the [minimum bond requirements](https://wiki.polkadot.com/general/chain-state-values/#minimum-validator-bond){target=\\_blank} for validating.\n- Verify the Polkadot binary is [installed](#install-the-polkadot-binaries)."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 11, "depth": 3, "title": "Create the Systemd Service File", "anchor": "create-the-systemd-service-file", "start_char": 13435, "end_char": 15175, "estimated_token_count": 339, "token_estimator": "heuristic-v1", "text": "### Create the Systemd Service File\n\nFirst create a new unit file called `polkadot-validator.service` in `/etc/systemd/system/`:\n\n```bash\ntouch /etc/systemd/system/polkadot-validator.service\n```\n\nIn this unit file, you will write the commands that you want to run on server boot/restart:\n\n```systemd title=\"/etc/systemd/system/polkadot-validator.service\"\n-[Unit]\nDescription=Polkadot Node\nAfter=network.target\nDocumentation=https://github.com/paritytech/polkadot-sdk\n\n[Service]\nEnvironmentFile=-/etc/default/polkadot\nExecStart=/usr/bin/polkadot $POLKADOT_CLI_ARGS\nUser=polkadot\nGroup=polkadot\nRestart=always\nRestartSec=120\nCapabilityBoundingSet=\nLockPersonality=true\nNoNewPrivileges=true\nPrivateDevices=true\nPrivateMounts=true\nPrivateTmp=true\nPrivateUsers=true\nProtectClock=true\nProtectControlGroups=true\nProtectHostname=true\nProtectKernelModules=true\nProtectKernelTunables=true\nProtectSystem=strict\nRemoveIPC=true\nRestrictAddressFamilies=AF_INET AF_INET6 AF_NETLINK AF_UNIX\nRestrictNamespaces=false\nRestrictSUIDSGID=true\nSystemCallArchitectures=native\nSystemCallFilter=@system-service\nSystemCallFilter=landlock_add_rule landlock_create_ruleset landlock_restrict_self seccomp mount umount2\nSystemCallFilter=~@clock @module @reboot @swap @privileged\nSystemCallFilter=pivot_root\nUMask=0027\n\n[Install]\nWantedBy=multi-user.target\n```\n\n!!! warning \"Restart delay and equivocation risk\"\n    It is recommended that a node's restart be delayed with `RestartSec` in the case of a crash. It's possible that when a node crashes, consensus votes in GRANDPA aren't persisted to disk. In this case, there is potential to equivocate when immediately restarting. Delaying the restart will allow the network to progress past potentially conflicting votes."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-start-validating", "index": 12, "depth": 3, "title": "Run the Service", "anchor": "run-the-service", "start_char": 15175, "end_char": 16150, "estimated_token_count": 243, "token_estimator": "heuristic-v1", "text": "### Run the Service\n\nActivate the systemd service to start on system boot by running:\n\n```bash\nsystemctl enable polkadot-validator.service\n```\n\nTo start the service manually, use:\n\n```bash\nsystemctl start polkadot-validator.service\n```\n\nCheck the service's status to confirm it is running:\n\n```bash\nsystemctl status polkadot-validator.service\n```\n\nTo view the logs in real-time, use [journalctl](https://www.freedesktop.org/software/systemd/man/latest/journalctl.html){target=\\_blank} like so:\n\n```bash\njournalctl -f -u polkadot-validator\n```\n\nWith these steps, you can effectively manage and monitor your validator as a systemd service.\n\nOnce your validator is active, it's officially part of Polkadot's security infrastructure. For questions or further support, you can reach out to the [Polkadot Validator chat](https://matrix.to/#/!NZrbtteFeqYKCUGQtr:matrix.parity.io?via=matrix.parity.io&via=matrix.org&via=web3.foundation){target=\\_blank} for tips and troubleshooting."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-stop-validating", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 498, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIf you're ready to stop validating on Polkadot, there are essential steps to ensure a smooth transition while protecting your funds and account integrity. Whether you're taking a break for maintenance or unbonding entirely, you'll need to chill your validator, purge session keys, and unbond your tokens. This guide explains how to use Polkadot's tools and extrinsics to safely withdraw from validation activities, safeguarding your account's future usability."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-stop-validating", "index": 1, "depth": 2, "title": "Pause Versus Stop", "anchor": "pause-versus-stop", "start_char": 498, "end_char": 920, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Pause Versus Stop\n\nIf you wish to remain a validator or nominator (for example, stopping for planned downtime or server maintenance), submitting the `chill` extrinsic in the `staking` pallet should suffice. Additional steps are only needed to unbond funds or reap an account.\n\nThe following are steps to ensure a smooth stop to validation:\n\n- Chill the validator.\n- Purge validator session keys.\n- Unbond your tokens."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-stop-validating", "index": 2, "depth": 2, "title": "Chill Validator", "anchor": "chill-validator", "start_char": 920, "end_char": 1499, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "## Chill Validator\n\nWhen stepping back from validating, the first step is to chill your validator status. This action stops your validator from being considered for the next era without fully unbonding your tokens, which can be useful for temporary pauses like maintenance or planned downtime.\n\nUse the `staking.chill` extrinsic to initiate this. For more guidance on chilling your node, refer to the [Pause Validating](/infrastructure/running-a-validator/operational-tasks/pause-validating/){target=\\_blank} guide. You may also claim any pending staking rewards at this point."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-stop-validating", "index": 3, "depth": 2, "title": "Purge Validator Session Keys", "anchor": "purge-validator-session-keys", "start_char": 1499, "end_char": 2530, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Purge Validator Session Keys\n\nPurging validator session keys is a critical step in removing the association between your validator account and its session keys, which ensures that your account is fully disassociated from validator activities. The `session.purgeKeys` extrinsic removes the reference to your session keys from the stash or staking proxy account that originally set them.\n\nHere are a couple of important things to know about purging keys:\n\n- **Account used to purge keys**: Always use the same account to purge keys you originally used to set them, usually your stash or staking proxy account. Using a different account may leave an unremovable reference to the session keys on the original account, preventing its reaping.\n- **Account reaping issue**: Failing to purge keys will prevent you from reaping (fully deleting) your stash account. If you attempt to transfer tokens without purging, you'll need to rebond, purge the session keys, unbond again, and wait through the unbonding period before any transfer."}
{"page_id": "infrastructure-running-a-validator-onboarding-and-offboarding-stop-validating", "index": 4, "depth": 2, "title": "Unbond Your Tokens", "anchor": "unbond-your-tokens", "start_char": 2530, "end_char": 3228, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Unbond Your Tokens\n\nAfter chilling your node and purging session keys, the final step is to unbond your staked tokens. This action removes them from staking and begins the unbonding period (usually 28 days for Polkadot and seven days for Kusama), after which the tokens will be transferable.\n\nTo unbond tokens, go to **Network > Staking > Account Actions** on Polkadot.js Apps. Select your stash account, click on the dropdown menu, and choose **Unbond Funds**. Alternatively, you can use the `staking.unbond` extrinsic if you handle this via a staking proxy account.\n\nOnce the unbonding period is complete, your tokens will be available for use in transactions or transfers outside of staking."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 759, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nValidator performance is pivotal in maintaining the security and stability of the Polkadot network. As a validator, optimizing your setup ensures efficient transaction processing, minimizes latency, and maintains system reliability during high-demand periods. Proper configuration and proactive monitoring also help mitigate risks like slashing and service interruptions.\n\nThis guide covers essential practices for managing a validator, including performance tuning techniques, security hardening, and tools for real-time monitoring. Whether you're fine-tuning CPU settings, configuring NUMA balancing, or setting up a robust alert system, these steps will help you build a resilient and efficient validator operation."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 1, "depth": 2, "title": "Configuration Optimization", "anchor": "configuration-optimization", "start_char": 759, "end_char": 987, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Configuration Optimization\n\nFor those seeking to optimize their validator's performance, the following configurations can improve responsiveness, reduce latency, and ensure consistent performance during high-demand periods."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 2, "depth": 3, "title": "Deactivate Simultaneous Multithreading", "anchor": "deactivate-simultaneous-multithreading", "start_char": 987, "end_char": 2454, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "### Deactivate Simultaneous Multithreading\n\nPolkadot validators operate primarily in single-threaded mode for critical tasks, so optimizing single-core CPU performance can reduce latency and improve stability. Deactivating simultaneous multithreading (SMT) can prevent virtual cores from affecting performance. SMT is called Hyper-Threading on Intel and 2-way SMT on AMD Zen.\n\nTake the following steps to deactivate every other (vCPU) core:\n\n1. Loop though all the CPU cores and deactivate the virtual cores associated with them:\n\n    ```bash\n    for cpunum in $(cat /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | \\\n    cut -s -d, -f2- | tr ',' '\\n' | sort -un)\n    do\n    echo 0 > /sys/devices/system/cpu/cpu$cpunum/online\n    done\n    ```\n\n2. To permanently save the changes, add `nosmt=force` to the `GRUB_CMDLINE_LINUX_DEFAULT` variable in `/etc/default/grub`:\n\n    ```bash\n    sudo nano /etc/default/grub\n    # Add to GRUB_CMDLINE_LINUX_DEFAULT\n    ```\n\n    ```config title=\"/etc/default/grub\"\n    GRUB_DEFAULT = 0;\nGRUB_HIDDEN_TIMEOUT = 0;\nGRUB_HIDDEN_TIMEOUT_QUIET = true;\nGRUB_TIMEOUT = 10;\nGRUB_DISTRIBUTOR = `lsb_release -i -s 2> /dev/null || echo Debian`;\nGRUB_CMDLINE_LINUX_DEFAULT = 'nosmt=force';\nGRUB_CMDLINE_LINUX = '';\n    ```\n\n3. Update GRUB to apply changes:\n\n    ```bash\n    sudo update-grub\n    ```\n\n4. After the reboot, you should see that half of the cores are offline. To confirm, run:\n\n    ```bash\n    lscpu --extended\n    ```"}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 3, "depth": 3, "title": "Deactivate Automatic NUMA Balancing", "anchor": "deactivate-automatic-numa-balancing", "start_char": 2454, "end_char": 3506, "estimated_token_count": 220, "token_estimator": "heuristic-v1", "text": "### Deactivate Automatic NUMA Balancing\n\nDeactivating NUMA (Non-Uniform Memory Access) balancing for multi-CPU setups helps keep processes on the same CPU node, minimizing latency.\n\nFollow these stpes:\n\n1. Deactivate NUMA balancing in runtime:\n\n    ```bash\n    sysctl kernel.numa_balancing=0\n    ```\n\n2. Deactivate NUMA balancing permanently by adding `numa_balancing=disable` to the GRUB settings:\n\n    ```bash\n    sudo nano /etc/default/grub\n    # Add to GRUB_CMDLINE_LINUX_DEFAULT\n    ```\n\n    ```config title=\"/etc/default/grub\"\n    GRUB_DEFAULT = 0;\nGRUB_HIDDEN_TIMEOUT = 0;\nGRUB_HIDDEN_TIMEOUT_QUIET = true;\nGRUB_TIMEOUT = 10;\nGRUB_DISTRIBUTOR = `lsb_release -i -s 2> /dev/null || echo Debian`;\nGRUB_CMDLINE_LINUX_DEFAULT = 'numa_balancing=disable';\nGRUB_CMDLINE_LINUX = '';\n    ```\n\n3. Update GRUB to apply changes:\n\n    ```bash\n    sudo update-grub\n    ```\n\n4. Confirm the deactivation:\n\n    ```bash\n    sysctl -a | grep 'kernel.numa_balancing'\n    ```\n\nIf you successfully deactivated NUMA balancing, the preceding command should return `0`."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 4, "depth": 3, "title": "Spectre and Meltdown Mitigations", "anchor": "spectre-and-meltdown-mitigations", "start_char": 3506, "end_char": 5138, "estimated_token_count": 319, "token_estimator": "heuristic-v1", "text": "### Spectre and Meltdown Mitigations\n\n[Spectre](https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)){target=\\_blank} and [Meltdown](https://en.wikipedia.org/wiki/Meltdown_(security_vulnerability)){target=\\_blank} are well-known CPU vulnerabilities that exploit speculative execution to access sensitive data. These vulnerabilities have been patched in recent Linux kernels, but the mitigations can slightly impact performance, especially in high-throughput or containerized environments.\n\nIf your security requirements allow it, you can deactivate specific mitigations, such as Spectre V2 and Speculative Store Bypass Disable (SSBD), to improve performance.\n\nTo selectively deactivate the Spectre mitigations, take these steps:\n\n1. Update the `GRUB_CMDLINE_LINUX_DEFAULT` variable in your `/etc/default/grub` configuration:\n\n    ```bash\n    sudo nano /etc/default/grub\n    # Add to GRUB_CMDLINE_LINUX_DEFAULT\n    ```\n\n    ```config title=\"/etc/default/grub\"\n    GRUB_DEFAULT = 0;\nGRUB_HIDDEN_TIMEOUT = 0;\nGRUB_HIDDEN_TIMEOUT_QUIET = true;\nGRUB_TIMEOUT = 10;\nGRUB_DISTRIBUTOR = `lsb_release -i -s 2> /dev/null || echo Debian`;\nGRUB_CMDLINE_LINUX_DEFAULT =\n  'spec_store_bypass_disable=prctl spectre_v2_user=prctl';\n    ```\n\n2. Update GRUB to apply changes and then reboot:\n\n    ```bash\n    sudo update-grub\n    sudo reboot\n    ```\n\nThis approach selectively deactivates the Spectre V2 and Spectre V4 mitigations, leaving other protections intact. For full security, keep mitigations activated unless there's a significant performance need, as disabling them could expose the system to potential attacks on affected CPUs."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 5, "depth": 2, "title": "Monitor Your Node", "anchor": "monitor-your-node", "start_char": 5138, "end_char": 5835, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Monitor Your Node\n\nMonitoring your node's performance is critical for network reliability and security. Tools like the following provide valuable insights:\n\n- **[Prometheus](https://prometheus.io/){target=\\_blank}**: An open-source monitoring toolkit for collecting and querying time-series data.\n- **[Grafana](https://grafana.com/){target=\\_blank}**: A visualization tool for real-time metrics, providing interactive dashboards.\n- **[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/){target=\\_blank}**: A tool for managing and routing alerts based on Prometheus data.\n\nThis section covers setting up these tools and configuring alerts to notify you of potential issues."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 6, "depth": 3, "title": "Environment Setup", "anchor": "environment-setup", "start_char": 5835, "end_char": 6529, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "### Environment Setup\n\nBefore installing Prometheus, ensure the environment is set up securely by running Prometheus with restricted user privileges.\n\nFollow these steps:\n\n1. Create a Prometheus user to ensure Prometheus runs with minimal permissions:\n\n    ```bash\n    sudo useradd --no-create-home --shell /usr/sbin/nologin prometheus\n    ```\n\n2. Create directories for configuration and data storage:\n\n    ```bash\n    sudo mkdir /etc/prometheus\n    sudo mkdir /var/lib/prometheus\n    ```\n  \n3. Change directory ownership to ensure Prometheus has access:\n\n    ```bash\n    sudo chown -R prometheus:prometheus /etc/prometheus\n    sudo chown -R prometheus:prometheus /var/lib/prometheus\n    ```"}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 7, "depth": 3, "title": "Install and Configure Prometheus", "anchor": "install-and-configure-prometheus", "start_char": 6529, "end_char": 8927, "estimated_token_count": 536, "token_estimator": "heuristic-v1", "text": "### Install and Configure Prometheus\n\nAfter setting up the environment, install and configure the latest version of Prometheus as follows:\n\n1. Download Prometheus for your system architecture from the [releases page](https://github.com/prometheus/prometheus/releases/){target=\\_blank}. Replace `INSERT_RELEASE_DOWNLOAD` with the release binary URL (e.g., `https://github.com/prometheus/prometheus/releases/download/v3.0.0/prometheus-3.0.0.linux-amd64.tar.gz`):\n\n    ```bash\n    sudo apt-get update && sudo apt-get upgrade\n    wget INSERT_RELEASE_DOWNLOAD_LINK\n    tar xfz prometheus-*.tar.gz\n    cd prometheus-3.0.0.linux-amd64\n    ```\n\n2. Set up Prometheus:\n\n    1. Copy binaries:\n\n        ```bash\n        sudo cp ./prometheus /usr/local/bin/\n        sudo cp ./promtool /usr/local/bin/\n        sudo cp ./prometheus /usr/local/bin/\n        ```\n\n    2. Copy directories and assign ownership of these files to the `prometheus` user:\n\n        ```bash\n        sudo cp -r ./consoles /etc/prometheus\n        sudo cp -r ./console_libraries /etc/prometheus\n        sudo chown -R prometheus:prometheus /etc/prometheus/consoles\n        sudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\n        ```\n\n    3. Clean up the download directory:\n\n        ```bash\n        cd .. && rm -r prometheus*\n        ```\n\n3. Create `prometheus.yml` to define global settings, rule files, and scrape targets:\n\n    ```bash\n    sudo nano /etc/prometheus/prometheus.yml\n    ```\n\n    ```yaml title=\"prometheus-config.yml\"\n    -global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nrule_files:\n  # - \"first.rules\"\n  # - \"second.rules\"\n\nscrape_configs:\n  - job_name: 'prometheus'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9090']\n  - job_name: 'substrate_node'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9615']\n    ```\n\n    Prometheus is scraped every 5 seconds in this example configuration file, ensuring detailed internal metrics. Node metrics with customizable intervals are scraped from port `9615` by default.\n\n4. Verify the configuration with `promtool`, an open source monitoring tool:\n\n    ```bash\n    promtool check config /etc/prometheus/prometheus.yml\n    ```\n\n5. Save the configuration and change the ownership of the file to `prometheus` user:\n\n    ```bash\n    sudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\n    ```"}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 8, "depth": 3, "title": "Start Prometheus", "anchor": "start-prometheus", "start_char": 8927, "end_char": 10702, "estimated_token_count": 411, "token_estimator": "heuristic-v1", "text": "### Start Prometheus\n\n1. Launch Prometheus with the appropriate configuration file, storage location, and necessary web resources, running it with restricted privileges for security:\n\n    ```bash\n    sudo -u prometheus /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml \\\n    --storage.tsdb.path /var/lib/prometheus/ \\\n    --web.console.templates=/etc/prometheus/consoles \\\n    --web.console.libraries=/etc/prometheus/console_libraries\n    ```\n\n    If you set the server up properly, you should see terminal output similar to the following:\n\n    \n\n2. Verify you can access the Prometheus interface by navigating to:\n\n    ```text\n    http://SERVER_IP_ADDRESS:9090/graph\n    ```\n\n    If the interface appears to work as expected, exit the process using `Control + C`.\n\n3. Create a systemd service file to ensure Prometheus starts on boot:\n\n    ```bash\n    sudo nano /etc/systemd/system/prometheus.service\n    ```\n\n    ```bash title=\"prometheus.service\"\n    -[Unit]\nDescription=Prometheus Monitoring\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=prometheus\nGroup=prometheus\nType=simple\nExecStart=/usr/local/bin/prometheus \\\n --config.file /etc/prometheus/prometheus.yml \\\n --storage.tsdb.path /var/lib/prometheus/ \\\n --web.console.templates=/etc/prometheus/consoles \\\n --web.console.libraries=/etc/prometheus/console_libraries\nExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n\n    ```\n\n4. Reload systemd and enable the service to start on boot:\n\n    ```bash\n    sudo systemctl daemon-reload && sudo systemctl enable prometheus && sudo systemctl start prometheus\n    ```\n\n5. Verify the service is running by visiting the Prometheus interface again at:\n\n    ```text\n    http://SERVER_IP_ADDRESS:9090/\n    ```"}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 9, "depth": 3, "title": "Install and Configure Grafana", "anchor": "install-and-configure-grafana", "start_char": 10702, "end_char": 14360, "estimated_token_count": 911, "token_estimator": "heuristic-v1", "text": "### Install and Configure Grafana\n\nThis guide follows [Grafana's canonical installation instructions](https://grafana.com/docs/grafana/latest/setup-grafana/installation/debian/#install-from-apt-repository){target=\\_blank}.\n\nTo install and configure Grafana, follow these steps:\n\n1. Install Grafana prerequisites:\n\n    ```bash\n    sudo apt-get install -y apt-transport-https software-properties-common wget    \n    ```\n\n2. Import the [GPG key](https://gnupg.org/){target=\\_blank}:\n\n    ```bash\n    sudo mkdir -p /etc/apt/keyrings/\n    wget -q -O - https://apt.grafana.com/gpg.key | gpg --dearmor | sudo tee /etc/apt/keyrings/grafana.gpg > /dev/null\n    ```\n\n3. Configure the stable release repo and update packages:\n\n    ```bash\n    echo \"deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\n    sudo apt-get update\n    ```\n\n4. Install the latest stable version of Grafana:\n\n    ```bash\n    sudo apt-get install grafana\n    ```\n\nTo configure Grafana, take these steps:\n\n1. Configure Grafana to start automatically on boot and start the service:\n\n    ```bash\n    sudo systemctl daemon-reload\n    sudo systemctl enable grafana-server.service\n    sudo systemctl start grafana-server\n    ```\n\n2. Check if Grafana is running:\n\n    ```bash\n    sudo systemctl status grafana-server\n    ```\n\n    If necessary, you can stop or restart the service with the following commands:\n\n    ```bash\n    sudo systemctl stop grafana-server\n    sudo systemctl restart grafana-server\n    ```\n\n3. Access Grafana by navigating to the following URL and logging in with the default username and password (`admin`):\n\n    ```text\n    http://SERVER_IP_ADDRESS:3000/login\n    ```\n\n    !!! tip \"Change default port\"\n        To change Grafana's port, edit `/usr/share/grafana/conf/defaults.ini`:\n\n        ```bash\n        sudo vim /usr/share/grafana/conf/defaults.ini\n        ```\n\n        Modify the `http_port` value, then restart Grafana:\n\n        ```bash\n        sudo systemctl restart grafana-server\n        ```\n\n![Grafana login screen](/images/infrastructure/running-a-validator/operational-tasks/general-management/general-management-1.webp)\n\nTo visualize node metrics, follow these steps:\n\n1. Select the gear icon to access **Data Sources** settings.\n2. Select **Add data source** to define the data source.\n\n    ![Select Prometheus](/images/infrastructure/running-a-validator/operational-tasks/general-management/general-management-2.webp)\n\n3. Select **Prometheus**.\n\n    ![Save and test](/images/infrastructure/running-a-validator/operational-tasks/general-management/general-management-3.webp)\n\n4. Enter `http://localhost:9090` in the **URL** field and click **Save & Test**. If **\"Data source is working\"** appears, your connection is configured correctly.\n\n    ![Import dashboard](/images/infrastructure/running-a-validator/operational-tasks/general-management/general-management-4.webp)\n\n5. Select **Import** from the left menu, choose **Prometheus** from the dropdown, and click **Import**.\n\n6. Start your Polkadot node by running `./polkadot`. You should now be able to monitor node performance, block height, network traffic, and tasks tasks on the Grafana dashboard.\n\n    ![Live dashboard](/images/infrastructure/running-a-validator/operational-tasks/general-management/general-management-5.webp)\n\nThe [Grafana dashboards](https://grafana.com/grafana/dashboards){target=\\_blank} page features user created dashboards made available for public use. For an example, see the [Substrate Node Metrics](https://grafana.com/grafana/dashboards/21715-substrate-node-metrics/){target=\\_blank} dashboard."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 10, "depth": 3, "title": "Install and Configure Alertmanager", "anchor": "install-and-configure-alertmanager", "start_char": 14360, "end_char": 21420, "estimated_token_count": 1629, "token_estimator": "heuristic-v1", "text": "### Install and Configure Alertmanager\n\n[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/){target=\\_blank} is an optional component that complements Prometheus by managing alerts and notifying users about potential issues.\n\nFollow these steps to install and configure Alertmanager:\n\n1. Download Alertmanager for your system architecture from the [releases page](https://github.com/prometheus/alertmanager/releases){target=\\_blank}. Replace `INSERT_RELEASE_DOWNLOAD` with the release binary URL (e.g., `https://github.com/prometheus/alertmanager/releases/download/v0.28.0-rc.0/alertmanager-0.28.0-rc.0.linux-amd64.tar.gz`):\n\n    ```bash\n    wget INSERT_RELEASE_DOWNLOAD_LINK\n    tar -xvzf alertmanager*\n    ```\n\n2. Copy the binaries to the system directory and set permissions:\n\n    ```bash\n    cd alertmanager-0.28.0-rc.0.linux-amd64\n    sudo cp ./alertmanager /usr/local/bin/\n    sudo cp ./amtool /usr/local/bin/\n    sudo chown prometheus:prometheus /usr/local/bin/alertmanager\n    sudo chown prometheus:prometheus /usr/local/bin/amtool\n    ```\n\n3. Create the `alertmanager.yml` configuration file under `/etc/alertmanager`:\n\n    ```bash\n    sudo mkdir /etc/alertmanager\n    sudo nano /etc/alertmanager/alertmanager.yml\n    ```\n\n    Generate an [app password in your Google account](https://support.google.com/accounts/answer/185833?hl=en){target=\\_blank} to enable email notifications from Alertmanager. Then, add the following code to the configuration file to define email notifications using your  email and app password: \n\n    ```yml title=\"alertmanager.yml\"\n    global:\n  resolve_timeout: 1m\n\nroute:\n  receiver: 'gmail-notifications'\n\nreceivers:\n  - name: 'gmail-notifications'\n    email_configs:\n      - to: INSERT_YOUR_EMAIL\n        from: INSERT_YOUR_EMAIL\n        smarthost: smtp.gmail.com:587\n        auth_username: INSERT_YOUR_EMAIL\n        auth_identity: INSERT_YOUR_EMAIL\n        auth_password: INSERT_YOUR_APP_PASSWORD\n        send_resolved: true\n\n    ```\n\n\n    ```bash\n    sudo chown -R prometheus:prometheus /etc/alertmanager\n    ```\n\n4. Configure Alertmanager as a service by creating a systemd service file:\n\n    ```bash\n    sudo nano /etc/systemd/system/alertmanager.service\n    ```\n\n    ```yml title=\"alertmanager.service\"\n    [Unit]\nDescription=AlertManager Server Service\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=root\nGroup=root\nType=simple\nExecStart=/usr/local/bin/alertmanager --config.file /etc/alertmanager/alertmanager.yml --web.external-url=http://SERVER_IP:9093 --cluster.advertise-address='0.0.0.0:9093'\n\n[Install]\nWantedBy=multi-user.target\n\n    ```\n\n5. Reload and enable the service:\n\n    ```bash\n    sudo systemctl daemon-reload\n    sudo systemctl enable alertmanager\n    sudo systemctl start alertmanager\n    ```\n\n6. Verify the service status:\n\n    ```bash\n    sudo systemctl status alertmanager\n    ```\n\n    If you have configured Alertmanager properly, the **Active** field should display **active (running)** similar to below:\n\n    <div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>sudo systemctl status alertmanager</span>\n  <span data-ty>alertmanager.service - AlertManager Server Service</span>\n  <span data-ty>Loaded: loaded (/etc/systemd/system/alertmanager.service; enabled; vendor preset: enabled)</span>\n  <span data-ty>Active: active (running) since Thu 2020-08-20 22:01:21 CEST; 3 days ago</span>\n  <span data-ty>Main PID: 20592 (alertmanager)</span>\n  <span data-ty>Tasks: 70 (limit: 9830)</span>\n  <span data-ty>CGroup: /system.slice/alertmanager.service</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>\n\n\n#### Grafana Plugin\n\nThere is an [Alertmanager plugin in Grafana](https://grafana.com/grafana/plugins/alertmanager/){target=\\_blank} that can help you monitor alert information.\n\nFollow these steps to use the plugin:\n\n1. Install the plugin:\n\n    ```bash\n    sudo grafana-cli plugins install camptocamp-prometheus-alertmanager-datasource\n    ```\n\n2. Restart Grafana:\n\n    ```bash\n    sudo systemctl restart grafana-server\n    ```\n\n3. Configure Alertmanager as a data source in your Grafana dashboard (`SERVER_IP:3000`):\n\n    1. Go to **Configuration** > **Data Sources** and search for **Prometheus Alertmanager**.\n    2. Enter the server URL and port for the Alertmanager service, and select **Save & Test** to verify the connection.\n\n4. Import the [8010](https://grafana.com/grafana/dashboards/8010-prometheus-alertmanager/){target=\\_blank} dashboard for Alertmanager, selecting **Prometheus Alertmanager** in the last column, then select **Import**.\n\n#### Integrate Alertmanager\n\nComplete the integration by following these steps to enable communication between Prometheus and Alertmanager and configure detection and alert rules:\n\n1. Update the `etc/prometheus/prometheus.yml` configuration file to include the following code:\n\n    ```yml title=\"prometheus.yml\"\n    -rule_files:\n  - 'rules.yml'\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n            - localhost:9093\n    ```\n\n    Expand the following item to view the complete `prometheus.yml` file.\n\n    ??? code \"prometheus.yml\"\n\n        ```yml title=\"prometheus.yml\"\n        -global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nrule_files:\n  - 'rules.yml'\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n            - localhost:9093\n\nscrape_configs:\n  - job_name: 'prometheus'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9090']\n  - job_name: 'substrate_node'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9615']\n\n        ```\n\n2. Create the rules file for detection and alerts:\n\n    ```bash\n    sudo nano /etc/prometheus/rules.yml\n    ```\n\n    Add a sample rule to trigger email notifications for node downtime over five minutes:\n\n    ```yml title=\"rules.yml\"\n    groups:\n  - name: alert_rules\n    rules:\n      - alert: InstanceDown\n        expr: up == 0\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: 'Instance [{{ $labels.instance }}] down'\n          description: '[{{ $labels.instance }}] of job [{{ $labels.job }}] has been down for more than 5 minutes.'\n\n    ```\n\n    If any of the conditions defined in the rules file are met, an alert will be triggered. For more on alert rules, refer to [Alerting Rules](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/){target=\\_blank} and [additional alerts](https://samber.github.io/awesome-prometheus-alerts/rules.html){target=\\_blank}.\n\n3. Update the file ownership to `prometheus`:\n\n    ```bash\n    sudo chown prometheus:prometheus rules.yml\n    ```\n\n4. Validate the rules syntax:\n\n    ```bash\n    sudo -u prometheus promtool check rules rules.yml\n    ```\n\n5. Restart Prometheus and Alertmanager:\n\n    ```bash\n    sudo systemctl restart prometheus && sudo systemctl restart alertmanager\n    ```\n\nNow you will receive an email alert if one of your rule triggering conditions is met."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 11, "depth": 2, "title": "Secure Your Validator", "anchor": "secure-your-validator", "start_char": 21420, "end_char": 21772, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Secure Your Validator\n\nValidators in Polkadot's Proof of Stake (PoS) network play a critical role in maintaining network integrity and security by keeping the network in consensus and verifying state transitions. To ensure optimal performance and minimize risks, validators must adhere to strict guidelines around security and reliable operations."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 12, "depth": 3, "title": "Key Management", "anchor": "key-management", "start_char": 21772, "end_char": 23039, "estimated_token_count": 261, "token_estimator": "heuristic-v1", "text": "### Key Management\n\nThough they don't transfer funds, session keys are essential for validators as they sign messages related to consensus and parachains. Securing session keys is crucial as allowing them to be exploited or used across multiple nodes can lead to a loss of staked funds via [slashing](/infrastructure/staking-mechanics/offenses-and-slashes/){target=\\_blank}.\n\nGiven the current limitations in high-availability setups and the risks associated with double-signing, it’s recommended to run only a single validator instance. Keys should be securely managed, and processes automated to minimize human error.\n\nThere are two approaches for generating session keys:\n\n- **Generate and store in node**: Using the `author.rotateKeys` RPC call. For most users, generating keys directly within the client is recommended. You must submit a session certificate from your staking proxy to register new keys. See the [How to Validate](/infrastructure/running-a-validator/onboarding-and-offboarding/set-up-validator/){target=\\_blank} guide for instructions on setting keys.\n\n- **Generate outside node and insert**: Using the `author.setKeys` RPC call. This flexibility accommodates advanced security setups and should only be used by experienced validator operators."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 13, "depth": 3, "title": "Signing Outside the Client", "anchor": "signing-outside-the-client", "start_char": 23039, "end_char": 23331, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Signing Outside the Client\n\nPolkadot plans to support external signing, allowing session keys to reside in secure environments like Hardware Security Modules (HSMs). However, these modules can sign any payload they receive, potentially enabling an attacker to perform slashable actions."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 14, "depth": 3, "title": "Secure-Validator Mode", "anchor": "secure-validator-mode", "start_char": 23331, "end_char": 24092, "estimated_token_count": 169, "token_estimator": "heuristic-v1", "text": "### Secure-Validator Mode\n\nPolkadot's Secure-Validator mode offers an extra layer of protection through strict filesystem, networking, and process sandboxing. This secure mode is activated by default if the machine meets the following requirements:\n\n- **Linux (x86-64 architecture)**: Usually Intel or AMD.\n- **Enabled `seccomp`**: This kernel feature facilitates a more secure approach for process management on Linux. Verify by running.\n\n    ```bash\n    cat /boot/config-`uname -r` | grep CONFIG_SECCOMP=\n    ```\n\n    If `seccomp` is enabled, you should see output similar to the following:\n\n    ```bash\n    CONFIG_SECCOMP=y\n    ```\n\n!!! tip \n    Optionally, **Linux 5.13** may also be used, as it provides access to even more strict filesystem protections."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 15, "depth": 3, "title": "Linux Best Practices", "anchor": "linux-best-practices", "start_char": 24092, "end_char": 24550, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "### Linux Best Practices\n\nFollow these best practices to keep your validator secure:\n\n- Use a non-root user for all operations.\n- Regularly apply OS security patches.\n- Enable and configure a firewall.\n- Use key-based SSH authentication; deactivate password-based login.\n- Regularly back up data and harden your SSH configuration. Visit this [SSH guide](https://blog.stribik.technology/2015/01/04/secure-secure-shell.html){target=\\_blank} for more details."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 16, "depth": 3, "title": "Validator Best Practices", "anchor": "validator-best-practices", "start_char": 24550, "end_char": 25308, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### Validator Best Practices\n\nAdditional best practices can add an additional layer of security and operational reliability:\n\n- Only run the Polkadot binary, and only listen on the configured p2p port.\n- Run on bare-metal machines, as opposed to virtual machines.\n- Provisioning of the validator machine should be automated and defined in code which is kept in private version control, reviewed, audited, and tested.\n- Generate and provide session keys in a secure way.\n- Start Polkadot at boot and restart if stopped for any reason.\n- Run Polkadot as a non-root user.\n- Establish and maintain an on-call rotation for managing alerts.\n- Establish and maintain a clear protocol with actions to perform for each level of each alert with an escalation policy."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-general-management", "index": 17, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 25308, "end_char": 25922, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- [Certus One's Knowledge Base](https://knowledgebase.certus.com/FAQ/){target=\\_blank}\n- [EOS Block Producer Security List](https://github.com/slowmist/eos-bp-nodes-security-checklist){target=\\_blank}\n- [HSM Policies and the Importance of Validator Security](https://medium.com/loom-network/hsm-policies-and-the-importance-of-validator-security-ec8a4cc1b6f){target=\\_blank}\n\nFor additional guidance, connect with other validators and the Polkadot engineering team in the [Polkadot Validator Lounge](https://matrix.to/#/#polkadotvalidatorlounge:web3.foundation){target=\\_blank} on Element."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-pause-validating", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 554, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIf you need to temporarily stop participating in Polkadot staking activities without fully unbonding your funds, chilling your account allows you to do so efficiently. Chilling removes your node from active validation or nomination in the next era while keeping your funds bonded, making it ideal for planned downtimes or temporary pauses.\n\nThis guide covers the steps for chilling as a validator or nominator, using the `chill` and `chillOther` extrinsics, and how these affect your staking status and nominations."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-pause-validating", "index": 1, "depth": 2, "title": "Chilling Your Node", "anchor": "chilling-your-node", "start_char": 554, "end_char": 1176, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Chilling Your Node\n\nIf you need to temporarily step back from staking without unbonding your funds, you can \"chill\" your account. Chilling pauses your active staking participation, setting your account to inactive in the next era while keeping your funds bonded.\n\nTo chill your account, go to the **Network > Staking > Account Actions** page on [Polkadot.js Apps](https://polkadot.js.org/apps){target=\\_blank}, and select **Stop**. Alternatively, you can call the [`chill`](https://paritytech.github.io/polkadot-sdk/master/pallet_staking/enum.Call.html#variant.chill){target=\\_blank} extrinsic in the Staking pallet."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-pause-validating", "index": 2, "depth": 2, "title": "Staking Election Timing Considerations", "anchor": "staking-election-timing-considerations", "start_char": 1176, "end_char": 1775, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Staking Election Timing Considerations\n\nWhen a node actively participates in staking but then chills, it will continue contributing for the remainder of the current era. However, its eligibility for the next election depends on the chill status at the start of the new era:\n\n- **Chilled during previous era**: Will not participate in the current era election and will remain inactive until reactivated.\n-**Chilled during current era**: Will not be selected for the next era's election.\n-**Chilled after current era**: May be selected if it was active during the previous era and is now chilled."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-pause-validating", "index": 3, "depth": 2, "title": "Chilling as a Nominator", "anchor": "chilling-as-a-nominator", "start_char": 1775, "end_char": 2552, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Chilling as a Nominator\n\nWhen you choose to chill as a nominator, your active nominations are reset. Upon re-entering the nominating process, you must reselect validators to support manually. Depending on preferences, these can be the same validators as before or a new set. Remember that your previous nominations won’t be saved or automatically reactivated after chilling.\n\nWhile chilled, your nominator account remains bonded, preserving your staked funds without requiring a full unbonding process. When you’re ready to start nominating again, you can issue a new nomination call to activate your bond with a fresh set of validators. This process bypasses the need for re-bonding, allowing you to maintain your stake while adjusting your involvement in active staking."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-pause-validating", "index": 4, "depth": 2, "title": "Chilling as a Validator", "anchor": "chilling-as-a-validator", "start_char": 2552, "end_char": 3450, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## Chilling as a Validator\n\nWhen you chill as a validator, your active validator status is paused. Although your nominators remain bonded to you, the validator bond will no longer appear as an active choice for new or revised nominations until reactivated. Any existing nominators who take no action will still have their stake linked to the validator, meaning they don’t need to reselect the validator upon reactivation. However, if nominators adjust their stakes while the validator is chilled, they will not be able to nominate the chilled validator until it resumes activity.\n\nUpon reactivating as a validator, you must also reconfigure your validator preferences, such as commission rate and other parameters. These can be set to match your previous configuration or updated as desired. This step is essential for rejoining the active validator set and regaining eligibility for nominations."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-pause-validating", "index": 5, "depth": 2, "title": "Chill Other", "anchor": "chill-other", "start_char": 3450, "end_char": 4437, "estimated_token_count": 191, "token_estimator": "heuristic-v1", "text": "## Chill Other\n\nHistorical constraints in the runtime prevented unlimited nominators and validators from being supported. These constraints created a need for checks to keep the size of the staking system manageable. One of these checks is the `chillOther` extrinsic, allowing users to chill accounts that no longer met standards such as minimum staking requirements set through on-chain governance.\n\nThis control mechanism included a `ChillThreshold`, which was structured to define how close to the maximum number of nominators or validators the staking system would be allowed to get before users could start chilling one another. With the passage of [Referendum #90](https://polkadot-old.polkassembly.io/referendum/90){target=\\_blank}, the value for `maxNominatorCount` on Polkadot was set to `None`, effectively removing the limit on how many nominators and validators can participate. This means the `ChillThreshold` will never be met; thus, `chillOther` no longer has any effect."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 821, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUpgrading a Polkadot validator node is essential for staying current with network updates and maintaining optimal performance. This guide covers routine and extended maintenance scenarios, including software upgrades and major server changes. Following these steps, you can manage session keys and transition smoothly between servers without risking downtime, slashing, or network disruptions. The process requires strategic planning, especially if you need to perform long-lead maintenance, ensuring your validator remains active and compliant.\n\nThis guide will allow validators to seamlessly substitute an active validator server to allow for maintenance operations. The process can take several hours, so ensure you understand the instructions first and plan accordingly."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 821, "end_char": 1374, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore beginning the upgrade process for your validator node, ensure the following:\n\n- You have a fully functional validator setup with all required binaries installed. See [Set Up a Validator](/infrastructure/running-a-validator/onboarding-and-offboarding/set-up-validator/){target=\\_blank} and [Validator Requirements](/infrastructure/running-a-validator/requirements/){target=\\_blank} for additional guidance.\n- Your VPS infrastructure has enough capacity to run a secondary validator instance temporarily for the upgrade process."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 2, "depth": 2, "title": "Session Keys", "anchor": "session-keys", "start_char": 1374, "end_char": 2087, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "## Session Keys\n\nSession keys are used to sign validator operations and establish a connection between your validator node and your staking proxy account. These keys are stored in the client, and any change to them requires a waiting period. Specifically, if you modify your session keys, the change will take effect only after the current session is completed and two additional sessions have passed.\n\nRemembering this delayed effect when planning upgrades is crucial to ensure that your validator continues to function correctly and avoids interruptions. To learn more about session keys and their importance, visit the [Keys section](https://wiki.polkadot.com/learn/learn-cryptography/#keys){target=\\_blank}."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 3, "depth": 2, "title": "Keystore", "anchor": "keystore", "start_char": 2087, "end_char": 2859, "estimated_token_count": 158, "token_estimator": "heuristic-v1", "text": "## Keystore\n\nYour validator server's `keystore` folder holds the private keys needed for signing network-level transactions. It is important not to duplicate or transfer this folder between validator instances. Doing so could result in multiple validators signing with the duplicate keys, leading to severe consequences such as [equivocation slashing](/infrastructure/staking-mechanics/offenses-and-slashes/#equivocation-slash){target=\\_blank}. Instead, always generate new session keys for each validator instance.\n\nThe default path to the `keystore` is as follows:\n\n```bash\n/home/polkadot/.local/share/polkadot/chains/<chain>/keystore\n```\n\nTaking care to manage your keys securely ensures that your validator operates safely and without the risk of slashing penalties."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 4, "depth": 2, "title": "Upgrade Using Backup Validator", "anchor": "upgrade-using-backup-validator", "start_char": 2859, "end_char": 3111, "estimated_token_count": 41, "token_estimator": "heuristic-v1", "text": "## Upgrade Using Backup Validator\n\nThe following instructions outline how to temporarily switch between two validator nodes. The original active validator is referred to as Validator A and the backup node used for maintenance purposes as Validator B."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 5, "depth": 3, "title": "Session `N`", "anchor": "session-n", "start_char": 3111, "end_char": 4063, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Session `N`\n\n1. **Start Validator B**: Launch a secondary node and wait until it is fully synced with the network. Once synced, start it with the `--validator` flag. This node will now act as Validator B.\n2. **Generate session keys**: Create new session keys specifically for Validator B.\n3. **Submit the `set_key` extrinsic**: Use your staking proxy account to submit a `set_key` extrinsic, linking the session keys for Validator B to your staking setup.\n4. **Record the session**: Make a note of the session in which you executed this extrinsic.\n5. **Wait for session changes**: Allow the current session to end and then wait for two additional full sessions for the new keys to take effect.\n\n!!! warning \"Keep Validator A running\"\n\n      It is crucial to keep Validator A operational during this entire waiting period. Since `set_key` does not take effect immediately, turning off Validator A too early may result in chilling or even slashing."}
{"page_id": "infrastructure-running-a-validator-operational-tasks-upgrade-your-node", "index": 6, "depth": 3, "title": "Session `N+3`", "anchor": "session-n3", "start_char": 4063, "end_char": 5625, "estimated_token_count": 379, "token_estimator": "heuristic-v1", "text": "### Session `N+3`\n\nAt this stage, Validator B becomes your active validator. You can now safely perform any maintenance tasks on Validator A.\n\nComplete the following steps when you are ready to bring Validator A back online:\n\n1. **Start Validator A**: Launch Validator A, sync the blockchain database, and ensure it is running with the `--validator` flag.\n2. **Generate new session keys for Validator A**: Create fresh session keys for Validator A.\n3. **Submit the `set_key` extrinsic**: Using your staking proxy account, submit a `set_key` extrinsic with the new Validator A session keys.\n4. **Record the session**: Again, make a note of the session in which you executed this extrinsic.\n\nKeep Validator B active until the session during which you executed the `set-key` extrinsic completes plus two additional full sessions have passed. Once Validator A has successfully taken over, you can safely stop Validator B. This process helps ensure a smooth handoff between nodes and minimizes the risk of downtime or penalties. Verify the transition by checking for finalized blocks in the new session. The logs should indicate the successful change, similar to the example below:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>INSERT_COMMAND</span>\n  <span data-ty>2019-10-28 21:44:13 Applying authority set change scheduled at block #450092</span>\n  <span data-ty>2019-10-28 21:44:13 Applying GRANDPA set change to new set with 20 authorities</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "infrastructure-running-a-validator-requirements", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 26, "end_char": 981, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRunning a validator in the Polkadot ecosystem is essential for maintaining network security and decentralization. Validators are responsible for validating transactions and adding new blocks to the chain, ensuring the system operates smoothly. In return for their services, validators earn rewards. However, the role comes with inherent risks, such as slashing penalties for misbehavior or technical failures. If you’re new to validation, starting on Kusama provides a lower-stakes environment to gain valuable experience before progressing to the Polkadot network.\n\nThis guide covers everything you need to know about becoming a validator, including system requirements, staking prerequisites, and infrastructure setup. Whether you’re deploying on a VPS or running your node on custom hardware, you’ll learn how to optimize your validator for performance and security, ensuring compliance with network standards while minimizing risks."}
{"page_id": "infrastructure-running-a-validator-requirements", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 981, "end_char": 2390, "estimated_token_count": 296, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nRunning a validator requires solid system administration skills and a secure, well-maintained infrastructure. Below are the primary requirements you need to be aware of before getting started:\n\n- **System administration expertise**: Handling technical anomalies and maintaining node infrastructure is critical. Validators must be able to troubleshoot and optimize their setup.\n- **Security**: Ensure your setup follows best practices for securing your node. Refer to the [Secure Your Validator](/infrastructure/running-a-validator/operational-tasks/general-management/#secure-your-validator){target=\\_blank} section to learn about important security measures.\n- **Network choice**: Start with [Kusama](/infrastructure/running-a-validator/onboarding-and-offboarding/set-up-validator/#run-a-kusama-validator){target=\\_blank} to gain experience. Look for \"Adjustments for Kusama\" throughout these guides for tips on adapting the provided instructions for the Kusama network.\n- **Staking requirements**: A minimum amount of native token (KSM or DOT) is required to be elected into the validator set. The required stake can come from your own holdings or from nominators.\n- **Risk of slashing**: Any DOT you stake is at risk if your setup fails or your validator misbehaves. If you’re unsure of your ability to maintain a reliable validator, consider nominating your DOT to a trusted validator."}
{"page_id": "infrastructure-running-a-validator-requirements", "index": 2, "depth": 2, "title": "Minimum Hardware Requirements", "anchor": "minimum-hardware-requirements", "start_char": 2390, "end_char": 3554, "estimated_token_count": 251, "token_estimator": "heuristic-v1", "text": "## Minimum Hardware Requirements\n\nPolkadot validators rely on high-performance hardware to process blocks efficiently. The recommended minimum hardware requirements to ensure a fully functional and performant validator are as follows:\n\n- CPU:\n\n    - x86-64 compatible.\n    - Eight physical cores @ 3.4 GHz.\n    - Processor:\n        - **Intel**: Ice Lake or newer (Xeon or Core series)\n        - **AMD**: Zen3 or newer (EPYC or Ryzen)\n    - Simultaneous multithreading disabled:\n        - **Intel**: Hyper-Threading\n        - **AMD**: SMT\n    - [Single-threaded performance](https://www.cpubenchmark.net/singleThread.html){target=\\_blank} is prioritized over higher cores count.\n\n- Storage:\n\n    - **NVMe SSD**: At least 2 TB for blockchain data recommended (prioritize latency rather than throughput).\n    - Storage requirements will increase as the chain grows. For current estimates, see the [current chain snapshot](https://stakeworld.io/docs/dbsize){target=\\_blank}.\n\n- Memory:\n\n    - 32 GB DDR4 ECC\n\n- Network:\n\n    - Symmetric networking speed of 500 Mbit/s is required to handle large numbers of parachains and ensure congestion control during peak times."}
{"page_id": "infrastructure-running-a-validator-requirements", "index": 3, "depth": 2, "title": "VPS Provider List", "anchor": "vps-provider-list", "start_char": 3554, "end_char": 6071, "estimated_token_count": 574, "token_estimator": "heuristic-v1", "text": "## VPS Provider List\n\nWhen selecting a VPS provider for your validator node, prioritize reliability, consistent performance, and adherence to the specific hardware requirements set for Polkadot validators. The following server types have been tested and showed acceptable performance in benchmark tests. However, this is not an endorsement and actual performance may vary depending on your workload and VPS provider.\n\nBe aware that some providers may overprovision the underlying host and use shared storage such as NVMe over TCP, which appears as local storage. These setups might result in poor or inconsistent performance. Benchmark your infrastructure before deploying.\n\n- **[Google Cloud Platform (GCP)](https://cloud.google.com/){target=\\_blank}**: `c2` and `c2d` machine families offer high-performance configurations suitable for validators.\n- **[Amazon Web Services (AWS)](https://aws.amazon.com/){target=\\_blank}**: `c6id` machine family provides strong performance, particularly for I/O-intensive workloads.\n- **[OVH](https://www.ovhcloud.com/en-au/){target=\\_blank}**: Can be a budget-friendly solution if it meets your minimum hardware specifications.\n- **[Digital Ocean](https://www.digitalocean.com/){target=\\_blank}**: Popular among developers, Digital Ocean's premium droplets offer configurations suitable for medium to high-intensity workloads.\n- **[Vultr](https://www.vultr.com/){target=\\_blank}**: Offers flexibility with plans that may meet validator requirements, especially for high-bandwidth needs.\n- **[Linode](https://www.linode.com/){target=\\_blank}**: Provides detailed documentation, which can be helpful for setup.\n- **[Scaleway](https://www.scaleway.com/en/){target=\\_blank}**: Offers high-performance cloud instances that can be suitable for validator nodes.\n- **[OnFinality](https://onfinality.io/){target=\\_blank}**: Specialized in blockchain infrastructure, OnFinality provides validator-specific support and configurations.\n\n!!! warning \"Acceptable use policies\"\n    Different VPS providers have varying acceptable use policies, and not all allow cryptocurrency-related activities. \n\n    For example, Digital Ocean, requires explicit permission to use servers for cryptocurrency mining and defines unauthorized mining as [network abuse](https://www.digitalocean.com/legal/acceptable-use-policy#network-abuse){target=\\_blank} in their acceptable use policy. \n    \n    Review the terms for your VPS provider to avoid account suspension or server shutdown due to policy violations."}
{"page_id": "infrastructure-running-a-validator-requirements", "index": 4, "depth": 2, "title": "Minimum Bond Requirement", "anchor": "minimum-bond-requirement", "start_char": 6071, "end_char": 6836, "estimated_token_count": 196, "token_estimator": "heuristic-v1", "text": "## Minimum Bond Requirement\n\nBefore bonding DOT, ensure you meet the minimum bond requirement to start a validator instance. The minimum bond is the least DOT you need to stake to enter the validator set. To become eligible for rewards, your validator node must be nominated by enough staked tokens.\n\nFor example, on November 19, 2024, the minimum stake backing a validator in Polkadot's era 1632 was 1,159,434.248 DOT. You can check the current minimum stake required using these tools:\n\n- [**Chain State Values**](https://wiki.polkadot.com/general/chain-state-values/){target=\\_blank}\n- [**Subscan**](https://polkadot.subscan.io/validator_list?status=validator){target=\\_blank}\n- [**Staking Dashboard**](https://staking.polkadot.cloud/#/overview){target=\\_blank}"}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 674, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn Polkadot's Nominated Proof of Stake (NPoS) system, validator misconduct is deterred through a combination of slashing, disabling, and reputation penalties. Validators and nominators who stake tokens face consequences for validator misbehavior, which range from token slashes to restrictions on network participation.\n\nThis page outlines the types of offenses recognized by Polkadot, including block equivocations and invalid votes, as well as the corresponding penalties. While some parachains may implement additional custom slashing mechanisms, this guide focuses on the offenses tied to staking within the Polkadot ecosystem."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 1, "depth": 2, "title": "Offenses", "anchor": "offenses", "start_char": 674, "end_char": 1106, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Offenses\n\nPolkadot is a public permissionless network. As such, it has a mechanism to disincentivize offenses and incentivize good behavior. You can review the [parachain protocol](https://wiki.polkadot.com/learn/learn-parachains-protocol/#parachain-protocol){target=\\_blank} to understand better the terminology used to describe offenses. Polkadot validator offenses fall into two categories: invalid votes and equivocations."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 2, "depth": 3, "title": "Invalid Votes", "anchor": "invalid-votes", "start_char": 1106, "end_char": 1733, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "### Invalid Votes\n\nA validator will be penalized for inappropriate voting activity during the block inclusion and approval processes. The invalid voting related offenses are as follows:\n\n- **Backing an invalid block**: A para-validator backs an invalid block for inclusion in a fork of the relay chain.\n- **`ForInvalid` vote**: When acting as a secondary checker, the validator votes in favor of an invalid block.\n- **`AgainstValid` vote**: When acting as a secondary checker, the validator votes against a valid block. This type of vote wastes network resources required to resolve the disparate votes and resulting dispute."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 3, "depth": 3, "title": "Equivocations", "anchor": "equivocations", "start_char": 1733, "end_char": 2746, "estimated_token_count": 197, "token_estimator": "heuristic-v1", "text": "### Equivocations\n\nEquivocation occurs when a validator produces statements that conflict with each other when producing blocks or voting. Unintentional equivocations usually occur when duplicate signing keys reside on the validator host. If keys are never duplicated, the probability of an honest equivocation slash decreases to near zero. The equivocation related offenses are as follows:\n\n- **Equivocation**: The validator produces two or more of the same block or vote.\n    - **GRANDPA and BEEFY equivocation**: The validator signs two or more votes in the same round on different chains.\n    - **BABE equivocation**: The validator produces two or more blocks on the relay chain in the same time slot.\n- **Double seconded equivocation**: The validator attempts to second, or back, more than one block in the same round.\n- **Seconded and valid equivocation**: The validator seconds, or backs, a block and then attempts to hide their role as the responsible backer by later placing a standard validation vote."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 4, "depth": 2, "title": "Penalties", "anchor": "penalties", "start_char": 2746, "end_char": 2924, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Penalties\n\nOn Polkadot, offenses to the network incur different penalties depending on severity. There are three main penalties: slashing, disabling, and reputation changes."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 5, "depth": 3, "title": "Slashing", "anchor": "slashing", "start_char": 2924, "end_char": 13705, "estimated_token_count": 2520, "token_estimator": "heuristic-v1", "text": "### Slashing\n\nValidators engaging in bad actor behavior in the network may be subject to slashing if they commit a qualifying offense. When a validator is slashed, they and their nominators lose a percentage of their staked DOT or KSM, from as little as 0.01% up to 100% based on the severity of the offense. Nominators are evaluated for slashing against their active validations at any given time. Validator nodes are evaluated as discrete entities, meaning an operator can't attempt to mitigate the offense on another node they operate in order to avoid a slash. \n\nAny slashed DOT or KSM will be added to the [Treasury](https://wiki.polkadot.com/learn/learn-polkadot-opengov-treasury/){target=\\_blank} rather than burned or distributed as rewards. Moving slashed funds to the Treasury allows tokens to be quickly moved away from malicious validators while maintaining the ability to revert faulty slashes when needed.\n\nA nominator with a very large bond may nominate several validators in a single era. In this case, a slash is proportionate to the amount staked to the offending validator. Stake allocation and validator activation is controlled by the [Phragmén algorithm](https://wiki.polkadot.com/learn/learn-phragmen/#algorithm){target=\\_blank}.\n\nA validator slash creates an `unapplied` state transition. You can view pending slashes on [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Frpc.polkadot.io#/staking/slashes){target=\\_blank}. The UI will display the slash per validator, the affected nominators, and the slash amounts. The unapplied state includes a 27-day grace period during which a governance proposal can be made to reverse the slash. Once this grace period expires, the slash is applied.\n\n#### Equivocation Slash\n\nThe Web3 Foundation's [Slashing mechanisms](https://research.web3.foundation/Polkadot/security/slashing/amounts){target=\\_blank} page provides guidelines for evaluating the security threat level of different offenses and determining penalties proportionate to the threat level of the offense. Offenses requiring coordination between validators or extensive computational costs to the system will typically call for harsher penalties than those more likely to be unintentional than malicious. A description of potential offenses for each threat level and the corresponding penalties is as follows:\n\n- **Level 1**: Honest misconduct such as isolated cases of unresponsiveness.\n    - **Penalty**: Validator can be kicked out or slashed up to 0.1% of stake in the validator slot.\n- **Level 2**: Misconduct that can occur honestly but is a sign of bad practices. Examples include repeated cases of unresponsiveness and isolated cases of equivocation.\n    - **Penalty**: Slash of up to 1% of stake in the validator slot.\n- **Level 3**: Misconduct that is likely intentional but of limited effect on the performance or security of the network. This level will typically include signs of coordination between validators. Examples include repeated cases of equivocation or isolated cases of unjustified voting on GRANDPA.\n    - **Penalty**: Reduction in networking reputation metrics, slash of up to 10% of stake in the validator slot.\n- **Level 4**: Misconduct that poses severe security or monetary risk to the system or mass collusion. Examples include signs of extensive coordination, creating a serious security risk to the system, or forcing the system to use extensive resources to counter the misconduct.\n    - **Penalty**: Slash of up to 100% of stake in the validator slot.\n\nSee the next section to understand how slash amounts for equivocations are calculated. If you want to know more details about slashing, please look at the research page on [Slashing mechanisms](https://research.web3.foundation/Polkadot/security/slashing/amounts){target=\\_blank}.\n\n#### Slash Calculation for Equivocation\n\nThe slashing penalty for GRANDPA, BABE, and BEEFY equivocations is calculated using the formula below, where `x` represents the number of offenders and `n` is the total number of validators in the active set:\n\n```text\nmin((3 * x / n )^2, 1)\n```\n\nThe following scenarios demonstrate how this formula means slash percentages can increase exponentially based on the number of offenders involved compared to the size of the validator pool:\n\n- **Minor offense**: Assume 1 validator out of a 100 validator active set equivocates in a slot. A single validator committing an isolated offense is most likely a mistake rather than malicious attack on the network. This offense results in a 0.09% slash to the stake in the validator slot.\n\n    ``` mermaid\n    flowchart LR\n    N[\"Total Validators = 100\"]\n    X[\"Offenders = 1\"]\n    F[\"min((3 * 1 / 100)^2, 1) = 0.0009\"]\n    G[\"0.09% slash of stake\"]\n\n    N --> F\n    X --> F\n    F --> G\n    ```\n\n- **Moderate offense**: Assume 5 validators out a 100 validator active set equivocate in a slot. This is a slightly more serious event as there may be some element of coordination involved. This offense results in a 2.25% slash to the stake in the validator slot.\n\n    ``` mermaid\n    flowchart LR\n    N[\"Total Validators = 100\"]\n    X[\"Offenders = 5\"]\n    F[\"min((3 * 5 / 100)^2, 1) = 0.0225\"]\n    G[\"2.25% slash of stake\"]\n\n    N --> F\n    X --> F\n    F --> G\n    ```\n\n- **Major offense**: Assume 20 validators out a 100 validator active set equivocate in a slot. This is a major security threat as it possible represents a coordinated attack on the network. This offense results in a 36% slash and all slashed validators will also be chilled.\n    ``` mermaid\n    flowchart LR\n    N[\"Total Validators = 100\"]\n    X[\"Offenders = 20\"]\n    F[\"min((3 * 20 / 100)^2, 1) = 0.36\"]\n    G[\"36% slash of stake\"]\n\n    N --> F\n    X --> F\n    F --> G\n    ```\n\nThe examples above show the risk of nominating or running many validators in the active set. While rewards grow linearly (two validators will get you approximately twice as many staking rewards as one), slashing grows exponentially. Going from a single validator equivocating to two validators equivocating causes a slash four time as much as the single validator.\n\nValidators may run their nodes on multiple machines to ensure they can still perform validation work if one of their nodes goes down. Still, validator operators should be cautious when setting these up. Equivocation is possible if they don't coordinate well in managing signing machines.\n\n#### Best Practices to Avoid Slashing\n\nThe following are advised to node operators to ensure that they obtain pristine binaries or source code and to ensure the security of their node:\n\n- Always download either source files or binaries from the official Parity repository.\n- Verify the hash of downloaded files.\n- Use the W3F secure validator setup or adhere to its principles.\n- Ensure essential security items are checked, use a firewall, manage user access, use SSH certificates.\n- Avoid using your server as a general-purpose system. Hosting a validator on your workstation or one that hosts other services increases the risk of maleficence.\n- Avoid cloning servers (copying all contents) when migrating to new hardware. If an image is needed, create it before generating keys.\n- High Availability (HA) systems are generally not recommended as equivocation may occur if concurrent operations happen—such as when a failed server restarts or two servers are falsely online simultaneously.\n- Copying the keystore folder when moving a database between instances can cause equivocation. Even brief use of duplicated keystores can result in slashing.\n\nBelow are some examples of small equivocations that happened in the past:\n\n| Network  | Era  | Event Type         | Details                                                                                                                                                                                                                                                                                                                                                             | Action Taken                                                                                                                      |\n|----------|------|--------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|\n| Polkadot | 774  | Small Equivocation | [The validator](https://matrix.to/#/!NZrbtteFeqYKCUGQtr:matrix.parity.io/$165562246360408hKCfC:matrix.org?via=matrix.parity.io&via=corepaper.org&via=matrix.org){target=\\_blank} migrated servers and cloned the keystore folder. The on-chain event can be viewed on [Subscan](https://polkadot.subscan.io/extrinsic/11190109-0?event=11190109-5){target=\\_blank}. | The validator didn't submit a request for the slash to be canceled.                                                               |\n| Kusama   | 3329 | Small Equivocation | The validator operated a test machine with cloned keys. The test machine was online simultaneously as the primary, which resulted in a slash.                                                                                                                                                                                                                       | The validator requested a slash cancellation, but the council declined.                                                           |\n| Kusama   | 3995 | Small Equivocation | The validator noticed several errors, after which the client crashed, and a slash was applied. The validator recorded all events and opened GitHub issues to allow for technical opinions to be shared.                                                                                                                                                             | The validator requested to cancel the slash. The council approved the request as they believed the error wasn't operator-related. |\n\n#### Slashing Across Eras\n\nThere are three main difficulties to account for with slashing in NPoS:\n\n- A nominator can nominate multiple validators and be slashed as a result of actions taken by any of them.\n- Until slashed, the stake is reused from era to era.\n- Slashable offenses can be found after the fact and out of order.\n\nTo balance this, the system applies only the maximum slash a participant can receive in a given time period rather than the sum. This ensures protection from excessive slashing."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 6, "depth": 3, "title": "Disabling", "anchor": "disabling", "start_char": 13705, "end_char": 14617, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "### Disabling\n\nThe disabling mechanism is triggered when validators commit serious infractions, such as backing invalid blocks or engaging in equivocations. Disabling stops validators from performing specific actions after they have committed an offense. Disabling is further divided into:\n\n- **On-chain disabling**: Lasts for a whole era and stops validators from authoring blocks, backing, and initiating a dispute.\n- **Off-chain disabling**: Lasts for a session, is caused by losing a dispute, and stops validators from initiating a dispute.\n\nOff-chain disabling is always a lower priority than on-chain disabling. Off-chain disabling prioritizes disabling first backers and then approval checkers.\n\nThe material in this guide reflects the changes introduced in Stage 4. For more details, see the [State of Disabling issue](https://github.com/paritytech/polkadot-sdk/issues/4359){target=\\_blank} on GitHub."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 7, "depth": 3, "title": "Reputation Changes", "anchor": "reputation-changes", "start_char": 14617, "end_char": 15241, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "### Reputation Changes\n\nSome minor offenses, such as spamming, are only punished by networking reputation changes. Validators use a reputation metric when choosing which peers to connect with. The system adds reputation if a peer provides valuable data and behaves appropriately. If they provide faulty or spam data, the system reduces their reputation. If a validator loses enough reputation, their peers will temporarily close their channels to them. This helps in fighting against Denial of Service (DoS) attacks. Performing validator tasks under reduced reputation will be harder, resulting in lower validator rewards."}
{"page_id": "infrastructure-staking-mechanics-offenses-and-slashes", "index": 8, "depth": 3, "title": "Penalties by Offense", "anchor": "penalties-by-offense", "start_char": 15241, "end_char": 15427, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Penalties by Offense\n\nRefer to the Polkadot Wiki's [offenses page](https://wiki.polkadot.com/learn/learn-offenses/){target=\\_blank} for a summary of penalties for specific offenses."}
{"page_id": "infrastructure-staking-mechanics-rewards-payout", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 621, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUnderstanding how rewards are distributed to validators and nominators is essential for network participants. In Polkadot and Kusama, validators earn rewards based on their era points, which are accrued through actions like block production and parachain validation.\n\nThis guide explains the payout scheme, factors influencing rewards, and how multiple validators affect returns. Validators can also share rewards with nominators, who contribute by staking behind them. By following the payout mechanics, validators can optimize their earnings and better engage with their nominators."}
{"page_id": "infrastructure-staking-mechanics-rewards-payout", "index": 1, "depth": 2, "title": "Era Points", "anchor": "era-points", "start_char": 621, "end_char": 1660, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "## Era Points\n\nThe Polkadot ecosystem measures its reward cycles in a unit called an era. Kusama eras are approximately 6 hours long, and Polkadot eras are 24 hours long. At the end of each era, validators are paid proportionally to the amount of [era points](/infrastructure/staking-mechanics/rewards-payout/#era-points){target=\\_blank} they have collected. Era points are reward points earned for payable actions like:\n\n- Issuing validity statements for [parachain blocks](/polkadot-protocol/parachain-basics/blocks-transactions-fees/blocks/){target=\\_blank}.\n- Producing a non-uncle block in the relay chain.\n- Producing a reference to a previously unreferenced uncle block.\n- Producing a referenced uncle block.\n\nAn uncle block is a relay chain block that is valid in every regard but has failed to become canonical. This can happen when two or more validators are block producers in a single slot, and the block produced by one validator reaches the next block producer before the others. The lagging blocks are called uncle blocks."}
{"page_id": "infrastructure-staking-mechanics-rewards-payout", "index": 2, "depth": 2, "title": "Reward Variance", "anchor": "reward-variance", "start_char": 1660, "end_char": 4201, "estimated_token_count": 564, "token_estimator": "heuristic-v1", "text": "## Reward Variance\n\nRewards in Polkadot and Kusama staking systems can fluctuate due to differences in era points earned by para-validators and non-para-validators. Para-validators generally contribute more to the overall reward distribution due to their role in validating parachain blocks, thus influencing the variance in staking rewards.\n\nTo illustrate this relationship:\n\n- Para-validator era points tend to have a higher impact on the expected value of staking rewards compared to non-para-validator points.\n- The variance in staking rewards increases as the total number of validators grows relative to the number of para-validators.\n- In simpler terms, when more validators are added to the active set without increasing the para-validator pool, the disparity in rewards between validators becomes more pronounced.\n\nHowever, despite this increased variance, rewards tend to even out over time due to the continuous rotation of para-validators across eras. The network's design ensures that over multiple eras, each validator has an equal opportunity to participate in para-validation, eventually leading to a balanced distribution of rewards.\n\n??? interface \"Probability in Staking Rewards\"\n\n    This should only serve as a high-level overview of the probabilistic nature for staking rewards.\n\n    Let:\n\n    - `pe` = para-validator era points\n    - `ne` = non-para-validator era points\n    - `EV` = expected value of staking rewards\n\n    Then, `EV(pe)` has more influence on the `EV` than `EV(ne)`.\n\n    Since `EV(pe)` has a more weighted probability on the `EV`, the increase in variance against the `EV` becomes apparent between the different validator pools (aka. validators in the active set and the ones chosen to para-validate).\n\n    Also, let:\n\n    - `v` = the variance of staking rewards\n    - `p` = number of para-validators\n    - `w` = number validators in the active set\n    - `e` = era\n\n    Then, `v` &#8593; if `w` &#8593;, as this reduces `p` : `w`, with respect to `e`.\n\n    Increased `v` is expected, and initially keeping `p` &#8595; using the same para-validator set for all parachains ensures [availability](https://spec.polkadot.network/chapter-anv){target=\\_blank} and [voting](https://wiki.polkadot.com/learn/learn-polkadot-opengov/){target=\\_blank}. In addition, despite `v` &#8593; on an `e` to `e` basis, over time, the amount of rewards each validator receives will equal out based on the continuous selection of para-validators.\n\n    There are plans to scale the active para-validation set in the future."}
{"page_id": "infrastructure-staking-mechanics-rewards-payout", "index": 3, "depth": 2, "title": "Payout Scheme", "anchor": "payout-scheme", "start_char": 4201, "end_char": 5622, "estimated_token_count": 328, "token_estimator": "heuristic-v1", "text": "## Payout Scheme\n\nValidator rewards are distributed equally among all validators in the active set, regardless of the total stake behind each validator. However, individual payouts may differ based on the number of era points a validator has earned. Although factors like network connectivity can affect era points, well-performing validators should accumulate similar totals over time.\n\nValidators can also receive tips from users, which incentivize them to include certain transactions in their blocks. Validators retain 100% of these tips.\n\nRewards are paid out in the network's native token (DOT for Polkadot and KSM for Kusama). \n\nThe following example illustrates a four member validator set with their names, amount they have staked, and how payout of rewards is divided. This scenario assumes all validators earned the same amount of era points and no one received tips: \n\n``` mermaid\nflowchart TD\n    A[\"Alice (18 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    D[\"Dave (7 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> D\n```\n\nNote that this is different than most other Proof of Stake (PoS) systems. As long as a validator is in the validator set, it will receive the same block reward as every other validator. Validator Alice, who had 18 DOT staked, received the same 2 DOT reward in this era as Dave, who had only 7 DOT staked."}
{"page_id": "infrastructure-staking-mechanics-rewards-payout", "index": 4, "depth": 2, "title": "Running Multiple Validators", "anchor": "running-multiple-validators", "start_char": 5622, "end_char": 7233, "estimated_token_count": 423, "token_estimator": "heuristic-v1", "text": "## Running Multiple Validators\n\nRunning multiple validators can offer a more favorable risk/reward ratio compared to running a single one. If you have sufficient DOT or nominators staking on your validators, maintaining multiple validators within the active set can yield higher rewards.\n\nIn the preceding section, with 18 DOT staked and no nominators, Alice earned 2 DOT in one era. This example uses DOT, but the same principles apply for KSM on the Kusama network. By managing stake across multiple validators, you can potentially increase overall returns. Recall the set of validators from the preceding section:\n\n``` mermaid\nflowchart TD\n    A[\"Alice (18 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    D[\"Dave (7 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> D \n```\n\nNow, assume Alice decides to split their stake and run two validators, each with a nine DOT stake. This validator set only has four spots and priority is given to validators with a larger stake. In this example, Dave has the smallest stake and loses his spot in the validator set. Now, Alice will earn two shares of the total payout each era as illustrated below:\n\n``` mermaid\nflowchart TD\n    A[\"Alice (9 DOT)\"]\n    F[\"Alice (9 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> F \n```\n\nWith enough stake, you could run more than two validators. However, each validator must have enough stake behind it to maintain a spot in the validator set."}
{"page_id": "infrastructure-staking-mechanics-rewards-payout", "index": 5, "depth": 2, "title": "Nominators and Validator Payments", "anchor": "nominators-and-validator-payments", "start_char": 7233, "end_char": 11070, "estimated_token_count": 990, "token_estimator": "heuristic-v1", "text": "## Nominators and Validator Payments\n\nA nominator's stake allows them to vote for validators and earn a share of the rewards without managing a validator node. Although staking rewards depend on validator activity during an era, validators themselves never control or own nominator rewards. To trigger payouts, anyone can call the `staking.payoutStakers` or `staking.payoutStakerByPage` methods, which mint and distribute rewards directly to the recipients. This trustless process ensures nominators receive their earned rewards.\n\nValidators set a commission rate as a percentage of the block reward, affecting how rewards are shared with nominators. A 0% commission means the validator keeps only rewards from their self-stake, while a 100% commission means they retain all rewards, leaving none for nominators.\n\nThe following examples model splitting validator payments between nominator and validator using various commission percentages. For simplicity, these examples assume a Polkadot-SDK based relay chain that uses DOT as a native token and a single nominator per validator. Calculations of KSM reward payouts for Kusama follow the same formula. \n\nStart with the original validator set from the previous section: \n\n``` mermaid\nflowchart TD\n    A[\"Alice (18 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    D[\"Dave (7 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> D \n```\n\nThe preceding diagram shows each validator receiving a 2 DOT payout, but doesn't account for sharing rewards with nominators. The following diagram shows what nominator payout might look like for validator Alice. Alice has a 20% commission rate and holds 50% of the stake for their validator:\n\n``` mermaid\n\nflowchart TD\n    A[\"Gross Rewards = 2 DOT\"]\n    E[\"Commission = 20%\"]\n    F[\"Alice Validator Payment = 0.4 DOT\"]\n    G[\"Total Stake Rewards = 1.6 DOT\"]\n    B[\"Alice Validator Stake = 18 DOT\"]\n    C[\"9 DOT Alice (50%)\"]\n    H[\"Alice Stake Reward = 0.8 DOT\"]\n    I[\"Total Alice Validator Reward = 1.2 DOT\"]\n    D[\"9 DOT Nominator (50%)\"]\n    J[\"Total Nominator Reward = 0.8 DOT\"]\n    \n    A --> E\n    E --(2 x 0.20)--> F\n    F --(2 - 0.4)--> G\n    B --> C\n    B --> D\n    C --(1.6 x 0.50)--> H\n    H --(0.4 + 0.8)--> I\n    D --(1.60 x 0.50)--> J\n```\n\nNotice the validator commission rate is applied against the gross amount of rewards for the era. The validator commission is subtracted from the total rewards. After the commission is paid to the validator, the remaining amount is split among stake owners according to their percentage of the total stake. A validator's total rewards for an era include their commission plus their piece of the stake rewards. \n\nNow, consider a different scenario for validator Bob where the commission rate is 40%, and Bob holds 33% of the stake for their validator:\n\n``` mermaid\n\nflowchart TD\n    A[\"Gross Rewards = 2 DOT\"]\n    E[\"Commission = 40%\"]\n    F[\"Bob Validator Payment = 0.8 DOT\"]\n    G[\"Total Stake Rewards = 1.2 DOT\"]\n    B[\"Bob Validator Stake = 9 DOT\"]\n    C[\"3 DOT Bob (33%)\"]\n    H[\"Bob Stake Reward = 0.4 DOT\"]\n    I[\"Total Bob Validator Reward = 1.2 DOT\"]\n    D[\"6 DOT Nominator (67%)\"]\n    J[\"Total Nominator Reward = 0.8 DOT\"]\n    \n    A --> E\n    E --(2 x 0.4)--> F\n    F --(2 - 0.8)--> G\n    B --> C\n    B --> D\n    C --(1.2 x 0.33)--> H\n    H --(0.8 + 0.4)--> I\n    D --(1.2 x 0.67)--> J\n```\n\nBob holds a smaller percentage of their node's total stake, making their stake reward smaller than Alice's. In this scenario, Bob makes up the difference by charging a 40% commission rate and ultimately ends up with the same total payment as Alice. Each validator will need to find their ideal balance between the amount of stake and commission rate to attract nominators while still making running a validator worthwhile."}
{"page_id": "polkadot-protocol-architecture-parachains-consensus", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 23, "end_char": 936, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nParachains are independent blockchains built with the Polkadot SDK, designed to leverage Polkadot’s relay chain for shared security and transaction finality. These specialized chains operate as part of Polkadot’s execution sharding model, where each parachain manages its own state and transactions while relying on the relay chain for validation and consensus.\n\nAt the core of parachain functionality are collators, specialized nodes that sequence transactions into blocks and maintain the parachain’s state. Collators optimize Polkadot’s architecture by offloading state management from the relay chain, allowing relay chain validators to focus solely on validating parachain blocks.\n\nThis guide explores how parachain consensus works, including the roles of collators and validators, and the steps involved in securing parachain blocks within Polkadot’s scalable and decentralized framework."}
{"page_id": "polkadot-protocol-architecture-parachains-consensus", "index": 1, "depth": 2, "title": "The Role of Collators", "anchor": "the-role-of-collators", "start_char": 936, "end_char": 1584, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## The Role of Collators\n\nCollators are responsible for sequencing end-user transactions into blocks and maintaining the current state of their respective parachains. Their role is akin to Ethereum’s sequencers but optimized for Polkadot's architecture.\n\nKey responsibilities include:\n\n- **Transaction sequencing**: Organizing transactions into [Proof of Validity (PoV)](https://wiki.polkadot.com/general/glossary/#proof-of-validity){target=\\_blank} blocks.\n- **State management**: Maintaining parachain states without burdening the relay chain validators.\n- **Consensus participation**: Sending PoV blocks to relay chain validators for approval."}
{"page_id": "polkadot-protocol-architecture-parachains-consensus", "index": 2, "depth": 2, "title": "Consensus and Validation", "anchor": "consensus-and-validation", "start_char": 1584, "end_char": 2483, "estimated_token_count": 169, "token_estimator": "heuristic-v1", "text": "## Consensus and Validation\n\nParachain consensus operates in tandem with the relay chain, leveraging Nominated Proof of Stake (NPoS) for shared security. The process ensures parachain transactions achieve finality through the following steps:\n\n1. **Packaging transactions**: Collators bundle transactions into PoV blocks (parablocks).\n2. **Submission to validator**: Parablocks are submitted to a randomly selected subset of relay chain validators, known as paravalidators.\n3. **Validation of PoV Blocks**: Paravalidators use the parachain’s state transition function (already available on the relay chain) to verify transaction validity.\n4. **Backing and inclusion**: If a sufficient number of positive validations are received, the parablock is backed and included via a para-header on the relay chain.\n\nThe following sections describe the actions taking place during each stage of the process."}
{"page_id": "polkadot-protocol-architecture-parachains-consensus", "index": 3, "depth": 3, "title": "Path of a Parachain Block", "anchor": "path-of-a-parachain-block", "start_char": 2483, "end_char": 6003, "estimated_token_count": 634, "token_estimator": "heuristic-v1", "text": "### Path of a Parachain Block\n\nPolkadot achieves scalability through execution sharding, where each parachain operates as an independent shard with its own blockchain and state. Shared security for all parachains is provided by the relay chain, powered by [Nominated Proof of Staking (NPoS)](/polkadot-protocol/glossary/#nominated-proof-of-stake-npos){target=\\_blank}. This framework allows parachains to focus on transaction processing and state management, while the relay chain ensures validation and finality.\n\nThe journey parachain transactions follow to reach consensus and finality can be described as follows:\n\n- Collators and parablocks:\n\n    - Collators, specialized nodes on parachains, package network transactions into Proof of Validity (PoV) blocks, also called parablocks.\n    - These parablocks are sent to a subset of relay chain validators, known as paravalidators, for validation.\n    - The parachain's state transition function (Wasm blob) is not re-sent, as it is already stored on the relay chain.\n\n```mermaid\nflowchart TB\n    %% Subgraph: Parachain\n    subgraph Parachain\n        direction LR\n        Txs[Network Transactions]\n        Collator[Collator Node]\n        ParaBlock[ParaBlock + PoV]\n        Txs -->|Package Transactions| Collator\n        Collator -->|Create| ParaBlock\n    end\n\n    subgraph Relay[\"Relay Chain\"]\n        ParaValidator\n    end\n\n    %% Main Flow\n    Parachain -->|Submit To| Relay\n```\n\n- Validation by paravalidators:\n\n    - Paravalidators are groups of approximately five relay chain validators, randomly assigned to parachains and shuffled every minute.\n    - Each paravalidator downloads the parachain's Wasm blob and validates the parablock by ensuring all transactions comply with the parachain’s state transition rules.\n    - Paravalidators sign positive or negative validation statements based on the block’s validity.\n\n- Backing and approval:\n\n    - If a parablock receives sufficient positive validation statements, it is backed and included on the relay chain as a para-header.\n    - An additional approval process resolves disputes. If a parablock contains invalid transactions, additional validators are tasked with verification.\n    - Validators who back invalid parablocks are penalized through slashing, creating strong incentives for honest behavior.\n\n```mermaid\nflowchart\n    subgraph RelayChain[\"Relay Chain\"]\n        direction TB\n        subgraph InitialValidation[\"Initial Validation\"]\n            direction LR\n            PValidators[ParaValidators]\n            Backing[Backing<br>Process]\n            Header[Submit Para-header<br>on Relay Chain]\n        end\n        subgraph Secondary[\"Secondary Validation\"]\n            Approval[Approval<br>Process]\n            Dispute[Dispute<br>Resolution]\n            Slashing[Slashing<br>Mechanism]\n        end\n        \n    end\n\n\n    %% Validation Process\n    PValidators -->|Download<br>Wasm<br>Validate Block| Backing\n    Backing -->|If Valid<br>Signatures| Header\n    InitialValidation -->|Additional<br>Verification| Secondary\n    \n    %% Dispute Flow\n    Approval -->|If Invalid<br>Detected| Dispute\n    Dispute -->|Penalize<br>Dishonest<br>Validators| Slashing\n```\n\nIt is important to understand that relay chain blocks do not store full parachain blocks (parablocks). Instead, they include para-headers, which serve as summaries of the backed parablocks. The complete parablock remains within the parachain network, maintaining its autonomy while relying on the relay chain for validation and finality."}
{"page_id": "polkadot-protocol-architecture-parachains-consensus", "index": 4, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6003, "end_char": 6158, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor more technical details, refer to the:\n\n- [Parachain Wiki](https://wiki.polkadot.com/learn/learn-parachains/){target=\\_blank} page"}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 1419, "estimated_token_count": 303, "token_estimator": "heuristic-v1", "text": "## Introduction \n\nA [_parachain_](/polkadot-protocol/glossary#parachain){target=\\_blank} is a coherent, application-specific blockchain that derives security from its respective relay chain. Parachains on Polkadot are each their own separate, fully functioning blockchain. The primary difference between a parachain and a regular, \"solo\" blockchain is that the relay chain verifies the state of all parachains that are connected to it.  In many ways, parachains can be thought of as a [\"cynical\" rollup](#cryptoeconomic-security-elves-protocol), as the crypto-economic protocol used (ELVES) assumes the worst-case scenario, rather than the typical optimistic approach that many roll-up mechanisms take. Once enough validators attest that a block is valid, then the probability of that block being valid is high.\n\nAs each parachain’s state is validated by the relay chain, the relay chain represents the collective state of all parachains.\n\n```mermaid\nflowchart TB\n    subgraph \"Relay Chain\"\n        RC[Relay Chain Validators]\n        State[Collective State Validation]\n    end\n\n    PA[Parachain A]\n    PB[Parachain B]\n    PC[Parachain C]\n\n    RC -->|Validate State| PA\n    RC -->|Validate State| PB\n    RC -->|Validate State| PC\n\n    State -->|Represents Collective<br>Parachain State| RC\n\n    note[\"ELVES Protocol:<br>- Crypto-economic security<br>- Assumes worst-case scenario<br>- High probability validation\"]\n```"}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 1, "depth": 2, "title": "Coherent Systems", "anchor": "coherent-systems", "start_char": 1419, "end_char": 2205, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Coherent Systems\n    \nCoherency refers to the degree of synchronization, consistency, and interoperability between different components or chains within a system. It encompasses the internal coherence of individual chains and the external coherence between chains regarding how they interact.\n    \nA single-state machine like Ethereum is very coherent, as all of its components (smart contracts, dApps/applications, staking, consensus) operate within a single environment with the downside of less scalability. Multi-protocol state machines, such as Polkadot, offer less coherency due to their sharded nature but more scalability due to the parallelization of their architecture.\n\nParachains are coherent, as they are self-contained environments with domain-specific functionality."}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 2, "depth": 2, "title": "Flexible Ecosystem", "anchor": "flexible-ecosystem", "start_char": 2205, "end_char": 4089, "estimated_token_count": 381, "token_estimator": "heuristic-v1", "text": "## Flexible Ecosystem\n\nParachains enable parallelization of different services within the same network. However, unlike most layer two rollups, parachains don't suffer the same interoperability pitfalls that most rollups suffer. [Cross-Consensus Messaging (XCM)](/develop/interoperability/intro-to-xcm/){target=\\_blank} provides a common communication format for each parachain and can be configured to allow a parachain to communicate with just the relay chain or certain parachains. \n\nThe diagram below highlights the flexibility of the Polkadot ecosystem, where each parachain specializes in a distinct domain. This example illustrates how parachains, like DeFi and GameFi, leverage XCM for cross-chain operations such as asset transfers and credential verification.\n\n```mermaid\nflowchart TB\n    subgraph \"Polkadot Relay Chain\"\n        RC[Relay Chain<br>Cross-Consensus<br>Routing]\n    end\n\n    subgraph \"Parachain Ecosystem\"\n        direction TB\n        DeFi[DeFi Parachain<br>Financial Services]\n        GameFi[GameFi Parachain<br>Gaming Ecosystem]\n        NFT[NFT Parachain<br>Digital Collectibles]\n        Identity[Identity Parachain<br>User Verification]\n    end\n\n    DeFi <-->|XCM: Asset Transfer| GameFi\n    GameFi <-->|XCM: Token Exchange| NFT\n    Identity <-->|XCM: Credential Verification| DeFi\n\n    RC -->|Validate & Route XCM| DeFi\n    RC -->|Validate & Route XCM| GameFi\n    RC -->|Validate & Route XCM| NFT\n    RC -->|Validate & Route XCM| Identity\n\n    note[\"XCM Features:<br>- Standardized Messaging<br>- Cross-Chain Interactions<br>- Secure Asset/Data Transfer\"]\n```\n\nMost parachains are built using the Polkadot SDK, which provides all the tools to create a fully functioning parachain. However, it is possible to construct a parachain that can inherit the security of the relay chain as long as it implements the correct mechanisms expected by the relay chain."}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 3, "depth": 2, "title": "State Transition Functions (Runtimes)", "anchor": "state-transition-functions-runtimes", "start_char": 4089, "end_char": 6055, "estimated_token_count": 389, "token_estimator": "heuristic-v1", "text": "## State Transition Functions (Runtimes)\n\nDeterminism is a fundamental property where given the same input, a system will consistently produce identical outputs. In blockchain systems, this predictable behavior is essential for state machines, which are algorithms that transition between different states based on specific inputs to generate a new state.\n\nAt their core, parachains, like most blockchains, are deterministic, finite-state machines that are often backed by game theory and economics. The previous state of the parachain, combined with external input in the form of [extrinsics](/polkadot-protocol/glossary#extrinsic){target=\\_blank}, allows the state machine to progress forward, one block at a time.\n\n```mermaid\nstateDiagram-v2\n    direction LR\n    [*] --> StateA : Initial State\n    \n    StateA --> STF : Extrinsics/Transactions\n    STF --> StateB : Deterministic Transformation\n    StateB --> [*] : New State\n```\n\nThe primary driver of this progression is the state transition function (STF), commonly referred to as a runtime. Each time a block is submitted, it represents the next proposed state for a parachain. By applying the state transition function to the previous state and including a new block that contains the proposed changes in the form of a list of extrinsics/transactions, the runtime defines just exactly how the parachain is to advance from state A to state B.\n\nThe STF in a Polkadot SDK-based chain is compiled to Wasm and uploaded on the relay chain. This STF is crucial for the relay chain to validate the state changes coming from the parachain, as it is used to ensure that all proposed state transitions are happening correctly as part of the validation process.\n\nFor more information on the Wasm meta protocol that powers runtimes, see the [WASM Meta Protocol](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/wasm_meta_protocol/index.html){target=\\blank} in the Polkadot SDK Rust Docs."}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 4, "depth": 2, "title": "Shared Security: Validated by the Relay Chain", "anchor": "shared-security-validated-by-the-relay-chain", "start_char": 6055, "end_char": 7342, "estimated_token_count": 264, "token_estimator": "heuristic-v1", "text": "## Shared Security: Validated by the Relay Chain\n\nThe relay chain provides a layer of economic security for its parachains. Parachains submit proof of validation (PoV) data to the relay chain for validation through [collators](/polkadot-protocol/glossary/#collator), upon which the relay chains' validators ensure the validity of this data in accordance with the STF for that particular parachain. In other words, the consensus for a parachain follows the relay chain. While parachains choose how a block is authored, what it contains, and who authors it, the relay chain ultimately provides finality and consensus for those blocks.\n\nFor more information about the parachain and relay chain validation process, see the [Parachains' Protocol Overview: Protocols' Summary](https://wiki.polkadot.com/learn/learn-parachains-protocol/#protocols-summary){target=\\blank} entry in the Polkadot Wiki.\n\nParachains need at least one honest collator to submit PoV data to the relay chain. Without this, the parachain can't progress. The mechanisms that facilitate this are found in the Cumulus portion of the Polkadot SDK, some of which are found in the [`cumulus_pallet_parachain_system`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/index.html){target=\\blank}"}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 5, "depth": 3, "title": "Cryptoeconomic Security: ELVES Protocol", "anchor": "cryptoeconomic-security-elves-protocol", "start_char": 7342, "end_char": 8153, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### Cryptoeconomic Security: ELVES Protocol\n\nThe [ELVES (Economic Last Validation Enforcement System)](https://eprint.iacr.org/2024/961){target=\\_blank} protocol forms the foundation of Polkadot's cryptoeconomic security model. ELVES assumes a worst-case scenario by enforcing strict validation rules before any state transitions are finalized. Unlike optimistic approaches that rely on post-facto dispute resolution, ELVES ensures that validators collectively confirm the validity of a block before it becomes part of the parachain's state.\n\nValidators are incentivized through staking and penalized for malicious or erroneous actions, ensuring adherence to the protocol. This approach minimizes the probability of invalid states being propagated across the network, providing robust security for parachains."}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 6, "depth": 2, "title": "Interoperability", "anchor": "interoperability", "start_char": 8153, "end_char": 9024, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "## Interoperability\n\nPolkadot's interoperability framework allows parachains to communicate with each other, fostering a diverse ecosystem of interconnected blockchains. Through [Cross-Consensus Messaging (XCM)](/develop/interoperability/intro-to-xcm/){target=_blank}, parachains can transfer assets, share data, and invoke functionalities on other chains securely. This standardized messaging protocol ensures that parachains can interact with the relay chain and each other, supporting efficient cross-chain operations.\n\nThe XCM protocol mitigates common interoperability challenges in isolated blockchain networks, such as fragmented ecosystems and limited collaboration. By enabling decentralized applications to leverage resources and functionality across parachains, Polkadot promotes a scalable, cooperative blockchain environment that benefits all participants."}
{"page_id": "polkadot-protocol-architecture-parachains-overview", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 9024, "end_char": 9565, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor further information about the consensus protocol used by parachains, see the [Consensus](/polkadot-protocol/architecture/parachains/consensus/) page.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge learn\">Learn</span> __Consensus__\n\n    ---\n\n    Understand how the blocks authored by parachain collators are secured by the relay chain validators and how the parachain transactions achieve finality.\n\n    [:octicons-arrow-right-24: Reference](/polkadot-protocol/architecture/parachains/consensus/)\n\n</div>"}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-agile-coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 1479, "estimated_token_count": 318, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAgile Coretime is the [scheduling](https://en.wikipedia.org/wiki/Scheduling_(computing)){target=\\_blank} framework on Polkadot that lets parachains efficiently access cores, which comprise an active validator set tasked with parablock validation. As the first blockchain to enable a flexible scheduling system for blockspace production, Polkadot offers unparalleled adaptability for parachains.\n\n``` mermaid\ngraph TB\n    A[Cores Designation]\n    B[Bulk Coretime]\n    C[On-Demand Coretime]\n    A --continuous--> B\n    A --flexible--> C \n```\n\nCores can be designated to a parachain either continuously through [bulk coretime](#bulk-coretime) or dynamically via [on-demand coretime](#on-demand-coretime). Additionally, Polkadot supports scheduling multiple cores in parallel through [elastic scaling](https://wiki.polkadot.com/learn/learn-elastic-scaling/){target=\\_blank}, which is a feature under active development on Polkadot. This flexibility empowers parachains to optimize their resource usage and block production according to their unique needs.\n\nIn this guide, you'll learn how bulk coretime enables continuous core access with features like interlacing and splitting, and how on-demand coretime provides flexible, pay-per-use scheduling for parachains. For a deep dive on Agile Coretime and its terminology, refer to the [Wiki doc](https://wiki.polkadot.com/learn/learn-agile-coretime/#introduction-to-agile-coretime){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-agile-coretime", "index": 1, "depth": 2, "title": "Bulk Coretime", "anchor": "bulk-coretime", "start_char": 1479, "end_char": 2179, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "## Bulk Coretime\n\nBulk coretime is a fixed duration of continuous coretime represented by an NFT that can be purchased through [coretime sales](#coretime-sales) in DOT and can be split, shared, or resold. Currently, the duration of bulk coretime is set to 28 days. Coretime purchased in bulk and assigned to a single parachain is eligible for a price-capped renewal, providing a form of rent-controlled access, which is important for predicting the running costs in the near future. Suppose the bulk coretime is [interlaced](#coretime-interlacing) or [split](#coretime-splitting) or is kept idle without assigning it to a parachain. In that case, it will be ineligible for the price-capped renewal."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-agile-coretime", "index": 2, "depth": 3, "title": "Coretime Interlacing", "anchor": "coretime-interlacing", "start_char": 2179, "end_char": 2550, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### Coretime Interlacing\n\nIt is the action of dividing bulk coretime across multiple parachains that produce blocks spaced uniformly in time. For example, think of multiple parachains taking turns producing blocks, demonstrating a simple form of interlacing. This feature can be used by parachains with a low transaction volume and need not continuously produce blocks."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-agile-coretime", "index": 3, "depth": 3, "title": "Coretime Splitting", "anchor": "coretime-splitting", "start_char": 2550, "end_char": 2815, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### Coretime Splitting\n\nIt is the action of dividing bulk coretime into multiple contiguous regions. This feature can be used by parachains that need to produce blocks continuously but do not require the whole 28 days of bulk coretime and require only part of it."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-agile-coretime", "index": 4, "depth": 2, "title": "On-Demand Coretime", "anchor": "on-demand-coretime", "start_char": 2815, "end_char": 3028, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "## On-Demand Coretime\n\nPolkadot has dedicated cores assigned to provide core time on demand. These cores are excluded from the coretime sales and are reserved for on-demand parachains, which pay in DOT per block."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 842, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's architecture delivers scalability and security through its shared security model, where the relay chain coordinates and validates multiple parallel chains. \n\nElastic scaling enhances this architecture by allowing parachains to utilize multiple computational cores simultaneously, breaking the previous 1:1 relationship between parachain and relay chain blocks.\n\nThis technical advancement enables parachains to process multiple blocks within a single relay chain block, significantly increasing throughput capabilities. By leveraging [Agile Coretime](/polkadot-protocol/architecture/polkadot-chain/agile-coretime){target=\\_blank}, parachains can dynamically adjust their processing capacity based on demand, creating an efficient and responsive infrastructure for high-throughput applications."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 1, "depth": 2, "title": "How Elastic Scaling Works", "anchor": "how-elastic-scaling-works", "start_char": 842, "end_char": 4212, "estimated_token_count": 710, "token_estimator": "heuristic-v1", "text": "## How Elastic Scaling Works\n\nElastic scaling enables parachains to process multiple blocks in parallel by utilizing additional cores on the relay chain. This section provides a technical analysis of the performance advantages and details of the implementation.\n\nConsider a parachain that needs to process four consecutive parablocks. With traditional single-core allocation, the validation process follows a strictly sequential pattern. Each parablock undergoes a two-phase process on the relay chain:\n\n1. **Backing phase**: Validators create and distribute validity statements.\n2. **Inclusion phase**: The parablock is included in the relay chain after availability verification.\n\nThroughout the following diagrams, specific notation is used to represent different components of the system:\n\n- **R1, R2, ...**: Relay chain blocks (produced at ~6-second intervals).\n- **P1, P2, ...**: Parachain blocks that need validation and inclusion.\n- **C1, C2, ...**: Cores on the relay chain.\n\nIn the single-core scenario (assuming a 6-second relay chain block time), processing four parablocks requires approximately 30 seconds:\n\n```mermaid\nsequenceDiagram\n    participant R1 as R1\n    participant R2 as R2\n    participant R3 as R3\n    participant R4 as R4\n    participant R5 as R5\n    \n    Note over R1,R5: Single Core Scenario\n    \n    rect rgb(200, 220, 240)\n    Note right of R1: Core C1\n    R1->>R1: Back P1\n    R2->>R2: Include P1\n    R2->>R2: Back P2\n    R3->>R3: Include P2\n    R3->>R3: Back P3\n    R4->>R4: Include P3\n    R4->>R4: Back P4\n    R5->>R5: Include P4\n    end\n```\n\nWith elastic scaling utilizing two cores simultaneously, the same four parablocks can be processed in approximately 18 seconds:\n\n```mermaid\nsequenceDiagram\n    participant R1 as R1\n    participant R2 as R2\n    participant R3 as R3\n    participant R4 as R4\n    participant R5 as R5\n    \n    Note over R1,R3: Multi-Core Scenario\n    \n    rect rgb(200, 220, 240)\n    Note right of R1: Core C1\n    R1->>R1: Back P1\n    R2->>R2: Include P1\n    R2->>R2: Back P2\n    R3->>R3: Include P2\n    end\n    \n    rect rgb(220, 200, 240)\n    Note right of R1: Core C2\n    R1->>R1: Back P3\n    R2->>R2: Include P3\n    R2->>R2: Back P4\n    R3->>R3: Include P4\n    end\n```\n\nTo help interpret the sequence diagrams above, note the following key elements:\n\n- The horizontal axis represents time progression through relay chain blocks (R1-R5).\n- Each colored rectangle shows processing on a specific core (C1 or C2).\n- In the single-core scenario, all blocks must be processed sequentially on one core.\n- In the multi-core scenario, blocks are processed in parallel across multiple cores, reducing total time.\n\nThe relay chain processes these multiple parablocks as independent validation units during the backing, availability, and approval phases. However, during inclusion, it verifies that their state roots align properly to maintain chain consistency.\n\nFrom an implementation perspective:\n\n- **Parachain side**: Collators must increase their block production rate to utilize multiple cores fully.\n- **Validation process**: Each core operates independently, but with coordinated state verification.\n- **Resource management**: Cores are dynamically allocated based on parachain requirements.\n- **State consistency**: While backed and processed in parallel, the parablocks maintain sequential state transitions."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 2, "depth": 2, "title": "Benefits of Elastic Scaling", "anchor": "benefits-of-elastic-scaling", "start_char": 4212, "end_char": 6001, "estimated_token_count": 288, "token_estimator": "heuristic-v1", "text": "## Benefits of Elastic Scaling\n\n- **Increased throughput**: Multiple concurrent cores enable parachains to process transactions at multiples of their previous capacity. By allowing multiple parachain blocks to be validated within each relay chain block cycle, applications can achieve significantly higher transaction volumes.\n\n- **Lower latency**: Transaction finality improves substantially with multi-core processing. Parachains currently achieve 2-second latency with three cores, with projected improvements to 500ms using 12 cores, enabling near-real-time application responsiveness.\n\n- **Resource efficiency**: Applications acquire computational resources precisely matched to their needs, eliminating wasteful over-provisioning. Coretime can be purchased at granular intervals (blocks, hours, days), creating cost-effective operations, particularly for applications with variable transaction patterns.\n\n- **Scalable growth**: New applications can launch with minimal initial resource commitment and scale dynamically as adoption increases. This eliminates the traditional paradox of either over-allocating resources (increasing costs) or under-allocating (degrading performance) during growth phases.\n\n- **Workload distribution**: Parachains intelligently distribute workloads across cores during peak demand periods and release resources when traffic subsides. Paired with secondary coretime markets, this ensures maximum resource utilization across the entire network ecosystem.\n\n- **Reliable performance**: End-users experience reliable application performance regardless of network congestion levels. Applications maintain responsiveness even during traffic spikes, eliminating performance degradation that commonly impacts blockchain applications during high-demand periods."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 3, "depth": 2, "title": "Use Cases", "anchor": "use-cases", "start_char": 6001, "end_char": 6369, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Use Cases\n\nElastic scaling enables applications to dynamically adjust their resource consumption based on real-time demand. This is especially valuable for decentralized applications where usage patterns can be highly variable. The following examples illustrate common scenarios where elastic scaling delivers significant performance and cost-efficiency benefits."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 4, "depth": 3, "title": "Handling Sudden Traffic Spikes", "anchor": "handling-sudden-traffic-spikes", "start_char": 6369, "end_char": 6786, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "### Handling Sudden Traffic Spikes\n\nMany decentralized applications experience unpredictable, high-volume traffic bursts, especially in gaming, DeFi protocols, NFT auctions, messaging platforms, and social media. Elastic scaling allows these systems to acquire additional coretime during peak usage and release it during quieter periods, ensuring responsiveness without incurring constant high infrastructure costs."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 5, "depth": 3, "title": "Supporting Early-Stage Growth", "anchor": "supporting-early-stage-growth", "start_char": 6786, "end_char": 7168, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### Supporting Early-Stage Growth\n\nStartups and new projects often begin with uncertain or volatile demand. With elastic scaling, teams can launch with minimal compute resources (e.g., a single core) and gradually scale as adoption increases. This prevents overprovisioning and enables cost-efficient growth until the application is ready for more permanent or horizontal scaling."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 6, "depth": 3, "title": "Scaling Massive IoT Networks", "anchor": "scaling-massive-iot-networks", "start_char": 7168, "end_char": 7556, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "### Scaling Massive IoT Networks\n\nInternet of Things (IoT) applications often involve processing data from millions of devices in real time. Elastic scaling supports this need by enabling high-throughput transaction processing as demand fluctuates. Combined with Polkadot’s shared security model, it provides a reliable and privacy-preserving foundation for large-scale IoT deployments."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-elastic-scaling", "index": 7, "depth": 3, "title": "Powering Real-Time, Low-Latency Systems", "anchor": "powering-real-time-low-latency-systems", "start_char": 7556, "end_char": 7871, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Powering Real-Time, Low-Latency Systems\n\nApplications like payment processors, trading platforms, gaming engines, or real-time data feeds require fast, consistent performance. Elastic scaling can reduce execution latency during demand spikes, helping ensure low-latency, reliable service even under heavy load."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 882, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot is a next-generation blockchain protocol designed to support a multi-chain future by enabling secure communication and interoperability between different blockchains. Built as a Layer-0 protocol, Polkadot introduces innovations like application-specific Layer-1 chains ([parachains](/polkadot-protocol/architecture/parachains/){targe=\\_blank}), shared security through [Nominated Proof of Stake (NPoS)](/polkadot-protocol/glossary/#nominated-proof-of-stake-npos){target=\\_blank}, and cross-chain interactions via its native [Cross-Consensus Messaging Format (XCM)](/develop/interoperability/intro-to-xcm/){target=\\_blank}.\n\nThis guide covers key aspects of Polkadot’s architecture, including its high-level protocol structure, blockspace commoditization, and the role of its native token, DOT, in governance, staking, and resource allocation."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 1, "depth": 2, "title": "Polkadot 1.0", "anchor": "polkadot-10", "start_char": 882, "end_char": 2926, "estimated_token_count": 462, "token_estimator": "heuristic-v1", "text": "## Polkadot 1.0\n\nPolkadot 1.0 represents the state of Polkadot as of 2023, coinciding with the release of [Polkadot runtime v1.0.0](https://github.com/paritytech/polkadot/releases/tag/v1.0.0){target=\\_blank}. This section will focus on Polkadot 1.0, along with philosophical insights into network resilience and blockspace.\n\nAs a Layer-0 blockchain, Polkadot contributes to the multi-chain vision through several key innovations and initiatives, including:\n\n- **Application-specific Layer-1 blockchains (parachains)**: Polkadot's sharded network allows for parallel transaction processing, with shards that can have unique state transition functions, enabling custom-built L1 chains optimized for specific applications.\n\n- **Shared security and scalability**: L1 chains connected to Polkadot benefit from its [Nominated Proof of Stake (NPoS)](/polkadot-protocol/architecture/polkadot-chain/pos-consensus/#nominated-proof-of-stake){target=\\_blank} system, providing security out-of-the-box without the need to bootstrap their own.\n\n- **Secure interoperability**: Polkadot's native interoperability enables seamless data and value exchange between parachains. This interoperability can also be used outside of the ecosystem for bridging with external networks.\n\n- **Resilient infrastructure**: Decentralized and scalable, Polkadot ensures ongoing support for development and community initiatives via its on-chain [treasury](https://wiki.polkadot.com/learn/learn-polkadot-opengov-treasury/){target=\\_blank} and governance.\n\n- **Rapid L1 development**: The [Polkadot SDK](/develop/parachains/intro-polkadot-sdk/){target=\\_blank} allows fast, flexible creation and deployment of Layer-1 chains.\n\n- **Cultivating the next generation of Web3 developers**: Polkadot supports the growth of Web3 core developers through initiatives such as.\n\n    - [Polkadot Blockchain Academy](https://polkadot.com/blockchain-academy){target=\\_blank}\n    - [EdX courses](https://www.edx.org/school/web3x){target=\\_blank}\n    - Rust and Substrate courses (coming soon)"}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 2, "depth": 3, "title": "High-Level Architecture", "anchor": "high-level-architecture", "start_char": 2926, "end_char": 4245, "estimated_token_count": 270, "token_estimator": "heuristic-v1", "text": "### High-Level Architecture\n\nPolkadot features a chain that serves as the central component of the system. This chain is depicted as a ring encircled by several parachains that are connected to it.\n\nAccording to Polkadot's design, any blockchain that can compile to WebAssembly (Wasm) and adheres to the Parachains Protocol becomes a parachain on the Polkadot network.\n\nHere’s a high-level overview of the Polkadot protocol architecture:\n\n![](/images/polkadot-protocol/architecture/polkadot-chain/overview/overview-1.webp)\n\nParachains propose blocks to Polkadot validators, who check for availability and validity before finalizing them. With the relay chain providing security, collators—full nodes of parachains—can focus on their tasks without needing strong incentives.\n\nThe [Cross-Consensus Messaging Format (XCM)](/develop/interoperability/intro-to-xcm/){target=\\_blank} allows parachains to exchange messages freely, leveraging the chain's security for trust-free communication.\n\nIn order to interact with chains that want to use their own finalization process (e.g., Bitcoin), Polkadot has [bridges](/polkadot-protocol/parachain-basics/interoperability/#bridges-connecting-external-networks){target=\\_blank} that offer two-way compatibility, meaning that transactions can be made between different parachains."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 3, "depth": 3, "title": "Polkadot's Additional Functionalities", "anchor": "polkadots-additional-functionalities", "start_char": 4245, "end_char": 6210, "estimated_token_count": 428, "token_estimator": "heuristic-v1", "text": "### Polkadot's Additional Functionalities\n\nHistorically, obtaining core slots on Polkadot chain relied upon crowdloans and auctions. Chain cores were leased through auctions for three-month periods, up to a maximum of two years. Crowdloans enabled users to securely lend funds to teams for lease deposits in exchange for pre-sale tokens, which is the only way to access slots on Polkadot 1.0. Auctions are now deprecated in favor of [coretime](/polkadot-protocol/architecture/system-chains/coretime/){target=\\_blank}.\n\nAdditionally, the chain handles [staking](https://wiki.polkadot.com/learn/learn-staking/){target=\\_blank}, [accounts](/polkadot-protocol/parachain-basics/accounts/){target=\\_blank}, balances, and [governance](/polkadot-protocol/onchain-governance/){target=\\_blank}.\n\n#### Agile Coretime\n\nThe new and more efficient way of obtaining core on Polkadot is to go through the process of purchasing coretime.\n\n[Agile coretime](/polkadot-protocol/architecture/polkadot-chain/agile-coretime/){target=\\_blank} improves the efficient use of Polkadot's network resources and offers economic flexibility for developers, extending Polkadot's capabilities far beyond the original vision outlined in the [whitepaper](https://polkadot.com/papers/Polkadot-whitepaper.pdf){target=\\_blank}.\n\nIt enables parachains to purchase monthly \"bulk\" allocations of coretime (the time allocated for utilizing a core, measured in Polkadot relay chain blocks), ensuring heavy-duty parachains that can author a block every six seconds with [Asynchronous Backing](https://wiki.polkadot.com/learn/learn-async-backing/#asynchronous-backing){target=\\_blank} can reliably renew their coretime each month. Although six-second block times are now the default, parachains have the option of producing blocks less frequently.\n\nRenewal orders are prioritized over new orders, offering stability against price fluctuations and helping parachains budget more effectively for project costs."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 4, "depth": 3, "title": "Polkadot's Resilience", "anchor": "polkadots-resilience", "start_char": 6210, "end_char": 7519, "estimated_token_count": 259, "token_estimator": "heuristic-v1", "text": "### Polkadot's Resilience\n\nDecentralization is a vital component of blockchain networks, but it comes with trade-offs:\n\n- An overly decentralized network may face challenges in reaching consensus and require significant energy to operate.\n- Also, a network that achieves consensus quickly risks centralization, making it easier to manipulate or attack.\n\nA network should be decentralized enough to prevent manipulative or malicious influence. In this sense, decentralization is a tool for achieving resilience.\n\nPolkadot 1.0 currently achieves resilience through several strategies:\n\n- **Nominated Proof of Stake (NPoS)**: Ensures that the stake per validator is maximized and evenly distributed among validators.\n\n- **Decentralized nodes**: Designed to encourage operators to join the network. This program aims to expand and diversify the validators in the ecosystem who aim to become independent of the program during their term. Feel free to explore more about the program on the official [Decentralized Nodes](https://nodes.web3.foundation/){target=\\_blank} page.\n\n- **On-chain treasury and governance**: Known as [OpenGov](/polkadot-protocol/onchain-governance/overview/){target=\\_blank}, this system allows every decision to be made through public referenda, enabling any token holder to cast a vote."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 5, "depth": 3, "title": "Polkadot's Blockspace", "anchor": "polkadots-blockspace", "start_char": 7519, "end_char": 9331, "estimated_token_count": 363, "token_estimator": "heuristic-v1", "text": "### Polkadot's Blockspace\n\nPolkadot 1.0’s design allows for the commoditization of blockspace.\n\nBlockspace is a blockchain's capacity to finalize and commit operations, encompassing its security, computing, and storage capabilities. Its characteristics can vary across different blockchains, affecting security, flexibility, and availability.\n\n- **Security**: Measures the robustness of blockspace in Proof of Stake (PoS) networks linked to the stake locked on validator nodes, the variance in stake among validators, and the total number of validators. It also considers social centralization (how many validators are owned by single operators) and physical centralization (how many validators run on the same service provider).\n\n- **Flexibility**: Reflects the functionalities and types of data that can be stored, with high-quality data essential to avoid bottlenecks in critical processes.\n\n- **Availability**: Indicates how easily users can access blockspace. It should be easily accessible, allowing diverse business models to thrive, ideally regulated by a marketplace based on demand and supplemented by options for \"second-hand\" blockspace.\n\nPolkadot is built on core blockspace principles, but there's room for improvement. Tasks like balance transfers, staking, and governance are managed on the relay chain.\n\nDelegating these responsibilities to [system chains](/polkadot-protocol/architecture/system-chains/){target=\\_blank} could enhance flexibility and allow the relay chain to concentrate on providing shared security and interoperability.\n\nFor more information about blockspace, watch [Robert Habermeier’s interview](https://www.youtube.com/watch?v=e1vISppPwe4){target=\\_blank} or read his [technical blog post](https://www.rob.tech/blog/polkadot-blockspace-over-blockchains/){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 6, "depth": 2, "title": "DOT Token", "anchor": "dot-token", "start_char": 9331, "end_char": 9624, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "## DOT Token\n\nDOT is the native token of the Polkadot network, much like BTC for Bitcoin and Ether for the Ethereum blockchain. DOT has 10 decimals, uses the Planck base unit, and has a balance type of `u128`. The same is true for Kusama's KSM token with the exception of having 12 decimals."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 7, "depth": 3, "title": "Redenomination of DOT", "anchor": "redenomination-of-dot", "start_char": 9624, "end_char": 10176, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Redenomination of DOT\n    \nPolkadot conducted a community poll, which ended on 27 July 2020 at block 888,888, to decide whether to redenominate the DOT token. The stakeholders chose to redenominate the token, changing the value of 1 DOT from 1e12 plancks to 1e10 plancks.\n\nImportantly, this did not affect the network's total number of base units (plancks); it only affects how a single DOT is represented. The redenomination became effective 72 hours after transfers were enabled, occurring at block 1,248,328 on 21 August 2020 around 16:50 UTC."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 8, "depth": 3, "title": "The Planck Unit", "anchor": "the-planck-unit", "start_char": 10176, "end_char": 10582, "estimated_token_count": 84, "token_estimator": "heuristic-v1", "text": "### The Planck Unit\n\nThe smallest unit of account balance on Polkadot SDK-based blockchains (such as Polkadot and Kusama) is called _Planck_, named after the Planck length, the smallest measurable distance in the physical universe.\n\nSimilar to how BTC's smallest unit is the Satoshi and ETH's is the Wei, Polkadot's native token DOT equals 1e10 Planck, while Kusama's native token KSM equals 1e12 Planck."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 9, "depth": 3, "title": "Uses for DOT", "anchor": "uses-for-dot", "start_char": 10582, "end_char": 11149, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### Uses for DOT\n\nDOT serves three primary functions within the Polkadot network:\n\n- **Governance**: It is used to participate in the governance of the network.\n- **Staking**: DOT is staked to support the network's operation and security.\n- **Buying coretime**: Used to purchase coretime in-bulk or on-demand and access the  chain to benefit from Polkadot's security and interoperability.\n\nAdditionally, DOT can serve as a transferable token. For example, DOT, held in the treasury, can be allocated to teams developing projects that benefit the Polkadot ecosystem."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-overview", "index": 10, "depth": 2, "title": "JAM and the Road Ahead", "anchor": "jam-and-the-road-ahead", "start_char": 11149, "end_char": 12513, "estimated_token_count": 239, "token_estimator": "heuristic-v1", "text": "## JAM and the Road Ahead\n\nThe Join-Accumulate Machine (JAM) represents a transformative redesign of Polkadot's core architecture, envisioned as the successor to the current relay chain. Unlike traditional blockchain architectures, JAM introduces a unique computational model that processes work through two primary functions:\n\n- **Join**: Handles data integration.\n- **Accumulate**: Folds computations into the chain's state.\n\nJAM removes many of the opinions and constraints of the current relay chain while maintaining its core security properties. Expected improvements include:\n\n- **Permissionless code execution**: JAM is designed to be more generic and flexible, allowing for permissionless code execution through services that can be deployed without governance approval.\n- **More effective block time utilization**: JAM's efficient pipeline processing model places the prior state root in block headers instead of the posterior state root, enabling more effective utilization of block time for computations.\n\nThis architectural evolution promises to enhance Polkadot's scalability and flexibility while maintaining robust security guarantees. JAM is planned to be rolled out to Polkadot as a single, complete upgrade rather than a stream of smaller updates. This approach seeks to minimize the developer overhead required to address any breaking changes."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 769, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's Proof of Stake consensus model leverages a unique hybrid approach by design to promote decentralized and secure network operations. In traditional Proof of Stake (PoS) systems, a node's ability to validate transactions is tied to its token holdings, which can lead to centralization risks and limited validator participation. Polkadot addresses these concerns through its [Nominated Proof of Stake (NPoS)](/polkadot-protocol/glossary/#nominated-proof-of-stake-npos){target=\\_blank} model and a combination of advanced consensus mechanisms to ensure efficient block production and strong finality guarantees. This combination enables the Polkadot network to scale while maintaining security and decentralization."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 1, "depth": 2, "title": "Nominated Proof of Stake", "anchor": "nominated-proof-of-stake", "start_char": 769, "end_char": 1796, "estimated_token_count": 215, "token_estimator": "heuristic-v1", "text": "## Nominated Proof of Stake\n\nPolkadot uses Nominated Proof of Stake (NPoS) to select the validator set and secure the network. This model is designed to maximize decentralization and security by balancing the roles of [validators](https://wiki.polkadot.com/learn/learn-validator/){target=\\_blank} and [nominators](https://wiki.polkadot.com/learn/learn-nominator/){target=\\_blank}.\n\n- **Validators**: Play a key role in maintaining the network's integrity. They produce new blocks, validate parachain blocks, and ensure the finality of transactions across the relay chain.\n- **Nominators**: Support the network by selecting validators to back with their stake. This mechanism allows users who don't want to run a validator node to still participate in securing the network and earn rewards based on the validators they support.\n\nIn Polkadot's NPoS system, nominators can delegate their tokens to trusted validators, giving them voting power in selecting validators while spreading security responsibilities across the network."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 2, "depth": 2, "title": "Hybrid Consensus", "anchor": "hybrid-consensus", "start_char": 1796, "end_char": 2848, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Hybrid Consensus\n\nPolkadot employs a hybrid consensus model that combines two key protocols: a finality gadget called [GRANDPA](#finality-gadget-grandpa) and a block production mechanism known as [BABE](#block-production-babe). This hybrid approach enables the network to benefit from both rapid block production and provable finality, ensuring security and performance.\n\nThe hybrid consensus model has some key advantages:\n\n- **Probabilistic finality**: With BABE constantly producing new blocks, Polkadot ensures that the network continues to make progress, even when a final decision has not yet been reached on which chain is the true canonical chain.\n\n- **Provable finality**: GRANDPA guarantees that once a block is finalized, it can never be reverted, ensuring that all network participants agree on the finalized chain.\n\nBy using separate protocols for block production and finality, Polkadot can achieve rapid block creation and strong guarantees of finality while avoiding the typical trade-offs seen in traditional consensus mechanisms."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 3, "depth": 2, "title": "Block Production - BABE", "anchor": "block-production-babe", "start_char": 2848, "end_char": 4678, "estimated_token_count": 364, "token_estimator": "heuristic-v1", "text": "## Block Production - BABE\n\nBlind Assignment for Blockchain Extension (BABE) is Polkadot's block production mechanism, working with GRANDPA to ensure blocks are produced consistently across the network. As validators participate in BABE, they are assigned block production slots through a randomness-based lottery system. This helps determine which validator is responsible for producing a block at a given time. BABE shares similarities with [Ouroboros Praos](https://eprint.iacr.org/2017/573.pdf){target=\\_blank} but differs in key aspects like chain selection rules and slot timing.\n\nKey features of BABE include:\n\n- **Epochs and slots**: BABE operates in phases called epochs, each of which is divided into slots (around 6 seconds per slot). Validators are assigned slots at the beginning of each epoch based on stake and randomness.\n\n- **Randomized block production**: Validators enter a lottery to determine which will produce a block in a specific slot. This randomness is sourced from the relay chain's [randomness cycle](/polkadot-protocol/parachain-basics/randomness/){target=\\_blank}.\n\n- **Multiple block producers per slot**: In some cases, more than one validator might win the lottery for the same slot, resulting in multiple blocks being produced. These blocks are broadcasted, and the network's fork choice rule helps decide which chain to follow.\n\n- **Handling empty slots**: If no validators win the lottery for a slot, a secondary selection algorithm ensures that a block is still produced. Validators selected through this method always produce a block, ensuring no slots are skipped.\n\nBABE's combination of randomness and slot allocation creates a secure, decentralized system for consistent block production while also allowing for fork resolution when multiple validators produce blocks for the same slot."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 4, "depth": 3, "title": "Validator Participation", "anchor": "validator-participation", "start_char": 4678, "end_char": 6347, "estimated_token_count": 335, "token_estimator": "heuristic-v1", "text": "### Validator Participation\n\nIn BABE, validators participate in a lottery for every slot to determine whether they are responsible for producing a block during that slot. This process's randomness ensures a decentralized and unpredictable block production mechanism.\n\nThere are two lottery outcomes for any given slot that initiate additional processes:\n\n- **Multiple validators in a slot**: Due to the randomness, multiple validators can be selected to produce a block for the same slot. When this happens, each validator produces a block and broadcasts it to the network resulting in a race condition. The network's topology and latency then determine which block reaches the majority of nodes first. BABE allows both chains to continue building until the finalization process resolves which one becomes canonical. The [Fork Choice](#fork-choice) rule is then used to decide which chain the network should follow.\n\n- **No validators in a slot**: On occasions when no validator is selected by the lottery, a [secondary validator selection algorithm](https://spec.polkadot.network/sect-block-production#defn-babe-secondary-slots){target=\\_blank} steps in. This backup ensures that a block is still produced, preventing skipped slots. However, if the primary block produced by a verifiable random function [(VRF)-selected](/polkadot-protocol/parachain-basics/randomness/#vrf){target=\\_blank} validator exists for that slot, the secondary block will be ignored. As a result, every slot will have either a primary or a secondary block.\n\nThis design ensures continuous block production, even in cases of multiple competing validators or an absence of selected validators."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 5, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 6347, "end_char": 6842, "estimated_token_count": 111, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nFor further technical insights about BABE, including cryptographic details and formal proofs, see the [BABE paper](https://research.web3.foundation/Polkadot/protocols/block-production/Babe){target=\\_blank} from Web3 Foundation.\n\nFor BABE technical definitions, constants, and formulas, see the [Block Production Lottery](https://spec.polkadot.network/sect-block-production#sect-block-production-lottery){target=\\_blank} section of the Polkadot Protocol Specification."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 6, "depth": 2, "title": "Finality Gadget - GRANDPA", "anchor": "finality-gadget-grandpa", "start_char": 6842, "end_char": 8360, "estimated_token_count": 292, "token_estimator": "heuristic-v1", "text": "## Finality Gadget - GRANDPA\n\nGRANDPA (GHOST-based Recursive ANcestor Deriving Prefix Agreement) serves as the finality gadget for Polkadot's relay chain. Operating alongside the BABE block production mechanism, it ensures provable finality, giving participants confidence that blocks finalized by GRANDPA cannot be reverted.\n\nKey features of GRANDPA include:\n\n- **Independent finality service**: GRANDPA runs separately from the block production process, operating in parallel to ensure seamless finalization.\n- **Chain-based finalization**: Instead of finalizing one block at a time, GRANDPA finalizes entire chains, speeding up the process significantly.\n- **Batch finalization**: Can finalize multiple blocks in a single round, enhancing efficiency and minimizing delays in the network.\n- **Partial synchrony tolerance**: GRANDPA works effectively in a partially synchronous network environment, managing both asynchronous and synchronous conditions.\n- **Byzantine fault tolerance**: Can handle up to 1/5 Byzantine (malicious) nodes, ensuring the system remains secure even when faced with adversarial behavior.\n\n??? note \"What is GHOST?\"\n    [GHOST (Greedy Heaviest-Observed Subtree)](https://eprint.iacr.org/2018/104.pdf){target=\\blank} is a consensus protocol used in blockchain networks to select the heaviest branch in a block tree. Unlike traditional longest-chain rules, GHOST can more efficiently handle high block production rates by considering the weight of subtrees rather than just the chain length."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 7, "depth": 3, "title": "Probabilistic vs. Provable Finality", "anchor": "probabilistic-vs-provable-finality", "start_char": 8360, "end_char": 9166, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "### Probabilistic vs. Provable Finality\n\nIn traditional Proof of Work (PoW) blockchains, finality is probabilistic. As blocks are added to the chain, the probability that a block is final increases, but it can never be guaranteed. Eventual consensus means that all nodes will agree on a single version of the blockchain over time, but this process can be unpredictable and slow.\n\nConversely, GRANDPA provides provable finality, which means that once a block is finalized, it is irreversible. By using Byzantine fault-tolerant agreements, GRANDPA finalizes blocks more efficiently and securely than probabilistic mechanisms like Nakamoto consensus. Like Ethereum's Casper the Friendly Finality Gadget (FFG), GRANDPA ensures that finalized blocks cannot be reverted, offering stronger consensus guarantees."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 8, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources-2", "start_char": 9166, "end_char": 9712, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nFor technical insights, including formal proofs and detailed algorithms, see the [GRANDPA paper](https://github.com/w3f/consensus/blob/master/pdf/grandpa.pdf){target=\\_blank} from Web3 Foundation.\n\nFor a deeper look at the code behind GRANDPA, see the following GitHub repositories:\n\n- [GRANDPA Rust implementation](https://github.com/paritytech/finality-grandpa){target=\\_blank}\n- [GRANDPA Pallet](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/substrate/frame/grandpa/src/lib.rs){target=\\_blank}"}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 9, "depth": 2, "title": "Fork Choice", "anchor": "fork-choice", "start_char": 9712, "end_char": 10553, "estimated_token_count": 174, "token_estimator": "heuristic-v1", "text": "## Fork Choice\n\nThe fork choice of the relay chain combines BABE and GRANDPA:\n\n1. BABE must always build on the chain that GRANDPA has finalized.\n2. When there are forks after the finalized head, BABE builds on the chain with the most primary blocks to provide probabilistic finality.\n\n![Fork choice diagram](/images/polkadot-protocol/architecture/polkadot-chain/pos-consensus/consensus-protocols-1.webp)\n\nIn the preceding diagram, finalized blocks are black, and non-finalized blocks are yellow. Primary blocks are labeled '1', and secondary blocks are labeled '2.' The topmost chain is the longest chain originating from the last finalized block, but it is not selected because it only has one primary block at the time of evaluation. In comparison, the one below it originates from the last finalized block and has three primary blocks."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 10, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources-3", "start_char": 10553, "end_char": 11140, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nTo learn more about how BABE and GRANDPA work together to produce and finalize blocks on Kusama, see this [Block Production and Finalization in Polkadot](https://youtu.be/FiEAnVECa8c){target=\\_blank} talk from Web3 Foundation's Bill Laboon. \n\nFor an in-depth academic discussion about Polkadot's hybrid consensus model, see this [Block Production and Finalization in Polkadot: Understanding the BABE and GRANDPA Protocols](https://www.youtube.com/watch?v=1CuTSluL7v4&t=4s){target=\\_blank} MIT Cryptoeconomic Systems 2020 talk by Web3 Foundation's Bill Laboon."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 11, "depth": 2, "title": "Bridging - BEEFY", "anchor": "bridging-beefy", "start_char": 11140, "end_char": 12542, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "## Bridging - BEEFY\n\nBridge Efficiency Enabling Finality Yielder (BEEFY) is a specialized protocol that extends the finality guarantees provided by GRANDPA. It is specifically designed to facilitate efficient bridging between Polkadot relay chains (such as Polkadot and Kusama) and external blockchains like Ethereum. While GRANDPA is well-suited for finalizing blocks within Polkadot, it has limitations when bridging external chains that weren't built with Polkadot's interoperability features in mind. BEEFY addresses these limitations by ensuring other networks can efficiently verify finality proofs.\n\nKey features of BEEFY include:\n\n- **Efficient finality proof verification**: BEEFY enables external networks to easily verify Polkadot finality proofs, ensuring seamless communication between chains.\n- **Merkle Mountain Ranges (MMR)**: This data structure is used to efficiently store and transmit proofs between chains, optimizing data storage and reducing transmission overhead.\n- **ECDSA signature schemes**: BEEFY uses ECDSA signatures, which are widely supported on Ethereum and other EVM-based chains, making integration with these ecosystems smoother.\n- **Light client optimization**: BEEFY reduces the computational burden on light clients by allowing them to check for a super-majority of validator votes rather than needing to process all validator signatures, improving performance."}
{"page_id": "polkadot-protocol-architecture-polkadot-chain-pos-consensus", "index": 12, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources-4", "start_char": 12542, "end_char": 12786, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nFor BEEFY technical definitions, constants, and formulas, see the [Bridge design (BEEFY)](https://spec.polkadot.network/sect-finality#sect-grandpa-beefy){target=\\_blank} section of the Polkadot Protocol Specification."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 682, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Asset Hub is a critical component in the Polkadot ecosystem, enabling the management of fungible and non-fungible assets across the network. Since the relay chain focuses on maintaining security and consensus without direct asset management, Asset Hub provides a streamlined platform for creating, managing, and using on-chain assets in a fee-efficient manner. This guide outlines the core features of Asset Hub, including how it handles asset operations, cross-chain transfers, and asset integration using XCM, as well as essential tools like [API Sidecar](#api-sidecar) and [`TxWrapper`](#txwrapper) for developers working with on-chain assets."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 1, "depth": 2, "title": "Assets Basics", "anchor": "assets-basics", "start_char": 682, "end_char": 3257, "estimated_token_count": 493, "token_estimator": "heuristic-v1", "text": "## Assets Basics\n\nIn the Polkadot ecosystem, the relay chain does not natively support additional assets beyond its native token (DOT for Polkadot, KSM for Kusama). The Asset Hub parachain on Polkadot and Kusama provides a fungible and non-fungible assets framework. Asset Hub allows developers and users to create, manage, and use assets across the ecosystem.\n\nAsset creators can use Asset Hub to track their asset issuance across multiple parachains and manage assets through operations such as minting, burning, and transferring. Projects that need a standardized method of handling on-chain assets will find this particularly useful. The fungible asset interface provided by Asset Hub closely resembles Ethereum's ERC-20 standard but is directly integrated into Polkadot's runtime, making it more efficient in terms of speed and transaction fees.\n\nIntegrating with Asset Hub offers several key benefits, particularly for infrastructure providers and users:\n\n- **Support for non-native on-chain assets**: Asset Hub enables seamless asset creation and management, allowing projects to develop tokens or assets that can interact with the broader ecosystem.\n- **Lower transaction fees**: Asset Hub offers significantly lower transaction costs—approximately one-tenth of the fees on the relay chain, providing cost-efficiency for regular operations.\n- **Reduced deposit requirements**: Depositing assets in Asset Hub is more accessible, with deposit requirements that are around one one-hundredth of those on the relay chain.\n- **Payment of transaction fees with non-native assets**: Users can pay transaction fees in assets other than the native token (DOT or KSM), offering more flexibility for developers and users.\n\nAssets created on the Asset Hub are stored as part of a map, where each asset has a unique ID that links to information about the asset, including details like:\n\n- The management team.\n- The total supply.\n- The number of accounts holding the asset.\n- **Sufficiency for account existence**: Whether the asset alone is enough to maintain an account without a native token balance.\n- The metadata of the asset, including its name, symbol, and the number of decimals for representation.\n\nSome assets can be regarded as sufficient to maintain an account's existence, meaning that users can create accounts on the network without needing a native token balance (i.e., no existential deposit required). Developers can also set minimum balances for their assets. If an account's balance drops below the minimum, the balance is considered dust and may be cleared."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 2, "depth": 2, "title": "Assets Pallet", "anchor": "assets-pallet", "start_char": 3257, "end_char": 3793, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "## Assets Pallet\n\nThe Polkadot SDK's Assets pallet is a powerful module designated for creating and managing fungible asset classes with a fixed supply. It offers a secure and flexible way to issue, transfer, freeze, and destroy assets. The pallet supports various operations and includes permissioned and non-permissioned functions to cater to simple and advanced use cases.\n\nVisit the [Assets Pallet Rust docs](https://paritytech.github.io/polkadot-sdk/master/pallet_assets/index.html){target=\\_blank} for more in-depth information."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 3, "depth": 3, "title": "Key Features", "anchor": "key-features", "start_char": 3793, "end_char": 4454, "estimated_token_count": 140, "token_estimator": "heuristic-v1", "text": "### Key Features\n\nKey features of the Assets pallet include:\n\n- **Asset issuance**: Allows the creation of a new asset, where the total supply is assigned to the creator's account.\n- **Asset transfer**: Enables transferring assets between accounts while maintaining a balance in both accounts.\n- **Asset freezing**: Prevents transfers of a specific asset from one account, locking it from further transactions.\n- **Asset destruction**: Allows accounts to burn or destroy their holdings, removing those assets from circulation.\n- **Non-custodial transfers**: A non-custodial mechanism to enable one account to approve a transfer of assets on behalf of another."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 4, "depth": 3, "title": "Main Functions", "anchor": "main-functions", "start_char": 4454, "end_char": 5397, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "### Main Functions\n\nThe Assets pallet provides a broad interface for managing fungible assets. Some of the main dispatchable functions include:\n\n- **`create()`**: Create a new asset class by placing a deposit, applicable when asset creation is permissionless.\n- **`issue()`**: Mint a fixed supply of a new asset and assign it to the creator's account.\n- **`transfer()`**: Transfer a specified amount of an asset between two accounts.\n- **`approve_transfer()`**: Approve a non-custodial transfer, allowing a third party to move assets between accounts.\n- **`destroy()`**: Destroy an entire asset class, removing it permanently from the chain.\n- **`freeze()` and `thaw()`**: Administrators or privileged users can lock or unlock assets from being transferred.\n\nFor a full list of dispatchable and privileged functions, see the [dispatchables Rust docs](https://docs.rs/pallet-assets/latest/pallet_assets/pallet/enum.Call.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 5, "depth": 3, "title": "Querying Functions", "anchor": "querying-functions", "start_char": 5397, "end_char": 6347, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "### Querying Functions\n\nThe Assets pallet exposes several key querying functions that developers can interact with programmatically. These functions allow you to query asset information and perform operations essential for managing assets across accounts. The two main querying functions are:\n\n- **`balance(asset_id, account)`**: Retrieves the balance of a given asset for a specified account. Useful for checking the holdings of an asset class across different accounts.\n\n- **`total_supply(asset_id)`**: Returns the total supply of the asset identified by `asset_id`. Allows users to verify how much of the asset exists on-chain.\n\nIn addition to these basic functions, other utility functions are available for querying asset metadata and performing asset transfers. You can view the complete list of querying functions in the [Struct Pallet Rust docs](https://docs.rs/pallet-assets/latest/pallet_assets/pallet/struct.Pallet.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 6, "depth": 3, "title": "Permission Models and Roles", "anchor": "permission-models-and-roles", "start_char": 6347, "end_char": 7634, "estimated_token_count": 239, "token_estimator": "heuristic-v1", "text": "### Permission Models and Roles\n\nThe Assets pallet incorporates a robust permission model, enabling control over who can perform specific operations like minting, transferring, or freezing assets. The key roles within the permission model are:\n\n- **Admin**: Can freeze (preventing transfers) and forcibly transfer assets between accounts. Admins also have the power to reduce the balance of an asset class across arbitrary accounts. They manage the more sensitive and administrative aspects of the asset class.\n- **Issuer**: Responsible for minting new tokens. When new assets are created, the Issuer is the account that controls their distribution to other accounts.\n- **Freezer**: Can lock the transfer of assets from an account, preventing the account holder from moving their balance. This function is useful for freezing accounts involved in disputes or fraud.\n- **Owner**: Has overarching control, including destroying an entire asset class. Owners can also set or update the Issuer, Freezer, and Admin roles.\n\nThese permissions provide fine-grained control over assets, enabling developers and asset managers to ensure secure, controlled operations. Each of these roles is crucial for managing asset lifecycles and ensuring that assets are used appropriately across the network."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 7, "depth": 3, "title": "Asset Freezing", "anchor": "asset-freezing", "start_char": 7634, "end_char": 8552, "estimated_token_count": 172, "token_estimator": "heuristic-v1", "text": "### Asset Freezing\n\nThe Assets pallet allows you to freeze assets. This feature prevents transfers or spending from a specific account, effectively locking the balance of an asset class until it is explicitly unfrozen. Asset freezing is beneficial when assets are restricted due to security concerns or disputes.\n\nFreezing assets is controlled by the Freezer role, as mentioned earlier. Only the account with the Freezer privilege can perform these operations. Here are the key freezing functions:\n\n- **`freeze(asset_id, account)`**: Locks the specified asset of the account. While the asset is frozen, no transfers can be made from the frozen account.\n- **`thaw(asset_id, account)`**: Corresponding function for unfreezing, allowing the asset to be transferred again.\n\nThis approach enables secure and flexible asset management, providing administrators the tools to control asset movement in special circumstances."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 8, "depth": 3, "title": "Non-Custodial Transfers (Approval API)", "anchor": "non-custodial-transfers-approval-api", "start_char": 8552, "end_char": 9746, "estimated_token_count": 232, "token_estimator": "heuristic-v1", "text": "### Non-Custodial Transfers (Approval API)\n\nThe Assets pallet also supports non-custodial transfers through the Approval API. This feature allows one account to approve another account to transfer a specific amount of its assets to a third-party recipient without granting full control over the account's balance. Non-custodial transfers enable secure transactions where trust is required between multiple parties.\n\nHere's a brief overview of the key functions for non-custodial asset transfers:\n\n- **`approve_transfer(asset_id, delegate, amount)`**: Approves a delegate to transfer up to a certain amount of the asset on behalf of the original account holder.\n- **`cancel_approval(asset_id, delegate)`**: Cancels a previous approval for the delegate. Once canceled, the delegate no longer has permission to transfer the approved amount.\n- **`transfer_approved(asset_id, owner, recipient, amount)`**: Executes the approved asset transfer from the owner’s account to the recipient. The delegate account can call this function once approval is granted.\n\nThese delegated operations make it easier to manage multi-step transactions and dApps that require complex asset flows between participants."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 9, "depth": 2, "title": "Foreign Assets", "anchor": "foreign-assets", "start_char": 9746, "end_char": 10290, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Foreign Assets\n\nForeign assets in Asset Hub refer to assets originating from external blockchains or parachains that are registered in the Asset Hub. These assets are typically native tokens from other parachains within the Polkadot ecosystem or bridged tokens from external blockchains such as Ethereum.\n\nOnce a foreign asset is registered in the Asset Hub by its originating blockchain's root origin, users are able to send these tokens to the Asset Hub and interact with them as they would any other asset within the Polkadot ecosystem."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 10, "depth": 3, "title": "Handling Foreign Assets", "anchor": "handling-foreign-assets", "start_char": 10290, "end_char": 11225, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "### Handling Foreign Assets\n\nThe Foreign Assets pallet, an instance of the Assets pallet, manages these assets. Since foreign assets are integrated into the same interface as native assets, developers can use the same functionalities, such as transferring and querying balances. However, there are important distinctions when dealing with foreign assets.\n\n- **Asset identifier**: Unlike native assets, foreign assets are identified using an XCM Multilocation rather than a simple numeric `AssetId`. This multilocation identifier represents the cross-chain location of the asset and provides a standardized way to reference it across different parachains and relay chains.\n\n- **Transfers**: Once registered in the Asset Hub, foreign assets can be transferred between accounts, just like native assets. Users can also send these assets back to their originating blockchain if supported by the relevant cross-chain messaging mechanisms."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 11, "depth": 2, "title": "Integration", "anchor": "integration", "start_char": 11225, "end_char": 11668, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Integration\n\nAsset Hub supports a variety of integration tools that make it easy for developers to manage assets and interact with the blockchain in their applications. The tools and libraries provided by Parity Technologies enable streamlined operations, such as querying asset information, building transactions, and monitoring cross-chain asset transfers.\n\nDevelopers can integrate Asset Hub into their projects using these core tools:"}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 12, "depth": 3, "title": "API Sidecar", "anchor": "api-sidecar", "start_char": 11668, "end_char": 12511, "estimated_token_count": 211, "token_estimator": "heuristic-v1", "text": "### API Sidecar\n\n[API Sidecar](https://github.com/paritytech/substrate-api-sidecar){target=\\_blank} is a RESTful service that can be deployed alongside Polkadot and Kusama nodes. It provides endpoints to retrieve real-time blockchain data, including asset information. When used with Asset Hub, Sidecar allows querying:\n\n- **Asset look-ups**: Retrieve specific assets using `AssetId`.\n- **Asset balances**: View the balance of a particular asset on Asset Hub.\n\nPublic instances of API Sidecar connected to Asset Hub are available, such as:\n\n- [Polkadot Asset Hub Sidecar](https://polkadot-asset-hub-public-sidecar.parity-chains.parity.io/){target=\\_blank}\n- [Kusama Asset Hub Sidecar](https://kusama-asset-hub-public-sidecar.parity-chains.parity.io/){target=\\_blank}\n\nThese public instances are primarily for ad-hoc testing and quick checks."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 13, "depth": 3, "title": "TxWrapper", "anchor": "txwrapper", "start_char": 12511, "end_char": 13112, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "### TxWrapper\n\n[`TxWrapper`](https://github.com/paritytech/txwrapper-core){target=\\_blank} is a library that simplifies constructing and signing transactions for Polkadot SDK-based chains, including Polkadot and Kusama. This tool includes support for working with Asset Hub, enabling developers to:\n\n- Construct offline transactions.\n- Leverage asset-specific functions such as minting, burning, and transferring assets.\n\n`TxWrapper` provides the flexibility needed to integrate asset operations into custom applications while maintaining the security and efficiency of Polkadot's transaction model."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 14, "depth": 3, "title": "Asset Transfer API", "anchor": "asset-transfer-api", "start_char": 13112, "end_char": 13984, "estimated_token_count": 181, "token_estimator": "heuristic-v1", "text": "### Asset Transfer API\n\n[Asset Transfer API](https://github.com/paritytech/asset-transfer-api){target=\\_blank} is a library focused on simplifying the construction of asset transfers for Polkadot SDK-based chains that involve system parachains like Asset Hub. It exposes a reduced set of methods that facilitate users sending transfers to other parachains or locally. Refer to the [cross-chain support table](https://github.com/paritytech/asset-transfer-api/tree/main#current-cross-chain-support){target=\\_blank} for the current status of cross-chain support development.\n\nKey features include:\n\n- Support for cross-chain transfers between parachains.\n- Streamlined transaction construction with support for the necessary parachain metadata.\n\nThe API supports various asset operations, such as paying transaction fees with non-native tokens and managing asset liquidity."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 15, "depth": 3, "title": "Parachain Node", "anchor": "parachain-node", "start_char": 13984, "end_char": 14635, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "### Parachain Node\n\nTo fully leverage the Asset Hub's functionality, developers will need to run a system parachain node. Setting up an Asset Hub node allows users to interact with the parachain in real time, syncing data and participating in the broader Polkadot ecosystem. Guidelines for setting up an [Asset Hub node](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/cumulus#asset-hub-){target=\\_blank} are available in the Parity documentation.\n\nUsing these integration tools, developers can manage assets seamlessly and integrate Asset Hub functionality into their applications, leveraging Polkadot's powerful infrastructure."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 16, "depth": 2, "title": "XCM Transfer Monitoring", "anchor": "xcm-transfer-monitoring", "start_char": 14635, "end_char": 14978, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## XCM Transfer Monitoring\n\nSince Asset Hub facilitates cross-chain asset transfers across the Polkadot ecosystem, XCM transfer monitoring becomes an essential practice for developers and infrastructure providers. This section outlines how to monitor the cross-chain movement of assets between parachains, the relay chain, and other systems."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 17, "depth": 3, "title": "Monitor XCM Deposits", "anchor": "monitor-xcm-deposits", "start_char": 14978, "end_char": 15770, "estimated_token_count": 160, "token_estimator": "heuristic-v1", "text": "### Monitor XCM Deposits\n\nAs assets move between chains, tracking the cross-chain transfers in real time is crucial. Whether assets are transferred via a teleport from system parachains or through a reserve-backed transfer from any other parachain, each transfer emits a relevant event (such as the `balances.minted` event).\n\nTo ensure accurate monitoring of these events:\n\n- **Track XCM deposits**: Query every new block created in the relay chain or Asset Hub, loop through the events array, and filter for any `balances.minted` events which confirm the asset was successfully transferred to the account.\n- **Track event origins**: Each `balances.minted` event points to a specific address. By monitoring this, service providers can verify that assets have arrived in the correct account."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 18, "depth": 3, "title": "Track XCM Information Back to the Source", "anchor": "track-xcm-information-back-to-the-source", "start_char": 15770, "end_char": 16437, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "### Track XCM Information Back to the Source\n\nWhile the `balances.minted` event confirms the arrival of assets, there may be instances where you need to trace the origin of the cross-chain message that triggered the event. In such cases, you can:\n\n1. Query the relevant chain at the block where the `balances.minted` event was emitted.\n2. Look for a `messageQueue(Processed)` event within that block's initialization. This event contains a parameter (`Id`) that identifies the cross-chain message received by the relay chain or Asset Hub. You can use this `Id` to trace the message back to its origin chain, offering full visibility of the asset transfer's journey."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 19, "depth": 3, "title": "Practical Monitoring Examples", "anchor": "practical-monitoring-examples", "start_char": 16437, "end_char": 17248, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "### Practical Monitoring Examples\n\nThe preceding sections outline the process of monitoring XCM deposits to specific accounts and then tracing back the origin of these deposits. The process of tracking an XCM transfer and the specific events to monitor may vary based on the direction of the XCM message. Here are some examples to showcase the slight differences:\n\n- **Transfer from parachain to relay chain**: Track `parachainsystem(UpwardMessageSent)` on the parachain and `messagequeue(Processed)` on the relay chain.\n- **Transfer from relay chain to parachain**: Track `xcmPallet(sent)` on the relay chain and `dmpqueue(ExecutedDownward)` on the parachain.\n- **Transfer between parachains**: Track `xcmpqueue(XcmpMessageSent)` on the system parachain and `xcmpqueue(Success)` on the destination parachain."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 20, "depth": 3, "title": "Monitor for Failed XCM Transfers", "anchor": "monitor-for-failed-xcm-transfers", "start_char": 17248, "end_char": 18056, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "### Monitor for Failed XCM Transfers\n\nSometimes, XCM transfers may fail due to liquidity or other errors. Failed transfers emit specific error events, which are key to resolving issues in asset transfers. Monitoring for these failure events helps catch issues before they affect asset balances.\n\n- **Relay chain to system parachain**: Look for the `dmpqueue(ExecutedDownward)` event on the parachain with an `Incomplete` outcome and an error type such as `UntrustedReserveLocation`.\n- **Parachain to parachain**: Monitor for `xcmpqueue(Fail)` on the destination parachain with error types like `TooExpensive`.\n\nFor detailed error management in XCM, see Gavin Wood's blog post on [XCM Execution and Error Management](https://polkadot.com/blog/xcm-part-three-execution-and-error-management/){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-asset-hub", "index": 21, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 18056, "end_char": 19115, "estimated_token_count": 262, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Register a Local Asset__\n\n    ---\n\n    Comprehensive guide to registering a local asset on the Asset Hub system parachain, including step-by-step instructions.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-asset/)\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Register a Foreign Asset__\n\n    ---\n\n    An in-depth guide to registering a foreign asset on the Asset Hub parachain, providing clear, step-by-step instructions.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-asset/)\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Convert Assets__\n\n    ---\n\n    A guide detailing the step-by-step process of converting assets on Asset Hub, helping users efficiently navigate asset management on the platform.\n\n    [:octicons-arrow-right-24: Reference](/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/)\n\n</div>"}
{"page_id": "polkadot-protocol-architecture-system-chains-bridge-hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 1073, "estimated_token_count": 186, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Bridge Hub system parachain plays a crucial role in facilitating trustless interactions between Polkadot, Kusama, Ethereum, and other blockchain ecosystems. By implementing on-chain light clients and supporting protocols like BEEFY and GRANDPA, Bridge Hub ensures seamless message transmission and state verification across chains. It also provides essential [pallets](/polkadot-protocol/glossary/#pallet){target=\\_blank} for sending and receiving messages, making it a cornerstone of Polkadot’s interoperability framework. With built-in support for XCM (Cross-Consensus Messaging), Bridge Hub enables secure, efficient communication between diverse blockchain networks.\n\nThis guide covers the architecture, components, and deployment of the Bridge Hub system. You'll explore its trustless bridging mechanisms, key pallets for various blockchains, and specific implementations like Snowbridge and the Polkadot <> Kusama bridge. By the end, you'll understand how Bridge Hub enhances connectivity within the Polkadot ecosystem and beyond."}
{"page_id": "polkadot-protocol-architecture-system-chains-bridge-hub", "index": 1, "depth": 2, "title": "Trustless Bridging", "anchor": "trustless-bridging", "start_char": 1073, "end_char": 2679, "estimated_token_count": 311, "token_estimator": "heuristic-v1", "text": "## Trustless Bridging\n\nBridge Hub provides a mode of trustless bridging through its implementation of on-chain light clients and trustless relayers. Trustless bridges are essentially two one-way bridges, where each chain has a method of verifying the state of the other in a trustless manner through consensus proofs. In this context, \"trustless\" refers to the lack of need to trust a human when interacting with various system components. Trustless systems are based instead on trusting mathematics, cryptography, and code. The target chain and source chain both provide ways of verifying one another's state and actions (such as a transfer) based on the consensus and finality of both chains rather than an external mechanism controlled by a third party.\n\n[BEEFY (Bridge Efficiency Enabling Finality Yielder)](/polkadot-protocol/architecture/polkadot-chain/pos-consensus/#bridging-beefy){target=\\_blank} is instrumental in this solution. It provides a more efficient way to verify the consensus on the relay chain. It allows the participants in a network to verify finality proofs, meaning a remote chain like Ethereum can verify the state of Polkadot at a given block height. \n\nFor example, the Ethereum and Polkadot bridging solution that [Snowbridge](https://docs.snowbridge.network/){target=\\_blank} implements involves two light clients: one which verifies the state of Polkadot and the other which verifies the state of Ethereum. The light client for Polkadot is implemented in the runtime as a pallet, whereas the light client for Ethereum is implemented as a smart contract on the beacon chain."}
{"page_id": "polkadot-protocol-architecture-system-chains-bridge-hub", "index": 2, "depth": 2, "title": "Bridging Components", "anchor": "bridging-components", "start_char": 2679, "end_char": 3631, "estimated_token_count": 242, "token_estimator": "heuristic-v1", "text": "## Bridging Components\n\nIn any given Bridge Hub implementation (Kusama, Polkadot, or other relay chains), there are a few primary pallets that are utilized:\n\n- **[Pallet Bridge GRANDPA](https://paritytech.github.io/polkadot-sdk/master/pallet_bridge_grandpa/index.html){target=\\_blank}**: An on-chain GRANDPA light client for Substrate based chains.\n- **[Pallet Bridge Parachains](https://paritytech.github.io/polkadot-sdk/master/pallet_bridge_parachains/index.html){target=\\_blank}**: A finality module for parachains.\n- **[Pallet Bridge Messages](https://paritytech.github.io/polkadot-sdk/master/pallet_bridge_messages/index.html){target=\\_blank}**: A pallet which allows sending, receiving, and tracking of inbound and outbound messages.\n- **[Pallet XCM Bridge](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm_bridge_hub/index.html){target=\\_blank}**: A pallet which, with the Bridge Messages pallet, adds XCM support to bridge pallets."}
{"page_id": "polkadot-protocol-architecture-system-chains-bridge-hub", "index": 3, "depth": 3, "title": "Ethereum-Specific Support", "anchor": "ethereum-specific-support", "start_char": 3631, "end_char": 4249, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### Ethereum-Specific Support\n\nBridge Hub also has a set of components and pallets that support a bridge between Polkadot and Ethereum through [Snowbridge](https://github.com/Snowfork/snowbridge){target=\\_blank}.\n\nTo view the complete list of which pallets are included in Bridge Hub, visit the Subscan [Runtime Modules](https://bridgehub-polkadot.subscan.io/runtime){target=\\_blank} page. Alternatively, the source code for those pallets can be found in the Polkadot SDK [Snowbridge Pallets](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/bridges/snowbridge/pallets){target=\\_blank} repository."}
{"page_id": "polkadot-protocol-architecture-system-chains-bridge-hub", "index": 4, "depth": 2, "title": "Deployed Bridges", "anchor": "deployed-bridges", "start_char": 4249, "end_char": 4846, "estimated_token_count": 160, "token_estimator": "heuristic-v1", "text": "## Deployed Bridges\n\n- [**Snowbridge**](https://wiki.polkadot.com/learn/learn-snowbridge/){target=\\_blank}: A general-purpose, trustless bridge between Polkadot and Ethereum.\n- [**Hyperbridge**](https://wiki.polkadot.com/learn/learn-hyperbridge/){target=\\_blank}: A cross-chain solution built as an interoperability coprocessor, providing state-proof-based interoperability across all blockchains.\n- [**Polkadot <> Kusama Bridge**](https://wiki.polkadot.com/learn/learn-dot-ksm-bridge/){target=\\_blank}: A bridge that utilizes relayers to bridge the Polkadot and Kusama relay chains trustlessly."}
{"page_id": "polkadot-protocol-architecture-system-chains-bridge-hub", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4846, "end_char": 5469, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n- Go over the Bridge Hub README in the Polkadot SDK [Bridge-hub Parachains](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/cumulus/parachains/runtimes/bridge-hubs/README.md){target=\\_blank} repository.\n- Take a deeper dive into bridging architecture in the Polkadot SDK [High-Level Bridge](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/bridges/docs/high-level-overview.md){target=\\_blank} documentation.\n- Read more about [BEEFY and Bridging in the Polkadot Wiki](/polkadot-protocol/architecture/polkadot-chain/pos-consensus/#bridging-beefy){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-collectives", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 824, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEstablished through [Referendum 81](https://polkadot-old.polkassembly.io/referendum/81){target=\\_blank}, the Collectives chain operates as a dedicated parachain exclusive to the Polkadot network with no counterpart on Kusama. This specialized infrastructure provides a foundation for various on-chain governance groups essential to Polkadot's ecosystem.\n\nThe architecture enables entire networks to function as unified entities, allowing them to present cohesive positions and participate in cross-network governance through [Bridge Hub](/polkadot-protocol/architecture/system-chains/bridge-hub){target=\\_blank}. This capability represents a fundamental advancement in Web3 principles, eliminating dependencies on traditional third-party intermediaries such as legal systems or jurisdictional authorities."}
{"page_id": "polkadot-protocol-architecture-system-chains-collectives", "index": 1, "depth": 2, "title": "Key Collectives", "anchor": "key-collectives", "start_char": 824, "end_char": 2288, "estimated_token_count": 274, "token_estimator": "heuristic-v1", "text": "## Key Collectives\n\nThe Collectives chain hosts several important governance bodies:\n\n- [**Polkadot Technical Fellowship**](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank}: A self-governing assembly of protocol experts and developers who oversee technical aspects of the Polkadot and Kusama networks. The Fellowship operates both on-chain through the collectives system and off-chain via GitHub repositories, public discussion forums, and monthly development calls that are publicly accessible.\n\n- [**Polkadot Alliance**](https://wiki.polkadot.com/general/glossary/#polkadot-alliance){target=\\_blank}: A consortium founded by seven leading parachain projects (Acala, Astar, Interlay, Kilt, Moonbeam, Phala, and Subscan) to establish development standards and ethical guidelines within the ecosystem. This ranked collective, comprised of \"Fellows\" and \"Allies,\" focuses on promoting best practices and identifying potential bad actors. Membership is primarily designed for organizations, projects, and other networks rather than individuals.\n\nThese collectives serve as pillars of Polkadot's decentralized governance model, enabling community-driven decision-making and establishing technical standards that shape the network's evolution. Through structured on-chain representation, they provide transparent mechanisms for ecosystem development while maintaining the core Web3 principles of trustlessness and decentralization."}
{"page_id": "polkadot-protocol-architecture-system-chains-coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 1800, "estimated_token_count": 451, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Coretime system chain facilitates the allocation, procurement, sale, and scheduling of bulk [coretime](/polkadot-protocol/glossary/#coretime){target=\\_blank}, enabling tasks (such as [parachains](/polkadot-protocol/glossary/#parachain){target=\\_blank}) to utilize the computation and security provided by Polkadot. \n\nThe [Broker pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/index.html){target=\\_blank}, along with [Cross Consensus Messaging (XCM)](/develop/interoperability/intro-to-xcm/){target=\\_blank}, enables this functionality to be delegated to the system chain rather than the relay chain. Using [XCMP's Upward Message Passing (UMP)](https://wiki.polkadot.com/learn/learn-xcm-transport/#ump-upward-message-passing){target=\\_blank} to the relay chain allows for core assignments to take place for a task registered on the relay chain.\n\nThe Fellowship RFC [RFC-1: Agile Coretime](https://github.com/polkadot-fellows/RFCs/blob/main/text/0001-agile-coretime.md){target=\\_blank} contains the specification for the Coretime system chain and coretime as a concept.\n\nBesides core management, its responsibilities include: \n\n- The number of cores that should be made available.\n- Which tasks should be running on which cores and in what ratios.\n- Accounting information for the on-demand pool.\n\nFrom the relay chain, it expects the following via [Downward Message Passing (DMP)](https://wiki.polkadot.com/learn/learn-xcm-transport/#dmp-downward-message-passing){target=\\_blank}:\n\n- The number of cores available to be scheduled.\n- Account information on on-demand scheduling.\n\nThe details for this interface can be found in [RFC-5: Coretime Interface](https://github.com/polkadot-fellows/RFCs/blob/main/text/0005-coretime-interface.md){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-coretime", "index": 1, "depth": 2, "title": "Bulk Coretime Assignment", "anchor": "bulk-coretime-assignment", "start_char": 1800, "end_char": 4640, "estimated_token_count": 630, "token_estimator": "heuristic-v1", "text": "## Bulk Coretime Assignment\n\nThe Coretime chain allocates coretime before its usage. It also manages the ownership of a core. As cores are made up of regions (by default, one core is a single region), a region is recognized as a non-fungible asset. The Coretime chain exposes Regions over XCM as an NFT. Users can transfer individual regions, partition, interlace, or allocate them to a task. Regions describe how a task may use a core.\n\nA core can be considered a logical representation of an active validator set on the relay chain, where these validators commit to verifying the state changes for a particular task running on that region. With partitioning, having more than one region per core is possible, allowing for different computational schemes. Therefore, running more than one task on a single core is possible.\n\nRegions can be managed in the following manner on the Coretime chain:\n\n- **Assigning region**: Regions can be assigned to a task on the relay chain, such as a parachain/rollup using the [`assign`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/dispatchables/fn.assign.html){target=\\_blank} dispatchable.\n\n- **Transferring regions**: Regions may be transferred on the Coretime chain, upon which the [`transfer`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/dispatchables/fn.transfer.html){target=\\_blank} [dispatchable](/polkadot-protocol/glossary/#dispatchable){target=\\_blank} in the Broker pallet would assign a new owner to that specific region.\n\n- **Partitioning regions**: Using the [`partition`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/dispatchables/fn.partition.html){target=\\_blank} dispatchable, regions may be partitioned into two non-overlapping subregions within the same core. A partition involves specifying a *pivot*, wherein the new region will be defined and available for use.\n\n- **Interlacing regions**: Using the [`interlace`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/pallet/dispatchables/fn.interlace.html){target=\\_blank} dispatchable, interlacing regions allows a core to have alternative-compute strategies. Whereas partitioned regions are mutually exclusive, interlaced regions overlap because multiple tasks may utilize a single core in an alternating manner.\n\nWhen bulk coretime is obtained, block production is not immediately available. It becomes available to produce blocks for a task in the next Coretime cycle. To view the status of the current or next Coretime cycle, see the [Subscan Coretime Dashboard](https://coretime-polkadot.subscan.io/coretime_dashboard){target=\\_blank}.\n\nFor more information regarding these mechanisms, see the coretime page on the Polkadot Wiki: [Introduction to Agile Coretime](https://wiki.polkadot.com/learn/learn-agile-coretime/){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-coretime", "index": 2, "depth": 2, "title": "On Demand Coretime", "anchor": "on-demand-coretime", "start_char": 4640, "end_char": 5126, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "## On Demand Coretime\n\nAt this writing, on-demand coretime is currently deployed on the relay chain and will eventually be deployed to the Coretime chain. On-demand coretime allows parachains (previously known as parathreads) to utilize available cores per block.\n\nThe Coretime chain also handles coretime sales, details of which can be found on the Polkadot Wiki: [Agile Coretime: Coretime Sales](https://wiki.polkadot.com/learn/learn-agile-coretime/#coretime-sales){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-coretime", "index": 3, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5126, "end_char": 5301, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n- Learn about [Agile Coretime](https://wiki.polkadot.com/learn/learn-agile-coretime/#introduction-to-agile-coretime){target=\\_blank} on the Polkadot Wiki"}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 898, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's relay chain is designed to secure parachains and facilitate seamless inter-chain communication. However, resource-intensive—tasks like governance, asset management, and bridging are more efficiently handled by system parachains. These specialized chains offload functionality from the relay chain, leveraging Polkadot's parallel execution model to improve performance and scalability. By distributing key functionalities across system parachains, Polkadot can maximize its relay chain's blockspace for its core purpose of securing and validating parachains.\n\nThis guide will explore how system parachains operate within Polkadot and Kusama, detailing their critical roles in network governance, asset management, and bridging. You'll learn about the currently deployed system parachains, their unique functions, and how they enhance Polkadot's decentralized ecosystem."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 1, "depth": 2, "title": "System Chains", "anchor": "system-chains", "start_char": 898, "end_char": 1878, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "## System Chains\n\nSystem parachains contain core Polkadot protocol features, but in parachains rather than the relay chain. Execution cores for system chains are allocated via network [governance](/polkadot-protocol/onchain-governance/overview/){target=\\_blank} rather than purchasing coretime on a marketplace.\n\nSystem parachains defer to on-chain governance to manage their upgrades and other sensitive actions as they do not have native tokens or governance systems separate from DOT or KSM. It is not uncommon to see a system parachain implemented specifically to manage network governance.\n\n!!!note\n    You may see system parachains called common good parachains in articles and discussions. This nomenclature caused confusion as the network evolved, so system parachains is preferred. \n    \n    For more details on this evolution, review this [parachains forum discussion](https://forum.polkadot.network/t/polkadot-protocol-and-common-good-parachains/866){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 2, "depth": 2, "title": "Existing System Chains", "anchor": "existing-system-chains", "start_char": 1878, "end_char": 2673, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Existing System Chains\n\n```mermaid\n---\ntitle: System Parachains at a Glance\n---\nflowchart TB\n    subgraph POLKADOT[\"Polkadot\"]\n        direction LR\n            PAH[\"Polkadot Asset Hub\"]\n            PCOL[\"Polkadot Collectives\"]\n            PBH[\"Polkadot Bridge Hub\"]\n            PPC[\"Polkadot People Chain\"]\n            PCC[\"Polkadot Coretime Chain\"]\n    end\n\n    subgraph KUSAMA[\"Kusama\"]\n        direction LR\n            KAH[\"Kusama Asset Hub\"]\n            KBH[\"Kusama Bridge Hub\"]\n            KPC[\"Kusama People Chain\"]\n            KCC[\"Kusama Coretime Chain\"]\n            E[\"Encointer\"]\n        end\n```\n\nAll system parachains are on both Polkadot and Kusama with the following exceptions:\n\n- **[Collectives](#collectives)**: Only on Polkadot\n- **[Encointer](#encointer)**: Only on Kusama"}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 3, "depth": 3, "title": "Asset Hub", "anchor": "asset-hub", "start_char": 2673, "end_char": 3972, "estimated_token_count": 305, "token_estimator": "heuristic-v1", "text": "### Asset Hub\n\nThe [Asset Hub](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/cumulus#asset-hub-){target=\\_blank} is an asset portal for the entire network. It helps asset creators, such as reserve-backed stablecoin issuers, track the total issuance of an asset in the network, including amounts transferred to other parachains. It also serves as the hub where asset creators can perform on-chain operations, such as minting and burning, to manage their assets effectively.\n\nThis asset management logic is encoded directly in the runtime of the chain rather than in smart contracts. The efficiency of executing logic in a parachain allows for fees and deposits that are about 1/10th of what is required on the relay chain. These low fees mean that the Asset Hub is well suited for handling the frequent transactions required when managing balances, transfers, and on-chain assets.\n\nThe Asset Hub also supports non-fungible assets (NFTs) via the [Uniques pallet](https://polkadot.js.org/docs/substrate/extrinsics#uniques){target=\\_blank} and [NFTs pallet](https://polkadot.js.org/docs/substrate/extrinsics#nfts){target=\\_blank}. For more information about NFTs, see the Polkadot Wiki section on [NFT Pallets](https://wiki.polkadot.com/learn/learn-nft-pallets/){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 4, "depth": 3, "title": "Collectives", "anchor": "collectives", "start_char": 3972, "end_char": 5041, "estimated_token_count": 234, "token_estimator": "heuristic-v1", "text": "### Collectives\n\nThe Polkadot Collectives parachain was added in [Referendum 81](https://polkadot-old.polkassembly.io/referendum/81){target=\\_blank} and exists on Polkadot but not on Kusama. The Collectives chain hosts on-chain collectives that serve the Polkadot network, including the following:\n\n- [**Polkadot Alliance**](https://polkadot-old.polkassembly.io/referendum/94){target=\\_blank}: Provides a set of ethics and standards for the community to follow. Includes an on-chain means to call out bad actors.\n- [**Polkadot Technical Fellowship**](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank}: A rules-based social organization to support and incentivize highly-skilled developers to contribute to the technical stability, security, and progress of the network.\n\nThese on-chain collectives will play essential roles in the future of network stewardship and decentralized governance. Networks can use a bridge hub to help them act as collectives and express their legislative voices as single opinions within other networks."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 5, "depth": 3, "title": "Bridge Hub", "anchor": "bridge-hub", "start_char": 5041, "end_char": 5822, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "### Bridge Hub\n\nBefore parachains, the only way to design a bridge was to put the logic onto the relay chain. Since both networks now support parachains and the isolation they provide, each network can have a parachain dedicated to bridges. \n\nThe Bridge Hub system parachain operates on the relay chain, and is responsible for facilitating bridges to the wider Web3 space. It contains the required bridge [pallets](/polkadot-protocol/glossary/#pallet){target=\\_blank} in its runtime, which enable trustless bridging with other blockchain networks like Polkadot, Kusama, and Ethereum. The Bridge Hub uses the native token of the relay chain.\n\nSee the [Bridge Hub](/polkadot-protocol/architecture/system-chains/bridge-hub/){target=\\_blank} documentation for additional information."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 6, "depth": 3, "title": "People Chain", "anchor": "people-chain", "start_char": 5822, "end_char": 6013, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### People Chain\n\nThe People Chain provides a naming system that allows users to manage and verify their account [identity](https://wiki.polkadot.com/learn/learn-identity/){target=\\_blank}."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 7, "depth": 3, "title": "Coretime Chain", "anchor": "coretime-chain", "start_char": 6013, "end_char": 6627, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "### Coretime Chain\n\nThe Coretime system chain lets users buy coretime to access Polkadot's computation. [Coretime marketplaces](https://wiki.polkadot.com/learn/learn-guides-coretime-marketplaces/){target=\\_blank} run on top of the Coretime chain. Kusama does not use the Collectives system chain. Instead, Kusama relies on the Encointer system chain, which provides Sybil resistance as a service to the entire Kusama ecosystem.\n\nVisit [Introduction to Agile Coretime](https://wiki.polkadot.com/learn/learn-agile-coretime/#introduction-to-agile-coretime){target=\\_blank} in the Polkadot Wiki for more information."}
{"page_id": "polkadot-protocol-architecture-system-chains-overview", "index": 8, "depth": 3, "title": "Encointer", "anchor": "encointer", "start_char": 6627, "end_char": 7782, "estimated_token_count": 260, "token_estimator": "heuristic-v1", "text": "### Encointer\n\n[Encointer](https://encointer.org/encointer-for-web3/){target=\\_blank} is a blockchain platform for self-sovereign ID and a global [universal basic income (UBI)](https://book.encointer.org/economics-ubi.html){target=\\_blank}. The Encointer protocol uses a novel Proof of Personhood (PoP) system to create unique identities and resist Sybil attacks. PoP is based on the notion that a person can only be in one place at any given time. Encointer offers a framework that allows for any group of real people to create, distribute, and use their own digital community tokens.\n\nParticipants are requested to attend physical key-signing ceremonies with small groups of random people at randomized locations. These local meetings are part of one global signing ceremony occurring at the same time. Participants use the Encointer wallet app to participate in these ceremonies and manage local community currencies. \n\nTo learn more about Encointer, see the official [Encointer book](https://book.encointer.org/introduction.html){target=\\_blank} or watch an [Encointer ceremony](https://www.youtube.com/watch?v=tcgpCCYBqko){target=\\_blank} in action."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 504, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPeople chain is a specialized parachain within the Polkadot ecosystem dedicated to secure, decentralized identity management. \n\nThis solution empowers users to create, control, and verify their digital identities without reliance on centralized authorities. By prioritizing user sovereignty and data privacy, People chain establishes a foundation for trusted interactions throughout the Polkadot ecosystem while returning control of personal information to individuals."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 1, "depth": 2, "title": "Identity Management System", "anchor": "identity-management-system", "start_char": 504, "end_char": 953, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Identity Management System\n\nPeople chain provides a comprehensive identity framework allowing users to:\n\n- Establish verifiable on-chain identities.\n- Control disclosure of personal information.\n- Receive verification from trusted registrars.\n- Link multiple accounts under a unified identity.\n\nUsers must reserve funds in a bond to store their information on chain. These funds are locked, not spent, and returned when the identity is cleared."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 2, "depth": 3, "title": "Sub-Identities", "anchor": "sub-identities", "start_char": 953, "end_char": 1224, "estimated_token_count": 52, "token_estimator": "heuristic-v1", "text": "### Sub-Identities\n\nThe platform supports hierarchical identity structures through sub-accounts:\n\n- Primary accounts can establish up to 100 linked sub-accounts.\n- Each sub-account maintains its own distinct identity.\n- All sub-accounts require a separate bond deposit."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 3, "depth": 2, "title": "Verification Process", "anchor": "verification-process", "start_char": 1224, "end_char": 1249, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Verification Process"}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 4, "depth": 3, "title": "Judgment Requests", "anchor": "judgment-requests", "start_char": 1249, "end_char": 1598, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "### Judgment Requests\n\nAfter establishing an on-chain identity, users can request verification from [registrars](#registrars):\n\n1. Users specify the maximum fee they're willing to pay for judgment.\n2. Only registrars whose fees fall below this threshold can provide verification.\n3. Registrars assess the provided information and issue a judgment."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 5, "depth": 3, "title": "Judgment Classifications", "anchor": "judgment-classifications", "start_char": 1598, "end_char": 2385, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "### Judgment Classifications\n\nRegistrars can assign the following confidence levels to identity information:\n\n- **Unknown**: Default status; no judgment rendered yet.\n- **Reasonable**: Data appears valid but without formal verification (standard for most verified identities).\n- **Known good**: Information certified correct through formal verification (requires documentation; limited to registrars).\n- **Out of date**: Previously verified information that requires updating.\n- **Low quality**: Imprecise information requiring correction.\n- **Erroneous**: Incorrect information, potentially indicating fraudulent intent.\n\nA temporary \"Fee Paid\" status indicates judgment in progress. Both \"Fee Paid\" and \"Erroneous\" statuses lock identity information from modification until resolved."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 6, "depth": 3, "title": "Registrars", "anchor": "registrars", "start_char": 2385, "end_char": 3680, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "### Registrars\n\nRegistrars serve as trusted verification authorities within the People chain ecosystem. These entities validate user identities and provide attestations that build trust in the network.\n\n- Registrars set specific fees for their verification services.\n- They can specialize in verifying particular identity fields.\n- Verification costs vary based on complexity and thoroughness.\n\nWhen requesting verification, users specify their maximum acceptable fee. Only registrars whose fees fall below this threshold can provide judgment. Upon completing the verification process, the user pays the registrar's fee, and the registrar issues an appropriate confidence level classification based on their assessment.\n\nMultiple registrars operate across the Polkadot and People chain ecosystems, each with unique specializations and fee structures. To request verification:\n\n1. Research available registrars and their verification requirements.\n2. Contact your chosen registrar directly through their specified channels.\n3. Submit required documentation according to their verification process.\n4. Pay the associated verification fee.\n\nYou must contact specific registrars individually to request judgment. Each registrar maintains its own verification procedures and communication channels."}
{"page_id": "polkadot-protocol-architecture-system-chains-people", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3680, "end_char": 4750, "estimated_token_count": 257, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Polkadot.js Guides about Identity__\n\n    ---\n\n    Step-by-step instructions for managing identities through the Polkadot.js interface, with practical examples and visual guides.\n\n    [:octicons-arrow-right-24: Reference](https://wiki.polkadot.com/learn/learn-guides-identity/)\n\n-   <span class=\"badge external\">External</span> __How to Set and Clear an Identity__\n\n    ---\n\n    Practical walkthrough covering identity setup and removal process on People chain.\n\n    [:octicons-arrow-right-24: Reference](https://support.polkadot.network/support/solutions/articles/65000181981-how-to-set-and-clear-an-identity)\n\n-   <span class=\"badge external\">External</span> __People Chain Runtime Implementation__\n\n    ---\n\n    Source code for the People chain runtime, detailing the technical architecture of decentralized identity management.\n\n    [:octicons-arrow-right-24: Reference](https://github.com/polkadot-fellows/runtimes/tree/main/system-parachains/people)\n\n</div>"}
{"page_id": "polkadot-protocol-glossary", "index": 0, "depth": 2, "title": "Authority", "anchor": "authority", "start_char": 416, "end_char": 897, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Authority\n\nThe role in a blockchain that can participate in consensus mechanisms. \n\n- **[GRANDPA](#grandpa)**: The authorities vote on chains they consider final.\n- **[Blind Assignment of Blockchain Extension](#blind-assignment-of-blockchain-extension-babe) (BABE)**: The authorities are also [block authors](#block-author).\n\nAuthority sets can be used as a basis for consensus mechanisms such as the [Nominated Proof of Stake (NPoS)](#nominated-proof-of-stake-npos) protocol."}
{"page_id": "polkadot-protocol-glossary", "index": 1, "depth": 2, "title": "Authority Round (Aura)", "anchor": "authority-round-aura", "start_char": 897, "end_char": 1416, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Authority Round (Aura)\n\nA deterministic [consensus](#consensus) protocol where block production is limited to a rotating list of [authorities](#authority) that take turns creating blocks. In authority round (Aura) consensus, most online authorities are assumed to be honest. It is often used in combination with [GRANDPA](#grandpa) as a [hybrid consensus](#hybrid-consensus) protocol.\n\nLearn more by reading the official [Aura consensus algorithm](https://openethereum.github.io/Aura){target=\\_blank} wiki article."}
{"page_id": "polkadot-protocol-glossary", "index": 2, "depth": 2, "title": "Blind Assignment of Blockchain Extension (BABE)", "anchor": "blind-assignment-of-blockchain-extension-babe", "start_char": 1416, "end_char": 1930, "estimated_token_count": 124, "token_estimator": "heuristic-v1", "text": "## Blind Assignment of Blockchain Extension (BABE)\n\nA [block authoring](#block-author) protocol similar to [Aura](#authority-round-aura), except [authorities](#authority) win [slots](#slot) based on a Verifiable Random Function (VRF) instead of the round-robin selection method. The winning authority can select a chain and submit a new block.\n\nLearn more by reading the official Web3 Foundation [BABE research document](https://research.web3.foundation/Polkadot/protocols/block-production/Babe){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 3, "depth": 2, "title": "Block Author", "anchor": "block-author", "start_char": 1930, "end_char": 2099, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Block Author\n\nThe node responsible for the creation of a block, also called _block producers_. In a Proof of Work (PoW) blockchain, these nodes are called _miners_."}
{"page_id": "polkadot-protocol-glossary", "index": 4, "depth": 2, "title": "Byzantine Fault Tolerance (BFT)", "anchor": "byzantine-fault-tolerance-bft", "start_char": 2099, "end_char": 2527, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Byzantine Fault Tolerance (BFT)\n\nThe ability of a distributed computer network to remain operational if a certain proportion of its nodes or [authorities](#authority) are defective or behaving maliciously. A distributed network is typically considered Byzantine fault tolerant if it can remain functional, with up to one-third of nodes assumed to be defective, offline, actively malicious, and part of a coordinated attack."}
{"page_id": "polkadot-protocol-glossary", "index": 5, "depth": 3, "title": "Byzantine Failure", "anchor": "byzantine-failure", "start_char": 2527, "end_char": 2667, "estimated_token_count": 26, "token_estimator": "heuristic-v1", "text": "### Byzantine Failure\n\nThe loss of a network service due to node failures that exceed the proportion of nodes required to reach consensus."}
{"page_id": "polkadot-protocol-glossary", "index": 6, "depth": 3, "title": "Practical Byzantine Fault Tolerance (pBFT)", "anchor": "practical-byzantine-fault-tolerance-pbft", "start_char": 2667, "end_char": 3007, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "### Practical Byzantine Fault Tolerance (pBFT)\n\nAn early approach to Byzantine fault tolerance (BFT), practical Byzantine fault tolerance (pBFT) systems tolerate Byzantine behavior from up to one-third of participants.\n\nThe communication overhead for such systems is `O(n²)`, where `n` is the number of nodes (participants) in the system."}
{"page_id": "polkadot-protocol-glossary", "index": 7, "depth": 3, "title": "Preimage", "anchor": "preimage", "start_char": 3007, "end_char": 3284, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### Preimage\n\nA preimage is the data that is input into a hash function to calculate a hash. Since a hash function is a [one-way function](https://en.wikipedia.org/wiki/One-way_function){target=\\_blank}, the output, the hash, cannot be used to reveal the input, the preimage."}
{"page_id": "polkadot-protocol-glossary", "index": 8, "depth": 2, "title": "Call", "anchor": "call", "start_char": 3284, "end_char": 3561, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Call\n\nIn the context of pallets containing functions to be dispatched to the runtime, `Call` is an enumeration data type that describes the functions that can be dispatched with one variant per pallet. A `Call` represents a [dispatch](#dispatchable) data structure object."}
{"page_id": "polkadot-protocol-glossary", "index": 9, "depth": 2, "title": "Chain Specification", "anchor": "chain-specification", "start_char": 3561, "end_char": 4014, "estimated_token_count": 84, "token_estimator": "heuristic-v1", "text": "## Chain Specification \n\nA chain specification file defines the properties required to run a node in an active or new Polkadot SDK-built network. It often contains the initial genesis runtime code, network properties (such as the network's name), the initial state for some pallets, and the boot node list. The chain specification file makes it easy to use a single Polkadot SDK codebase as the foundation for multiple independently configured chains."}
{"page_id": "polkadot-protocol-glossary", "index": 10, "depth": 2, "title": "Collator", "anchor": "collator", "start_char": 4014, "end_char": 4353, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Collator\n\nAn [author](#block-author) of a [parachain](#parachain) network.\nThey aren't [authorities](#authority) in themselves, as they require a [relay chain](#relay-chain) to coordinate [consensus](#consensus).\n\nMore details are found on the [Polkadot Collator Wiki](https://wiki.polkadot.com/learn/learn-collator/){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 11, "depth": 2, "title": "Collective", "anchor": "collective", "start_char": 4353, "end_char": 4593, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Collective\n\nMost often used to refer to an instance of the Collective pallet on Polkadot SDK-based networks such as [Kusama](#kusama) or [Polkadot](#polkadot) if the Collective pallet is part of the FRAME-based runtime for the network."}
{"page_id": "polkadot-protocol-glossary", "index": 12, "depth": 2, "title": "Consensus", "anchor": "consensus", "start_char": 4593, "end_char": 4984, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Consensus\n\nConsensus is the process blockchain nodes use to agree on a chain's canonical fork. It is composed of [authorship](#block-author), finality, and [fork-choice rule](#fork-choice-rulestrategy). In the Polkadot ecosystem, these three components are usually separate and the term consensus often refers specifically to authorship.\n\nSee also [hybrid consensus](#hybrid-consensus)."}
{"page_id": "polkadot-protocol-glossary", "index": 13, "depth": 2, "title": "Consensus Algorithm", "anchor": "consensus-algorithm", "start_char": 4984, "end_char": 5546, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Consensus Algorithm\n\nEnsures a set of [actors](#authority)—who don't necessarily trust each other—can reach an agreement about the state as the result of some computation. Most consensus algorithms assume that up to one-third of the actors or nodes can be [Byzantine fault tolerant](#byzantine-fault-tolerance-bft).\n\nConsensus algorithms are generally concerned with ensuring two properties:\n\n- **Safety**: Indicating that all honest nodes eventually agreed on the state of the chain.\n- **Liveness**: Indicating the ability of the chain to keep progressing."}
{"page_id": "polkadot-protocol-glossary", "index": 14, "depth": 2, "title": "Consensus Engine", "anchor": "consensus-engine", "start_char": 5546, "end_char": 5885, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Consensus Engine\n\nThe node subsystem responsible for consensus tasks.\n\nFor detailed information about the consensus strategies of the [Polkadot](#polkadot) network, see the [Polkadot Consensus](/polkadot-protocol/architecture/polkadot-chain/pos-consensus/){target=\\_blank} blog series.\n\nSee also [hybrid consensus](#hybrid-consensus)."}
{"page_id": "polkadot-protocol-glossary", "index": 15, "depth": 2, "title": "Coretime", "anchor": "coretime", "start_char": 5885, "end_char": 6685, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Coretime\n\nThe time allocated for utilizing a core, measured in relay chain blocks. There are two types of coretime: *on-demand* and *bulk*.\n\nOn-demand coretime refers to coretime acquired through bidding in near real-time for the validation of a single parachain block on one of the cores reserved specifically for on-demand orders. They are available as an on-demand coretime pool. Set of cores that are available on-demand. Cores reserved through bulk coretime could also be made available in the on-demand coretime pool, in parts or in entirety.\n\nBulk coretime is a fixed duration of continuous coretime represented by an NFT that can be split, shared, or resold. It is managed by the [Broker pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/index.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 16, "depth": 2, "title": "Development Phrase", "anchor": "development-phrase", "start_char": 6685, "end_char": 7341, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Development Phrase\n\nA [mnemonic phrase](https://en.wikipedia.org/wiki/Mnemonic#For_numerical_sequences_and_mathematical_operations){target=\\_blank} that is intentionally made public.\n\nWell-known development accounts, such as Alice, Bob, Charlie, Dave, Eve, and Ferdie, are generated from the same secret phrase:\n\n```\nbottom drive obey lake curtain smoke basket hold race lonely fit walk\n```\n\nMany tools in the Polkadot SDK ecosystem, such as [`subkey`](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/bin/utils/subkey){target=\\_blank}, allow you to implicitly specify an account using a derivation path such as `//Alice`."}
{"page_id": "polkadot-protocol-glossary", "index": 17, "depth": 2, "title": "Digest", "anchor": "digest", "start_char": 7341, "end_char": 7653, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Digest\n\nAn extensible field of the [block header](#header) that encodes information needed by several actors in a blockchain network, including:\n\n- [Light clients](#light-client) for chain synchronization.\n- Consensus engines for block verification.\n- The runtime itself, in the case of pre-runtime digests."}
{"page_id": "polkadot-protocol-glossary", "index": 18, "depth": 2, "title": "Dispatchable", "anchor": "dispatchable", "start_char": 7653, "end_char": 7951, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "## Dispatchable\n\nFunction objects that act as the entry points in FRAME [pallets](#pallet). Internal or external entities can call them to interact with the blockchain’s state. They are a core aspect of the runtime logic, handling [transactions](#transaction) and other state-changing operations."}
{"page_id": "polkadot-protocol-glossary", "index": 19, "depth": 2, "title": "Events", "anchor": "events", "start_char": 7951, "end_char": 8383, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "## Events\n\nA means of recording that some particular [state](#state) transition happened.\n\nIn the context of [FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities), events are composable data types that each [pallet](#pallet) can individually define. Events in FRAME are implemented as a set of transient storage items inspected immediately after a block has been executed and reset during block initialization."}
{"page_id": "polkadot-protocol-glossary", "index": 20, "depth": 2, "title": "Executor", "anchor": "executor", "start_char": 8383, "end_char": 9019, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## Executor\n\nA means of executing a function call in a given [runtime](#runtime) with a set of dependencies.\nThere are two orchestration engines in Polkadot SDK, _WebAssembly_ and _native_.\n\n- The _native executor_ uses a natively compiled runtime embedded in the node to execute calls. This is a performance optimization available to up-to-date nodes.\n\n- The _WebAssembly executor_ uses a [Wasm](#webassembly-wasm) binary and a Wasm interpreter to execute calls. The binary is guaranteed to be up-to-date regardless of the version of the blockchain node because it is persisted in the [state](#state) of the Polkadot SDK-based chain."}
{"page_id": "polkadot-protocol-glossary", "index": 21, "depth": 2, "title": "Existential Deposit", "anchor": "existential-deposit", "start_char": 9019, "end_char": 9759, "estimated_token_count": 179, "token_estimator": "heuristic-v1", "text": "## Existential Deposit\n\nThe minimum balance an account is allowed to have in the [Balances pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_balances/index.html){target=\\_blank}. Accounts cannot be created with a balance less than the existential deposit amount. \n\nIf an account balance drops below this amount, the Balances pallet uses [a FRAME System API](https://paritytech.github.io/substrate/master/frame_system/pallet/struct.Pallet.html#method.dec_ref){target=\\_blank} to drop its references to that account.\n\nIf the Balances pallet reference to an account is dropped, the account can be [reaped](https://paritytech.github.io/substrate/master/frame_system/pallet/struct.Pallet.html#method.allow_death){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 22, "depth": 2, "title": "Extrinsic", "anchor": "extrinsic", "start_char": 9759, "end_char": 10375, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Extrinsic\n\nA general term for data that originates outside the runtime, is included in a block, and leads to some action. This includes user-initiated transactions and inherent transactions placed into the block by the block builder.\n\nIt is a SCALE-encoded array typically consisting of a version number, signature, and varying data types indicating the resulting runtime function to be called. Extrinsics can take two forms: [inherents](#inherent-transactions) and [transactions](#transaction). \n\nFor more technical details, see the [Polkadot spec](https://spec.polkadot.network/id-extrinsics){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 23, "depth": 2, "title": "Fork Choice Rule/Strategy", "anchor": "fork-choice-rulestrategy", "start_char": 10375, "end_char": 10721, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Fork Choice Rule/Strategy\n\nA fork choice rule or strategy helps determine which chain is valid when reconciling several network forks. A common fork choice rule is the [longest chain](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/struct.LongestChain.html){target=\\_blank}, in which the chain with the most blocks is selected."}
{"page_id": "polkadot-protocol-glossary", "index": 24, "depth": 2, "title": "FRAME (Framework for Runtime Aggregation of Modularized Entities)", "anchor": "frame-framework-for-runtime-aggregation-of-modularized-entities", "start_char": 10721, "end_char": 11167, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## FRAME (Framework for Runtime Aggregation of Modularized Entities)\n\nEnables developers to create blockchain [runtime](#runtime) environments from a modular set of components called [pallets](#pallet). It utilizes a set of procedural macros to construct runtimes.\n\n[Visit the Polkadot SDK docs for more details on FRAME.](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank}"}
{"page_id": "polkadot-protocol-glossary", "index": 25, "depth": 2, "title": "Full Node", "anchor": "full-node", "start_char": 11167, "end_char": 11446, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## Full Node\n\nA node that prunes historical states, keeping only recently finalized block states to reduce storage needs. Full nodes provide current chain state access and allow direct submission and validation of [extrinsics](#extrinsic), maintaining network decentralization."}
{"page_id": "polkadot-protocol-glossary", "index": 26, "depth": 2, "title": "Genesis Configuration", "anchor": "genesis-configuration", "start_char": 11446, "end_char": 11781, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## Genesis Configuration\n\nA mechanism for specifying the initial state of a blockchain. By convention, this initial state or first block is commonly referred to as the genesis state or genesis block. The genesis configuration for Polkadot SDK-based chains is accomplished by way of a [chain specification](#chain-specification) file."}
{"page_id": "polkadot-protocol-glossary", "index": 27, "depth": 2, "title": "GRANDPA", "anchor": "grandpa", "start_char": 11781, "end_char": 12137, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## GRANDPA\n\nA deterministic finality mechanism for blockchains that is implemented in the [Rust](https://www.rust-lang.org/){target=\\_blank} programming language.\n\nThe [formal specification](https://github.com/w3f/consensus/blob/master/pdf/grandpa-old.pdf){target=\\_blank} is maintained by the [Web3 Foundation](https://web3.foundation/){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 28, "depth": 2, "title": "Header", "anchor": "header", "start_char": 12137, "end_char": 12377, "estimated_token_count": 44, "token_estimator": "heuristic-v1", "text": "## Header\n\nA structure that aggregates the information used to summarize a block. Primarily, it consists of cryptographic information used by [light clients](#light-client) to get minimally secure but very efficient chain synchronization."}
{"page_id": "polkadot-protocol-glossary", "index": 29, "depth": 2, "title": "Hybrid Consensus", "anchor": "hybrid-consensus", "start_char": 12377, "end_char": 12791, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Hybrid Consensus\n\nA blockchain consensus protocol that consists of independent or loosely coupled mechanisms for [block production](#block-author) and finality.\n\nHybrid consensus allows the chain to grow as fast as probabilistic consensus protocols, such as [Aura](#authority-round-aura), while maintaining the same level of security as deterministic finality consensus protocols, such as [GRANDPA](#grandpa)."}
{"page_id": "polkadot-protocol-glossary", "index": 30, "depth": 2, "title": "Inherent Transactions", "anchor": "inherent-transactions", "start_char": 12791, "end_char": 13257, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Inherent Transactions\n\nA special type of unsigned transaction, referred to as _inherents_, that enables a block authoring node to insert information that doesn't require validation directly into a block.\n\nOnly the block-authoring node that calls the inherent transaction function can insert data into its block. In general, validators assume the data inserted using an inherent transaction is valid and reasonable even if it can't be deterministically verified."}
{"page_id": "polkadot-protocol-glossary", "index": 31, "depth": 2, "title": "JSON-RPC", "anchor": "json-rpc", "start_char": 13257, "end_char": 13598, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## JSON-RPC\n\nA stateless, lightweight remote procedure call protocol encoded in JavaScript Object Notation (JSON). JSON-RPC provides a standard way to call functions on a remote system by using JSON.\n\nFor Polkadot SDK, this protocol is implemented through the [Parity JSON-RPC](https://github.com/paritytech/jsonrpc){target=\\_blank} crate."}
{"page_id": "polkadot-protocol-glossary", "index": 32, "depth": 2, "title": "Keystore", "anchor": "keystore", "start_char": 13598, "end_char": 13683, "estimated_token_count": 16, "token_estimator": "heuristic-v1", "text": "## Keystore\n\nA subsystem for managing keys for the purpose of producing new blocks."}
{"page_id": "polkadot-protocol-glossary", "index": 33, "depth": 2, "title": "Kusama", "anchor": "kusama", "start_char": 13683, "end_char": 14377, "estimated_token_count": 174, "token_estimator": "heuristic-v1", "text": "## Kusama\n\n[Kusama](https://kusama.network/){target=\\_blank} is a Polkadot SDK-based blockchain that implements a design similar to the [Polkadot](#polkadot) network.\n\nKusama is a [canary](https://en.wiktionary.org/wiki/canary_in_a_coal_mine){target=\\_blank} network and is referred to as [Polkadot's \"wild cousin.\"](https://wiki.polkadot.com/learn/learn-comparisons-kusama/){target=\\_blank}.\n\nAs a canary network, Kusama is expected to be more stable than a test network like [Westend](#westend) but less stable than a production network like [Polkadot](#polkadot). Kusama is controlled by its network participants and is intended to be stable enough to encourage meaningful experimentation."}
{"page_id": "polkadot-protocol-glossary", "index": 34, "depth": 2, "title": "libp2p", "anchor": "libp2p", "start_char": 14377, "end_char": 14653, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "## libp2p\n\nA peer-to-peer networking stack that allows the use of many transport mechanisms, including WebSockets (usable in a web browser).\n\nPolkadot SDK uses the [Rust implementation](https://github.com/libp2p/rust-libp2p){target=\\_blank} of the `libp2p` networking stack."}
{"page_id": "polkadot-protocol-glossary", "index": 35, "depth": 2, "title": "Light Client", "anchor": "light-client", "start_char": 14653, "end_char": 14991, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Light Client\n\nA type of blockchain node that doesn't store the [chain state](#state) or produce blocks.\n\nA light client can verify cryptographic primitives and provides a [remote procedure call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call){target=\\_blank} server, enabling blockchain users to interact with the network."}
{"page_id": "polkadot-protocol-glossary", "index": 36, "depth": 2, "title": "Metadata", "anchor": "metadata", "start_char": 14991, "end_char": 15187, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Metadata\n\nData that provides information about one or more aspects of a system.\nThe metadata that exposes information about a Polkadot SDK blockchain enables you to interact with that system."}
{"page_id": "polkadot-protocol-glossary", "index": 37, "depth": 2, "title": "Nominated Proof of Stake (NPoS)", "anchor": "nominated-proof-of-stake-npos", "start_char": 15187, "end_char": 15414, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Nominated Proof of Stake (NPoS)\n\nA method for determining [validators](#validator) or _[authorities](#authority)_ based on a willingness to commit their stake to the proper functioning of one or more block-producing nodes."}
{"page_id": "polkadot-protocol-glossary", "index": 38, "depth": 2, "title": "Oracle", "anchor": "oracle", "start_char": 15414, "end_char": 15651, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "## Oracle\n\nAn entity that connects a blockchain to a non-blockchain data source. Oracles enable the blockchain to access and act upon information from existing data sources and incorporate data from non-blockchain systems and services."}
{"page_id": "polkadot-protocol-glossary", "index": 39, "depth": 2, "title": "Origin", "anchor": "origin", "start_char": 15651, "end_char": 16141, "estimated_token_count": 126, "token_estimator": "heuristic-v1", "text": "## Origin\n\nA [FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities) primitive that identifies the source of a [dispatched](#dispatchable) function call into the [runtime](#runtime). The FRAME System pallet defines three built-in [origins](#origin). As a [pallet](#pallet) developer, you can also define custom origins, such as those defined by the [Collective pallet](https://paritytech.github.io/substrate/master/pallet_collective/enum.RawOrigin.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 40, "depth": 2, "title": "Pallet", "anchor": "pallet", "start_char": 16141, "end_char": 16432, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Pallet\n\nA module that can be used to extend the capabilities of a [FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities)-based [runtime](#runtime).\nPallets bundle domain-specific logic with runtime primitives like [events](#events) and [storage items](#storage-item)."}
{"page_id": "polkadot-protocol-glossary", "index": 41, "depth": 2, "title": "Parachain", "anchor": "parachain", "start_char": 16432, "end_char": 16688, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Parachain\n\nA parachain is a blockchain that derives shared infrastructure and security from a _[relay chain](#relay-chain)_.\nYou can learn more about parachains on the [Polkadot Wiki](https://wiki.polkadot.com/learn/learn-parachains/){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 42, "depth": 2, "title": "Paseo", "anchor": "paseo", "start_char": 16688, "end_char": 17142, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "## Paseo\n\nPaseo TestNet provisions testing on Polkadot's \"production\" runtime, which means less chance of feature or code mismatch when developing parachain apps. Specifically, after the [Polkadot Technical fellowship](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank} proposes a runtime upgrade for Polkadot, this TestNet is updated, giving a period where the TestNet will be ahead of Polkadot to allow for testing."}
{"page_id": "polkadot-protocol-glossary", "index": 43, "depth": 2, "title": "Polkadot", "anchor": "polkadot", "start_char": 17142, "end_char": 17443, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Polkadot\n\nThe [Polkadot network](https://polkadot.com/){target=\\_blank} is a blockchain that serves as the central hub of a heterogeneous blockchain network. It serves the role of the [relay chain](#relay-chain) and provides shared infrastructure and security to support [parachains](#parachain)."}
{"page_id": "polkadot-protocol-glossary", "index": 44, "depth": 2, "title": "Polkadot Cloud", "anchor": "polkadot-cloud", "start_char": 17443, "end_char": 18081, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Polkadot Cloud\n\nPolkadot Cloud is a platform for deploying resilient, customizable and scalable Web3 applications through Polkadot's functionality. It encompasses the wider Polkadot network infrastructure and security layer where parachains operate. The platform enables users to launch Ethereum-compatible chains, build specialized blockchains, and flexibly manage computing resources through on-demand or bulk coretime purchases. Initially launched with basic parachain functionality, Polkadot Cloud has evolved to offer enhanced flexibility with features like coretime, elastic scaling, and async backing for improved performance."}
{"page_id": "polkadot-protocol-glossary", "index": 45, "depth": 2, "title": "Polkadot Hub", "anchor": "polkadot-hub", "start_char": 18081, "end_char": 18489, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Polkadot Hub\n\nPolkadot Hub is a Layer 1 platform that serves as the primary entry point to the Polkadot ecosystem, providing essential functionality without requiring parachain deployment. It offers core services including smart contracts, identity management, staking, governance, and interoperability with other ecosystems, making it simple and fast for both builders and users to get started in Web3."}
{"page_id": "polkadot-protocol-glossary", "index": 46, "depth": 2, "title": "PolkaVM", "anchor": "polkavm", "start_char": 18489, "end_char": 18772, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## PolkaVM\n\nPolkaVM is a custom virtual machine optimized for performance, leveraging a RISC-V-based architecture to support Solidity and any language that compiles to RISC-V. It is specifically designed for the Polkadot ecosystem, enabling smart contract deployment and execution."}
{"page_id": "polkadot-protocol-glossary", "index": 47, "depth": 2, "title": "Relay Chain", "anchor": "relay-chain", "start_char": 18772, "end_char": 19088, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Relay Chain\n\nRelay chains are blockchains that provide shared infrastructure and security to the [parachains](#parachain) in the network. In addition to providing [consensus](#consensus) capabilities, relay chains allow parachains to communicate and exchange digital assets without needing to trust one another."}
{"page_id": "polkadot-protocol-glossary", "index": 48, "depth": 2, "title": "Rococo", "anchor": "rococo", "start_char": 19088, "end_char": 19340, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Rococo\n\nA [parachain](#parachain) test network for the Polkadot network. The [Rococo](#rococo) network is a Polkadot SDK-based blockchain with an October 14, 2024 deprecation date. Development teams are encouraged to use the Paseo TestNet instead."}
{"page_id": "polkadot-protocol-glossary", "index": 49, "depth": 2, "title": "Runtime", "anchor": "runtime", "start_char": 19340, "end_char": 19677, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Runtime\n\nThe runtime represents the [state transition function](#state-transition-function-stf) for a blockchain. In Polkadot SDK, the runtime is stored as a [Wasm](#webassembly-wasm) binary in the chain state. The Runtime is stored under a unique state key and can be modified during the execution of the state transition function."}
{"page_id": "polkadot-protocol-glossary", "index": 50, "depth": 2, "title": "Slot", "anchor": "slot", "start_char": 19677, "end_char": 19957, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Slot\n\nA fixed, equal interval of time used by consensus engines such as [Aura](#authority-round-aura) and [BABE](#blind-assignment-of-blockchain-extension-babe). In each slot, a subset of [authorities](#authority) is permitted, or obliged, to [author](#block-author) a block."}
{"page_id": "polkadot-protocol-glossary", "index": 51, "depth": 2, "title": "Sovereign Account", "anchor": "sovereign-account", "start_char": 19957, "end_char": 20459, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Sovereign Account\n\nThe unique account identifier for each chain in the relay chain ecosystem. It is often used in cross-consensus (XCM) interactions to sign XCM messages sent to the relay chain or other chains in the ecosystem.\n\nThe sovereign account for each chain is a root-level account that can only be accessed using the Sudo pallet or through governance. The account identifier is calculated by concatenating the Blake2 hash of a specific text string and the registered parachain identifier."}
{"page_id": "polkadot-protocol-glossary", "index": 52, "depth": 2, "title": "SS58 Address Format", "anchor": "ss58-address-format", "start_char": 20459, "end_char": 21012, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## SS58 Address Format\n\nA public key address based on the Bitcoin [`Base-58-check`](https://en.bitcoin.it/wiki/Base58Check_encoding){target=\\_blank} encoding. Each Polkadot SDK SS58 address uses a `base-58` encoded value to identify a specific account on a specific Polkadot SDK-based chain\n\nThe [canonical `ss58-registry`](https://github.com/paritytech/ss58-registry){target=\\_blank} provides additional details about the address format used by different Polkadot SDK-based chains, including the network prefix and website used for different networks"}
{"page_id": "polkadot-protocol-glossary", "index": 53, "depth": 2, "title": "State Transition Function (STF)", "anchor": "state-transition-function-stf", "start_char": 21012, "end_char": 21241, "estimated_token_count": 46, "token_estimator": "heuristic-v1", "text": "## State Transition Function (STF)\n\nThe logic of a blockchain that determines how the state changes when a block is processed. In Polkadot SDK, the state transition function is effectively equivalent to the [runtime](#runtime)."}
{"page_id": "polkadot-protocol-glossary", "index": 54, "depth": 2, "title": "Storage Item", "anchor": "storage-item", "start_char": 21241, "end_char": 21604, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Storage Item\n\n[FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities) primitives that provide type-safe data persistence capabilities to the [runtime](#runtime).\nLearn more in the [storage items](https://paritytech.github.io/polkadot-sdk/master/frame_support/storage/types/index.html){target=\\_blank} reference document in the Polkadot SDK."}
{"page_id": "polkadot-protocol-glossary", "index": 55, "depth": 2, "title": "Substrate", "anchor": "substrate", "start_char": 21604, "end_char": 21886, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Substrate\n\nA flexible framework for building modular, efficient, and upgradeable blockchains. Substrate is written in the [Rust](https://www.rust-lang.org/){target=\\_blank} programming language and is maintained by [Parity Technologies](https://www.parity.io/){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 56, "depth": 2, "title": "Transaction", "anchor": "transaction", "start_char": 21886, "end_char": 22177, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Transaction\n\nAn [extrinsic](#extrinsic) that includes a signature that can be used to verify the account authorizing it inherently or via [signed extensions](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/signed_extensions/index.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-glossary", "index": 57, "depth": 2, "title": "Transaction Era", "anchor": "transaction-era", "start_char": 22177, "end_char": 22456, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Transaction Era\n\nA definable period expressed as a range of block numbers during which a transaction can be included in a block.\nTransaction eras are used to protect against transaction replay attacks if an account is reaped and its replay-protecting nonce is reset to zero."}
{"page_id": "polkadot-protocol-glossary", "index": 58, "depth": 2, "title": "Trie (Patricia Merkle Tree)", "anchor": "trie-patricia-merkle-tree", "start_char": 22456, "end_char": 23202, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Trie (Patricia Merkle Tree)\n\nA data structure used to represent sets of key-value pairs and enables the items in the data set to be stored and retrieved using a cryptographic hash. Because incremental changes to the data set result in a new hash, retrieving data is efficient even if the data set is very large. With this data structure, you can also prove whether the data set includes any particular key-value pair without access to the entire data set.\n\nIn Polkadot SDK-based blockchains, state is stored in a trie data structure that supports the efficient creation of incremental digests. This trie is exposed to the [runtime](#runtime) as [a simple key/value map](#storage-item) where both keys and values can be arbitrary byte arrays."}
{"page_id": "polkadot-protocol-glossary", "index": 59, "depth": 2, "title": "Validator", "anchor": "validator", "start_char": 23202, "end_char": 23405, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Validator\n\nA validator is a node that participates in the consensus mechanism of the network. Its roles include block production, transaction validation, network integrity, and security maintenance."}
{"page_id": "polkadot-protocol-glossary", "index": 60, "depth": 2, "title": "WebAssembly (Wasm)", "anchor": "webassembly-wasm", "start_char": 23405, "end_char": 23868, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## WebAssembly (Wasm)\n\nAn execution architecture that allows for the efficient, platform-neutral expression of\ndeterministic, machine-executable logic.\n\n[Wasm](https://webassembly.org/){target=\\_blank} can be compiled from many languages, including\nthe [Rust](https://www.rust-lang.org/){target=\\_blank} programming language. Polkadot SDK-based chains use a Wasm binary to provide portable [runtimes](#runtime) that can be included as part of the chain's state."}
{"page_id": "polkadot-protocol-glossary", "index": 61, "depth": 2, "title": "Weight", "anchor": "weight", "start_char": 23868, "end_char": 24594, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## Weight\n\nA convention used in Polkadot SDK-based blockchains to measure and manage the time it takes to validate a block.\nPolkadot SDK defines one unit of weight as one picosecond of execution time on reference hardware.\n\nThe maximum block weight should be equivalent to one-third of the target block time with an allocation of one-third each for:\n\n- Block construction\n- Network propagation\n- Import and verification\n\nBy defining weights, you can trade-off the number of transactions per second and the hardware required to maintain the target block time appropriate for your use case. Weights are defined in the runtime, meaning you can tune them using runtime updates to keep up with hardware and software improvements."}
{"page_id": "polkadot-protocol-glossary", "index": 62, "depth": 2, "title": "Westend", "anchor": "westend", "start_char": 24594, "end_char": 24737, "estimated_token_count": 32, "token_estimator": "heuristic-v1", "text": "## Westend\n\nWestend is a Parity-maintained, Polkadot SDK-based blockchain that serves as a test network for the [Polkadot](#polkadot) network."}
{"page_id": "polkadot-protocol-onchain-governance-origins-tracks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 833, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's OpenGov system empowers decentralized decision-making and active community participation by tailoring the governance process to the impact of proposed changes. Through a system of origins and tracks, OpenGov ensures that every referendum receives the appropriate scrutiny, balancing security, inclusivity, and efficiency.\n\nThis guide will help you understand the role of origins in classifying proposals by privilege and priority. You will learn how tracks guide proposals through tailored stages like voting, confirmation, and enactment and how to select the correct origin for your referendum to align with community expectations and network governance.\n\nOrigins and tracks are vital in streamlining the governance workflow and maintaining Polkadot's resilience and adaptability."}
{"page_id": "polkadot-protocol-onchain-governance-origins-tracks", "index": 1, "depth": 2, "title": "Origins", "anchor": "origins", "start_char": 833, "end_char": 1886, "estimated_token_count": 200, "token_estimator": "heuristic-v1", "text": "## Origins\n\nOrigins are the foundation of Polkadot's OpenGov governance system. They categorize proposals by privilege and define their decision-making rules. Each origin corresponds to a specific level of importance and risk, guiding how referendums progress through the governance process.\n\n- High-privilege origins like Root Origin govern critical network changes, such as core software upgrades.\n- Lower-privilege origins like Small Spender handle minor requests, such as community project funding under 10,000 DOT.\n\nProposers select an origin based on the nature of their referendum. Origins determine parameters like approval thresholds, required deposits, and timeframes for voting and confirmation. Each origin is paired with a track, which acts as a roadmap for the proposal's lifecycle, including preparation, voting, and enactment.\n\nFor a detailed list of origins and their associated parameters, see the [Polkadot OpenGov Origins](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/){target=\\_blank} entry in the Polkadot Wiki."}
{"page_id": "polkadot-protocol-onchain-governance-origins-tracks", "index": 2, "depth": 2, "title": "Tracks", "anchor": "tracks", "start_char": 1886, "end_char": 2836, "estimated_token_count": 175, "token_estimator": "heuristic-v1", "text": "## Tracks\n\nTracks define a referendum's journey from submission to enactment, tailoring governance parameters to the impact of proposed changes. Each track operates independently and includes several key stages:\n\n- **Preparation**: Time for community discussion before voting begins.\n- **Voting**: Period for token holders to cast their votes.\n- **Decision**: Finalization of results and determination of the proposal's outcome.\n- **Confirmation**: Period to verify sustained community support before enactment.\n- **Enactment**: Final waiting period before the proposal takes effect.\n\nTracks customize these stages with parameters like decision deposit requirements, voting durations, and approval thresholds, ensuring proposals from each origin receive the required scrutiny and process. For example, a runtime upgrade in the Root Origin track will have longer timeframes and stricter thresholds than a treasury request in the Small Spender track."}
{"page_id": "polkadot-protocol-onchain-governance-origins-tracks", "index": 3, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 2836, "end_char": 3333, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- For a list of origins and tracks for Polkadot and Kusama, including associated parameters, see the [Origins and Tracks Info](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#origins-and-tracks-info){target=\\_blank} entry in the Polkadot Wiki.\n\n- For a deeper dive into the approval and support system, see the [Approval and Support](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#approval-and-support){target=\\_blank} entry of the Polkadot Wiki."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 852, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot’s governance system exemplifies decentralized decision-making, empowering its community of stakeholders to shape the network’s future through active participation. The latest evolution, OpenGov, builds on Polkadot’s foundation by providing a more inclusive and efficient governance model.\n\nThis guide will explain the principles and structure of OpenGov and walk you through its key components, such as Origins, Tracks, and Delegation. You will learn about improvements over earlier governance systems, including streamlined voting processes and enhanced stakeholder participation.\n\nWith OpenGov, Polkadot achieves a flexible, scalable, and democratic governance framework that allows multiple proposals to proceed simultaneously, ensuring the network evolves in alignment with its community's needs."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 1, "depth": 2, "title": "Governance Evolution", "anchor": "governance-evolution", "start_char": 852, "end_char": 1816, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Governance Evolution\n\nPolkadot’s governance journey began with [Governance V1](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#governance-summary){target=\\_blank}, a system that proved effective in managing treasury funds and protocol upgrades. However, it faced limitations, such as:\n\n- Slow voting cycles, causing delays in decision-making.\n- Inflexibility in handling multiple referendums, restricting scalability.\n\nTo address these challenges, Polkadot introduced OpenGov, a governance model designed for greater inclusivity, efficiency, and scalability. OpenGov replaces the centralized structures of Governance V1, such as the Council and Technical Committee, with a fully decentralized and dynamic framework.\n\nFor a full comparison of the historic and current governance models, visit the [Gov1 vs. Polkadot OpenGov](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#gov1-vs-polkadot-opengov){target=\\_blank} section of the Polkadot Wiki."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 2, "depth": 2, "title": "OpenGov Key Features", "anchor": "opengov-key-features", "start_char": 1816, "end_char": 2574, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "## OpenGov Key Features\n\nOpenGov transforms Polkadot’s governance into a decentralized, stakeholder-driven model, eliminating centralized decision-making bodies like the Council. Key enhancements include:\n\n- **Decentralization**: Shifts all decision-making power to the public, ensuring a more democratic process.\n- **Enhanced delegation**: Allows users to delegate their votes to trusted experts across specific governance tracks.\n- **Simultaneous referendums**: Multiple proposals can progress at once, enabling faster decision-making.\n- **Polkadot Technical Fellowship**: A broad, community-driven group replacing the centralized Technical Committee.\n\nThis new system ensures Polkadot governance remains agile and inclusive, even as the ecosystem grows."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 3, "depth": 2, "title": "Origins and Tracks", "anchor": "origins-and-tracks", "start_char": 2574, "end_char": 3654, "estimated_token_count": 248, "token_estimator": "heuristic-v1", "text": "## Origins and Tracks\n\nIn OpenGov, origins and tracks are central to managing proposals and votes.\n\n- **Origin**: Determines the authority level of a proposal (e.g., Treasury, Root) which decides the track of all referendums from that origin.\n- **Track**: Define the procedural flow of a proposal, such as voting duration, approval thresholds, and enactment timelines.\n\nDevelopers must be aware that referendums from different origins and tracks will take varying amounts of time to reach approval and enactment. The [Polkadot Technical Fellowship](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank} has the option to shorten this timeline by whitelisting a proposal and allowing it to be enacted through the [Whitelist Caller](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#whitelisted-caller){target=\\_blank} origin.\n\nVisit [Origins and Tracks Info](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#origins-and-tracks){target=\\_blank} for details on current origins and tracks, associated terminology, and parameters."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 4, "depth": 2, "title": "Referendums", "anchor": "referendums", "start_char": 3654, "end_char": 4505, "estimated_token_count": 178, "token_estimator": "heuristic-v1", "text": "## Referendums\n\nIn OpenGov, anyone can submit a referendum, fostering an open and participatory system. The timeline for a referendum depends on the privilege level of the origin with more significant changes offering more time for community voting and participation before enactment. \n\nThe timeline for an individual referendum includes four distinct periods:\n\n- **Lead-in**: A minimum amount of time to allow for community participation, available room in the origin, and payment of the decision deposit. Voting is open during this period.\n- **Decision**: Voting continues.\n- **Confirmation**: Referendum must meet [approval and support](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#approval-and-support){target=\\_blank} criteria during entire period to avoid rejection.\n- **Enactment**: Changes approved by the referendum are executed."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 5, "depth": 3, "title": "Vote on Referendums", "anchor": "vote-on-referendums", "start_char": 4505, "end_char": 5146, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### Vote on Referendums\n\nVoters can vote with their tokens on each referendum. Polkadot uses a voluntary token locking mechanism, called conviction voting, as a way for voters to increase their voting power. A token holder signals they have a stronger preference for approving a proposal based upon their willingness to lock up tokens. Longer voluntary token locks are seen as a signal of continual approval and translate to increased voting weight.\n\nSee [Voting on a Referendum](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#voting-on-a-referendum){target=\\_blank} for a deeper look at conviction voting and related token locks."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 6, "depth": 3, "title": "Delegate Voting Power", "anchor": "delegate-voting-power", "start_char": 5146, "end_char": 5929, "estimated_token_count": 168, "token_estimator": "heuristic-v1", "text": "### Delegate Voting Power\n\nThe OpenGov system also supports multi-role delegations, allowing token holders to assign their voting power on different tracks to entities with expertise in those areas. \n\nFor example, if a token holder lacks the technical knowledge to evaluate proposals on the [Root track](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#root){target=\\_blank}, they can delegate their voting power for that track to an expert they trust to vote in the best interest of the network. This ensures informed decision-making across tracks while maintaining flexibility for token holders.\n\nVisit [Multirole Delegation](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#multirole-delegation){target=\\_blank} for more details on delegating voting power."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 7, "depth": 3, "title": "Cancel a Referendum", "anchor": "cancel-a-referendum", "start_char": 5929, "end_char": 6702, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "### Cancel a Referendum\n\nPolkadot OpenGov has two origins for rejecting ongoing referendums: \n\n- [**Referendum Canceller**](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#referendum-canceller){target=\\_blank}: Cancels an active referendum when non-malicious errors occur and refunds the deposits to the originators.\n- [**Referendum Killer**](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#referendum-killer){target=\\_blank}: Used for urgent, malicious cases this origin instantly terminates an active referendum and slashes deposits.\n\nSee [Cancelling, Killing, and Blacklisting](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#cancelling-killing--blacklisting){target=\\_blank} for additional information on rejecting referendums."}
{"page_id": "polkadot-protocol-onchain-governance-overview", "index": 8, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 6702, "end_char": 7491, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- **[Democracy pallet](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/democracy/src){target=\\_blank}**: Handles administration of general stakeholder voting.\n- **[Gov2: Polkadot’s Next Generation of Decentralised Governance](https://medium.com/polkadot-network/gov2-polkadots-next-generation-of-decentralised-governance-4d9ef657d11b){target=\\_blank}**: Medium article by Gavin Wood.\n- **[Polkadot Direction](https://matrix.to/#/#Polkadot-Direction:parity.io){target=\\_blank}**: Matrix Element client.\n- **[Polkassembly](https://polkadot.polkassembly.io/){target=\\_blank}**: OpenGov dashboard and UI.\n- **[Polkadot.js Apps Governance](https://polkadot.js.org/apps/#/referenda){target=\\_blank}**: Overview of active referendums."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 597, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAccounts are essential for managing identity, transactions, and governance on the network in the Polkadot SDK. Understanding these components is critical for seamless development and operation on the network, whether you're building or interacting with Polkadot-based chains.\n\nThis page will guide you through the essential aspects of accounts, including their data structure, balance types, reference counters, and address formats. You’ll learn how accounts are managed within the runtime, how balances are categorized, and how addresses are encoded and validated."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 1, "depth": 2, "title": "Account Data Structure", "anchor": "account-data-structure", "start_char": 597, "end_char": 862, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "## Account Data Structure\n\nAccounts are foundational to any blockchain, and the Polkadot SDK provides a flexible management system. This section explains how the Polkadot SDK defines accounts and manages their lifecycle through data structures within the runtime."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 2, "depth": 3, "title": "Account", "anchor": "account", "start_char": 862, "end_char": 3154, "estimated_token_count": 570, "token_estimator": "heuristic-v1", "text": "### Account\n\nThe [`Account` data type](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/type.Account.html){target=\\_blank} is a storage map within the [System pallet](https://paritytech.github.io/polkadot-sdk/master/src/frame_system/lib.rs.html){target=\\_blank} that links an account ID to its corresponding data. This structure is fundamental for mapping account-related information within the chain.\n\nThe code snippet below shows how accounts are defined:\n\n```rs\n -/// The full account information for a particular account ID.\n\t#[pallet::storage]\n\t#[pallet::getter(fn account)]\n\tpub type Account<T: Config> = StorageMap<\n\t\t_,\n\t\tBlake2_128Concat,\n\t\tT::AccountId,\n\t\tAccountInfo<T::Nonce, T::AccountData>,\n\t\tValueQuery,\n\t>;\n```\n\nThe preceding code block defines a storage map named `Account`. The `StorageMap` is a type of on-chain storage that maps keys to values. In the `Account` map, the key is an account ID, and the value is the account's information. Here, `T` represents the generic parameter for the runtime configuration, which is defined by the pallet's configuration trait (`Config`).\n\nThe `StorageMap` consists of the following parameters:\n\n- **`_`**: Used in macro expansion and acts as a placeholder for the storage prefix type. Tells the macro to insert the default prefix during expansion.\n- **`Blake2_128Concat`**: The hashing function applied to keys in the storage map.\n- **`T: :AccountId`**: Represents the key type, which corresponds to the account’s unique ID.\n- **`AccountInfo<T: :Nonce, T::AccountData>`**: The value type stored in the map. For each account ID, the map stores an `AccountInfo` struct containing:\n\n    - **`T::Nonce`**: A nonce for the account, which is incremented with each transaction to ensure transaction uniqueness.\n    - **`T: :AccountData`**: Custom account data defined by the runtime configuration, which could include balances, locked funds, or other relevant information.\n    \n- **`ValueQuery`**: Defines how queries to the storage map behave when no value is found; returns a default value instead of `None`.\n\nFor a detailed explanation of storage maps, see the [`StorageMap`](https://paritytech.github.io/polkadot-sdk/master/frame_support/storage/types/struct.StorageMap.html){target=\\_blank} entry in the Rust docs."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 3, "depth": 3, "title": "Account Info", "anchor": "account-info", "start_char": 3154, "end_char": 5818, "estimated_token_count": 618, "token_estimator": "heuristic-v1", "text": "### Account Info\n\nThe `AccountInfo` structure is another key element within the [System pallet](https://paritytech.github.io/polkadot-sdk/master/src/frame_system/lib.rs.html){target=\\_blank}, providing more granular details about each account's state. This structure tracks vital data, such as the number of transactions and the account’s relationships with other modules.\n\n```rs\n-/// Information of an account.\n#[derive(Clone, Eq, PartialEq, Default, RuntimeDebug, Encode, Decode, TypeInfo, MaxEncodedLen)]\npub struct AccountInfo<Nonce, AccountData> {\n\t/// The number of transactions this account has sent.\n\tpub nonce: Nonce,\n\t/// The number of other modules that currently depend on this account's existence. The account\n\t/// cannot be reaped until this is zero.\n\tpub consumers: RefCount,\n\t/// The number of other modules that allow this account to exist. The account may not be reaped\n\t/// until this and `sufficients` are both zero.\n\tpub providers: RefCount,\n\t/// The number of modules that allow this account to exist for their own purposes only. The\n\t/// account may not be reaped until this and `providers` are both zero.\n\tpub sufficients: RefCount,\n\t/// The additional data that belongs to this account. Used to store the balance(s) in a lot of\n\t/// chains.\n\tpub data: AccountData,\n}\n```\n\nThe `AccountInfo` structure includes the following components:\n\n- **`nonce`**: Tracks the number of transactions initiated by the account, which ensures transaction uniqueness and prevents replay attacks.\n- **`consumers`**: Counts how many other modules or pallets rely on this account’s existence. The account cannot be removed from the chain (reaped) until this count reaches zero.\n- **`providers`**: Tracks how many modules permit this account’s existence. An account can only be reaped once both `providers` and `sufficients` are zero.\n- **`sufficients`**: Represents the number of modules that allow the account to exist for internal purposes, independent of any other modules.\n- **`AccountData`**: A flexible data structure that can be customized in the runtime configuration, usually containing balances or other user-specific data.\n\nThis structure helps manage an account's state and prevents its premature removal while it is still referenced by other on-chain data or modules. The [`AccountInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_system/struct.AccountInfo.html){target=\\_blank} structure can vary as long as it satisfies the trait bounds defined by the `AccountData` associated type in the [`frame-system::pallet::Config`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html){target=\\_blank} trait."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 4, "depth": 3, "title": "Account Reference Counters", "anchor": "account-reference-counters", "start_char": 5818, "end_char": 10911, "estimated_token_count": 1040, "token_estimator": "heuristic-v1", "text": "### Account Reference Counters\n\nPolkadot SDK uses reference counters to track an account’s dependencies across different runtime modules. These counters ensure that accounts remain active while data is associated with them.\n\nThe reference counters include:\n\n- **`consumers`**: Prevents account removal while other pallets still rely on the account.\n- **`providers`**: Ensures an account is active before other pallets store data related to it.\n- **`sufficients`**: Indicates the account’s independence, ensuring it can exist even without a native token balance, such as when holding sufficient alternative assets.\n\n#### Providers Reference Counters\n\nThe `providers` counter ensures that an account is ready to be depended upon by other runtime modules. For example, it is incremented when an account has a balance above the existential deposit, which marks the account as active.\n\nThe system requires this reference counter to be greater than zero for the `consumers` counter to be incremented, ensuring the account is stable before any dependencies are added.\n\n#### Consumers Reference Counters\n\nThe `consumers` counter ensures that the account cannot be reaped until all references to it across the runtime have been removed. This check prevents the accidental deletion of accounts that still have active on-chain data.\n\nIt is the user’s responsibility to clear out any data from other runtime modules if they wish to remove their account and reclaim their existential deposit.\n\n#### Sufficients Reference Counter\n\nThe `sufficients` counter tracks accounts that can exist independently without relying on a native account balance. This is useful for accounts holding other types of assets, like tokens, without needing a minimum balance in the native token.\n\nFor instance, the [Assets pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_assets/index.html){target=\\_blank}, may increment this counter for an account holding sufficient tokens.\n\n#### Account Deactivation\n\nIn Polkadot SDK-based chains, an account is deactivated when its reference counters (such as `providers`, `consumers`, and `sufficient`) reach zero. These counters ensure the account remains active as long as other runtime modules or pallets reference it.\n\nWhen all dependencies are cleared and the counters drop to zero, the account becomes deactivated and may be removed from the chain (reaped). This is particularly important in Polkadot SDK-based blockchains, where accounts with balances below the existential deposit threshold are pruned from storage to conserve state resources.\n\nEach pallet that references an account has cleanup functions that decrement these counters when the pallet no longer depends on the account. Once these counters reach zero, the account is marked for deactivation.\n\n#### Updating Counters\n\nThe Polkadot SDK provides runtime developers with various methods to manage account lifecycle events, such as deactivation or incrementing reference counters. These methods ensure that accounts cannot be reaped while still in use.\n\nThe following helper functions manage these counters:\n\n- **`inc_consumers()`**: Increments the `consumer` reference counter for an account, signaling that another pallet depends on it.\n- **`dec_consumers()`**: Decrements the `consumer` reference counter, signaling that a pallet no longer relies on the account.\n- **`inc_providers()`**: Increments the `provider` reference counter, ensuring the account remains active.\n- **`dec_providers()`**: Decrements the `provider` reference counter, allowing for account deactivation when no longer in use.\n- **`inc_sufficients()`**: Increments the `sufficient` reference counter for accounts that hold sufficient assets.\n- **`dec_sufficients()`**: Decrements the `sufficient` reference counter.\n\nTo ensure proper account cleanup and lifecycle management, a corresponding decrement should be made for each increment action.\n\nThe `System` pallet offers three query functions to assist developers in tracking account states:\n\n- **[`can_inc_consumer()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.can_inc_consumer){target=\\_blank}**: Checks if the account can safely increment the consumer reference.\n- **[`can_dec_provider()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.can_dec_provider){target=\\_blank}**: Ensures that no consumers exist before allowing the decrement of the provider counter.\n- **[`is_provider_required()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.is_provider_required){target=\\_blank}**: Verifies whether the account still has any active consumer references.\n\nThis modular and flexible system of reference counters tightly controls the lifecycle of accounts in Polkadot SDK-based blockchains, preventing the accidental removal or retention of unneeded accounts. You can refer to the [System pallet Rust docs](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html){target=\\_blank} for more details."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 5, "depth": 2, "title": "Account Balance Types", "anchor": "account-balance-types", "start_char": 10911, "end_char": 12831, "estimated_token_count": 465, "token_estimator": "heuristic-v1", "text": "## Account Balance Types\n\nIn the Polkadot ecosystem, account balances are categorized into different types based on how the funds are utilized and their availability. These balance types determine the actions that can be performed, such as transferring tokens, paying transaction fees, or participating in governance activities. Understanding these balance types helps developers manage user accounts and implement balance-dependent logic.\n\n!!! note \"A more efficient distribution of account balance types is in development\"\n    Soon, pallets in the Polkadot SDK will implement the [`Fungible` trait](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/tokens/fungible/index.html){target=\\_blank} (see the [tracking issue](https://github.com/paritytech/polkadot-sdk/issues/226){target=\\_blank} for more details). For example, the [`transaction-storage`](https://paritytech.github.io/polkadot-sdk/master/pallet_transaction_storage/index.html){target=\\_blank} pallet changed the implementation of the [`Currency`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/tokens/currency/index.html){target=\\_blank} trait (see the [Refactor transaction storage pallet to use fungible traits](https://github.com/paritytech/polkadot-sdk/pull/1800){target=\\_blank} PR for further details):\n\n    ```rust\n    type BalanceOf<T> = <<T as Config>::Currency as Currency<<T as frame_system::Config>::AccountId>>::Balance;\n    ```\n    \n    To the [`Fungible`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/tokens/fungible/index.html){target=\\_blank} trait:\n\n    ```rust\n    type BalanceOf<T> = <<T as Config>::Currency as FnInspect<<T as frame_system::Config>::AccountId>>::Balance;\n    ```\n    \n    This update will enable more efficient use of account balances, allowing the free balance to be utilized for on-chain activities such as setting proxies and managing identities."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 6, "depth": 3, "title": "Balance Types", "anchor": "balance-types", "start_char": 12831, "end_char": 15306, "estimated_token_count": 601, "token_estimator": "heuristic-v1", "text": "### Balance Types\n\nThe five main balance types are:\n\n- **Free balance**: Represents the total tokens available to the account for any on-chain activity, including staking, governance, and voting. However, it may not be fully spendable or transferrable if portions of it are locked or reserved.\n- **Locked balance**: Portions of the free balance that cannot be spent or transferred because they are tied up in specific activities like [staking](https://wiki.polkadot.com/learn/learn-staking/#nominating-validators){target=\\_blank}, [vesting](https://wiki.polkadot.com/learn/learn-guides-transfers/#vested-transfers-with-the-polkadot-js-ui){target=\\_blank}, or participating in [governance](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#voting-on-a-referendum){target=\\_blank}. While the tokens remain part of the free balance, they are non-transferable for the duration of the lock.\n- **Reserved balance**: Funds locked by specific system actions, such as setting up an [identity](https://wiki.polkadot.com/learn/learn-identity/){target=\\_blank}, creating [proxies](https://wiki.polkadot.com/learn/learn-proxies/){target=\\_blank}, or submitting [deposits for governance proposals](https://wiki.polkadot.com/learn/learn-guides-polkadot-opengov/#claiming-opengov-deposits){target=\\_blank}. These tokens are not part of the free balance and cannot be spent unless they are unreserved.\n- **Spendable balance**: The portion of the free balance that is available for immediate spending or transfers. It is calculated by subtracting the maximum of locked or reserved amounts from the free balance, ensuring that existential deposit limits are met.\n- **Untouchable balance**: Funds that cannot be directly spent or transferred but may still be utilized for on-chain activities, such as governance participation or staking. These tokens are typically tied to certain actions or locked for a specific period.\n\nThe spendable balance is calculated as follows:\n\n```text\nspendable = free - max(locked - reserved, ED)\n```\n\nHere, `free`, `locked`, and `reserved` are defined above. The `ED` represents the [existential deposit](https://wiki.polkadot.com/learn/learn-accounts/#existential-deposit-and-reaping){target=\\_blank}, the minimum balance required to keep an account active and prevent it from being reaped. You may find you can't see all balance types when looking at your account via a wallet. Wallet providers often display only spendable, locked, and reserved balances."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 7, "depth": 3, "title": "Locks", "anchor": "locks", "start_char": 15306, "end_char": 17501, "estimated_token_count": 464, "token_estimator": "heuristic-v1", "text": "### Locks\n\nLocks are applied to an account's free balance, preventing that portion from being spent or transferred. Locks are automatically placed when an account participates in specific on-chain activities, such as staking or governance. Although multiple locks may be applied simultaneously, they do not stack. Instead, the largest lock determines the total amount of locked tokens.\n\nLocks follow these basic rules:\n\n- If different locks apply to varying amounts, the largest lock amount takes precedence.\n- If multiple locks apply to the same amount, the lock with the longest duration governs when the balance can be unlocked.\n\n#### Locks Example\n\nConsider an example where an account has 80 DOT locked for both staking and governance purposes like so:\n\n- 80 DOT is staked with a 28-day lock period.\n- 24 DOT is locked for governance with a 1x conviction and a 7-day lock period.\n- 4 DOT is locked for governance with a 6x conviction and a 224-day lock period.\n\nIn this case, the total locked amount is 80 DOT because only the largest lock (80 DOT from staking) governs the locked balance. These 80 DOT will be released at different times based on the lock durations. In this example, the 24 DOT locked for governance will be released first since the shortest lock period is seven days. The 80 DOT stake with a 28-day lock period is released next. Now, all that remains locked is the 4 DOT for governance. After 224 days, all 80 DOT (minus the existential deposit) will be free and transferable.\n\n![Illustration of Lock Example](/images/polkadot-protocol/parachain-basics/accounts/locks-example-2.webp)\n\n#### Edge Cases for Locks\n\nIn scenarios where multiple convictions and lock periods are active, the lock duration and amount are determined by the longest period and largest amount. For example, if you delegate with different convictions and attempt to undelegate during an active lock period, the lock may be extended for the full amount of tokens. For a detailed discussion on edge case lock behavior, see this [Stack Exchange post](https://substrate.stackexchange.com/questions/5067/delegating-and-undelegating-during-the-lock-period-extends-it-for-the-initial-am){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 8, "depth": 3, "title": "Balance Types on Polkadot.js", "anchor": "balance-types-on-polkadotjs", "start_char": 17501, "end_char": 20566, "estimated_token_count": 611, "token_estimator": "heuristic-v1", "text": "### Balance Types on Polkadot.js\n\nPolkadot.js provides a user-friendly interface for managing and visualizing various account balances on Polkadot and Kusama networks. When interacting with Polkadot.js, you will encounter multiple balance types that are critical for understanding how your funds are distributed and restricted. This section explains how different balances are displayed in the Polkadot.js UI and what each type represents.\n\n![](/images/polkadot-protocol/parachain-basics/accounts/account-balance-types-1.webp)\n\nThe most common balance types displayed on Polkadot.js are:\n\n- **Total balance**: The total number of tokens available in the account. This includes all tokens, whether they are transferable, locked, reserved, or vested. However, the total balance does not always reflect what can be spent immediately. In this example, the total balance is 0.6274 KSM.\n\n- **Transferable balance**: Shows how many tokens are immediately available for transfer. It is calculated by subtracting the locked and reserved balances from the total balance. For example, if an account has a total balance of 0.6274 KSM and a transferable balance of 0.0106 KSM, only the latter amount can be sent or spent freely.\n\n- **Vested balance**: Tokens that allocated to the account but released according to a specific schedule. Vested tokens remain locked and cannot be transferred until fully vested. For example, an account with a vested balance of 0.2500 KSM means that this amount is owned but not yet transferable.\n\n- **Locked balance**: Tokens that are temporarily restricted from being transferred or spent. These locks typically result from participating in staking, governance, or vested transfers. In Polkadot.js, locked balances do not stack—only the largest lock is applied. For instance, if an account has 0.5500 KSM locked for governance and staking, the locked balance would display 0.5500 KSM, not the sum of all locked amounts.\n\n- **Reserved balance**: Refers to tokens locked for specific on-chain actions, such as setting an identity, creating a proxy, or making governance deposits. Reserved tokens are not part of the free balance, but can be freed by performing certain actions. For example, removing an identity would unreserve those funds.\n\n- **Bonded balance**: The tokens locked for staking purposes. Bonded tokens are not transferable until they are unbonded after the unbonding period.\n\n- **Redeemable balance**: The number of tokens that have completed the unbonding period and are ready to be unlocked and transferred again. For example, if an account has a redeemable balance of 0.1000 KSM, those tokens are now available for spending.\n\n- **Democracy balance**: Reflects the number of tokens locked for governance activities, such as voting on referenda. These tokens are locked for the duration of the governance action and are only released after the lock period ends.\n\nBy understanding these balance types and their implications, developers and users can better manage their funds and engage with on-chain activities more effectively."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 9, "depth": 2, "title": "Address Formats", "anchor": "address-formats", "start_char": 20566, "end_char": 21025, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Address Formats\n\nThe SS58 address format is a core component of the Polkadot SDK that enables accounts to be uniquely identified across Polkadot-based networks. This format is a modified version of Bitcoin's Base58Check encoding, specifically designed to accommodate the multi-chain nature of the Polkadot ecosystem. SS58 encoding allows each chain to define its own set of addresses while maintaining compatibility and checksum validation for security."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 10, "depth": 3, "title": "Basic Format", "anchor": "basic-format", "start_char": 21025, "end_char": 22267, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "### Basic Format\n\nSS58 addresses consist of three main components:\n\n```text\nbase58encode(concat(<address-type>, <address>, <checksum>))\n```\n\n- **Address type**: A byte or set of bytes that define the network (or chain) for which the address is intended. This ensures that addresses are unique across different Polkadot SDK-based chains.\n- **Address**: The public key of the account encoded as bytes.\n- **Checksum**: A hash-based checksum which ensures that addresses are valid and unaltered. The checksum is derived from the concatenated address type and address components, ensuring integrity.\n\nThe encoding process transforms the concatenated components into a Base58 string, providing a compact and human-readable format that avoids easily confused characters (e.g., zero '0', capital 'O', lowercase 'l'). This encoding function ([`encode`](https://docs.rs/bs58/latest/bs58/fn.encode.html){target=\\_blank}) is implemented exactly as defined in Bitcoin and IPFS specifications, using the same alphabet as both implementations.\n\nFor more details about the SS58 address format implementation, see the [`Ss58Codec`](https://paritytech.github.io/polkadot-sdk/master/sp_core/crypto/trait.Ss58Codec.html){target=\\_blank} trait in the Rust Docs."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 11, "depth": 3, "title": "Address Type", "anchor": "address-type", "start_char": 22267, "end_char": 23202, "estimated_token_count": 203, "token_estimator": "heuristic-v1", "text": "### Address Type\n\nThe address type defines how an address is interpreted and to which network it belongs. Polkadot SDK uses different prefixes to distinguish between various chains and address formats:\n\n- **Address types `0-63`**: Simple addresses, commonly used for network identifiers.\n- **Address types `64-127`**: Full addresses that support a wider range of network identifiers.\n- **Address types `128-255`**: Reserved for future address format extensions.\n\nFor example, Polkadot’s main network uses an address type of 0, while Kusama uses 2. This ensures that addresses can be used without confusion between networks.\n\nThe address type is always encoded as part of the SS58 address, making it easy to quickly identify the network. Refer to the [SS58 registry](https://github.com/paritytech/ss58-registry){target=\\_blank} for the canonical listing of all address type identifiers and how they map to Polkadot SDK-based networks."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 12, "depth": 3, "title": "Address Length", "anchor": "address-length", "start_char": 23202, "end_char": 24396, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "### Address Length\n\nSS58 addresses can have different lengths depending on the specific format. Address lengths range from as short as 3 to 35 bytes, depending on the complexity of the address and network requirements. This flexibility allows SS58 addresses to adapt to different chains while providing a secure encoding mechanism.\n\n| Total | Type | Raw account | Checksum |\n|-------|------|-------------|----------|\n| 3     | 1    | 1           | 1        |\n| 4     | 1    | 2           | 1        |\n| 5     | 1    | 2           | 2        |\n| 6     | 1    | 4           | 1        |\n| 7     | 1    | 4           | 2        |\n| 8     | 1    | 4           | 3        |\n| 9     | 1    | 4           | 4        |\n| 10    | 1    | 8           | 1        |\n| 11    | 1    | 8           | 2        |\n| 12    | 1    | 8           | 3        |\n| 13    | 1    | 8           | 4        |\n| 14    | 1    | 8           | 5        |\n| 15    | 1    | 8           | 6        |\n| 16    | 1    | 8           | 7        |\n| 17    | 1    | 8           | 8        |\n| 35    | 1    | 32          | 2        |\n\nSS58 addresses also support different payload sizes, allowing a flexible range of account identifiers."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 13, "depth": 3, "title": "Checksum Types", "anchor": "checksum-types", "start_char": 24396, "end_char": 24861, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "### Checksum Types\n\nA checksum is applied to validate SS58 addresses. Polkadot SDK uses a Blake2b-512 hash function to calculate the checksum, which is appended to the address before encoding. The checksum length can vary depending on the address format (e.g., 1-byte, 2-byte, or longer), providing varying levels of validation strength.\n\nThe checksum ensures that an address is not modified or corrupted, adding an extra layer of security for account management."}
{"page_id": "polkadot-protocol-parachain-basics-accounts", "index": 14, "depth": 3, "title": "Validating Addresses", "anchor": "validating-addresses", "start_char": 24861, "end_char": 29646, "estimated_token_count": 1077, "token_estimator": "heuristic-v1", "text": "### Validating Addresses\n\nSS58 addresses can be validated using the subkey command-line interface or the Polkadot.js API. These tools help ensure an address is correctly formatted and valid for the intended network. The following sections will provide an overview of how validation works with these tools.\n\n#### Using Subkey\n\n[Subkey](https://paritytech.github.io/polkadot-sdk/master/subkey/index.html){target=\\_blank} is a CLI tool provided by Polkadot SDK for generating and managing keys. It can inspect and validate SS58 addresses.\n\nThe `inspect` command gets a public key and an SS58 address from the provided secret URI. The basic syntax for the `subkey inspect` command is:\n\n```bash\nsubkey inspect [flags] [options] uri\n```\n\nFor the `uri` command-line argument, you can specify the secret seed phrase, a hex-encoded private key, or an SS58 address. If the input is a valid address, the `subkey` program displays the corresponding hex-encoded public key, account identifier, and SS58 addresses.\n\nFor example, to inspect the public keys derived from a secret seed phrase, you can run a command similar to the following:\n\n```bash\nsubkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\"\n```\n\nThe command displays output similar to the following:\n\n-<div id=\"termynal\" data-termynal markdown>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\"</span>\n  <span data-ty>Secret phrase `caution juice atom organ advance problem want pledge someone senior holiday very` is account:</span>\n  <span data-ty> Secret seed: 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849</span>\n  <span data-ty> Public key (hex): 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746</span>\n  <span data-ty> Public key (SS58): 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR</span>\n  <span data-ty> Account ID: 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746</span>\n  <span data-ty> SS58 Address: 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR</span>\n</div>\n\n\nThe `subkey` program assumes an address is based on a public/private key pair. If you inspect an address, the command returns the 32-byte account identifier.\n\nHowever, not all addresses in Polkadot SDK-based networks are based on keys.\n\nDepending on the command-line options you specify and the input you provided, the command output might also display the network for which the address has been encoded. For example:\n\n```bash\nsubkey inspect \"12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU\"\n```\n\nThe command displays output similar to the following:\n\n-<div id=\"termynal\" data-termynal markdown>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>subkey inspect \"12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU\"</span>\n  <span data-ty>Public Key URI `12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU` is account:</span>\n  <span data-ty> Network ID/Version: polkadot</span>\n  <span data-ty> Public key (hex): 0x46ebddef8cd9bb167dc30878d7113b7e168e6f0646beffd77d69d39bad76b47a</span>\n  <span data-ty> Account ID: 0x46ebddef8cd9bb167dc30878d7113b7e168e6f0646beffd77d69d39bad76b47a</span>\n  <span data-ty> Public key (SS58): 12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU</span>\n  <span data-ty> SS58 Address: 12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU</span>\n</div>\n\n\n#### Using Polkadot.js API\n\nTo verify an address in JavaScript or TypeScript projects, you can use the functions built into the [Polkadot.js API](https://polkadot.js.org/docs/){target=\\_blank}. For example:\n\n```js\n-// Import Polkadot.js API dependencies\nconst { decodeAddress, encodeAddress } = require('@polkadot/keyring');\nconst { hexToU8a, isHex } = require('@polkadot/util');\n\n// Specify an address to test.\nconst address = 'INSERT_ADDRESS_TO_TEST';\n\n// Check address\nconst isValidSubstrateAddress = () => {\n  try {\n    encodeAddress(isHex(address) ? hexToU8a(address) : decodeAddress(address));\n\n    return true;\n  } catch (error) {\n    return false;\n  }\n};\n\n// Query result\nconst isValid = isValidSubstrateAddress();\nconsole.log(isValid);\n\n```\n\nIf the function returns `true`, the specified address is a valid address.\n\n#### Other SS58 Implementations\n\nSupport for encoding and decoding Polkadot SDK SS58 addresses has been implemented in several other languages and libraries.\n\n- **Crystal**: [`wyhaines/base58.cr`](https://github.com/wyhaines/base58.cr){target=\\_blank}\n- **Go**: [`itering/subscan-plugin`](https://github.com/itering/subscan-plugin){target=\\_blank}\n- **Python**: [`polkascan/py-scale-codec`](https://github.com/polkascan/py-scale-codec){target=\\_blank}\n- **TypeScript**: [`subsquid/squid-sdk`](https://github.com/subsquid/squid-sdk){target=\\_blank}"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 10, "end_char": 707, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn the Polkadot SDK, blocks are fundamental to the functioning of the blockchain, serving as containers for [transactions](/polkadot-protocol/parachain-basics/blocks-transactions-fees/transactions/){target=\\_blank} and changes to the chain's state. Blocks consist of headers and an array of transactions, ensuring the integrity and validity of operations on the network. This guide explores the essential components of a block, the process of block production, and how blocks are validated and imported across the network. By understanding these concepts, developers can better grasp how blockchains maintain security, consistency, and performance within the Polkadot ecosystem."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 1, "depth": 2, "title": "What is a Block?", "anchor": "what-is-a-block", "start_char": 707, "end_char": 1844, "estimated_token_count": 226, "token_estimator": "heuristic-v1", "text": "## What is a Block?\n\nIn the Polkadot SDK, a block is a fundamental unit that encapsulates both the header and an array of transactions. The block header includes critical metadata to ensure the integrity and sequence of the blockchain. Here's a breakdown of its components:\n\n- **Block height**: Indicates the number of blocks created in the chain so far.\n- **Parent hash**: The hash of the previous block, providing a link to maintain the blockchain's immutability.\n- **Transaction root**: Cryptographic digest summarizing all transactions in the block.\n- **State root**: A cryptographic digest representing the post-execution state.\n- **Digest**: Additional information that can be attached to a block, such as consensus-related messages.\n\nEach transaction is part of a series that is executed according to the runtime's rules. The transaction root is a cryptographic digest of this series, which prevents alterations and enables succinct verification by light clients. This verification process allows light clients to confirm whether a transaction exists in a block with only the block header, avoiding downloading the entire block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 2, "depth": 2, "title": "Block Production", "anchor": "block-production", "start_char": 1844, "end_char": 2168, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Block Production\n\nWhen an authoring node is authorized to create a new block, it selects transactions from the transaction queue based on priority. This step, known as block production, relies heavily on the executive module to manage the initialization and finalization of blocks. The process is summarized as follows:"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 3, "depth": 3, "title": "Initialize Block", "anchor": "initialize-block", "start_char": 2168, "end_char": 3037, "estimated_token_count": 199, "token_estimator": "heuristic-v1", "text": "### Initialize Block\n\nThe block initialization process begins with a series of function calls that prepare the block for transaction execution:\n\n1. **Call `on_initialize`**: The executive module calls the [`on_initialize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_initialize){target=\\_blank} hook from the system pallet and other runtime pallets to prepare for the block's transactions.\n2. **Coordinate runtime calls**: Coordinates function calls in the order defined by the transaction queue.\n3. **Verify information**: Once [`on_initialize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_initialize){target=\\_blank} functions are executed, the executive module checks the parent hash in the block header and the trie root to verify information is consistent."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 4, "depth": 3, "title": "Finalize Block", "anchor": "finalize-block", "start_char": 3037, "end_char": 3911, "estimated_token_count": 209, "token_estimator": "heuristic-v1", "text": "### Finalize Block\n\nOnce transactions are processed, the block must be finalized before being broadcast to the network. The finalization steps are as follows:\n\n1. **Call `on_finalize`**: The executive module calls the [`on_finalize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_finalize){target=\\_blank} hooks in each pallet to ensure any remaining state updates or checks are completed before the block is sealed and published.\n2. **Verify information**: The block's digest and storage root in the header are checked against the initialized block to ensure consistency.\n3. **Call `on_idle`**: The [`on_idle`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_idle){target=\\_blank} hook is triggered to process any remaining tasks using the leftover weight from the block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 5, "depth": 2, "title": "Block Authoring and Import", "anchor": "block-authoring-and-import", "start_char": 3911, "end_char": 4413, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Block Authoring and Import\n\nOnce the block is finalized, it is gossiped to other nodes in the network. Nodes follow this procedure:\n\n1. **Receive transactions**: The authoring node collects transactions from the network.\n2. **Validate**: Transactions are checked for validity.\n3. **Queue**: Valid transactions are placed in the transaction pool for execution.\n4. **Execute**: State changes are made as the transactions are executed.\n5. **Publish**: The finalized block is broadcast to the network."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 6, "depth": 3, "title": "Block Import Queue", "anchor": "block-import-queue", "start_char": 4413, "end_char": 6019, "estimated_token_count": 401, "token_estimator": "heuristic-v1", "text": "### Block Import Queue\n\nAfter a block is published, other nodes on the network can import it into their chain state. The block import queue is part of the outer node in every Polkadot SDK-based node and ensures incoming blocks are valid before adding them to the node's state.\n\nIn most cases, you don't need to know details about how transactions are gossiped or how other nodes on the network import blocks. The following traits are relevant, however, if you plan to write any custom consensus logic or want a deeper dive into the block import queue:\n\n- **[`ImportQueue`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/trait.ImportQueue.html){target=\\_blank}**: The trait that defines the block import queue.\n- **[`Link`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/trait.Link.html){target=\\_blank}**: The trait that defines the link between the block import queue and the network.\n- **[`BasicQueue`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/struct.BasicQueue.html){target=\\_blank}**: A basic implementation of the block import queue.\n- **[`Verifier`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/trait.Verifier.html){target=\\_blank}**: The trait that defines the block verifier.\n- **[`BlockImport`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/block_import/trait.BlockImport.html){target=\\_blank}**: The trait that defines the block import process.\n\nThese traits govern how blocks are validated and imported across the network, ensuring consistency and security."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-blocks", "index": 7, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 6019, "end_char": 6266, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nTo learn more about the block structure in the Polkadot SDK runtime, see the [`Block` reference](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/traits/trait.Block.html){target=\\_blank} entry in the Rust Docs."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 0, "depth": 2, "title": "Introductions", "anchor": "introductions", "start_char": 33, "end_char": 2289, "estimated_token_count": 414, "token_estimator": "heuristic-v1", "text": "## Introductions\n\nWhen transactions are executed, or data is stored on-chain, the activity changes the chain's state and consumes blockchain resources. Because the resources available to a blockchain are limited, managing how operations on-chain consume them is important. In addition to being limited in practical terms, such as storage capacity, blockchain resources represent a potential attack vector for malicious users. For example, a malicious user might attempt to overload the network with messages to stop the network from producing new blocks. To protect blockchain resources from being drained or overloaded, you need to manage how they are made available and how they are consumed. The resources to be aware of include:\n\n- Memory usage\n- Storage input and output\n- Computation\n- Transaction and block size\n- State database size\n\nThe Polkadot SDK provides block authors with several ways to manage access to resources and to prevent individual components of the chain from consuming too much of any single resource. Two of the most important mechanisms available to block authors are weights and transaction fees.\n\n[Weights](/polkadot-protocol/glossary/#weight){target=\\_blank} manage the time it takes to validate a block and characterize the time it takes to execute the calls in the block's body. By controlling the execution time a block can consume, weights set limits on storage input, output, and computation.\n\nSome of the weight allowed for a block is consumed as part of the block's initialization and finalization. The weight might also be used to execute mandatory inherent extrinsic calls. To help ensure blocks don’t consume too much execution time and prevent malicious users from overloading the system with unnecessary calls, weights are combined with transaction fees.\n\n[Transaction fees](/polkadot-protocol/parachain-basics/blocks-transactions-fees/transactions/#transaction-fees){target=\\_blank} provide an economic incentive to limit execution time, computation, and the number of calls required to perform operations. Transaction fees are also used to make the blockchain economically sustainable because they are typically applied to transactions initiated by users and deducted before a transaction request is executed."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 1, "depth": 2, "title": "How Fees are Calculated", "anchor": "how-fees-are-calculated", "start_char": 2289, "end_char": 3614, "estimated_token_count": 287, "token_estimator": "heuristic-v1", "text": "## How Fees are Calculated\n\nThe final fee for a transaction is calculated using the following parameters:\n\n- **`base fee`**: This is the minimum amount a user pays for a transaction. It is declared a base weight in the runtime and converted to a fee using the [`WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank} conversion.\n- **`weight fee`**: A fee proportional to the execution time (input and output and computation) that a transaction consumes.\n- **`length fee`**: A fee proportional to the encoded length of the transaction.\n- **`tip`**: An optional tip to increase the transaction’s priority, giving it a higher chance to be included in the transaction queue.\n\nThe base fee and proportional weight and length fees constitute the inclusion fee. The inclusion fee is the minimum fee that must be available for a transaction to be included in a block.\n\n```text\ninclusion fee = base fee + weight fee + length fee\n```\n\nTransaction fees are withdrawn before the transaction is executed. After the transaction is executed, the weight can be adjusted to reflect the resources used. If a transaction uses fewer resources than expected, the transaction fee is corrected, and the adjusted transaction fee is deposited."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 2, "depth": 2, "title": "Using the Transaction Payment Pallet", "anchor": "using-the-transaction-payment-pallet", "start_char": 3614, "end_char": 4951, "estimated_token_count": 307, "token_estimator": "heuristic-v1", "text": "## Using the Transaction Payment Pallet\n\nThe [Transaction Payment pallet](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/transaction-payment){target=\\_blank} provides the basic logic for calculating the inclusion fee. You can also use the Transaction Payment pallet to:\n\n- Convert a weight value into a deductible fee based on a currency type using [`Config::WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank}.\n- Update the fee for the next block by defining a multiplier based on the chain’s final state at the end of the previous block using [`Config::FeeMultiplierUpdate`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.FeeMultiplierUpdate){target=\\_blank}.\n- Manage the withdrawal, refund, and deposit of transaction fees using [`Config::OnChargeTransaction`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.OnChargeTransaction){target=\\_blank}.\n\nYou can learn more about these configuration traits in the [Transaction Payment documentation](https://paritytech.github.io/polkadot-sdk/master/pallet_transaction_payment/index.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 3, "depth": 3, "title": "Understanding the Inclusion Fee", "anchor": "understanding-the-inclusion-fee", "start_char": 4951, "end_char": 6275, "estimated_token_count": 278, "token_estimator": "heuristic-v1", "text": "### Understanding the Inclusion Fee\n\nThe formula for calculating the inclusion fee is as follows:\n\n```text\ninclusion_fee = base_fee + length_fee + [targeted_fee_adjustment * weight_fee]\n```\n\nAnd then, for calculating the final fee:\n\n```text\nfinal_fee = inclusion_fee + tip\n```\n\nIn the first formula, the `targeted_fee_adjustment` is a multiplier that can tune the final fee based on the network’s congestion.\n\n- The `base_fee` derived from the base weight covers inclusion overhead like signature verification.\n- The `length_fee` is a per-byte fee that is multiplied by the length of the encoded extrinsic.\n- The `weight_fee` fee is calculated using two parameters:\n  - The `ExtrinsicBaseWeight` that is declared in the runtime and applies to all extrinsics.\n  - The `#[pallet::weight]` annotation that accounts for an extrinsic's complexity.\n\nTo convert the weight to `Currency`, the runtime must define a `WeightToFee` struct that implements a conversion function, [`Convert<Weight,Balance>`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/struct.Pallet.html#method.weight_to_fee){target=\\_blank}.\n\nNote that the extrinsic sender is charged the inclusion fee before the extrinsic is invoked. The fee is deducted from the sender's balance even if the transaction fails upon execution."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 4, "depth": 3, "title": "Accounts with an Insufficient Balance", "anchor": "accounts-with-an-insufficient-balance", "start_char": 6275, "end_char": 6836, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "### Accounts with an Insufficient Balance\n\nIf an account does not have a sufficient balance to pay the inclusion fee and remain alive—that is, enough to pay the inclusion fee and maintain the minimum existential deposit—then you should ensure the transaction is canceled so that no fee is deducted and the transaction does not begin execution.\n\nThe Polkadot SDK doesn't enforce this rollback behavior. However, this scenario would be rare because the transaction queue and block-making logic perform checks to prevent it before adding an extrinsic to a block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 5, "depth": 3, "title": "Fee Multipliers", "anchor": "fee-multipliers", "start_char": 6836, "end_char": 8054, "estimated_token_count": 260, "token_estimator": "heuristic-v1", "text": "### Fee Multipliers\n\nThe inclusion fee formula always results in the same fee for the same input. However, weight can be dynamic and—based on how [`WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank} is defined—the final fee can include some degree of variability.\nThe Transaction Payment pallet provides the [`FeeMultiplierUpdate`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.FeeMultiplierUpdate){target=\\_blank} configurable parameter to account for this variability.\n\nThe Polkadot network inspires the default update function and implements a targeted adjustment in which a target saturation level of block weight is defined. If the previous block is more saturated, the fees increase slightly. Similarly, if the last block has fewer transactions than the target, fees are decreased by a small amount. For more information about fee multiplier adjustments, see the [Web3 Research Page](https://research.web3.foundation/Polkadot/overview/token-economics#relay-chain-transaction-fees-and-per-block-transaction-limits){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 6, "depth": 2, "title": "Transactions with Special Requirements", "anchor": "transactions-with-special-requirements", "start_char": 8054, "end_char": 9464, "estimated_token_count": 275, "token_estimator": "heuristic-v1", "text": "## Transactions with Special Requirements\n\nInclusion fees must be computable before execution and can only represent fixed logic. Some transactions warrant limiting resources with other strategies. For example:\n\n- Bonds are a type of fee that might be returned or slashed after some on-chain event. For example, you might want to require users to place a bond to participate in a vote. The bond might then be returned at the end of the referendum or slashed if the voter attempted malicious behavior.\n- Deposits are fees that might be returned later. For example, you might require users to pay a deposit to execute an operation that uses storage. The user’s deposit could be returned if a subsequent operation frees up storage.\n- Burn operations are used to pay for a transaction based on its internal logic. For example, a transaction might burn funds from the sender if the transaction creates new storage items to pay for the increased state size.\n- Limits enable you to enforce constant or configurable limits on specific operations. For example, the default [Staking pallet](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/staking){target=\\_blank} only allows nominators to nominate 16 validators to limit the complexity of the validator election process.\n\nIt is important to note that if you query the chain for a transaction fee, it only returns the inclusion fee."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 7, "depth": 2, "title": "Default Weight Annotations", "anchor": "default-weight-annotations", "start_char": 9464, "end_char": 10123, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Default Weight Annotations\n\nAll dispatchable functions in the Polkadot SDK must specify a weight. The way of doing that is using the annotation-based system that lets you combine fixed values for database read/write weight and/or fixed values based on benchmarks. The most basic example would look like this:\n\n```rust\n-#[pallet::weight(100_000)]\nfn my_dispatchable() {\n    // ...\n}\n```\n\nNote that the [`ExtrinsicBaseWeight`](https://crates.parity.io/frame_support/weights/constants/struct.ExtrinsicBaseWeight.html){target=\\_blank} is automatically added to the declared weight to account for the costs of simply including an empty extrinsic into a block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 8, "depth": 3, "title": "Weights and Database Read/Write Operations", "anchor": "weights-and-database-readwrite-operations", "start_char": 10123, "end_char": 11264, "estimated_token_count": 265, "token_estimator": "heuristic-v1", "text": "### Weights and Database Read/Write Operations\n\nTo make weight annotations independent of the deployed database backend, they are defined as a constant and then used in the annotations when expressing database accesses performed by the dispatchable:\n\n```rust\n-#[pallet::weight(T::DbWeight::get().reads_writes(1, 2) + 20_000)]\nfn my_dispatchable() {\n    // ...\n}\n```\n\nThis dispatchable allows one database to read and two to write, in addition to other things that add the additional 20,000. Database access is generally every time a value declared inside the [`#[pallet::storage]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.storage.html){target=\\_blank} block is accessed. However, unique accesses are counted because after a value is accessed, it is cached, and reaccessing it does not result in a database operation. That is:\n\n- Multiple reads of the exact value count as one read.\n- Multiple writes of the exact value count as one write.\n- Multiple reads of the same value, followed by a write to that value, count as one read and one write.\n- A write followed by a read-only counts as one write."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 9, "depth": 3, "title": "Dispatch Classes", "anchor": "dispatch-classes", "start_char": 11264, "end_char": 14004, "estimated_token_count": 573, "token_estimator": "heuristic-v1", "text": "### Dispatch Classes\n\nDispatches are broken into three classes:\n\n- Normal\n- Operational\n- Mandatory\n\nIf a dispatch is not defined as `Operational` or `Mandatory` in the weight annotation, the dispatch is identified as `Normal` by default. You can specify that the dispatchable uses another class like this:\n\n```rust\n-#[pallet::dispatch((DispatchClass::Operational))]\nfn my_dispatchable() {\n    // ...\n}\n```\n\nThis tuple notation also allows you to specify a final argument determining whether the user is charged based on the annotated weight. If you don't specify otherwise, `Pays::Yes` is assumed:\n\n```rust\n-#[pallet::dispatch(DispatchClass::Normal, Pays::No)]\nfn my_dispatchable() {\n    // ...\n}\n```\n\n#### Normal Dispatches\n\nDispatches in this class represent normal user-triggered transactions. These types of dispatches only consume a portion of a block's total weight limit. For information about the maximum portion of a block that can be consumed for normal dispatches, see [`AvailableBlockRatio`](https://paritytech.github.io/polkadot-sdk/master/frame_system/limits/struct.BlockLength.html){target=\\_blank}. Normal dispatches are sent to the transaction pool.\n\n#### Operational Dispatches\n\nUnlike normal dispatches, which represent the usage of network capabilities, operational dispatches are those that provide network capabilities. Operational dispatches can consume the entire weight limit of a block. They are not bound by the [`AvailableBlockRatio`](https://paritytech.github.io/polkadot-sdk/master/frame_system/limits/struct.BlockLength.html){target=\\_blank}. Dispatches in this class are given maximum priority and are exempt from paying the [`length_fee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/){target=\\_blank}.\n\n#### Mandatory Dispatches\n\nMandatory dispatches are included in a block even if they cause the block to surpass its weight limit. You can only use the mandatory dispatch class for inherent transactions that the block author submits. This dispatch class is intended to represent functions in the block validation process. Because these dispatches are always included in a block regardless of the function weight, the validation process must prevent malicious nodes from abusing the function to craft valid but impossibly heavy blocks. You can typically accomplish this by ensuring that:\n\n- The operation performed is always light.\n- The operation can only be included in a block once.\n\nTo make it more difficult for malicious nodes to abuse mandatory dispatches, they cannot be included in blocks that return errors. This dispatch class serves the assumption that it is better to allow an overweight block to be created than not to allow any block to be created at all."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 10, "depth": 3, "title": "Dynamic Weights", "anchor": "dynamic-weights", "start_char": 14004, "end_char": 14552, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### Dynamic Weights\n\nIn addition to purely fixed weights and constants, the weight calculation can consider the input arguments of a dispatchable. The weight should be trivially computable from the input arguments with some basic arithmetic:\n\n```rust\n-use frame_support:: {\n    dispatch:: {\n        DispatchClass::Normal,\n        Pays::Yes,\n    },\n   weights::Weight,\n};\n\n#[pallet::weight(FunctionOf(\n  |args: (&Vec<User>,)| args.0.len().saturating_mul(10_000),\n  )\n]\nfn handle_users(origin, calls: Vec<User>) {\n    // Do something per user\n}\n```"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 11, "depth": 2, "title": "Post Dispatch Weight Correction", "anchor": "post-dispatch-weight-correction", "start_char": 14552, "end_char": 15177, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "## Post Dispatch Weight Correction\n\nDepending on the execution logic, a dispatchable function might consume less weight than was prescribed pre-dispatch. To correct weight, the function declares a different return type and returns its actual weight:\n\n```rust\n-#[pallet::weight(10_000 + 500_000_000)]\nfn expensive_or_cheap(input: u64) -> DispatchResultWithPostInfo {\n    let was_heavy = do_calculation(input);\n\n    if (was_heavy) {\n        // None means \"no correction\" from the weight annotation.\n        Ok(None.into())\n    } else {\n        // Return the actual weight consumed.\n        Ok(Some(10_000).into())\n    }\n}\n```"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 12, "depth": 2, "title": "Custom Fees", "anchor": "custom-fees", "start_char": 15177, "end_char": 15293, "estimated_token_count": 20, "token_estimator": "heuristic-v1", "text": "## Custom Fees\n\nYou can also define custom fee systems through custom weight functions or inclusion fee functions."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 13, "depth": 3, "title": "Custom Weights", "anchor": "custom-weights", "start_char": 15293, "end_char": 19824, "estimated_token_count": 1047, "token_estimator": "heuristic-v1", "text": "### Custom Weights\n\nInstead of using the default weight annotations, you can create a custom weight calculation type using the weights module. The custom weight calculation type must implement the following traits:\n\n- [`WeighData<T>`](https://crates.parity.io/frame_support/weights/trait.WeighData.html){target=\\_blank} to determine the weight of the dispatch.\n- [`ClassifyDispatch<T>`](https://crates.parity.io/frame_support/weights/trait.ClassifyDispatch.html){target=\\_blank} to determine the class of the dispatch.\n- [`PaysFee<T>`](https://crates.parity.io/frame_support/weights/trait.PaysFee.html){target=\\_blank} to determine whether the sender of the dispatch pays fees.\n \nThe Polkadot SDK then bundles the output information of the three traits into the [`DispatchInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_support/dispatch/struct.DispatchInfo.html){target=\\_blank} struct and provides it by implementing the [`GetDispatchInfo`](https://docs.rs/frame-support/latest/frame_support/dispatch/trait.GetDispatchInfo.html){target=\\_blank} for all `Call` variants and opaque extrinsic types. This is used internally by the System and Executive modules.\n\n`ClassifyDispatch`, `WeighData`, and `PaysFee` are generic over T, which gets resolved into the tuple of all dispatch arguments except for the origin. The following example illustrates a struct that calculates the weight as `m * len(args)`, where `m` is a given multiplier and args is the concatenated tuple of all dispatch arguments. In this example, the dispatch class is `Operational` if the transaction has more than 100 bytes of length in arguments and will pay fees if the encoded length exceeds 10 bytes.\n\n```rust\n-struct LenWeight(u32);\nimpl<T> WeighData<T> for LenWeight {\n    fn weigh_data(&self, target: T) -> Weight {\n        let multiplier = self.0;\n        let encoded_len = target.encode().len() as u32;\n        multiplier * encoded_len\n    }\n}\n\nimpl<T> ClassifyDispatch<T> for LenWeight {\n    fn classify_dispatch(&self, target: T) -> DispatchClass {\n        let encoded_len = target.encode().len() as u32;\n        if encoded_len > 100 {\n            DispatchClass::Operational\n        } else {\n            DispatchClass::Normal\n        }\n    }\n}\n\nimpl<T> PaysFee<T> {\n    fn pays_fee(&self, target: T) -> Pays {\n        let encoded_len = target.encode().len() as u32;\n        if encoded_len > 10 {\n            Pays::Yes\n        } else {\n            Pays::No\n        }\n    }\n}\n```\n\nA weight calculator function can also be coerced to the final type of the argument instead of defining it as a vague type that can be encoded. The code would roughly look like this:\n\n```rust\n-struct CustomWeight;\nimpl WeighData<(&u32, &u64)> for CustomWeight {\n    fn weigh_data(&self, target: (&u32, &u64)) -> Weight {\n        ...\n    }\n}\n\n// given a dispatch:\n#[pallet::call]\nimpl<T: Config<I>, I: 'static> Pallet<T, I> {\n    #[pallet::weight(CustomWeight)]\n    fn foo(a: u32, b: u64) { ... }\n}\n```\n\nIn this example, the `CustomWeight` can only be used in conjunction with a dispatch with a particular signature `(u32, u64)`, as opposed to `LenWeight`, which can be used with anything because there aren't any assumptions about `<T>`.\n\n#### Custom Inclusion Fee\n\nThe following example illustrates how to customize your inclusion fee. You must configure the appropriate associated types in the respective module.\n\n```rust\n-// Assume this is the balance type\ntype Balance = u64;\n\n// Assume we want all the weights to have a `100 + 2 * w` conversion to fees\nstruct CustomWeightToFee;\nimpl WeightToFee<Weight, Balance> for CustomWeightToFee {\n    fn convert(w: Weight) -> Balance {\n        let a = Balance::from(100);\n        let b = Balance::from(2);\n        let w = Balance::from(w);\n        a + b * w\n    }\n}\n\nparameter_types! {\n    pub const ExtrinsicBaseWeight: Weight = 10_000_000;\n}\n\nimpl frame_system::Config for Runtime {\n    type ExtrinsicBaseWeight = ExtrinsicBaseWeight;\n}\n\nparameter_types! {\n    pub const TransactionByteFee: Balance = 10;\n}\n\nimpl transaction_payment::Config {\n    type TransactionByteFee = TransactionByteFee;\n    type WeightToFee = CustomWeightToFee;\n    type FeeMultiplierUpdate = TargetedFeeAdjustment<TargetBlockFullness>;\n}\n\nstruct TargetedFeeAdjustment<T>(sp_std::marker::PhantomData<T>);\nimpl<T: Get<Perquintill>> WeightToFee<Fixed128, Fixed128> for TargetedFeeAdjustment<T> {\n    fn convert(multiplier: Fixed128) -> Fixed128 {\n        // Don't change anything. Put any fee update info here.\n        multiplier\n    }\n}\n```"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-fees", "index": 14, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 19824, "end_char": 20800, "estimated_token_count": 225, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nYou now know the weight system, how it affects transaction fee computation, and how to specify weights for your dispatchable calls. The next step is determining the correct weight for your dispatchable operations. You can use Substrate benchmarking functions and frame-benchmarking calls to test your functions with different parameters and empirically determine the proper weight in their worst-case scenarios.\n\n- [Benchmark](/develop/parachains/testing/benchmarking/)\n- [`SignedExtension`](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/traits/trait.SignedExtension.html){target=\\_blank}\n- [Custom weights for the Example pallet](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506/substrate/frame/examples/basic/src/weights.rs){target=\\_blank}\n- [Web3 Foundation Research](https://research.web3.foundation/Polkadot/overview/token-economics#relay-chain-transaction-fees-and-per-block-transaction-limits){target=\\_blank}"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 655, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nTransactions are essential components of blockchain networks, enabling state changes and the execution of key operations. In the Polkadot SDK, transactions, often called extrinsics, come in multiple forms, including signed, unsigned, and inherent transactions.\n\nThis guide walks you through the different transaction types and how they're formatted, validated, and processed within the Polkadot ecosystem. You'll also learn how to customize transaction formats and construct transactions for FRAME-based runtimes, ensuring a complete understanding of how transactions are built and executed in Polkadot SDK-based chains."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 1, "depth": 2, "title": "What Is a Transaction?", "anchor": "what-is-a-transaction", "start_char": 655, "end_char": 1674, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## What Is a Transaction?\n\nIn the Polkadot SDK, transactions represent operations that modify the chain's state, bundled into blocks for execution. The term extrinsic is often used to refer to any data that originates outside the runtime and is included in the chain. While other blockchain systems typically refer to these operations as \"transactions,\" the Polkadot SDK adopts the broader term \"extrinsic\" to capture the wide variety of data types that can be added to a block.\n\nThere are three primary types of transactions (extrinsics) in the Polkadot SDK:\n\n- **Signed transactions**: Signed by the submitting account, often carrying transaction fees.\n- **Unsigned transactions**: Submitted without a signature, often requiring custom validation logic.\n- **Inherent transactions**: Typically inserted directly into blocks by block authoring nodes, without gossiping between peers.\n\nEach type serves a distinct purpose, and understanding when and how to use each is key to efficiently working with the Polkadot SDK."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 2, "depth": 3, "title": "Signed Transactions", "anchor": "signed-transactions", "start_char": 1674, "end_char": 2838, "estimated_token_count": 221, "token_estimator": "heuristic-v1", "text": "### Signed Transactions\n\nSigned transactions require an account's signature and typically involve submitting a request to execute a runtime call. The signature serves as a form of cryptographic proof that the sender has authorized the action, using their private key. These transactions often involve a transaction fee to cover the cost of execution and incentivize block producers.\n\nSigned transactions are the most common type of transaction and are integral to user-driven actions, such as token transfers. For instance, when you transfer tokens from one account to another, the sending account must sign the transaction to authorize the operation.\n\nFor example, the [`pallet_balances::Call::transfer_allow_death`](https://paritytech.github.io/polkadot-sdk/master/pallet_balances/pallet/struct.Pallet.html#method.transfer_allow_death){target=\\_blank} extrinsic in the Balances pallet allows you to transfer tokens. Since your account initiates this transaction, your account key is used to sign it. You'll also be responsible for paying the associated transaction fee, with the option to include an additional tip to incentivize faster inclusion in the block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 3, "depth": 3, "title": "Unsigned Transactions", "anchor": "unsigned-transactions", "start_char": 2838, "end_char": 4091, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "### Unsigned Transactions\n\nUnsigned transactions do not require a signature or account-specific data from the sender. Unlike signed transactions, they do not come with any form of economic deterrent, such as fees, which makes them susceptible to spam or replay attacks. Custom validation logic must be implemented to mitigate these risks and ensure these transactions are secure.\n\nUnsigned transactions typically involve scenarios where including a fee or signature is unnecessary or counterproductive. However, due to the absence of fees, they require careful validation to protect the network. For example, [`pallet_im_online::Call::heartbeat`](https://paritytech.github.io/polkadot-sdk/master/pallet_im_online/pallet/struct.Pallet.html#method.heartbeat){target=\\_blank} extrinsic allows validators to send a heartbeat signal, indicating they are active. Since only validators can make this call, the logic embedded in the transaction ensures that the sender is a validator, making the need for a signature or fee redundant.\n\nUnsigned transactions are more resource-intensive than signed ones because custom validation is required, but they play a crucial role in certain operational scenarios, especially when regular user accounts aren't involved."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 4, "depth": 3, "title": "Inherent Transactions", "anchor": "inherent-transactions", "start_char": 4091, "end_char": 5815, "estimated_token_count": 327, "token_estimator": "heuristic-v1", "text": "### Inherent Transactions\n\nInherent transactions are a specialized type of unsigned transaction that is used primarily for block authoring. Unlike signed or other unsigned transactions, inherent transactions are added directly by block producers and are not broadcasted to the network or stored in the transaction queue. They don't require signatures or the usual validation steps and are generally used to insert system-critical data directly into blocks.\n\nA key example of an inherent transaction is inserting a timestamp into each block. The [`pallet_timestamp::Call::now`](https://paritytech.github.io/polkadot-sdk/master/pallet_timestamp/pallet/struct.Pallet.html#method.now-1){target=\\_blank} extrinsic allows block authors to include the current time in the block they are producing. Since the block producer adds this information, there is no need for transaction validation, like signature verification. The validation in this case is done indirectly by the validators, who check whether the timestamp is within an acceptable range before finalizing the block.\n\nAnother example is the [`paras_inherent::Call::enter`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/paras_inherent/pallet/struct.Pallet.html#method.enter){target=\\_blank} extrinsic, which enables parachain collator nodes to send validation data to the relay chain. This inherent transaction ensures that the necessary parachain data is included in each block without the overhead of gossiped transactions.\n\nInherent transactions serve a critical role in block authoring by allowing important operational data to be added directly to the chain without needing the validation processes required for standard transactions."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 5, "depth": 2, "title": "Transaction Formats", "anchor": "transaction-formats", "start_char": 5815, "end_char": 6164, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Transaction Formats\n\nUnderstanding the structure of signed and unsigned transactions is crucial for developers building on Polkadot SDK-based chains. Whether you're optimizing transaction processing, customizing formats, or interacting with the transaction pool, knowing the format of extrinsics, Polkadot's term for transactions, is essential."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 6, "depth": 3, "title": "Types of Transaction Formats", "anchor": "types-of-transaction-formats", "start_char": 6164, "end_char": 7058, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "### Types of Transaction Formats\n\nIn Polkadot SDK-based chains, extrinsics can fall into three main categories:\n\n- **Unchecked extrinsics**: Typically used for signed transactions that require validation. They contain a signature and additional data, such as a nonce and information for fee calculation. Unchecked extrinsics are named as such because they require validation checks before being accepted into the transaction pool.\n- **Checked extrinsics**: Typically used for inherent extrinsics (unsigned transactions); these don't require signature verification. Instead, they carry information such as where the extrinsic originates and any additional data required for the block authoring process.\n- **Opaque extrinsics**: Used when the format of an extrinsic is not yet fully committed or finalized. They are still decodable, but their structure can be flexible depending on the context."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 7, "depth": 3, "title": "Signed Transaction Data Structure", "anchor": "signed-transaction-data-structure", "start_char": 7058, "end_char": 8020, "estimated_token_count": 195, "token_estimator": "heuristic-v1", "text": "### Signed Transaction Data Structure\n\nA signed transaction typically includes the following components:\n\n- **Signature**: Verifies the authenticity of the transaction sender.\n- **Call**: The actual function or method call the transaction is requesting (for example, transferring funds).\n- **Nonce**: Tracks the number of prior transactions sent from the account, helping to prevent replay attacks.\n- **Tip**: An optional incentive to prioritize the transaction in block inclusion.\n- **Additional data**: Includes details such as spec version, block hash, and genesis hash to ensure the transaction is valid within the correct runtime and chain context.\n\nHere's a simplified breakdown of how signed transactions are typically constructed in a Polkadot SDK runtime:\n\n``` code\n<signing account ID> + <signature> + <additional data>\n```\n\nEach part of the signed transaction has a purpose, ensuring the transaction's authenticity and context within the blockchain."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 8, "depth": 3, "title": "Signed Extensions", "anchor": "signed-extensions", "start_char": 8020, "end_char": 10654, "estimated_token_count": 610, "token_estimator": "heuristic-v1", "text": "### Signed Extensions\n\nPolkadot SDK also provides the concept of [signed extensions](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/signed_extensions/index.html){target=\\_blank}, which allow developers to extend extrinsics with additional data or validation logic before they are included in a block. The [`SignedExtension`](https://paritytech.github.io/try-runtime-cli/sp_runtime/traits/trait.SignedExtension.html){target=\\_blank} set helps enforce custom rules or protections, such as ensuring the transaction's validity or calculating priority.\n\nThe transaction queue regularly calls signed extensions to verify a transaction's validity before placing it in the ready queue. This safeguard ensures transactions won't fail in a block. Signed extensions are commonly used to enforce validation logic and protect the transaction pool from spam and replay attacks.\n\nIn FRAME, a signed extension can hold any of the following types by default:\n\n- **[`AccountId`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/runtime/types_common/type.AccountId.html){target=\\_blank}**: To encode the sender's identity.\n- **[`Call`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/traits/trait.SignedExtension.html#associatedtype.Call){target=\\_blank}**: To encode the pallet call to be dispatched. This data is used to calculate transaction fees.\n- **[`AdditionalSigned`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/traits/trait.SignedExtension.html#associatedtype.AdditionalSigned){target=\\_blank}**: To handle any additional data to go into the signed payload allowing you to attach any custom logic prior to dispatching a transaction.\n- **[`Pre`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/traits/trait.SignedExtension.html#associatedtype.Pre){target=\\_blank}**: To encode the information that can be passed from before a call is dispatched to after it gets dispatched.\n\nSigned extensions can enforce checks like:\n\n- **[`CheckSpecVersion`](https://paritytech.github.io/polkadot-sdk/master/src/frame_system/extensions/check_spec_version.rs.html){target=\\_blank}**: Ensures the transaction is compatible with the runtime's current version.\n- **[`CheckWeight`](https://paritytech.github.io/polkadot-sdk/master/frame_system/struct.CheckWeight.html){target=\\_blank}**: Calculates the weight (or computational cost) of the transaction, ensuring the block doesn't exceed the maximum allowed weight.\n\nThese extensions are critical in the transaction lifecycle, ensuring that only valid and prioritized transactions are processed."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 9, "depth": 2, "title": "Transaction Construction", "anchor": "transaction-construction", "start_char": 10654, "end_char": 10991, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Transaction Construction\n\nBuilding transactions in the Polkadot SDK involves constructing a payload that can be verified, signed, and submitted for inclusion in a block. Each runtime in the Polkadot SDK has its own rules for validating and executing transactions, but there are common patterns for constructing a signed transaction."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 10, "depth": 3, "title": "Construct a Signed Transaction", "anchor": "construct-a-signed-transaction", "start_char": 10991, "end_char": 12901, "estimated_token_count": 405, "token_estimator": "heuristic-v1", "text": "### Construct a Signed Transaction\n\nA signed transaction in the Polkadot SDK includes various pieces of data to ensure security, prevent replay attacks, and prioritize processing. Here's an overview of how to construct one:\n\n1. **Construct the unsigned payload**: Gather the necessary information for the call, including:\n\n    - **Pallet index**: Identifies the pallet where the runtime function resides.\n    - **Function index**: Specifies the particular function to call in the pallet.\n    - **Parameters**: Any additional arguments required by the function call.\n\n2. **Create a signing payload**: Once the unsigned payload is ready, additional data must be included:\n\n    - **Transaction nonce**: Unique identifier to prevent replay attacks.\n    - **Era information**: Defines how long the transaction is valid before it's dropped from the pool.\n    - **Block hash**: Ensures the transaction doesn't execute on the wrong chain or fork.\n\n3. **Sign the payload**: Using the sender's private key, sign the payload to ensure that the transaction can only be executed by the account holder.\n4. **Serialize the signed payload**: Once signed, the transaction must be serialized into a binary format, ensuring the data is compact and easy to transmit over the network.\n5. **Submit the serialized transaction**: Finally, submit the serialized transaction to the network, where it will enter the transaction pool and wait for processing by an authoring node.\n\nThe following is an example of how a signed transaction might look:\n\n``` rust\n-node_runtime::UncheckedExtrinsic::new_signed(\n    function.clone(),                                      // some call\n    sp_runtime::AccountId32::from(sender.public()).into(), // some sending account\n    node_runtime::Signature::Sr25519(signature.clone()),   // the account's signature\n    extra.clone(),                                         // the signed extensions\n)\n```"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 11, "depth": 3, "title": "Transaction Encoding", "anchor": "transaction-encoding", "start_char": 12901, "end_char": 13899, "estimated_token_count": 225, "token_estimator": "heuristic-v1", "text": "### Transaction Encoding\n\nBefore a transaction is sent to the network, it is serialized and encoded using a structured encoding process that ensures consistency and prevents tampering:\n\n- **`[1]`**: Compact encoded length in bytes of the entire transaction.\n- **`[2]`**: A u8 containing 1 byte to indicate whether the transaction is signed or unsigned (1 bit) and the encoded transaction version ID (7 bits).\n- **`[3]`**: If signed, this field contains an account ID, an SR25519 signature, and some extra data.\n- **`[4]`**: Encoded call data, including pallet and function indices and any required arguments.\n\nThis encoded format ensures consistency and efficiency in processing transactions across the network. By adhering to this format, applications can construct valid transactions and pass them to the network for execution.\n\nTo learn more about how compact encoding works using SCALE, see the [SCALE Codec](https://github.com/paritytech/parity-scale-codec){target=\\_blank} README on GitHub."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 12, "depth": 3, "title": "Customize Transaction Construction", "anchor": "customize-transaction-construction", "start_char": 13899, "end_char": 14539, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Customize Transaction Construction\n\nAlthough the basic steps for constructing transactions are consistent across Polkadot SDK-based chains, developers can customize transaction formats and validation rules. For example:\n\n- **Custom pallets**: You can define new pallets with custom function calls, each with its own parameters and validation logic.\n- **Signed extensions**: Developers can implement custom extensions that modify how transactions are prioritized, validated, or included in blocks.\n\nBy leveraging Polkadot SDK's modular design, developers can create highly specialized transaction logic tailored to their chain's needs."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 13, "depth": 2, "title": "Lifecycle of a Transaction", "anchor": "lifecycle-of-a-transaction", "start_char": 14539, "end_char": 15017, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Lifecycle of a Transaction\n\nIn the Polkadot SDK, transactions are often referred to as extrinsics because the data in transactions originates outside of the runtime. These transactions contain data that initiates changes to the chain state. The most common type of extrinsic is a signed transaction, which is cryptographically verified and typically incurs a fee. This section focuses on how signed transactions are processed, validated, and ultimately included in a block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 14, "depth": 3, "title": "Define Transaction Properties", "anchor": "define-transaction-properties", "start_char": 15017, "end_char": 15748, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "### Define Transaction Properties\n\nThe Polkadot SDK runtime defines key transaction properties, such as:\n\n- **Transaction validity**: Ensures the transaction meets all runtime requirements.\n- **Signed or unsigned**: Identifies whether a transaction needs to be signed by an account.\n- **State changes**: Determines how the transaction modifies the state of the chain.\n\nPallets, which compose the runtime's logic, define the specific transactions that your chain supports. When a user submits a transaction, such as a token transfer, it becomes a signed transaction, verified by the user's account signature. If the account has enough funds to cover fees, the transaction is executed, and the chain's state is updated accordingly."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 15, "depth": 3, "title": "Process on a Block Authoring Node", "anchor": "process-on-a-block-authoring-node", "start_char": 15748, "end_char": 16439, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Process on a Block Authoring Node\n\nIn Polkadot SDK-based networks, some nodes are authorized to author blocks. These nodes validate and process transactions. When a transaction is sent to a node that can produce blocks, it undergoes a lifecycle that involves several stages, including validation and execution. Non-authoring nodes gossip the transaction across the network until an authoring node receives it. The following diagram illustrates the lifecycle of a transaction that's submitted to a network and processed by an authoring node.\n\n![Transaction lifecycle diagram](/images/polkadot-protocol/parachain-basics/blocks-transactions-fees/transactions/transaction-lifecycle-1.webp)"}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 16, "depth": 3, "title": "Validate and Queue", "anchor": "validate-and-queue", "start_char": 16439, "end_char": 18683, "estimated_token_count": 436, "token_estimator": "heuristic-v1", "text": "### Validate and Queue\n\nOnce a transaction reaches an authoring node, it undergoes an initial validation process to ensure it meets specific conditions defined in the runtime. This validation includes checks for:\n\n- **Correct nonce**: Ensures the transaction is sequentially valid for the account.\n- **Sufficient funds**: Confirms the account can cover any associated transaction fees.\n- **Signature validity**: Verifies that the sender's signature matches the transaction data.\n\nAfter these checks, valid transactions are placed in the transaction pool, where they are queued for inclusion in a block. The transaction pool regularly re-validates queued transactions to ensure they remain valid before being processed. To reach consensus, two-thirds of the nodes must agree on the order of the transactions executed and the resulting state change. Transactions are validated and queued on the local node in a transaction pool to prepare for consensus.\n\n#### Transaction Pool\n\nThe transaction pool is responsible for managing valid transactions. It ensures that only transactions that pass initial validity checks are queued. Transactions that fail validation, expire, or become invalid for other reasons are removed from the pool.\n\nThe transaction pool organizes transactions into two queues:\n\n- **Ready queue**: Transactions that are valid and ready to be included in a block.\n- **Future queue**: Transactions that are not yet valid but could be in the future, such as transactions with a nonce too high for the current state.\n\nDetails on how the transaction pool validates transactions, including fee and signature handling, can be found in the [`validate_transaction`](https://paritytech.github.io/polkadot-sdk/master/sp_transaction_pool/runtime_api/trait.TaggedTransactionQueue.html#method.validate_transaction){target=\\_blank} method.\n\n#### Invalid Transactions\n\nIf a transaction is invalid, for example, due to an invalid signature or insufficient funds, it is rejected and won't be added to the block. Invalid transactions might be rejected for reasons such as:\n\n- The transaction has already been included in a block.\n- The transaction's signature does not match the sender.\n- The transaction is too large to fit in the current block."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 17, "depth": 3, "title": "Transaction Ordering and Priority", "anchor": "transaction-ordering-and-priority", "start_char": 18683, "end_char": 19321, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "### Transaction Ordering and Priority\n\nWhen a node is selected as the next block author, it prioritizes transactions based on weight, length, and tip amount. The goal is to fill the block with high-priority transactions without exceeding its maximum size or computational limits. Transactions are ordered as follows:\n\n- **Inherents first**: Inherent transactions, such as block timestamp updates, are always placed first.\n- **Nonce-based ordering**: Transactions from the same account are ordered by their nonce.\n- **Fee-based ordering**: Among transactions with the same nonce or priority level, those with higher fees are prioritized."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 18, "depth": 3, "title": "Transaction Execution", "anchor": "transaction-execution", "start_char": 19321, "end_char": 19938, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "### Transaction Execution\n\nOnce a block author selects transactions from the pool, the transactions are executed in priority order. As each transaction is processed, the state changes are written directly to the chain's storage. It's important to note that these changes are not cached, meaning a failed transaction won't revert earlier state changes, which could leave the block in an inconsistent state.\n\nEvents are also written to storage. Runtime logic should not emit an event before performing the associated actions. If the associated transaction fails after the event was emitted, the event will not revert."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 19, "depth": 2, "title": "Transaction Mortality", "anchor": "transaction-mortality", "start_char": 19938, "end_char": 21469, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "## Transaction Mortality\n\nTransactions in the network can be configured as either mortal (with expiration) or immortal (without expiration). Every transaction payload contains a block checkpoint (reference block number and hash) and an era/validity period that determines how many blocks after the checkpoint the transaction remains valid.\n\nWhen a transaction is submitted, the network validates it against these parameters. If the transaction is not included in a block within the specified validity window, it is automatically removed from the transaction queue.\n\n- **Mortal transactions**: Have a finite lifespan and will expire after a specified number of blocks. For example, a transaction with a block checkpoint of 1000 and a validity period of 64 blocks will be valid from blocks 1000 to 1064.\n\n- **Immortal transactions**: Never expire and remain valid indefinitely. To create an immortal transaction, set the block checkpoint to 0 (genesis block), use the genesis hash as a reference, and set the validity period to 0.\n\nHowever, immortal transactions pose significant security risks through replay attacks. If an account is reaped (balance drops to zero, account removed) and later re-funded, malicious actors can replay old immortal transactions.\n\nThe blockchain maintains only a limited number of prior block hashes for reference validation, called `BlockHashCount`. If your validity period exceeds `BlockHashCount`, the effective validity period becomes the minimum of your specified period and the block hash count."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 20, "depth": 2, "title": "Unique Identifiers for Extrinsics", "anchor": "unique-identifiers-for-extrinsics", "start_char": 21469, "end_char": 23365, "estimated_token_count": 427, "token_estimator": "heuristic-v1", "text": "## Unique Identifiers for Extrinsics\n\nTransaction hashes are **not unique identifiers** in Polkadot SDK-based chains.\n\nKey differences from traditional blockchains:\n\n- Transaction hashes serve only as fingerprints of transaction information.\n- Multiple valid transactions can share the same hash.\n- Hash uniqueness assumptions lead to serious issues.\n\nFor example, when an account is reaped (removed due to insufficient balance) and later recreated, it resets to nonce 0, allowing identical transactions to be valid at different points:\n\n| Block | Extrinsic Index | Hash | Origin    | Nonce | Call                | Result                        |\n|-------|----------------|------|-----------|-------|---------------------|-------------------------------|\n| 100   | 0              | 0x01 | Account A | 0     | Transfer 5 DOT to B | Account A reaped              |\n| 150   | 5              | 0x02 | Account B | 4     | Transfer 7 DOT to A | Account A created (nonce = 0) |\n| 200   | 2              | 0x01 | Account A | 0     | Transfer 5 DOT to B | Successful transaction        |\n\nNotice that blocks 100 and 200 contain transactions with identical hashes (0x01) but are completely different, valid operations occurring at different times.\n\nAdditional complexity comes from Polkadot SDK's origin abstraction. Origins can represent collectives, governance bodies, or other non-account entities that don't maintain nonces like regular accounts and might dispatch identical calls multiple times with the same hash values. Each execution occurs in different chain states with different results.\n\nThe correct way to uniquely identify an extrinsic on a Polkadot SDK-based chain is to use the block ID (height or hash) and the extrinsic index. Since the Polkadot SDK defines blocks as headers plus ordered arrays of extrinsics, the index position within a canonical block provides guaranteed uniqueness."}
{"page_id": "polkadot-protocol-parachain-basics-blocks-transactions-fees-transactions", "index": 21, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 23365, "end_char": 23605, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nFor a video overview of the lifecycle of transactions and the types of transactions that exist, see the [Transaction lifecycle](https://www.youtube.com/watch?v=3pfM0GOp02c){target=\\_blank} seminar from Parity Tech."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 612, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUnderstanding and leveraging on-chain data is a fundamental aspect of blockchain development. Whether you're building frontend applications or backend systems, accessing and decoding runtime metadata is vital to interacting with the blockchain. This guide introduces you to the tools and processes for generating and retrieving metadata, explains its role in application development, and outlines the additional APIs available for interacting with a Polkadot node. By mastering these components, you can ensure seamless communication between your applications and the blockchain."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 1, "depth": 2, "title": "Application Development", "anchor": "application-development", "start_char": 612, "end_char": 1674, "estimated_token_count": 195, "token_estimator": "heuristic-v1", "text": "## Application Development\n\nYou might not be directly involved in building frontend applications as a blockchain developer. However, most applications that run on a blockchain require some form of frontend or user-facing client to enable users or other programs to access and modify the data that the blockchain stores. For example, you might develop a browser-based, mobile, or desktop application that allows users to submit transactions, post articles, view their assets, or track previous activity. The backend for that application is configured in the runtime logic for your blockchain, but the frontend client makes the runtime features accessible to your users.\n\nFor your custom chain to be useful to others, you'll need to provide a client application that allows users to view, interact with, or update information that the blockchain keeps track of. In this article, you'll learn how to expose information about your runtime so that client applications can use it, see examples of the information exposed, and explore tools and libraries that use it."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 2, "depth": 2, "title": "Understand Metadata", "anchor": "understand-metadata", "start_char": 1674, "end_char": 2288, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Understand Metadata\n\nPolkadot SDK-based blockchain networks are designed to expose their runtime information, allowing developers to learn granular details regarding pallets, RPC calls, and runtime APIs. The metadata also exposes their related documentation. The chain's metadata is [SCALE-encoded](/polkadot-protocol/parachain-basics/data-encoding/){target=\\_blank}, allowing for the development of browser-based, mobile, or desktop applications to support the chain's runtime upgrades seamlessly. It is also possible to develop applications compatible with multiple Polkadot SDK-based chains simultaneously."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 3, "depth": 2, "title": "Expose Runtime Information as Metadata", "anchor": "expose-runtime-information-as-metadata", "start_char": 2288, "end_char": 3887, "estimated_token_count": 282, "token_estimator": "heuristic-v1", "text": "## Expose Runtime Information as Metadata\n\nTo interact with a node or the state of the blockchain, you need to know how to connect to the chain and access the exposed runtime features. This interaction involves a Remote Procedure Call (RPC) through a node endpoint address, commonly through a secure web socket connection.\n\nAn application developer typically needs to know the contents of the runtime logic, including the following details:\n\n- Version of the runtime the application is connecting to.\n- Supported APIs.\n- Implemented pallets.\n- Defined functions and corresponding type signatures.\n- Defined custom types.\n- Exposed parameters users can set.\n\nAs the Polkadot SDK is modular and provides a composable framework for building blockchains, there are limitless opportunities to customize the schema of properties. Each runtime can be configured with its properties, including function calls and types, which can be changed over time with runtime upgrades.\n\nThe Polkadot SDK enables you to generate the runtime metadata schema to capture information unique to a runtime. The metadata for a runtime describes the pallets in use and types defined for a specific runtime version. The metadata includes information about each pallet's storage items, functions, events, errors, and constants. The metadata also provides type definitions for any custom types included in the runtime.\n\nMetadata provides a complete inventory of a chain's runtime. It is key to enabling client applications to interact with the node, parse responses, and correctly format message payloads sent back to that chain."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 4, "depth": 2, "title": "Generate Metadata", "anchor": "generate-metadata", "start_char": 3887, "end_char": 5193, "estimated_token_count": 297, "token_estimator": "heuristic-v1", "text": "## Generate Metadata\n\nTo efficiently use the blockchain's networking resources and minimize the data transmitted over the network, the metadata schema is encoded using the [Parity SCALE Codec](https://github.com/paritytech/parity-scale-codec?tab=readme-ov-file#parity-scale-codec){target=\\_blank}. This encoding is done automatically through the [`scale-info`](https://docs.rs/scale-info/latest/scale_info/){target=\\_blank}crate.\n\nAt a high level, generating the metadata involves the following steps:\n\n1. The pallets in the runtime logic expose callable functions, types, parameters, and documentation that need to be encoded in the metadata.\n2. The `scale-info` crate collects type information for the pallets in the runtime, builds a registry of the pallets that exist in a particular runtime, and the relevant types for each pallet in the registry. The type information is detailed enough to enable encoding and decoding for every type.\n3. The [`frame-metadata`](https://github.com/paritytech/frame-metadata){target=\\_blank} crate describes the structure of the runtime based on the registry provided by the `scale-info` crate.\n4. Nodes provide the RPC method `state_getMetadata` to return a complete description of all the types in the current runtime as a hex-encoded vector of SCALE-encoded bytes."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 5, "depth": 2, "title": "Retrieve Runtime Metadata", "anchor": "retrieve-runtime-metadata", "start_char": 5193, "end_char": 5709, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Retrieve Runtime Metadata\n\nThe type information provided by the metadata enables applications to communicate with nodes using different runtime versions and across chains that expose different calls, events, types, and storage items. The metadata also allows libraries to generate a substantial portion of the code needed to communicate with a given node, enabling libraries like [`subxt`](https://github.com/paritytech/subxt){target=\\_blank} to generate frontend interfaces that are specific to a target chain."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 6, "depth": 3, "title": "Use Polkadot.js", "anchor": "use-polkadotjs", "start_char": 5709, "end_char": 6160, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "### Use Polkadot.js\n\nVisit the [Polkadot.js Portal](https://polkadot.js.org/apps/#/rpc){target=\\_blank} and select the **Developer** dropdown in the top banner. Select **RPC Calls** to make the call to request metadata. Follow these steps to make the RPC call:\n\n1. Select **state** as the endpoint to call.\n2. Select **`getMetadata(at)`** as the method to call.\n3. Click **Submit RPC call** to submit the call and return the metadata in JSON format."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 7, "depth": 3, "title": "Use Curl", "anchor": "use-curl", "start_char": 6160, "end_char": 6474, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "### Use Curl \n\nYou can fetch the metadata for the network by calling the node's RPC endpoint. This request returns the metadata in bytes rather than human-readable JSON:\n\n```sh\ncurl -H \"Content-Type: application/json\" \\\n-d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"state_getMetadata\"}' \\\nhttps://rpc.polkadot.io\n\n```"}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 8, "depth": 3, "title": "Use Subxt", "anchor": "use-subxt", "start_char": 6474, "end_char": 6840, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "### Use Subxt\n\n[`subxt`](https://github.com/paritytech/subxt){target=\\_blank} may also be used to fetch the metadata of any data in a human-readable JSON format: \n\n```sh\nsubxt metadata  --url wss://rpc.polkadot.io --format json > spec.json\n```\n\nAnother option is to use the [`subxt` explorer web UI](https://paritytech.github.io/subxt-explorer/#/){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 9, "depth": 2, "title": "Client Applications and Metadata", "anchor": "client-applications-and-metadata", "start_char": 6840, "end_char": 7393, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Client Applications and Metadata\n\nThe metadata exposes the expected way to decode each type, meaning applications can send, retrieve, and process application information without manual encoding and decoding. Client applications must use the [SCALE codec library](https://github.com/paritytech/parity-scale-codec?tab=readme-ov-file#parity-scale-codec){target=\\_blank} to encode and decode RPC payloads to use the metadata. Client applications use the metadata to interact with the node, parse responses, and format message payloads sent to the node."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 10, "depth": 2, "title": "Metadata Format", "anchor": "metadata-format", "start_char": 7393, "end_char": 9590, "estimated_token_count": 471, "token_estimator": "heuristic-v1", "text": "## Metadata Format\n\nAlthough the SCALE-encoded bytes can be decoded using the `frame-metadata` and [`parity-scale-codec`](https://github.com/paritytech/parity-scale-codec){target=\\_blank} libraries, there are other tools, such as `subxt` and the Polkadot-JS API, that can convert the raw data to human-readable JSON format.\n\nThe types and type definitions included in the metadata returned by the `state_getMetadata` RPC call depend on the runtime's metadata version.\n\nIn general, the metadata includes the following information:\n\n- A constant identifying the file as containing metadata.\n- The version of the metadata format used in the runtime.\n- Type definitions for all types used in the runtime and generated by the `scale-info` crate.\n- Pallet information for the pallets included in the runtime in the order that they are defined in the `construct_runtime` macro.\n\n!!!tip \n    Depending on the frontend library used (such as the [Polkadot API](https://papi.how/){target=\\_blank}), they may format the metadata differently than the raw format shown.\n\nThe following example illustrates a condensed and annotated section of metadata decoded and converted to JSON:\n\n```json\n-[\n    1635018093,\n    {\n        \"V14\": {\n            \"types\": {\n                \"types\": [{}]\n            },\n            \"pallets\": [{}],\n            \"extrinsic\": {\n                \"ty\": 126,\n                \"version\": 4,\n                \"signed_extensions\": [{}]\n            },\n            \"ty\": 141\n        }\n    }\n]\n\n```\n\nThe constant `1635018093` is a magic number that identifies the file as a metadata file. The rest of the metadata is divided into the `types`, `pallets`, and `extrinsic` sections:\n\n- The `types` section contains an index of the types and information about each type's type signature.\n- The `pallets` section contains information about each pallet in the runtime.\n- The `extrinsic` section describes the type identifier and transaction format version that the runtime uses.\n\nDifferent extrinsic versions can have varying formats, especially when considering [signed transactions](/polkadot-protocol/parachain-basics/blocks-transactions-fees/transactions/#signed-transactions){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 11, "depth": 3, "title": "Pallets", "anchor": "pallets", "start_char": 9590, "end_char": 15112, "estimated_token_count": 988, "token_estimator": "heuristic-v1", "text": "### Pallets\n\nThe following is a condensed and annotated example of metadata for a single element in the `pallets` array (the [`sudo`](https://paritytech.github.io/polkadot-sdk/master/pallet_sudo/index.html){target=\\_blank} pallet):\n\n```json\n-{\n    \"name\": \"Sudo\",\n    \"storage\": {\n        \"prefix\": \"Sudo\",\n        \"entries\": [\n            {\n                \"name\": \"Key\",\n                \"modifier\": \"Optional\",\n                \"ty\": {\n                    \"Plain\": 0\n                },\n                \"default\": [0],\n                \"docs\": [\"The `AccountId` of the sudo key.\"]\n            }\n        ]\n    },\n    \"calls\": {\n        \"ty\": 117\n    },\n    \"event\": {\n        \"ty\": 42\n    },\n    \"constants\": [],\n    \"error\": {\n        \"ty\": 124\n    },\n    \"index\": 8\n}\n\n```\n\nEvery element metadata contains the name of the pallet it represents and information about its storage, calls, events, and errors. You can look up details about the definition of the calls, events, and errors by viewing the type index identifier. The type index identifier is the `u32` integer used to access the type information for that item. For example, the type index identifier for calls in the Sudo pallet is 117. If you view information for that type identifier in the `types` section of the metadata, it provides information about the available calls, including the documentation for each call.\n\nFor example, the following is a condensed excerpt of the calls for the Sudo pallet:\n\n```json\n-{\n    \"id\": 117,\n    \"type\": {\n        \"path\": [\"pallet_sudo\", \"pallet\", \"Call\"],\n        \"params\": [\n            {\n                \"name\": \"T\",\n                \"type\": null\n            }\n        ],\n        \"def\": {\n            \"variant\": {\n                \"variants\": [\n                    {\n                        \"name\": \"sudo\",\n                        \"fields\": [\n                            {\n                                \"name\": \"call\",\n                                \"type\": 114,\n                                \"typeName\": \"Box<<T as Config>::RuntimeCall>\"\n                            }\n                        ],\n                        \"index\": 0,\n                        \"docs\": [\n                            \"Authenticates sudo key, dispatches a function call with `Root` origin\"\n                        ]\n                    },\n                    {\n                        \"name\": \"sudo_unchecked_weight\",\n                        \"fields\": [\n                            {\n                                \"name\": \"call\",\n                                \"type\": 114,\n                                \"typeName\": \"Box<<T as Config>::RuntimeCall>\"\n                            },\n                            {\n                                \"name\": \"weight\",\n                                \"type\": 8,\n                                \"typeName\": \"Weight\"\n                            }\n                        ],\n                        \"index\": 1,\n                        \"docs\": [\n                            \"Authenticates sudo key, dispatches a function call with `Root` origin\"\n                        ]\n                    },\n                    {\n                        \"name\": \"set_key\",\n                        \"fields\": [\n                            {\n                                \"name\": \"new\",\n                                \"type\": 103,\n                                \"typeName\": \"AccountIdLookupOf<T>\"\n                            }\n                        ],\n                        \"index\": 2,\n                        \"docs\": [\n                            \"Authenticates current sudo key, sets the given AccountId (`new`) as the new sudo\"\n                        ]\n                    },\n                    {\n                        \"name\": \"sudo_as\",\n                        \"fields\": [\n                            {\n                                \"name\": \"who\",\n                                \"type\": 103,\n                                \"typeName\": \"AccountIdLookupOf<T>\"\n                            },\n                            {\n                                \"name\": \"call\",\n                                \"type\": 114,\n                                \"typeName\": \"Box<<T as Config>::RuntimeCall>\"\n                            }\n                        ],\n                        \"index\": 3,\n                        \"docs\": [\n                            \"Authenticates sudo key, dispatches a function call with `Signed` origin from a given account\"\n                        ]\n                    }\n                ]\n            }\n        }\n    }\n}\n\n```\n\nFor each field, you can access type information and metadata for the following:\n\n- **Storage metadata**: Provides the information required to enable applications to get information for specific storage items.\n- **Call metadata**: Includes information about the runtime calls defined by the `#[pallet]` macro including call names, arguments and documentation.\n- **Event metadata**: Provides the metadata generated by the `#[pallet::event]` macro, including the name, arguments, and documentation for each pallet event.\n- **Constants metadata**: Provides metadata generated by the `#[pallet::constant]` macro, including the name, type, and hex-encoded value of the constant.\n- **Error metadata**: Provides metadata generated by the `#[pallet::error]` macro, including the name and documentation for each pallet error.\n\n!!!tip\n    Type identifiers change from time to time, so you should avoid relying on specific type identifiers in your applications."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 12, "depth": 3, "title": "Extrinsic", "anchor": "extrinsic", "start_char": 15112, "end_char": 17237, "estimated_token_count": 385, "token_estimator": "heuristic-v1", "text": "### Extrinsic\n\nThe runtime generates extrinsic metadata and provides useful information about transaction format. When decoded, the metadata contains the transaction version and the list of signed extensions.\n\nFor example:\n\n```json\n-{\n    \"extrinsic\": {\n        \"ty\": 126,\n        \"version\": 4,\n        \"signed_extensions\": [\n            {\n                \"identifier\": \"CheckNonZeroSender\",\n                \"ty\": 132,\n                \"additional_signed\": 41\n            },\n            {\n                \"identifier\": \"CheckSpecVersion\",\n                \"ty\": 133,\n                \"additional_signed\": 4\n            },\n            {\n                \"identifier\": \"CheckTxVersion\",\n                \"ty\": 134,\n                \"additional_signed\": 4\n            },\n            {\n                \"identifier\": \"CheckGenesis\",\n                \"ty\": 135,\n                \"additional_signed\": 11\n            },\n            {\n                \"identifier\": \"CheckMortality\",\n                \"ty\": 136,\n                \"additional_signed\": 11\n            },\n            {\n                \"identifier\": \"CheckNonce\",\n                \"ty\": 138,\n                \"additional_signed\": 41\n            },\n            {\n                \"identifier\": \"CheckWeight\",\n                \"ty\": 139,\n                \"additional_signed\": 41\n            },\n            {\n                \"identifier\": \"ChargeTransactionPayment\",\n                \"ty\": 140,\n                \"additional_signed\": 41\n            }\n        ]\n    },\n    \"ty\": 141\n}\n\n```\n\nThe type system is [composite](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/frame_runtime_types/index.html){target=\\_blank}, meaning each type identifier contains a reference to a specific type or to another type identifier that provides information about the associated primitive types.\n\nFor example, you can encode the `BitVec<Order, Store>` type, but to decode it properly, you must know the types used for the `Order` and `Store` types. To find type information for `Order` and `Store`, you can use the path in the decoded JSON to locate their type identifiers."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 13, "depth": 2, "title": "Included RPC APIs", "anchor": "included-rpc-apis", "start_char": 17237, "end_char": 18349, "estimated_token_count": 302, "token_estimator": "heuristic-v1", "text": "## Included RPC APIs\n\nA standard node comes with the following APIs to interact with a node:\n\n- **[`AuthorApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/author/trait.AuthorApiServer.html){target=\\_blank}**: Make calls into a full node, including authoring extrinsics and verifying session keys.\n- **[`ChainApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/chain/trait.ChainApiServer.html){target=\\_blank}**: Retrieve block header and finality information.\n- **[`OffchainApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/offchain/trait.OffchainApiServer.html){target=\\_blank}**: Make RPC calls for off-chain workers.\n- **[`StateApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/state/trait.StateApiServer.html){target=\\_blank}**: Query information about on-chain state such as runtime version, storage items, and proofs.\n- **[`SystemApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/system/trait.SystemApiServer.html){target=\\_blank}**: Retrieve information about network state, such as connected peers and node roles."}
{"page_id": "polkadot-protocol-parachain-basics-chain-data", "index": 14, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 18349, "end_char": 18682, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nThe following tools can help you locate and decode metadata:\n\n- [Subxt Explorer](https://paritytech.github.io/subxt-explorer/#/){target=\\_blank}\n- [Metadata Portal 🌗](https://github.com/paritytech/metadata-portal){target=\\_blank}\n- [De[code] Sub[strate]](https://github.com/paritytech/desub){target=\\_blank}"}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 525, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nCryptography forms the backbone of blockchain technology, providing the mathematical verifiability crucial for consensus systems, data integrity, and user security. While a deep understanding of the underlying mathematical processes isn't necessary for most blockchain developers, grasping the fundamental applications of cryptography is essential. This page comprehensively overviews cryptographic implementations used across Polkadot SDK-based chains and the broader blockchain ecosystem."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 1, "depth": 2, "title": "Hash Functions", "anchor": "hash-functions", "start_char": 525, "end_char": 1170, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Hash Functions\n\nHash functions are fundamental to blockchain technology, creating a unique digital fingerprint for any piece of data, including simple text, images, or any other form of file. They map input data of any size to a fixed-size output (typically 32 bytes) using complex mathematical operations. Hashing is used to verify data integrity, create digital signatures, and provide a secure way to store passwords. This form of mapping is known as the [\"pigeonhole principle,\"](https://en.wikipedia.org/wiki/Pigeonhole_principle){target=\\_blank} it is primarily implemented to efficiently and verifiably identify data from large sets."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 2, "depth": 3, "title": "Key Properties of Hash Functions", "anchor": "key-properties-of-hash-functions", "start_char": 1170, "end_char": 1720, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Key Properties of Hash Functions\n\n- **Deterministic**: The same input always produces the same output.\n- **Quick computation**: It's easy to calculate the hash value for any given input.\n- **Pre-image resistance**: It's infeasible to generate the input data from its hash.\n- **Small changes in input yield large changes in output**: Known as the [\"avalanche effect\"](https://en.wikipedia.org/wiki/Avalanche_effect){target=\\_blank}.\n- **Collision resistance**: The probabilities are extremely low to find two different inputs with the same hash."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 3, "depth": 3, "title": "Blake2", "anchor": "blake2", "start_char": 1720, "end_char": 2257, "estimated_token_count": 126, "token_estimator": "heuristic-v1", "text": "### Blake2\n\nThe Polkadot SDK utilizes Blake2, a state-of-the-art hashing method that offers:\n\n- Equal or greater security compared to [SHA-2](https://en.wikipedia.org/wiki/SHA-2){target=\\_blank}.\n- Significantly faster performance than other algorithms.\n\nThese properties make Blake2 ideal for blockchain systems, reducing sync times for new nodes and lowering the resources required for validation. For detailed technical specifications about Blake2, see the [official Blake2 paper](https://www.blake2.net/blake2.pdf){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 4, "depth": 2, "title": "Types of Cryptography", "anchor": "types-of-cryptography", "start_char": 2257, "end_char": 2412, "estimated_token_count": 22, "token_estimator": "heuristic-v1", "text": "## Types of Cryptography\n\nThere are two different ways that cryptographic algorithms are implemented: symmetric cryptography and asymmetric cryptography."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 5, "depth": 3, "title": "Symmetric Cryptography", "anchor": "symmetric-cryptography", "start_char": 2412, "end_char": 3256, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "### Symmetric Cryptography\n\nSymmetric encryption is a branch of cryptography that isn't based on one-way functions, unlike asymmetric cryptography. It uses the same cryptographic key to encrypt plain text and decrypt the resulting ciphertext.\n\nSymmetric cryptography is a type of encryption that has been used throughout history, such as the Enigma Cipher and the Caesar Cipher. It is still widely used today and can be found in Web2 and Web3 applications alike. There is only one single key, and a recipient must also have access to it to access the contained information.\n\n#### Advantages {: #symmetric-advantages }\n\n- Fast and efficient for large amounts of data.\n- Requires less computational power.\n\n#### Disadvantages {: #symmetric-disadvantages }\n\n- Key distribution can be challenging.\n- Scalability issues in systems with many users."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 6, "depth": 3, "title": "Asymmetric Cryptography", "anchor": "asymmetric-cryptography", "start_char": 3256, "end_char": 4221, "estimated_token_count": 182, "token_estimator": "heuristic-v1", "text": "### Asymmetric Cryptography\n\nAsymmetric encryption is a type of cryptography that uses two different keys, known as a keypair: a public key, used to encrypt plain text, and a private counterpart, used to decrypt the ciphertext.\n\nThe public key encrypts a fixed-length message that can only be decrypted with the recipient's private key and, sometimes, a set password. The public key can be used to cryptographically verify that the corresponding private key was used to create a piece of data without compromising the private key, such as with digital signatures. This has obvious implications for identity, ownership, and properties and is used in many different protocols across Web2 and Web3.\n\n#### Advantages {: #asymmetric-advantages }\n\n- Solves the key distribution problem.\n- Enables digital signatures and secure key exchange.\n\n#### Disadvantages {: #asymmetric-disadvantages }\n\n- Slower than symmetric encryption.\n- Requires more computational resources."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 7, "depth": 3, "title": "Trade-offs and Compromises", "anchor": "trade-offs-and-compromises", "start_char": 4221, "end_char": 5014, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "### Trade-offs and Compromises\n\nSymmetric cryptography is faster and requires fewer bits in the key to achieve the same level of security that asymmetric cryptography provides. However, it requires a shared secret before communication can occur, which poses issues to its integrity and a potential compromise point. On the other hand, asymmetric cryptography doesn't require the secret to be shared ahead of time, allowing for far better end-user security.\n\nHybrid symmetric and asymmetric cryptography is often used to overcome the engineering issues of asymmetric cryptography, as it is slower and requires more bits in the key to achieve the same level of security. It encrypts a key and then uses the comparatively lightweight symmetric cipher to do the \"heavy lifting\" with the message."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 8, "depth": 2, "title": "Digital Signatures", "anchor": "digital-signatures", "start_char": 5014, "end_char": 6403, "estimated_token_count": 266, "token_estimator": "heuristic-v1", "text": "## Digital Signatures\n\nDigital signatures are a way of verifying the authenticity of a document or message using asymmetric keypairs. They are used to ensure that a sender or signer's document or message hasn't been tampered with in transit, and for recipients to verify that the data is accurate and from the expected sender.\n\nSigning digital signatures only requires a low-level understanding of mathematics and cryptography. For a conceptual example -- when signing a check, it is expected that it cannot be cashed multiple times. This isn't a feature of the signature system but rather the check serialization system. The bank will check that the serial number on the check hasn't already been used. Digital signatures essentially combine these two concepts, allowing the signature to provide the serialization via a unique cryptographic fingerprint that cannot be reproduced.\n\nUnlike pen-and-paper signatures, knowledge of a digital signature cannot be used to create other signatures. Digital signatures are often used in bureaucratic processes, as they are more secure than simply scanning in a signature and pasting it onto a document.\n\nPolkadot SDK provides multiple different cryptographic schemes and is generic so that it can support anything that implements the [`Pair` trait](https://paritytech.github.io/polkadot-sdk/master/sp_core/crypto/trait.Pair.html){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 9, "depth": 3, "title": "Example of Creating a Digital Signature", "anchor": "example-of-creating-a-digital-signature", "start_char": 6403, "end_char": 6977, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "### Example of Creating a Digital Signature\n\nThe process of creating and verifying a digital signature involves several steps:\n\n1. The sender creates a hash of the message.\n2. The hash is encrypted using the sender's private key, creating the signature.\n3. The message and signature are sent to the recipient.\n4. The recipient decrypts the signature using the sender's public key.\n5. The recipient hashes the received message and compares it to the decrypted hash.\n\nIf the hashes match, the signature is valid, confirming the message's integrity and the sender's identity."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 10, "depth": 2, "title": "Elliptic Curve", "anchor": "elliptic-curve", "start_char": 6977, "end_char": 7869, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Elliptic Curve\n\nBlockchain technology requires the ability to have multiple keys creating a signature for block proposal and validation. To this end, Elliptic Curve Digital Signature Algorithm (ECDSA) and Schnorr signatures are two of the most commonly used methods. While ECDSA is a far simpler implementation, Schnorr signatures are more efficient when it comes to multi-signatures.\n\nSchnorr signatures bring some noticeable features over the ECDSA/EdDSA schemes:\n\n- It is better for hierarchical deterministic key derivations.\n- It allows for native multi-signature through [signature aggregation](https://bitcoincore.org/en/2017/03/23/schnorr-signature-aggregation/){target=\\_blank}.\n- It is generally more resistant to misuse.\n\nOne sacrifice that is made when using Schnorr signatures over ECDSA is that both require 64 bytes, but only ECDSA signatures communicate their public key."}
{"page_id": "polkadot-protocol-parachain-basics-cryptography", "index": 11, "depth": 3, "title": "Various Implementations", "anchor": "various-implementations", "start_char": 7869, "end_char": 8860, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "### Various Implementations\n\n- **[ECDSA](https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm){target=\\_blank}**: Polkadot SDK provides an ECDSA signature scheme using the [secp256k1](https://en.bitcoin.it/wiki/Secp256k1){target=\\_blank} curve. This is the same cryptographic algorithm used to secure [Bitcoin](https://en.wikipedia.org/wiki/Bitcoin){target=\\_blank} and [Ethereum](https://en.wikipedia.org/wiki/Ethereum){target=\\_blank}.\n\n- **[Ed25519](https://en.wikipedia.org/wiki/EdDSA#Ed25519){target=\\_blank}**: An EdDSA signature scheme using [Curve25519](https://en.wikipedia.org/wiki/Curve25519){target=\\_blank}. It is carefully engineered at several levels of design and implementation to achieve very high speeds without compromising security.\n\n- **[SR25519](https://research.web3.foundation/Polkadot/security/keys/accounts-more){target=\\_blank}**: Based on the same underlying curve as Ed25519. However, it uses Schnorr signatures instead of the EdDSA scheme."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 1595, "estimated_token_count": 332, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot SDK uses a lightweight and efficient encoding/decoding mechanism to optimize data transmission across the network. This mechanism, known as the _SCALE_ codec, is used for serializing and deserializing data.\n\nThe SCALE codec enables communication between the runtime and the outer node. This mechanism is designed for high-performance, copy-free data encoding and decoding in resource-constrained environments like the Polkadot SDK [Wasm runtime](/develop/parachains/deployment/build-deterministic-runtime/#introduction){target=\\_blank}.\n\nIt is not self-describing, meaning the decoding context must fully know the encoded data types. \n\nParity's libraries utilize the [`parity-scale-codec`](https://github.com/paritytech/parity-scale-codec){target=\\_blank} crate (a Rust implementation of the SCALE codec) to handle encoding and decoding for interactions between RPCs and the runtime.\n\nThe `codec` mechanism is ideal for Polkadot SDK-based chains because:\n\n- It is lightweight compared to generic serialization frameworks like [`serde`](https://serde.rs/){target=\\_blank}, which add unnecessary bulk to binaries.\n- It doesn’t rely on Rust’s `libstd`, making it compatible with `no_std` environments like Wasm runtime.\n- It integrates seamlessly with Rust, allowing easy derivation of encoding and decoding logic for new types using `#[derive(Encode, Decode)]`.\n\nDefining a custom encoding scheme in the Polkadot SDK-based chains, rather than using an existing Rust codec library, is crucial for enabling cross-platform and multi-language support."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 1, "depth": 2, "title": "SCALE Codec", "anchor": "scale-codec", "start_char": 1595, "end_char": 1798, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## SCALE Codec\n\nThe codec is implemented using the following traits:\n\n- [`Encode`](#encode)\n- [`Decode`](#decode)\n- [`CompactAs`](#compactas)\n- [`HasCompact`](#hascompact)\n- [`EncodeLike`](#encodelike)"}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 2, "depth": 3, "title": "Encode", "anchor": "encode", "start_char": 1798, "end_char": 2875, "estimated_token_count": 291, "token_estimator": "heuristic-v1", "text": "### Encode\n\nThe [`Encode`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.Encode.html){target=\\_blank} trait handles data encoding into SCALE format and includes the following key functions:\n\n- **`size_hint(&self) -> usize`**: Estimates the number of bytes required for encoding to prevent multiple memory allocations. This should be inexpensive and avoid complex operations. Optional if the size isn’t known.\n- **`encode_to<T: Output>(&self, dest: &mut T)`**: Encodes the data, appending it to a destination buffer.\n- **`encode(&self) -> Vec<u8>`**: Encodes the data and returns it as a byte vector.\n- **`using_encoded<R, F: FnOnce(&[u8]) -> R>(&self, f: F) -> R`**: Encodes the data and passes it to a closure, returning the result.\n- **`encoded_size(&self) -> usize`**: Calculates the encoded size. Should be used when the encoded data isn’t required.\n\n!!!tip\n    For best performance, value types should override `using_encoded`, and allocating types should override `encode_to`. It's recommended to implement `size_hint` for all types where possible."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 3, "depth": 3, "title": "Decode", "anchor": "decode", "start_char": 2875, "end_char": 3216, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "### Decode\n\nThe [`Decode`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.Decode.html){target=\\_blank} trait handles decoding SCALE-encoded data back into the appropriate types:\n\n- **`fn decode<I: Input>(value: &mut I) -> Result<Self, Error>`**: Decodes data from the SCALE format, returning an error if decoding fails."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 4, "depth": 3, "title": "CompactAs", "anchor": "compactas", "start_char": 3216, "end_char": 3566, "estimated_token_count": 109, "token_estimator": "heuristic-v1", "text": "### CompactAs\n\nThe [`CompactAs`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.CompactAs.html){target=\\_blank} trait wraps custom types for compact encoding:\n\n- **`encode_as(&self) -> &Self::As`**: Encodes the type as a compact type.\n- **`decode_from(_: Self::As) -> Result<Self, Error>`**: decodes from a compact encoded type."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 5, "depth": 3, "title": "HasCompact", "anchor": "hascompact", "start_char": 3566, "end_char": 3752, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### HasCompact\n\nThe [`HasCompact`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.HasCompact.html){target=\\_blank} trait indicates a type supports compact encoding."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 6, "depth": 3, "title": "EncodeLike", "anchor": "encodelike", "start_char": 3752, "end_char": 4038, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### EncodeLike\n\nThe [`EncodeLike`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.EncodeLike.html){target=\\_blank} trait is used to ensure multiple types that encode similarly are accepted by the same function. When using `derive`, it is automatically implemented."}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 7, "depth": 3, "title": "Data Types", "anchor": "data-types", "start_char": 4038, "end_char": 11053, "estimated_token_count": 1201, "token_estimator": "heuristic-v1", "text": "### Data Types\n\nThe table below outlines how the Rust implementation of the Parity SCALE codec encodes different data types.\n\n| Type                          | Description                                                                                                                                                                                                                                                                                                                | Example SCALE Decoded Value                                                                                                                        | SCALE Encoded Value                                                     |\n|-------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n| Boolean                       | Boolean values are encoded using the least significant bit of a single byte.                                                                                                                                                                                                                                               | `false` / `true`                                                                                                                                   | `0x00` / `0x01`                                                         |\n| Compact/general integers      | A \"compact\" or general integer encoding is sufficient for encoding large integers (up to 2^536) and is more efficient at encoding most values than the fixed-width version.                                                                                                                                                | `unsigned integer 0` / `unsigned integer 1` / `unsigned integer 42` / `unsigned integer 69` / `unsigned integer 65535` / `BigInt(100000000000000)` | `0x00` / `0x04` / `0xa8` / `0x1501` / `0xfeff0300` / `0x0b00407a10f35a` |\n| Enumerations (tagged-unions)  | A fixed number of variants, each mutually exclusive and potentially implying a further value or series of values. Encoded as the first byte identifying the index of the variant that the value is. Any further bytes are used to encode any data that the variant implies. Thus, no more than 256 variants are supported. | `Int(42)` and `Bool(true)` where `enum IntOrBool { Int(u8), Bool(bool) }`                                                                          | `0x002a` and `0x0101`                                                   |\n| Fixed-width integers          | Basic integers are encoded using a fixed-width little-endian (LE) format.                                                                                                                                                                                                                                                  | `signed 8-bit integer 69` / `unsigned 16-bit integer 42` / `unsigned 32-bit integer 16777215`                                                      | `0x45` / `0x2a00` / `0xffffff00`                                        |\n| Options                       | One or zero values of a particular type.                                                                                                                                                                                                                                                                                   | `Some` / `None`                                                                                                                                    | `0x01` followed by the encoded value / `0x00`                           |\n| Results                       | Results are commonly used enumerations which indicate whether certain operations were successful or unsuccessful.                                                                                                                                                                                                          | `Ok(42)` / `Err(false)`                                                                                                                            | `0x002a` / `0x0100`                                                     |\n| Strings                       | Strings are Vectors of bytes (Vec<u8>) containing a valid UTF8 sequence.                                                                                                                                                                                                                                                   |                                                                                                                                                    |                                                                         |\n| Structs                       | For structures, the values are named, but that is irrelevant for the encoding (names are ignored - only order matters).                                                                                                                                                                                                    | `SortedVecAsc::from([3, 5, 2, 8])`                                                                                                                 | `[3, 2, 5, 8] `                                                         |\n| Tuples                        | A fixed-size series of values, each with a possibly different but predetermined and fixed type. This is simply the concatenation of each encoded value.                                                                                                                                                                    | Tuple of compact unsigned integer and boolean: `(3, false)`                                                                                        | `0x0c00`                                                                |\n| Vectors (lists, series, sets) | A collection of same-typed values is encoded, prefixed with a compact encoding of the number of items, followed by each item's encoding concatenated in turn.                                                                                                                                                              | Vector of unsigned `16`-bit integers: `[4, 8, 15, 16, 23, 42]`                                                                                     | `0x18040008000f00100017002a00`                                          |"}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 8, "depth": 2, "title": "Encode and Decode Rust Trait Implementations", "anchor": "encode-and-decode-rust-trait-implementations", "start_char": 11053, "end_char": 12106, "estimated_token_count": 445, "token_estimator": "heuristic-v1", "text": "## Encode and Decode Rust Trait Implementations\n\nHere's how the `Encode` and `Decode` traits are implemented:\n\n\n```rust\n-use parity_scale_codec::{Encode, Decode};\n\n[derive(Debug, PartialEq, Encode, Decode)]\nenum EnumType {\n    #[codec(index = 15)]\n    A,\n    B(u32, u64),\n    C {\n        a: u32,\n        b: u64,\n    },\n}\n\nlet a = EnumType::A;\nlet b = EnumType::B(1, 2);\nlet c = EnumType::C { a: 1, b: 2 };\n\na.using_encoded(|ref slice| {\n    assert_eq!(slice, &b\"\\x0f\");\n});\n\nb.using_encoded(|ref slice| {\n    assert_eq!(slice, &b\"\\x01\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\");\n});\n\nc.using_encoded(|ref slice| {\n    assert_eq!(slice, &b\"\\x02\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\");\n});\n\nlet mut da: &[u8] = b\"\\x0f\";\nassert_eq!(EnumType::decode(&mut da).ok(), Some(a));\n\nlet mut db: &[u8] = b\"\\x01\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\";\nassert_eq!(EnumType::decode(&mut db).ok(), Some(b));\n\nlet mut dc: &[u8] = b\"\\x02\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\";\nassert_eq!(EnumType::decode(&mut dc).ok(), Some(c));\n\nlet mut dz: &[u8] = &[0];\nassert_eq!(EnumType::decode(&mut dz).ok(), None);\n```"}
{"page_id": "polkadot-protocol-parachain-basics-data-encoding", "index": 9, "depth": 2, "title": "SCALE Codec Libraries", "anchor": "scale-codec-libraries", "start_char": 12106, "end_char": 13630, "estimated_token_count": 557, "token_estimator": "heuristic-v1", "text": "## SCALE Codec Libraries\n\nSeveral SCALE codec implementations are available in various languages. Here's a list of them:\n\n- **AssemblyScript**: [`LimeChain/as-scale-codec`](https://github.com/LimeChain/as-scale-codec){target=\\_blank}\n- **C**: [`MatthewDarnell/cScale`](https://github.com/MatthewDarnell/cScale){target=\\_blank}\n- **C++**: [`qdrvm/scale-codec-cpp`](https://github.com/qdrvm/scale-codec-cpp){target=\\_blank}\n- **JavaScript**: [`polkadot-js/api`](https://github.com/polkadot-js/api){target=\\_blank}\n- **Dart**: [`leonardocustodio/polkadart`](https://github.com/leonardocustodio/polkadart){target=\\_blank}\n- **Haskell**: [`airalab/hs-web3`](https://github.com/airalab/hs-web3/tree/master/packages/scale){target=\\_blank}\n- **Golang**: [`itering/scale.go`](https://github.com/itering/scale.go){target=\\_blank}\n- **Java**: [`splix/polkaj`](https://github.com/splix/polkaj){target=\\_blank}\n- **Python**: [`polkascan/py-scale-codec`](https://github.com/polkascan/py-scale-codec){target=\\_blank}\n- **Ruby**: [` wuminzhe/scale_rb`](https://github.com/wuminzhe/scale_rb){target=\\_blank}\n- **TypeScript**: [`parity-scale-codec-ts`](https://github.com/tjjfvi/subshape){target=\\_blank}, [`scale-ts`](https://github.com/unstoppablejs/unstoppablejs/tree/main/packages/scale-ts#scale-ts){target=\\_blank}, [`soramitsu/scale-codec-js-library`](https://github.com/soramitsu/scale-codec-js-library){target=\\_blank}, [`subsquid/scale-codec`](https://github.com/subsquid/squid-sdk/tree/master/substrate/scale-codec){target=\\_blank}"}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 607, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nInteroperability lies at the heart of the Polkadot ecosystem, enabling communication and collaboration across a diverse range of blockchains. By bridging the gaps between parachains, relay chains, and even external networks, Polkadot unlocks the potential for truly decentralized applications, efficient resource sharing, and scalable solutions.\n\nPolkadot’s design ensures that blockchains can transcend their individual limitations by working together as part of a unified system. This cooperative architecture is what sets Polkadot apart in the blockchain landscape."}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 1, "depth": 2, "title": "Why Interoperability Matters", "anchor": "why-interoperability-matters", "start_char": 607, "end_char": 1641, "estimated_token_count": 169, "token_estimator": "heuristic-v1", "text": "## Why Interoperability Matters\n\nThe blockchain ecosystem is inherently fragmented. Different blockchains excel in specialized domains such as finance, gaming, or supply chain management, but these chains function in isolation without interoperability. This lack of connectivity stifles the broader utility of blockchain technology.\n\nInteroperability solves this problem by enabling blockchains to:\n\n- **Collaborate across networks**: Chains can interact to share assets, functionality, and data, creating synergies that amplify their individual strengths.\n- **Achieve greater scalability**: Specialized chains can offload tasks to others, optimizing performance and resource utilization.\n- **Expand use-case potential**: Cross-chain applications can leverage features from multiple blockchains, unlocking novel user experiences and solutions.\n\nIn the Polkadot ecosystem, interoperability transforms a collection of isolated chains into a cohesive, efficient network, pushing the boundaries of what blockchains can achieve together."}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 2, "depth": 2, "title": "Key Mechanisms for Interoperability", "anchor": "key-mechanisms-for-interoperability", "start_char": 1641, "end_char": 1921, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## Key Mechanisms for Interoperability\n\nAt the core of Polkadot's cross-chain collaboration are foundational technologies designed to break down barriers between networks. These mechanisms empower blockchains to communicate, share resources, and operate as a cohesive ecosystem."}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 3, "depth": 3, "title": "Cross-Consensus Messaging (XCM): The Backbone of Communication", "anchor": "cross-consensus-messaging-xcm-the-backbone-of-communication", "start_char": 1921, "end_char": 2747, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "### Cross-Consensus Messaging (XCM): The Backbone of Communication\n\nPolkadot's Cross-Consensus Messaging (XCM) is the standard framework for interaction between parachains, relay chains, and, eventually, external blockchains. XCM provides a trustless, secure messaging format for exchanging assets, sharing data, and executing cross-chain operations.\n\nThrough XCM, decentralized applications can:\n\n- Transfer tokens and other assets across chains.\n- Coordinate complex workflows that span multiple blockchains.\n- Enable seamless user experiences where underlying blockchain differences are invisible.\n- XCM exemplifies Polkadot’s commitment to creating a robust and interoperable ecosystem.\n\nFor further information about XCM, check the [Introduction to XCM](/develop/interoperability/intro-to-xcm/){target=\\_blank} article."}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 4, "depth": 3, "title": "Bridges: Connecting External Networks", "anchor": "bridges-connecting-external-networks", "start_char": 2747, "end_char": 3551, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### Bridges: Connecting External Networks\n\nWhile XCM enables interoperability within the Polkadot ecosystem, bridges extend this functionality to external blockchains such as Ethereum and Bitcoin. By connecting these networks, bridges allow Polkadot-based chains to access external liquidity, additional functionalities, and broader user bases.\n\nWith bridges, developers and users gain the ability to:\n\n- Integrate external assets into Polkadot-based applications.\n- Combine the strengths of Polkadot’s scalability with the liquidity of other networks.\n- Facilitate accurate multi-chain applications that transcend ecosystem boundaries.\n\nFor more information about bridges in the Polkadot ecosystem, see the [Bridge Hub](/polkadot-protocol/architecture/system-chains/bridge-hub/){target=\\_blank} guide."}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 5, "depth": 2, "title": "The Polkadot Advantage", "anchor": "the-polkadot-advantage", "start_char": 3551, "end_char": 4269, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## The Polkadot Advantage\n\nPolkadot was purpose-built for interoperability. Unlike networks that add interoperability as an afterthought, Polkadot integrates it as a fundamental design principle. This approach offers several distinct advantages:\n\n- **Developer empowerment**: Polkadot’s interoperability tools allow developers to build applications that leverage multiple chains’ capabilities without added complexity.\n- **Enhanced ecosystem collaboration**: Chains in Polkadot can focus on their unique strengths while contributing to the ecosystem’s overall growth.\n- **Future-proofing blockchain**: By enabling seamless communication, Polkadot ensures its ecosystem can adapt to evolving demands and technologies."}
{"page_id": "polkadot-protocol-parachain-basics-interoperability", "index": 6, "depth": 2, "title": "Looking Ahead", "anchor": "looking-ahead", "start_char": 4269, "end_char": 4657, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Looking Ahead\n\nPolkadot’s vision of interoperability extends beyond technical functionality, representing a shift towards a more collaborative blockchain landscape. By enabling chains to work together, Polkadot fosters innovation, efficiency, and accessibility, paving the way for a decentralized future where blockchains are not isolated competitors but interconnected collaborators."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 601, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot ecosystem is built on a robust set of networks designed to enable secure and scalable development. Whether you are testing new features or deploying to live production, Polkadot offers several layers of networks tailored for each stage of the development process. From local environments to experimental networks like Kusama and community-run TestNets such as Paseo, developers can thoroughly test, iterate, and validate their applications. This guide will introduce you to Polkadot's various networks and explain how they fit into the development workflow."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 1, "depth": 2, "title": "Network Overview", "anchor": "network-overview", "start_char": 601, "end_char": 3131, "estimated_token_count": 484, "token_estimator": "heuristic-v1", "text": "## Network Overview \n\nPolkadot's development process is structured to ensure new features and upgrades are rigorously tested before being deployed on live production networks. The progression follows a well-defined path, starting from local environments and advancing through TestNets, ultimately reaching the Polkadot MainNet. The diagram below outlines the typical progression of the Polkadot development cycle:\n\n``` mermaid\n\nflowchart LR\n    id1[Local] --> id2[Westend] --> id4[Kusama] --> id5[Polkadot]  \n    id1[Local] --> id3[Paseo] --> id5[Polkadot] \n```\nThis flow ensures developers can thoroughly test and iterate without risking real tokens or affecting production networks. Testing tools like [Chopsticks](#chopsticks) and various TestNets make it easier to experiment safely before releasing to production.\n\nA typical journey through the Polkadot core protocol development process might look like this:\n\n1. **Local development node**: Development starts in a local environment, where developers can create, test, and iterate on upgrades or new features using a local development node. This stage allows rapid experimentation in an isolated setup without any external dependencies.\n\n2. **Westend**: After testing locally, upgrades are deployed to [Westend](#westend), Polkadot's primary TestNet. Westend simulates real-world conditions without using real tokens, making it the ideal place for rigorous feature testing before moving on to production networks.\n\n3. **Kusama**: Once features have passed extensive testing on Westend, they move to Kusama, Polkadot's experimental and fast-moving \"canary\" network. Kusama operates as a high-fidelity testing ground with actual economic incentives, giving developers insights into how their features will perform in a real-world environment.\n\n4. **Polkadot**: After passing tests on Westend and Kusama, features are considered ready for deployment to Polkadot, the live production network.\n\n    In addition, parachain developers can leverage local TestNets like [Zombienet](#zombienet) and deploy upgrades on parachain TestNets.\n\n5. **Paseo**: For parachain and dApp developers, Paseo serves as a community-run TestNet that mirrors Polkadot's runtime. Like Westend for core protocol development, Paseo provides a testing ground for parachain development without affecting live networks.\n\n!!!note\n    The Rococo TestNet deprecation date was October 14, 2024. Teams should use Westend for Polkadot protocol and feature testing and Paseo for chain development-related testing."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 2, "depth": 2, "title": "Polkadot Development Networks", "anchor": "polkadot-development-networks", "start_char": 3131, "end_char": 3663, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Polkadot Development Networks\n\nDevelopment and testing are crucial to building robust dApps and parachains and performing network upgrades within the Polkadot ecosystem. To achieve this, developers can leverage various networks and tools that provide a risk-free environment for experimentation and validation before deploying features to live networks. These networks help avoid the costs and risks associated with real tokens, enabling testing for functionalities like governance, cross-chain messaging, and runtime upgrades."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 3, "depth": 2, "title": "Kusama Network", "anchor": "kusama-network", "start_char": 3663, "end_char": 4269, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Kusama Network\n\nKusama is the experimental version of Polkadot, designed for developers who want to move quickly and test their applications in a real-world environment with economic incentives. Kusama serves as a production-grade testing ground where developers can deploy features and upgrades with the pressure of game theory and economics in mind. It mirrors Polkadot but operates as a more flexible space for innovation.\n\nThe native token for Kusama is KSM. For more information about KSM, visit the [Native Assets](https://guide.kusama.network/docs/learn-DOT#kusama-tokens){target=\\_blank} page."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 4, "depth": 2, "title": "Test Networks", "anchor": "test-networks", "start_char": 4269, "end_char": 4489, "estimated_token_count": 47, "token_estimator": "heuristic-v1", "text": "## Test Networks\n\nThe following test networks provide controlled environments for testing upgrades and new features. TestNet tokens are available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 5, "depth": 3, "title": "Westend", "anchor": "westend", "start_char": 4489, "end_char": 5010, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "### Westend\n\nWestend is Polkadot's primary permanent TestNet. Unlike temporary test networks, Westend is not reset to the genesis block, making it an ongoing environment for testing Polkadot core features. Managed by Parity Technologies, Westend ensures that developers can test features in a real-world simulation without using actual tokens.\n\nThe native token for Westend is WND. More details about WND can be found on the [Native Assets](https://wiki.polkadot.com/learn/learn-dot/#__tabbed_2_2){target=\\_blank} page."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 6, "depth": 3, "title": "Paseo", "anchor": "paseo", "start_char": 5010, "end_char": 5580, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "### Paseo\n\n[Paseo](https://github.com/paseo-network){target=\\_blank} is a community-managed TestNet designed for parachain and dApp developers. It mirrors Polkadot's runtime and is maintained by Polkadot community members. Paseo provides a dedicated space for parachain developers to test their applications in a Polkadot-like environment without the risks associated with live networks.\n\nThe native token for Paseo is PAS. Additional information on PAS is available on the [Native Assets](https://wiki.polkadot.com/learn/learn-dot/#__tabbed_2_1){target=\\_blank} page."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 7, "depth": 2, "title": "Local Test Networks", "anchor": "local-test-networks", "start_char": 5580, "end_char": 6058, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Local Test Networks\n\nLocal test networks are an essential part of the development cycle for blockchain developers using the Polkadot SDK. They allow for fast, iterative testing in controlled, private environments without connecting to public TestNets. Developers can quickly spin up local instances to experiment, debug, and validate their code before deploying to larger TestNets like Westend or Paseo. Two key tools for local network testing are Zombienet and Chopsticks."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 8, "depth": 3, "title": "Zombienet", "anchor": "zombienet", "start_char": 6058, "end_char": 6982, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "### Zombienet\n\n[Zombienet](https://github.com/paritytech/zombienet){target=\\_blank} is a flexible testing framework for Polkadot SDK-based blockchains. It enables developers to create and manage ephemeral, short-lived networks. This feature makes Zombienet particularly useful for quick iterations, as it allows you to run multiple local networks concurrently, mimicking different runtime conditions. Whether you're developing a parachain or testing your custom blockchain logic, Zombienet gives you the tools to automate local testing.\n\nKey features of Zombienet include:\n\n- Creating dynamic, local networks with different configurations.\n- Running parachains and relay chains in a simulated environment.\n- Efficient testing of network components like cross-chain messaging and governance.\n\nZombienet is ideal for developers looking to test quickly and thoroughly before moving to more resource-intensive public TestNets."}
{"page_id": "polkadot-protocol-parachain-basics-networks", "index": 9, "depth": 3, "title": "Chopsticks", "anchor": "chopsticks", "start_char": 6982, "end_char": 7835, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "### Chopsticks\n\n[Chopsticks](https://github.com/AcalaNetwork/chopsticks){target=\\_blank} is a tool designed to create forks of Polkadot SDK-based blockchains, allowing developers to interact with network forks as part of their testing process. This capability makes Chopsticks a powerful option for testing upgrades, runtime changes, or cross-chain applications in a forked network environment.\n\nKey features of Chopsticks include:\n\n- Forking live Polkadot SDK-based blockchains for isolated testing.\n- Simulating cross-chain messages in a private, controlled setup.\n- Debugging network behavior by interacting with the fork in real-time.\n\nChopsticks provides a controlled environment for developers to safely explore the effects of runtime changes. It ensures that network behavior is tested and verified before upgrades are deployed to live networks."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 1003, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEvery blockchain platform relies on a decentralized network of computers, called nodes, that communicate with each other about transactions and blocks. In this context, a node refers to the software running on the connected devices rather than the physical or virtual machines in the network.\n\nPolkadot SDK-based nodes consist of two main components, each with distinct responsibilities: the client (also called node) and the runtime.\n\nIf the system were a monolithic protocol, any modification would require updating the entire system. Instead, Polkadot achieves true upgradeability by defining an immutable meta-protocol (the client) and a protocol (the runtime) that can be upgraded independently.\n\nThis separation gives the [Polkadot Relay Chain](/polkadot-protocol/architecture/polkadot-chain){target=\\_blank} and all connected [parachains](/polkadot-protocol/architecture/parachains){target=\\_blank} an evolutionary advantage over other blockchain platforms."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 1, "depth": 2, "title": "Architectural Principles", "anchor": "architectural-principles", "start_char": 1003, "end_char": 1725, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Architectural Principles\n\nThe Polkadot SDK-based blockchain architecture is fundamentally built on two distinct yet interconnected components:\n\n- Client (Meta-protocol):\n    - Handles the foundational infrastructure of the blockchain.\n    - Manages runtime execution, networking, consensus, and other off-chain components.\n    - Provides an immutable base layer that ensures network stability.\n    - Upgradable only through hard forks.\n\n- Runtime (Protocol):\n    - Defines the blockchain's state transition logic.\n    - Determines the specific rules and behaviors of the blockchain.\n    - Compiled to WebAssembly (Wasm) for platform-independent execution.\n    - Capable of being upgraded without network-wide forking."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 2, "depth": 3, "title": "Advantages of this Architecture", "anchor": "advantages-of-this-architecture", "start_char": 1725, "end_char": 2106, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "### Advantages of this Architecture\n\n- **Forkless upgrades**: Runtime can be updated without disrupting the entire network.\n- **Modularity**: Clear separation allows independent development of client and runtime.\n- **Flexibility**: Enables rapid iteration and evolution of blockchain logic.\n- **Performance**: WebAssembly compilation provides efficient, cross-platform execution."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 3, "depth": 2, "title": "Node (Client)", "anchor": "node-client", "start_char": 2106, "end_char": 2939, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "## Node (Client)\n\nThe node, also known as the client, is the core component responsible for executing the Wasm runtime and orchestrating various essential blockchain components. It ensures the correct execution of the state transition function and manages multiple critical subsystems, including:\n\n- **Wasm execution**: Runs the blockchain runtime, which defines the state transition rules.\n- **Database management**: Stores blockchain data.\n- **Networking**: Facilitates peer-to-peer communication, block propagation, and transaction gossiping.\n- **Transaction pool (Mempool)**: Manages pending transactions before they are included in a block.\n- **Consensus mechanism**: Ensures agreement on the blockchain state across nodes.\n- **RPC services**: Provides external interfaces for applications and users to interact with the node."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 4, "depth": 2, "title": "Runtime", "anchor": "runtime", "start_char": 2939, "end_char": 3221, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Runtime\n\nThe runtime is more than just a set of rules. It's the fundamental logic engine that defines a blockchain's entire behavior. In Polkadot SDK-based blockchains, the runtime represents a complete, self-contained description of the blockchain's state transition function."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 5, "depth": 3, "title": "Characteristics", "anchor": "characteristics", "start_char": 3221, "end_char": 3555, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "### Characteristics\n\nThe runtime is distinguished by three key characteristics:\n\n- **Business logic**: Defines the complete application-specific blockchain behavior.\n- **WebAssembly compilation**: Ensures platform-independent, secure execution.\n- **On-chain storage**: Stored within the blockchain's state, allowing dynamic updates."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 6, "depth": 3, "title": "Key Functions", "anchor": "key-functions", "start_char": 3555, "end_char": 3840, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Key Functions\n\nThe runtime performs several critical functions, such as:\n\n- Define state transition rules.\n- Implement blockchain-specific logic.\n- Manage account interactions.\n- Control transaction processing.\n- Define governance mechanisms.\n- Handle custom pallets and modules."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 7, "depth": 2, "title": "Communication Between Node and Runtime", "anchor": "communication-between-node-and-runtime", "start_char": 3840, "end_char": 4112, "estimated_token_count": 53, "token_estimator": "heuristic-v1", "text": "## Communication Between Node and Runtime\n\nThe client and runtime communicate exclusively using [SCALE-encoded](/polkadot-protocol/parachain-basics/data-encoding){target=\\_blank} communication. This ensures efficient and compact data exchange between the two components."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 8, "depth": 3, "title": "Runtime APIs", "anchor": "runtime-apis", "start_char": 4112, "end_char": 4537, "estimated_token_count": 76, "token_estimator": "heuristic-v1", "text": "### Runtime APIs\n\nThe Runtime API consists of well-defined functions and constants a client assumes are implemented in the Runtime Wasm blob. These APIs enable the client to interact with the runtime to execute blockchain operations and retrieve information. The client invokes these APIs to:\n\n- Build, execute, and finalize blocks.\n- Access metadata.\n- Access consensus related information.\n- Handle transaction execution."}
{"page_id": "polkadot-protocol-parachain-basics-node-and-runtime", "index": 9, "depth": 3, "title": "Host Functions", "anchor": "host-functions", "start_char": 4537, "end_char": 4937, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "### Host Functions\n\nDuring execution, the runtime can access certain external client functionalities via host functions. The specific functions the client exposes allow the runtime to perform operations outside the WebAssembly domain. Host functions enable the runtime to:\n\n- Perform cryptographic operations.\n- Access the current blockchain state.\n- Handle storage modifications.\n- Allocate memory."}
{"page_id": "polkadot-protocol-parachain-basics-randomness", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 1254, "estimated_token_count": 285, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRandomness is crucial in Proof of Stake (PoS) blockchains to ensure a fair and unpredictable distribution of validator duties. However, computers are inherently deterministic, meaning the same input always produces the same output. What we typically refer to as \"random\" numbers on a computer are actually pseudo-random. These numbers rely on an initial \"seed,\" which can come from external sources like [atmospheric noise](https://www.random.org/randomness/){target=\\_blank}, [heart rates](https://mdpi.altmetric.com/details/47574324){target=\\_blank}, or even [lava lamps](https://en.wikipedia.org/wiki/Lavarand){target=\\_blank}. While this may seem random, given the same \"seed,\" the same sequence of numbers will always be generated.\n\nIn a global blockchain network, relying on real-world entropy for randomness isn’t feasible because these inputs vary by time and location. If nodes use different inputs, blockchains can fork. Hence, real-world randomness isn't suitable for use as a seed in blockchain systems.\n\nCurrently, two primary methods for generating randomness in blockchains are used: [`RANDAO`](#randao) and [`VRF`](#vrf) (Verifiable Random Function). Polkadot adopts the `VRF` approach for its randomness."}
{"page_id": "polkadot-protocol-parachain-basics-randomness", "index": 1, "depth": 2, "title": "VRF", "anchor": "vrf", "start_char": 1254, "end_char": 2042, "estimated_token_count": 181, "token_estimator": "heuristic-v1", "text": "## VRF\n\nA Verifiable Random Function (VRF) is a cryptographic function that generates a random number and proof that ensures the submitter produced the number. This proof allows anyone to verify the validity of the random number.\n\nPolkadot's VRF is similar to the one used in [**Ouroboros Praos**](https://eprint.iacr.org/2017/573.pdf){target=\\_blank}, which secures randomness for block production in systems like [BABE](/polkadot-protocol/architecture/polkadot-chain/pos-consensus/#block-production-babe){target=\\_blank} (Polkadot’s block production mechanism). \n\nThe key difference is that Polkadot's VRF doesn’t rely on a central clock—avoiding the issue of whose clock to trust. Instead, it uses its own past results and slot numbers to simulate time and determine future outcomes."}
{"page_id": "polkadot-protocol-parachain-basics-randomness", "index": 2, "depth": 3, "title": "How VRF Works", "anchor": "how-vrf-works", "start_char": 2042, "end_char": 4617, "estimated_token_count": 545, "token_estimator": "heuristic-v1", "text": "### How VRF Works\n\nSlots on Polkadot are discrete units of time, each lasting six seconds, and can potentially hold a block. Multiple slots form an epoch, with 2400 slots making up one four-hour epoch.\n\nIn each slot, validators execute a \"die roll\" using a VRF. The VRF uses three inputs:\n\n1. A \"secret key,\" unique to each validator, is used for the die roll.\n2. An epoch randomness value, derived from the hash of VRF outputs from blocks two epochs ago (N-2), so past randomness influences the current epoch (N).\n3. The current slot number.\n\nThis process helps maintain fair randomness across the network.\n\nHere is a graphical representation:\n\n![](/images/polkadot-protocol/parachain-basics/blocks-transactions-fees/randomness/slots-epochs.webp)\n\nThe VRF produces two outputs: a result (the random number) and a proof (verifying that the number was generated correctly).\n\nThe result is checked by the validator against a protocol threshold. If it's below the threshold, the validator becomes a candidate for block production in that slot. \n\nThe validator then attempts to create a block, submitting it along with the `PROOF` and `RESULT`.\n\nSo, VRF can be expressed like:\n\n`(RESULT, PROOF) = VRF(SECRET, EPOCH_RANDOMNESS_VALUE, CURRENT_SLOT_NUMBER)`\n\nPut simply, performing a \"VRF roll\" generates a random number along with proof that the number was genuinely produced and not arbitrarily chosen.\n\nAfter executing the VRF, the `RESULT` is compared to a protocol-defined `THRESHOLD`. If the `RESULT` is below the `THRESHOLD`, the validator becomes a valid candidate to propose a block for that slot. Otherwise, the validator skips the slot.\n\nAs a result, there may be multiple validators eligible to propose a block for a slot. In this case, the block accepted by other nodes will prevail, provided it is on the chain with the latest finalized block as determined by the GRANDPA finality gadget. It's also possible for no block producers to be available for a slot, in which case the AURA consensus takes over. AURA is a fallback mechanism that randomly selects a validator to produce a block, running in parallel with BABE and only stepping in when no block producers exist for a slot. Otherwise, it remains inactive.\n\nBecause validators roll independently, no block candidates may appear in some slots if all roll numbers are above the threshold. \n\nTo verify resolution of this issue and that Polkadot block times remain near constant-time, see the [PoS Consensus](/polkadot-protocol/architecture/polkadot-chain/pos-consensus/){target=\\_blank} page of this documentation."}
{"page_id": "polkadot-protocol-parachain-basics-randomness", "index": 3, "depth": 2, "title": "RANDAO", "anchor": "randao", "start_char": 4617, "end_char": 5304, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## RANDAO\n\nAn alternative on-chain randomness method is Ethereum's RANDAO, where validators perform thousands of hashes on a seed and publish the final hash during a round. The collective input from all validators forms the random number, and as long as one honest validator participates, the randomness is secure.\n\nTo enhance security, RANDAO can optionally be combined with a Verifiable Delay Function (VDF), ensuring that randomness can't be predicted or manipulated during computation.\n\nFor more information about RANDAO, see the [Randomness - RANDAO](https://eth2book.info/capella/part2/building_blocks/randomness/){target=\\_blank} section of the Upgrading Ethereum documentation."}
{"page_id": "polkadot-protocol-parachain-basics-randomness", "index": 4, "depth": 2, "title": "VDFs", "anchor": "vdfs", "start_char": 5304, "end_char": 5981, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## VDFs\n\nVerifiable Delay Functions (VDFs) are time-bound computations that, even on parallel computers, take a set amount of time to complete. \n\nThey produce a unique result that can be quickly verified publicly. When combined with RANDAO, feeding RANDAO's output into a VDF introduces a delay that nullifies an attacker's chance to influence the randomness.\n\nHowever, VDF likely requires specialized ASIC devices to run separately from standard nodes.\n\n!!!warning \n    While only one is needed to secure the system, and they will be open-source and inexpensive, running VDF devices involves significant costs without direct incentives, adding friction for blockchain users."}
{"page_id": "polkadot-protocol-parachain-basics-randomness", "index": 5, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 5981, "end_char": 6541, "estimated_token_count": 124, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nFor more information about the reasoning for choices made along with proofs, see Polkadot's research on blockchain randomness and sortition in the [Block production](https://research.web3.foundation/Polkadot/protocols/block-production){target=\\_blank} entry of the Polkadot Wiki. \n\nFor a discussion with Web3 Foundation researchers about when and under what conditions Polkadot's randomness can be utilized, see the [Discussion on Randomness used in Polkadot](https://github.com/use-ink/ink/issues/57){target=\\_blank} issue on GitHub."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 213, "end_char": 1057, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAsset Hub natively utilizes Polkadot's 32-byte account system while providing interoperability with Ethereum's 20-byte addresses through an automatic conversion system. When interacting with smart contracts:\n\n- Ethereum-compatible wallets (like MetaMask) can use their familiar 20-byte addresses.\n- Polkadot accounts continue using their native 32-byte format.\n- The Asset Hub chain automatically handles conversion between the two formats behind the scenes:\n\n    - 20-byte Ethereum addresses are padded with `0xEE` bytes to create valid 32-byte Polkadot accounts.\n    - 32-byte Polkadot accounts can optionally register a mapping to a 20-byte address for Ethereum compatibility.\n\nThis dual-format approach enables Asset Hub to maintain compatibility with Ethereum tooling while fully integrating with the Polkadot ecosystem."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 1, "depth": 2, "title": "Address Types and Mappings", "anchor": "address-types-and-mappings", "start_char": 1057, "end_char": 1371, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Address Types and Mappings\n\nThe platform handles two distinct address formats:\n\n- [Ethereum-style addresses (20 bytes)](https://ethereum.org/en/developers/docs/accounts/#account-creation){target=\\_blank}\n- [Polkadot native account IDs (32 bytes)](/polkadot-protocol/parachain-basics/accounts/){target=\\_blank}"}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 2, "depth": 3, "title": "Ethereum to Polkadot Mapping", "anchor": "ethereum-to-polkadot-mapping", "start_char": 1371, "end_char": 2416, "estimated_token_count": 237, "token_estimator": "heuristic-v1", "text": "### Ethereum to Polkadot Mapping\n\nThe [`AccountId32Mapper`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/struct.AccountId32Mapper.html){target=\\_blank} implementation in [`pallet_revive`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/index.html){target=\\_blank} handles the core address conversion logic. For converting a 20-byte Ethereum address to a 32-byte Polkadot address, the pallet uses a simple concatenation approach:\n\n- [**Core mechanism**](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_fallback_account_id){target=\\_blank}: Takes a 20-byte Ethereum address and extends it to 32 bytes by adding twelve `0xEE` bytes at the end. The key benefits of this approach are:\n    - Able to fully revert, allowing a smooth transition back to the Ethereum format.\n    - Provides clear identification of Ethereum-controlled accounts through the `0xEE` suffix pattern.\n    - Maintains cryptographic security with a `2^96` difficulty for pattern reproduction."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 3, "depth": 3, "title": "Polkadot to Ethereum Mapping", "anchor": "polkadot-to-ethereum-mapping", "start_char": 2416, "end_char": 4745, "estimated_token_count": 517, "token_estimator": "heuristic-v1", "text": "### Polkadot to Ethereum Mapping\n\nThe conversion from 32-byte Polkadot accounts to 20-byte Ethereum addresses is more complex than the reverse direction due to the lossy nature of the conversion. The [`AccountId32Mapper`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/struct.AccountId32Mapper.html){target=\\_blank} handles this through two distinct approaches:\n\n- **For Ethereum-derived accounts**: The system uses the [`is_eth_derived`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/fn.is_eth_derived.html){target=\\_blank} function to detect accounts that were originally Ethereum addresses (identified by the `0xEE` suffix pattern). For these accounts, the conversion strips the last 12 bytes to recover the original 20-byte Ethereum address.\n\n- **For native Polkadot accounts**: Since these accounts utilize the whole 32-byte space and weren't derived from Ethereum addresses, direct truncation would result in lost information. Instead, the system:\n\n    1. Hashes the entire 32-byte account using Keccak-256.\n    2. Takes the last 20 bytes of the hash to create the Ethereum address.\n    3. This ensures a deterministic mapping while avoiding simple truncation.\n\nThe conversion process is implemented through the [`to_address`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_address){target=\\_blank} function, which automatically detects the account type and applies the appropriate conversion method.\n\n**Stateful Mapping for Reversibility** : Since the conversion from 32-byte to 20-byte addresses is inherently lossy, the system provides an optional stateful mapping through the [`OriginalAccount`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/storage_types/struct.OriginalAccount.html){target=\\_blank} storage. When a Polkadot account registers a mapping (via the [`map`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.map){target=\\_blank} function), the system stores the original 32-byte account ID, enabling the [`to_account_id`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_account_id){target=\\_blank} function to recover the exact original account rather than falling back to a default conversion."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 4, "depth": 3, "title": "Account Mapping for Native Polkadot Accounts", "anchor": "account-mapping-for-native-polkadot-accounts", "start_char": 4745, "end_char": 5913, "estimated_token_count": 250, "token_estimator": "heuristic-v1", "text": "### Account Mapping for Native Polkadot Accounts\n\nIf you have a native Polkadot account (32-byte format) that was created with a Polkadot/Substrate keypair (Ed25519/Sr25519) rather than an Ethereum-compatible keypair (secp256k1), you'll need to map your account to enable Ethereum compatibility.\n\nTo map your account, call the [`map_account`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/dispatchables/fn.map_account.html){target=\\_blank} extrinsic of the [`pallet_revive`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/index.html){target=\\_blank} pallet using your original Substrate account. This creates a stateful mapping that allows your 32-byte account to interact with the Ethereum-compatible smart contract system.\n\nOnce mapped, you'll be able to:\n\n- Transfer funds between 20-byte format addresses.\n- Interact with smart contracts using Ethereum-compatible tools like MetaMask.\n- Maintain full reversibility to your original 32-byte account format.\n\n!!! warning \"Mapping Requirement\"\n    Without this mapping, native Polkadot accounts cannot transfer funds or interact with the Ethereum-compatible layer on the Hub."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 5, "depth": 2, "title": "Account Registration", "anchor": "account-registration", "start_char": 5913, "end_char": 6358, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Account Registration\n\nThe registration process is implemented through the [`map`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.map){target=\\_blank} function. This process involves:\n\n- Checking if the account is already mapped.\n- Calculating and collecting required deposits based on data size.\n- Storing the address suffix for future reference.\n- Managing the currency holds for security."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 6, "depth": 2, "title": "Fallback Accounts", "anchor": "fallback-accounts", "start_char": 6358, "end_char": 6812, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Fallback Accounts\n\nThe fallback mechanism is integrated into the [`to_account_id`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_account_id){target=\\_blank} function. It provides a safety net for address conversion by:\n\n- First, attempting to retrieve stored mapping data.\n- Falling back to the default conversion method if no mapping exists.\n- Maintaining consistency in address representation."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 7, "depth": 2, "title": "Contract Address Generation", "anchor": "contract-address-generation", "start_char": 6812, "end_char": 7410, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Contract Address Generation\n\nThe system supports two methods for generating contract addresses:\n\n- [CREATE1 method](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/fn.create1.html){target=\\_blank}:\n\n    - Uses the deployer address and nonce.\n    - Generates deterministic addresses for standard contract deployment.\n\n- [CREATE2 method](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/fn.create2.html){target=\\_blank}:\n\n    - Uses the deployer address, initialization code, input data, and salt.\n    - Enables predictable address generation for advanced use cases."}
{"page_id": "polkadot-protocol-smart-contract-basics-accounts", "index": 8, "depth": 2, "title": "Security Considerations", "anchor": "security-considerations", "start_char": 7410, "end_char": 8540, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "## Security Considerations\n\nThe address mapping system maintains security through several design choices evident in the implementation:\n\n- The stateless mapping requires no privileged operations, as shown in the [`to_fallback_account_id`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_fallback_account_id){target=\\_blank} implementation.\n- The stateful mapping requires a deposit managed through the [`Currency`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/trait.Config.html#associatedtype.Currency){target=\\_blank} trait.\n- Mapping operations are protected against common errors through explicit checks.\n- The system prevents double-mapping through the [`ensure!(!Self::is_mapped(account_id))`](https://github.com/paritytech/polkadot-sdk/blob/stable2412/substrate/frame/revive/src/address.rs#L125){target=\\_blank} check.\n\nAll source code references are from the [`address.rs`](https://github.com/paritytech/polkadot-sdk/blob/stable2412/substrate/frame/revive/src/address.rs){target=\\_blank} file in the Revive pallet of the Polkadot SDK repository."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 206, "end_char": 650, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAsset Hub smart contracts operate within the Polkadot ecosystem using the [`pallet_revive`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/){target=\\_blank} implementation, which provides EVM compatibility. While many aspects of blocks and transactions are inherited from the underlying parachain architecture, there are specific considerations and mechanisms unique to smart contract operations on Asset Hub."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 1, "depth": 2, "title": "Smart Contract Blocks", "anchor": "smart-contract-blocks", "start_char": 650, "end_char": 1273, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Smart Contract Blocks\n\nSmart contract blocks in Asset Hub follow the same fundamental structure as parachain blocks, inheriting all standard parachain block components. The `pallet_revive` implementation maintains this consistency while adding necessary [EVM-specific features](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm){target=\\_blank}. For detailed implementation specifics, the [`Block`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Block.html){target=\\_blank} struct in `pallet_revive` demonstrates how parachain and smart contract block implementations align."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 2, "depth": 2, "title": "Smart Contract Transactions", "anchor": "smart-contract-transactions", "start_char": 1273, "end_char": 1497, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Smart Contract Transactions\n\nAsset Hub implements a sophisticated transaction system that supports various transaction types and formats, encompassing both traditional parachain operations and EVM-specific interactions."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 3, "depth": 3, "title": "EVM Transaction Types", "anchor": "evm-transaction-types", "start_char": 1497, "end_char": 3542, "estimated_token_count": 433, "token_estimator": "heuristic-v1", "text": "### EVM Transaction Types\n\nThe system provides a fundamental [`eth_transact`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/dispatchables/fn.eth_transact.html){target=\\_blank} interface for processing raw EVM transactions dispatched through [Ethereum JSON-RPC APIs](/develop/smart-contracts/json-rpc-apis/){target=\\_blank}. This interface acts as a wrapper for Ethereum transactions, requiring an encoded signed transaction payload, though it cannot be dispatched directly. Building upon this foundation, the system supports multiple transaction formats to accommodate different use cases and optimization needs:\n\n- **[Legacy transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.TransactionLegacyUnsigned.html){target=\\_blank}**: The original Ethereum transaction format, providing basic transfer and contract interaction capabilities. These transactions use a simple pricing mechanism and are supported for backward compatibility.\n\n- **[EIP-1559 transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Transaction1559Unsigned.html){target=\\_blank}**: An improved transaction format that introduces a more predictable fee mechanism with base fee and priority fee components. This format helps optimize gas fee estimation and network congestion management.\n\n- **[EIP-2930 transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Transaction2930Unsigned.html){target=\\_blank}**: Introduces access lists to optimize gas costs for contract interactions by pre-declaring accessed addresses and storage slots.\n\n- **[EIP-4844 transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Transaction4844Unsigned.html){target=\\_blank}**: Implements blob-carrying transactions, designed to optimize Layer 2 scaling solutions by providing dedicated space for roll-up data.\n\nEach transaction type can exist in both signed and unsigned states, with appropriate validation and processing mechanisms for each."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 4, "depth": 2, "title": "Fees and Gas", "anchor": "fees-and-gas", "start_char": 3542, "end_char": 3750, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Fees and Gas\n\nAsset Hub implements a sophisticated resource management system that combines parachain transaction fees with EVM gas mechanics, providing both Ethereum compatibility and enhanced features."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 5, "depth": 3, "title": "Gas Model Overview", "anchor": "gas-model-overview", "start_char": 3750, "end_char": 5538, "estimated_token_count": 330, "token_estimator": "heuristic-v1", "text": "### Gas Model Overview\n\nGas serves as the fundamental unit for measuring computational costs, with each network operation consuming a specified amount. This implementation maintains compatibility with Ethereum's approach while adding parachain-specific optimizations.\n\n- **Dynamic gas scaling**: Asset Hub implements a dynamic pricing mechanism that reflects actual execution performance. This results in:\n\n    - More efficient pricing for computational instructions relative to I/O operations.\n    - Better correlation between gas costs and actual resource consumption.\n    - Need for developers to implement flexible gas calculation rather than hardcoding values.\n\n- **Multi-dimensional resource metering**: Asset Hub extends beyond the traditional single-metric gas model to track three distinct resources.\n\n    - `ref_time` (computation time):\n\n        - Functions as traditional gas equivalent.\n        - Measures actual computational resource usage.\n        - Primary metric for basic operation costs.\n\n\n    - `proof_size` (verification overhead):\n\n        - Tracks state proof size required for validator verification.\n        - Helps manage consensus-related resource consumption.\n        - Important for cross-chain operations.\n\n\n    - `storage_deposit` (state management):\n\n        - Manages blockchain state growth.\n        - Implements a deposit-based system for long-term storage.\n        - Refundable when storage is freed.\n\nThese resources can be limited at both transaction and contract levels, similar to Ethereum's gas limits. For more information, check the [Gas Model](/polkadot-protocol/smart-contract-basics/evm-vs-polkavm#gas-model){target=\\_blank} section in the [EVM vs PolkaVM](/polkadot-protocol/smart-contract-basics/evm-vs-polkavm/){target=\\_blank} article."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 6, "depth": 3, "title": "Fee Components", "anchor": "fee-components", "start_char": 5538, "end_char": 6014, "estimated_token_count": 84, "token_estimator": "heuristic-v1", "text": "### Fee Components\n\n- Base fees:\n\n    - Storage deposit for contract deployment.\n    - Minimum transaction fee for network access.\n    - Network maintenance costs.\n\n- Execution fees:\n\n    - Computed based on gas consumption.\n    - Converted to native currency using network-defined rates.\n    - Reflects actual computational resource usage.\n\n- Storage fees:\n\n    - Deposit for long-term storage usage.\n    - Refundable when storage is freed.\n    - Helps prevent state bloat."}
{"page_id": "polkadot-protocol-smart-contract-basics-blocks-transactions-fees", "index": 7, "depth": 3, "title": "Gas Calculation and Conversion", "anchor": "gas-calculation-and-conversion", "start_char": 6014, "end_char": 6363, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "### Gas Calculation and Conversion\n\nThe system maintains precise conversion mechanisms between:\n\n- Substrate weights and EVM gas units.\n- Native currency and gas costs.\n- Different resource metrics within the multi-dimensional model.\n\nThis ensures accurate fee calculation while maintaining compatibility with existing Ethereum tools and workflows."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 190, "end_char": 631, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhile [PolkaVM](/polkadot-protocol/smart-contract-basics/polkavm-design/){target=\\_blank} strives for maximum Ethereum compatibility, several fundamental design decisions create necessary divergences from the [EVM](https://ethereum.org/en/developers/docs/evm/){target=\\_blank}. These differences represent trade-offs that enhance performance and resource management while maintaining accessibility for Solidity developers."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 1, "depth": 2, "title": "Core Virtual Machine Architecture", "anchor": "core-virtual-machine-architecture", "start_char": 631, "end_char": 3065, "estimated_token_count": 479, "token_estimator": "heuristic-v1", "text": "## Core Virtual Machine Architecture\n\nThe most significant departure from Ethereum comes from PolkaVM's foundation itself. Rather than implementing the EVM, PolkaVM utilizes a RISC-V instruction set. For most Solidity developers, this architectural change remains transparent thanks to the [Revive compiler's](https://github.com/paritytech/revive){target=\\_blank} complete Solidity support, including inline assembler functionality.\n\n```mermaid\ngraph TD\n    subgraph \"Ethereum Path\"\n        EthCompile[\"Standard Solidity Compiler\"] --> EVM_Bytecode[\"EVM Bytecode\"]\n        EVM_Bytecode --> EVM[\"Stack-based EVM\"]\n        EVM --> EthExecution[\"Contract Execution\"]\n    end\n\n    subgraph \"PolkaVM Path\"\n        ReviveCompile[\"Revive Compiler\"] --> RISCV_Bytecode[\"RISC-V Format Bytecode\"]\n        RISCV_Bytecode --> PolkaVM[\"RISC-V Based PolkaVM\"]\n        PolkaVM --> PolkaExecution[\"Contract Execution\"]\n    end\n\n    EthExecution -.-> DifferencesNote[\"Key Differences:\n    - Instruction Set Architecture\n    - Bytecode Format\n    - Runtime Behavior\"]\n    PolkaExecution -.-> DifferencesNote\n```\n\nHowever, this architectural difference becomes relevant in specific scenarios. Tools that attempt to download and inspect contract bytecode will fail, as they expect EVM bytecode rather than PolkaVM's RISC-V format. Most applications typically pass bytecode as an opaque blob, making this a non-issue for standard use cases.\n\nThis primarily affects contracts using [`EXTCODECOPY`](https://www.evm.codes/?fork=cancun#3c){target=\\_blank} to manipulate code at runtime. A contract encounters problems specifically when it uses `EXTCODECOPY` to copy contract code into memory and then attempts to mutate it. This pattern is not possible in standard Solidity and requires dropping down to YUL assembly. An example would be a factory contract written in assembly that constructs and instantiates new contracts by generating code at runtime. Such contracts are rare in practice.\n\nPolkaVM offers an elegant alternative through its [on-chain constructors](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/struct.Pallet.html#method.bare_instantiate){target=\\_blank}, enabling contract instantiation without runtime code modification, making this pattern unnecessary. This architectural difference also impacts how contract deployment works more broadly, as discussed in the [Contract Deployment](#contract-deployment) section."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 2, "depth": 3, "title": "High-Level Architecture Comparison", "anchor": "high-level-architecture-comparison", "start_char": 3065, "end_char": 5064, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "### High-Level Architecture Comparison\n\n|            Feature            |                            Ethereum Virtual Machine (EVM)                            |                        PolkaVM                         |\n|:-----------------------------:|:------------------------------------------------------------------------------------:|:------------------------------------------------------:|\n|      **Instruction Set**      |                               Stack-based architecture                               |                 RISC-V instruction set                 |\n|      **Bytecode Format**      |                                     EVM bytecode                                     |                     RISC-V format                      |\n|    **Contract Size Limit**    |                                 24KB code size limit                                 |            Contract-specific memory limits             |\n|         **Compiler**          |                                  Solidity Compiler                                   |                    Revive Compiler                     |\n|      **Inline Assembly**      |                                      Supported                                       |         Supported with the compatibility layer         |\n|    **Code Introspection**     | Supported via [`EXTCODECOPY`](https://www.evm.codes/?fork=cancun#3c){target=\\_blank} | Limited support, alternative via on-chain constructors |\n|     **Resource Metering**     |                                  Single gas metric                                   |                   Multi-dimensional                    |\n| **Runtime Code Modification** |                                      Supported                                       |               Limited, with alternatives               |\n|  **Contract Instantiation**   |                                 Standard deployment                                  |    On-chain constructors for flexible instantiation    |"}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 3, "depth": 2, "title": "Gas Model", "anchor": "gas-model", "start_char": 5064, "end_char": 5559, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Gas Model\n\nEthereum's resource model relies on a single metric: [gas](https://ethereum.org/en/developers/docs/gas/#what-is-gas){target=\\_blank}, which serves as the universal unit for measuring computational costs. Each operation on the network consumes a specific amount of gas. Most platforms aiming for Ethereum compatibility typically adopt identical gas values to ensure seamless integration.\n\nThe significant changes to Ethereum's gas model will be outlined in the following sections."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 4, "depth": 3, "title": "Dynamic Gas Value Scaling", "anchor": "dynamic-gas-value-scaling", "start_char": 5559, "end_char": 5902, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "### Dynamic Gas Value Scaling\n\nInstead of adhering to Ethereum's fixed gas values, PolkaVM implements benchmark-based pricing that better reflects its improved execution performance. This makes instructions cheaper relative to I/O-bound operations but requires developers to avoid hardcoding gas values, particularly in cross-contract calls."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 5, "depth": 3, "title": "Multi-Dimensional Resource Metering", "anchor": "multi-dimensional-resource-metering", "start_char": 5902, "end_char": 8048, "estimated_token_count": 461, "token_estimator": "heuristic-v1", "text": "### Multi-Dimensional Resource Metering\n\nMoving beyond Ethereum's single gas metric, PolkaVM meters three distinct resources:\n\n- **`ref_time`**: Equivalent to traditional gas, measuring computation time.\n- **`proof_size`**: Tracks state proof size for validator verification.\n- **`storage_deposit`**: Manages state bloat through a deposit system.\n\nAll three resources can be limited at the transaction level, just like gas on Ethereum. The [Ethereum RPC proxy](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/revive/rpc){target=\\_blank} maps all three dimensions into the single gas dimension, ensuring everything behaves as expected for users.\n\nThese resources can also be limited when making cross-contract calls, which is essential for security when interacting with untrusted contracts. However, Solidity only allows specifying `gas_limit` for cross-contract calls. The `gas_limit` is most similar to Polkadots `ref_time_limit`, but the Revive compiler doesn't supply any imposed `gas_limit` for cross-contract calls for two key reasons:\n\n- **Semantic differences**: `gas_limit` and `ref_time_limit` are not semantically identical; blindly passing EVM gas as `ref_time_limit` can lead to unexpected behavior.\n- **Incomplete protection**: The other two resources (`proof_size` and `storage_deposit`) would remain uncapped anyway, making it insufficient to prevent malicious callees from performing DOS attacks.\n\nWhen resources are \"uncapped\" in cross-contract calls, they remain constrained by transaction-specified limits, preventing abuse of the transaction signer.\n\n!!! note\n    The runtime will provide a special precompile, allowing cross-contract calls with limits specified for all weight dimensions in the future.\n\nAll gas-related opcodes like [`GAS`](https://www.evm.codes/?fork=cancun#5a){target=\\_blank} or [`GAS_LIMIT`](https://www.evm.codes/?fork=cancun#45){target=\\_blank} return only the `ref_time` value as it's the closest match to traditional gas. Extended APIs will be provided through precompiles to make full use of all resources, including cross-contract calls with all three resources specified."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 6, "depth": 2, "title": "Memory Management", "anchor": "memory-management", "start_char": 8048, "end_char": 10028, "estimated_token_count": 413, "token_estimator": "heuristic-v1", "text": "## Memory Management\n\nThe EVM and the PolkaVM take fundamentally different approaches to memory constraints:\n\n|         Feature          |      Ethereum Virtual Machine (EVM)       |                    PolkaVM                     |\n|:------------------------:|:-----------------------------------------:|:----------------------------------------------:|\n|  **Memory Constraints**  |      Indirect control via gas costs       |        Hard memory limits per contract         |\n|      **Cost Model**      | Increasing gas curve with allocation size |    Fixed costs separated from execution gas    |\n|    **Memory Limits**     | Soft limits through prohibitive gas costs |         Hard fixed limits per contract         |\n|  **Pricing Efficiency**  |     Potential overcharging for memory     | More efficient through separation of concerns  |\n|   **Contract Nesting**   |         Limited by available gas          |    Limited by constant memory per contract     |\n|   **Memory Metering**    |     Dynamic based on total allocation     |      Static limits per contract instance       |\n| **Future Improvements**  |       Incremental gas cost updates        | Potential dynamic metering for deeper nesting  |\n| **Cross-Contract Calls** |      Handled through gas forwarding       | Requires careful boundary limit implementation |\n\nThe architecture establishes a constant memory limit per contract, which is the basis for calculating maximum contract nesting depth. This calculation assumes worst-case memory usage for each nested contract, resulting in a straightforward but conservative limit that operates independently of actual memory consumption. Future iterations may introduce dynamic memory metering, allowing deeper nesting depths for contracts with smaller memory footprints. However, such an enhancement would require careful implementation of cross-contract boundary limits before API stabilization, as it would introduce an additional resource metric to the system."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 7, "depth": 3, "title": "Current Memory Limits", "anchor": "current-memory-limits", "start_char": 10028, "end_char": 10853, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "### Current Memory Limits\n\nThe following table depicts memory-related limits at the time of writing:\n\n|                   Limit                    |     Maximum     |\n|:------------------------------------------:|:---------------:|\n|              Call stack depth              |        5        |\n|                Event topics                |        4        |\n| Event data payload size (including topics) |    416 bytes    |\n|             Storage value size             |    416 bytes    |\n|        Transient storage variables         | 128 uint values |\n|            Immutable variables             | 16 uint values  |\n|          Contract code blob size           | ~100 kilobytes  |\n\n!!! note\n    Limits might be increased in the future. To guarantee existing contracts work as expected, limits will never be decreased."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 8, "depth": 2, "title": "Account Management - Existential Deposit", "anchor": "account-management-existential-deposit", "start_char": 10853, "end_char": 11015, "estimated_token_count": 22, "token_estimator": "heuristic-v1", "text": "## Account Management - Existential Deposit\n\nEthereum and Polkadot handle account persistence differently, affecting state management and contract interactions:"}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 9, "depth": 3, "title": "Account Management Comparison", "anchor": "account-management-comparison", "start_char": 11015, "end_char": 13380, "estimated_token_count": 470, "token_estimator": "heuristic-v1", "text": "### Account Management Comparison\n\n|          Feature          |                   Ethereum Approach                   |               PolkaVM/Polkadot Approach                |\n|:-------------------------:|:-----------------------------------------------------:|:------------------------------------------------------:|\n|  **Account Persistence**  | Accounts persist indefinitely, even with zero balance | Requires existential deposit (ED) to maintain account  |\n|    **Minimum Balance**    |                         None                          |                      ED required                       |\n|   **Account Deletion**    |               Accounts remain in state                |      Accounts below ED are automatically deleted       |\n|   **Contract Accounts**   |                  Exist indefinitely                   |                    Must maintain ED                    |\n|   **Balance Reporting**   |                 Reports full balance                  |      Reports ED-adjusted balance via Ethereum RPC      |\n| **New Account Transfers** |                   Standard transfer                   |     Includes ED automatically with extra fee cost      |\n| **Contract-to-Contract**  |                   Direct transfers                    | ED drawn from transaction signer, not sending contract |\n|   **State Management**    |      Potential bloat from zero-balance accounts       |     Optimized with auto-deletion of dust accounts      |\n\nThis difference introduces potential compatibility challenges for Ethereum-based contracts and tools, particularly wallets. To mitigate this, PolkaVM implements several transparent adjustments:\n\n- Balance queries via Ethereum RPC automatically deduct the ED, ensuring reported balances match spendable amounts.\n- Account balance checks through EVM opcodes reflect the ED-adjusted balance.\n- Transfers to new accounts automatically include the ED (`x + ED`), with the extra cost incorporated into transaction fees.\n- Contract-to-contract transfers handle ED requirements by:\n    - Drawing ED from the transaction signer instead of the sending contract.\n    - Keeping transfer amounts transparent for contract logic.\n    - Treating ED like other storage deposit costs.\n\nThis approach ensures that Ethereum contracts work without modifications while maintaining Polkadot's optimized state management."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 10, "depth": 2, "title": "Contract Deployment", "anchor": "contract-deployment", "start_char": 13380, "end_char": 15238, "estimated_token_count": 327, "token_estimator": "heuristic-v1", "text": "## Contract Deployment\n\nFor most users deploying contracts (like ERC-20 tokens), contract deployment works seamlessly without requiring special steps. However, when using advanced patterns like factory contracts that dynamically create other contracts at runtime, you'll need to understand PolkaVM's unique deployment model.\n\nIn the PolkaVM, contract deployment follows a fundamentally different model from EVM. The EVM allows contracts to be deployed with a single transaction, where the contract code is bundled with the deployment transaction. In contrast, PolkaVM has a different process for contract instantiation.\n\n- **Code must be pre-uploaded**: Unlike EVM, where contract code is bundled within the deploying contract, PolkaVM requires all contract bytecode to be uploaded to the chain before instantiation.\n- **Factory pattern limitations**: The common EVM pattern, where contracts dynamically create other contracts, will fail with a `CodeNotFound` error unless the dependent contract code was previously uploaded.\n- **Separate upload and instantiation**: This creates a two-step process where developers must first upload all contract code, then instantiate relationships between contracts.\n\nThis architecture impacts several common EVM patterns and requires developers to adapt their deployment strategies accordingly. _Factory contracts must be modified to work with pre-uploaded code rather than embedding bytecode_, and runtime code generation is not supported due to PolkaVM's RISC-V bytecode format. The specific behavior of contract creation opcodes is detailed in the [YUL IR Translation](#yul-function-translation-differences) section.\n\nWhen migrating EVM projects to PolkaVM, developers should identify all contracts that will be instantiated at runtime and ensure they are pre-uploaded to the chain before any instantiation attempts."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 11, "depth": 2, "title": "Solidity and YUL IR Translation Incompatibilities", "anchor": "solidity-and-yul-ir-translation-incompatibilities", "start_char": 15238, "end_char": 15583, "estimated_token_count": 52, "token_estimator": "heuristic-v1", "text": "## Solidity and YUL IR Translation Incompatibilities\n\nWhile PolkaVM maintains high-level compatibility with Solidity, several low-level differences exist in the translation of YUL IR and specific Solidity constructs. These differences are particularly relevant for developers working with assembly code or utilizing advanced contract patterns."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 12, "depth": 3, "title": "Contract Code Structure", "anchor": "contract-code-structure", "start_char": 15583, "end_char": 16543, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "### Contract Code Structure\n\nPolkaVM's contract runtime does not differentiate between runtime code and deploy (constructor) code. Instead, both are emitted into a single PolkaVM contract code blob and live on-chain. Therefore, in EVM terminology, the deploy code equals the runtime code. For most standard Solidity contracts, this is transparent. However, if you are analyzing raw bytecode or building tools that expect separate deploy and runtime sections, you'll need to adjust for this unified structure.\n\nIn the constructor code, the `codesize` instruction returns the call data size instead of the actual code blob size, which differs from standard EVM behavior. Developers might consider that the constructor logic uses `codesize` to inspect the deployed contract's size (e.g., for self-validation or specific deployment patterns); this will return an incorrect value on PolkaVM. Re-evaluate such logic or use alternative methods to achieve your goal."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 13, "depth": 3, "title": "Solidity-Specific Differences", "anchor": "solidity-specific-differences", "start_char": 16543, "end_char": 17091, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "### Solidity-Specific Differences\n\nSolidity constructs behave differently under PolkaVM:\n\n- **`address.creationCode`**: Returns the bytecode keccak256 hash instead of the actual creation code, reflecting PolkaVM's hash-based code referencing system.\n    - If your contract relies on `address.creationCode` to verify or interact with the full raw bytecode of a newly deployed contract, this will not work as expected. You will receive a hash, not the code itself. This typically affects highly specialized factory contracts or introspection tools."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 14, "depth": 3, "title": "YUL Function Translation Differences", "anchor": "yul-function-translation-differences", "start_char": 17091, "end_char": 24319, "estimated_token_count": 1348, "token_estimator": "heuristic-v1", "text": "### YUL Function Translation Differences\n\nThe following YUL functions exhibit notable behavioral differences in PolkaVM:\n\n- Memory operations:\n\n    - **`mload`, `mstore`, `msize`, `mcopy`**: PolkaVM preserves memory layout but implements several constraints.\n\n        - EVM linear heap memory is emulated using a fixed 64KB byte buffer, limiting maximum contract memory usage.\n        - Accessing memory offsets larger than the buffer size traps the contract with an `OutOfBound` error.\n        - Compiler optimizations may eliminate unused memory operations, potentially causing `msize` to differ from EVM behavior.\n\n        For Solidity developers, the compiler generally handles memory efficiently within this 64KB limit. However, if you are writing low-level YUL assembly and perform direct memory manipulations, you must respect the 64KB buffer limit. Attempting to access memory outside this range will cause your transaction to revert. Be aware that `msize` might not always reflect the exact EVM behavior if compiler optimizations occur.\n\n- Call data operations:\n\n    - **`calldataload`, `calldatacopy`**: In constructor code, the offset parameter is ignored and these functions always return `0`, diverging from EVM behavior where call data represents constructor arguments.\n\n        - If your constructor logic in YUL assembly attempts to read constructor arguments using `calldataload` or `calldatacopy` with specific offsets, this will not yield the expected constructor arguments. Instead, these functions will return `zeroed` values. Standard Solidity constructors are handled correctly by the compiler, but manual YUL assembly for constructor argument parsing will need adjustment.\n\n- Code operations:\n\n    - **`codecopy`**: Only supported within constructor code, reflecting PolkaVM's different approach to code handling and the unified code blob structure.\n\n        - If your contracts use `codecopy` (e.g., for self-modifying code or inspecting other contract's runtime bytecode) outside of the constructor, this will not be supported and will likely result in a compile-time error or runtime trap. This implies that patterns like dynamically generating or modifying contract code at runtime are not directly feasible with `codecopy` on PolkaVM.\n\n- Control flow:\n\n    - **`invalid`**: Traps the contract execution but does not consume remaining gas, unlike EVM where it consumes all available gas.\n\n        - While `invalid` still reverts the transaction, the difference in gas consumption could subtly affect very specific error handling or gas accounting patterns that rely on `invalid` to consume all remaining gas. For most error scenarios, `revert()` is the standard and recommended practice.\n\n- Cross-contract calls:\n\n    - **`call`, `delegatecall`, `staticall`**: These functions ignore supplied gas limits and forward all remaining resources due to PolkaVM's multi-dimensional resource model. This creates important security implications:\n\n        - Contract authors must implement reentrancy protection since gas stipends don't provide protection.\n        - The compiler detects `address payable.{send,transfer}` patterns and disables call reentrancy as a protective heuristic.\n        - Using `address payable.{send,transfer}` is already deprecated; PolkaVM will provide dedicated precompiles for safe balance transfers.\n\n        The traditional EVM pattern of limiting gas in cross-contract calls (especially with the 2300 gas stipend for send/transfer) does not provide reentrancy protection on PolkaVM. Developers must explicitly implement reentrancy guards (e.g., using a reentrancy lock mutex) in their Solidity code when making external calls to untrusted contracts. Relying on gas limits alone for reentrancy prevention is unsafe and will lead to vulnerabilities on PolkaVM.\n\n        !!! warning\n            The 2300 gas stipend that is provided by solc for address payable.{send, transfer} calls offers no reentrancy protection in PolkaVM. While the compiler attempts to detect and mitigate this pattern, developers should avoid these deprecated functions.\n\n- Contract creation:\n\n    - **`create`, `create2`**: Contract instantiation works fundamentally differently in PolkaVM. Instead of supplying deploy code concatenated with constructor arguments, the runtime expects:\n\n        1. A buffer containing the code hash to deploy.\n        2. The constructor arguments buffer.\n\n        PolkaVM translates `dataoffset` and `datasize` instructions to handle contract hashes instead of contract code, enabling seamless use of the `new` keyword in Solidity. However, this translation may fail for contracts creating other contracts within `assembly` blocks.\n\n        If you use the Solidity `new` keyword to deploy contracts, the Revive compiler handles this transparently. However, if you are creating contracts manually in YUL assembly using `create` or `create2` opcodes, you must provide the code hash of the contract to be deployed, not its raw bytecode. Attempting to pass raw bytecode will fail. This fundamentally changes how manual contract creation is performed in assembly.\n\n        !!! warning\n            Avoid using `create` family opcodes for manual deployment crafting in `assembly` blocks. This pattern is discouraged due to translation complexity and offers no gas savings benefits in PolkaVM.\n\n- Data operations:\n\n    - **`dataoffset`**: Returns the contract hash instead of code offset, aligning with PolkaVM's hash-based code referencing.\n    - **`datasize`**: Returns the constant contract hash size (32 bytes) rather than variable code size.\n\n    These changes are primarily relevant for low-level YUL assembly developers who are trying to inspect or manipulate contract code directly. `dataoffset` will provide a hash, not a memory offset to the code, and `datasize` will always be 32 bytes (the size of a hash). This reinforces that direct manipulation of contract bytecode at runtime, as might be done in some EVM patterns, is not supported.\n\n- Resource queries:\n\n    - **`gas`, `gaslimit`**: Return only the `ref_time` component of PolkaVM's multi-dimensional weight system, providing the closest analog to traditional gas measurements.\n\n        - While `gas` and `gaslimit` still provide a useful metric, consider that they represent `ref_time` (computation time) only. If your contract logic depends on precise knowledge of other resource costs (like `proof_size` or `storage_deposit`), you won't get that information from these opcodes. You'll need to use future precompiles for full multi-dimensional resource queries.\n\n- Blockchain state:\n\n    - **`prevrandao`, `difficulty`**: Both translate to a constant value of `2500000000000000`, as PolkaVM doesn't implement Ethereum's difficulty adjustment or randomness mechanisms.\n\n        - If your Solidity contract relies on `block.difficulty` (or its equivalent YUL opcode `difficulty`) for randomness generation or any logic tied to Ethereum's proof-of-work difficulty, this will not provide true randomness on PolkaVM. The value will always be constant. Developers needing on-chain randomness should utilize Polkadot's native randomness sources or dedicated VRF (Verifiable Random Function) solutions if available."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 15, "depth": 3, "title": "Unsupported Operations", "anchor": "unsupported-operations", "start_char": 24319, "end_char": 25726, "estimated_token_count": 270, "token_estimator": "heuristic-v1", "text": "### Unsupported Operations\n\nSeveral EVM operations are not supported in PolkaVM and produce compile-time errors:\n\n- **`pc`, `extcodecopy`**: These operations are EVM-specific and have no equivalent functionality in PolkaVM's RISC-V architecture.\n\n    - Any Solidity contracts that utilize inline assembly to interact with `pc` (program counter) or `extcodecopy` will fail to compile or behave unexpectedly. This means patterns involving introspection of the current execution location or copying external contract bytecode at runtime are not supported.\n\n- **`blobhash`, `blobbasefee`**: Related to Ethereum's rollup model and blob data handling, these operations are unnecessary given Polkadot's superior rollup architecture.\n\n    - If you are porting contracts designed for Ethereum's EIP-4844 (proto-danksharding) and rely on these blob-related opcodes, they will not be available on PolkaVM.\n\n- **`extcodecopy`, `selfdestruct`**: These deprecated operations are not supported and generate compile-time errors.\n\n    - The `selfdestruct` opcode, which allowed contracts to remove themselves from the blockchain, is not supported. Contracts cannot be self-destroyed on PolkaVM. This affects contract upgradeability patterns that rely on self-destruction and redeployment. Similarly, `extcodecopy` is unsupported, impacting contracts that intend to inspect or copy the bytecode of other deployed contracts."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 16, "depth": 3, "title": "Compilation Pipeline Considerations", "anchor": "compilation-pipeline-considerations", "start_char": 25726, "end_char": 26425, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "### Compilation Pipeline Considerations\n\nPolkaVM processes YUL IR exclusively, meaning all contracts exhibit behavior consistent with Solidity's `via-ir` compilation mode. Developers familiar with the legacy compilation pipeline should expect [IR-based codegen behavior](https://docs.soliditylang.org/en/latest/ir-breaking-changes.html){target=\\_blank} when working with PolkaVM contracts.\n\nIf you've previously worked with older Solidity compilers that did not use the `via-ir` pipeline by default, you might observe subtle differences in compiled bytecode size or gas usage. It's recommended to familiarize yourself with Solidity's IR-based codegen behavior, as this is the standard for PolkaVM."}
{"page_id": "polkadot-protocol-smart-contract-basics-evm-vs-polkavm", "index": 17, "depth": 3, "title": "Memory Pointer Limitations", "anchor": "memory-pointer-limitations", "start_char": 26425, "end_char": 27687, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Memory Pointer Limitations\n\nYUL functions accepting memory buffer offset pointers or size arguments are limited by PolkaVM's 32-bit pointer size. Supplying values above `2^32-1` will trap the contract immediately. The Solidity compiler typically generates valid memory references, making this primarily a concern for low-level assembly code.\n\nFor standard Solidity development, this limitation is unlikely to be hit as the compiler handles memory addresses correctly within typical contract sizes. However, if you are writing extremely large contracts using YUL assembly that manually and extensively manipulate memory addresses, ensure that your memory offsets and sizes do not exceed PolkaVM's **fixed 64KB memory limit per contract**. While the YUL functions might accept 32-bit pointers (up to 2^32-1), attempting to access memory beyond the allocated 64KB buffer will trap the contract immediately.\n\nThese incompatibilities reflect the fundamental architectural differences between EVM and PolkaVM while maintaining high-level Solidity compatibility. Most developers using standard Solidity patterns will encounter no issues, but those working with assembly code or advanced contract patterns should carefully review these differences during migration."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 184, "end_char": 815, "estimated_token_count": 96, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub provides smart contract functionality across multiple networks to facilitate smart contract development in the Polkadot ecosystem. Whether you're testing new contracts or deploying to production, Polkadot Hub offers several network environments tailored for each stage of development. Developers can thoroughly test, iterate, and validate their smart contracts from local testing environments to production networks like Polkadot Hub.\n\nThis guide will introduce you to the current and upcoming networks available for smart contract development and explain how they fit into the development workflow."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 1, "depth": 2, "title": "Network Overview", "anchor": "network-overview", "start_char": 815, "end_char": 2107, "estimated_token_count": 219, "token_estimator": "heuristic-v1", "text": "## Network Overview\n\nSmart contract development on Polkadot Hub follows a structured process to ensure rigorous testing of new contracts and upgrades before deployment on production networks. Development progresses through a well-defined path, beginning with local environments, advancing through TestNets, and ultimately reaching MainNets. The diagram below illustrates this progression:\n\n``` mermaid\nflowchart LR\n    id1[Local Polkadot Hub] --> id2[TestNet Polkadot Hub] --> id4[MainNet Polkadot Hub]\n```\n\nThis progression ensures developers can thoroughly test and iterate their smart contracts without risking real tokens or affecting production networks. A typical development journey consists of three main stages:\n\n1. Local development:\n\n    - Developers start in a local environment to create, test, and iterate on smart contracts.\n    - Provides rapid experimentation in an isolated setup without external dependencies.\n\n2. TestNet development:\n\n    - Contracts move to TestNets like Westend Hub and Passet Hub.\n    - Enables testing in simulated real-world conditions without using real tokens.\n\n3. Production deployment:\n\n    - Final deployment to MainNets like Kusama Hub and Polkadot Hub.\n    - Represents the live environment where contracts interact with real economic value."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 2, "depth": 2, "title": "Local Development", "anchor": "local-development", "start_char": 2107, "end_char": 3110, "estimated_token_count": 202, "token_estimator": "heuristic-v1", "text": "## Local Development\n\nThe local development environment is crucial for smart contract development on Polkadot Hub. It provides developers a controlled space for rapid testing and iteration before moving to public networks. The local setup consists of several key components:\n\n- **[Kitchensink node](https://paritytech.github.io/polkadot-sdk/master/kitchensink_runtime/index.html){target=\\_blank}**: A local node that can be run for development and testing. It includes logging capabilities for debugging contract execution and provides a pre-configured development environment with pre-funded accounts for testing purposes.\n- **[Ethereum RPC proxy](https://paritytech.github.io/polkadot-sdk/master/pallet_revive_eth_rpc/index.html){target=\\_blank}**: Bridges Ethereum-compatible tools with the Polkadot SDK-based network. It enables seamless integration with popular development tools like MetaMask and Remix IDE. The purpose of this component is to translate Ethereum RPC calls into Substrate format."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 3, "depth": 2, "title": "Test Networks", "anchor": "test-networks", "start_char": 3110, "end_char": 3541, "estimated_token_count": 96, "token_estimator": "heuristic-v1", "text": "## Test Networks\n\nThe following test networks provide controlled environments for testing smart contracts. TestNet tokens are available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}. They provide a stable environment for testing your contracts without using real tokens.\n\n``` mermaid\nflowchart TB\n    id1[Polkadot Hub TestNets] --> id2[Passet Hub]\n    id1[Polkadot Hub TestNets] --> id3[Westend Hub]\n```"}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 4, "depth": 3, "title": "Passet Hub", "anchor": "passet-hub", "start_char": 3541, "end_char": 3822, "estimated_token_count": 47, "token_estimator": "heuristic-v1", "text": "### Passet Hub\n\nThe Passet Hub will be a community-managed TestNet designed specifically for smart contract development. It will mirror Asset Hub's runtime and provide developers with an additional environment for testing their contracts before deployment to production networks."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 5, "depth": 3, "title": "Westend Hub", "anchor": "westend-hub", "start_char": 3822, "end_char": 4090, "estimated_token_count": 46, "token_estimator": "heuristic-v1", "text": "### Westend Hub\n\nWestend Hub is the TestNet for smart contract development and its cutting-edge features. The network maintains the same features and capabilities as the production Polkadot Hub, and also incorporates the latest features developed by core developers."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 6, "depth": 2, "title": "Production Networks", "anchor": "production-networks", "start_char": 4090, "end_char": 4427, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Production Networks\n\nThe MainNet environments represent the final destination for thoroughly tested and validated smart contracts, where they operate with real economic value and serve actual users.\n\n``` mermaid\nflowchart TB\n    id1[Polkadot Hub MainNets] --> id2[Polkadot Hub]\n    id1[Polkadot Hub MainNets] --> id3[Kusama Hub]\n```"}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 7, "depth": 3, "title": "Polkadot Hub", "anchor": "polkadot-hub", "start_char": 4427, "end_char": 4792, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "### Polkadot Hub\n\nPolkadot Hub is the primary production network for deploying smart contracts in the Polkadot ecosystem. It provides a secure and stable environment for running smart contracts with real economic value. The network supports PolkaVM-compatible contracts written in Solidity or Rust, maintaining compatibility with Ethereum-based development tools."}
{"page_id": "polkadot-protocol-smart-contract-basics-networks", "index": 8, "depth": 3, "title": "Kusama Hub", "anchor": "kusama-hub", "start_char": 4792, "end_char": 5110, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Kusama Hub\n\nKusama Hub is the canary version of Polkadot Hub. It is designed for developers who want to move quickly and test their smart contracts in a real-world environment with economic incentives. It provides a more flexible space for innovation while maintaining the same core functionality as Polkadot Hub."}
{"page_id": "polkadot-protocol-smart-contract-basics-overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 231, "end_char": 1692, "estimated_token_count": 301, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot is designed to support an ecosystem of parachains, rather than hosting smart contracts directly. Developers aiming to build smart contract applications on Polkadot rely on parachains within the ecosystem that provide smart contract functionality.\n\nThis guide outlines the primary approaches to developing smart contracts in the Polkadot ecosystem:\n\n- **PolkaVM-compatible contracts**: Support Solidity and any language that compiles down to RISC-V while maintaining compatibility with Ethereum based tools.\n- **EVM-compatible contracts**: Support languages like [Solidity](https://soliditylang.org/){target=\\_blank} and [Vyper](https://vyperlang.org/){target=\\_blank}, offering compatibility with popular Ethereum tools and wallets.\n- **Wasm-based smart contracts**: Using [ink!](https://use.ink/){target=\\_blank}, a Rust-based embedded domain-specific language (eDSL), enabling developers to leverage Rust’s safety and tooling.\n\nYou'll explore the key differences between these development paths, along with considerations for parachain developers integrating smart contract functionality.\n\n!!!note \"Parachain Developer?\"\n    If you are a parachain developer looking to add smart contract functionality to your chain, please refer to the [Add Smart Contract Functionality](/develop/parachains/customize-parachain/add-smart-contract-functionality/){target=\\_blank} page, which covers both Wasm and EVM-based contract implementations."}
{"page_id": "polkadot-protocol-smart-contract-basics-overview", "index": 1, "depth": 2, "title": "Smart Contracts Versus Parachains", "anchor": "smart-contracts-versus-parachains", "start_char": 1692, "end_char": 4949, "estimated_token_count": 706, "token_estimator": "heuristic-v1", "text": "## Smart Contracts Versus Parachains\n\nA smart contract is a program that executes specific logic isolated to the chain on which it is being executed. All the logic executed is bound to the same state transition rules determined by the underlying virtual machine (VM). Consequently, smart contracts are more streamlined to develop, and programs can easily interact with each other through similar interfaces.\n\n``` mermaid\nflowchart LR\n  subgraph A[Chain State]\n    direction LR\n    B[\"Program Logic and Storage<br/>(Smart Contract)\"]\n    C[\"Tx Relevant Storage\"]\n  end\n  A --> D[[Virtual Machine]]\n  E[Transaction] --> D\n  D --> F[(New State)]\n  D --> G[Execution Logs]\n  style A fill:#ffffff,stroke:#000000,stroke-width:1px\n```\n\nIn addition, because smart contracts are programs that execute on top of existing chains, teams don't have to think about the underlying consensus they are built on.\n\nThese strengths do come with certain limitations. Some smart contracts environments, like EVM, tend to be immutable by default. Developers have developed different [proxy strategies](https://blog.openzeppelin.com/proxy-patterns){target=\\_blank} to be able to upgrade smart contracts over time. The typical pattern relies on a proxy contract which holds the program storage forwarding a call to an implementation contract where the execution logic resides. Smart contract upgrades require changing the implementation contract while retaining the same storage structure, necessitating careful planning.\n\nAnother downside is that smart contracts often follow a gas metering model, where program execution is associated with a given unit and a marketplace is set up to pay for such an execution unit. This fee system is often very rigid, and some complex flows, like account abstraction, have been developed to circumvent this problem.\n\nIn contrast, parachains can create their own custom logics (known as pallets or modules), and combine them as the state transition function (STF or runtime) thanks to the modularity provided by the [Polkadot-SDK](https://github.com/paritytech/polkadot-sdk/){target=\\_blank}. The different pallets within the parachain runtime can give developers a lot of flexibility when building applications on top of it.\n\n``` mermaid\nflowchart LR\n    A[(Chain State)] --> B[[\"STF<br/>[Pallet 1]<br/>[Pallet 2]<br/>...<br/>[Pallet N]\"]]\n    C[Transaction<br/>Targeting Pallet 2] --> B\n    B --> E[(New State)]\n    B --> F[Execution Logs]\n```\n\nParachains inherently offer features such as logic upgradeability, flexible transaction fee mechanisms, and chain abstraction logic. More so, by using Polkadot, parachains can benefit from robust consensus guarantees with little engineering overhead.\n\nTo read more about the differences between smart contracts and parachain runtimes, see the [Runtime vs. Smart Contracts](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/runtime_vs_smart_contract/index.html){target=\\_blank} section of the Polkadot SDK Rust docs. For a more in-depth discussion about choosing between runtime development and smart contract development, see the Stack Overflow post on [building a Polkadot SDK runtime versus a smart contract](https://stackoverflow.com/a/56041305){target=\\_blank}."}
{"page_id": "polkadot-protocol-smart-contract-basics-overview", "index": 2, "depth": 2, "title": "Building a Smart Contract", "anchor": "building-a-smart-contract", "start_char": 4949, "end_char": 6258, "estimated_token_count": 377, "token_estimator": "heuristic-v1", "text": "## Building a Smart Contract\n\nThe Polkadot SDK supports multiple smart contract execution environments:\n\n- **PolkaVM**: A cutting-edge virtual machine tailored to optimize smart contract execution on Polkadot. Unlike traditional EVMs, PolkaVM is built with a [RISC-V-based register architecture](https://en.wikipedia.org/wiki/RISC-V){target=\\_blank} for increased performance and scalability.\n- **EVM**: Through [Frontier](https://github.com/polkadot-evm/frontier){target=\\_blank}. It consists of a full Ethereum JSON RPC compatible client, an Ethereum emulation layer, and a [Rust-based EVM](https://github.com/rust-ethereum/evm){target=\\_blank}. This is used by chains like [Acala](https://acala.network/){target=\\_blank}, [Astar](https://astar.network/){target=\\_blank}, [Moonbeam](https://moonbeam.network){target=\\_blank} and more.\n- **Wasm**: [ink!](https://use.ink/){target=\\_blank} is a domain-specific language (DSL) for Rust smart contract development that uses the [Contracts pallet](https://github.com/paritytech/polkadot-sdk/blob/master/substrate/frame/contracts/){target=\\_blank} with [`cargo-contract`](https://github.com/use-ink/cargo-contract){target=\\_blank} serving as the compiler to WebAssembly. Wasm contracts can be used by chains like [Astar](https://astar.network/){target=\\_blank}."}
{"page_id": "polkadot-protocol-smart-contract-basics-overview", "index": 3, "depth": 3, "title": "PolkaVM Contracts", "anchor": "polkavm-contracts", "start_char": 6258, "end_char": 6674, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "### PolkaVM Contracts\n\nA component of the Asset Hub parachain, PolkaVM helps enable the deployment of Solidity-based smart contracts directly on Asset Hub. Learn more about how this cutting edge virtual machine facilitates using familiar Ethereum-compatible contracts and tools with Asset Hub by visiting the [Native Smart Contracts](/develop/smart-contracts/overview#native-smart-contracts){target=\\_blank} guide."}
{"page_id": "polkadot-protocol-smart-contract-basics-overview", "index": 4, "depth": 3, "title": "EVM Contracts", "anchor": "evm-contracts", "start_char": 6674, "end_char": 9410, "estimated_token_count": 721, "token_estimator": "heuristic-v1", "text": "### EVM Contracts\n\nThe [Frontier](https://github.com/polkadot-evm/frontier){target=\\_blank} project provides a set of modules that enables a Polkadot SDK-based chain to run an Ethereum emulation layer that allows the execution of EVM smart contracts natively with the same API/RPC interface.\n\n[Ethereum addresses (ECDSA)](https://ethereum.org/en/glossary/#address){target=\\_blank} can also be mapped directly to and from the Polkadot SDK's SS58 scheme from existing accounts. Moreover, you can modify Polkadot SDK to use the ECDSA signature scheme directly to avoid any mapping.\n\nAt a high level, [Frontier](https://github.com/polkadot-evm/frontier){target=\\_blank} is composed of three main components:\n\n- **[Ethereum Client](https://github.com/polkadot-evm/frontier/tree/master/client){target=\\_blank}**: An Ethereum JSON RPC compliant client that allows any request coming from an Ethereum tool, such as [Remix](https://remix.ethereum.org/){target=\\_blank}, [Hardhat](https://hardhat.org/){target=\\_blank} or [Foundry](https://getfoundry.sh/){target=\\_blank}, to be admitted by the network.\n- **[Pallet Ethereum](https://docs.rs/pallet-ethereum/latest/pallet_ethereum/){target=\\_blank}**: A block emulation and Ethereum transaction validation layer that works jointly with the Ethereum client to ensure compatibility with Ethereum tools.\n- **[Pallet EVM](https://docs.rs/pallet-evm/latest/pallet_evm/){target=\\_blank}**: Access layer to the [Rust-based EVM](https://github.com/rust-ethereum/evm){target=\\_blank}, enabling the execution of EVM smart contract logic natively.\n\nThe following diagram illustrates a high-level overview of the path an EVM transaction follows when using this configuration:\n\n``` mermaid\nflowchart TD\n    A[Users and Devs] -->|Send Tx| B[Frontier RPC Ext]\n    subgraph C[Pallet Ethereum]\n        D[Validate Tx]\n        E[Send<br/>Valid Tx]    \n    end\n    B -->|Interact with| C\n    D --> E\n    subgraph F[Pallet EVM]\n        G[Rust EVM]\n    end\n    I[(Current EVM<br/>Emulated State)]\n\n    H[Smart Contract<br/>Solidity, Vyper...] <-->|Compiled to EVM<br/>Bytecode| I\n\n    C --> F\n    I --> F\n    F --> J[(New Ethereum<br/>Emulated State)]\n    F --> K[Execution Logs]\n\n    style C fill:#ffffff,stroke:#000000,stroke-width:1px\n    style F fill:#ffffff,stroke:#000000,stroke-width:1px\n```\n\nAlthough it seems complex, users and developers are abstracted of that complexity, and tools can easily interact with the parachain as they would with any other Ethereum-compatible environment.\n\nThe Rust EVM is capable of executing regular [EVM bytecode](https://www.ethervm.io/){target=\\_blank}. Consequently, any language that compiles to EVM bytecode can be used to create programs that the parachain can execute."}
{"page_id": "polkadot-protocol-smart-contract-basics-overview", "index": 5, "depth": 3, "title": "Wasm Contracts", "anchor": "wasm-contracts", "start_char": 9410, "end_char": 10921, "estimated_token_count": 384, "token_estimator": "heuristic-v1", "text": "### Wasm Contracts\n\nThe [`pallet_contracts`](https://docs.rs/pallet-contracts/latest/pallet_contracts/index.html#contracts-pallet){target=\\_blank} provides the execution environment for Wasm-based smart contracts. Consequently, any smart contract language that compiles to Wasm can be executed in a parachain that enables this module.\n\nAt the time of writing there are two main languages that can be used for Wasm programs:\n\n- **[ink!](https://use.ink/){target=\\_blank}**: A Rust-based language that compiles to Wasm. It allows developers to inherit all its safety guarantees and use normal Rust tooling, being the dedicated domain-specific language.\n- **Solidity**: Can be compiled to Wasm via the [Solang](https://github.com/hyperledger-solang/solang/){target=\\_blank} compiler. Consequently, developers can write Solidity 0.8 smart contracts that can be executed as Wasm programs in parachains.\n\nThe following diagram illustrates a high-level overview of the path a transaction follows when using [`pallet_contracts`](https://docs.rs/pallet-contracts/latest/pallet_contracts/index.html#contracts-pallet){target=\\_blank}:\n\n``` mermaid\nflowchart TD\n    \n    subgraph A[Wasm Bytecode API]\n        C[Pallet Contracts]\n    end\n\n    B[Users and Devs] -- Interact with ---> A\n    \n    D[(Current State)]\n\n    E[Smart Contract<br/>ink!, Solidity...] <-->|Compiled to Wasm<br/>Bytecode| D\n\n    D --> A\n    A --> F[(New State)]\n    A --> G[Execution Logs]\n\n    style A fill:#ffffff,stroke:#000000,stroke-width:1px\n```"}
{"page_id": "polkadot-protocol-smart-contract-basics-polkavm-design", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 190, "end_char": 482, "estimated_token_count": 40, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Asset Hub smart contracts solution includes multiple components to ensure Ethereum compatibility and high performance. Its architecture allows for integration with current Ethereum tools, while its innovative virtual machine design enhances performance characteristics."}
{"page_id": "polkadot-protocol-smart-contract-basics-polkavm-design", "index": 1, "depth": 2, "title": "PolkaVM", "anchor": "polkavm", "start_char": 482, "end_char": 1368, "estimated_token_count": 172, "token_estimator": "heuristic-v1", "text": "## PolkaVM\n\n[**PolkaVM**](https://github.com/paritytech/polkavm){target=\\_blank} is a custom virtual machine optimized for performance with [RISC-V-based](https://en.wikipedia.org/wiki/RISC-V){target=\\_blank} architecture, supporting Solidity and additional high-performance languages. It serves as the core execution environment, integrated directly within the runtime. It features:\n\n- An efficient interpreter for immediate code execution.\n- A planned JIT compiler for optimized performance.\n- Dual-mode execution capability, allowing selection of the most appropriate backend for specific workloads.\n- Optimized performance for short-running contract calls through the interpreter.\n\nThe interpreter remains particularly beneficial for contracts with minimal code execution, as it eliminates JIT compilation overhead and enables immediate code execution through lazy interpretation."}
{"page_id": "polkadot-protocol-smart-contract-basics-polkavm-design", "index": 2, "depth": 2, "title": "Architecture", "anchor": "architecture", "start_char": 1368, "end_char": 1533, "estimated_token_count": 26, "token_estimator": "heuristic-v1", "text": "## Architecture\n\nThe smart contract solution consists of the following key components that work together to enable Ethereum compatibility on Polkadot-based chains."}
{"page_id": "polkadot-protocol-smart-contract-basics-polkavm-design", "index": 3, "depth": 3, "title": "Pallet Revive", "anchor": "pallet-revive", "start_char": 1533, "end_char": 2803, "estimated_token_count": 230, "token_estimator": "heuristic-v1", "text": "### Pallet Revive\n\n[**`pallet_revive`**](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/index.html){target=\\_blank} is a runtime module that executes smart contracts by adding extrinsics, runtime APIs, and logic to convert Ethereum-style transactions into formats compatible with Polkadot SDK-based blockchains. It processes Ethereum-style transactions through the following workflow:\n\n```mermaid\nsequenceDiagram\n    participant User as User/dApp\n    participant Proxy as Ethereum JSON RPC Proxy\n    participant Chain as Blockchain Node\n    participant Pallet as pallet_revive\n    \n    User->>Proxy: Submit Ethereum Transaction\n    Proxy->>Chain: Repackage as Polkadot Compatible Transaction\n    Chain->>Pallet: Process Transaction\n    Pallet->>Pallet: Decode Ethereum Transaction\n    Pallet->>Pallet: Execute Contract via PolkaVM\n    Pallet->>Chain: Return Results\n    Chain->>Proxy: Forward Results\n    Proxy->>User: Return Ethereum-compatible Response\n```\n\nThis proxy-based approach eliminates the need for node binary modifications, maintaining compatibility across different client implementations. Preserving the original Ethereum transaction payload simplifies adapting existing tools, which can continue processing familiar transaction formats."}
{"page_id": "polkadot-protocol-smart-contract-basics-polkavm-design", "index": 4, "depth": 3, "title": "PolkaVM Design Fundamentals", "anchor": "polkavm-design-fundamentals", "start_char": 2803, "end_char": 4304, "estimated_token_count": 258, "token_estimator": "heuristic-v1", "text": "### PolkaVM Design Fundamentals\n\nPolkaVM introduces two fundamental architectural differences compared to the Ethereum Virtual Machine (EVM):\n\n```mermaid\nflowchart TB\n    subgraph \"EVM Architecture\"\n        EVMStack[Stack-Based]\n        EVM256[256-bit Word Size]\n    end\n    \n    subgraph \"PolkaVM Architecture\"\n        PVMReg[Register-Based]\n        PVM64[64-bit Word Size]\n    end\n```\n\n- **Register-based design**: PolkaVM utilizes a RISC-V register-based approach. This design:\n\n    - Employs a finite set of registers for argument passing instead of an infinite stack.\n    - Facilitates efficient translation to underlying hardware architectures.\n    - Optimizes register allocation through careful register count selection.\n    - Enables simple 1:1 mapping to x86-64 instruction sets.\n    - Reduces compilation complexity through strategic register limitation.\n    - Improves overall execution performance through hardware-aligned design.\n\n- **64-bit word size**: PolkaVM operates with a 64-bit word size. This design:\n\n    - Enables direct hardware-supported arithmetic operations.\n    - Maintains compatibility with Solidity's 256-bit operations through YUL translation.\n    - Allows integration of performance-critical components written in lower-level languages.\n    - Optimizes computation-intensive operations through native word size alignment.\n    - Reduces overhead for operations not requiring extended precision.\n    - Facilitates efficient integration with modern CPU architectures."}
{"page_id": "polkadot-protocol-smart-contract-basics-polkavm-design", "index": 5, "depth": 2, "title": "Compilation Process", "anchor": "compilation-process", "start_char": 4304, "end_char": 5336, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "## Compilation Process\n\nWhen compiling a Solidity smart contract, the code passes through the following stages:\n\n```mermaid\nflowchart LR\n    Dev[Developer] --> |Solidity<br>Source<br>Code| Solc\n    \n    subgraph \"Compilation Process\"\n        direction LR\n        Solc[solc] --> |YUL<br>IR| Revive\n        Revive[Revive Compiler] --> |LLVM<br>IR| LLVM\n        LLVM[LLVM<br>Optimizer] --> |RISC-V ELF<br>Shared Object| PVMLinker\n    end\n    \n    PVMLinker[PVM Linker] --> PVM[PVM Blob<br>with Metadata]\n```\n\nThe compilation process integrates several specialized components:\n\n1. **Solc**: The standard Ethereum Solidity compiler that translates Solidity source code to [YUL IR](https://docs.soliditylang.org/en/latest/yul.html){target=\\_blank}.\n2. **Revive Compiler**: Takes YUL IR and transforms it to [LLVM IR](https://llvm.org/){target=\\_blank}.\n3. **LLVM**: A compiler infrastructure that optimizes the code and generates RISC-V ELF objects.\n4. **PVM linker**: Links the RISC-V ELF object into a final PolkaVM blob with metadata."}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 25, "end_char": 1000, "estimated_token_count": 220, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis tutorial demonstrates how to build a simple command-line interface (CLI) application that monitors a user's account on the relay chain for the [`system.remarkWithEvent`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.remark_with_event){target=\\_blank} extrinsic, using the [Polkadot API](/develop/toolkit/api-libraries/papi){target=\\_blank}.\n\nThe `system.remarkWithEvent` extrinsic enables the submission of arbitrary data on-chain. In this tutorial, the data consists of a hash derived from the combination of an account address and the word \"email\" (`address+email`). This hash is monitored on-chain, and the application listens for remarks addressed to the specified account. The `system.remarkWithEvent` extrinsic emits an event that can be observed using the Polkadot API (PAPI).\n\nWhen the application detects a remark addressed to the specified account, it plays the \"You've Got Mail!\" sound byte."}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1000, "end_char": 1349, "estimated_token_count": 96, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, ensure the following tools and dependencies are installed:\n\n- Node.js (version 18 or higher).\n- A package manager (npm or yarn).\n- [Polkadot.js browser extension (wallet)](https://polkadot.js.org/extension/){target=\\_blank}.\n- An account with [Westend tokens](https://faucet.polkadot.io/westend){target=\\_blank}."}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 2, "depth": 2, "title": "Clone the Repository", "anchor": "clone-the-repository", "start_char": 1349, "end_char": 2001, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "## Clone the Repository\n\nTo follow this tutorial, you can either run the example directly or use a boilerplate/template. This tutorial uses a template that includes all necessary dependencies for working with the Polkadot API and TypeScript. Clone the `polkadot-api-example-cli` project and checkout to the [`empty-cli`](https://github.com/CrackTheCode016/polkadot-api-example-cli/tree/empty-cli){target=\\_blank} as follows:\n\n```bash\ngit clone https://github.com/polkadot-developers/dapp-examples/tree/v0.0.2\ncd polkadot-api-example-cli\ngit checkout empty-cli\n```\n\nAfter cloning, install the required dependencies by running:\n\n```bash\nnpm install\n```"}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 3, "depth": 2, "title": "Explore the Template (Light Clients)", "anchor": "explore-the-template-light-clients", "start_char": 2001, "end_char": 2853, "estimated_token_count": 200, "token_estimator": "heuristic-v1", "text": "## Explore the Template (Light Clients)\n\nAfter opening the repository, you will find the following code (excluding imports):\n\n```typescript title=\"index.ts\"\n-async function withLightClient(): Promise<PolkadotClient> {\n  // Start the light client\n  const smoldot = start();\n  // The Westend Relay Chain\n  const relayChain = await smoldot.addChain({ chainSpec: westEndChainSpec });\n  return createClient(getSmProvider(relayChain));\n}\n\nasync function main() {\n  // CLI code goes here...\n}\n\nmain();\n\n```\n\nThe `withLightClient` function is particularly important. It uses the built-in [light client](/develop/toolkit/parachains/light-clients/){target=\\_blank} functionality, powered by [`smoldot`](https://github.com/smol-dot/smoldot){target=\\_blank}, to create a light client that synchronizes and interacts with Polkadot directly within the application."}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 4, "depth": 2, "title": "Create the CLI", "anchor": "create-the-cli", "start_char": 2853, "end_char": 3453, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Create the CLI\n\nThe CLI functionality is implemented within the `main` function. The CLI includes an option (`-a` / `--account`) to specify the account to monitor for remarks:\n\n```typescript title=\"index.ts\"\n-const program = new Command();\nconsole.log(chalk.white.dim(figlet.textSync('Web3 Mail Watcher')));\nprogram\n  .version('0.0.1')\n  .description(\n    'Web3 Mail Watcher - A simple CLI tool to watch for remarks on the Polkadot network'\n  )\n  .option('-a, --account <account>', 'Account to watch')\n  .parse(process.argv);\n\n// CLI arguments from commander\nconst options = program.opts();\n\n```"}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 5, "depth": 2, "title": "Watch for Remarks", "anchor": "watch-for-remarks", "start_char": 3453, "end_char": 4778, "estimated_token_count": 339, "token_estimator": "heuristic-v1", "text": "## Watch for Remarks\n\nThe application monitors the Westend network for remarks sent to the specified account. The following code, placed within the `main` function, implements this functionality:\n\n```typescript title=\"index.ts\"\n-if (options.account) {\n  console.log(\n    chalk.black.bgRed('Watching account:'),\n    chalk.bold.whiteBright(options.account)\n  );\n  // Create a light client to connect to the Polkadot (Westend) network\n  const lightClient = await withLightClient();\n  // Get the typed API to interact with the network\n  const dotApi = lightClient.getTypedApi(wnd);\n  // Subscribe to the System.Remarked event and watch for remarks from the account\n  dotApi.event.System.Remarked.watch().subscribe((event) => {\n    const { sender, hash } = event.payload;\n    const calculatedHash = bytesToHex(\n      blake2b(`${options.account}+email`, { dkLen: 32 })\n    );\n    if (`0x${calculatedHash}` === hash.asHex()) {\n      sound.play('youve-got-mail-sound.mp3');\n      console.log(chalk.black.bgRed('You got mail!'));\n      console.log(\n        chalk.black.bgCyan('From:'),\n        chalk.bold.whiteBright(sender.toString())\n      );\n      console.log(\n        chalk.black.bgBlue('Hash:'),\n        chalk.bold.whiteBright(hash.asHex())\n      );\n    }\n  });\n} else {\n  console.error('Account is required');\n  return;\n}\n\n```"}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 6, "depth": 2, "title": "Compile and Run", "anchor": "compile-and-run", "start_char": 4778, "end_char": 6113, "estimated_token_count": 479, "token_estimator": "heuristic-v1", "text": "## Compile and Run\n\nCompile and execute the application using the following command:\n\n```bash\nnpm start -- --account <account-address>\n```\n\nFor example:\n\n```bash\nnpm start -- --account 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\n```\n\nThe output should look like this:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npm start -- --account 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY</span>\n  <span data-ty> __ __ _ _____ __ __ _ _ __ __ _ _</span>\n  <span data-ty> \\ \\ / /__| |__|___ / | \\/ | __ _(_) | \\ \\ / /_ _| |_ ___| |__ ___ _ __</span>\n  <span data-ty> \\ \\ /\\ / / _ \\ '_ \\ |_ \\ | |\\/| |/ _` | | | \\ \\ /\\ / / _` | __/ __| '_ \\ / _ \\ '__|</span>\n  <span data-ty> \\ V V / __/ |_) |__) | | | | | (_| | | | \\ V V / (_| | || (__| | | | __/ |</span>\n  <span data-ty> \\_/\\_/ \\___|_.__/____/ |_| |_|\\__,_|_|_| \\_/\\_/ \\__,_|\\__\\___|_| |_|\\___|_|</span>\n  <span data-ty> </span>\n  <span data-ty>📬 Watching account: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY</span>\n  <span data-ty>⚙️ [smoldot] Smoldot v2.0.34</span>\n  <span data-ty>✅ [smoldot] Chain initialization complete for westend2.</span>\n  <span data-ty>🔗 Name: \"Westend\"</span>\n  <span data-ty>🧬 Genesis hash: 0xe143…423e</span>\n  <span data-ty>⛓️ Chain specification starting at: 0x10cf…b908 (#23920337)</span>\n</div>"}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 7, "depth": 2, "title": "Test the CLI", "anchor": "test-the-cli", "start_char": 6113, "end_char": 7728, "estimated_token_count": 522, "token_estimator": "heuristic-v1", "text": "## Test the CLI\n\nTo test the application, navigate to the [**Extrinsics** page of the PAPI Dev Console](https://dev.papi.how/extrinsics#networkId=westend&endpoint=light-client){target=\\_blank}. Select the **System** pallet and the **remark_with_event** call. Ensure the input field follows the convention `address+email`. For example, if monitoring `5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY`, the input should be:\n\n![](/images/tutorials/dapps/remark-tutorial/papi-console.webp)\n\nSubmit the extrinsic and sign it using the Polkadot.js browser wallet. The CLI will display the following output and play the \"You've Got Mail!\" sound:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npm start -- --account 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY</span>\n  <span data-ty> __ __ _ _____ __ __ _ _ __ __ _ _</span>\n  <span data-ty> \\ \\ / /__| |__|___ / | \\/ | __ _(_) | \\ \\ / /_ _| |_ ___| |__ ___ _ __</span>\n  <span data-ty> \\ \\ /\\ / / _ \\ '_ \\ |_ \\ | |\\/| |/ _` | | | \\ \\ /\\ / / _` | __/ __| '_ \\ / _ \\ '__|</span>\n  <span data-ty> \\ V V / __/ |_) |__) | | | | | (_| | | | \\ V V / (_| | || (__| | | | __/ |</span>\n  <span data-ty> \\_/\\_/ \\___|_.__/____/ |_| |_|\\__,_|_|_| \\_/\\_/ \\__,_|\\__\\___|_| |_|\\___|_|</span>\n  <span data-ty> </span>\n  <span data-ty>📬 Watching account: 5Cm8yiG45rqrpyV2zPLrbtr8efksrRuCXcqcB4xj8AejfcTB</span>\n  <span data-ty>📥 You've got mail!</span>\n  <span data-ty>👤 From: 5Cm8yiG45rqrpyV2zPLrbtr8efksrRuCXcqcB4xj8AejfcTB</span>\n  <span data-ty>🔖 Hash: 0xb6999c9082f5b1dede08b387404c9eb4eb2deee4781415dfa7edf08b87472050</span>\n</div>"}
{"page_id": "tutorials-dapps-remark-tutorial", "index": 8, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 7728, "end_char": 8062, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\nThis application demonstrates how the Polkadot API can be used to build decentralized applications. While this is not a production-grade application, it introduces several key features for developing with the Polkadot API.\n\nTo explore more, refer to the [official PAPI documentation](https://papi.how){target=\\_blank}."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 44, "end_char": 735, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn this tutorial, you'll learn how to replay and dry-run XCMs using [Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks/get-started/){target=\\_blank}, a powerful tool for forking live Polkadot SDK-based chains in your local environment. These techniques are essential for:\n\n- Debugging cross-chain message failures.\n- Tracing execution across relay chains and parachains.\n- Analyzing weight usage, error types, and message flow.\n- Safely simulating XCMs without committing state changes.\n\nBy the end of this guide, you'll be able to set up a local fork, capture and replay real XCMs, and use dry-run features to diagnose and resolve complex cross-chain issues."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 735, "end_char": 1478, "estimated_token_count": 199, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, make sure you have:\n\n- [Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks/get-started/){target=\\_blank} installed (`npm i -g @acala-network/chopsticks`).\n- Access to the endpoint or genesis file of the parachain you want to fork.\n- The block number or hash where the XCM was sent.\n- (Optional) A Chopsticks config file for repeated setups.\n\nIf you haven't forked a chain before, see the [Fork a Chain with Chopsticks guide](/tutorials/polkadot-sdk/testing/fork-live-chains/){target=\\_blank} or [Fork a Network Locally using Chopsticks](https://wiki.polkadot.com/learn/learn-guides-test-opengov-proposals/#fork-a-network-locally-using-chopsticks){target=\\_blank} for step-by-step instructions."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 2, "depth": 2, "title": "Set Up Your Project", "anchor": "set-up-your-project", "start_char": 1478, "end_char": 2310, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Set Up Your Project\n\nLet's start by creating a dedicated workspace for your XCM replay and dry-run experiments.\n\n1. Create a new directory and navigate into it:\n\n    ```bash\n    mkdir -p replay-xcm-tests\n    cd replay-xcm-tests\n    ```\n\n2. Initialize a new Node project:\n\n    ```bash\n    npm init -y\n    ```\n\n3. Install Chopsticks globally (recommended to avoid conflicts with local installs):\n\n    ```bash\n    npm install -g @acala-network/chopsticks@latest\n    ```\n\n4. Install TypeScript and related tooling for local development:\n\n    ```bash\n    npm install --save-dev typescript @types/node tsx\n    ```\n\n5. Install the required Polkadot packages:\n\n    ```bash\n    npm install polkadot-api @polkadot-labs/hdkd @polkadot-labs/hdkd-helpers\n    ```\n\n6. Initialize the TypeScript config:\n\n    ```bash\n    npx tsc --init\n    ```"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 3, "depth": 2, "title": "Capture the XCM to Replay", "anchor": "capture-the-xcm-to-replay", "start_char": 2310, "end_char": 2886, "estimated_token_count": 151, "token_estimator": "heuristic-v1", "text": "## Capture the XCM to Replay\n\nTo replay a specific XCM, identify:\n\n- The source and destination chains involved.\n- The block number or height where the XCM was sent.\n- Optionally, the call payload (if you plan to simulate it manually via development commands).\n\nYou can use [Polkadot.js Apps](/tutorials/polkadot-sdk/testing/fork-live-chains/#use-polkadotjs-apps){target=\\_blank}, [papi console](https://dev.papi.how/){target=\\_blank}, or indexers such as [Subscan](https://polkadot.subscan.io/xcm_dashboard){target=\\_blank} to locate and inspect the original XCM execution."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 4, "depth": 2, "title": "Fork the Relevant Chains", "anchor": "fork-the-relevant-chains", "start_char": 2886, "end_char": 3074, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## Fork the Relevant Chains\n\nUse Chopsticks to [fork the required chains](/tutorials/polkadot-sdk/testing/fork-live-chains/#xcm-testing){target=\\_blank} at the appropriate block heights."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 5, "depth": 3, "title": "Set the Block Numbers", "anchor": "set-the-block-numbers", "start_char": 3074, "end_char": 3359, "estimated_token_count": 61, "token_estimator": "heuristic-v1", "text": "### Set the Block Numbers\n\nCreate/edit a `.env` file with the block heights for each chain. These should be just before the XCM is sent to allow a full replay:\n\n```text title=\".env\"\nPOLKADOT_BLOCK_NUMBER=26481107\nPOLKADOT_ASSET_HUB_BLOCK_NUMBER=9079591\nACALA_BLOCK_NUMBER=8826385\n```"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 6, "depth": 3, "title": "Enable Logging and Wasm Override", "anchor": "enable-logging-and-wasm-override", "start_char": 3359, "end_char": 7151, "estimated_token_count": 1012, "token_estimator": "heuristic-v1", "text": "### Enable Logging and Wasm Override\n\nFull execution logs only work if the runtime was compiled with logging enabled. Most live chains are built using the `production` profile, which disables logs. To enable logging, you'll need to override the Wasm with a locally built `release` or `debug` version. The `release` profile is faster to load in Chopsticks. \n\n1. Clone the `polkadot-fellows/runtimes` repository:\n\n    ```bash\n    git clone git@github.com:polkadot-fellows/runtimes.git\n    ```\n\n2. Build the Polkadot Asset Hub runtime:\n\n    ```bash\n    cd runtimes\n    # Build with the `debug` profile (default): \n    # cargo build -p asset-hub-polkadot-runtime\n\n    # Build with the `release` profile (faster to load in Chopsticks)\n    cargo build --release -p asset-hub-polkadot-runtime\n    ```\n\n3. Copy the compiled Wasm to your working directory:\n\n    ```bash\n    # Assuming you're still in the `runtimes` directory\n    mkdir -p ../wasms  # or your <replay-xcm-tests>/wasms path\n\n    # Copy the compiled Wasm to your working directory:\n\n    # If built with the `debug` profile:\n    # cp target/debug/wbuild/asset-hub-polkadot-runtime/asset_hub_polkadot_runtime.wasm ../wasms\n\n    # If built with the `release` profile:\n    cp target/release/wbuild/asset-hub-polkadot-runtime/asset_hub_polkadot_runtime.compact.compressed.wasm ../wasms\n    ```\n\n4. Download and modify a config file:\n\n    ```bash\n    # Still in the `runtimes` directory\n    cd .. # Return to your replay-xcm-tests root\n    mkdir -p configs\n    wget https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot-asset-hub.yml -O configs/polkadot-asset-hub-override.yaml\n    ```\n\n5. Edit `configs/polkadot-asset-hub-override.yaml` to include:\n\n    ```yaml title=\"configs/polkadot-asset-hub-override.yaml\"\n    ...\n    runtime-log-level: 5\n    # wasm-override: wasms/asset_hub_polkadot_runtime.wasm                     # Uncomment if using the `debug` build\n    wasm-override: wasms/asset_hub_polkadot_runtime.compact.compressed.wasm    # Use this if you built with `release`\n    ...\n    ```\n\n6. Start the forked chains using your custom config:\n\n    ```bash\n    npx @acala-network/chopsticks xcm \\\n    -r polkadot \\\n    -p configs/polkadot-asset-hub-override.yaml \\\n    -p acala\n    ```\n\n    This command starts the relay chain and parachains locally, with full runtime execution logs enabled. Once the chains are running, you should see output indicating that the following RPC endpoints are available:\n\n    - Polkadot Asset Hub RPC on `http://localhost:8000`\n    - Acala RPC on `http://localhost:8001`\n    - Polkadot RPC on `http://localhost:8002`\n\n    You'll also see runtime logs such as:\n\n    -<div class=\"termynal\" data-termynal>\n  <span data-ty=\"input\">npx @acala-network/chopsticks xcm \\ -r polkadot \\ -p configs/polkadot-asset-hub-override.yaml \\ -p acala</span>\n  <span data-ty>[09:29:14.988] INFO: Polkadot Asset Hub RPC listening on http://[::]:8000 and ws://[::]:8000</span>\n  <span data-ty>[09:29:14.988] INFO: Loading config file https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/acala.yml</span>\n  <span data-ty>[09:29:15.984] INFO: Acala RPC listening on http://[::]:8001 and ws://[::]:8001</span>\n  <span data-ty>[09:29:15.990] INFO (xcm): Connected parachains [1000,2000]</span>\n  <span data-ty>[09:29:15.990] INFO: Loading config file https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot.yml</span>\n  <span data-ty>[09:29:16.927] INFO: Polkadot RPC listening on http://[::]:8002 and ws://[::]:8002</span>\n  <span data-ty>[09:29:16.984] INFO (xcm): Connected relaychain 'Polkadot' with parachain 'Polkadot Asset Hub'</span>\n  <span data-ty>[09:29:17.028] INFO (xcm): Connected relaychain 'Polkadot' with parachain 'Acala'</span>\n</div>"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 7, "depth": 2, "title": "Identify and Extract the XCM", "anchor": "identify-and-extract-the-xcm", "start_char": 7151, "end_char": 8774, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "## Identify and Extract the XCM\n\nTo replay an XCM, you'll first need to identify the exact extrinsic that triggered it. In this example, we'll use block 9079592 on the Polkadot Asset Hub.\n\n1. Find and open the block on Subscan to inspect its extrinsics and events. In this case, the block is [9079592](https://assethub-polkadot.subscan.io/block/9079592){target=\\_blank}.\n\n2. Copy the black hash. Look for the block hash at the top of the page. For block 9079592, the hash is:\n\n    ```bash title=\"Block Hash\"\n    0xeb5a5737d47367dc1c02b978232283cdb096eb7e51d2eb22366a106a011347f6\n    ```\n\n3. Explore and view the block in [Polkadot.Js Apps](https://polkadot.js.org/apps){target=\\_blank} using this direct link: [Block Hash Explorer](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fpolkadot-asset-hub-rpc.polkadot.io#/explorer/query/0xeb5a5737d47367dc1c02b978232283cdb096eb7e51d2eb22366a106a011347f6){target=\\_blank}.\n\n4. Locate and decode the XCM extrinsic. Once you've found the extrinsic (e.g., 9079592-2), extract and decode its call data. For example, the call data is:\n   \n    ```bash title=\"Call Data\"\n    0xad028400fc39fcf04a8071b7409823b7c82427ce67910c6ed80aa0e5093aff234624c820016a30461702adc48213e5c9ee4d15c5a481c578cb5cbc935f0bd11fe8aee489082a745ffbbe94282f91b67daa6cb44920d77c30849c1d25f5f6c3e59015a3e383440055040000011f0803010100411f0300010100fc39fcf04a8071b7409823b7c82427ce67910c6ed80aa0e5093aff234624c8200304000002043205011f0092e81d790000000000\n    ```\n\n5. From the decoded view, copy the **hex-encoded call** (e.g. `0x1f08...0000`). You'll pass this into `api.txFromCallData(...)` to replay the XCM locally."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 8, "depth": 2, "title": "Replay the XCM", "anchor": "replay-the-xcm", "start_char": 8774, "end_char": 9028, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Replay the XCM\n\nOnce your project is set up, you're ready to replay the XCM locally.\n\nThis is useful for:\n\n- Diagnosing execution failures or weight limits.\n- Inspecting all emitted events.\n- Verifying behaviour before submitting a real transaction."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 9, "depth": 3, "title": "Add the Asset Hub Descriptor", "anchor": "add-the-asset-hub-descriptor", "start_char": 9028, "end_char": 9461, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "### Add the Asset Hub Descriptor\n\nThis will let you use type-safe APIs with PAPI:\n\n```bash\nnpx papi add assetHub -w ws://localhost:8000\n```\n\nThe script assumes the Polkadot Asset Hub is served on `ws://localhost:8000`. If you're using a different port or config, update the WebSocket endpoint in the script or descriptor. You can confirm the port by checking your terminal logs or by seeing [Launch Chopsticks](#launch-chopsticks)."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 10, "depth": 3, "title": "Create a Replay Script", "anchor": "create-a-replay-script", "start_char": 9461, "end_char": 12340, "estimated_token_count": 668, "token_estimator": "heuristic-v1", "text": "### Create a Replay Script\n\nCreate a file named `replay-xcm.ts` and copy the following code into it:\n\n```ts\n-import { Binary, createClient, Transaction } from 'polkadot-api';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport { getPolkadotSigner } from 'polkadot-api/signer';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { assetHub } from '@polkadot-api/descriptors';\nimport { sr25519CreateDerive } from '@polkadot-labs/hdkd';\nimport {\n  DEV_PHRASE,\n  entropyToMiniSecret,\n  mnemonicToEntropy,\n} from '@polkadot-labs/hdkd-helpers';\n\nconst toHuman = (_key: any, value: any) => {\n  if (typeof value === 'bigint') {\n    return Number(value);\n  }\n\n  if (value && typeof value === 'object' && typeof value.asHex === 'function') {\n    return value.asHex();\n  }\n\n  return value;\n};\n\nfunction getSigner() {\n  const entropy = mnemonicToEntropy(DEV_PHRASE);\n  const miniSecret = entropyToMiniSecret(entropy);\n  const derive = sr25519CreateDerive(miniSecret);\n  const alice = derive('//Alice');\n\n  return getPolkadotSigner(alice.publicKey, 'Sr25519', alice.sign);\n}\n\nasync function main() {\n  const provider = withPolkadotSdkCompat(getWsProvider('ws://localhost:8000'));\n  const client = createClient(provider);\n  const api = client.getTypedApi(assetHub);\n  const aliceSigner = getSigner();\n\n  const callData = Binary.fromHex(\n    '0x1f0803010100411f0300010100fc39fcf04a8071b7409823b7c82427ce67910c6ed80aa0e5093aff234624c8200304000002043205011f0092e81d790000000000',\n  );\n  const tx: Transaction<any, string, string, any> =\n    await api.txFromCallData(callData);\n  console.log('👀 Executing XCM:', JSON.stringify(tx.decodedCall, toHuman, 2));\n\n  await new Promise<void>((resolve) => {\n    const subscription = tx.signSubmitAndWatch(aliceSigner).subscribe((ev) => {\n      if (\n        ev.type === 'finalized' ||\n        (ev.type === 'txBestBlocksState' && ev.found)\n      ) {\n        console.log(\n          `📦 Included in block #${ev.block.number}: ${ev.block.hash}`,\n        );\n\n        if (!ev.ok) {\n          const dispatchError = ev.dispatchError;\n          if (dispatchError.type === 'Module') {\n            const modErr: any = dispatchError.value;\n            console.error(\n              `❌ Dispatch error in module: ${modErr.type} → ${modErr.value?.type}`,\n            );\n          } else {\n            console.error(\n              '❌ Dispatch error:',\n              JSON.stringify(dispatchError, toHuman, 2),\n            );\n          }\n        }\n\n        for (const event of ev.events) {\n          console.log(\n            '📣 Event:',\n            event.type,\n            JSON.stringify(event.value, toHuman, 2),\n          );\n        }\n\n        console.log('✅ Process completed, exiting...');\n        subscription.unsubscribe();\n        resolve();\n      }\n    });\n  });\n\n  client.destroy();\n}\n\nmain().catch(console.error);\n\n```"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 11, "depth": 3, "title": "Execute the Replay Script", "anchor": "execute-the-replay-script", "start_char": 12340, "end_char": 12529, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "### Execute the Replay Script\n\nEnsure Chopsticks is running and serving a chain that includes `pallet-xcm`, such as a Polkadot Asset Hub fork. Then run:\n\n```bash\nnpx tsx replay-xcm.ts\n```"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 12, "depth": 3, "title": "Expected Output", "anchor": "expected-output", "start_char": 12529, "end_char": 14437, "estimated_token_count": 675, "token_estimator": "heuristic-v1", "text": "### Expected Output\n\nIf everything is working, you'll see logs like:\n\n-<div class=\"termynal\" data-termynal>\n  <span data-ty=\"input\">npx tsx replay-xcm.ts</span>\n  <pre data-ty>\nexecuting xcm: {\n  \"type\": \"polkadotxcm\",\n  \"value\": {\n    \"type\": \"limited_reserve_transfer_assets\",\n    \"value\": {\n      \"dest\": { \"parents\": 0, \"interior\": { \"X1\": [{ \"Parachain\": 2006 }] } },\n      \"beneficiary\": { \"parents\": 0, \"interior\": { \"X1\": [{ \"AccountId32\": { \"network\": null, \"id\": \"0x...\" } }] } },\n      \"assets\": [{ \"id\": { \"Concrete\": { \"parents\": 0, \"interior\": \"Here\" } }, \"fun\": { \"Fungible\": 120000000000 } }],\n      \"fee_asset_item\": 0,\n      \"weight_limit\": { \"type\": \"Unlimited\" }\n    }\n  }\n}\n  </pre>\n  <span data-ty>📦 Included in block #9079592: 0x227a11c64f6051ba2e090a13abd17e5f7581640a80f6c03fc2d43fac66ab7949</span>\n  <span data-ty>📣 Event: Balances { \"type\": \"Upgraded\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: Balances { \"type\": \"Withdraw\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: Assets { \"type\": \"Transferred\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: PolkadotXcm { \"type\": \"Attempted\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: Balances { \"type\": \"Burned\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: Balances { \"type\": \"Minted\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: PolkadotXcm { \"type\": \"FeesPaid\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: XcmpQueue { \"type\": \"XcmpMessageSent\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: PolkadotXcm { \"type\": \"Sent\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: Balances { \"type\": \"Deposit\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: TransactionPayment { \"type\": \"TransactionFeePaid\", \"value\": { ... } }</span>\n  <span data-ty>📣 Event: System { \"type\": \"ExtrinsicSuccess\", \"value\": { ... } }</span>\n  <span data-ty>✅ Process completed, exiting...</span>\n</div>"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 13, "depth": 2, "title": "Dry Run the XCM", "anchor": "dry-run-the-xcm", "start_char": 14437, "end_char": 14625, "estimated_token_count": 38, "token_estimator": "heuristic-v1", "text": "## Dry Run the XCM\n\nTo simulate the XCM without actually sending it, you can use the `dry_run_call` method. This lets you check whether the XCM would succeed without modifying any state."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 14, "depth": 3, "title": "Create a Dry Run Script", "anchor": "create-a-dry-run-script", "start_char": 14625, "end_char": 16308, "estimated_token_count": 367, "token_estimator": "heuristic-v1", "text": "### Create a Dry Run Script\n\nAssuming you've the `tx` transaction from the previous step, you can create a new script, `dry-run-call.ts`, then paste in the following code:\n\n```ts\n-import { Binary, createClient, Enum } from 'polkadot-api';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { assetHub } from '@polkadot-api/descriptors';\nimport { sr25519CreateDerive } from '@polkadot-labs/hdkd';\nimport {\n  DEV_PHRASE,\n  entropyToMiniSecret,\n  mnemonicToEntropy,\n  ss58Address,\n} from '@polkadot-labs/hdkd-helpers';\n\nconst XCM_VERSION = 5;\n\nasync function main() {\n  const provider = withPolkadotSdkCompat(getWsProvider('ws://localhost:8000'));\n  const client = createClient(provider);\n  const api = client.getTypedApi(assetHub);\n\n  const entropy = mnemonicToEntropy(DEV_PHRASE);\n  const miniSecret = entropyToMiniSecret(entropy);\n  const derive = sr25519CreateDerive(miniSecret);\n  const alice = derive('//Alice');\n  const aliceAddress = ss58Address(alice.publicKey);\n\n  const callData = Binary.fromHex(\n    '0x1f0803010100411f0300010100fc39fcf04a8071b7409823b7c82427ce67910c6ed80aa0e5093aff234624c8200304000002043205011f0092e81d790000000000',\n  );\n  const tx: any = await api.txFromCallData(callData);\n  const origin = Enum('system', Enum('Signed', aliceAddress));\n  const dryRunResult: any = await api.apis.DryRunApi.dry_run_call(\n    origin,\n    tx.decodedCall,\n    XCM_VERSION,\n  );\n  console.dir(dryRunResult.value, { depth: null });\n\n  client.destroy();\n}\n\nmain().catch(console.error);\n\n```\n\nEnsure your local Chopsticks fork is running and the ports match those used in the script."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 15, "depth": 3, "title": "Execute the Dry Run Script", "anchor": "execute-the-dry-run-script", "start_char": 16308, "end_char": 17885, "estimated_token_count": 498, "token_estimator": "heuristic-v1", "text": "### Execute the Dry Run Script\n\n```bash\nnpx tsx dry-run-call.ts\n```\n\nIf successful, the dry run confirms that the XCM would execute correctly:\n\n-<div class=\"termynal\" data-termynal>\n  <span data-ty=\"input\">npx tsx dry-run-call.ts</span>\n  <pre data-ty>\nexecution_result: {\n  \"success\": true,\n  \"value\": {\n    \"post_info\": { \"actual_weight\": 123456, \"pays_fee\": \"Yes\" },\n    \"result\": \"Ok\"\n  }\n}\nemitted_events: [ { \"section\": \"Balances\", \"method\": \"Transfer\", \"data\": { \"from\": \"0x...\", \"to\": \"0x...\", \"amount\": 1000000000 } } ]\nlocal_xcm: { \"type\": \"SomeType\", \"value\": { ... } }\nforwarded_xcms: []\n  </pre>\n  <span data-ty>✅ Dry run succeeded</span>\n  <span data-ty>✅ Process completed, exiting...</span>\n</div>\n\n\nIf it fails, you'll receive detailed error information:\n\n-<div class=\"termynal\" data-termynal>\n  <span data-ty=\"input\">npx tsx dry-run-call.ts</span>\n  <pre data-ty>\nexecution_result: {\n  \"success\": false,\n  \"value\": {\n    \"post_info\": { \"actual_weight\": 123456, \"pays_fee\": \"Yes\" },\n    \"error\": {\n      \"type\": \"Module\",\n      \"value\": {\n        \"type\": \"PolkadotXcm\",\n        \"value\": { \"type\": \"LocalExecutionIncomplete\", \"value\": null }\n      }\n    }\n  }\n}\n  </pre>\n  <span data-ty>❌ Dry run failed: LocalExecutionIncomplete</span>\n  <span data-ty>✅ Process completed, exiting...</span>\n</div>\n\n\nFor more information, see:\n\n- [Dry Run Call](/develop/interoperability/xcm-runtime-apis/#dry-run-call){target=\\_blank} to simulate a full extrinsic\n- [Dry Run XCM](/develop/interoperability/xcm-runtime-apis/#dry-run-xcm){target=\\_blank} to simulate a raw XCM"}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 16, "depth": 2, "title": "Review and Debug", "anchor": "review-and-debug", "start_char": 17885, "end_char": 18230, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "## Review and Debug\n\nReplaying XCMs with full logging provides fine-grained control and visibility into cross-chain message behaviour. Chopsticks makes this possible in a safe, local environment – empowering developers to:\n\n- Debug complex message flows.\n- Identify root causes of XCM failures.\n- Improve observability for future integrations."}
{"page_id": "tutorials-interoperability-replay-and-dry-run-xcms", "index": 17, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 18230, "end_char": 18931, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Chopsticks Repository__\n\n    ---\n\n    View the official Chopsticks GitHub repository.\n\n    [:octicons-arrow-right-24: Get Started](https://github.com/AcalaNetwork/chopsticks/)\n\n-   <span class=\"badge guide\">Guide</span> __Polkadot XCM Docs__\n\n    ---\n\n    Learn how to use XCM effectively.\n\n    [:octicons-arrow-right-24: Get Started](/develop/interoperability/intro-to-xcm/)\n\n-   <span class=\"badge tutorial\">Tutorial</span> __XCM Runtime APIs__\n\n    ---\n\n    Learn how to use XCM Runtime APIs.\n\n    [:octicons-arrow-right-24: Get Started](/develop/interoperability/xcm-runtime-apis/)\n\n</div>"}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 44, "end_char": 1023, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nFor establishing communication channels between parachains on the Polkadot network using the Horizontal Relay-routed Message Passing (HRMP) protocol, the following steps are required:\n\n1. **Channel request**: The parachain that wants to open an HRMP channel must make a request to the parachain it wishes to have an open channel with.\n2. **Channel acceptance**: The other parachain must then accept this request to complete the channel establishment.\n\nThis process results in a unidirectional HRMP channel, where messages can flow in only one direction between the two parachains.\n\nAn additional HRMP channel must be established in the opposite direction to enable bidirectional communication. This requires repeating the request and acceptance process but with the parachains reversing their roles.\n\nOnce both unidirectional channels are established, the parachains can send messages back and forth freely through the bidirectional HRMP communication channel."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1023, "end_char": 1267, "estimated_token_count": 40, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore proceeding, ensure you meet the following requirements:\n\n- Blockchain network with a relay chain and at least two connected parachains.\n- Wallet with sufficient funds to execute transactions on the participant chains."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 2, "depth": 2, "title": "Procedure to Initiate an HRMP Channel", "anchor": "procedure-to-initiate-an-hrmp-channel", "start_char": 1267, "end_char": 1444, "estimated_token_count": 32, "token_estimator": "heuristic-v1", "text": "## Procedure to Initiate an HRMP Channel\n\nThis example will demonstrate how to open a channel between parachain 2500 and parachain 2600, using Rococo Local as the relay chain."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 3, "depth": 3, "title": "Fund Sender Sovereign Account", "anchor": "fund-sender-sovereign-account", "start_char": 1444, "end_char": 3063, "estimated_token_count": 358, "token_estimator": "heuristic-v1", "text": "### Fund Sender Sovereign Account\n\n\nThe [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=_blank} for parachain 2500 on the relay chain must be funded so it can take care of any XCM transact fees.\n\nUse [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} UI to connect to the relay chain and transfer funds from your account to the parachain 2500 sovereign account.\n![](/images/tutorials/interoperability/xcm-channels/hrmp-channels-2.webp)\n\n??? note \"Calculating Parachain Sovereign Account\"\n    To generate the sovereign account address for a parachain, you'll need to follow these steps:\n\n    1. Determine if the parachain is an \"up/down\" chain (parent or child) or a \"sibling\" chain:\n\n        - Up/down chains use the prefix `0x70617261` (which decodes to `b\"para\"`).\n        - Sibling chains use the prefix `0x7369626c` (which decodes to `b\"sibl\"`).\n\n    2. Calculate the u32 scale encoded value of the parachain ID:\n\n        - Parachain 2500 would be encoded as `c4090000`.\n\n    3. Combine the prefix and parachain ID encoding to form the full sovereign account address:\n\n        The sovereign account of parachain 2500 in relay chain will be `0x70617261c4090000000000000000000000000000000000000000000000000000`\n        and the SS58 format of this address is `5Ec4AhPSY2GEE4VoHUVheqv5wwq2C1HMKa7c9fVJ1WKivX1Y`.\n    \n    To perform this conversion, you can also use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=_blank}."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 4, "depth": 3, "title": "Create Channel Opening Extrinsic", "anchor": "create-channel-opening-extrinsic", "start_char": 3063, "end_char": 4022, "estimated_token_count": 239, "token_estimator": "heuristic-v1", "text": "### Create Channel Opening Extrinsic\n\n1. In Polkadot.js Apps, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-1.webp)\n\n2. Construct an `hrmpInitOpenChannel` extrinsic call:\n\n    1. Select the **`hrmp`** pallet.\n    2. Choose the **`hrmpInitOpenChannel`** extrinsic.\n    3. Fill in the parameters:\n        - **`recipient`**: Parachain ID of the target chain (in this case, 2600).\n        - **`proposedMaxCapacity`**: Max number of messages that can be pending in the channel at once.\n        - **`proposedMaxMessageSize`**: Max message size that could be put into the channel.\n    4. Copy the encoded call data.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-2.webp)\n\n    The encoded call data for opening a channel with parachain 2600 is `0x3c00280a00000800000000001000`."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 5, "depth": 3, "title": "Craft and Submit the XCM Message from the Sender", "anchor": "craft-and-submit-the-xcm-message-from-the-sender", "start_char": 4022, "end_char": 7453, "estimated_token_count": 737, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM Message from the Sender\n\nTo initiate the HRMP channel opening process, you need to create an XCM message that includes the encoded `hrmpInitOpenChannel` call data from the previous step. This message will be sent from your parachain to the relay chain.\n\nThis example uses the `sudo` pallet to dispatch the extrinsic. Verify the XCM configuration of the parachain you're working with and ensure you're using an origin with the necessary privileges to execute the `polkadotXcm.send` extrinsic.\n\nThe XCM message should contain the following instructions:\n\n- **`WithdrawAsset`**: Withdraws assets from the origin's ownership and places them in the Holding Register.\n- **`BuyExecution`**: Pays for the execution of the current message using the assets in the Holding Register.\n- **`Transact`**: Execute the encoded transaction call.\n- **`RefundSurplus`**: Increases the Refunded Weight Register to the value of the Surplus Weight Register, attempting to reclaim any excess fees paid via BuyExecution.\n- **`DepositAsset`**: Subtracts assets from the Holding Register and deposits equivalent on-chain assets under the specified beneficiary's ownership.\n\n!!!note \n    For more detailed information about XCM's functionality, complexities, and instruction set, refer to the [xcm-format](https://github.com/polkadot-fellows/xcm-format){target=_blank} documentation.\n\nIn essence, this process withdraws funds from the parachain's sovereign account to the XCVM Holding Register, then uses these funds to purchase execution time for the XCM `Transact` instruction, executes `Transact`, refunds any unused execution time and deposits any remaining funds into a specified account.\n\nTo send the XCM message to the relay chain, connect to parachain 2500 in Polkadot.js Apps. Fill in the required parameters as shown in the image below, ensuring that you:\n\n1. Replace the **`call`** field with your encoded `hrmpInitOpenChannel` call data from the previous step.\n2. Use the correct beneficiary information.\n3. Click the **Submit Transaction** button to dispatch the XCM message to the relay chain.\n\n![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-3.webp)\n\n!!! note\n    The exact process and parameters for submitting this XCM message may vary depending on your specific parachain and relay chain configurations. Always refer to the most current documentation for your particular network setup.\n\nAfter submitting the XCM message to initiate the HRMP channel opening, you should verify that the request was successful. Follow these steps to check the status of your channel request:\n\n1. Using Polkadot.js Apps, connect to the relay chain and navigate to the **Developer** dropdown, then select the **Chain state** option.\n\n    ![](/images/tutorials/interoperability/xcm-channels/hrmp-channels-1.webp)\n\n2. Query the HRMP open channel requests:\n\n    1. Select **`hrmp`**.\n    2. Choose the **`hrmpOpenChannelRequests`** call.\n    3. Click the **+** button to execute the query.\n    4. Check the status of all pending channel requests.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-4.webp)\n\nIf your channel request was successful, you should see an entry for your parachain ID in the list of open channel requests. This confirms that your request has been properly registered on the relay chain and is awaiting acceptance by the target parachain."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 6, "depth": 2, "title": "Procedure to Accept an HRMP Channel", "anchor": "procedure-to-accept-an-hrmp-channel", "start_char": 7453, "end_char": 7637, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Procedure to Accept an HRMP Channel\n\nFor the channel to be fully established, the target parachain must accept the channel request by submitting an XCM message to the relay chain."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 7, "depth": 3, "title": "Fund Receiver Sovereign Account", "anchor": "fund-receiver-sovereign-account", "start_char": 7637, "end_char": 7983, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "### Fund Receiver Sovereign Account\n\nBefore proceeding, ensure that the sovereign account of parachain 2600 on the relay chain is funded. This account will be responsible for covering any XCM transact fees.\nTo fund the account, follow the same process described in the previous section, [Fund Sovereign Account](#fund-sender-sovereign-account)."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 8, "depth": 3, "title": "Create Channel Accepting Extrinsic", "anchor": "create-channel-accepting-extrinsic", "start_char": 7983, "end_char": 8749, "estimated_token_count": 197, "token_estimator": "heuristic-v1", "text": "### Create Channel Accepting Extrinsic\n\n1. In Polkadot.js Apps, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-1.webp)\n\n2. Construct an `hrmpAcceptOpenChannel` extrinsic call:\n\n    1. Select the **`hrmp`** pallet.\n    2. Choose the **`hrmpAcceptOpenChannel`** extrinsic.\n    3. Fill in the parameters:\n        - **`sender`**: Parachain ID of the requesting chain (in this case, 2500).\n    4. Copy the encoded call data.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-5.webp)\n    \n    The encoded call data for accepting a channel with parachain 2500 should be `0x3c01c4090000`."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-para", "index": 9, "depth": 3, "title": "Craft and Submit the XCM Message from the Receiver", "anchor": "craft-and-submit-the-xcm-message-from-the-receiver", "start_char": 8749, "end_char": 10985, "estimated_token_count": 504, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM Message from the Receiver\n\nTo accept the HRMP channel opening, you need to create and submit an XCM message that includes the encoded `hrmpAcceptOpenChannel` call data from the previous step. This process is similar to the one described in the previous section, [Craft and Submit the XCM Message](#craft-and-submit-the-xcm-message-from-the-sender), with a few key differences:\n\n- Use the encoded call data for `hrmpAcceptOpenChannel` obtained in step 2 of this section.\n- In the last XCM instruction (DepositAsset), set the beneficiary to parachain 2600's sovereign account to receive any surplus funds.\n\nTo send the XCM message to the relay chain, connect to parachain 2600 in Polkadot.js Apps. Fill in the required parameters as shown in the image below, ensuring that you:\n\n1. Replace the **`call`** field with your encoded `hrmpAcceptOpenChannel` call data from the previous step.\n2. Use the correct beneficiary information.\n3. Click the **Submit Transaction** button to dispatch the XCM message to the relay chain.\n\n![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-6.webp)\n\nAfter submitting the XCM message to accept the HRMP channel opening, verify that the channel has been set up correctly.\n\n1. Using Polkadot.js Apps, connect to the relay chain and navigate to the **Developer** dropdown, then select the **Chain state** option.\n\n    ![](/images/tutorials/interoperability/xcm-channels/hrmp-channels-1.webp)\n\n2. Query the HRMP channels:\n\n    1. Select **`hrmp`**.\n    2. Choose the **`hrmpChannels`** call.\n    3. Click the **+** button to execute the query.\n    4. Check the status of the opened channel.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-7.webp)\n\nIf the channel has been successfully established, you should see the channel details in the query results.\n\nBy following these steps, you will have successfully accepted the HRMP channel request and established a unidirectional channel between the two parachains. \n\n!!! note\n    Remember that for full bidirectional communication, you'll need to repeat this process in the opposite direction, with parachain 2600 initiating a channel request to parachain 2500."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-system", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 48, "end_char": 827, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhile establishing Horizontal Relay-routed Message Passing (HRMP) channels between regular parachains involves a two-step request and acceptance procedure, opening channels with system parachains follows a more straightforward approach.\n\nSystem parachains are specialized chains that provide core functionality to the Polkadot network. Examples include Asset Hub for cross-chain asset transfers and Bridge Hub for connecting to external networks. Given their critical role, establishing communication channels with these system parachains has been optimized for efficiency and ease of use.\n\nAny parachain can establish a bidirectional channel with a system chain through a single operation, requiring just one XCM message from the parachain to the relay chain."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-system", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 827, "end_char": 1146, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo successfully complete this process, you'll need to have the following in place:\n\n- Access to a blockchain network consisting of:\n    - A relay chain\n    - A parachain\n    - An Asset Hub system chain\n- A wallet containing enough funds to cover transaction fees on each of the participating chains."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-system", "index": 2, "depth": 2, "title": "Procedure to Establish an HRMP Channel", "anchor": "procedure-to-establish-an-hrmp-channel", "start_char": 1146, "end_char": 1338, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Procedure to Establish an HRMP Channel\n\nThis guide demonstrates opening an HRMP channel between parachain 2500 and system chain Asset Hub (parachain 1000) on the Rococo Local relay chain."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-system", "index": 3, "depth": 3, "title": "Fund Parachain Sovereign Account", "anchor": "fund-parachain-sovereign-account", "start_char": 1338, "end_char": 2961, "estimated_token_count": 359, "token_estimator": "heuristic-v1", "text": "### Fund Parachain Sovereign Account\n\nThe [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=_blank} for parachain 2500 on the relay chain must be funded so it can take care of any XCM transact fees.\n\nUse [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} UI to connect to the relay chain and transfer funds from your account to the parachain 2500 sovereign account.\n\n![](/images/tutorials/interoperability/xcm-channels/hrmp-channels-2.webp)\n\n??? note \"Calculating Parachain Sovereign Account\"\n    To generate the sovereign account address for a parachain, you'll need to follow these steps:\n\n    1. Determine if the parachain is an \"up/down\" chain (parent or child) or a \"sibling\" chain:\n\n        - Up/down chains use the prefix `0x70617261` (which decodes to `b\"para\"`).\n        - Sibling chains use the prefix `0x7369626c` (which decodes to `b\"sibl\"`).\n\n    2. Calculate the u32 scale encoded value of the parachain ID:\n\n        - Parachain 2500 would be encoded as `c4090000`.\n\n    3. Combine the prefix and parachain ID encoding to form the full sovereign account address:\n\n        The sovereign account of parachain 2500 in relay chain will be `0x70617261c4090000000000000000000000000000000000000000000000000000`\n        and the SS58 format of this address is `5Ec4AhPSY2GEE4VoHUVheqv5wwq2C1HMKa7c9fVJ1WKivX1Y`.\n    \n    To perform this conversion, you can also use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=\\_blank}."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-system", "index": 4, "depth": 3, "title": "Create Establish Channel with System Extrinsic", "anchor": "create-establish-channel-with-system-extrinsic", "start_char": 2961, "end_char": 3780, "estimated_token_count": 201, "token_estimator": "heuristic-v1", "text": "### Create Establish Channel with System Extrinsic\n\n1. In Polkadot.js Apps, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-para/hrmp-para-to-para-1.webp)\n\n2. Construct an `establish_channel_with_system` extrinsic call:\n\n    1. Select the **`hrmp`** pallet.\n    2. Choose the **`establish_channel_with_system`** extrinsic.\n    3. Fill in the parameters:\n        - **`target_system_chain`**: Parachain ID of the target system chain (in this case, 1000).\n    4. Copy the encoded call data.\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-system/hrmp-para-to-system-1.webp)\n\n    The encoded call data for establishing a channel with system parachain 1000 should be `0x3c0ae8030000`."}
{"page_id": "tutorials-interoperability-xcm-channels-para-to-system", "index": 5, "depth": 3, "title": "Craft and Submit the XCM Message", "anchor": "craft-and-submit-the-xcm-message", "start_char": 3780, "end_char": 7061, "estimated_token_count": 686, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM Message\n\nConnect to parachain 2500 using Polkadot.js Apps to send the XCM message to the relay chain. Input the necessary parameters as illustrated in the image below. Make sure to:\n\n1. Insert your previously encoded `establish_channel_with_system` call data into the **`call`** field.\n2. Provide beneficiary details.\n3. Dispatch the XCM message to the relay chain by clicking the **Submit Transaction** button.\n\n![](/images/tutorials/interoperability/xcm-channels/para-to-system/hrmp-para-to-system-2.webp)\n\n!!! note\n    The exact process and parameters for submitting this XCM message may vary depending on your specific parachain and relay chain configurations. Always refer to the most current documentation for your particular network setup.\n\nAfter successfully submitting the XCM message to the relay chain, two [`HrmpSystemChannelOpened`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/hrmp/pallet/enum.Event.html#variant.HrmpSystemChannelOpened){target=\\_blank} events are emitted, indicating that the channels are now present in storage under [`HrmpOpenChannelRequests`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/hrmp/pallet/storage_types/struct.HrmpOpenChannelRequests.html){target=\\_blank}. However, the channels are not actually set up until the start of the next session, at which point bidirectional communication between parachain 2500 and system chain 1000 is established.\n\nTo verify this, wait for the next session and then follow these steps:\n\n1. Using Polkadot.js Apps, connect to the relay chain and navigate to the **Developer** dropdown, then select **Chain state**.\n\n    ![](/images/tutorials/interoperability/xcm-channels/hrmp-channels-1.webp)\n\n2. Query the HRMP channels:\n\n    1. Select **`hrmp`** from the options.\n    2. Choose the **`hrmpChannels`** call.\n    3. Click the **+** button to execute the query.\n\n    ![](/images/tutorials/interoperability/xcm-channels/para-to-system/hrmp-para-to-system-3.webp)\n    \n3. Examine the query results. You should see output similar to the following:\n\n    ```json\n    -[\n    [\n        [\n            {\n                \"sender\": 1000,\n                \"recipient\": 2500\n            }\n        ],\n        {\n            \"maxCapacity\": 8,\n            \"maxTotalSize\": 8192,\n            \"maxMessageSize\": 1048576,\n            \"msgCount\": 0,\n            \"totalSize\": 0,\n            \"mqcHead\": null,\n            \"senderDeposit\": 0,\n            \"recipientDeposit\": 0\n        }\n    ],\n    [\n        [\n            {\n                \"sender\": 2500,\n                \"recipient\": 1000\n            }\n        ],\n        {\n            \"maxCapacity\": 8,\n            \"maxTotalSize\": 8192,\n            \"maxMessageSize\": 1048576,\n            \"msgCount\": 0,\n            \"totalSize\": 0,\n            \"mqcHead\": null,\n            \"senderDeposit\": 0,\n            \"recipientDeposit\": 0\n        }\n    ]\n]\n\n    ```\n\nThe output confirms the successful establishment of two HRMP channels:\n\n- From chain 1000 (system chain) to chain 2500 (parachain).\n- From chain 2500 (parachain) to chain 1000 (system chain).\n\nThis bidirectional channel enables direct communication between the system chain and the parachain, allowing for cross-chain message passing."}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 450, "estimated_token_count": 76, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhen sending cross-chain messages, ensure that the transaction will be successful not only in the local chain but also in the destination chain and any intermediate chains.\n\nSending cross-chain messages requires estimating the fees for the operation. \n\nThis tutorial will demonstrate how to dry-run and estimate the fees for teleporting assets from the Paseo Asset Hub parachain to the Paseo Bridge Hub chain."}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 1, "depth": 2, "title": "Fee Mechanism", "anchor": "fee-mechanism", "start_char": 450, "end_char": 1437, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "## Fee Mechanism\n\nThere are three types of fees that can be charged when sending a cross-chain message:\n\n- **Local execution fees**: Fees charged in the local chain for executing the message.\n- **Delivery fees**: Fees charged for delivering the message to the destination chain.\n- **Remote execution fees**: Fees charged in the destination chain for executing the message.\n\nIf there are multiple intermediate chains, delivery fees and remote execution fees will be charged for each one.\n\nIn this example, you will estimate the fees for teleporting assets from the Paseo Asset Hub parachain to the Paseo Bridge Hub chain. The fee structure will be as follows:\n\n```mermaid\nflowchart LR\n    AssetHub[Paseo Asset Hub] -->|Delivery Fees| BridgeHub[Paseo Bridge Hub]\n    AssetHub -->|<br />Local<br />Execution<br />Fees| AssetHub\n    BridgeHub -->|<br />Remote<br />Execution<br />Fees| BridgeHub\n```\n\nThe overall fees are `local_execution_fees` + `delivery_fees` + `remote_execution_fees`."}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 2, "depth": 2, "title": "Environment Setup", "anchor": "environment-setup", "start_char": 1437, "end_char": 13410, "estimated_token_count": 2584, "token_estimator": "heuristic-v1", "text": "## Environment Setup\n\nFirst, you need to set up your environment:\n\n1. Create a new directory and initialize the project:\n\n    ```bash\n    mkdir xcm-fee-estimation && \\\n    cd xcm-fee-estimation\n    ```\n\n2. Initialize the project:\n\n    ```bash\n    npm init -y\n    ```\n\n3. Install dev dependencies:\n\n    ```bash\n    npm install --save-dev @types/node@^22.12.0 ts-node@^10.9.2 typescript@^5.7.3\n    ```\n\n4. Install dependencies:\n\n    ```bash\n    npm install --save @polkadot-labs/hdkd@^0.0.13 @polkadot-labs/hdkd-helpers@^0.0.13 polkadot-api@1.9.5\n    ```\n\n5. Create TypeScript configuration:\n\n    ```bash\n    npx tsc --init\n    ```\n\n6. Generate the types for the Polkadot API for Paseo Bridge Hub and Paseo Asset Hub:\n\n    ```bash\n    npx papi add paseoAssetHub -n paseo_asset_hub && \\\n    npx papi add paseoBridgeHub -w wss://bridge-hub-paseo.dotters.network\n    ```\n\n7. Create a new file called `teleport-ah-to-bridge-hub.ts`:\n\n    ```bash\n    touch teleport-ah-to-bridge-hub.ts\n    ```\n\n8. Import the necessary modules. Add the following code to the `teleport-ah-to-bridge-hub.ts` file:\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -import { paseoAssetHub, paseoBridgeHub } from '@polkadot-api/descriptors';\nimport { createClient, FixedSizeBinary, Enum } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/node';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport {\n  XcmVersionedLocation,\n  XcmVersionedAssetId,\n  XcmV3Junctions,\n  XcmV3MultiassetFungibility,\n  XcmVersionedXcm,\n  XcmV5Instruction,\n  XcmV5Junctions,\n  XcmV5Junction,\n  XcmV5AssetFilter,\n  XcmV5WildAsset,\n} from '@polkadot-api/descriptors';\n\n// 1 PAS = 10^10 units\nconst PAS_UNITS = 10_000_000_000n; // 1 PAS\nconst PAS_CENTS = 100_000_000n; // 0.01 PAS\n\n// Paseo Asset Hub constants\nconst PASEO_ASSET_HUB_RPC_ENDPOINT = 'ws://localhost:8001';\nconst ASSET_HUB_ACCOUNT = '15oF4uVJwmo4TdGW7VfQxNLavjCXviqxT9S1MgbjMNHr6Sp5'; // Alice (Paseo Asset Hub)\n\n// Bridge Hub destination\nconst BRIDGE_HUB_RPC_ENDPOINT = 'ws://localhost:8000';\nconst BRIDGE_HUB_PARA_ID = 1002;\nconst BRIDGE_HUB_BENEFICIARY =\n  '14E5nqKAp3oAJcmzgZhUD2RcptBeUBScxKHgJKU4HPNcKVf3'; // Bob (Bridge Hub)\n\n// Create the XCM message for teleport (Asset Hub → Bridge Hub)\nfunction createTeleportXcmToBridgeHub(paraId: number) {\n  return XcmVersionedXcm.V5([\n    // Withdraw PAS from Asset Hub (PAS on parachains is parents:1, interior: Here)\n    XcmV5Instruction.WithdrawAsset([\n      {\n        id: { parents: 1, interior: XcmV5Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(1n * PAS_UNITS), // 1 PAS\n      },\n    ]),\n    // Pay local fees on Asset Hub in PAS\n    XcmV5Instruction.PayFees({\n      asset: {\n        id: { parents: 1, interior: XcmV5Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(10n * PAS_CENTS), // 0.01 PAS\n      },\n    }),\n    // Send to Bridge Hub parachain (parents:1, interior: X1(Parachain(paraId)))\n    XcmV5Instruction.InitiateTransfer({\n      destination: {\n        parents: 1,\n        interior: XcmV5Junctions.X1(XcmV5Junction.Parachain(paraId)),\n      },\n      remote_fees: Enum(\n        'Teleport',\n        XcmV5AssetFilter.Definite([\n          {\n            id: { parents: 1, interior: XcmV5Junctions.Here() },\n            fun: XcmV3MultiassetFungibility.Fungible(10n * PAS_CENTS), // 0.01 PAS\n          },\n        ]),\n      ),\n      preserve_origin: false,\n      remote_xcm: [\n        XcmV5Instruction.DepositAsset({\n          assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n          beneficiary: {\n            parents: 0,\n            interior: XcmV5Junctions.X1(\n              XcmV5Junction.AccountId32({\n                network: undefined,\n                id: FixedSizeBinary.fromAccountId32(BRIDGE_HUB_BENEFICIARY),\n              }),\n            ),\n          },\n        }),\n      ],\n      assets: [\n        Enum('Teleport', XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1))), // Send everything.\n      ],\n    }),\n  ]);\n}\n\nasync function estimateXcmFeesFromAssetHubToBridgeHub(\n  xcm: any,\n  assetHubApi: any,\n) {\n  console.log('=== Fee Estimation Process (Asset Hub → Bridge Hub) ===');\n\n  // 1. LOCAL EXECUTION FEES on Asset Hub\n  console.log('1. Calculating local execution fees on Asset Hub...');\n  let localExecutionFees = 0n;\n\n  const weightResult =\n    await assetHubApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n  if (weightResult.success) {\n    console.log('✓ XCM weight (Asset Hub):', weightResult.value);\n\n    // Convert weight to PAS fees from Asset Hub's perspective (parents:1, Here)\n    const executionFeesResult =\n      await assetHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n        weightResult.value,\n        XcmVersionedAssetId.V4({\n          parents: 1,\n          interior: XcmV3Junctions.Here(),\n        }),\n      );\n\n    if (executionFeesResult.success) {\n      localExecutionFees = executionFeesResult.value;\n      console.log(\n        '✓ Local execution fees (Asset Hub):',\n        localExecutionFees.toString(),\n        'PAS units',\n      );\n    } else {\n      console.log(\n        '✗ Failed to calculate local execution fees:',\n        executionFeesResult.value,\n      );\n    }\n  } else {\n    console.log(\n      '✗ Failed to query XCM weight on Asset Hub:',\n      weightResult.value,\n    );\n  }\n\n  // 2. DELIVERY FEES + REMOTE EXECUTION FEES\n  console.log('\\n2. Calculating delivery and remote execution fees...');\n  let deliveryFees = 0n;\n  let remoteExecutionFees = 0n; // Skipped (Bridge Hub descriptor not available)\n\n  // Origin from Asset Hub perspective\n  const origin = XcmVersionedLocation.V5({\n    parents: 0,\n    interior: XcmV5Junctions.X1(\n      XcmV5Junction.AccountId32({\n        id: FixedSizeBinary.fromAccountId32(ASSET_HUB_ACCOUNT),\n        network: undefined,\n      }),\n    ),\n  });\n\n  // Dry run the XCM locally on Asset Hub\n  const dryRunResult = await assetHubApi.apis.DryRunApi.dry_run_xcm(\n    origin,\n    xcm,\n  );\n\n  if (\n    dryRunResult.success &&\n    dryRunResult.value.execution_result.type === 'Complete'\n  ) {\n    console.log('✓ Local dry run on Asset Hub successful');\n\n    const { forwarded_xcms: forwardedXcms } = dryRunResult.value;\n\n    // Find the XCM message sent to Bridge Hub (parents:1, interior: X1(Parachain(1002)))\n    const bridgeHubXcmEntry = forwardedXcms.find(\n      ([location, _]: [any, any]) =>\n        (location.type === 'V4' || location.type === 'V5') &&\n        location.value.parents === 1 &&\n        location.value.interior?.type === 'X1' &&\n        location.value.interior.value?.type === 'Parachain' &&\n        location.value.interior.value.value === BRIDGE_HUB_PARA_ID,\n    );\n\n    if (bridgeHubXcmEntry) {\n      const [destination, messages] = bridgeHubXcmEntry;\n      const remoteXcm = messages[0];\n\n      console.log('✓ Found XCM message to Bridge Hub');\n\n      // Calculate delivery fees from Asset Hub to Bridge Hub\n      const deliveryFeesResult =\n        await assetHubApi.apis.XcmPaymentApi.query_delivery_fees(\n          destination,\n          remoteXcm,\n        );\n\n      if (\n        deliveryFeesResult.success &&\n        deliveryFeesResult.value.type === 'V5' &&\n        deliveryFeesResult.value.value[0]?.fun?.type === 'Fungible'\n      ) {\n        deliveryFees = deliveryFeesResult.value.value[0].fun.value;\n        console.log('✓ Delivery fees:', deliveryFees.toString(), 'PAS units');\n      } else {\n        console.log('✗ Failed to calculate delivery fees:', deliveryFeesResult);\n      }\n\n      // 3. REMOTE EXECUTION FEES on Bridge Hub\n      console.log('\\n3. Calculating remote execution fees on Bridge Hub');\n      try {\n        const bridgeHubClient = createClient(\n          withPolkadotSdkCompat(getWsProvider(BRIDGE_HUB_RPC_ENDPOINT)),\n        );\n        const bridgeHubApi = bridgeHubClient.getTypedApi(paseoBridgeHub);\n        const remoteWeightResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_xcm_weight(remoteXcm);\n        const remoteFeesResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n            remoteWeightResult.value as {\n              ref_time: bigint;\n              proof_size: bigint;\n            },\n            XcmVersionedAssetId.V4({\n              parents: 1,\n              interior: XcmV3Junctions.Here(),\n            }),\n          );\n        bridgeHubClient.destroy();\n        remoteExecutionFees = remoteFeesResult.value as bigint;\n        console.log(\n          '✓ Remote execution fees:',\n          remoteExecutionFees.toString(),\n          'PAS units',\n        );\n      } catch (error) {\n        console.error(\n          'Error calculating remote execution fees on Bridge Hub:',\n          error,\n        );\n      }\n    } else {\n      console.log('✗ No XCM message found to Bridge Hub');\n    }\n  } else {\n    console.log('✗ Local dry run failed on Asset Hub:', dryRunResult.value);\n  }\n\n  // 4. TOTAL FEES\n  const totalFees = localExecutionFees + deliveryFees + remoteExecutionFees;\n\n  console.log('\\n=== Fee Summary (Asset Hub → Bridge Hub) ===');\n  console.log(\n    'Local execution fees:',\n    localExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('Delivery fees:', deliveryFees.toString(), 'PAS units');\n  console.log(\n    'Remote execution fees:',\n    remoteExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('TOTAL FEES:', totalFees.toString(), 'PAS units');\n  console.log(\n    'TOTAL FEES:',\n    (Number(totalFees) / Number(PAS_UNITS)).toFixed(4),\n    'PAS',\n  );\n\n  return {\n    localExecutionFees,\n    deliveryFees,\n    remoteExecutionFees,\n    totalFees,\n  };\n}\n\nasync function main() {\n  // Connect to the Asset Hub parachain\n  const assetHubClient = createClient(\n    withPolkadotSdkCompat(getWsProvider(PASEO_ASSET_HUB_RPC_ENDPOINT)),\n  );\n\n  // Get the typed API for Asset Hub\n  const assetHubApi = assetHubClient.getTypedApi(paseoAssetHub);\n\n  try {\n    // Create the XCM message for teleport (Asset Hub → Bridge Hub)\n    const xcm = createTeleportXcmToBridgeHub(BRIDGE_HUB_PARA_ID);\n\n    console.log('=== XCM Teleport: Paseo Asset Hub → Bridge Hub ===');\n    console.log('From:', ASSET_HUB_ACCOUNT, '(Alice on Asset Hub)');\n    console.log('To:', BRIDGE_HUB_BENEFICIARY, '(Beneficiary on Bridge Hub)');\n    console.log('Amount:', '1 PAS');\n    console.log('');\n\n    // Estimate all fees\n    const fees = await estimateXcmFeesFromAssetHubToBridgeHub(xcm, assetHubApi);\n    void fees; // prevent unused var under isolatedModules\n\n    // Create the execute transaction on Asset Hub\n    const tx = assetHubApi.tx.PolkadotXcm.execute({\n      message: xcm,\n      max_weight: {\n        ref_time: 6000000000n,\n        proof_size: 65536n,\n      },\n    });\n\n    console.log('\\n=== Transaction Details ===');\n    console.log('Transaction hex:', (await tx.getEncodedData()).asHex());\n    console.log('Ready to submit!');\n  } catch (error) {\n    console.log('Error stack:', (error as Error).stack);\n    console.error('Error occurred:', (error as Error).message);\n    if ((error as Error).cause) {\n      console.dir((error as Error).cause, { depth: null });\n    }\n  } finally {\n    // Ensure client is always destroyed\n    assetHubClient.destroy();\n  }\n}\n\nmain().catch(console.error);\n\n    ```\n\n9. Define constants and a `main` function where you will implement all the logic:\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -// 1 PAS = 10^10 units\nconst PAS_UNITS = 10_000_000_000n; // 1 PAS\nconst PAS_CENTS = 100_000_000n; // 0.01 PAS\n\n// Paseo Asset Hub constants\nconst PASEO_ASSET_HUB_RPC_ENDPOINT = 'ws://localhost:8001';\nconst ASSET_HUB_ACCOUNT = '15oF4uVJwmo4TdGW7VfQxNLavjCXviqxT9S1MgbjMNHr6Sp5'; // Alice (Paseo Asset Hub)\n\n// Bridge Hub destination\nconst BRIDGE_HUB_RPC_ENDPOINT = 'ws://localhost:8000';\nconst BRIDGE_HUB_PARA_ID = 1002;\nconst BRIDGE_HUB_BENEFICIARY =\n\n    async function main() {\n      // Code will go here\n    }\n    ```\n\nAll the following code explained in the subsequent sections must be added inside the `main` function."}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 3, "depth": 2, "title": "Client and API Setup", "anchor": "client-and-api-setup", "start_char": 13410, "end_char": 14288, "estimated_token_count": 173, "token_estimator": "heuristic-v1", "text": "## Client and API Setup\n\nNow you are ready to start implementing the logic for the fee estimation for the teleport you want to perform. In this step, you will create the client for the Paseo Asset Hub parachain and generate the typed API to interact with the chain. Follow the steps below:\n\nCreate the API client. You will need to create a client for the Paseo Asset Hub parachain:\n\n```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n-  // Connect to the Asset Hub parachain\n  const assetHubClient = createClient(\n    withPolkadotSdkCompat(getWsProvider(PASEO_ASSET_HUB_RPC_ENDPOINT)),\n  );\n\n  // Get the typed API for Asset Hub\n  const assetHubApi = assetHubClient.getTypedApi(paseoAssetHub);\n```\n\nEnsure that you replace the endpoint URLs with the actual WebSocket endpoints. This example uses local chopsticks endpoints, but you can use public endpoints or run local nodes."}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 4, "depth": 2, "title": "Create the XCM Message", "anchor": "create-the-xcm-message", "start_char": 14288, "end_char": 16249, "estimated_token_count": 396, "token_estimator": "heuristic-v1", "text": "## Create the XCM Message\n\nNow, you can construct a proper XCM message using the new XCM V5 instructions for teleporting from Asset Hub to the Bridge Hub Chain:\n\n```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n-function createTeleportXcmToBridgeHub(paraId: number) {\n  return XcmVersionedXcm.V5([\n    // Withdraw PAS from Asset Hub (PAS on parachains is parents:1, interior: Here)\n    XcmV5Instruction.WithdrawAsset([\n      {\n        id: { parents: 1, interior: XcmV5Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(1n * PAS_UNITS), // 1 PAS\n      },\n    ]),\n    // Pay local fees on Asset Hub in PAS\n    XcmV5Instruction.PayFees({\n      asset: {\n        id: { parents: 1, interior: XcmV5Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(10n * PAS_CENTS), // 0.01 PAS\n      },\n    }),\n    // Send to Bridge Hub parachain (parents:1, interior: X1(Parachain(paraId)))\n    XcmV5Instruction.InitiateTransfer({\n      destination: {\n        parents: 1,\n        interior: XcmV5Junctions.X1(XcmV5Junction.Parachain(paraId)),\n      },\n      remote_fees: Enum(\n        'Teleport',\n        XcmV5AssetFilter.Definite([\n          {\n            id: { parents: 1, interior: XcmV5Junctions.Here() },\n            fun: XcmV3MultiassetFungibility.Fungible(10n * PAS_CENTS), // 0.01 PAS\n          },\n        ]),\n      ),\n      preserve_origin: false,\n      remote_xcm: [\n        XcmV5Instruction.DepositAsset({\n          assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n          beneficiary: {\n            parents: 0,\n            interior: XcmV5Junctions.X1(\n              XcmV5Junction.AccountId32({\n                network: undefined,\n                id: FixedSizeBinary.fromAccountId32(BRIDGE_HUB_BENEFICIARY),\n              }),\n            ),\n          },\n        }),\n      ],\n      assets: [\n        Enum('Teleport', XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1))), // Send everything.\n      ],\n    }),\n  ]);\n}\n```"}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 5, "depth": 2, "title": "Fee Estimation Function", "anchor": "fee-estimation-function", "start_char": 16249, "end_char": 28873, "estimated_token_count": 2705, "token_estimator": "heuristic-v1", "text": "## Fee Estimation Function\n\nBelow is a four-step breakdown of the logic needed to estimate the fees for the teleport.\n\nFirst, you need to create the function that will estimate the fees for the teleport:\n\n```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n-async function estimateXcmFeesFromAssetHubToBridgeHub(\n  xcm: any,\n  assetHubApi: any,\n) {\n  // Code will go here\n}\n```\n\n1. **Local execution fees on Asset Hub**: Compute the XCM weight locally, then convert that weight to PAS using Asset Hub's view of PAS (`parents: 1, interior: Here`). Add the code to the function:\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -  console.log('=== Fee Estimation Process (Asset Hub → Bridge Hub) ===');\n\n  // 1. LOCAL EXECUTION FEES on Asset Hub\n  console.log('1. Calculating local execution fees on Asset Hub...');\n  let localExecutionFees = 0n;\n\n  const weightResult =\n    await assetHubApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n  if (weightResult.success) {\n    console.log('✓ XCM weight (Asset Hub):', weightResult.value);\n\n    // Convert weight to PAS fees from Asset Hub's perspective (parents:1, Here)\n    const executionFeesResult =\n      await assetHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n        weightResult.value,\n        XcmVersionedAssetId.V4({\n          parents: 1,\n          interior: XcmV3Junctions.Here(),\n        }),\n      );\n\n    if (executionFeesResult.success) {\n      localExecutionFees = executionFeesResult.value;\n      console.log(\n        '✓ Local execution fees (Asset Hub):',\n        localExecutionFees.toString(),\n        'PAS units',\n      );\n    } else {\n      console.log(\n        '✗ Failed to calculate local execution fees:',\n        executionFeesResult.value,\n      );\n    }\n  } else {\n    console.log(\n      '✗ Failed to query XCM weight on Asset Hub:',\n      weightResult.value,\n    );\n  }\n    ```\n\n2. **Dry-run and delivery fees to Bridge Hub**: Dry-run the XCM on Asset Hub to capture forwarded messages, locate the one targeting Bridge Hub (`parents: 1, interior: Here`), and ask for delivery fees. Add the code to the function:\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -  // 2. DELIVERY FEES + REMOTE EXECUTION FEES\n  console.log('\\n2. Calculating delivery and remote execution fees...');\n  let deliveryFees = 0n;\n  let remoteExecutionFees = 0n; // Skipped (Bridge Hub descriptor not available)\n\n  // Origin from Asset Hub perspective\n  const origin = XcmVersionedLocation.V5({\n    parents: 0,\n    interior: XcmV5Junctions.X1(\n      XcmV5Junction.AccountId32({\n        id: FixedSizeBinary.fromAccountId32(ASSET_HUB_ACCOUNT),\n        network: undefined,\n      }),\n    ),\n  });\n\n  // Dry run the XCM locally on Asset Hub\n  const dryRunResult = await assetHubApi.apis.DryRunApi.dry_run_xcm(\n    origin,\n    xcm,\n  );\n\n  if (\n    dryRunResult.success &&\n    dryRunResult.value.execution_result.type === 'Complete'\n  ) {\n    console.log('✓ Local dry run on Asset Hub successful');\n\n    const { forwarded_xcms: forwardedXcms } = dryRunResult.value;\n\n    // Find the XCM message sent to Bridge Hub (parents:1, interior: X1(Parachain(1002)))\n    const bridgeHubXcmEntry = forwardedXcms.find(\n      ([location, _]: [any, any]) =>\n        (location.type === 'V4' || location.type === 'V5') &&\n        location.value.parents === 1 &&\n        location.value.interior?.type === 'X1' &&\n        location.value.interior.value?.type === 'Parachain' &&\n        location.value.interior.value.value === BRIDGE_HUB_PARA_ID,\n    );\n\n    if (bridgeHubXcmEntry) {\n      const [destination, messages] = bridgeHubXcmEntry;\n      const remoteXcm = messages[0];\n\n      console.log('✓ Found XCM message to Bridge Hub');\n\n      // Calculate delivery fees from Asset Hub to Bridge Hub\n      const deliveryFeesResult =\n        await assetHubApi.apis.XcmPaymentApi.query_delivery_fees(\n          destination,\n          remoteXcm,\n        );\n\n      if (\n        deliveryFeesResult.success &&\n        deliveryFeesResult.value.type === 'V5' &&\n        deliveryFeesResult.value.value[0]?.fun?.type === 'Fungible'\n      ) {\n        deliveryFees = deliveryFeesResult.value.value[0].fun.value;\n        console.log('✓ Delivery fees:', deliveryFees.toString(), 'PAS units');\n      } else {\n        console.log('✗ Failed to calculate delivery fees:', deliveryFeesResult);\n      }\n    ```\n\n3. **Remote execution fees on Bridge Hub**: Connect to Bridge Hub, recompute the forwarded XCM weight there, and convert weight to PAS (`parents: 0, interior: Here`). Add the code to the function:\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -      // 3. REMOTE EXECUTION FEES on Bridge Hub\n      console.log('\\n3. Calculating remote execution fees on Bridge Hub');\n      try {\n        const bridgeHubClient = createClient(\n          withPolkadotSdkCompat(getWsProvider(BRIDGE_HUB_RPC_ENDPOINT)),\n        );\n        const bridgeHubApi = bridgeHubClient.getTypedApi(paseoBridgeHub);\n        const remoteWeightResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_xcm_weight(remoteXcm);\n        const remoteFeesResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n            remoteWeightResult.value as {\n              ref_time: bigint;\n              proof_size: bigint;\n            },\n            XcmVersionedAssetId.V4({\n              parents: 1,\n              interior: XcmV3Junctions.Here(),\n            }),\n          );\n        bridgeHubClient.destroy();\n        remoteExecutionFees = remoteFeesResult.value as bigint;\n        console.log(\n          '✓ Remote execution fees:',\n          remoteExecutionFees.toString(),\n          'PAS units',\n        );\n      } catch (error) {\n        console.error(\n          'Error calculating remote execution fees on Bridge Hub:',\n          error,\n        );\n      }\n    } else {\n      console.log('✗ No XCM message found to Bridge Hub');\n    }\n  } else {\n    console.log('✗ Local dry run failed on Asset Hub:', dryRunResult.value);\n  }\n    ```\n\n4. **Sum and return totals**: Aggregate all parts, print a short summary, and return a structured result. Add the code to the function:\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -  // 4. TOTAL FEES\n  const totalFees = localExecutionFees + deliveryFees + remoteExecutionFees;\n\n  console.log('\\n=== Fee Summary (Asset Hub → Bridge Hub) ===');\n  console.log(\n    'Local execution fees:',\n    localExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('Delivery fees:', deliveryFees.toString(), 'PAS units');\n  console.log(\n    'Remote execution fees:',\n    remoteExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('TOTAL FEES:', totalFees.toString(), 'PAS units');\n  console.log(\n    'TOTAL FEES:',\n    (Number(totalFees) / Number(PAS_UNITS)).toFixed(4),\n    'PAS',\n  );\n\n  return {\n    localExecutionFees,\n    deliveryFees,\n    remoteExecutionFees,\n    totalFees,\n  };\n}\n    ```\n\nThe full code for the fee estimation function is the following:\n\n??? code \"Fee Estimation Function\"\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -async function estimateXcmFeesFromAssetHubToBridgeHub(\n  xcm: any,\n  assetHubApi: any,\n) {\n  console.log('=== Fee Estimation Process (Asset Hub → Bridge Hub) ===');\n\n  // 1. LOCAL EXECUTION FEES on Asset Hub\n  console.log('1. Calculating local execution fees on Asset Hub...');\n  let localExecutionFees = 0n;\n\n  const weightResult =\n    await assetHubApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n  if (weightResult.success) {\n    console.log('✓ XCM weight (Asset Hub):', weightResult.value);\n\n    // Convert weight to PAS fees from Asset Hub's perspective (parents:1, Here)\n    const executionFeesResult =\n      await assetHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n        weightResult.value,\n        XcmVersionedAssetId.V4({\n          parents: 1,\n          interior: XcmV3Junctions.Here(),\n        }),\n      );\n\n    if (executionFeesResult.success) {\n      localExecutionFees = executionFeesResult.value;\n      console.log(\n        '✓ Local execution fees (Asset Hub):',\n        localExecutionFees.toString(),\n        'PAS units',\n      );\n    } else {\n      console.log(\n        '✗ Failed to calculate local execution fees:',\n        executionFeesResult.value,\n      );\n    }\n  } else {\n    console.log(\n      '✗ Failed to query XCM weight on Asset Hub:',\n      weightResult.value,\n    );\n  }\n\n  // 2. DELIVERY FEES + REMOTE EXECUTION FEES\n  console.log('\\n2. Calculating delivery and remote execution fees...');\n  let deliveryFees = 0n;\n  let remoteExecutionFees = 0n; // Skipped (Bridge Hub descriptor not available)\n\n  // Origin from Asset Hub perspective\n  const origin = XcmVersionedLocation.V5({\n    parents: 0,\n    interior: XcmV5Junctions.X1(\n      XcmV5Junction.AccountId32({\n        id: FixedSizeBinary.fromAccountId32(ASSET_HUB_ACCOUNT),\n        network: undefined,\n      }),\n    ),\n  });\n\n  // Dry run the XCM locally on Asset Hub\n  const dryRunResult = await assetHubApi.apis.DryRunApi.dry_run_xcm(\n    origin,\n    xcm,\n  );\n\n  if (\n    dryRunResult.success &&\n    dryRunResult.value.execution_result.type === 'Complete'\n  ) {\n    console.log('✓ Local dry run on Asset Hub successful');\n\n    const { forwarded_xcms: forwardedXcms } = dryRunResult.value;\n\n    // Find the XCM message sent to Bridge Hub (parents:1, interior: X1(Parachain(1002)))\n    const bridgeHubXcmEntry = forwardedXcms.find(\n      ([location, _]: [any, any]) =>\n        (location.type === 'V4' || location.type === 'V5') &&\n        location.value.parents === 1 &&\n        location.value.interior?.type === 'X1' &&\n        location.value.interior.value?.type === 'Parachain' &&\n        location.value.interior.value.value === BRIDGE_HUB_PARA_ID,\n    );\n\n    if (bridgeHubXcmEntry) {\n      const [destination, messages] = bridgeHubXcmEntry;\n      const remoteXcm = messages[0];\n\n      console.log('✓ Found XCM message to Bridge Hub');\n\n      // Calculate delivery fees from Asset Hub to Bridge Hub\n      const deliveryFeesResult =\n        await assetHubApi.apis.XcmPaymentApi.query_delivery_fees(\n          destination,\n          remoteXcm,\n        );\n\n      if (\n        deliveryFeesResult.success &&\n        deliveryFeesResult.value.type === 'V5' &&\n        deliveryFeesResult.value.value[0]?.fun?.type === 'Fungible'\n      ) {\n        deliveryFees = deliveryFeesResult.value.value[0].fun.value;\n        console.log('✓ Delivery fees:', deliveryFees.toString(), 'PAS units');\n      } else {\n        console.log('✗ Failed to calculate delivery fees:', deliveryFeesResult);\n      }\n\n      // 3. REMOTE EXECUTION FEES on Bridge Hub\n      console.log('\\n3. Calculating remote execution fees on Bridge Hub');\n      try {\n        const bridgeHubClient = createClient(\n          withPolkadotSdkCompat(getWsProvider(BRIDGE_HUB_RPC_ENDPOINT)),\n        );\n        const bridgeHubApi = bridgeHubClient.getTypedApi(paseoBridgeHub);\n        const remoteWeightResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_xcm_weight(remoteXcm);\n        const remoteFeesResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n            remoteWeightResult.value as {\n              ref_time: bigint;\n              proof_size: bigint;\n            },\n            XcmVersionedAssetId.V4({\n              parents: 1,\n              interior: XcmV3Junctions.Here(),\n            }),\n          );\n        bridgeHubClient.destroy();\n        remoteExecutionFees = remoteFeesResult.value as bigint;\n        console.log(\n          '✓ Remote execution fees:',\n          remoteExecutionFees.toString(),\n          'PAS units',\n        );\n      } catch (error) {\n        console.error(\n          'Error calculating remote execution fees on Bridge Hub:',\n          error,\n        );\n      }\n    } else {\n      console.log('✗ No XCM message found to Bridge Hub');\n    }\n  } else {\n    console.log('✗ Local dry run failed on Asset Hub:', dryRunResult.value);\n  }\n\n  // 4. TOTAL FEES\n  const totalFees = localExecutionFees + deliveryFees + remoteExecutionFees;\n\n  console.log('\\n=== Fee Summary (Asset Hub → Bridge Hub) ===');\n  console.log(\n    'Local execution fees:',\n    localExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('Delivery fees:', deliveryFees.toString(), 'PAS units');\n  console.log(\n    'Remote execution fees:',\n    remoteExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('TOTAL FEES:', totalFees.toString(), 'PAS units');\n  console.log(\n    'TOTAL FEES:',\n    (Number(totalFees) / Number(PAS_UNITS)).toFixed(4),\n    'PAS',\n  );\n\n  return {\n    localExecutionFees,\n    deliveryFees,\n    remoteExecutionFees,\n    totalFees,\n  };\n}\n    ```"}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 6, "depth": 2, "title": "Complete Implementation", "anchor": "complete-implementation", "start_char": 28873, "end_char": 30589, "estimated_token_count": 412, "token_estimator": "heuristic-v1", "text": "## Complete Implementation\n\nNow put it all together in the main function:\n\n```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n-async function main() {\n  // Connect to the Asset Hub parachain\n  const assetHubClient = createClient(\n    withPolkadotSdkCompat(getWsProvider(PASEO_ASSET_HUB_RPC_ENDPOINT)),\n  );\n\n  // Get the typed API for Asset Hub\n  const assetHubApi = assetHubClient.getTypedApi(paseoAssetHub);\n\n  try {\n    // Create the XCM message for teleport (Asset Hub → Bridge Hub)\n    const xcm = createTeleportXcmToBridgeHub(BRIDGE_HUB_PARA_ID);\n\n    console.log('=== XCM Teleport: Paseo Asset Hub → Bridge Hub ===');\n    console.log('From:', ASSET_HUB_ACCOUNT, '(Alice on Asset Hub)');\n    console.log('To:', BRIDGE_HUB_BENEFICIARY, '(Beneficiary on Bridge Hub)');\n    console.log('Amount:', '1 PAS');\n    console.log('');\n\n    // Estimate all fees\n    const fees = await estimateXcmFeesFromAssetHubToBridgeHub(xcm, assetHubApi);\n    void fees; // prevent unused var under isolatedModules\n\n    // Create the execute transaction on Asset Hub\n    const tx = assetHubApi.tx.PolkadotXcm.execute({\n      message: xcm,\n      max_weight: {\n        ref_time: 6000000000n,\n        proof_size: 65536n,\n      },\n    });\n\n    console.log('\\n=== Transaction Details ===');\n    console.log('Transaction hex:', (await tx.getEncodedData()).asHex());\n    console.log('Ready to submit!');\n  } catch (error) {\n    console.log('Error stack:', (error as Error).stack);\n    console.error('Error occurred:', (error as Error).message);\n    if ((error as Error).cause) {\n      console.dir((error as Error).cause, { depth: null });\n    }\n  } finally {\n    // Ensure client is always destroyed\n    assetHubClient.destroy();\n  }\n}\n```"}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 7, "depth": 2, "title": "Full Code", "anchor": "full-code", "start_char": 30589, "end_char": 40833, "estimated_token_count": 2143, "token_estimator": "heuristic-v1", "text": "## Full Code\n\nThe full code for the complete implementation is the following:\n\n??? code \"Teleport from Asset Hub to Bridge Hub\"\n\n    ```typescript title=\"teleport-ah-to-bridge-hub.ts\"\n    -import { paseoAssetHub, paseoBridgeHub } from '@polkadot-api/descriptors';\nimport { createClient, FixedSizeBinary, Enum } from 'polkadot-api';\nimport { getWsProvider } from 'polkadot-api/ws-provider/node';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport {\n  XcmVersionedLocation,\n  XcmVersionedAssetId,\n  XcmV3Junctions,\n  XcmV3MultiassetFungibility,\n  XcmVersionedXcm,\n  XcmV5Instruction,\n  XcmV5Junctions,\n  XcmV5Junction,\n  XcmV5AssetFilter,\n  XcmV5WildAsset,\n} from '@polkadot-api/descriptors';\n\n// 1 PAS = 10^10 units\nconst PAS_UNITS = 10_000_000_000n; // 1 PAS\nconst PAS_CENTS = 100_000_000n; // 0.01 PAS\n\n// Paseo Asset Hub constants\nconst PASEO_ASSET_HUB_RPC_ENDPOINT = 'ws://localhost:8001';\nconst ASSET_HUB_ACCOUNT = '15oF4uVJwmo4TdGW7VfQxNLavjCXviqxT9S1MgbjMNHr6Sp5'; // Alice (Paseo Asset Hub)\n\n// Bridge Hub destination\nconst BRIDGE_HUB_RPC_ENDPOINT = 'ws://localhost:8000';\nconst BRIDGE_HUB_PARA_ID = 1002;\nconst BRIDGE_HUB_BENEFICIARY =\n  '14E5nqKAp3oAJcmzgZhUD2RcptBeUBScxKHgJKU4HPNcKVf3'; // Bob (Bridge Hub)\n\n// Create the XCM message for teleport (Asset Hub → Bridge Hub)\nfunction createTeleportXcmToBridgeHub(paraId: number) {\n  return XcmVersionedXcm.V5([\n    // Withdraw PAS from Asset Hub (PAS on parachains is parents:1, interior: Here)\n    XcmV5Instruction.WithdrawAsset([\n      {\n        id: { parents: 1, interior: XcmV5Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(1n * PAS_UNITS), // 1 PAS\n      },\n    ]),\n    // Pay local fees on Asset Hub in PAS\n    XcmV5Instruction.PayFees({\n      asset: {\n        id: { parents: 1, interior: XcmV5Junctions.Here() },\n        fun: XcmV3MultiassetFungibility.Fungible(10n * PAS_CENTS), // 0.01 PAS\n      },\n    }),\n    // Send to Bridge Hub parachain (parents:1, interior: X1(Parachain(paraId)))\n    XcmV5Instruction.InitiateTransfer({\n      destination: {\n        parents: 1,\n        interior: XcmV5Junctions.X1(XcmV5Junction.Parachain(paraId)),\n      },\n      remote_fees: Enum(\n        'Teleport',\n        XcmV5AssetFilter.Definite([\n          {\n            id: { parents: 1, interior: XcmV5Junctions.Here() },\n            fun: XcmV3MultiassetFungibility.Fungible(10n * PAS_CENTS), // 0.01 PAS\n          },\n        ]),\n      ),\n      preserve_origin: false,\n      remote_xcm: [\n        XcmV5Instruction.DepositAsset({\n          assets: XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1)),\n          beneficiary: {\n            parents: 0,\n            interior: XcmV5Junctions.X1(\n              XcmV5Junction.AccountId32({\n                network: undefined,\n                id: FixedSizeBinary.fromAccountId32(BRIDGE_HUB_BENEFICIARY),\n              }),\n            ),\n          },\n        }),\n      ],\n      assets: [\n        Enum('Teleport', XcmV5AssetFilter.Wild(XcmV5WildAsset.AllCounted(1))), // Send everything.\n      ],\n    }),\n  ]);\n}\n\nasync function estimateXcmFeesFromAssetHubToBridgeHub(\n  xcm: any,\n  assetHubApi: any,\n) {\n  console.log('=== Fee Estimation Process (Asset Hub → Bridge Hub) ===');\n\n  // 1. LOCAL EXECUTION FEES on Asset Hub\n  console.log('1. Calculating local execution fees on Asset Hub...');\n  let localExecutionFees = 0n;\n\n  const weightResult =\n    await assetHubApi.apis.XcmPaymentApi.query_xcm_weight(xcm);\n  if (weightResult.success) {\n    console.log('✓ XCM weight (Asset Hub):', weightResult.value);\n\n    // Convert weight to PAS fees from Asset Hub's perspective (parents:1, Here)\n    const executionFeesResult =\n      await assetHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n        weightResult.value,\n        XcmVersionedAssetId.V4({\n          parents: 1,\n          interior: XcmV3Junctions.Here(),\n        }),\n      );\n\n    if (executionFeesResult.success) {\n      localExecutionFees = executionFeesResult.value;\n      console.log(\n        '✓ Local execution fees (Asset Hub):',\n        localExecutionFees.toString(),\n        'PAS units',\n      );\n    } else {\n      console.log(\n        '✗ Failed to calculate local execution fees:',\n        executionFeesResult.value,\n      );\n    }\n  } else {\n    console.log(\n      '✗ Failed to query XCM weight on Asset Hub:',\n      weightResult.value,\n    );\n  }\n\n  // 2. DELIVERY FEES + REMOTE EXECUTION FEES\n  console.log('\\n2. Calculating delivery and remote execution fees...');\n  let deliveryFees = 0n;\n  let remoteExecutionFees = 0n; // Skipped (Bridge Hub descriptor not available)\n\n  // Origin from Asset Hub perspective\n  const origin = XcmVersionedLocation.V5({\n    parents: 0,\n    interior: XcmV5Junctions.X1(\n      XcmV5Junction.AccountId32({\n        id: FixedSizeBinary.fromAccountId32(ASSET_HUB_ACCOUNT),\n        network: undefined,\n      }),\n    ),\n  });\n\n  // Dry run the XCM locally on Asset Hub\n  const dryRunResult = await assetHubApi.apis.DryRunApi.dry_run_xcm(\n    origin,\n    xcm,\n  );\n\n  if (\n    dryRunResult.success &&\n    dryRunResult.value.execution_result.type === 'Complete'\n  ) {\n    console.log('✓ Local dry run on Asset Hub successful');\n\n    const { forwarded_xcms: forwardedXcms } = dryRunResult.value;\n\n    // Find the XCM message sent to Bridge Hub (parents:1, interior: X1(Parachain(1002)))\n    const bridgeHubXcmEntry = forwardedXcms.find(\n      ([location, _]: [any, any]) =>\n        (location.type === 'V4' || location.type === 'V5') &&\n        location.value.parents === 1 &&\n        location.value.interior?.type === 'X1' &&\n        location.value.interior.value?.type === 'Parachain' &&\n        location.value.interior.value.value === BRIDGE_HUB_PARA_ID,\n    );\n\n    if (bridgeHubXcmEntry) {\n      const [destination, messages] = bridgeHubXcmEntry;\n      const remoteXcm = messages[0];\n\n      console.log('✓ Found XCM message to Bridge Hub');\n\n      // Calculate delivery fees from Asset Hub to Bridge Hub\n      const deliveryFeesResult =\n        await assetHubApi.apis.XcmPaymentApi.query_delivery_fees(\n          destination,\n          remoteXcm,\n        );\n\n      if (\n        deliveryFeesResult.success &&\n        deliveryFeesResult.value.type === 'V5' &&\n        deliveryFeesResult.value.value[0]?.fun?.type === 'Fungible'\n      ) {\n        deliveryFees = deliveryFeesResult.value.value[0].fun.value;\n        console.log('✓ Delivery fees:', deliveryFees.toString(), 'PAS units');\n      } else {\n        console.log('✗ Failed to calculate delivery fees:', deliveryFeesResult);\n      }\n\n      // 3. REMOTE EXECUTION FEES on Bridge Hub\n      console.log('\\n3. Calculating remote execution fees on Bridge Hub');\n      try {\n        const bridgeHubClient = createClient(\n          withPolkadotSdkCompat(getWsProvider(BRIDGE_HUB_RPC_ENDPOINT)),\n        );\n        const bridgeHubApi = bridgeHubClient.getTypedApi(paseoBridgeHub);\n        const remoteWeightResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_xcm_weight(remoteXcm);\n        const remoteFeesResult =\n          await bridgeHubApi.apis.XcmPaymentApi.query_weight_to_asset_fee(\n            remoteWeightResult.value as {\n              ref_time: bigint;\n              proof_size: bigint;\n            },\n            XcmVersionedAssetId.V4({\n              parents: 1,\n              interior: XcmV3Junctions.Here(),\n            }),\n          );\n        bridgeHubClient.destroy();\n        remoteExecutionFees = remoteFeesResult.value as bigint;\n        console.log(\n          '✓ Remote execution fees:',\n          remoteExecutionFees.toString(),\n          'PAS units',\n        );\n      } catch (error) {\n        console.error(\n          'Error calculating remote execution fees on Bridge Hub:',\n          error,\n        );\n      }\n    } else {\n      console.log('✗ No XCM message found to Bridge Hub');\n    }\n  } else {\n    console.log('✗ Local dry run failed on Asset Hub:', dryRunResult.value);\n  }\n\n  // 4. TOTAL FEES\n  const totalFees = localExecutionFees + deliveryFees + remoteExecutionFees;\n\n  console.log('\\n=== Fee Summary (Asset Hub → Bridge Hub) ===');\n  console.log(\n    'Local execution fees:',\n    localExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('Delivery fees:', deliveryFees.toString(), 'PAS units');\n  console.log(\n    'Remote execution fees:',\n    remoteExecutionFees.toString(),\n    'PAS units',\n  );\n  console.log('TOTAL FEES:', totalFees.toString(), 'PAS units');\n  console.log(\n    'TOTAL FEES:',\n    (Number(totalFees) / Number(PAS_UNITS)).toFixed(4),\n    'PAS',\n  );\n\n  return {\n    localExecutionFees,\n    deliveryFees,\n    remoteExecutionFees,\n    totalFees,\n  };\n}\n\nasync function main() {\n  // Connect to the Asset Hub parachain\n  const assetHubClient = createClient(\n    withPolkadotSdkCompat(getWsProvider(PASEO_ASSET_HUB_RPC_ENDPOINT)),\n  );\n\n  // Get the typed API for Asset Hub\n  const assetHubApi = assetHubClient.getTypedApi(paseoAssetHub);\n\n  try {\n    // Create the XCM message for teleport (Asset Hub → Bridge Hub)\n    const xcm = createTeleportXcmToBridgeHub(BRIDGE_HUB_PARA_ID);\n\n    console.log('=== XCM Teleport: Paseo Asset Hub → Bridge Hub ===');\n    console.log('From:', ASSET_HUB_ACCOUNT, '(Alice on Asset Hub)');\n    console.log('To:', BRIDGE_HUB_BENEFICIARY, '(Beneficiary on Bridge Hub)');\n    console.log('Amount:', '1 PAS');\n    console.log('');\n\n    // Estimate all fees\n    const fees = await estimateXcmFeesFromAssetHubToBridgeHub(xcm, assetHubApi);\n    void fees; // prevent unused var under isolatedModules\n\n    // Create the execute transaction on Asset Hub\n    const tx = assetHubApi.tx.PolkadotXcm.execute({\n      message: xcm,\n      max_weight: {\n        ref_time: 6000000000n,\n        proof_size: 65536n,\n      },\n    });\n\n    console.log('\\n=== Transaction Details ===');\n    console.log('Transaction hex:', (await tx.getEncodedData()).asHex());\n    console.log('Ready to submit!');\n  } catch (error) {\n    console.log('Error stack:', (error as Error).stack);\n    console.error('Error occurred:', (error as Error).message);\n    if ((error as Error).cause) {\n      console.dir((error as Error).cause, { depth: null });\n    }\n  } finally {\n    // Ensure client is always destroyed\n    assetHubClient.destroy();\n  }\n}\n\nmain().catch(console.error);\n\n    ```"}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 8, "depth": 2, "title": "Running the Script", "anchor": "running-the-script", "start_char": 40833, "end_char": 44756, "estimated_token_count": 935, "token_estimator": "heuristic-v1", "text": "## Running the Script\n\nBefore running the script, you can use chopsticks to fork the Paseo Asset Hub and Paseo Bridge Hub chains locally. To do so, you can use the following files and commands:\n\n1. Create a new directory called `.chopsticks` and add the files:\n\n    ??? code \"paseo-bridge-hub.yml\"\n\n        ```yaml title=\".chopsticks/paseo-bridge-hub.yml\"\n        -endpoint: wss://bridge-hub-paseo.dotters.network\nmock-signature-host: true\nblock: ${env.PASEO_BRIDGE_HUB_BLOCK_NUMBER}\ndb: ./db.sqlite\n\nimport-storage:\n  Sudo:\n    Key: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY # Alice\n  System:\n    Account:\n      -\n        -\n          - 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\n        - providers: 1\n          data:\n            free: '10000000000000000000'\n        ```\n    \n    ??? code \"paseo-asset-hub.yml\"\n\n        ```yaml title=\".chopsticks/paseo-asset-hub.yml\"\n        -endpoint: wss://asset-hub-paseo-rpc.n.dwellir.com\nmock-signature-host: true\nblock: ${env.PASEO_ASSET_HUB_BLOCK_NUMBER}\ndb: ./db.sqlite\n\nimport-storage:\n  Sudo:\n    Key: 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY # Alice\n  System:\n    Account:\n      -\n        -\n          - 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\n        - providers: 1\n          data:\n            free: '10000000000000000000'\n        ```\n\n2. Run the following command to fork the Paseo Bridge Hub chain:\n\n    ```bash\n    chopsticks --config=.chopsticks/paseo-bridge-hub.yml\n    ```\n\n    After running the command, you will see the following output:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>chopsticks --config=.chopsticks/paseo-bridge-hub.yml</span>\n  <span data-ty=\"output\">[15:55:22.770] INFO: Paseo Bridge Hub RPC listening on http://[::]:8000 and ws://[::]:8000</span>\n  <span data-ty=\"output\">app: \"chopsticks\"</span>\n</div>\n\n\n3. Run the following command to fork the Paseo Asset Hub chain:\n\n    ```bash\n    chopsticks --config=.chopsticks/paseo-asset-hub.yml\n    ```\n\n    After running the commands, you will see the following output:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>chopsticks --config=.chopsticks/paseo-asset-hub.yml</span>\n  <span data-ty=\"output\">[15:55:22.770] INFO: Paseo Asset Hub Testnet RPC listening on http://[::]:8001 and ws://[::]:8001</span>\n  <span data-ty=\"output\">app: \"chopsticks\"</span>\n</div>\n\n\n4. Run the script:\n\n    ```bash\n    npx ts-node teleport-ah-to-bridge-hub.ts\n    ```\n\nAfter running the script, you will see the following output:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx ts-node teleport-ah-to-bridge-hub.ts</span>\n  <pre>\n=== XCM Teleport: Paseo Asset Hub → Bridge Hub ===\nFrom: 15oF4uVJwmo4TdGW7VfQxNLavjCXviqxT9S1MgbjMNHr6Sp5 (Alice on Asset Hub)\nTo: 14E5nqKAp3oAJcmzgZhUD2RcptBeUBScxKHgJKU4HPNcKVf3 (Beneficiary on Bridge Hub)\nAmount: 1 PAS\n\n=== Fee Estimation Process (Asset Hub → Bridge Hub) ===\n1. Calculating local execution fees on Asset Hub...\n✓ XCM weight (Asset Hub): { ref_time: 1462082000n, proof_size: 19578n }\n✓ Local execution fees (Asset Hub): 97890000 PAS units\n\n2. Calculating delivery and remote execution fees...\n✓ Local dry run on Asset Hub successful\n✓ Found XCM message to Bridge Hub\n✓ Delivery fees: 305150000 PAS units\n\n3. Calculating remote execution fees on Bridge Hub\n✓ Remote execution fees: 17965000 PAS units\n\n=== Fee Summary (Asset Hub → Bridge Hub) ===\nLocal execution fees: 97890000 PAS units\nDelivery fees: 305150000 PAS units\nRemote execution fees: 17965000 PAS units\nTOTAL FEES: 421005000 PAS units\nTOTAL FEES: 0.0421 PAS\n\n=== Transaction Details ===\nTransaction hex: 0x1f03050c00040100000700e40b54023001000002286bee31010100a90f0100000401000002286bee000400010204040d010204000101008eaf04151687736326c9fea17e25fc5287613693c912909cb226aa4794f26a480700bca0650102000400\nReady to submit!\n\n</pre\n  >\n</div>"}
{"page_id": "tutorials-interoperability-xcm-fee-estimation", "index": 9, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 44756, "end_char": 45366, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThis approach provides accurate fee estimation for XCM teleports from Asset Hub to Bridge Hub Chain by properly simulating execution on both chains and utilizing dedicated runtime APIs for fee calculation. The fee breakdown helps you understand the cost structure of reverse cross-chain operations (parachain → bridge hub chain) and ensures your transactions have sufficient funds to complete successfully.\n\nThe key insight is understanding how asset references change based on the perspective of each chain in the XCM ecosystem, which is crucial for proper fee estimation and XCM construction."}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 33, "end_char": 1004, "estimated_token_count": 227, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Cross-Consensus Messaging (XCM)](/develop/interoperability/intro-to-xcm/){target=\\_blank} facilitates asset transfers both within the same consensus system and between different ones, such as between a relay chain and its parachains. For cross-system transfers, two main methods are available:\n\n- **[Asset teleportation](https://paritytech.github.io/xcm-docs/journey/transfers/teleports.html){target=\\_blank}**: A simple and efficient method involving only the source and destination chains, ideal for systems with a high level of trust.\n- **[Reserve-backed transfers](https://paritytech.github.io/xcm-docs/journey/transfers/reserve.html){target=\\_blank}**: Involves a trusted reserve holding real assets and mints derivative tokens to track ownership. This method is suited for systems with lower trust levels.\n\nIn this tutorial, you will learn how to perform a reserve-backed transfer of DOT between a relay chain (Polkadot) and a parachain (Astar)."}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1004, "end_char": 1600, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nWhen adapting this tutorial for other chains, before you can send messages between different consensus systems, you must first open HRMP channels. For detailed guidance, refer to the [XCM Channels](/develop/interoperability/xcm-channels/#xcm-channels){target=\\_blank} article before for further information about.\n\nThis tutorial uses Chopsticks to fork a relay chain and a parachain connected via HRMP channels. For more details on this setup, see the [XCM Testing](/tutorials/polkadot-sdk/testing/fork-live-chains/#xcm-testing){target=\\_blank} section on the Chopsticks page."}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 2, "depth": 2, "title": "Setup", "anchor": "setup", "start_char": 1600, "end_char": 2447, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "## Setup\n\nTo simulate XCM operations between different consensus systems, start by forking the network with the following command:\n\n```bash\nchopsticks xcm -r polkadot -p astar\n```\nAfter executing this command, the relay chain and parachain will expose the following WebSocket endpoints:\n\n| Chain                  | WebSocket Endpoint                   |\n|------------------------|--------------------------------------|\n| Polkadot (relay chain) | <pre>```ws://localhost:8001```</pre> |\n| Astar (parachain)      | <pre>```ws://localhost:8000```</pre> |\n\nYou can perform the reserve-backed transfer using either the [Polkadot.js Apps interface](#using-polkadotjs-apps) or the [Polkadot API](#using-papi), depending on your preference. Both methods provide the same functionality to facilitate asset transfers between the relay chain and parachain."}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 3, "depth": 2, "title": "Use Polkadot.js Apps", "anchor": "use-polkadotjs-apps", "start_char": 2447, "end_char": 3470, "estimated_token_count": 224, "token_estimator": "heuristic-v1", "text": "## Use Polkadot.js Apps\n\nUse the [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} interface to connect to each chain. Open two browser tabs—one for each chain—and follow these steps:\n\na. Add the custom endpoint for each chain, as defined above.\n\nb. Click **Switch** to connect to the respective network.\n\n![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-01.webp)\n\nThis reserve-backed transfer method facilitates asset transfers from a local chain to a destination chain by trusting a third party called a reserve to store the real assets. Fees on the destination chain are deducted from the asset specified in the assets vector at the `fee_asset_item` index, covering up to the specified `weight_limit.` The operation fails if the required weight exceeds this limit, potentially putting the transferred assets at risk.\n\nThe following steps outline how to execute a reserve-backed transfer from the Polkadot relay chain to the Astar parachain."}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 4, "depth": 3, "title": "From the Relay Chain Perspective", "anchor": "from-the-relay-chain-perspective", "start_char": 3470, "end_char": 5777, "estimated_token_count": 557, "token_estimator": "heuristic-v1", "text": "### From the Relay Chain Perspective\n\n1. Navigate to the Extrinsics page:\n\n    1. Click on the **Developer** tab from the top navigation bar.\n    2. Select **Extrinsics** from the dropdown.\n\n    ![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-02.webp)\n\n2. Select **xcmPallet**.\n\n    ![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-03.webp)\n\n3. Select the **limitedReservedAssetTransfer** extrinsic from the dropdown list.\n\n    ![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-04.webp)\n\n4. Fill out the required fields:\n\n    1. **dest**: Specifies the destination context for the assets. Commonly set to `[Parent, Parachain(..)]` for parachain-to-parachain transfers or `[Parachain(..)]` for relay chain-to-parachain transfers. In this case, since the transfer is from a relay chain to a parachain, the destination ([`Location`](https://paritytech.github.io/xcm-docs/fundamentals/multilocation/index.html){target=\\_blank}) is the following:\n\n        ```bash\n        { parents: 0, interior: { X1: [{ Parachain: 2006 }] } }\n        ```\n\n    2. **beneficiary**: Defines the recipient of the assets within the destination context, typically represented as an `AccountId32` value. This example uses the following account present in the destination chain:\n\n        ```bash\n        X2mE9hCGX771c3zzV6tPa8U2cDz4U4zkqUdmBrQn83M3cm7\n        ```\n\n    3. **assets**: Lists the assets to be withdrawn, including those designated for fee payment on the destination chain.\n    4. **feeAssetItem**: Indicates the index of the asset within the assets list to be used for paying fees.\n    5. **weightLimit**: Specifies the weight limit, if applicable, for the fee payment on the remote chain.\n    6. Click on the **Submit Transaction** button to send the transaction.\n\n        ![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-05.webp)\n\nAfter submitting the transaction, verify that the `xcmPallet.FeesPaid` and `xcmPallet.Sent` events have been emitted:\n\n![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-06.webp)"}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 5, "depth": 3, "title": "From the Parachain Perspective", "anchor": "from-the-parachain-perspective", "start_char": 5777, "end_char": 6162, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "### From the Parachain Perspective\n\nAfter submitting the transaction from the relay chain, confirm its success by checking the parachain's events. Look for the `assets.Issued` event, which verifies that the assets have been issued to the destination as expected:\n\n![](/images/tutorials/interoperability/xcm-transfers/from-relaychain-to-parachain/from-relaychain-to-parachain-07.webp)"}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 6, "depth": 2, "title": "Use PAPI", "anchor": "use-papi", "start_char": 6162, "end_char": 12106, "estimated_token_count": 1273, "token_estimator": "heuristic-v1", "text": "## Use PAPI\n\nTo programmatically execute the reserve-backed asset transfer between the relay chain and the parachain, you can use [Polkadot API (PAPI)](/develop/toolkit/api-libraries/papi/){target=\\_blank}. PAPI is a robust toolkit that simplifies interactions with Polkadot-based chains. For this project, you'll first need to set up your environment, install necessary dependencies, and create a script to handle the transfer process.\n\n1. Start by creating a folder for your project:\n\n   ```bash\n   mkdir reserve-backed-asset-transfer\n   cd reserve-backed-asset\n   ```\n\n2. Initialize a Node.js project and install the required dependencies. Execute the following commands:\n\n    ```bash\n    npm init\n    npm install polkadot-api @polkadot-labs/hdkd @polkadot-labs/hdkd-helpers\n    ```\n\n3. To enable static, type-safe APIs for interacting with the Polkadot and Astar chains, add their metadata to your project using PAPI:\n\n    ```bash\n    npx papi add dot -n polkadot\n    npx papi add astar -w wss://rpc.astar.network\n    ```\n\n    !!! note \n        - `dot` and `astar` are arbitrary names you assign to the chains, allowing you to access their metadata information.\n        - The first command uses the well-known Polkadot chain, while the second connects to the Astar chain using its WebSocket endpoint.\n\n4. Create a `index.js` file and insert the following code to configure the clients and handle the asset transfer:\n\n    ```js\n    -// Import necessary modules from Polkadot API and helpers\nimport {\n  astar, // Astar chain metadata\n  dot, // Polkadot chain metadata\n  XcmVersionedLocation,\n  XcmVersionedAssets,\n  XcmV3Junction,\n  XcmV3Junctions,\n  XcmV3WeightLimit,\n  XcmV3MultiassetFungibility,\n  XcmV3MultiassetAssetId,\n} from '@polkadot-api/descriptors';\nimport { createClient } from 'polkadot-api';\nimport { sr25519CreateDerive } from '@polkadot-labs/hdkd';\nimport {\n  DEV_PHRASE,\n  entropyToMiniSecret,\n  mnemonicToEntropy,\n  ss58Decode,\n} from '@polkadot-labs/hdkd-helpers';\nimport { getPolkadotSigner } from 'polkadot-api/signer';\nimport { getWsProvider } from 'polkadot-api/ws-provider/web';\nimport { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\nimport { Binary } from 'polkadot-api';\n\n// Create Polkadot client using WebSocket provider for Polkadot chain\nconst polkadotClient = createClient(\n  withPolkadotSdkCompat(getWsProvider('ws://127.0.0.1:8001'))\n);\nconst dotApi = polkadotClient.getTypedApi(dot);\n\n// Create Astar client using WebSocket provider for Astar chain\nconst astarClient = createClient(\n  withPolkadotSdkCompat(getWsProvider('ws://localhost:8000'))\n);\nconst astarApi = astarClient.getTypedApi(astar);\n\n// Create keypair for Alice using dev phrase to sign transactions\nconst miniSecret = entropyToMiniSecret(mnemonicToEntropy(DEV_PHRASE));\nconst derive = sr25519CreateDerive(miniSecret);\nconst aliceKeyPair = derive('//Alice');\nconst alice = getPolkadotSigner(\n  aliceKeyPair.publicKey,\n  'Sr25519',\n  aliceKeyPair.sign\n);\n\n// Define recipient (Dave) address on Astar chain\nconst daveAddress = 'X2mE9hCGX771c3zzV6tPa8U2cDz4U4zkqUdmBrQn83M3cm7';\nconst davePublicKey = ss58Decode(daveAddress)[0];\nconst idBenef = Binary.fromBytes(davePublicKey);\n\n// Define Polkadot Asset ID on Astar chain (example)\nconst polkadotAssetId = 340282366920938463463374607431768211455n;\n\n// Fetch asset balance of recipient (Dave) before transaction\nlet assetMetadata = await astarApi.query.Assets.Account.getValue(\n  polkadotAssetId,\n  daveAddress\n);\nconsole.log('Asset balance before tx:', assetMetadata?.balance ?? 0);\n\n// Prepare and submit transaction to transfer assets from Polkadot to Astar\nconst tx = dotApi.tx.XcmPallet.limited_reserve_transfer_assets({\n  dest: XcmVersionedLocation.V3({\n    parents: 0,\n    interior: XcmV3Junctions.X1(\n      XcmV3Junction.Parachain(2006) // Destination is the Astar parachain\n    ),\n  }),\n  beneficiary: XcmVersionedLocation.V3({\n    parents: 0,\n    interior: XcmV3Junctions.X1(\n      XcmV3Junction.AccountId32({\n        // Beneficiary address on Astar\n        network: undefined,\n        id: idBenef,\n      })\n    ),\n  }),\n  assets: XcmVersionedAssets.V3([\n    {\n      id: XcmV3MultiassetAssetId.Concrete({\n        parents: 0,\n        interior: XcmV3Junctions.Here(), // Asset from the sender's location\n      }),\n      fun: XcmV3MultiassetFungibility.Fungible(120000000000), // Asset amount to transfer\n    },\n  ]),\n  fee_asset_item: 0, // Asset used to pay transaction fees\n  weight_limit: XcmV3WeightLimit.Unlimited(), // No weight limit on transaction\n});\n\n// Sign and submit the transaction\ntx.signSubmitAndWatch(alice).subscribe({\n  next: async (event) => {\n    if (event.type === 'finalized') {\n      console.log('Transaction completed successfully');\n    }\n  },\n  error: console.error,\n  complete() {\n    polkadotClient.destroy(); // Clean up after transaction\n  },\n});\n\n// Wait for transaction to complete\nawait new Promise((resolve) => setTimeout(resolve, 20000));\n\n// Fetch asset balance of recipient (Dave) after transaction\nassetMetadata = await astarApi.query.Assets.Account.getValue(\n  polkadotAssetId,\n  daveAddress\n);\nconsole.log('Asset balance after tx:', assetMetadata?.balance ?? 0);\n\n// Exit the process\nprocess.exit(0);\n\n    ```\n\n    !!! note\n        To use this script with real-world blockchains, you'll need to update the WebSocket endpoint to the appropriate one, replace the Alice account with a valid account, and ensure the account has sufficient funds to cover transaction fees.\n\n4. Execute the script:\n\n    ```bash \n    node index.js\n    ```\n\n5. Check the terminal output. If the operation is successful, you should see the following message:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>node index.js</span>\n  <span data-ty> Asset balance before tx: 0</span>\n  <span data-ty> Transaction completed successfully</span>\n  <span data-ty> Asset balance after tx: 119999114907n</span>\n</div>"}
{"page_id": "tutorials-interoperability-xcm-transfers-from-relaychain-to-parachain", "index": 7, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 12106, "end_char": 12372, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nYou can perform these operations using the Asset Transfer API for an alternative approach. Refer to the [Asset Transfer API](/develop/toolkit/interoperability/asset-transfer-api/){target=\\_blank} guide in the documentation for more details."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 36, "end_char": 1714, "estimated_token_count": 314, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's [OpenGov](/polkadot-protocol/onchain-governance/overview){target=\\_blank} is a sophisticated governance mechanism designed to allow the network to evolve gracefully over time, guided by its stakeholders. This system features multiple [tracks](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#origins-and-tracks-info){target=\\_blank} for different types of proposals, each with parameters for approval, support, and confirmation period. While this flexibility is powerful, it also introduces complexity that can lead to failed proposals or unexpected outcomes.\n\nTesting governance proposals before submission is crucial for the ecosystem. This process enhances efficiency by reducing the need for repeated submissions, improves security by identifying potential risks, and allows proposal optimization based on simulated outcomes. It also serves as an educational tool, providing stakeholders with a safe environment to understand the impacts of different voting scenarios. \n\nBy leveraging simulation tools like [Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks){target=\\_blank}, developers can:\n\n- Simulate the entire lifecycle of a proposal.\n- Test the voting outcomes by varying the support and approval levels.\n- Analyze the effects of a successfully executed proposal on the network's state.\n- Identify and troubleshoot potential issues or unexpected consequences before submitting the proposals.\n\nThis tutorial will guide you through using Chopsticks to test OpenGov proposals thoroughly. This ensures that when you submit a proposal to the live network, you can do so with confidence in its effects and viability."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1714, "end_char": 2238, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore proceeding, ensure the following prerequisites are met:\n\n- **Chopsticks installation**: If you have not installed Chopsticks yet, refer to the [Install Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks/get-started/#install-chopsticks){target=\\_blank} guide for detailed instructions.\n- **Familiarity with key concepts**:\n    - [Polkadot.js](/develop/toolkit/api-libraries/polkadot-js-api){target=\\_blank}\n    - [OpenGov](/polkadot-protocol/onchain-governance/overview){target=\\_blank}"}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 2, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 2238, "end_char": 3723, "estimated_token_count": 328, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nBefore testing OpenGov proposals, you need to set up your development environment. \nYou'll set up a TypeScript project and install the required dependencies to simulate and evaluate proposals. You'll use Chopsticks to fork the Polkadot network and simulate the proposal lifecycle, while Polkadot.js will be your interface for interacting with the forked network and submitting proposals.\n\nFollow these steps to set up your project:\n\n1. Create a new project directory and navigate into it:\n    ```bash\n    mkdir opengov-chopsticks && cd opengov-chopsticks\n    ```\n\n2. Initialize a new TypeScript project:\n    ```bash\n    npm init -y \\\n    && npm install typescript ts-node @types/node --save-dev \\\n    && npx tsc --init\n    ```\n\n3. Install the required dependencies:\n    ```bash\n    npm install @polkadot/api @acala-network/chopsticks\n    ```\n\n4. Create a new TypeScript file for your script:\n    ```bash\n    touch test-proposal.ts\n    ```\n\n    !!!note\n        You'll write your code to simulate and test OpenGov proposals in the `test-proposal.ts` file.\n\n5. Open the `tsconfig.json` file and ensure it includes these compiler options:\n    ```json\n    -{\n    \"compilerOptions\": {\n        \"module\": \"CommonJS\",\n        \"esModuleInterop\": true,\n        \"target\": \"esnext\",\n        \"moduleResolution\": \"node\",\n        \"declaration\": true,\n        \"sourceMap\": true,\n        \"skipLibCheck\": true,\n        \"outDir\": \"dist\",\n        \"composite\": true\n    }\n}\n\n    ```"}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 3, "depth": 2, "title": "Submit and Execute a Proposal Using Chopsticks", "anchor": "submit-and-execute-a-proposal-using-chopsticks", "start_char": 3723, "end_char": 4422, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Submit and Execute a Proposal Using Chopsticks\n\nYou should identify the right track and origin for your proposal. For example, select the appropriate treasury track based on the spending limits if you're requesting funds from the treasury. For more detailed information, refer to [Polkadot OpenGov Origins](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/){target=\\_blank}.\n\n!!!note\n    This tutorial will focus on the main steps and core logic within the main function. For clarity and conciseness, the implementation details of individual functions will be available in expandable tabs below each section. You'll find the complete code for reference at the end of the tutorial."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 4, "depth": 3, "title": "Spin Up the Polkadot Fork", "anchor": "spin-up-the-polkadot-fork", "start_char": 4422, "end_char": 4882, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "### Spin Up the Polkadot Fork\n\nTo set up your Polkadot fork using Chopsticks, open a new terminal window and run the following command:\n\n```bash\nnpx @acala-network/chopsticks --config=polkadot\n```\n\nThis command will start a local fork of the Polkadot network accessible at `ws://localhost:8000`. Keep this terminal window open and running throughout your testing process.\n\nOnce your forked network is up and running, you can proceed with the following steps."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 5, "depth": 3, "title": "Set Up Dependencies and Structure", "anchor": "set-up-dependencies-and-structure", "start_char": 4882, "end_char": 25140, "estimated_token_count": 4534, "token_estimator": "heuristic-v1", "text": "### Set Up Dependencies and Structure\n\nBegin by adding the necessary imports and a basic structure to the `test-proposal.ts` file:\n\n```typescript\n-// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\nconst main = async () => {\n  // The code will be added here\n\n  process.exit(0);\n}\n\n-// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n```\n\nThis structure provides the foundation for your script. It imports all the necessary dependencies and sets up a main function that will contain the core logic of your proposal submission process."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 6, "depth": 3, "title": "Connect to the Forked Chain", "anchor": "connect-to-the-forked-chain", "start_char": 25140, "end_char": 35470, "estimated_token_count": 2323, "token_estimator": "heuristic-v1", "text": "### Connect to the Forked Chain\n\nCreate a `connectToFork` function outside the `main` function to connect your locally forked chain to the Polkadot.js API:\n\n```typescript\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n```\n\nInside the `main` function, add the code to establish a connection to your local Polkadot fork:\n\n```typescript hl_lines=\"2-3\"\n-const main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n  ...\n}\n```"}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 7, "depth": 3, "title": "Create and Submit the Proposal", "anchor": "create-and-submit-the-proposal", "start_char": 35470, "end_char": 49477, "estimated_token_count": 3097, "token_estimator": "heuristic-v1", "text": "### Create and Submit the Proposal\n\nCreate a `generateProposal` function that will be responsible for preparing and submitting the on-chain proposal:\n\n```typescript\n-async function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n    ...\n}\n```\n\nNow, you need to implement the following logic:\n\n1. Set up the keyring and use the Alice development account:\n\n    ```typescript\n    -  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n    ```\n \n    !!!note\n        When using Chopsticks, this development account is pre-funded to execute all necessary actions.\n\n2. Retrieve the proposal index:\n\n    ```typescript\n    -  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n    ```\n\n3. Execute a batch transaction that comprises the following three operations:\n\n    1. **`preimage.notePreimage`**: Registers a [preimage](/polkadot-protocol/glossary#preimage){target=\\_blank} using the selected call.\n\n        !!!note\n            The preimage hash is simply the hash of the proposal to be enacted. The on-chain proposals do not require the entire image of extrinsics and data (for instance, the Wasm code, in case of upgrades) to be submitted but would need that image's hash. That preimage can be submitted and stored on-chain against the hash later upon the proposal's dispatch.\n\n    2. **`referenda.submit`**: Submits the proposal to the referenda system. It uses the preimage hash extracted from the call as part of the proposal submission process. The proposal is submitted with the selected origin.\n\n    3. **`referenda.placeDecisionDeposit`**: Places the required decision deposit for the referendum. This deposit is required to move the referendum from the preparing phase to the deciding phase.\n\n    ```typescript\n    -  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n    ```\n\n4. Return the proposal index:\n\n    ```typescript\n    -  return proposalIndex;\n    ```\n\nIf you followed all the steps correctly, the function should look like this:\n\n??? code \"`generateProposal` code\"\n    ```typescript\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n    ```\n\nThen, within the `main` function, define the specific call you want to execute and its corresponding origin, then invoke the `generateProposal` method:\n\n```typescript hl_lines=\"5-14\"\n-const main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n  ...\n}\n```\n\n!!!note\n    The [`setCodeWithoutChecks`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.set_code_without_checks){target=\\_blank} extrinsic used in this example is for demonstration purposes only. Replace it with the specific extrinsic that matches your governance proposal's intended functionality. Ensure the call matches your target Polkadot SDK-based network's runtime requirements and governance process."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 8, "depth": 3, "title": "Force Proposal Execution", "anchor": "force-proposal-execution", "start_char": 49477, "end_char": 84152, "estimated_token_count": 7665, "token_estimator": "heuristic-v1", "text": "### Force Proposal Execution\n\nAfter submitting your proposal, you can test its execution by directly manipulating the chain state and scheduler using Chopsticks, bypassing the standard voting and enactment periods.\n\nCreate a new function called `forceProposalExecution`:\n\n```typescript\n-async function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  ...\n}\n```\n\nThis function will accomplish two primary objectives:\n\n- Modify the chain storage to set the proposal's approvals and support artificially, ensuring its passage.\n- Override the scheduler to execute the proposal immediately in the subsequent blocks, circumventing standard waiting periods.\n\nImplement the functionality through the following steps:\n\n1. Get the referendum information and its hash:\n    ```typescript\n    -  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n    ```\n\n2. Determine the total amount of existing native tokens:\n    ```typescript\n    -  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n    ```\n\n3. Fetch the current block number:\n    ```typescript\n    -  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n    ```\n\n4. Modify the proposal data and overwrite the storage:\n    ```typescript\n    -  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n    ```\n\n5. Manipulate the scheduler to execute the proposal in the next blocks:\n    ```typescript\n    -  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n    ```\n\n    ???+ child \"Utility Function\"\n        This section utilizes a `moveScheduledCallTo` utility function to move a scheduled call matching specific criteria to a designated future block. Include this function in the same file:\n\n        ??? code \"`moveScheduledCallTo`\"\n            ```typescript\n            -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n            ```\n\nAfter implementing the complete logic, your function will resemble:\n\n??? code \"`forceProposalExecution`\"\n    ```typescript\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n    ```\n\nInvoke `forceProposalExecution` from the `main` function using the `proposalIndex` obtained from the previous `generateProposal` call:\n\n```typescript hl_lines=\"16-17\"\n-// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n```"}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 9, "depth": 2, "title": "Execute the Proposal Script", "anchor": "execute-the-proposal-script", "start_char": 84152, "end_char": 85081, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "## Execute the Proposal Script\n\nTo run the proposal execution script, use the following command in your terminal:\n\n```bash\nnpx ts-node test-proposal.ts\n```\n\nWhen executing the script, you should expect the following key actions and outputs:\n\n- **Chain forking**: The script connects to a forked version of the Polkadot network, allowing safe manipulation of the chain state without affecting the live network.\n\n- **Proposal generation**: A new governance proposal is created using the specified extrinsic (in this example, `setCodeWithoutChecks`).\n\n- **State manipulation**: The referendum's storage is modified to simulate immediate approval by adjusting tally and support values to force proposal passing. Scheduled calls are then redirected to ensure immediate execution.\n\n- **Execution**: The script advances the chain to trigger the scheduled call execution. The specified call (e.g., `setCodeWithoutChecks`) is processed."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 10, "depth": 2, "title": "Summary", "anchor": "summary", "start_char": 85081, "end_char": 85741, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## Summary\n\nIn this tutorial, you've learned how to use Chopsticks to test OpenGov proposals on a local fork of the Polkadot network. You've set up a TypeScript project, connected to a local fork, submitted a proposal, and forced its execution for testing purposes. This process allows you to:\n\n- Safely experiment with different types of proposals.\n- Test the effects of proposals without affecting the live network.\n- Rapidly iterate and debug your governance ideas.\n\nUsing these techniques, you can develop and refine your proposals before submitting them to the Polkadot network, ensuring they're well-tested and likely to achieve their intended effects."}
{"page_id": "tutorials-onchain-governance-fast-track-gov-proposal", "index": 11, "depth": 2, "title": "Full Code", "anchor": "full-code", "start_char": 85741, "end_char": 155338, "estimated_token_count": 15590, "token_estimator": "heuristic-v1", "text": "## Full Code\n\nHere's the complete code for the `test-proposal.ts` file, incorporating all the steps we've covered:\n\n??? code \"`test-proposal.ts`\"\n    ```typescript\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n\n    -// --8<-- [start:imports]\nimport '@polkadot/api-augment/polkadot';\nimport { FrameSupportPreimagesBounded } from '@polkadot/types/lookup';\nimport { blake2AsHex } from '@polkadot/util-crypto';\nimport { ApiPromise, Keyring, WsProvider } from '@polkadot/api';\nimport { type SubmittableExtrinsic } from '@polkadot/api/types';\nimport { ISubmittableResult } from '@polkadot/types/types';\n// --8<-- [end:imports]\n\n// --8<-- [start:connectToFork]\n/**\n * Establishes a connection to the local forked chain.\n *\n * @returns A promise that resolves to an `ApiPromise` instance connected to the local chain.\n */\nasync function connectToFork(): Promise<ApiPromise> {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n  return api;\n}\n// --8<-- [end:connectToFork]\n\n// --8<-- [start:generateProposal]\n/**\n * Generates a proposal by submitting a preimage, creating the proposal, and placing a deposit.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param call - The extrinsic to be executed, encapsulating the specific action to be proposed.\n * @param origin - The origin of the proposal, specifying the source authority (e.g., `{ System: 'Root' }`).\n * @returns A promise that resolves to the proposal ID of the generated proposal.\n *\n */\nasync function generateProposal(\n  api: ApiPromise,\n  call: SubmittableExtrinsic<'promise', ISubmittableResult>,\n  origin: any\n): Promise<number> {\n  // Initialize the keyring\n  const keyring = new Keyring({ type: 'sr25519' });\n\n  // Set up Alice development account\n  const alice = keyring.addFromUri('//Alice');\n\n  // Get the next available proposal index\n  const proposalIndex = (\n    await api.query.referenda.referendumCount()\n  ).toNumber();\n\n  // Execute the batch transaction\n  await new Promise<void>(async (resolve) => {\n    const unsub = await api.tx.utility\n      .batch([\n        // Register the preimage for your proposal\n        api.tx.preimage.notePreimage(call.method.toHex()),\n        // Submit your proposal to the referenda system\n        api.tx.referenda.submit(\n          origin as any,\n          {\n            Lookup: {\n              Hash: call.method.hash.toHex(),\n              len: call.method.encodedLength,\n            },\n          },\n          { At: 0 }\n        ),\n        // Place the required decision deposit\n        api.tx.referenda.placeDecisionDeposit(proposalIndex),\n      ])\n      .signAndSend(alice, (status: any) => {\n        if (status.blockNumber) {\n          unsub();\n          resolve();\n        }\n      });\n  });\n  return proposalIndex;\n}\n// --8<-- [end:generateProposal]\n\n// --8<-- [start:moveScheduledCallTo]\n/**\n * Moves a scheduled call to a specified future block if it matches the given verifier criteria.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param blockCounts - The number of blocks to move the scheduled call forward.\n * @param verifier - A function to verify if a scheduled call matches the desired criteria.\n * @throws An error if no matching scheduled call is found.\n */\nasync function moveScheduledCallTo(\n  api: ApiPromise,\n  blockCounts: number,\n  verifier: (call: FrameSupportPreimagesBounded) => boolean\n) {\n  // Get the current block number\n  const blockNumber = (await api.rpc.chain.getHeader()).number.toNumber();\n  \n  // Retrieve the scheduler's agenda entries\n  const agenda = await api.query.scheduler.agenda.entries();\n  \n  // Initialize a flag to track if a matching scheduled call is found\n  let found = false;\n  \n  // Iterate through the scheduler's agenda entries\n  for (const agendaEntry of agenda) {\n    // Iterate through the scheduled entries in the current agenda entry\n    for (const scheduledEntry of agendaEntry[1]) {\n      // Check if the scheduled entry is valid and matches the verifier criteria\n      if (scheduledEntry.isSome && verifier(scheduledEntry.unwrap().call)) {\n        found = true;\n        \n        // Overwrite the agendaEntry item in storage\n        const result = await api.rpc('dev_setStorage', [\n          [agendaEntry[0]], // require to ensure unique id\n          [\n            await api.query.scheduler.agenda.key(blockNumber + blockCounts),\n            agendaEntry[1].toHex(),\n          ],\n        ]);\n        \n        // Check if the scheduled call has an associated lookup\n        if (scheduledEntry.unwrap().maybeId.isSome) {\n          // Get the lookup ID\n          const id = scheduledEntry.unwrap().maybeId.unwrap().toHex();\n          const lookup = await api.query.scheduler.lookup(id);\n\n          // Check if the lookup exists\n          if (lookup.isSome) {\n            // Get the lookup key\n            const lookupKey = await api.query.scheduler.lookup.key(id);\n            \n            // Create a new lookup object with the updated block number\n            const fastLookup = api.registry.createType('Option<(u32,u32)>', [\n              blockNumber + blockCounts,\n              0,\n            ]);\n            \n            // Overwrite the lookup entry in storage\n            const result = await api.rpc('dev_setStorage', [\n              [lookupKey, fastLookup.toHex()],\n            ]);\n          }\n        }\n      }\n    }\n  }\n  \n  // Throw an error if no matching scheduled call is found\n  if (!found) {\n    throw new Error('No scheduled call found');\n  }\n}\n// --8<-- [end:moveScheduledCallTo]\n\n// --8<-- [start:forceProposalExecution]\n/**\n * Forces the execution of a specific proposal by updating its referendum state and ensuring the execution process is triggered.\n *\n * @param api - An instance of the Polkadot.js API promise used to interact with the blockchain.\n * @param proposalIndex - The index of the proposal to be executed.\n * @throws An error if the referendum is not found or not in an ongoing state.\n */\nasync function forceProposalExecution(api: ApiPromise, proposalIndex: number) {\n  // Retrieve the referendum data for the given proposal index\n  const referendumData = await api.query.referenda.referendumInfoFor(\n    proposalIndex\n  );\n  // Get the storage key for the referendum data\n  const referendumKey =\n    api.query.referenda.referendumInfoFor.key(proposalIndex);\n\n  // Check if the referendum data exists\n  if (!referendumData.isSome) {\n    throw new Error(`Referendum ${proposalIndex} not found`);\n  }\n\n  const referendumInfo = referendumData.unwrap();\n\n  // Check if the referendum is in an ongoing state\n  if (!referendumInfo.isOngoing) {\n    throw new Error(`Referendum ${proposalIndex} is not ongoing`);\n  }\n\n  // Get the ongoing referendum data\n  const ongoingData = referendumInfo.asOngoing;\n  // Convert the ongoing data to JSON\n  const ongoingJson = ongoingData.toJSON();\n\n  // Support Lookup, Inline or Legacy proposals\n  const callHash = ongoingData.proposal.isLookup\n    ? ongoingData.proposal.asLookup.toHex()\n    : ongoingData.proposal.isInline\n    ? blake2AsHex(ongoingData.proposal.asInline.toHex())\n    : ongoingData.proposal.asLegacy.toHex();\n\n  // Get the total issuance of the native token\n  const totalIssuance = (await api.query.balances.totalIssuance()).toBigInt();\n\n  // Get the current block number\n  const proposalBlockTarget = (\n    await api.rpc.chain.getHeader()\n  ).number.toNumber();\n\n  // Create a new proposal data object with the updated fields\n  const fastProposalData = {\n    ongoing: {\n      ...ongoingJson,\n      enactment: { after: 0 },\n      deciding: {\n        since: proposalBlockTarget - 1,\n        confirming: proposalBlockTarget - 1,\n      },\n      tally: {\n        ayes: totalIssuance - 1n,\n        nays: 0,\n        support: totalIssuance - 1n,\n      },\n      alarm: [proposalBlockTarget + 1, [proposalBlockTarget + 1, 0]],\n    },\n  };\n\n  // Create a new proposal object from the proposal data\n  let fastProposal;\n  try {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfo>`,\n      fastProposalData\n    );\n  } catch {\n    fastProposal = api.registry.createType(\n      `Option<PalletReferendaReferendumInfoConvictionVotingTally>`,\n      fastProposalData\n    );\n  }\n\n  // Update the storage with the new proposal object\n  const result = await api.rpc('dev_setStorage', [\n    [referendumKey, fastProposal.toHex()],\n  ]);\n\n  // Fast forward the nudge referendum to the next block to get the refendum to be scheduled\n  await moveScheduledCallTo(api, 1, (call) => {\n    if (!call.isInline) {\n      return false;\n    }\n\n    const callData = api.createType('Call', call.asInline.toHex());\n\n    return (\n      callData.method == 'nudgeReferendum' &&\n      (callData.args[0] as any).toNumber() == proposalIndex\n    );\n  });\n\n  // Create a new block\n  await api.rpc('dev_newBlock', { count: 1 });\n\n  // Move the scheduled call to the next block\n  await moveScheduledCallTo(api, 1, (call) =>\n    call.isLookup\n      ? call.asLookup.toHex() == callHash\n      : call.isInline\n      ? blake2AsHex(call.asInline.toHex()) == callHash\n      : call.asLegacy.toHex() == callHash\n  );\n\n  // Create another new block\n  await api.rpc('dev_newBlock', { count: 1 });\n}\n// --8<-- [end:forceProposalExecution]\n\n// --8<-- [start:main]\nconst main = async () => {\n  // Connect to the forked chain\n  const api = await connectToFork();\n\n  // Select the call to perform\n  const call = api.tx.system.setCodeWithoutChecks('0x1234');\n\n  // Select the origin\n  const origin = {\n    System: 'Root',\n  };\n\n  // Submit preimage, submit proposal, and place decision deposit\n  const proposalIndex = await generateProposal(api, call, origin);\n\n  // Force the proposal to be executed\n  await forceProposalExecution(api, proposalIndex);\n\n  process.exit(0);\n};\n// --8<-- [end:main]\n\n// --8<-- [start:try-catch-block]\ntry {\n  main();\n} catch (e) {\n  console.log(e);\n  process.exit(1);\n}\n// --8<-- [end:try-catch-block]\n\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-add-pallets-to-runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 30, "end_char": 866, "estimated_token_count": 192, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn previous tutorials, you learned how to [create a custom pallet](/tutorials/polkadot-sdk/parachains/zero-to-hero/build-custom-pallet/){target=\\_blank} and [test it](/tutorials/polkadot-sdk/parachains/zero-to-hero/pallet-unit-testing/){target=\\_blank}. The next step is to include this pallet in your runtime, integrating it into the core logic of your blockchain.\n\nThis tutorial will guide you through adding two pallets to your runtime: the custom pallet you previously developed and the [utility pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_utility/index.html){target=\\_blank}. This standard Polkadot SDK pallet provides powerful dispatch functionality. The utility pallet offers, for example, batch dispatch, a stateless operation that enables executing multiple calls in a single transaction."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-add-pallets-to-runtime", "index": 1, "depth": 2, "title": "Add the Pallets as Dependencies", "anchor": "add-the-pallets-as-dependencies", "start_char": 866, "end_char": 7582, "estimated_token_count": 1866, "token_estimator": "heuristic-v1", "text": "## Add the Pallets as Dependencies\n\nFirst, you'll update the runtime's `Cargo.toml` file to include the Utility pallet and your custom pallets as dependencies for the runtime. Follow these steps:\n\n1. Open the `runtime/Cargo.toml` file and locate the `[dependencies]` section. Add pallet-utility as one of the features for the `polkadot-sdk` dependency with the following line:\n\n    ```toml hl_lines=\"4\" title=\"runtime/Cargo.toml\"\n    -[dependencies]\n    ...\n    -polkadot-sdk = { workspace = true, features = [\n  \"pallet-utility\",\n        ...\n    -], default-features = false }\n    ```\n\n2. In the same `[dependencies]` section, add the custom pallet that you built from scratch with the following line:\n\n    ```toml hl_lines=\"3\" title=\"Cargo.toml\"\n    -[dependencies]\n    ...\n    -custom-pallet = { path = \"../pallets/custom-pallet\", default-features = false }\n    ```\n\n3. In the `[features]` section, add the custom pallet to the `std` feature list:\n\n    ```toml hl_lines=\"5\" title=\"Cargo.toml\"\n    -[features]\ndefault = [\"std\"]\nstd = [\n      ...\n      -\"custom-pallet/std\",\n      ...\n    ]\n    ```\n\n3. Save the changes and close the `Cargo.toml` file.\n\n    Once you have saved your file, it should look like the following:\n\n    ???- code \"runtime/Cargo.toml\"\n        \n        ```rust title=\"runtime/Cargo.toml\"\n        -[package]\nname = \"parachain-template-runtime\"\ndescription = \"A parachain runtime template built with Substrate and Cumulus, part of Polkadot Sdk.\"\nversion = \"0.1.0\"\nlicense = \"Unlicense\"\nauthors.workspace = true\nhomepage.workspace = true\nrepository.workspace = true\nedition.workspace = true\npublish = false\n\n[package.metadata.docs.rs]\ntargets = [\"x86_64-unknown-linux-gnu\"]\n\n[build-dependencies]\ndocify = { workspace = true }\nsubstrate-wasm-builder = { optional = true, workspace = true, default-features = true }\n\n[dependencies]\ncodec = { features = [\"derive\"], workspace = true }\ncumulus-pallet-parachain-system.workspace = true\ndocify = { workspace = true }\nhex-literal = { optional = true, workspace = true, default-features = true }\nlog = { workspace = true }\npallet-parachain-template = { path = \"../pallets/template\", default-features = false }\npolkadot-sdk = { workspace = true, features = [\n  \"pallet-utility\",\n  \"cumulus-pallet-aura-ext\",\n  \"cumulus-pallet-session-benchmarking\",\n  \"cumulus-pallet-weight-reclaim\",\n  \"cumulus-pallet-xcm\",\n  \"cumulus-pallet-xcmp-queue\",\n  \"cumulus-primitives-aura\",\n  \"cumulus-primitives-core\",\n  \"cumulus-primitives-utility\",\n  \"pallet-aura\",\n  \"pallet-authorship\",\n  \"pallet-balances\",\n  \"pallet-collator-selection\",\n  \"pallet-message-queue\",\n  \"pallet-session\",\n  \"pallet-sudo\",\n  \"pallet-timestamp\",\n  \"pallet-transaction-payment\",\n  \"pallet-transaction-payment-rpc-runtime-api\",\n  \"pallet-xcm\",\n  \"parachains-common\",\n  \"polkadot-parachain-primitives\",\n  \"polkadot-runtime-common\",\n  \"runtime\",\n  \"staging-parachain-info\",\n  \"staging-xcm\",\n  \"staging-xcm-builder\",\n  \"staging-xcm-executor\",\n], default-features = false }\nscale-info = { features = [\"derive\"], workspace = true }\nserde_json = { workspace = true, default-features = false, features = [\n  \"alloc\",\n] }\nsmallvec = { workspace = true, default-features = true }\n\ncustom-pallet = { path = \"../pallets/custom-pallet\", default-features = false }\n\n[features]\ndefault = [\"std\"]\nstd = [\n  \"codec/std\",\n  \"cumulus-pallet-parachain-system/std\",\n  \"log/std\",\n  \"pallet-parachain-template/std\",\n  \"polkadot-sdk/std\",\n  \"scale-info/std\",\n  \"serde_json/std\",\n  \"substrate-wasm-builder\",\n  \"custom-pallet/std\",\n]\n\nruntime-benchmarks = [\n  \"cumulus-pallet-parachain-system/runtime-benchmarks\",\n  \"hex-literal\",\n  \"pallet-parachain-template/runtime-benchmarks\",\n  \"polkadot-sdk/runtime-benchmarks\",\n]\n\ntry-runtime = [\n  \"cumulus-pallet-parachain-system/try-runtime\",\n  \"pallet-parachain-template/try-runtime\",\n  \"polkadot-sdk/try-runtime\",\n]\n\n# Enable the metadata hash generation.\n#\n# This is hidden behind a feature because it increases the compile time.\n# The wasm binary needs to be compiled twice, once to fetch the metadata,\n# generate the metadata hash and then a second time with the\n# `RUNTIME_METADATA_HASH` environment variable set for the `CheckMetadataHash`\n# extension.\nmetadata-hash = [\"substrate-wasm-builder/metadata-hash\"]\n\n# A convenience feature for enabling things when doing a build\n# for an on-chain release.\non-chain-release-build = [\"metadata-hash\"]\n\n        ```\n\nUpdate your root parachain template's `Cargo.toml` file to include your custom pallet as a dependency. Follow these steps:\n\n1. Open the `./Cargo.toml` file and locate the `[workspace]` section. \n    \n    Make sure the `custom-pallet` is a member of the workspace:\n\n    ```toml hl_lines=\"4\" title=\"Cargo.toml\"\n     -[workspace]\ndefault-members = [\"pallets/template\", \"runtime\"]\nmembers = [\n    \"node\", \"pallets/custom-pallet\",\n    \"pallets/template\",\n    \"runtime\",\n]\n    ```\n\n???- code \"./Cargo.toml\"\n\n    ```rust title=\"./Cargo.toml\"\n    -[workspace.package]\nlicense = \"MIT-0\"\nauthors = [\"Parity Technologies <admin@parity.io>\"]\nhomepage = \"https://paritytech.github.io/polkadot-sdk/\"\nrepository = \"https://github.com/paritytech/polkadot-sdk-parachain-template.git\"\nedition = \"2021\"\n\n[workspace]\ndefault-members = [\"pallets/template\", \"runtime\"]\nmembers = [\n    \"node\", \"pallets/custom-pallet\",\n    \"pallets/template\",\n    \"runtime\",\n]\nresolver = \"2\"\n\n[workspace.dependencies]\nparachain-template-runtime = { path = \"./runtime\", default-features = false }\npallet-parachain-template = { path = \"./pallets/template\", default-features = false }\nclap = { version = \"4.5.13\" }\ncolor-print = { version = \"0.3.4\" }\ndocify = { version = \"0.2.9\" }\nfutures = { version = \"0.3.31\" }\njsonrpsee = { version = \"0.24.3\" }\nlog = { version = \"0.4.22\", default-features = false }\npolkadot-sdk = { version = \"2503.0.1\", default-features = false }\nprometheus-endpoint = { version = \"0.17.2\", default-features = false, package = \"substrate-prometheus-endpoint\" }\nserde = { version = \"1.0.214\", default-features = false }\ncodec = { version = \"3.7.4\", default-features = false, package = \"parity-scale-codec\" }\ncumulus-pallet-parachain-system = { version = \"0.20.0\", default-features = false }\nhex-literal = { version = \"0.4.1\", default-features = false }\nscale-info = { version = \"2.11.6\", default-features = false }\nserde_json = { version = \"1.0.132\", default-features = false }\nsmallvec = { version = \"1.11.0\", default-features = false }\nsubstrate-wasm-builder = { version = \"26.0.1\", default-features = false }\nframe = { version = \"0.9.1\", default-features = false, package = \"polkadot-sdk-frame\" }\n\n[profile.release]\nopt-level = 3\npanic = \"unwind\"\n\n[profile.production]\ncodegen-units = 1\ninherits = \"release\"\nlto = true\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-add-pallets-to-runtime", "index": 2, "depth": 3, "title": "Update the Runtime Configuration", "anchor": "update-the-runtime-configuration", "start_char": 7582, "end_char": 9386, "estimated_token_count": 412, "token_estimator": "heuristic-v1", "text": "### Update the Runtime Configuration\n\nConfigure the pallets by implementing their `Config` trait and update the runtime macro to include the new pallets:\n\n1. Add the `OriginCaller` import:\n\n    ```rust title=\"mod.rs\" hl_lines=\"8\"\n    -// Local module imports\nuse super::OriginCaller;\n    ...\n    ```\n\n2. Implement the [`Config`](https://paritytech.github.io/polkadot-sdk/master/pallet_utility/pallet/trait.Config.html){target=\\_blank} trait for both pallets at the end of the `runtime/src/config/mod.rs` file:\n\n    ```rust title=\"mod.rs\" hl_lines=\"8-25\"\n    ...\n    -/// Configure the pallet template in pallets/template.\nimpl pallet_parachain_template::Config for Runtime {\n    type RuntimeEvent = RuntimeEvent;\n    type WeightInfo = pallet_parachain_template::weights::SubstrateWeight<Runtime>;\n}\n\n// Configure utility pallet.\nimpl pallet_utility::Config for Runtime {\n    type RuntimeEvent = RuntimeEvent;\n    type RuntimeCall = RuntimeCall;\n    type PalletsOrigin = OriginCaller;\n    type WeightInfo = pallet_utility::weights::SubstrateWeight<Runtime>;\n}\n    -// Define counter max value runtime constant.\nparameter_types! {\n    pub const CounterMaxValue: u32 = 500;\n}\n\n// Configure custom pallet.\nimpl custom_pallet::Config for Runtime {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = CounterMaxValue;\n    }\n    ```\n\n3. Locate the `#[frame_support::runtime]` macro in the `runtime/src/lib.rs` file and add the pallets:\n\n    ```rust hl_lines=\"9-14\" title=\"lib.rs\"\n    -#[frame_support::runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n            ...\n        -    )]\n    pub struct Runtime;\n\n    -    #[runtime::pallet_index(51)]\n    pub type Utility = pallet_utility;\n\n    #[runtime::pallet_index(52)]\n    pub type CustomPallet = custom_pallet;\n    }\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-add-pallets-to-runtime", "index": 3, "depth": 2, "title": "Recompile the Runtime", "anchor": "recompile-the-runtime", "start_char": 9386, "end_char": 9835, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Recompile the Runtime\n\nAfter adding and configuring your pallets in the runtime, the next step is to ensure everything is set up correctly. To do this, recompile the runtime with the following command (make sure you're in the project's root directory):\n\n```bash\ncargo build --release\n```\n\nThis command ensures the runtime compiles without errors, validates the pallet configurations, and prepares the build for subsequent testing or deployment."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-add-pallets-to-runtime", "index": 4, "depth": 2, "title": "Run Your Chain Locally", "anchor": "run-your-chain-locally", "start_char": 9835, "end_char": 11308, "estimated_token_count": 373, "token_estimator": "heuristic-v1", "text": "## Run Your Chain Locally\n\nLaunch your parachain locally and start producing blocks:\n\n!!!tip\n    Generated chain TestNet specifications include development accounts \"Alice\" and \"Bob.\" These accounts are pre-funded with native parachain currency, allowing you to sign and send TestNet transactions. Take a look at the [Polkadot.js Accounts section](https://polkadot.js.org/apps/#/accounts){target=\\_blank} to view the development accounts for your chain.\n\n1. Create a new chain specification file with the updated runtime:\n\n    ```bash\n    chain-spec-builder create -t development \\\n    --relay-chain paseo \\\n    --para-id 1000 \\\n    --runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    named-preset development\n    ```\n\n2. Start the omni node with the generated chain specification:\n\n    ```bash\n    polkadot-omni-node --chain ./chain_spec.json --dev\n    ```\n\n3. Verify you can interact with the new pallets using the [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/extrinsics){target=\\_blank} interface. Navigate to the **Extrinsics** tab and check that you can see both pallets:\n\n    - Utility pallet\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/add-pallets-to-runtime/add-pallets-to-runtime-1.webp)\n    \n\n    - Custom pallet\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/add-pallets-to-runtime/add-pallets-to-runtime-2.webp)"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-add-pallets-to-runtime", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 11308, "end_char": 12060, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Deploy on Paseo TestNet__\n\n    ---\n\n    Deploy your Polkadot SDK blockchain on Paseo! Follow this step-by-step guide for a seamless journey to a successful TestNet deployment.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/)\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Pallet Benchmarking (Optional)__\n\n    ---\n\n    Discover how to measure extrinsic costs and assign precise weights to optimize your pallet for accurate fees and runtime performance.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/pallet-benchmarking/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 25, "end_char": 1088, "estimated_token_count": 214, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn Polkadot SDK-based blockchains, runtime functionality is built through modular components called [pallets](/polkadot-protocol/glossary#pallet){target=\\_blank}. These pallets are Rust-based runtime modules created using [FRAME (Framework for Runtime Aggregation of Modular Entities)](/develop/parachains/customize-parachain/overview/){target=\\_blank}, a powerful library that simplifies blockchain development by providing specialized macros and standardized patterns for building blockchain logic.\nA pallet encapsulates a specific set of blockchain functionalities, such as managing token balances, implementing governance mechanisms, or creating custom state transitions.\n\nIn this tutorial, you'll learn how to create a custom pallet from scratch. You will develop a simple counter pallet with the following features:\n\n- Users can increment and decrement a counter.\n- Only a [root origin](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/type.Origin.html#variant.Root){target=\\_blank} can set an arbitrary counter value."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1088, "end_char": 1378, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nYou'll use the [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk/tree/master/templates/parachain){target=\\_blank} created in the [Set Up a Template](/tutorials/polkadot-sdk/parachains/zero-to-hero/set-up-a-template/){target=\\_blank} tutorial."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 2, "depth": 2, "title": "Create a New Project", "anchor": "create-a-new-project", "start_char": 1378, "end_char": 2276, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Create a New Project\n\nIn this tutorial, you'll build a custom pallet from scratch to demonstrate the complete workflow, rather than starting with the pre-built `pallet-template`. The first step is to create a new Rust package for your pallet:\n\n1. Navigate to the `pallets` directory in your workspace:\n\n    ```bash\n    cd pallets\n    ```\n\n2. Create a new Rust library project for your custom pallet by running the following command:\n\n    ```bash\n    cargo new --lib custom-pallet\n    ```\n\n3. Enter the new project directory:\n\n    ```bash\n    cd custom-pallet\n    ```\n\n4. Ensure the project was created successfully by checking its structure. The file layout should resemble the following:\n\n    ```\n    custom-pallet \n    ├── Cargo.toml\n    └── src\n        └── lib.rs\n    ```\n\n    If the files are in place, your project setup is complete, and you're ready to start building your custom pallet."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 3, "depth": 2, "title": "Add Dependencies", "anchor": "add-dependencies", "start_char": 2276, "end_char": 3845, "estimated_token_count": 406, "token_estimator": "heuristic-v1", "text": "## Add Dependencies\n\nTo build and integrate your custom pallet into a Polkadot SDK-based runtime, you must add specific dependencies to the `Cargo.toml` file of your pallet's project. These dependencies provide essential modules and features required for pallet development. Since your custom pallet is part of a workspace that includes other components, such as the runtime, the configuration must align with the workspace structure. Follow the steps below to set up your `Cargo.toml` file properly:\n\n1. Open your `Cargo.toml` file.\n\n2. Add the required dependencies in the `[dependencies]` section:\n\n    ```toml\n    -[dependencies]\ncodec = { features = [\"derive\"], workspace = true }\nscale-info = { features = [\"derive\"], workspace = true }\nframe = { features = [\"experimental\", \"runtime\"], workspace = true }\n    ```\n\n3. Enable `std` features:\n\n    ```toml\n    -[features]\ndefault = [\"std\"]\nstd = [\"codec/std\", \"frame/std\", \"scale-info/std\"]\n    ```\n\nThe final `Cargo.toml` file should resemble the following:\n\n??? code \"Cargo.toml\"\n\n    ```toml\n    -[package]\nname = \"custom-pallet\"\nversion = \"0.1.0\"\nlicense.workspace = true\nauthors.workspace = true\nhomepage.workspace = true\nrepository.workspace = true\nedition.workspace = true\n\n[dependencies]\ncodec = { features = [\"derive\"], workspace = true }\nscale-info = { features = [\"derive\"], workspace = true }\nframe = { features = [\"experimental\", \"runtime\"], workspace = true }\n\n[features]\ndefault = [\"std\"]\nstd = [\"codec/std\", \"frame/std\", \"scale-info/std\"]\nruntime-benchmarks = [\"frame/runtime-benchmarks\"]\n\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 4, "depth": 2, "title": "Implement the Pallet Logic", "anchor": "implement-the-pallet-logic", "start_char": 3845, "end_char": 4141, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Implement the Pallet Logic\n\nIn this section, you will construct the core structure of your custom pallet, starting with setting up its basic scaffold. This scaffold acts as the foundation, enabling you to later add functionality such as storage items, events, errors, and dispatchable calls."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 5, "depth": 3, "title": "Add Scaffold Pallet Structure", "anchor": "add-scaffold-pallet-structure", "start_char": 4141, "end_char": 5042, "estimated_token_count": 224, "token_estimator": "heuristic-v1", "text": "### Add Scaffold Pallet Structure\n\nYou now have the bare minimum of package dependencies that your pallet requires specified in the `Cargo.toml` file. The next step is to prepare the scaffolding for your new pallet.\n\n1. Open `src/lib.rs` in a text editor and delete all the content.\n   \n2. Prepare the scaffolding for the pallet by adding the following:\n\n    ```rust title=\"lib.rs\"\n    -#![cfg_attr(not(feature = \"std\"), no_std)]\n\npub use pallet::*;\n\n    -#[frame::pallet]\npub mod pallet {\n    use super::*;\n    use frame::prelude::*;\n    #[pallet::pallet]\n    pub struct Pallet<T>(_);\n\n    // Configuration trait for the pallet.\n    #[pallet::config]\n    pub trait Config: frame_system::Config {\n        // Defines the event type for the pallet.\n        -    }\n    -}\n    ```\n\n3. Verify that it compiles by running the following command:\n\n    ```bash\n    cargo build --package custom-pallet\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 6, "depth": 3, "title": "Pallet Configuration", "anchor": "pallet-configuration", "start_char": 5042, "end_char": 6297, "estimated_token_count": 285, "token_estimator": "heuristic-v1", "text": "### Pallet Configuration\n\nImplementing the `#[pallet::config]` macro is mandatory and sets the module's dependency on other modules and the types and values specified by the runtime-specific settings.\n\nIn this step, you will configure two essential components that are critical for the pallet's functionality:\n\n- **`RuntimeEvent`**: Since this pallet emits events, the [`RuntimeEvent`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html#associatedtype.RuntimeEvent){target=\\_blank} type is required to handle them. This ensures that events generated by the pallet can be correctly processed and interpreted by the runtime.\n\n- **`CounterMaxValue`**: A constant that sets an upper limit on the value of the counter, ensuring that the counter remains within a predefined range.\n\nAdd the following `Config` trait definition to your pallet:\n\n```rust title=\"lib.rs\"\n-    #[pallet::config]\n    pub trait Config: frame_system::Config {\n        // Defines the event type for the pallet.\n        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n        // Defines the maximum value the counter can hold.\n        #[pallet::constant]\n        type CounterMaxValue: Get<u32>;\n-    }\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 7, "depth": 3, "title": "Add Events", "anchor": "add-events", "start_char": 6297, "end_char": 8271, "estimated_token_count": 381, "token_estimator": "heuristic-v1", "text": "### Add Events\n\nEvents allow the pallet to communicate with the outside world by emitting signals when specific actions occur. These events are critical for transparency, debugging, and integration with external systems such as UIs or monitoring tools.\n\nBelow are the events defined for this pallet:\n\n- **`CounterValueSet`**: Is emitted when the counter is explicitly set to a new value. This event includes the counter's updated value.\n\n- **`CounterIncremented`**: Is emitted after a successful increment operation. It includes.\n\n    - The new counter value.\n    - The account responsible for the increment.\n    - The amount by which the counter was incremented.\n\n- **`CounterDecremented`**: Is emitted after a successful decrement operation. It includes.\n\n    - The new counter value.\n    - The account responsible for the decrement.\n    - The amount by which the counter was decremented.\n\nDefine the events in the pallet as follows:\n\n```rust title=\"lib.rs\"\n-    #[pallet::event]\n    #[pallet::generate_deposit(pub(super) fn deposit_event)]\n    pub enum Event<T: Config> {\n        /// The counter value has been set to a new value by Root.\n        CounterValueSet {\n            /// The new value set.\n            counter_value: u32,\n        },\n        /// A user has successfully incremented the counter.\n        CounterIncremented {\n            /// The new value set.\n            counter_value: u32,\n            /// The account who incremented the counter.\n            who: T::AccountId,\n            /// The amount by which the counter was incremented.\n            incremented_amount: u32,\n        },\n        /// A user has successfully decremented the counter.\n        CounterDecremented {\n            /// The new value set.\n            counter_value: u32,\n            /// The account who decremented the counter.\n            who: T::AccountId,\n            /// The amount by which the counter was decremented.\n            decremented_amount: u32,\n        },\n    }\n\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 8, "depth": 3, "title": "Add Storage Items", "anchor": "add-storage-items", "start_char": 8271, "end_char": 9066, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "### Add Storage Items\n\nStorage items are used to manage the pallet's state. This pallet defines two items to handle the counter's state and user interactions:\n\n- **`CounterValue`**: A single storage value that keeps track of the current value of the counter. This value is the core state variable manipulated by the pallet's functions.\n\n- **`UserInteractions`**: A storage map that tracks the number of times each account interacts with the counter.\n  \nDefine the storage items as follows:\n\n```rust title=\"lib.rs\"\n-    #[pallet::storage]\n    pub type CounterValue<T> = StorageValue<_, u32>;\n\n    /// Storage map to track the number of interactions performed by each account.\n    #[pallet::storage]\n    pub type UserInteractions<T: Config> = StorageMap<_, Twox64Concat, T::AccountId, u32>;\n\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 9, "depth": 3, "title": "Implement Custom Errors", "anchor": "implement-custom-errors", "start_char": 9066, "end_char": 10101, "estimated_token_count": 203, "token_estimator": "heuristic-v1", "text": "### Implement Custom Errors\n\nThe `#[pallet::error]` macro defines a custom `Error` enum to handle specific failure conditions within the pallet. Errors help provide meaningful feedback to users and external systems when an extrinsic cannot be completed successfully. They are critical for maintaining the pallet's clarity and robustness.\n\nTo add custom errors, use the `#[pallet::error]` macro to define the `Error` enum. Each variant represents a unique error that the pallet can emit, and these errors should align with the logic and constraints of the pallet. \n\nAdd the following errors to the pallet:\n\n```rust title=\"lib.rs\"\n-    #[pallet::error]\n    pub enum Error<T> {\n        /// The counter value exceeds the maximum allowed value.\n        CounterValueExceedsMax,\n        /// The counter value cannot be decremented below zero.\n        CounterValueBelowZero,\n        /// Overflow occurred in the counter.\n        CounterOverflow,\n        /// Overflow occurred in user interactions.\n        UserInteractionOverflow,\n    }\n\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 10, "depth": 3, "title": "Implement Calls", "anchor": "implement-calls", "start_char": 10101, "end_char": 17779, "estimated_token_count": 1608, "token_estimator": "heuristic-v1", "text": "### Implement Calls\n\nThe `#[pallet::call]` macro defines the dispatchable functions (or calls) the pallet exposes. These functions allow users or the runtime to interact with the pallet's logic and state. Each call includes comprehensive validations, modifies the state, and optionally emits events to signal successful execution.\n\nThe structure of the dispatchable calls in this pallet is as follows:\n\n```rust title=\"lib.rs\"\n-    #[pallet::call]\n    impl<T: Config> Pallet<T> {\n        /// Set the value of the counter.\n        ///\n        /// The dispatch origin of this call must be _Root_.\n        ///\n        /// - `new_value`: The new value to set for the counter.\n        ///\n        /// Emits `CounterValueSet` event when successful.\n        #[pallet::call_index(0)]\n    #[pallet::weight(0)]\n    -        pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n    -        }\n\n    -        /// Increment the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_increment`: The amount by which to increment the counter.\n        ///\n        /// Emits `CounterIncremented` event when successful.\n        #[pallet::call_index(1)]\n    #[pallet::weight(0)]\n    -        pub fn increment(origin: OriginFor<T>, amount_to_increment: u32) -> DispatchResult {\n    -        }\n\n    -        /// Decrement the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_decrement`: The amount by which to decrement the counter.\n        ///\n        /// Emits `CounterDecremented` event when successful.\n        #[pallet::call_index(2)]\n    #[pallet::weight(0)]\n    -        pub fn decrement(origin: OriginFor<T>, amount_to_decrement: u32) -> DispatchResult {\n    -    }\n-}\n```\n\nExpand the following items to view the implementations of each dispatchable call in this pallet.\n\n???- code \"set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult\"\n    This call sets the counter to a specific value. It is restricted to the Root origin, meaning it can only be invoked by privileged users or entities.\n\n    - Parameters:\n        - **`new_value`**: The value to set the counter to.\n    - Validations:\n        - The new value must not exceed the maximum allowed counter value (`CounterMaxValue`).\n    - Behavior:\n        - Updates the `CounterValue` storage item.\n        - Emits a `CounterValueSet` event on success.\n\n    ```rust title=\"lib.rs\"\n    -        /// Set the value of the counter.\n        ///\n        /// The dispatch origin of this call must be _Root_.\n        ///\n        /// - `new_value`: The new value to set for the counter.\n        ///\n        /// Emits `CounterValueSet` event when successful.\n        #[pallet::call_index(0)]\n    #[pallet::weight(0)]\n    -        pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n            ensure_root(origin)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            Self::deposit_event(Event::<T>::CounterValueSet {\n                counter_value: new_value,\n            });\n\n            Ok(())\n        }\n    ```\n\n???- code \"increment(origin: OriginFor<T>, amount_to_increment: u32) -> DispatchResult\"\n    This call increments the counter by a specified amount. It is accessible to any signed account.\n\n    - Parameters:\n        - **`amount_to_increment`**: The amount to add to the counter.\n    - Validations:\n        - Prevents overflow during the addition.\n        - Ensures the resulting counter value does not exceed `CounterMaxValue`.\n    - Behavior:\n        - Updates the `CounterValue` storage item.\n        - Tracks the number of interactions by the user in the `UserInteractions` storage map.\n        - Emits a `CounterIncremented` event on success.\n\n    ```rust title=\"lib.rs\"\n    -        /// Increment the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_increment`: The amount by which to increment the counter.\n        ///\n        /// Emits `CounterIncremented` event when successful.\n        #[pallet::call_index(1)]\n    #[pallet::weight(0)]\n    -        pub fn increment(origin: OriginFor<T>, amount_to_increment: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_add(amount_to_increment)\n                .ok_or(Error::<T>::CounterOverflow)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterIncremented {\n                counter_value: new_value,\n                who,\n                incremented_amount: amount_to_increment,\n            });\n\n            Ok(())\n        }\n    ```\n\n???- code \"decrement(origin: OriginFor<T>, amount_to_decrement: u32) -> DispatchResult\"\n    This call decrements the counter by a specified amount. It is accessible to any signed account.\n\n    - Parameters:\n        - **`amount_to_decrement`**: The amount to subtract from the counter.\n    - Validations:\n        - Prevents underflow during the subtraction.\n        - Ensures the counter does not drop below zero.\n    - Behavior:\n        - Updates the `CounterValue` storage item.\n        - Tracks the number of interactions by the user in the `UserInteractions` storage map.\n        - Emits a `CounterDecremented` event on success.\n\n    ```rust title=\"lib.rs\"\n    -        /// Decrement the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_decrement`: The amount by which to decrement the counter.\n        ///\n        /// Emits `CounterDecremented` event when successful.\n        #[pallet::call_index(2)]\n    #[pallet::weight(0)]\n    -        pub fn decrement(origin: OriginFor<T>, amount_to_decrement: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_sub(amount_to_decrement)\n                .ok_or(Error::<T>::CounterValueBelowZero)?;\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterDecremented {\n                counter_value: new_value,\n                who,\n                decremented_amount: amount_to_decrement,\n            });\n\n            Ok(())\n        }\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 11, "depth": 2, "title": "Verify Compilation", "anchor": "verify-compilation", "start_char": 17779, "end_char": 18208, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Verify Compilation\n\nAfter implementing all the pallet components, verifying that the code still compiles successfully is crucial. Run the following command in your terminal to ensure there are no errors:\n\n```bash\ncargo build --package custom-pallet\n```\n\nIf you encounter any errors or warnings, carefully review your code to resolve the issues. Once the build is complete without errors, your pallet implementation is ready."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 12, "depth": 2, "title": "Key Takeaways", "anchor": "key-takeaways", "start_char": 18208, "end_char": 31258, "estimated_token_count": 2734, "token_estimator": "heuristic-v1", "text": "## Key Takeaways\n\nIn this tutorial, you learned how to create a custom pallet by defining storage, implementing errors, adding dispatchable calls, and emitting events. These are the foundational building blocks for developing robust Polkadot SDK-based blockchain logic.\n\nExpand the following item to review this implementation and the complete pallet code.\n\n???- code \"src/lib.rs\"\n\n    ```rust title=\"lib.rs\"\n    -#![cfg_attr(not(feature = \"std\"), no_std)]\n\npub use pallet::*;\n\n    -#[frame::pallet]\npub mod pallet {\n    use super::*;\n    use frame::prelude::*;\n    #[pallet::pallet]\n    pub struct Pallet<T>(_);\n\n    // Configuration trait for the pallet.\n    #[pallet::config]\n    pub trait Config: frame_system::Config {\n        // Defines the event type for the pallet.\n        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n        // Defines the maximum value the counter can hold.\n        #[pallet::constant]\n        type CounterMaxValue: Get<u32>;\n        -    }\n\n    #[pallet::event]\n    #[pallet::generate_deposit(pub(super) fn deposit_event)]\n    pub enum Event<T: Config> {\n        /// The counter value has been set to a new value by Root.\n        CounterValueSet {\n            /// The new value set.\n            counter_value: u32,\n        },\n        /// A user has successfully incremented the counter.\n        CounterIncremented {\n            /// The new value set.\n            counter_value: u32,\n            /// The account who incremented the counter.\n            who: T::AccountId,\n            /// The amount by which the counter was incremented.\n            incremented_amount: u32,\n        },\n        /// A user has successfully decremented the counter.\n        CounterDecremented {\n            /// The new value set.\n            counter_value: u32,\n            /// The account who decremented the counter.\n            who: T::AccountId,\n            /// The amount by which the counter was decremented.\n            decremented_amount: u32,\n        },\n    }\n\n    /// Storage for the current value of the counter.\n    #[pallet::storage]\n    pub type CounterValue<T> = StorageValue<_, u32>;\n\n    /// Storage map to track the number of interactions performed by each account.\n    #[pallet::storage]\n    pub type UserInteractions<T: Config> = StorageMap<_, Twox64Concat, T::AccountId, u32>;\n\n    #[pallet::error]\n    pub enum Error<T> {\n        /// The counter value exceeds the maximum allowed value.\n        CounterValueExceedsMax,\n        /// The counter value cannot be decremented below zero.\n        CounterValueBelowZero,\n        /// Overflow occurred in the counter.\n        CounterOverflow,\n        /// Overflow occurred in user interactions.\n        UserInteractionOverflow,\n    }\n\n    #[pallet::call]\n    impl<T: Config> Pallet<T> {\n        /// Set the value of the counter.\n        ///\n        /// The dispatch origin of this call must be _Root_.\n        ///\n        /// - `new_value`: The new value to set for the counter.\n        ///\n        /// Emits `CounterValueSet` event when successful.\n        #[pallet::call_index(0)]\n            #[pallet::weight(0)]\n            -        pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n            ensure_root(origin)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            Self::deposit_event(Event::<T>::CounterValueSet {\n                counter_value: new_value,\n            });\n\n            Ok(())\n        }\n\n        /// Increment the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_increment`: The amount by which to increment the counter.\n        ///\n        /// Emits `CounterIncremented` event when successful.\n        #[pallet::call_index(1)]\n            #[pallet::weight(0)]\n            -        pub fn increment(origin: OriginFor<T>, amount_to_increment: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_add(amount_to_increment)\n                .ok_or(Error::<T>::CounterOverflow)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterIncremented {\n                counter_value: new_value,\n                who,\n                incremented_amount: amount_to_increment,\n            });\n\n            Ok(())\n        }\n\n        /// Decrement the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_decrement`: The amount by which to decrement the counter.\n        ///\n        /// Emits `CounterDecremented` event when successful.\n        #[pallet::call_index(2)]\n            #[pallet::weight(0)]\n    -// This file is part of 'custom-pallet'.\n\n// SPDX-License-Identifier: MIT-0\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\n#![cfg_attr(not(feature = \"std\"), no_std)]\n\npub use pallet::*;\n\n#[cfg(test)]\nmod mock;\n\n#[cfg(test)]\nmod tests;\n\n#[cfg(feature = \"runtime-benchmarks\")]\nmod benchmarking;\n\npub mod weights;\nuse crate::weights::WeightInfo;\n\n#[frame::pallet]\npub mod pallet {\n    use super::*;\n    use frame::prelude::*;\n    #[pallet::pallet]\n    pub struct Pallet<T>(_);\n\n    // Configuration trait for the pallet.\n    #[pallet::config]\n    pub trait Config: frame_system::Config {\n        // Defines the event type for the pallet.\n        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n        // Defines the maximum value the counter can hold.\n        #[pallet::constant]\n        type CounterMaxValue: Get<u32>;\n\n        /// A type representing the weights required by the dispatchables of this pallet.\n        type WeightInfo: WeightInfo;\n    }\n\n    #[pallet::event]\n    #[pallet::generate_deposit(pub(super) fn deposit_event)]\n    pub enum Event<T: Config> {\n        /// The counter value has been set to a new value by Root.\n        CounterValueSet {\n            /// The new value set.\n            counter_value: u32,\n        },\n        /// A user has successfully incremented the counter.\n        CounterIncremented {\n            /// The new value set.\n            counter_value: u32,\n            /// The account who incremented the counter.\n            who: T::AccountId,\n            /// The amount by which the counter was incremented.\n            incremented_amount: u32,\n        },\n        /// A user has successfully decremented the counter.\n        CounterDecremented {\n            /// The new value set.\n            counter_value: u32,\n            /// The account who decremented the counter.\n            who: T::AccountId,\n            /// The amount by which the counter was decremented.\n            decremented_amount: u32,\n        },\n    }\n\n    /// Storage for the current value of the counter.\n    #[pallet::storage]\n    pub type CounterValue<T> = StorageValue<_, u32>;\n\n    /// Storage map to track the number of interactions performed by each account.\n    #[pallet::storage]\n    pub type UserInteractions<T: Config> = StorageMap<_, Twox64Concat, T::AccountId, u32>;\n\n    #[pallet::error]\n    pub enum Error<T> {\n        /// The counter value exceeds the maximum allowed value.\n        CounterValueExceedsMax,\n        /// The counter value cannot be decremented below zero.\n        CounterValueBelowZero,\n        /// Overflow occurred in the counter.\n        CounterOverflow,\n        /// Overflow occurred in user interactions.\n        UserInteractionOverflow,\n    }\n\n    #[pallet::call]\n    impl<T: Config> Pallet<T> {\n        /// Set the value of the counter.\n        ///\n        /// The dispatch origin of this call must be _Root_.\n        ///\n        /// - `new_value`: The new value to set for the counter.\n        ///\n        /// Emits `CounterValueSet` event when successful.\n        #[pallet::call_index(0)]\n        #[pallet::weight(T::WeightInfo::set_counter_value())]\n        pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n            ensure_root(origin)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            Self::deposit_event(Event::<T>::CounterValueSet {\n                counter_value: new_value,\n            });\n\n            Ok(())\n        }\n\n        /// Increment the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_increment`: The amount by which to increment the counter.\n        ///\n        /// Emits `CounterIncremented` event when successful.\n        #[pallet::call_index(1)]\n        #[pallet::weight(T::WeightInfo::increment())]\n        pub fn increment(origin: OriginFor<T>, amount_to_increment: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_add(amount_to_increment)\n                .ok_or(Error::<T>::CounterOverflow)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterIncremented {\n                counter_value: new_value,\n                who,\n                incremented_amount: amount_to_increment,\n            });\n\n            Ok(())\n        }\n\n        /// Decrement the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_decrement`: The amount by which to decrement the counter.\n        ///\n        /// Emits `CounterDecremented` event when successful.\n        #[pallet::call_index(2)]\n        #[pallet::weight(T::WeightInfo::decrement())]\n        pub fn decrement(origin: OriginFor<T>, amount_to_decrement: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_sub(amount_to_decrement)\n                .ok_or(Error::<T>::CounterValueBelowZero)?;\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterDecremented {\n                counter_value: new_value,\n                who,\n                decremented_amount: amount_to_decrement,\n            });\n\n            Ok(())\n        }\n    }\n}\n\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-build-custom-pallet", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 31258, "end_char": 31658, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Pallet Unit Testing__\n\n    ---\n\n    Learn to write effective unit tests for Polkadot SDK pallets! Use a custom pallet as a practical example in this comprehensive guide.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/pallet-unit-testing/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 27, "end_char": 670, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPreviously, you learned how to [build and run a blockchain locally](/tutorials/polkadot-sdk/parachains/zero-to-hero/add-pallets-to-runtime/){target=\\_blank}. Now, you'll take the next step towards a production-like environment by deploying your parachain to a public test network.\n\nThis tutorial guides you through deploying a parachain on the Paseo network, a public TestNet that provides a more realistic blockchain ecosystem. While public testnets have a higher barrier to entry compared to private networks, they are crucial for validating your parachain's functionality and preparing it for eventual mainnet deployment."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 1, "depth": 2, "title": "Get Started with an Account and Tokens", "anchor": "get-started-with-an-account-and-tokens", "start_char": 670, "end_char": 2727, "estimated_token_count": 561, "token_estimator": "heuristic-v1", "text": "## Get Started with an Account and Tokens\n\nTo perform any action on Paseo, you need PAS tokens, which can be requested from the [Polkadot Faucet](https://faucet.polkadot.io/){target=\\_blank}. To store the tokens, you must have access to a Substrate-compatible wallet. Go to the [Polkadot Wallets](https://polkadot.com/get-started/wallets/){target=\\_blank} page on the Polkadot Wiki to view different options for a wallet, or use the [Polkadot.js browser extension](https://polkadot.js.org/extension/){target=\\_blank}, which is suitable for development purposes.\n\n!!!warning \n    Development keys and accounts should never hold assets of actual value and should not be used for production.\n\nThe [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} interface can be used to get you started for testing purposes.\n\nTo prepare an account, follow these steps:\n\n1. Open the [Polkadot.js Apps: Paseo](https://polkadot.js.org/apps/?rpc=wss://paseo.dotters.network#/explorer){target=\\_blank} interface and connect to the Paseo network. Alternatively use this link to connect directly to Paseo.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-1.webp)\n\n2. Navigate to the **Accounts** section:\n\n    1. Click on the **Accounts** tab in the top menu.\n    2. Select the **Accounts** option from the dropdown menu.\n  \n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-2.webp)\n\n3. Copy the address of the account you want to use for the parachain deployment.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-3.webp)\n\n4. Visit the [Polkadot Faucet](https://faucet.polkadot.io){target=\\_blank} and paste the copied address in the input field. Ensure that the network is set to Paseo and click on the **Get some PASs** button.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-4.webp)\n\n    After a few seconds, you will receive 5000 PAS tokens in your account."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 2, "depth": 2, "title": "Reserve a Parachain Identifier", "anchor": "reserve-a-parachain-identifier", "start_char": 2727, "end_char": 3944, "estimated_token_count": 327, "token_estimator": "heuristic-v1", "text": "## Reserve a Parachain Identifier\n\nYou must reserve a parachain identifier (ID) before registering your parachain on Paseo. You'll be assigned the next available identifier.\n\nTo reserve a parachain identifier, follow these steps:\n\n1. Navigate to the **Parachains** section:\n\n    1. Click on the **Network** tab in the top menu.\n    2. Select the **Parachains** option from the dropdown menu.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-5.webp)\n\n2. Register a ParaId:\n\n    1. Select the **Parathreads** tab.\n    2. Click on the **+ ParaId** button.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-6.webp)\n\n3. Review the transaction and click on the **+ Submit** button.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-7.webp)\n\n    For this case, the next available parachain identifier is `4508`.\n\n4. After submitting the transaction, you can navigate to the **Explorer** tab and check the list of recent events for successful `registrar.Reserved`.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-8.webp)"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 3, "depth": 2, "title": "Generate Customs Keys for Your Collator", "anchor": "generate-customs-keys-for-your-collator", "start_char": 3944, "end_char": 5956, "estimated_token_count": 411, "token_estimator": "heuristic-v1", "text": "## Generate Customs Keys for Your Collator\n\nTo securely deploy your parachain, it is essential to generate custom keys specifically for your collators (block producers). You should generate two sets of keys for each collator:\n\n- **Account keys**: Used to interact with the network and manage funds. These should be protected carefully and should never exist on the filesystem of the collator node.\n\n- **Session keys**: Used in block production to identify your node and its blocks on the network. These keys are stored in the parachain keystore and function as disposable \"hot wallet\" keys. If these keys are leaked, someone could impersonate your node, which could result in the slashing of your funds. To minimize these risks, rotating your session keys frequently is essential. Treat them with the same level of caution as you would a hot wallet to ensure the security of your node.\n\nTo perform this step, you can use [subkey](https://docs.rs/crate/subkey/latest){target=\\_blank}, a command-line tool for generating and managing keys:\n\n```bash\ndocker run -it parity/subkey:latest generate --scheme sr25519\n```\n\nThe output should look similar to the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>docker run -it parity/subkey:latest generate --scheme sr25519</span>\n  <span> <br />Secret phrase: lemon play remain picture leopard frog mad bridge hire hazard best buddy <br />Network ID: substrate <br />Secret seed: 0xb748b501de061bae1fcab1c0b814255979d74d9637b84e06414a57a1a149c004 <br />Public key (hex): 0xf4ec62ec6e70a3c0f8dcbe0531e2b1b8916cf16d30635bbe9232f6ed3f0bf422 <br />Account ID: 0xf4ec62ec6e70a3c0f8dcbe0531e2b1b8916cf16d30635bbe9232f6ed3f0bf422 <br />Public key (SS58): 5HbqmBBJ5ALUzho7tw1k1jEgKBJM7dNsQwrtfSfUskT1a3oe <br />SS58 Address: 5HbqmBBJ5ALUzho7tw1k1jEgKBJM7dNsQwrtfSfUskT1a3oe </span>\n</div>\n\n\nEnsure that this command is executed twice to generate the keys for both the account and session keys. Save them for future reference."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 4, "depth": 2, "title": "Generate the Chain Specification", "anchor": "generate-the-chain-specification", "start_char": 5956, "end_char": 14573, "estimated_token_count": 1526, "token_estimator": "heuristic-v1", "text": "## Generate the Chain Specification\n\nPolkadot SDK-based blockchains are defined by a file called the [chain specification](/develop/parachains/deployment/generate-chain-specs/){target=\\_blank}, or chain spec for short. There are two types of chain spec files:\n\n- **Plain chain spec**: A human-readable JSON file that can be modified to suit your parachain's requirements. It serves as a template for initial configuration and includes human-readable keys and structures.\n- **Raw chain spec**: A binary-encoded file used to start your parachain node. This file is generated from the plain chain spec and contains the encoded information necessary for the parachain node to synchronize with the blockchain network. It ensures compatibility across different runtime versions by providing data in a format directly interpretable by the node's runtime, regardless of upgrades since the chain's genesis.\n\nThe chain spec file is only required during the initial blockchain creation (genesis). You do not need to generate a new chain spec when performing runtime upgrades after your chain is already running.\n\nThe files required to register a parachain must specify the correct relay chain to connect to and the parachain identifier you have been assigned. To make these changes, you must build and modify the chain specification file for your parachain. In this tutorial, the relay chain is `paseo`, and the parachain identifier is `4508`.\n\nTo define your chain specification:\n\n1. Generate the plain chain specification for the parachain template node by running the following command. Make sure to use the `*.compact.compressed.wasm` version of your compiled runtime when generating your chain specification, and replace `INSERT_PARA_ID` with the ID you obtained in the [Reserve a Parachain Identifier](#reserve-a-parachain-identifier) section:\n\n    ```bash\n    chain-spec-builder \\\n    --chain-spec-path ./plain_chain_spec.json \\\n    create \\\n    --relay-chain paseo \\\n    --para-id INSERT_PARA_ID \\\n    --runtime target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    named-preset local_testnet\n    ```\n\n2. Edit the `plain_chain_spec.json` file:\n\n    - Update the `name`, `id`, and `protocolId` fields to unique values for your parachain.\n    - Change `para_id` and `parachainInfo.parachainId` fields to the parachain ID you obtained previously. Make sure to use a number without quotes.\n    - Modify the `balances` field to specify the initial balances for your accounts in SS58 format.\n    - Insert the account IDs and session keys in SS58 format generated for your collators in the `collatorSelection.invulnerables` and `session.keys` fields.\n    - Modify the `sudo` value to specify the account that will have sudo access to the parachain.\n  \n    ```json\n    -{\n    \"bootNodes\": [],\n    \"chainType\": \"Live\",\n    \"codeSubstitutes\": {},\n    \"genesis\": {\n        \"runtimeGenesis\": {\n            \"code\": \"0x...\",\n            \"patch\": {\n                \"aura\": {\n                    \"authorities\": []\n                },\n                \"auraExt\": {},\n                \"balances\": {\n                    \"balances\": [[\"INSERT_SUDO_ACCOUNT\", 1152921504606846976]]\n                },\n                \"collatorSelection\": {\n                    \"candidacyBond\": 16000000000,\n                    \"desiredCandidates\": 0,\n                    \"invulnerables\": [\"INSERT_ACCOUNT_ID_COLLATOR_1\"]\n                },\n                \"parachainInfo\": {\n                    \"parachainId\": \"INSERT_PARA_ID\"\n                },\n                \"parachainSystem\": {},\n                \"polkadotXcm\": {\n                    \"safeXcmVersion\": 4\n                },\n                \"session\": {\n                    \"keys\": [\n                        [\n                            \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n                            \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n                            {\n                                \"aura\": \"INSERT_SESSION_KEY_COLLATOR_1\"\n                            }\n                        ]\n                    ],\n                    \"nonAuthorityKeys\": []\n                },\n                \"sudo\": {\n                    \"key\": \"INSERT_SUDO_ACCOUNT\"\n                },\n                \"system\": {},\n                \"transactionPayment\": {\n                    \"multiplier\": \"1000000000000000000\"\n                }\n            }\n        }\n    },\n    \"id\": \"INSERT_ID\",\n    \"name\": \"INSERT_NAME\",\n    \"para_id\": \"INSERT_PARA_ID\",\n    \"properties\": {\n        \"tokenDecimals\": 12,\n        \"tokenSymbol\": \"UNIT\"\n    },\n    \"protocolId\": \"INSERT_PROTOCOL_ID\",\n    \"relay_chain\": \"paseo\",\n    \"telemetryEndpoints\": null\n}\n\n    ```\n\n    For this tutorial, the `plain_chain_spec.json` file should look similar to the following. Take into account that the same account is being used for the collator and sudo, which must not be the case in a production environment:\n\n    ??? code \"View complete script\"\n\n        ```json title=\"plain_chain_spec.json\"\n        -{\n    \"bootNodes\": [],\n    \"chainType\": \"Live\",\n    \"codeSubstitutes\": {},\n    \"genesis\": {\n        \"runtimeGenesis\": {\n            \"code\": \"0x...\",\n            \"patch\": {\n                \"aura\": {\n                    \"authorities\": []\n                },\n                \"auraExt\": {},\n                \"balances\": {\n                    \"balances\": [\n                        [\n                            \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\",\n                            1152921504606846976\n                        ]\n                    ]\n                },\n                \"collatorSelection\": {\n                    \"candidacyBond\": 16000000000,\n                    \"desiredCandidates\": 0,\n                    \"invulnerables\": [\n                        \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\"\n                    ]\n                },\n                \"parachainInfo\": {\n                    \"parachainId\": 4508\n                },\n                \"parachainSystem\": {},\n                \"polkadotXcm\": {\n                    \"safeXcmVersion\": 4\n                },\n                \"session\": {\n                    \"keys\": [\n                        [\n                            \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\",\n                            \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\",\n                            {\n                                \"aura\": \"5GcAKNdYcw5ybb2kAnta8WVFyiQbGJ5od3aH9MsgYDmVcrhJ\"\n                            }\n                        ]\n                    ],\n                    \"nonAuthorityKeys\": []\n                },\n                \"sudo\": {\n                    \"key\": \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\"\n                },\n                \"system\": {},\n                \"transactionPayment\": {\n                    \"multiplier\": \"1000000000000000000\"\n                }\n            }\n        }\n    },\n    \"id\": \"custom\",\n    \"name\": \"Custom\",\n    \"para_id\": 4508,\n    \"properties\": {\n        \"tokenDecimals\": 12,\n        \"tokenSymbol\": \"UNIT\"\n    },\n    \"protocolId\": null,\n    \"relay_chain\": \"paseo\",\n    \"telemetryEndpoints\": null\n}\n\n        ```\n\n3. Save your changes and close the plain text chain specification file.\n\n4. Convert the modified plain chain specification file to a raw chain specification file:\n\n    ```bash\n    chain-spec-builder \\\n    --chain-spec-path ./raw_chain_spec.json \\\n    convert-to-raw plain_chain_spec.json\n    ```\n\n    You should now see your chain specification containing SCALE-encoded hex values versus plain text.\n\n\n!!!note \"`para_id` Considerations\"\n\n    The `para_id` field in JSON chain specifications, added through the [`chain-spec-builder`](https://paritytech.github.io/polkadot-sdk/master/staging_chain_spec_builder/index.html){target=\\_blank} command, is used by nodes for configuration purposes. Beginning with Polkadot SDK release `stable2509`, runtimes can optionally implement the [`cumulus_primitives_core::GetParachainInfo`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/trait.GetParachainInfo.html){target=\\_blank} trait as an alternative method for parachain identification.\n\n    However, the `para_id` field will remain supported in chain specifications for backwards compatibility. This ensures that nodes can still sync from genesis or from runtime states that existed before the `GetParachainInfo` runtime API was introduced.\n\n    For guidance on performing runtime upgrades to implement the `GetParachainInfo` trait, refer to the [runtime upgrade tutorial](/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/){target=\\_blank}."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 5, "depth": 2, "title": "Export Required Files", "anchor": "export-required-files", "start_char": 14573, "end_char": 15059, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Export Required Files\n\nTo prepare the parachain collator to be registered on Paseo, follow these steps:\n\n1. Export the Wasm runtime for the parachain by running the following command:\n\n    ```bash\n    polkadot-omni-node export-genesis-wasm \\\n    --chain raw_chain_spec.json para-wasm\n    ```\n\n2. Export the genesis state for the parachain by running the following command:\n\n    ```bash\n    polkadot-omni-node export-genesis-head \\\n    --chain raw_chain_spec.json para-state\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 6, "depth": 2, "title": "Register a Parathread", "anchor": "register-a-parathread", "start_char": 15059, "end_char": 16324, "estimated_token_count": 316, "token_estimator": "heuristic-v1", "text": "## Register a Parathread\n\nOnce you have the genesis state and runtime, you can now register these with your parachain ID.\n\n1. Go to the [Parachains > Parathreads](https://polkadot.js.org/apps/#/parachains/parathreads){target=\\_blank} tab, and select **+ Parathread**.\n   \n2. You should see fields to place your runtime Wasm and genesis state respectively, along with the parachain ID. Select your parachain ID, and upload `para-wasm` in the **code** field and `para-state` in the **initial state** field.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-9.webp)\n   \n3. Confirm your details and **+ Submit** button, where there should be a new Parathread with your parachain ID and an active **Deregister** button.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/deploy-to-testnet-10.webp)\n\nYour parachain's runtime logic and genesis are now part of the relay chain. The next step is to ensure you are able to run a collator to produce blocks for your parachain.\n\n!!!note \n    You may need to wait several hours for your parachain to onboard. Until it has onboarded, you will be unable to purchase coretime, and therefore will not be able to perform transactions on your network."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 7, "depth": 2, "title": "Start the Collator Node", "anchor": "start-the-collator-node", "start_char": 16324, "end_char": 19053, "estimated_token_count": 682, "token_estimator": "heuristic-v1", "text": "## Start the Collator Node\n\nBefore starting a collator, you need to generate a node key. This key is responsible for communicating with other nodes over Libp2p:\n\n```bash\npolkadot-omni-node key generate-node-key \\\n--base-path data \\\n--chain raw_chain_spec.json\n```\n\nAfter running the command, you should see the following output, indicating the base path now has a suitable node key: \n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot-omni-node key generate-node-key --base-path data --chain raw_chain_spec.json</span>\n  <br />\n  <span data-ty=\"progress\">Generating key in \"/data/chains/custom/network/secret_ed25519\"</span>\n  <span data-ty=\"progress\">12D3KooWKGW964eG4fAwsNMFdckbj3GwhpmSGFU9dd8LFAVAa4EE</span>\n</div>\n\n\nYou must have the ports for the collator publicly accessible and discoverable to enable parachain nodes to peer with Paseo validator nodes to produce blocks. You can specify the ports with the `--port` command-line option. You can start the collator with a command similar to the following:\n\n```bash\npolkadot-omni-node --collator \\\n--chain raw_chain_spec.json \\\n--base-path data \\\n--port 40333 \\\n--rpc-port 8845 \\\n--force-authoring \\\n--node-key-file ./data/chains/custom/network/secret_ed25519 \\\n-- \\\n--sync warp \\\n--chain paseo \\\n--port 50343 \\\n--rpc-port 9988\n```\n\nIn this example, the first `--port` setting specifies the port for the collator node, and the second `--port` specifies the embedded relay chain node port. The first `--rpc-port` setting specifies the port you can connect to the collator. The second `--rpc-port` specifies the port for connecting to the embedded relay chain.\n\nBefore proceeding, ensure that the collator node is running. Then, open a new terminal and insert your generated session key into the collator keystore by running the following command. Use the same port specified in the `--rpc-port` parameter when starting the collator node (`8845` in this example) to connect to it. Replace `INSERT_SECRET_PHRASE` and `INSERT_PUBLIC_KEY_HEX_FORMAT` with the values from the session key you generated in the [Generate Customs Keys for Your Collator](#generate-customs-keys-for-your-collator) section:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n--data '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"author_insertKey\",\n  \"params\":[\n    \"aura\",\n    \"INSERT_SECRET_PHRASE\",\n    \"INSERT_PUBLIC_KEY_HEX_FORMAT\"\n  ],\n  \"id\":1\n}' \\\nhttp://localhost:8845\n```\n\nIf successful, you should see the following response:\n\n```json\n{\"jsonrpc\":\"2.0\",\"result\":null,\"id\":1}\n```\n\nOnce your collator is synced with the Paseo relay chain, and your parathread finished onboarding, it will be ready to start producing blocks. This process may take some time."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 8, "depth": 2, "title": "Producing Blocks", "anchor": "producing-blocks", "start_char": 19053, "end_char": 20101, "estimated_token_count": 211, "token_estimator": "heuristic-v1", "text": "## Producing Blocks\n\nWith your parachain collator operational, the next step is acquiring coretime. This is essential for ensuring your parachain's security through the relay chain. [Agile Coretime](https://wiki.polkadot.com/learn/learn-agile-coretime/){target=\\_blank} enhances Polkadot's resource management, offering developers greater economic adaptability. Once you have configured your parachain, you can follow two paths:\n\n- Bulk coretime is purchased via the Broker pallet on the respective coretime system parachain. You can purchase bulk coretime on the coretime chain and assign the purchased core to the registered `ParaID`.\n- On-demand coretime is ordered via the `OnDemandAssignment` pallet, which is located on the respective relay chain.\n\nOnce coretime is correctly assigned to your parachain, whether bulk or on-demand, blocks should be produced (provided your collator is running).\n\nFor more information on coretime, refer to the [Coretime](/polkadot-protocol/architecture/system-chains/coretime/){target=\\_blank} documentation."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-deploy-to-testnet", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 20101, "end_char": 20493, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Obtain Coretime__\n\n    ---\n\n    Get coretime for block production now! Follow this guide to explore on-demand and bulk options for seamless and efficient operations.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 1103, "estimated_token_count": 252, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter deploying a parachain to the Paseo TestNet in the [Deploy to TestNet](/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/){target=\\_blank} tutorial, the focus shifts to understanding Coretime, which is the mechanism in which validation resources are allocated from the relay chain to the respective task, such as a parachain. A parachain could only produce blocks and finalize them on the relay chain by obtaining coretime.\n\nThere are two ways to obtain coretime:\n\n- **[On-demand coretime](#order-on-demand-coretime)**: On-demand coretime allows you to buy coretime on a block-by-block basis.\n- **[Bulk coretime](#purchase-bulk-coretime)**: Bulk coretime allows you to obtain a core or part of a core. It is purchased for some time, up to 28 days. It must be renewed once the lease finishes.\n\nIn this tutorial, you will:\n\n- Learn about the different coretime interfaces available.\n- Learn how to purchase a core via bulk coretime.\n- Assign a task / parachain to the core for block production.\n- Alternatively, use on-demand coretime to produce blocks as required."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1103, "end_char": 1734, "estimated_token_count": 136, "token_estimator": "heuristic-v1", "text": "## Prerequisites \n\nBefore proceeding, you should have the following items:\n\n- A parachain ID.\n- A chain specification.\n- A registered parathread with the correct genesis, runtime, and parachain ID that matches the chain specification.\n- A properly configured and synced (with the relay chain) collator.\n\nOnce the above is complete, obtaining coretime is the last step to enable your parachain to start producing and finalizing blocks using the relay chain's validator set. If you don't, refer to the previous tutorial: [Deploy on Paseo TestNet](/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/){target=\\_blank}."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 2, "depth": 2, "title": "Order On Demand Coretime", "anchor": "order-on-demand-coretime", "start_char": 1734, "end_char": 3979, "estimated_token_count": 565, "token_estimator": "heuristic-v1", "text": "## Order On Demand Coretime\n\nThere are two extrinsics which allow you to place orders for on-demand coretime:\n\n- [**`onDemand.placeOrderAllowDeath`**](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/on_demand/pallet/dispatchables/fn.place_order_allow_death.html){target=\\_blank}: Will [reap](https://wiki.polkadot.com/learn/learn-accounts/#existential-deposit-and-reaping){target=\\_blank} the account once the provided funds run out.\n- [**`onDemand.placeOrderKeepAlive`**](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/on_demand/pallet/dispatchables/fn.place_order_keep_alive.html){target=\\_blank}: Includes a check that will **not** reap the account if the provided funds run out, ensuring the account is kept alive.\n\nTo produce a block in your parachain, navigate to Polkadot.js Apps and ensure you're connected to the Paseo relay chain. Then, access the [**Developer > Extrinsics**](https://polkadot.js.org/apps/#/extrinsics){target=\\_blank} tab and execute the `onDemand.placeOrderAllowDeath` extrinsic from the account that registered the `ParaID`. For this example, `maxAmount` is set to `1000000000000` (this value may vary depending on the network conditions), and `paraId` is set to `4518`:\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-9.webp)\n\nWith each successful on-demand extrinsic, the parachain will produce a new block. You can verify this by checking the collator logs. If the extrinsic is successful, you should see output similar to the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"progress\">2024-12-11 18:03:29 [Parachain] 🙌 Starting consensus session on top of parent </span>\n  <span data-ty=\"progress\">0x860e5e37dbc04e736e76c4a42c64e71e069084548862d4007d32958578b26d87 (#214) </span>\n  <span data-ty=\"progress\">2024-12-11 18:03:30 [Parachain] 🎁 Prepared block for proposing at 215 (701 ms) hash: </span>\n  <span data-ty=\"progress\">0xee48b7dd559ab4cbff679f59e5cd37f2fd5b60c53a25b11d770dce999968076c; parent_hash: 0x860e…6d87; end: NoMoreTransactions; extrinsics_count: 2 </span>\n  <span data-ty=\"progress\">2024-12-11 18:03:30 [Parachain] 🏆 Imported #215 (0x860e…6d87 → 0xee48…076c)</span>\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 3, "depth": 2, "title": "Purchase Bulk Coretime", "anchor": "purchase-bulk-coretime", "start_char": 3979, "end_char": 4913, "estimated_token_count": 232, "token_estimator": "heuristic-v1", "text": "## Purchase Bulk Coretime\n\nPurchasing bulk coretime involves purchasing a core from the [Coretime Chain](/polkadot-protocol/architecture/system-chains/coretime/){target=\\_blank}, which has an instance of [`pallet_broker`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/index.html){target=\\_blank} (the Broker pallet). Although this can be done via sending extrinsics through a tool like Polkadot.js Apps, the [RegionX Coretime Marketplace](https://app.regionx.tech){target=\\_blank} (includes Paseo support) also provides a user interface for purchasing and managing bulk coretime.\n  \n!!!tip\n    Obtaining a core for bulk coretime on Paseo follows a different process from Polkadot or Kusama. To apply for a core on Paseo, visit their guide for doing so: [PAS-10 Onboard Paras Coretime](https://github.com/paseo-network/paseo-action-submission/blob/main/pas/PAS-10-Onboard-paras-coretime.md#summary){target=\\_blank}."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 4, "depth": 3, "title": "Get Coretime Funds", "anchor": "get-coretime-funds", "start_char": 4913, "end_char": 5898, "estimated_token_count": 264, "token_estimator": "heuristic-v1", "text": "### Get Coretime Funds\n\nFirst, ensure your wallet is connected to the [RegionX](https://app.regionx.tech){target=\\_blank} interface. To do so, go to **Home** in the RegionX app and click the **Connect Wallet** button in the upper right.\n\nAfter connecting your wallet, you must obtain funds on the Coretime chain. You can use the [RegionX Transfer](https://app.regionx.tech/transfer){target=\\_blank} page to perform a cross-chain transfer from the relay to the system chain.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-1.webp)\n\nIf you are purchasing a core on a TestNet, be sure to visit the [Polkadot Faucet](https://faucet.polkadot.io/westend){target=\\_blank} for TestNet tokens.\n\nIf successful, you should see the balance in the upper right of the **Transfer** page update with balances on the relay and Coretime chain, respectively.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-2.webp)"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 5, "depth": 3, "title": "Purchase a Core", "anchor": "purchase-a-core", "start_char": 5898, "end_char": 7570, "estimated_token_count": 440, "token_estimator": "heuristic-v1", "text": "### Purchase a Core\n\nFor this tutorial, we will use [RegionX](https://app.regionx.tech){target=\\_blank}. Once you open the app, you should be presented with the following screen:\n\n![Screenshot of the RegionX app displaying the main interface.](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-3.webp)\n\nOn the top left is a network switch. Ensure you have selected your parachain and that it is registered before purchasing a core.\n\nTo purchase a core, go to the menu on the left and select the **Purchase A Core** item under **Primary Market**. Here, you should see the cores available for purchase, details regarding the sale period, and its current phase. Alternatively, you may use this link to visit it: [**Primary Market > Purchase A Core**](https://app.regionx.tech/purchase){target=\\_blank}.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-4.webp)\n\nAt the bottom-right corner of the page, select the **Purchase a Core** button. A modal detailing the fees will appear. Review the details, then click **Ok** and sign the transaction using the wallet of your choice.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-5.webp)\n\nOnce the transaction is confirmed, click [**My Regions**](https://app.regionx.tech/regions){target=\\_blank} on the left-hand menu, and you will see your purchased core.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-6.webp)\n\nCongratulations, you just purchased a core using RegionX! You can assign the core to your parachain, partition, interlace, and more using RegionX."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-obtain-coretime", "index": 6, "depth": 3, "title": "Assign a Core", "anchor": "assign-a-core", "start_char": 7570, "end_char": 8627, "estimated_token_count": 250, "token_estimator": "heuristic-v1", "text": "### Assign a Core\n\nOnce you have the core as shown in the dashboard, select it by clicking on it, then click the **Assign** option on the left-hand side. You will be presented with a modal in which you can add a new task.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-7.webp)\n\nClick the **Add Task** button and input the parachain identifier, along with the name of your project, and finalize it by clicking **Add Task**.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/obtain-coretime/obtain-coretime-8.webp)\n\nYou may now select a task from the list. You must also set the core's finality, which determines whether you can renew this specific core. Provisional finality allows for interlacing and partitioning, whereas Final finality does not allow the region to be modified. A core must not be interlaced or partitioned to be renewable, so Finality should be selected if you want to renew this specific core.\n\nOnce you sign and send this transaction, your parachain will be assigned to that core."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-benchmarking", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 1093, "estimated_token_count": 227, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter validating your pallet through testing and integrating it into your runtime, the next crucial step is benchmarking. Testing procedures were detailed in the [Pallet Unit Testing](/tutorials/polkadot-sdk/parachains/zero-to-hero/pallet-unit-testing/){target=\\_blank} tutorial, while runtime integration was covered in the [Add Pallets to the Runtime](/tutorials/polkadot-sdk/parachains/zero-to-hero/add-pallets-to-runtime/){target=\\_blank} guide.\n\nBenchmarking assigns precise [weight](/polkadot-protocol/glossary/#weight){target=\\_blank} to each extrinsic, \nmeasuring their computational and storage costs. These derived weights enable accurate fee calculation and resource \nallocation within the runtime.\n\nThis tutorial demonstrates how to:\n\n- Configure your development environment for benchmarking.\n- Create and implement benchmark tests for your extrinsics.\n- Apply benchmark results to your pallet's extrinsics.\n\nFor comprehensive information about benchmarking concepts, refer to the [Benchmarking](/develop/parachains/testing/benchmarking/){target=\\_blank} guide."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-benchmarking", "index": 1, "depth": 2, "title": "Environment Setup", "anchor": "environment-setup", "start_char": 1093, "end_char": 3836, "estimated_token_count": 681, "token_estimator": "heuristic-v1", "text": "## Environment Setup\n\nFollow these steps to prepare your environment for pallet benchmarking:\n\n1. Install the [`frame-omni-bencher`](https://crates.io/crates/frame-omni-bencher/0.13.0){target=\\_blank} command-line tool:\n    \n    ```bash\n    cargo install --locked frame-omni-bencher@0.13.0\n    ```\n\n2. Update your pallet's `Cargo.toml` file in the `pallets/custom-pallet` directory by adding the `runtime-benchmarks` feature flag:\n\n    ```toml hl_lines=\"4\" title=\"Cargo.toml\"\n    -[package]\nname = \"custom-pallet\"\nversion = \"0.1.0\"\nlicense.workspace = true\nauthors.workspace = true\nhomepage.workspace = true\nrepository.workspace = true\nedition.workspace = true\n\n[dependencies]\ncodec = { features = [\"derive\"], workspace = true }\nscale-info = { features = [\"derive\"], workspace = true }\nframe = { features = [\"experimental\", \"runtime\"], workspace = true }\n\n[features]\ndefault = [\"std\"]\nstd = [\"codec/std\", \"frame/std\", \"scale-info/std\"]\nruntime-benchmarks = [\"frame/runtime-benchmarks\"]\n\n    ```\n\n3. Add your pallet to the runtime's benchmark configuration:\n\n    1.  Register your pallet in `runtime/src/benchmarks.rs`:\n\n        ```rust hl_lines=\"11\" title=\"benchmarks.rs\"\n        -polkadot_sdk::frame_benchmarking::define_benchmarks!(\n    [frame_system, SystemBench::<Runtime>]\n    [pallet_balances, Balances]\n    [pallet_session, SessionBench::<Runtime>]\n    [pallet_timestamp, Timestamp]\n    [pallet_message_queue, MessageQueue]\n    [pallet_sudo, Sudo]\n    [pallet_collator_selection, CollatorSelection]\n    [cumulus_pallet_parachain_system, ParachainSystem]\n    [cumulus_pallet_xcmp_queue, XcmpQueue]\n    [custom_pallet, CustomPallet]\n);\n        ```\n\n    2. Enable runtime benchmarking for your pallet in `runtime/Cargo.toml`:\n\n        ```toml hl_lines=\"6\" title=\"Cargo.toml\"\n        -runtime-benchmarks = [\n\t\"cumulus-pallet-parachain-system/runtime-benchmarks\",\n\t\"hex-literal\",\n\t\"pallet-parachain-template/runtime-benchmarks\",\n\t\"polkadot-sdk/runtime-benchmarks\",\n\t\"custom-pallet/runtime-benchmarks\",\n]\n        ```\n\n4. Set up the benchmarking module in your pallet:\n    1. Create a `benchmarking.rs` file in your pallet's `src/` directory:\n    \n        ```bash\n        touch benchmarking.rs\n        ```\n\n    2. Add the benchmarking module to your pallet. In the pallet `lib.rs` file add the following:\n\n        ```rust hl_lines=\"9-10\" title=\"lib.rs\"\n        -\npub use pallet::*;\n\n#[cfg(test)]\nmod mock;\n\n#[cfg(test)]\nmod tests;\n\n#[cfg(feature = \"runtime-benchmarks\")]\nmod benchmarking;\n\n        ```\n\n    The `benchmarking` module is gated behind the `runtime-benchmarks` feature flag. It will only be compiled when this flag is explicitly enabled in your project's `Cargo.toml` or via the `--features runtime-benchmarks` compilation flag."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-benchmarking", "index": 2, "depth": 2, "title": "Implement Benchmark Tests", "anchor": "implement-benchmark-tests", "start_char": 3836, "end_char": 8785, "estimated_token_count": 1186, "token_estimator": "heuristic-v1", "text": "## Implement Benchmark Tests\n\nWhen writing benchmarking tests for your pallet, you'll create specialized test functions for each extrinsic, similar to unit tests. These tests use the mock runtime you created earlier for testing, allowing you to leverage its utility functions.\n\nEvery benchmark test must follow a three-step pattern:\n\n1. **Setup**: Perform any necessary setup before calling the extrinsic. This might include creating accounts, setting initial states, or preparing test data.\n2. **Execute the extrinsic**: Execute the actual extrinsic using the [`#[extrinsic_call]`](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/attr.extrinsic_call.html){target=\\_blank} macro. This must be a single line that calls your extrinsic function with the origin as its first argument.\n3. **Verification**: Check that the extrinsic worked correctly within the benchmark context by checking the expected state changes.\n\nCheck the following example on how to benchmark the `increment` extrinsic:\n\n```rust\n-    #[benchmark]\n    fn increment() {\n        let caller: T::AccountId = whitelisted_caller();\n\n        assert_ok!(CustomPallet::<T>::set_counter_value(\n            RawOrigin::Root.into(),\n            5u32\n        ));\n\n        #[extrinsic_call]\n        increment(RawOrigin::Signed(caller.clone()), 1);\n\n        assert_eq!(CounterValue::<T>::get(), Some(6u32.into()));\n        assert_eq!(UserInteractions::<T>::get(caller), 1u32.into());\n    }\n```\n\nThis benchmark test:\n\n1. Creates a whitelisted caller and sets an initial counter value of 5.\n2. Calls the increment extrinsic to increase the counter by 1.\n3. Verifies that the counter was properly incremented to 6 and that the user's interaction was recorded in storage.\n\nThis example demonstrates how to properly set up state, execute an extrinsic, and verify its effects during benchmarking.\n\nNow, implement the complete set of benchmark tests. Copy the following content in the `benchmarking.rs` file:\n\n```rust title=\"benchmarking.rs\"\n-// This file is part of 'custom-pallet'.\n\n// SPDX-License-Identifier: MIT-0\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\n#![cfg(feature = \"runtime-benchmarks\")]\n\nuse super::{Pallet as CustomPallet, *};\nuse frame::deps::frame_support::assert_ok;\nuse frame::{deps::frame_benchmarking::v2::*, prelude::*};\n\n#[benchmarks]\nmod benchmarks {\n    use super::*;\n    #[cfg(test)]\n    use crate::pallet::Pallet as CustomPallet;\n    use frame_system::RawOrigin;\n\n    #[benchmark]\n    fn set_counter_value() {\n        #[extrinsic_call]\n        set_counter_value(RawOrigin::Root, 5);\n\n        assert_eq!(CounterValue::<T>::get(), Some(5u32.into()));\n    }\n\n    #[benchmark]\n    fn increment() {\n        let caller: T::AccountId = whitelisted_caller();\n\n        assert_ok!(CustomPallet::<T>::set_counter_value(\n            RawOrigin::Root.into(),\n            5u32\n        ));\n\n        #[extrinsic_call]\n        increment(RawOrigin::Signed(caller.clone()), 1);\n\n        assert_eq!(CounterValue::<T>::get(), Some(6u32.into()));\n        assert_eq!(UserInteractions::<T>::get(caller), 1u32.into());\n    }\n\n    #[benchmark]\n    fn decrement() {\n        let caller: T::AccountId = whitelisted_caller();\n\n        assert_ok!(CustomPallet::<T>::set_counter_value(\n            RawOrigin::Root.into(),\n            5u32\n        ));\n\n        #[extrinsic_call]\n        decrement(RawOrigin::Signed(caller.clone()), 1);\n\n        assert_eq!(CounterValue::<T>::get(), Some(4u32.into()));\n        assert_eq!(UserInteractions::<T>::get(caller), 1u32.into());\n    }\n\n    impl_benchmark_test_suite!(CustomPallet, crate::mock::new_test_ext(), crate::mock::Test);\n}\n\n```\n\nThe [`#[benchmark]`](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/attr.benchmark.html){target=\\_blank} macro marks these functions as benchmark tests, while the `#[extrinsic_call]` macro specifically identifies which line contains the extrinsic being measured. For more information, see the [frame_benchmarking](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/index.html){target=\\_blank} Rust docs."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-benchmarking", "index": 3, "depth": 2, "title": "Execute the Benchmarking", "anchor": "execute-the-benchmarking", "start_char": 8785, "end_char": 10759, "estimated_token_count": 423, "token_estimator": "heuristic-v1", "text": "## Execute the Benchmarking\n\nAfter implementing your benchmark test suite, you'll need to execute the tests and generate the weights for your extrinsics. This process involves building your runtime with benchmarking features enabled and using the `frame-omni-bencher` CLI tool. To do that, follow these steps:\n\n1. Build your runtime with the `runtime-benchmarks` feature enabled:\n\n    ```bash\n    cargo build --features runtime-benchmarks --release\n    ```\n\n    This special build includes all the necessary benchmarking code that's normally excluded from production builds.\n\n2. Create a `weights.rs` file in your pallet's `src/` directory. This file will store the auto-generated weight calculations:\n\n    ```bash\n    touch weights.rs\n    ```\n\n3. Before running the benchmarking tool, you'll need a template file that defines how weight information should be formatted. Download the official template from the Polkadot SDK repository and save it in your project folders for future use:\n\n    ```bash\n    mkdir ./pallets/benchmarking && \\\n    curl https://raw.githubusercontent.com/paritytech/polkadot-sdk/refs/heads/stable2412/substrate/.maintain/frame-umbrella-weight-template.hbs \\\n    --output ./pallets/benchmarking/frame-umbrella-weight-template.hbs\n    ```\n\n4. Execute the benchmarking process using the `frame-omni-bencher` CLI:\n\n    ```bash\n    frame-omni-bencher v1 benchmark pallet \\\n    --runtime target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    --pallet \"custom_pallet\" \\\n    --extrinsic \"\" \\\n    --template ./pallets/benchmarking/frame-umbrella-weight-template.hbs \\\n    --output ./pallets/custom-pallet/src/weights.rs\n    ```\n\nWhen the benchmarking process completes, your `weights.rs` file will contain auto-generated code with weight calculations for each of your pallet's extrinsics. These weights help ensure fair and accurate fee calculations when your pallet is used in a production environment."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-benchmarking", "index": 4, "depth": 2, "title": "Add Benchmarking Weights to the Pallet", "anchor": "add-benchmarking-weights-to-the-pallet", "start_char": 10759, "end_char": 13577, "estimated_token_count": 637, "token_estimator": "heuristic-v1", "text": "## Add Benchmarking Weights to the Pallet\n\nAfter generating the weight calculations, you need to integrate these weights into your pallet's code. This integration ensures your pallet properly accounts for computational costs in its extrinsics.\n\nFirst, add the necessary module imports to your pallet. These imports make the weights available to your code:\n\n```rust hl_lines=\"4-5\" title=\"lib.rs\"\n-#[cfg(feature = \"runtime-benchmarks\")]\nmod benchmarking;\n\npub mod weights;\nuse crate::weights::WeightInfo;\n```\n\nNext, update your pallet's `Config` trait to include weight information. Define the `WeightInfo` type:\n\n```rust hl_lines=\"9-10\" title=\"lib.rs\"\n-    pub trait Config: frame_system::Config {\n        // Defines the event type for the pallet.\n        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n        // Defines the maximum value the counter can hold.\n        #[pallet::constant]\n        type CounterMaxValue: Get<u32>;\n\n        /// A type representing the weights required by the dispatchables of this pallet.\n        type WeightInfo: WeightInfo;\n    }\n```\n\nNow you can assign weights to your extrinsics. Here's how to add weight calculations to the `set_counter_value` function:\n\n```rust hl_lines=\"1\" title=\"lib.rs\"\n-        #[pallet::weight(T::WeightInfo::set_counter_value())]\n        pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n            ensure_root(origin)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            Self::deposit_event(Event::<T>::CounterValueSet {\n                counter_value: new_value,\n            });\n\n            Ok(())\n        }\n\n```\n\nYou must apply similar weight annotations to the other extrinsics in your pallet. Add the `#[pallet::weight(T::WeightInfo::function_name())]` attribute to both `increment` and `decrement`, replacing `function_name` with the respective function names from your `WeightInfo` trait.\n\nFor testing purposes, you must implement the weight calculations in your mock runtime. Open `custom-pallet/src/mock.rs` and add:\n\n```rust hl_lines=\"4\" title=\"mock.rs\"\n-impl custom_pallet::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = CounterMaxValue;\n    type WeightInfo = custom_pallet::weights::SubstrateWeight<Test>;\n}\n```\n\nFinally, configure the actual weight values in your production runtime. In `runtime/src/config/mod.rs`, add:\n\n```rust hl_lines=\"5\" title=\"mod.rs\"\n-\n// Define counter max value runtime constant.\nparameter_types! {\n    pub const CounterMaxValue: u32 = 500;\n}\n\n```\n\nYour pallet is now complete with full testing and benchmarking support, ready for production use."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-benchmarking", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 13577, "end_char": 14007, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Runtime Upgrade__\n\n    ---\n\n    Learn how to safely perform runtime upgrades for your Polkadot SDK-based blockchain, including step-by-step instructions for preparing, submitting, and verifying upgrades.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 23, "end_char": 913, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nYou have learned how to create a new pallet in the [Build a Custom Pallet](/tutorials/polkadot-sdk/parachains/zero-to-hero/build-custom-pallet/){target=\\_blank} tutorial; now you will see how to test the pallet to ensure that it works as expected. As stated in the [Pallet Testing](/develop/parachains/testing/pallet-testing/){target=\\_blank} article, unit testing is crucial for ensuring the reliability and correctness of pallets in Polkadot SDK-based blockchains. Comprehensive testing helps validate pallet functionality, prevent potential bugs, and maintain the integrity of your blockchain logic.\n\nThis tutorial will guide you through creating a unit testing suite for a custom pallet created in the [Build a Custom Pallet](/tutorials/polkadot-sdk/parachains/zero-to-hero/build-custom-pallet/){target=\\_blank} tutorial, covering essential testing aspects and steps."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 913, "end_char": 1450, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo set up your testing environment for Polkadot SDK pallets, you'll need:\n\n- [Polkadot SDK dependencies](/develop/parachains/install-polkadot-sdk/){target=\\_blank} installed.\n- Basic understanding of Substrate/Polkadot SDK concepts.\n- A custom pallet implementation, check the [Build a Custom Pallet](/tutorials/polkadot-sdk/parachains/zero-to-hero/build-custom-pallet/){target=\\_blank} tutorial.\n- Familiarity with [Rust testing frameworks](https://doc.rust-lang.org/book/ch11-01-writing-tests.html){target=\\_blank}."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 2, "depth": 2, "title": "Set Up the Testing Environment", "anchor": "set-up-the-testing-environment", "start_char": 1450, "end_char": 2045, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## Set Up the Testing Environment\n\nTo effectively create the test environment for your pallet, you'll need to follow these steps:\n\n1. Move to the project directory:\n\n    ```bash\n    cd custom-pallet\n    ```\n\n2. Create a `mock.rs` and a `tests.rs` files (leave these files empty for now, they will be filled in later):\n\n    ```bash\n    touch src/mock.rs\n    touch src/tests.rs\n    ```\n\n3. Include them in your `lib.rs` module:\n\n    ```rust hl_lines=\"5-9\" title=\"lib.rs\"\n    -#![cfg_attr(not(feature = \"std\"), no_std)]\n\npub use pallet::*;\n\n#[cfg(test)]\nmod mock;\n\n#[cfg(test)]\nmod tests;\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 3, "depth": 2, "title": "Implement Mocked Runtime", "anchor": "implement-mocked-runtime", "start_char": 2045, "end_char": 7124, "estimated_token_count": 1069, "token_estimator": "heuristic-v1", "text": "## Implement Mocked Runtime\n\nThe following portion of code sets up a mock runtime (`Test`) to test the `custom-pallet` in an isolated environment. Using [`frame_support`](https://paritytech.github.io/polkadot-sdk/master/frame_support/index.html){target=\\_blank} macros, it defines a minimal runtime configuration with traits such as `RuntimeCall` and `RuntimeEvent` to simulate runtime behavior. The mock runtime integrates the [`System pallet`](https://paritytech.github.io/polkadot-sdk/master/frame_system/index.html){target=\\_blank}, which provides core functionality, and the `custom pallet` under specific indices. Copy and paste the following snippet of code into your `mock.rs` file:\n\n```rust title=\"mock.rs\"\n-use crate as custom_pallet;\nuse frame::{prelude::*, runtime::prelude::*, testing_prelude::*};\n\ntype Block = frame_system::mocking::MockBlock<Test>;\n\n// Configure a mock runtime to test the pallet.\n#[frame_construct_runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n        RuntimeCall,\n        RuntimeEvent,\n        RuntimeError,\n        RuntimeOrigin,\n        RuntimeFreezeReason,\n        RuntimeHoldReason,\n        RuntimeSlashReason,\n        RuntimeLockId,\n        RuntimeTask\n    )]\n    pub struct Test;\n\n    #[runtime::pallet_index(0)]\n    pub type System = frame_system;\n\n    #[runtime::pallet_index(1)]\n    pub type CustomPallet = custom_pallet;\n}\n```\n\nOnce you have your mock runtime set up, you can customize it by implementing the configuration traits for the `System pallet` and your `custom-pallet`, along with additional constants and initial states for testing. Here's an example of how to extend the runtime configuration. Copy and paste the following snippet of code below the previous one you added to `mock.rs`:\n\n```rust title=\"mock.rs\"\n-// System pallet configuration\n#[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\nimpl frame_system::Config for Test {\n    type Block = Block;\n}\n\n// Custom pallet configuration\nparameter_types! {\n    pub const CounterMaxValue: u32 = 10;\n}\n\nimpl custom_pallet::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = CounterMaxValue;\n-// This file is part of 'custom-pallet'.\n\n// SPDX-License-Identifier: MIT-0\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\nuse crate as custom_pallet;\nuse frame::{prelude::*, runtime::prelude::*, testing_prelude::*};\n\ntype Block = frame_system::mocking::MockBlock<Test>;\n\n// Configure a mock runtime to test the pallet.\n#[frame_construct_runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n        RuntimeCall,\n        RuntimeEvent,\n        RuntimeError,\n        RuntimeOrigin,\n        RuntimeFreezeReason,\n        RuntimeHoldReason,\n        RuntimeSlashReason,\n        RuntimeLockId,\n        RuntimeTask\n    )]\n    pub struct Test;\n\n    #[runtime::pallet_index(0)]\n    pub type System = frame_system;\n\n    #[runtime::pallet_index(1)]\n    pub type CustomPallet = custom_pallet;\n}\n\n// System pallet configuration\n#[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\nimpl frame_system::Config for Test {\n    type Block = Block;\n}\n\n// Custom pallet configuration\nparameter_types! {\n    pub const CounterMaxValue: u32 = 10;\n}\n\nimpl custom_pallet::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = CounterMaxValue;\n    type WeightInfo = custom_pallet::weights::SubstrateWeight<Test>;\n}\n\n// Test externalities initialization\npub fn new_test_ext() -> TestExternalities {\n    frame_system::GenesisConfig::<Test>::default()\n        .build_storage()\n        .unwrap()\n        .into()\n}\n\n```\n\nExplanation of the additions:\n\n- **System pallet configuration**: Implements the `frame_system::Config` trait for the mock runtime, setting up the basic system functionality and specifying the block type.\n- **Custom pallet configuration**: Defines the `Config` trait for the `custom-pallet`, including a constant (`CounterMaxValue`) to set the maximum allowed counter value. In this case, that value is set to 10 for testing purposes.\n- **Test externalities initialization**: The `new_test_ext()` function initializes the mock runtime with default configurations, creating a controlled environment for testing."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 4, "depth": 3, "title": "Full Mocked Runtime", "anchor": "full-mocked-runtime", "start_char": 7124, "end_char": 10654, "estimated_token_count": 723, "token_estimator": "heuristic-v1", "text": "### Full Mocked Runtime\n\nExpand the following item to see the complete `mock.rs` implementation for the mock runtime.\n\n??? code \"mock.rs\"\n\n    ```rust title=\"mock.rs\"\n    -use crate as custom_pallet;\nuse frame::{prelude::*, runtime::prelude::*, testing_prelude::*};\n\ntype Block = frame_system::mocking::MockBlock<Test>;\n\n// Configure a mock runtime to test the pallet.\n#[frame_construct_runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n        RuntimeCall,\n        RuntimeEvent,\n        RuntimeError,\n        RuntimeOrigin,\n        RuntimeFreezeReason,\n        RuntimeHoldReason,\n        RuntimeSlashReason,\n        RuntimeLockId,\n        RuntimeTask\n    )]\n    pub struct Test;\n\n    #[runtime::pallet_index(0)]\n    pub type System = frame_system;\n\n    #[runtime::pallet_index(1)]\n    pub type CustomPallet = custom_pallet;\n}\n\n// System pallet configuration\n#[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\nimpl frame_system::Config for Test {\n    type Block = Block;\n}\n\n// Custom pallet configuration\nparameter_types! {\n    pub const CounterMaxValue: u32 = 10;\n}\n\nimpl custom_pallet::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = CounterMaxValue;\n    -// This file is part of 'custom-pallet'.\n\n// SPDX-License-Identifier: MIT-0\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\nuse crate as custom_pallet;\nuse frame::{prelude::*, runtime::prelude::*, testing_prelude::*};\n\ntype Block = frame_system::mocking::MockBlock<Test>;\n\n// Configure a mock runtime to test the pallet.\n#[frame_construct_runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n        RuntimeCall,\n        RuntimeEvent,\n        RuntimeError,\n        RuntimeOrigin,\n        RuntimeFreezeReason,\n        RuntimeHoldReason,\n        RuntimeSlashReason,\n        RuntimeLockId,\n        RuntimeTask\n    )]\n    pub struct Test;\n\n    #[runtime::pallet_index(0)]\n    pub type System = frame_system;\n\n    #[runtime::pallet_index(1)]\n    pub type CustomPallet = custom_pallet;\n}\n\n// System pallet configuration\n#[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\nimpl frame_system::Config for Test {\n    type Block = Block;\n}\n\n// Custom pallet configuration\nparameter_types! {\n    pub const CounterMaxValue: u32 = 10;\n}\n\nimpl custom_pallet::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = CounterMaxValue;\n    type WeightInfo = custom_pallet::weights::SubstrateWeight<Test>;\n}\n\n// Test externalities initialization\npub fn new_test_ext() -> TestExternalities {\n    frame_system::GenesisConfig::<Test>::default()\n        .build_storage()\n        .unwrap()\n        .into()\n}\n\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 5, "depth": 2, "title": "Implement Test Cases", "anchor": "implement-test-cases", "start_char": 10654, "end_char": 15136, "estimated_token_count": 909, "token_estimator": "heuristic-v1", "text": "## Implement Test Cases\n\nUnit testing a pallet involves creating a comprehensive test suite that validates various scenarios. You ensure your pallet’s reliability, security, and expected behavior under different conditions by systematically testing successful operations, error handling, event emissions, state modifications, and access control.\n\nExpand the following item to see the pallet calls to be tested.\n\n??? code \"Custom pallet calls\"\n\n    ```rust\n    -    #[pallet::call]\n    impl<T: Config> Pallet<T> {\n        /// Set the value of the counter.\n        ///\n        /// The dispatch origin of this call must be _Root_.\n        ///\n        /// - `new_value`: The new value to set for the counter.\n        ///\n        /// Emits `CounterValueSet` event when successful.\n        #[pallet::call_index(0)]\n        #[pallet::weight(0)]\n        -        pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n            ensure_root(origin)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            Self::deposit_event(Event::<T>::CounterValueSet {\n                counter_value: new_value,\n            });\n\n            Ok(())\n        }\n\n        /// Increment the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_increment`: The amount by which to increment the counter.\n        ///\n        /// Emits `CounterIncremented` event when successful.\n        #[pallet::call_index(1)]\n        #[pallet::weight(0)]\n        -        pub fn increment(origin: OriginFor<T>, amount_to_increment: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_add(amount_to_increment)\n                .ok_or(Error::<T>::CounterOverflow)?;\n\n            ensure!(\n                new_value <= T::CounterMaxValue::get(),\n                Error::<T>::CounterValueExceedsMax\n            );\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterIncremented {\n                counter_value: new_value,\n                who,\n                incremented_amount: amount_to_increment,\n            });\n\n            Ok(())\n        }\n\n        /// Decrement the counter by a specified amount.\n        ///\n        /// This function can be called by any signed account.\n        ///\n        /// - `amount_to_decrement`: The amount by which to decrement the counter.\n        ///\n        /// Emits `CounterDecremented` event when successful.\n        #[pallet::call_index(2)]\n        #[pallet::weight(0)]\n    -        pub fn decrement(origin: OriginFor<T>, amount_to_decrement: u32) -> DispatchResult {\n            let who = ensure_signed(origin)?;\n\n            let current_value = CounterValue::<T>::get().unwrap_or(0);\n\n            let new_value = current_value\n                .checked_sub(amount_to_decrement)\n                .ok_or(Error::<T>::CounterValueBelowZero)?;\n\n            CounterValue::<T>::put(new_value);\n\n            UserInteractions::<T>::try_mutate(&who, |interactions| -> Result<_, Error<T>> {\n                let new_interactions = interactions\n                    .unwrap_or(0)\n                    .checked_add(1)\n                    .ok_or(Error::<T>::UserInteractionOverflow)?;\n                *interactions = Some(new_interactions); // Store the new value.\n\n                Ok(())\n            })?;\n\n            Self::deposit_event(Event::<T>::CounterDecremented {\n                counter_value: new_value,\n                who,\n                decremented_amount: amount_to_decrement,\n            });\n\n            Ok(())\n        }\n    }\n}\n    ```\n\nThe following sub-sections outline various scenarios in which the `custom-pallet` can be tested. Feel free to add these snippets to your `tests.rs` while you read the examples."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 6, "depth": 3, "title": "Successful Operations", "anchor": "successful-operations", "start_char": 15136, "end_char": 16025, "estimated_token_count": 174, "token_estimator": "heuristic-v1", "text": "### Successful Operations\n\nVerify that the counter can be successfully incremented under normal conditions, ensuring the increment works and the correct event is emitted.\n\n```rust title=\"tests.rs\"\n-// Test successful counter increment\n#[test]\nfn it_works_for_increment() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Initialize the counter value to 0\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 0));\n\n        // Increment the counter by 5\n        assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(1), 5));\n        // Check that the event emitted matches the increment operation\n        System::assert_last_event(\n            Event::CounterIncremented {\n                counter_value: 5,\n                who: 1,\n                incremented_amount: 5,\n            }\n            .into(),\n        );\n    });\n}\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 7, "depth": 3, "title": "Preventing Value Overflow", "anchor": "preventing-value-overflow", "start_char": 16025, "end_char": 16801, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "### Preventing Value Overflow\n\nTest that the pallet prevents incrementing beyond the maximum allowed value, protecting against unintended state changes.\n\n```rust title=\"tests.rs\"\n-// Verify increment is blocked when it would exceed max value\n#[test]\nfn increment_fails_for_max_value_exceeded() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Set counter value close to max (10)\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 7));\n        // Ensure that incrementing by 4 exceeds max value (10) and fails\n        assert_noop!(\n            CustomPallet::increment(RuntimeOrigin::signed(1), 4),\n            Error::<Test>::CounterValueExceedsMax // Expecting CounterValueExceedsMax error\n        );\n    });\n}\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 8, "depth": 3, "title": "Origin and Access Control", "anchor": "origin-and-access-control", "start_char": 16801, "end_char": 17462, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "### Origin and Access Control\n\nConfirm that sensitive operations like setting counter value are restricted to authorized origins, preventing unauthorized modifications.\n\n```rust title=\"tests.rs\"\n-// Ensure non-root accounts cannot set counter value\n#[test]\nfn set_counter_value_fails_for_non_root() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Ensure only root (privileged account) can set counter value\n        assert_noop!(\n            CustomPallet::set_counter_value(RuntimeOrigin::signed(1), 5), // non-root account\n            sp_runtime::traits::BadOrigin // Expecting a BadOrigin error\n        );\n    });\n}\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 9, "depth": 3, "title": "Edge Case Handling", "anchor": "edge-case-handling", "start_char": 17462, "end_char": 18058, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "### Edge Case Handling\n\nEnsure the pallet gracefully handles edge cases, such as preventing increment operations that would cause overflow.\n\n```rust title=\"tests.rs\"\n-// Ensure increment fails on u32 overflow\n#[test]\nfn increment_handles_overflow() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Set to max value\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 1));\n        assert_noop!(\n            CustomPallet::increment(RuntimeOrigin::signed(1), u32::MAX),\n            Error::<Test>::CounterOverflow\n        );\n    });\n}\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 10, "depth": 3, "title": "Verify State Changes", "anchor": "verify-state-changes", "start_char": 18058, "end_char": 18913, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "### Verify State Changes\n\nTest that pallet operations modify the internal state correctly and maintain expected storage values across different interactions.\n\n```rust title=\"tests.rs\"\n-// Check that user interactions are correctly tracked\n#[test]\nfn user_interactions_increment() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Initialize counter value to 0\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 0));\n\n        // Increment by 5 and decrement by 2\n        assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(1), 5));\n        assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(1), 2));\n\n        // Check if the user interactions are correctly tracked\n        assert_eq!(UserInteractions::<Test>::get(1).unwrap_or(0), 2); // User should have 2 interactions\n    });\n}\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 11, "depth": 3, "title": "Full Test Suite", "anchor": "full-test-suite", "start_char": 18913, "end_char": 25885, "estimated_token_count": 1486, "token_estimator": "heuristic-v1", "text": "### Full Test Suite\n\nExpand the following item to see the complete `tests.rs` implementation for the custom pallet.\n\n??? code \"tests.rs\"\n\n    ```rust title=\"tests.rs\"\n    -// This file is part of 'custom-pallet'.\n\n// SPDX-License-Identifier: MIT-0\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\nuse crate::{mock::*, Error, Event, UserInteractions};\nuse frame::deps::sp_runtime;\nuse frame::testing_prelude::*;\n\n// Verify root can successfully set counter value\n#[test]\nfn it_works_for_set_counter_value() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Set counter value within max allowed (10)\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 5));\n        // Ensure that the correct event is emitted when the value is set\n        System::assert_last_event(Event::CounterValueSet { counter_value: 5 }.into());\n    });\n}\n\n// Ensure non-root accounts cannot set counter value\n#[test]\nfn set_counter_value_fails_for_non_root() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Ensure only root (privileged account) can set counter value\n        assert_noop!(\n            CustomPallet::set_counter_value(RuntimeOrigin::signed(1), 5), // non-root account\n            sp_runtime::traits::BadOrigin // Expecting a BadOrigin error\n        );\n    });\n}\n\n// Check that setting value above max is prevented\n#[test]\nfn set_counter_value_fails_for_max_value_exceeded() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Ensure the counter value cannot be set above the max limit (10)\n        assert_noop!(\n            CustomPallet::set_counter_value(RuntimeOrigin::root(), 11),\n            Error::<Test>::CounterValueExceedsMax // Expecting CounterValueExceedsMax error\n        );\n    });\n}\n\n// Test successful counter increment\n#[test]\nfn it_works_for_increment() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Initialize the counter value to 0\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 0));\n\n        // Increment the counter by 5\n        assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(1), 5));\n        // Check that the event emitted matches the increment operation\n        System::assert_last_event(\n            Event::CounterIncremented {\n                counter_value: 5,\n                who: 1,\n                incremented_amount: 5,\n            }\n            .into(),\n        );\n    });\n}\n\n// Verify increment is blocked when it would exceed max value\n#[test]\nfn increment_fails_for_max_value_exceeded() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Set counter value close to max (10)\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 7));\n        // Ensure that incrementing by 4 exceeds max value (10) and fails\n        assert_noop!(\n            CustomPallet::increment(RuntimeOrigin::signed(1), 4),\n            Error::<Test>::CounterValueExceedsMax // Expecting CounterValueExceedsMax error\n        );\n    });\n}\n\n// Ensure increment fails on u32 overflow\n#[test]\nfn increment_handles_overflow() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Set to max value\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 1));\n        assert_noop!(\n            CustomPallet::increment(RuntimeOrigin::signed(1), u32::MAX),\n            Error::<Test>::CounterOverflow\n        );\n    });\n}\n\n// Test successful counter decrement\n#[test]\nfn it_works_for_decrement() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Initialize counter value to 8\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 8));\n\n        // Decrement counter by 3\n        assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(1), 3));\n        // Ensure the event matches the decrement action\n        System::assert_last_event(\n            Event::CounterDecremented {\n                counter_value: 5,\n                who: 1,\n                decremented_amount: 3,\n            }\n            .into(),\n        );\n    });\n}\n\n// Verify decrement is blocked when it would go below zero\n#[test]\nfn decrement_fails_for_below_zero() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Set counter value to 5\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 5));\n        // Ensure that decrementing by 6 fails as it would result in a negative value\n        assert_noop!(\n            CustomPallet::decrement(RuntimeOrigin::signed(1), 6),\n            Error::<Test>::CounterValueBelowZero // Expecting CounterValueBelowZero error\n        );\n    });\n}\n\n// Check that user interactions are correctly tracked\n#[test]\nfn user_interactions_increment() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Initialize counter value to 0\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 0));\n\n        // Increment by 5 and decrement by 2\n        assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(1), 5));\n        assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(1), 2));\n\n        // Check if the user interactions are correctly tracked\n        assert_eq!(UserInteractions::<Test>::get(1).unwrap_or(0), 2); // User should have 2 interactions\n    });\n}\n\n// Ensure user interactions prevent overflow\n#[test]\nfn user_interactions_overflow() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Initialize counter value to 0\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 0));\n\n        // Set user interactions to max value (u32::MAX)\n        UserInteractions::<Test>::insert(1, u32::MAX);\n        // Ensure that incrementing by 5 fails due to overflow in user interactions\n        assert_noop!(\n            CustomPallet::increment(RuntimeOrigin::signed(1), 5),\n            Error::<Test>::UserInteractionOverflow // Expecting UserInteractionOverflow error\n        );\n    });\n}\n\n    ```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 12, "depth": 2, "title": "Run the Tests", "anchor": "run-the-tests", "start_char": 25885, "end_char": 27226, "estimated_token_count": 299, "token_estimator": "heuristic-v1", "text": "## Run the Tests\n\nExecute the test suite for your custom pallet using Cargo's test command. This will run all defined test cases and provide detailed output about the test results.\n\n```bash\ncargo test --package custom-pallet\n```\n\nAfter running the test suite, you should see the following output in your terminal:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>cargo test --package custom-pallet</span>\n  <pre>\nrunning 12 tests\ntest mock::__construct_runtime_integrity_test::runtime_integrity_tests ... ok\ntest mock::test_genesis_config_builds ... ok\ntest test::set_counter_value_fails_for_max_value_exceeded ... ok\ntest test::set_counter_value_fails_for_non_root ... ok\ntest test::user_interactions_increment ... ok\ntest test::it_works_for_increment ... ok\ntest test::it_works_for_set_counter_value ... ok\ntest test::it_works_for_decrement ... ok\ntest test::increment_handles_overflow ... ok\ntest test::decrement_fails_for_below_zero ... ok\ntest test::increment_fails_for_max_value_exceeded ... ok\ntest test::user_interactions_overflow ... ok\ntest result: ok. 12 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\nDoc-tests custom_pallet\nrunning 0 tests\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n    </pre\n  >\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-pallet-unit-testing", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 27226, "end_char": 27586, "estimated_token_count": 96, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Add Pallets to the Runtime__\n\n    ---\n\n    Learn how to add and integrate custom pallets in your Polkadot SDK-based blockchain\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/add-pallets-to-runtime/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 789, "estimated_token_count": 140, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUpgrading the runtime of your Polkadot SDK-based blockchain is a fundamental feature that allows you to add new functionality, fix bugs, or improve performance without requiring a hard fork. Runtime upgrades are performed by submitting a special extrinsic that replaces the existing on-chain WASM runtime code. This process is trustless, transparent, and can be executed either through governance or using sudo, depending on your chain's configuration.\n\nThis tutorial will guide you through the steps to prepare, submit, and verify a runtime upgrade for your parachain or standalone Polkadot SDK-based chain. For this example, you'll continue from the state left by the previous tutorials, where you have a custom pallet integrated into your runtime."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 1, "depth": 2, "title": "Update the Runtime", "anchor": "update-the-runtime", "start_char": 789, "end_char": 948, "estimated_token_count": 30, "token_estimator": "heuristic-v1", "text": "## Update the Runtime\n\nIn this section, you will add a new feature to your existing custom pallet and upgrade your runtime to include this new functionality."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 2, "depth": 3, "title": "Start Your Chain", "anchor": "start-your-chain", "start_char": 948, "end_char": 1585, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "### Start Your Chain\n\nBefore making any changes, ensure your blockchain node is running properly:\n\n```bash\npolkadot-omni-node --chain ./chain_spec.json --dev\n```\n\nVerify your chain is operational and note the runtime version state in Polkadot JS. For more details, check the [Interact with the Node](/tutorials/polkadot-sdk/parachains/zero-to-hero/set-up-a-template/#interact-with-the-node){target=\\_blank}.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-01.webp)\n\nAs you can see, the runtime version is `1` since this chain has not been upgraded. Keep this chain running in the background."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 3, "depth": 3, "title": "Add a New Feature", "anchor": "add-a-new-feature", "start_char": 1585, "end_char": 4387, "estimated_token_count": 632, "token_estimator": "heuristic-v1", "text": "### Add a New Feature\n\nNow, you can extend your existing custom pallet by adding a new dispatchable function to reset the counter to zero. This provides a meaningful upgrade that demonstrates new functionality. Copy and paste the following code at the end of your `lib.rs` file in your custom pallet:\n\n```rust title=\"custom-pallet/src/lib.rs\" hl_lines=\"5-17\"\n#[pallet::call]\nimpl<T: Config> Pallet<T> {\n    // ... existing calls like increment, decrement, etc.\n\n    /// Reset the counter to zero.\n    ///\n    /// The dispatch origin of this call must be _Root_.\n    ///\n    /// Emits `CounterValueSet` event when successful.\n    #[pallet::call_index(3)]\n    #[pallet::weight(0)]\n    pub fn reset_counter(origin: OriginFor<T>) -> DispatchResult {\n        ensure_root(origin)?;\n        <CounterValue<T>>::put(0u32);\n        Self::deposit_event(Event::CounterValueSet { counter_value: 0 });\n        Ok(())\n    }\n}\n```\n\nThe `reset_counter` function will be a Root-only operation that sets the counter value back to zero, regardless of its current state. This is useful for administrative purposes, such as clearing the counter after maintenance, testing, or at the start of new periods. Unlike the existing increment/decrement functions that any signed user can call, this reset function requires Root privileges, making it a controlled administrative action.\n\nEnsure that your runtime compiles by running:\n\n```bash\ncargo build --release\n```\n\nNow, you can test this new function in `pallets/custom-pallet/src/tests.rs`\n\n```rust title=\"custom-pallet/src/tests.rs\" hl_lines=\"4-39\"\n// ... existing unit tests\n...\n\n#[test]\nfn reset_counter_works() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // First increment the counter\n        assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(1), 1));\n\n        // Ensure the event matches the increment action\n        System::assert_last_event(\n            Event::CounterIncremented {\n                counter_value: 1,\n                who: 1,\n                incremented_amount: 1,\n            }\n            .into(),\n        );\n        \n        // Reset should work with root origin\n        assert_ok!(CustomPallet::reset_counter(RuntimeOrigin::root()));\n        \n        // Check that the event was emitted\n        System::assert_last_event(Event::CounterValueSet { counter_value: 0 }.into());\n    });\n}\n\n#[test]\nfn reset_counter_fails_without_root() {\n    new_test_ext().execute_with(|| {\n        System::set_block_number(1);\n        // Should fail with non-root origin\n        assert_noop!(\n            CustomPallet::reset_counter(RuntimeOrigin::signed(1)),\n            sp_runtime::DispatchError::BadOrigin\n        );\n    });\n}\n```\n\nEnsure that your tests pass by running:\n\n```bash\ncargo test --package custom-pallet\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 4, "depth": 3, "title": "Update Runtime Configuration", "anchor": "update-runtime-configuration", "start_char": 4387, "end_char": 4719, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "### Update Runtime Configuration\n\nSince you've only added new functionality without changing existing APIs, minimal runtime changes are needed. However, verify that your runtime configuration is still compatible. If you've added new configuration parameters to your pallet, update them accordingly in the `runtime/configs/mod.rs`."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 5, "depth": 3, "title": "Bump the Runtime Version", "anchor": "bump-the-runtime-version", "start_char": 4719, "end_char": 5813, "estimated_token_count": 281, "token_estimator": "heuristic-v1", "text": "### Bump the Runtime Version\n\nThis is a critical step - you must increment the runtime version numbers to signal that an upgrade has occurred. In `runtime/src/lib.rs`:\n\n```rust title=\"lib.rs\" hl_lines=\"6\"\n#[sp_version::runtime_version]\npub const VERSION: RuntimeVersion = RuntimeVersion {\n\tspec_name: alloc::borrow::Cow::Borrowed(\"parachain-template-runtime\"),\n\timpl_name: alloc::borrow::Cow::Borrowed(\"parachain-template-runtime\"),\n\tauthoring_version: 1,\n    spec_version: 2, // <-- increment this (was 1)\n\timpl_version: 0,\n\tapis: apis::RUNTIME_API_VERSIONS,\n\ttransaction_version: 1,\n\tsystem_version: 1,\n};\n```\n\nAlso update `runtime/Cargo.toml` version:\n\n```toml title=\"Cargo.toml\" hl_lines=\"4\"\n[package]\nname = \"parachain-template-runtime\"\ndescription = \"A parachain runtime template built with Substrate and Cumulus, part of Polkadot Sdk.\"\nversion = \"0.2.0\" # <-- increment this version\n# ... rest of your Cargo.toml\n```\n\nFor more information about runtime versioning, check the [Runtime Upgrades](/develop/parachains/maintenance/runtime-upgrades#runtime-versioning){target=\\_blank} guide."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 6, "depth": 3, "title": "Build the New Runtime", "anchor": "build-the-new-runtime", "start_char": 5813, "end_char": 6635, "estimated_token_count": 218, "token_estimator": "heuristic-v1", "text": "### Build the New Runtime\n\n1. Navigate to your project root:\n\n    ```bash\n    cd /path/to/your/parachain-template\n    ```\n\n2. Build the new runtime:\n\n    ```bash\n    cargo build --release\n    ```\n\n3. Verify that you have the proper WASM builds by executing:\n\n    ```\n    ls -la target/release/wbuild/parachain-template-runtime/\n    ```\n\nIf you can see the following elements, it means that you are ready to submit the runtime upgrade to your running chain:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>ls -la target/release/wbuild/parachain-template-runtime/</span>\n  <br />\n  <span data-ty>parachain_template_runtime.wasm</span>\n  <span data-ty>parachain_template_runtime.compact.wasm</span>\n  <span data-ty>parachain_template_runtime.compact.compressed.wasm</span>\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 7, "depth": 2, "title": "Submit the Runtime Upgrade", "anchor": "submit-the-runtime-upgrade", "start_char": 6635, "end_char": 8662, "estimated_token_count": 521, "token_estimator": "heuristic-v1", "text": "## Submit the Runtime Upgrade\n\nYou can submit a runtime upgrade using the [Sudo pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_sudo/index.html){target=\\_blank} (for development chains) or via on-chain governance (for production chains).\n\n1. Open [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} and connect to your node.\n2. Click on the **Developer** and select the **Extrinsics** option in the dropdown.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-02.webp) \n\n3. Prepare the **sudo** call:\n\n    1. Select the **sudo** pallet.\n    2. Select the **sudo(call)** extrinsic from the list.\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-03.webp) \n\n4. In the **sudo** call:\n\n    1. Select the **system** call.\n    2. Select **setCode** extrinsic from the list.\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-04.webp) \n\n5. For the `code` parameter, click **file upload** and select your WASM runtime file:\n\n    - Use `parachain_template_runtime.compact.compressed.wasm` if available (smaller file).\n    - Otherwise, use `parachain_template_runtime.wasm`.\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-05.webp) \n\n6. Click **Submit Transaction** and sign the transaction with the sudo key.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-06.webp) \n\n!!!info \"Using Governance (Production)\"\n    For production chains with governance enabled, you must follow the on-chain democratic process. This involves submitting a preimage of the new runtime code (using the Democracy pallet), referencing the preimage hash in a proposal, and then following your chain's governance process (such as voting and council approval) until the proposal passes and is enacted. This ensures that runtime upgrades are transparent and subject to community oversight."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 8, "depth": 2, "title": "Verify the Upgrade", "anchor": "verify-the-upgrade", "start_char": 8662, "end_char": 8786, "estimated_token_count": 23, "token_estimator": "heuristic-v1", "text": "## Verify the Upgrade\n\nAfter the runtime upgrade extrinsic is included in a block, verify that the upgrade was successful."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 9, "depth": 3, "title": "Check Runtime Version", "anchor": "check-runtime-version", "start_char": 8786, "end_char": 9683, "estimated_token_count": 253, "token_estimator": "heuristic-v1", "text": "### Check Runtime Version\n\n1. In Polkadot.js Apps, navigate to the **Chain State** section:\n\n    1. Click the **Developer** dropdown.\n    2. Click the **Chain State** option.\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-07.webp) \n\n2. Query runtime spec version:\n\n    1. Select the **System** pallet.\n    2. Select the **lastRuntimeUpgrade()** query.\n\n        ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-08.webp) \n\n3. Click the **+** button to query the current runtime version.\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-09.webp) \n\n4. Verify that the `specVersion` matches your new runtime (should be `2` if you followed the example).\n\n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-10.webp)"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 10, "depth": 3, "title": "Test New Functionality", "anchor": "test-new-functionality", "start_char": 9683, "end_char": 10192, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "### Test New Functionality\n\n1. Navigate to **Developer > Extrinsics**.\n2. Select your custom pallet from the dropdown.\n3. You should now see the new `resetCounter` function available.\n\n![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/runtime-upgrade/runtime-upgrade-11.webp) \n\nNow, you can test the new functionality:\n\n- First, increment the counter using your existing function.\n- Then use the new reset function (note: You'll need sudo/root privileges).\n- Verify the counter value is reset to 0."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-runtime-upgrade", "index": 11, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10192, "end_char": 10596, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Deploy on Paseo TestNet__\n\n    ---\n\n    Deploy your Polkadot SDK blockchain on Paseo! Follow this step-by-step guide for a seamless journey to a successful TestNet deployment.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/deploy-to-testnet/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 1229, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Polkadot SDK](https://github.com/paritytech/polkadot-sdk){target=\\_blank} offers a versatile and extensible blockchain development framework, enabling you to create custom blockchains tailored to your specific application or business requirements. \n\nThis tutorial guides you through compiling and running a parachain node using the [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk/tree/master/templates/parachain){target=\\_blank}.\n\nThe parachain template provides a pre-configured, functional runtime you can use in your local development environment. It includes several key components, such as user accounts and account balances.\n\nThese predefined elements allow you to experiment with common blockchain operations without requiring initial template modifications.\nIn this tutorial, you will:\n\n- Build and start a local parachain node using the node template.\n- Explore how to use a front-end interface to:\n    - View information about blockchain activity.\n    - Submit a transaction.\n\nBy the end of this tutorial, you'll have a working local parachain and understand how to interact with it, setting the foundation for further customization and development."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1229, "end_char": 1952, "estimated_token_count": 172, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have done the following:\n\n- Completed the [Install Polkadot SDK Dependencies](/develop/parachains/install-polkadot-sdk/){target=\\_blank} guide and successfully installed [Rust](https://www.rust-lang.org/){target=\\_blank} and the required packages to set up your development environment.\n\nFor this tutorial series, you need to use Rust `1.86`. Newer versions of the compiler may not work with this parachain template version.\n\nRun the following commands to set up the correct Rust version:\n\n```bash\nrustup default 1.86\nrustup target add wasm32-unknown-unknown --toolchain 1.86-aarch64-apple-darwin\nrustup component add rust-src --toolchain 1.86-aarch64-apple-darwin\n```"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 2, "depth": 2, "title": "Utility Tools", "anchor": "utility-tools", "start_char": 1952, "end_char": 3108, "estimated_token_count": 289, "token_estimator": "heuristic-v1", "text": "## Utility Tools\n\nThis tutorial requires two essential tools:\n\n- [**Chain spec builder**](https://crates.io/crates/staging-chain-spec-builder/10.0.0){target=\\_blank}: A Polkadot SDK utility for generating chain specifications. Refer to the [Generate Chain Specs](/develop/parachains/deployment/generate-chain-specs/){target=\\_blank} documentation for detailed usage.\n    \n    Install it by executing the following command:\n    \n    ```bash\n    cargo install --locked staging-chain-spec-builder@10.0.0\n    ```\n\n    This installs the `chain-spec-builder` binary.\n\n- [**Polkadot Omni Node**](https://crates.io/crates/polkadot-omni-node/0.5.0){target=\\_blank}: A white-labeled binary, released as a part of Polkadot SDK that can act as the collator of a parachain in production, with all the related auxiliary functionalities that a normal collator node has: RPC server, archiving state, etc. Moreover, it can also run the wasm blob of the parachain locally for testing and development.\n\n    To install it, run the following command:\n\n    ```bash\n    cargo install --locked polkadot-omni-node@0.5.0\n    ```\n\n    This installs the `polkadot-omni-node` binary."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 3, "depth": 2, "title": "Compile the Runtime", "anchor": "compile-the-runtime", "start_char": 3108, "end_char": 4773, "estimated_token_count": 443, "token_estimator": "heuristic-v1", "text": "## Compile the Runtime\n\nThe [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk/tree/master/templates/parachain){target=\\_blank} provides a ready-to-use development environment for building using the [Polkadot SDK](https://github.com/paritytech/polkadot-sdk){target=\\_blank}. Follow these steps to compile the runtime:\n\n1. Clone the template repository:\n\n    ```bash\n    git clone -b v0.0.4 https://github.com/paritytech/polkadot-sdk-parachain-template.git parachain-template\n    ```\n\n2. Navigate into the project directory:\n\n    ```bash\n    cd parachain-template\n    ```\n\n3. Compile the runtime:\n\n    ```bash\n    cargo build --release --locked\n    ```\n\n    !!!tip\n        Initial compilation may take several minutes, depending on your machine specifications. Use the `--release` flag for improved runtime performance compared to the default `--debug` build. If you need to troubleshoot issues, the `--debug` build provides better diagnostics.\n        \n        For production deployments, consider using a dedicated [`--profile production`](https://github.com/paritytech/polkadot-sdk-parachain-template/blob/v0.0.4/Cargo.toml#L42-L45){target=\\_blank} flag - this can provide an additional 15-30% performance improvement over the standard `--release` profile.\n\n4. Upon successful compilation, you should see output similar to:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>cargo build --release --locked</span>\n  <span data-ty>...</span>\n  <span data-ty>Finished `release` profile [optimized] target(s) in 1.79s</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 4, "depth": 2, "title": "Start the Local Chain", "anchor": "start-the-local-chain", "start_char": 4773, "end_char": 9622, "estimated_token_count": 1401, "token_estimator": "heuristic-v1", "text": "## Start the Local Chain\n\nAfter successfully compiling your runtime, you can spin up a local chain and produce blocks. This process will start your local parachain and allow you to interact with it. You'll first need to generate a chain specification that defines your network's identity, initial connections, and genesis state, providing the foundational configuration for how your nodes connect and what initial state they agree upon, and then run the chain. \n\nFollow these steps to launch your node in development mode:\n\n1. Generate the chain specification file of your parachain:\n\n    ```bash\n    chain-spec-builder create -t development \\\n    --relay-chain paseo \\\n    --para-id 1000 \\\n    --runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    named-preset development\n    ```\n\n2. Start the omni node with the generated chain spec. You'll start it in development mode (without a relay chain config), producing and finalizing blocks:\n\n    ```bash\n    polkadot-omni-node --chain ./chain_spec.json --dev\n    ```\n\n    The `--dev` option does the following:\n\n    - Deletes all active data (keys, blockchain database, networking information) when stopped.\n    - Ensures a clean working state each time you restart the node.\n\n3. Verify that your node is running by reviewing the terminal output. You should see something similar to:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot-omni-node --chain ./chain_spec.json --dev</span>\n  <br />\n  <span data-ty>2024-12-12 12:44:02 polkadot-omni-node</span>\n  <span data-ty>2024-12-12 12:44:02 ✌️ version 0.1.0-da2dd9b7737</span>\n  <span data-ty>2024-12-12 12:44:02 ❤️ by Parity Technologies admin@parity.io, 2017-2024</span>\n  <span data-ty>2024-12-12 12:44:02 📋 Chain specification: Custom</span>\n  <span data-ty>2024-12-12 12:44:02 🏷 Node name: grieving-drum-1926</span>\n  <span data-ty>2024-12-12 12:44:02 👤 Role: AUTHORITY</span>\n  <span data-ty>2024-12-12 12:44:02 💾 Database: RocksDb at /var/folders/x0/xl_kjddj3ql3bx7752yr09hc0000gn/T/substrateoUrZMQ/chains/custom/db/full</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] assembling new collators for new session 0 at #0</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] assembling new collators for new session 1 at #0</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] 🔨 Initializing Genesis block/state (state: 0xa6f8…5b46, header-hash: 0x0579…2153)</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] creating SingleState txpool Limit { count: 8192, total_bytes: 20971520 }/Limit { count: 819, total_bytes: 2097152 }.</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] Using default protocol ID \"sup\" because none is configured in the chain specs</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] 🏷 Local node identity is: 12D3KooWCSXy6rBuJVsn5mx8uyNqkdfNfFzEbToi4hR31v3PwdgX</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] Running libp2p network backend</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] 💻 Operating system: macos</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] 💻 CPU architecture: aarch64</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] 📦 Highest known block at #0</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] 〽️ Prometheus exporter started at 127.0.0.1:9615</span>\n  <span data-ty>2024-12-12 12:44:03 [Parachain] Running JSON-RPC server: addr=127.0.0.1:9944,[::1]:9944</span>\n  <span data-ty>2024-12-12 12:44:06 [Parachain] 🙌 Starting consensus session on top of parent 0x05794f9adcdaa23a5edd335e8310637d3a7e6e9393f2b0794af7d3e219f62153 (#0)</span>\n  <span data-ty>2024-12-12 12:44:06 [Parachain] 🎁 Prepared block for proposing at 1 (2 ms) hash: 0x6fbea46711e9b38bab8e7877071423cd03feab03d3f4a0d578a03ab42dcee34b; parent_hash: 0x0579…2153; end: NoMoreTransactions; extrinsics_count: 2</span>\n  <span data-ty>2024-12-12 12:44:06 [Parachain] 🏆 Imported #1 (0x0579…2153 → 0x6fbe…e34b)</span>\n  <span data-ty>...</span>\n</div>\n\n\n4. Confirm that your blockchain is producing new blocks by checking if the number after `finalized` is increasing.\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty>...</span>\n  <span data-ty>2024-12-12 12:49:20 [Parachain] 💤 Idle (0 peers), best: #1 (0x6fbe…e34b), finalized #1 (0x6fbe…e34b), ⬇ 0 ⬆ 0</span>\n  <span data-ty>...</span>\n  <span data-ty>2024-12-12 12:49:25 [Parachain] 💤 Idle (0 peers), best: #3 (0x7543…bcfc), finalized #3 (0x7543…bcfc), ⬇ 0 ⬆ 0</span>\n  <span data-ty>...</span>\n  <span data-ty>2024-12-12 12:49:30 [Parachain] 💤 Idle (0 peers), best: #4 (0x0478…8d63), finalized #4 (0x0478…8d63), ⬇ 0 ⬆ 0</span>\n  <span data-ty>...</span>\n</div>\n\n\nThe details of the log output will be explored in a later tutorial. For now, knowing that your node is running and producing blocks is sufficient."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 5, "depth": 2, "title": "Interact with the Node", "anchor": "interact-with-the-node", "start_char": 9622, "end_char": 11243, "estimated_token_count": 446, "token_estimator": "heuristic-v1", "text": "## Interact with the Node\n\nWhen running the template node, it's accessible by default at `ws://localhost:9944`. To interact with your node using the [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} interface, follow these steps:\n\n1. Open [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} in your web browser and click the network icon (which should be the Polkadot logo) in the top left corner as shown in the image below:\n    \n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/set-up-a-template/set-up-a-template-1.webp)\n\n2. Connect to your local node:\n\n    1. Scroll to the bottom and select **Development**.\n    2. Choose **Custom**.\n    3. **Enter `ws**: //localhost:9944` in the input field.\n    4. Click the **Switch** button.\n    \n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/set-up-a-template/set-up-a-template-2.webp)\n\n3. Verify connection:\n\n    - Once connected, you should see **parachain-template-runtime** in the top left corner.\n    - The interface will display information about your local blockchain.\n    \n    ![](/images/tutorials/polkadot-sdk/parachains/zero-to-hero/set-up-a-template/set-up-a-template-3.webp)\n\nYou are now connected to your local node and can now interact with it through the Polkadot.js Apps interface. This tool enables you to explore blocks, execute transactions, and interact with your blockchain's features. For in-depth guidance on using the interface effectively, refer to the [Polkadot.js Guides](https://wiki.polkadot.com/general/polkadotjs/){target=\\_blank} available on the Polkadot Wiki."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 6, "depth": 2, "title": "Stop the Node", "anchor": "stop-the-node", "start_char": 11243, "end_char": 11749, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Stop the Node\n\nWhen you're done exploring your local node, you can stop it to remove any state changes you've made. Since you started the node with the `--dev` option, stopping the node will purge all persistent block data, allowing you to start fresh the next time.\n\nTo stop the local node:\n\n1. Return to the terminal window where the node output is displayed.\n2. Press `Control-C` to stop the running process.\n3. Verify that your terminal returns to the prompt in the `parachain-template` directory."}
{"page_id": "tutorials-polkadot-sdk-parachains-zero-to-hero-set-up-a-template", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 11749, "end_char": 12175, "estimated_token_count": 109, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Build a Custom Pallet__\n\n    ---\n\n    Build your own custom pallet for Polkadot SDK-based blockchains! Follow this step-by-step guide to create and configure a simple counter pallet from scratch.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/polkadot-sdk/parachains/zero-to-hero/build-custom-pallet/)\n\n</div>"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 31, "end_char": 791, "estimated_token_count": 182, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAsset Conversion is an Automated Market Maker (AMM) utilizing [Uniswap V2](https://github.com/Uniswap/v2-core){target=\\_blank} logic and implemented as a pallet on Polkadot's Asset Hub. For more details about this feature, please visit the [Asset Conversion on Asset Hub](/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/){target=\\_blank} wiki page.\n\nThis guide will provide detailed information about the key functionalities offered by the [Asset Conversion](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506/substrate/frame/asset-conversion){target=\\_blank} pallet on Asset Hub, including:\n\n- Creating a liquidity pool.\n- Adding liquidity to a pool.\n- Swapping assets.\n- Withdrawing liquidity from a pool."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 791, "end_char": 1521, "estimated_token_count": 181, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore converting assets on Asset Hub, you must ensure you have:\n\n- Access to the [Polkadot.js Apps](https://polkadot.js.org/apps){target=\\_blank} interface and a connection with the intended blockchain.\n- A funded wallet containing the assets you wish to convert and enough available funds to cover the transaction fees.\n- An asset registered on Asset Hub that you want to convert. If you haven't created an asset on Asset Hub yet, refer to the [Register a Local Asset](/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-asset/){target=\\_blank} or [Register a Foreign Asset](/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-asset/){target=\\_blank} documentation to create an asset."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 2, "depth": 2, "title": "Create a Liquidity Pool", "anchor": "create-a-liquidity-pool", "start_char": 1521, "end_char": 4593, "estimated_token_count": 711, "token_estimator": "heuristic-v1", "text": "## Create a Liquidity Pool\n\nIf an asset on Asset Hub does not have an existing liquidity pool, the first step is to create one.\n\nThe asset conversion pallet provides the `createPool` extrinsic to create a new liquidity pool, creating an empty liquidity pool and a new `LP token` asset.\n\n!!! tip\n    A testing token with the asset ID `1112` and the name `PPM` was created for this example.\n\nAs stated in the [Test Environment Setup](#test-environment-setup) section, this tutorial is based on the assumption that you have an instance of Polkadot Asset Hub running locally. Therefore, the demo liquidity pool will be created between DOT and PPM tokens. However, the same steps can be applied to any other asset on Asset Hub.\n\nFrom the Asset Hub perspective, the Multilocation that identifies the PPM token is the following:\n\n```javascript\n{\n  parents: 0,\n  interior: {\n    X2: [{ PalletInstance: 50 }, { GeneralIndex: 1112 }]\n  }\n}\n```\n\nThe `PalletInstance` value of `50` represents the Assets pallet on Asset Hub. The `GeneralIndex` value of `1112` is the PPM asset's asset ID.\n\nTo create the liquidity pool, you can follow these steps:\n\n1. Navigate to the **Extrinsics** section on the Polkadot.js Apps interface:\n\n    1. Select **Developer** from the top menu.\n    2. Click on **Extrinsics** from the dropdown menu.\n\n    ![Extrinsics Section](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-1.webp)\n\n2. Select extrinsic to create the pool:\n\n    1. Select the **`AssetConversion`** pallet.\n    2. Choose the **`createPool`** extrinsic from the list of available extrinsics.\n\n    ![Create Pool Extrinsic](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-2.webp)\n\n3. Fill in the required fields:\n\n    1. **`asset1`**: The Multilocation of the first asset in the pool. In this case, it is the DOT token, which the following Multilocation represents.\n\n        ```javascript\n        {\n          parents: 0,\n          interior: 'Here'\n        }\n        ```\n\n    2. **`asset2`**: The second asset's Multilocation within the pool. This refers to the PPM token, which the following Multilocation identifies.\n\n        ```javascript\n        {\n          parents: 0,\n          interior: {\n            X2: [{ PalletInstance: 50 }, { GeneralIndex: 1112 }]\n          }\n        }\n        ```\n\n    3. Click on **Submit Transaction** to create the liquidity pool.\n\n    ![Create Pool Fields](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-3.webp)\n\nSigning and submitting the transaction triggers the creation of the liquidity pool. To verify the new pool's creation, check the **Explorer** section on the Polkadot.js Apps interface and ensure that the **`PoolCreated`** event was emitted.\n\n![Pool Created Event](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-4.webp)\n\nAs the preceding image shows, the **`lpToken`** ID created for this pool is 19. This ID is essential to identify the liquidity pool and associated LP tokens."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 3, "depth": 2, "title": "Add Liquidity to a Pool", "anchor": "add-liquidity-to-a-pool", "start_char": 4593, "end_char": 7804, "estimated_token_count": 714, "token_estimator": "heuristic-v1", "text": "## Add Liquidity to a Pool\n\nThe `addLiquidity` extrinsic allows users to provide liquidity to a pool of two assets. Users specify their preferred amounts for both assets and minimum acceptable quantities. The function determines the best asset contribution, which may vary from the amounts desired but won't fall below the specified minimums. Providers receive liquidity tokens representing their pool portion in return for their contribution.\n\nTo add liquidity to a pool, follow these steps:\n\n1. Navigate to the **Extrinsics** section on the Polkadot.js Apps interface:\n\n    1. Select **Developer** from the top menu.\n    2. Click on **Extrinsics** from the dropdown menu.\n\n    ![Extrinsics Section](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-1.webp)\n\n2. Select extrinsic to add liqudity:\n\n    1. Select the **`assetConversion`** pallet.\n    2. Choose the **`addLiquidity`** extrinsic from the list of available extrinsics.\n\n    ![Add Liquidity Extrinsic](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-5.webp)\n\n3. Fill in the required fields:\n\n    1. **`asset1`**: The Multilocation of the first asset in the pool. In this case, it is the DOT token, which the following Multilocation represents.\n\n        ```javascript\n        {\n          parents: 0,\n          interior: 'Here'\n        }\n        ```\n\n    2. **`asset2`**: The second asset's Multilocation within the pool. This refers to the PPM token, which the following Multilocation identifies.\n\n        ```javascript\n        {\n          parents: 0,\n          interior: {\n            X2: [{ PalletInstance: 50 }, { GeneralIndex: 1112 }]\n          }\n        }\n        ```\n\n    3. **`amount1Desired`**: The amount of the first asset that will be contributed to the pool.\n    4. **`amount2Desired`**: The quantity of the second asset intended for pool contribution.\n    5. **`amount1Min`**: The minimum amount of the first asset that will be contributed.\n    6. **`amount2Min`**: The lowest acceptable quantity of the second asset for contribution.\n    7. **`mintTo`**: The account to which the liquidity tokens will be minted.\n    8. Click on **Submit Transaction** to add liquidity to the pool.\n\n    ![Add Liquidity Fields](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-6.webp)\n\n    !!! warning\n        Ensure that the appropriate amount of tokens provided has been minted previously and is available in your account before adding liquidity to the pool.\n\n    In this case, the liquidity provided to the pool is between DOT tokens and PPM tokens with the asset ID 1112 on Polkadot Asset Hub. The intention is to provide liquidity for 1 DOT token (`u128` value of 1000000000000 as it has 10 decimals) and 1 PPM token (`u128` value of 1000000000000 as it also has 10 decimals).\n\nSigning and submitting the transaction adds liquidity to the pool. To verify the liquidity addition, check the **Explorer** section on the Polkadot.js Apps interface and ensure that the **`LiquidityAdded`** event was emitted.\n\n![Liquidity Added Event](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-7.webp)"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 4, "depth": 2, "title": "Swap Assets", "anchor": "swap-assets", "start_char": 7804, "end_char": 7820, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Swap Assets"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 5, "depth": 3, "title": "Swap from an Exact Amount of Tokens", "anchor": "swap-from-an-exact-amount-of-tokens", "start_char": 7820, "end_char": 11248, "estimated_token_count": 746, "token_estimator": "heuristic-v1", "text": "### Swap from an Exact Amount of Tokens\n\nThe asset conversion pallet enables users to exchange a specific quantity of one asset for another in a designated liquidity pool by swapping them for an exact amount of tokens. It guarantees the user will receive at least a predetermined minimum amount of the second asset. This function increases trading predictability and allows users to conduct asset exchanges with confidence that they are assured a minimum return.\n\nTo swap assets for an exact amount of tokens, follow these steps:\n\n1. Navigate to the **Extrinsics** section on the Polkadot.js Apps interface:\n\n    1. Select **Developer** from the top menu.\n    2. Click on **Extrinsics** from the dropdown menu.\n\n    ![Extrinsics Section](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-1.webp)\n\n2. Select extrinsic to swap assets:\n\n    1. Select the **`AssetConversion`** pallet.\n    2. Choose the **`swapExactTokensForTokens`** extrinsic from the list of available extrinsics.\n\n    ![Swap From Exact Tokens Extrinsic](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-8.webp)\n\n3. Fill in the required fields:\n\n    1. **`path: Vec<StagingXcmV3MultiLocation>`**: An array of Multilocations representing the path of the swap. The first and last elements of the array are the input and output assets, respectively. In this case, the path consists of two elements:\n\n        - **`0: StagingXcmV3MultiLocation`**: The Multilocation of the first asset in the pool. In this case, it is the DOT token, which the following Multilocation represents.\n\n            ```javascript\n            {\n              parents: 0,\n              interior: 'Here'\n            }\n            ```\n\n        - **`1: StagingXcmV3MultiLocation`**: The second asset's Multilocation within the pool. This refers to the PPM token, which the following Multilocation identifies.\n\n            ```javascript\n            {\n              parents: 0,\n              interior: {\n                X2: [{ PalletInstance: 50 }, { GeneralIndex: 1112 }]\n              }\n            }\n            ```\n\n    2. **`amountOut`**: The exact amount of the second asset that the user wants to receive.\n    3. **`amountInMax`**: The maximum amount of the first asset that the user is willing to swap.\n    4. **`sendTo`**: The account to which the swapped assets will be sent.\n    5. **`keepAlive`**: A boolean value that determines whether the pool should be kept alive after the swap.\n    6. Click on **Submit Transaction** to swap assets for an exact amount of tokens.\n\n    ![Swap For Exact Tokens Fields](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-9.webp)\n\n    !!! warning\n        Ensure that the appropriate amount of tokens provided has been minted previously and is available in your account before adding liquidity to the pool.\n\n    In this case, the intention is to swap 0.01 DOT token (u128 value of 100000000000 as it has 10 decimals) for 0.04 PPM token (u128 value of 400000000000 as it also has 10 decimals).\n\nSigning and submitting the transaction will execute the swap. To verify execution, check the **Explorer** section on the Polkadot.js Apps interface and make sure that the **`SwapExecuted`** event was emitted.\n\n![Swap From Exact Tokens Event](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-10.webp)"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 6, "depth": 3, "title": "Swap to an Exact Amount of Tokens", "anchor": "swap-to-an-exact-amount-of-tokens", "start_char": 11248, "end_char": 14617, "estimated_token_count": 745, "token_estimator": "heuristic-v1", "text": "### Swap to an Exact Amount of Tokens\n\nConversely, the Asset Conversion pallet comes with a function that allows users to trade a variable amount of one asset to acquire a precise quantity of another. It ensures that users stay within a set maximum of the initial asset to obtain the desired amount of the second asset. This provides a method to control transaction costs while achieving the intended result.\n\nTo swap assets for an exact amount of tokens, follow these steps:\n\n1. Navigate to the **Extrinsics** section on the Polkadot.js Apps interface:\n\n    1. Select **Developer** from the top menu.\n    2. Click on **Extrinsics** from the dropdown menu.\n\n    ![Extrinsics Section](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-1.webp)\n\n2. Select extrinsic to swap tokens:\n\n    1. Select the **`AssetConversion`** pallet.\n    2. Choose the **`swapTokensForExactTokens`** extrinsic from the list of available extrinsics.\n\n    ![Swap Tokens For Exact Tokens Extrinsic](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-11.webp)\n\n3. Fill in the required fields:\n\n    1. **`path: Vec<StagingXcmV3MultiLocation\\>`**: An array of Multilocations representing the path of the swap. The first and last elements of the array are the input and output assets, respectively. In this case, the path consists of two elements:\n        - **`0: StagingXcmV3MultiLocation`**: The Multilocation of the first asset in the pool. In this case, it is the PPM token, which the following Multilocation represents.\n\n            ```javascript\n            {\n              parents: 0,\n              interior: {\n                X2: [{ PalletInstance: 50 }, { GeneralIndex: 1112 }]\n              }\n            }\n            ```\n\n        - **`1: StagingXcmV3MultiLocation`**: The second asset's Multilocation within the pool. This refers to the DOT token, which the following Multilocation identifies.\n\n            ```javascript\n            {\n              parents: 0,\n              interior: 'Here'\n            }\n            ```\n\n    2. **`amountOut`**: The exact amount of the second asset that the user wants to receive.\n    3. **`amountInMax`**: The maximum amount of the first asset that the user is willing to swap.\n    4. **`sendTo`**: The account to which the swapped assets will be sent.\n    5. **`keepAlive`**: A boolean value that determines whether the pool should be kept alive after the swap.\n    6. Click on **Submit Transaction** to swap assets for an exact amount of tokens.\n\n    ![Swap Tokens For Exact Tokens Fields](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-12.webp)\n\n    !!! warning\n        Before swapping assets, ensure that the tokens provided have been minted previously and are available in your account.\n\n    In this case, the intention is to swap 0.01 DOT token (`u128` value of 100000000000 as it has ten decimals) for 0.04 PPM token (`u128` value of 400000000000 as it also has ten decimals).\n\nSigning and submitting the transaction will execute the swap. To verify execution, check the **Explorer** section on the Polkadot.js Apps interface and make sure that the **`SwapExecuted`** event was emitted.\n\n![Swap Tokens For Exact Tokens Event](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-13.webp)"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 7, "depth": 2, "title": "Withdraw Liquidity from a Pool", "anchor": "withdraw-liquidity-from-a-pool", "start_char": 14617, "end_char": 17890, "estimated_token_count": 715, "token_estimator": "heuristic-v1", "text": "## Withdraw Liquidity from a Pool\n\nThe Asset Conversion pallet provides the `removeLiquidity` extrinsic to remove liquidity from a pool. This function allows users to withdraw the liquidity they offered from a pool, returning the original assets. When calling this function, users specify the number of liquidity tokens (representing their share in the pool) they wish to burn. They also set minimum acceptable amounts for the assets they expect to receive back. This mechanism ensures that users can control the minimum value they receive, protecting against unfavorable price movements during the withdrawal process.\n\nTo withdraw liquidity from a pool, follow these steps:\n\n1. Navigate to the **Extrinsics** section on the Polkadot.js Apps interface:\n\n    1. Select **Developer** from the top menu.\n    2. Click on **Extrinsics** from the dropdown menu.\n\n    ![Extrinsics Section](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-1.webp)\n\n2. Select extrinsic to withdraw liqudity from a pool:\n\n    1. Select the **`AssetConversion`** pallet.\n    2. Choose the **`removeLiquidity`** extrinsic from the list of available extrinsics.\n\n    ![Remove Liquidity Extrinsic](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-14.webp)\n\n3. Fill in the required fields:\n\n    1. **`asset1`**: The Multilocation of the first asset in the pool. In this case, it is the DOT token, which the following Multilocation represents.\n\n        ```javascript\n        {\n          parents: 0,\n          interior: 'Here'\n        }\n        ```\n\n    2. **`asset2`**: The second asset's Multilocation within the pool. This refers to the PPM token, which the following Multilocation identifies.\n\n        ```javascript\n        {\n          parents: 0,\n          interior: {\n            X2: [{ PalletInstance: 50 }, { GeneralIndex: 1112 }]\n          }\n        }\n        ```\n\n    3. **`lpTokenBurn`**: The number of liquidity tokens to burn.\n    4. **`amount1MinReceived`**: The minimum amount of the first asset that the user expects to receive.\n    5. **`amount2MinReceived`**: The minimum quantity of the second asset the user expects to receive.\n    6. **`withdrawTo`**: The account to which the withdrawn assets will be sent.\n    7. Click on **Submit Transaction** to withdraw liquidity from the pool.\n\n    ![Remove Liquidity Fields](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-15.webp)\n\n    !!! warning\n        Ensure that the tokens provided have been minted previously and are available in your account before withdrawing liquidity from the pool.\n\n    In this case, the intention is to withdraw 0.05 liquidity tokens from the pool, expecting to receive 0.004 DOT token (`u128` value of 40000000000 as it has 10 decimals) and 0.04 PPM token (`u128` value of 400000000000 as it also has 10 decimals).\n\nSigning and submitting the transaction will initiate the withdrawal of liquidity from the pool. To verify the withdrawal, check the **Explorer** section on the Polkadot.js Apps interface and ensure that the **`LiquidityRemoved`** event was emitted.\n\n![Remove Liquidity Event](/images/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/asset-conversion-16.webp)"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-asset-conversion", "index": 8, "depth": 2, "title": "Test Environment Setup", "anchor": "test-environment-setup", "start_char": 17890, "end_char": 18994, "estimated_token_count": 242, "token_estimator": "heuristic-v1", "text": "## Test Environment Setup\n\nTo test the Asset Conversion pallet, you can set up a local test environment to simulate different scenarios. This guide uses Chopsticks to spin up an instance of Polkadot Asset Hub. For further details on using Chopsticks, please refer to the [Chopsticks documentation](/develop/toolkit/parachains/fork-chains/chopsticks/get-started){target=\\_blank}.\n\nTo set up a local test environment, execute the following command:\n\n```bash\nnpx @acala-network/chopsticks \\\n--config=https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot-asset-hub.yml\n```\n\nThis command initiates a lazy fork of Polkadot Asset Hub, including the most recent block information from the network. For Kusama Asset Hub testing, simply switch out `polkadot-asset-hub.yml` with `kusama-asset-hub.yml` in the command.\n\nYou now have a local Asset Hub instance up and running, ready for you to test various asset conversion procedures. The process here mirrors what you'd do on MainNet. After completing a transaction on TestNet, you can apply the same steps to convert assets on MainNet."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 41, "end_char": 1109, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAs outlined in the [Asset Hub Overview](/polkadot-protocol/architecture/system-chains/asset-hub){target=\\_blank}, Asset Hub supports two categories of assets: local and foreign. Local assets are created on the Asset Hub system parachain and are identified by integer IDs. On the other hand, foreign assets, which originate outside of Asset Hub, are recognized by [Multilocations](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#7-universal-consensus-location-identifiers){target=\\_blank}.\n\nWhen registering a foreign asset on Asset Hub, it's essential to notice that the process involves communication between two parachains. The Asset Hub parachain will be the destination of the foreign asset, while the source parachain will be the origin of the asset. The communication between the two parachains is facilitated by the [Cross-Chain Message Passing (XCMP)](/develop/interoperability/intro-to-xcm/){target=\\_blank} protocol.\n\nThis guide will take you through the process of registering a foreign asset on the Asset Hub parachain."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1109, "end_char": 2803, "estimated_token_count": 472, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nThe Asset Hub parachain is one of the system parachains on a relay chain, such as [Polkadot](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fpolkadot.api.onfinality.io%2Fpublic-ws#/explorer){target=\\_blank} or [Kusama](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fkusama.api.onfinality.io%2Fpublic-ws#/explorer){target=\\_blank}. To interact with these parachains, you can use the [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} interface for:\n\n- [Polkadot Asset Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fasset-hub-polkadot-rpc.dwellir.com#/explorer){target=\\_blank}\n- [Kusama Asset Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fsys.ibp.network%2Fstatemine#/explorer){target=\\_blank}\n\nFor testing purposes, you can also interact with the Asset Hub instance on the following test networks:\n\n- [Paseo Asset Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fpas-rpc.stakeworld.io%2Fassethub#/explorer){target=\\_blank}\n\nBefore you start, ensure that you have: \n\n- Access to the Polkadot.js Apps interface, and you are connected to the desired chain.\n- A parachain that supports the XCMP protocol to interact with the Asset Hub parachain.\n- A funded wallet to pay for the transaction fees and subsequent registration of the foreign asset.\n\nThis guide will use Polkadot, its local Asset Hub instance, and the [Astar](https://astar.network/){target=\\_blank} parachain (`ID` 2006), as stated in the [Test Environment Setup](#test-environment-setup) section. However, the process is the same for other relay chains and their respective Asset Hub parachain, regardless of the network you are using and the parachain owner of the foreign asset."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 2, "depth": 2, "title": "Steps to Register a Foreign Asset", "anchor": "steps-to-register-a-foreign-asset", "start_char": 2803, "end_char": 2841, "estimated_token_count": 8, "token_estimator": "heuristic-v1", "text": "## Steps to Register a Foreign Asset"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 3, "depth": 3, "title": "Asset Hub", "anchor": "asset-hub", "start_char": 2841, "end_char": 5953, "estimated_token_count": 725, "token_estimator": "heuristic-v1", "text": "### Asset Hub\n\n1. Open the [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} interface and connect to the Asset Hub parachain using the network selector in the top left corner.\n\n      - Testing foreign asset registration is recommended on TestNet before proceeding to MainNet. If you haven't set up a local testing environment yet, consult the [Environment setup](#test-environment-setup) guide. After setting up, connect to the Local Node (Chopsticks) at `ws://127.0.0.1:8000`.\n      - For live network operations, connect to the Asset Hub parachain. You can choose either Polkadot or Kusama Asset Hub from the dropdown menu, selecting your preferred RPC provider.\n\n2. Navigate to the **Extrinsics** page:\n\n      1. Click on the **Developer** tab from the top navigation bar.\n      2. Select **Extrinsics** from the dropdown.\n\n    ![Access to Developer Extrinsics section](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-assets/register-a-foreign-asset-1.webp)\n\n3. Select the Foreign Assets pallet:\n\n      3. Select the **`foreignAssets`** pallet from the dropdown list.\n      4. Choose the **`create`** extrinsic.\n\n    ![Select the Foreign Asset pallet](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-assets/register-a-foreign-asset-2.webp)\n\n3. Fill out the required fields and click on the copy icon to copy the **encoded call data** to your clipboard. The fields to be filled are:\n\n    - **id**: As this is a foreign asset, the ID will be represented by a Multilocation that reflects its origin. For this case, the Multilocation of the asset will be from the source parachain perspective.\n  \n        ```javascript\n        { parents: 1, interior: { X1: [{ Parachain: 2006 }] } }\n        ```\n\n    - **admin**: Refers to the account that will be the admin of this asset. This account will be able to manage the asset, including updating its metadata. As the registered asset corresponds to a native asset of the source parachain, the admin account should be the sovereign account of the source parachain.\n      \n        The sovereign account can be obtained through [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=\\_blank}.\n\n        Ensure that **Sibling** is selected and that the **Para ID** corresponds to the source parachain. In this case, since the guide follows the test setup stated in the [Test Environment Setup](#test-environment-setup) section, the **Para ID** is `2006`.\n\n        ![Get parachain sovereign account](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-assets/register-a-foreign-asset-3.webp)\n\n\n    - **`minBalance`**: The minimum balance required to hold this asset.\n\n    ![Fill out the required fields](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-assets/register-a-foreign-asset-4.webp)\n\n    !!! tip \n        If you need an example of the encoded call data, you can copy the following:\n        ```\n        0x3500010100591f007369626cd6070000000000000000000000000000000000000000000000000000a0860100000000000000000000000000\n        ```"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 4, "depth": 3, "title": "Source Parachain", "anchor": "source-parachain", "start_char": 5953, "end_char": 7606, "estimated_token_count": 303, "token_estimator": "heuristic-v1", "text": "### Source Parachain\n\n1. Navigate to the **Developer > Extrinsics** section.\n2. Create the extrinsic to register the foreign asset through XCM:\n\n      1. Paste the **encoded call data** copied in the previous step.\n      2. Click the **Submit Transaction** button.\n\n    ![Register foreign asset through XCM](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-assets/register-a-foreign-asset-5.webp)\n\n    This XCM call involves withdrawing DOT from the sibling account of the parachain, using it to initiate an execution. The transaction will be carried out with XCM as the origin kind, and will be a hex-encoded call to create a foreign asset on Asset Hub for the specified parachain asset multilocation. Any surplus will be refunded, and the asset will be deposited into the sibling account.\n\n    !!! warning\n        Note that the sovereign account on the Asset Hub parachain must have a sufficient balance to cover the XCM `BuyExecution` instruction. If the account does not have enough balance, the transaction will fail.\n\n    If you want to have the whole XCM call ready to be copied, go to the **Developer > Extrinsics > Decode** section and paste the following hex-encoded call data:\n\n    ```text\n    0x6300330003010100a10f030c000400010000070010a5d4e81300010000070010a5d4e80006030700b4f13501419ce03500010100591f007369626cd607000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n    ```\n\n    Be sure to replace the encoded call data with the one you copied in the previous step.\n\nAfter the transaction is successfully executed, the foreign asset will be registered on the Asset Hub parachain."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 5, "depth": 2, "title": "Asset Registration Verification", "anchor": "asset-registration-verification", "start_char": 7606, "end_char": 8164, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Asset Registration Verification\n\nTo confirm that a foreign asset has been successfully accepted and registered on the Asset Hub parachain, you can navigate to the `Network > Explorer` section of the Polkadot.js Apps interface for Asset Hub. You should be able to see an event that includes the following details:\n\n![Asset registration event](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-foreign-assets/register-a-foreign-asset-6.webp)\n\nIn the image above, the **success** field indicates whether the asset registration was successful."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-foreign-asset", "index": 6, "depth": 2, "title": "Test Environment Setup", "anchor": "test-environment-setup", "start_char": 8164, "end_char": 9821, "estimated_token_count": 398, "token_estimator": "heuristic-v1", "text": "## Test Environment Setup\n\nTo test the foreign asset registration process before deploying it on a live network, you can set up a local parachain environment. This guide uses Chopsticks to simulate that process. For more information on using Chopsticks, please refer to the [Chopsticks documentation](/develop/toolkit/parachains/fork-chains/chopsticks/get-started){target=\\_blank}.\n\nTo set up a test environment, run the following command:\n\n```bash\nnpx @acala-network/chopsticks xcm \\\n--r polkadot \\\n--p polkadot-asset-hub \\\n--p astar\n```\n\nThe preceding command will create a lazy fork of Polkadot as the relay chain, its Asset Hub instance, and the Astar parachain. The `xcm` parameter enables communication through the XCMP protocol between the relay chain and the parachains, allowing the registration of foreign assets on Asset Hub. For further information on the chopsticks usage of the XCMP protocol, refer to the [XCM Testing](/tutorials/polkadot-sdk/testing/fork-live-chains/#xcm-testing){target=\\_blank} section of the Chopsticks documentation.\n\nAfter executing the command, the terminal will display output indicating the Polkadot relay chain, the Polkadot Asset Hub, and the Astar parachain are running locally and connected through XCM. You can access them individually via the Polkadot.js Apps interface.\n\n- [Polkadot Relay Chain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Flocalhost%3A8002#/explorer){target=\\_blank}\n- [Polkadot Asset Hub](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Flocalhost%3A8000#/explorer){target=\\_blank}\n- [Astar Parachain](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Flocalhost%3A8001#/explorer){target=\\_blank}"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-local-asset", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 39, "end_char": 541, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAs detailed in the [Asset Hub Overview](/polkadot-protocol/architecture/system-chains/asset-hub){target=\\_blank} page, Asset Hub accommodates two types of assets: local and foreign. Local assets are those that were created in Asset Hub and are identifiable by an integer ID. On the other hand, foreign assets originate from a sibling parachain and are identified by a Multilocation.\n\nThis guide will take you through the steps of registering a local asset on the Asset Hub parachain."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-local-asset", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 541, "end_char": 1097, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have access to the [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} interface and a funded wallet with DOT or KSM.\n\n- For Polkadot Asset Hub, you would need a deposit of 10 DOT and around 0.201 DOT for the metadata.\n- For Kusama Asset Hub, the deposit is 0.1 KSM and around 0.000669 KSM for the metadata.\n\nYou need to ensure that your Asset Hub account balance is a bit more than the sum of those two deposits, which should seamlessly account for the required deposits and transaction fees."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-local-asset", "index": 2, "depth": 2, "title": "Steps to Register a Local Asset", "anchor": "steps-to-register-a-local-asset", "start_char": 1097, "end_char": 4387, "estimated_token_count": 838, "token_estimator": "heuristic-v1", "text": "## Steps to Register a Local Asset\n\nTo register a local asset on the Asset Hub parachain, follow these steps:\n\n1. Open the [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} interface and connect to the Asset Hub parachain using the network selector in the top left corner.\n\n      - You may prefer to test local asset registration on TestNet before registering the asset on a MainNet hub. If you still need to set up a local testing environment, review the [Environment setup](#test-setup-environment) section for instructions. Once the local environment is set up, connect to the Local Node (Chopsticks) available on `ws://127.0.0.1:8000`.\n      - For the live network, connect to the **Asset Hub** parachain. Either Polkadot or Kusama Asset Hub can be selected from the dropdown list, choosing the desired RPC provider.\n\n2. Click on the **Network** tab on the top navigation bar and select **Assets** from the dropdown list.\n\n      ![Access to Asset Hub through Polkadot.JS](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-1.webp)\n\n3. Now, you need to examine all the registered asset IDs. This step is crucial to ensure that the asset ID you are about to register is unique. Asset IDs are displayed in the **assets** column.\n\n      ![Asset IDs on Asset Hub](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-2.webp)\n\n4. Once you have confirmed that the asset ID is unique, click on the **Create** button on the top right corner of the page.\n\n      ![Create a new asset](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-3.webp)\n\n5. Fill in the required fields in the **Create Asset** form:\n\n    1. **creator account**: The account to be used for creating this asset and setting up the initial metadata.\n    2. **asset name**: The descriptive name of the asset you are registering.\n    3. **asset symbol**: The symbol that will be used to represent the asset.\n    4. **asset decimals**: The number of decimal places for this token, with a maximum of 20 allowed through the user interface.\n    5. **minimum balance**: The minimum balance for the asset. This is specified in the units and decimals as requested.\n    6. **asset ID**: The selected id for the asset. This should not match an already-existing asset id.\n    7. Click on the **Next** button.\n \n    ![Create Asset Form](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-4.webp)\n\n6. Choose the accounts for the roles listed below:\n\n    1. **admin account**: The account designated for continuous administration of the token.\n    2. **issuer account**: The account that will be used for issuing this token.\n    3. **freezer account**: The account that will be used for performing token freezing operations.\n    4. Click on the **Create** button.\n\n    ![Admin, Issuer, Freezer accounts](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-5.webp)\n\n7. Click on the **Sign and Submit** button to complete the asset registration process.\n\n    ![Sign and Submit](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-6.webp)"}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-local-asset", "index": 3, "depth": 2, "title": "Verify Asset Registration", "anchor": "verify-asset-registration", "start_char": 4387, "end_char": 5337, "estimated_token_count": 259, "token_estimator": "heuristic-v1", "text": "## Verify Asset Registration\n\nAfter completing these steps, the asset will be successfully registered. You can now view your asset listed on the [**Assets**](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fasset-hub-polkadot-rpc.dwellir.com#/assets){target=\\_blank} section of the Polkadot.js Apps interface.\n\n![Asset listed on Polkadot.js Apps](/images/tutorials/polkadot-sdk/system-chains/asset-hub/register-local-assets/register-a-local-asset-7.webp)\n\n!!! tip\n    Take into consideration that the **Assets** section’s link may differ depending on the network you are using. For the local environment, enter `ws://127.0.0.1:8000` into the **Custom Endpoint** field.\n\nIn this way, you have successfully registered a local asset on the Asset Hub parachain.\n\nFor an in-depth explanation about Asset Hub and its features, see the [Asset Hub](/tutorials/polkadot-sdk/system-chains/asset-hub/asset-conversion/){target=\\_blank} entry in the Polkadot Wiki."}
{"page_id": "tutorials-polkadot-sdk-system-chains-asset-hub-register-local-asset", "index": 4, "depth": 2, "title": "Test Setup Environment", "anchor": "test-setup-environment", "start_char": 5337, "end_char": 6445, "estimated_token_count": 240, "token_estimator": "heuristic-v1", "text": "## Test Setup Environment\n\nYou can set up a local parachain environment to test the asset registration process before deploying it on the live network. This guide uses Chopsticks to simulate that process. For further information on chopsticks usage, refer to the [Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks/get-started){target=\\_blank} documentation.\n\nTo set up a test environment, execute the following command:\n\n```bash\nnpx @acala-network/chopsticks \\\n--config=https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot-asset-hub.yml\n```\n\nThe above command will spawn a lazy fork of Polkadot Asset Hub with the latest block data from the network. If you need to test Kusama Asset Hub, replace `polkadot-asset-hub.yml` with `kusama-asset-hub.yml` in the command.\n\nAn Asset Hub instance is now running locally, and you can proceed with the asset registration process. Note that the local registration process does not differ from the live network process. Once you have a successful TestNet transaction, you can use the same steps to register the asset on MainNet."}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 32, "end_char": 1108, "estimated_token_count": 208, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nChopsticks is an innovative tool that simplifies the process of forking live Polkadot SDK chains. This guide provides step-by-step instructions to configure and fork chains, enabling developers to:\n\n- Replay blocks for state analysis.\n- Test cross-chain messaging (XCM).\n- Simulate blockchain environments for debugging and experimentation.\n\nWith support for both configuration files and CLI commands, Chopsticks offers flexibility for diverse development workflows. Whether you're testing locally or exploring complex blockchain scenarios, Chopsticks empowers developers to gain deeper insights and accelerate application development.\n\nChopsticks uses the [Smoldot](https://github.com/smol-dot/smoldot){target=\\_blank} light client, which does not support calls made through the Ethereum JSON-RPC. As a result, you can't fork your chain using Chopsticks and then interact with it using tools like MetaMask.\n\nFor additional support and information, please reach out through [GitHub Issues](https://github.com/AcalaNetwork/chopsticks/issues){target=\\_blank}."}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1108, "end_char": 1591, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo follow this tutorial, ensure you have completed the following:\n\n- **Installed Chopsticks**: If you still need to do so, see the [Install Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks/get-started/#install-chopsticks){target=\\_blank} guide for assistance.\n- **Reviewed** [Configure Chopsticks](/develop/toolkit/parachains/fork-chains/chopsticks/get-started/#configure-chopsticks){target=\\_blank}: And understand how forked chains are configured."}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 2, "depth": 2, "title": "Configuration File", "anchor": "configuration-file", "start_char": 1591, "end_char": 3202, "estimated_token_count": 441, "token_estimator": "heuristic-v1", "text": "## Configuration File \n\nTo run Chopsticks using a configuration file, utilize the `--config` flag. You can use a raw GitHub URL, a path to a local file, or simply the chain's name. The following commands all look different but they use the `polkadot` configuration in the same way:\n\n=== \"GitHub URL\"\n\n    ```bash\n    npx @acala-network/chopsticks \\\n    --config=https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot.yml\n    ```\n\n=== \"Local File Path\"\n\n    ```bash\n    npx @acala-network/chopsticks --config=configs/polkadot.yml\n    ```\n\n=== \"Chain Name\"\n\n    ```bash\n    npx @acala-network/chopsticks --config=polkadot\n    ```\n\nRegardless of which method you choose from the preceding examples, you'll see an output similar to the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx @acala-network/chopsticks --config=polkadot</span>\n  <br />\n  <span data-ty>[18:38:26.155] INFO: Loading config file https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot.yml</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty> chopsticks::executor TRACE: Calling Metadata_metadata</span>\n  <span data-ty> chopsticks::executor TRACE: Completed Metadata_metadata</span>\n  <span data-ty>[18:38:28.186] INFO: Polkadot RPC listening on port 8000</span>\n  <span data-ty> app: \"chopsticks\"</span>\n</div>\n\n\nIf using a file path, make sure you've downloaded the [Polkadot configuration file](https://github.com/AcalaNetwork/chopsticks/blob/master/configs/polkadot.yml){target=\\_blank}, or have created your own."}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 3, "depth": 2, "title": "Create a Fork", "anchor": "create-a-fork", "start_char": 3202, "end_char": 3908, "estimated_token_count": 212, "token_estimator": "heuristic-v1", "text": "## Create a Fork\n\nOnce you've configured Chopsticks, use the following command to fork Polkadot at block 100:\n\n```bash\nnpx @acala-network/chopsticks \\\n--endpoint wss://polkadot-rpc.dwellir.com \\\n--block 100\n```\n\nIf the fork is successful, you will see output similar to the following:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx @acala-network/chopsticks \\ --endpoint wss://polkadot-rpc.dwellir.com \\ --block 100</span>\n  <br />\n  <span data-ty>[19:12:21.023] INFO: Polkadot RPC listening on port 8000</span>\n  <span data-ty> app: \"chopsticks\"</span>\n</div>\n\n\nAccess the running Chopsticks fork using the default address.\n\n```bash\nws://localhost:8000\n```"}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 4, "depth": 2, "title": "Interact with a Fork", "anchor": "interact-with-a-fork", "start_char": 3908, "end_char": 4214, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "## Interact with a Fork\n\nYou can interact with the forked chain using various [libraries](/develop/toolkit/#libraries){target=\\_blank} such as [Polkadot.js](https://polkadot.js.org/docs/){target=\\_blank} and its user interface, [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}."}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 5, "depth": 3, "title": "Use Polkadot.js Apps", "anchor": "use-polkadotjs-apps", "start_char": 4214, "end_char": 4890, "estimated_token_count": 192, "token_estimator": "heuristic-v1", "text": "### Use Polkadot.js Apps\n\nTo interact with Chopsticks via the hosted user interface, visit [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} and follow these steps:\n\n1. Select the network icon in the top left corner.\n\n    ![](/images/tutorials/polkadot-sdk/testing/fork-live-chains/chopsticks-1.webp)\n\n2. Scroll to the bottom and select **Development**.\n3. Choose **Custom**.\n4. Enter `ws://localhost:8000` in the input field.\n5. Select the **Switch** button.\n\n    ![](/images/tutorials/polkadot-sdk/testing/fork-live-chains/chopsticks-2.webp)\n\nYou should now be connected to your local fork and can interact with it as you would with a real chain."}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 6, "depth": 3, "title": "Use Polkadot.js Library", "anchor": "use-polkadotjs-library", "start_char": 4890, "end_char": 5415, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "### Use Polkadot.js Library\n\nFor programmatic interaction, you can use the Polkadot.js library. The following is a basic example:\n\n```js\n-import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function connectToFork() {\n  const wsProvider = new WsProvider('ws://localhost:8000');\n  const api = await ApiPromise.create({ provider: wsProvider });\n  await api.isReady;\n\n  // Now you can use 'api' to interact with your fork\n  console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n}\n\nconnectToFork();\n\n```"}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 7, "depth": 2, "title": "Replay Blocks", "anchor": "replay-blocks", "start_char": 5415, "end_char": 19268, "estimated_token_count": 576, "token_estimator": "heuristic-v1", "text": "## Replay Blocks\n\nChopsticks allows you to replay specific blocks from a chain, which is useful for debugging and analyzing state changes. You can use the parameters in the [Configuration](/develop/toolkit/parachains/fork-chains/chopsticks/get-started/#configure-chopsticks){target=\\_blank} section to set up the chain configuration, and then use the run-block subcommand with the following additional options:\n\n- **`output-path`**: Path to print output.\n- **`html`**: Generate HTML with storage diff.\n- **`open`**: Open generated HTML.\n\nFor example, the command to replay block 1000 from Polkadot and save the output to a JSON file would be as follows:\n\n```bash\nnpx @acala-network/chopsticks run-block  \\\n--endpoint wss://polkadot-rpc.dwellir.com  \\\n--output-path ./polkadot-output.json  \\\n--block 1000\n```\n\n??? code \"polkadot-output.json\"\n\n    ```json\n    -{\n    \"Call\": {\n        \"result\": \"0xba754e7478944d07a1f7e914422b4d973b0855abeb6f81138fdca35beb474b44a10f6fc59a4d90c3b78e38fac100fc6adc6f9e69a07565ec8abce6165bd0d24078cc7bf34f450a2cc7faacc1fa1e244b959f0ed65437f44208876e1e5eefbf8dd34c040642414245b501030100000083e2cc0f00000000d889565422338aa58c0fd8ebac32234149c7ce1f22ac2447a02ef059b58d4430ca96ba18fbf27d06fe92ec86d8b348ef42f6d34435c791b952018d0a82cae40decfe5faf56203d88fdedee7b25f04b63f41f23da88c76c876db5c264dad2f70c\",\n        \"storageDiff\": [\n            [\n                \"0x0b76934f4cc08dee01012d059e1b83eebbd108c4899964f707fdaffb82636065\",\n                \"0x00\"\n            ],\n            [\n                \"0x1cb6f36e027abb2091cfb5110ab5087f0323475657e0890fbdbf66fb24b4649e\",\n                null\n            ],\n            [\n                \"0x1cb6f36e027abb2091cfb5110ab5087f06155b3cd9a8c9e5e9a23fd5dc13a5ed\",\n                \"0x83e2cc0f00000000\"\n            ],\n            [\n                \"0x1cb6f36e027abb2091cfb5110ab5087ffa92de910a7ce2bd58e99729c69727c1\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef702a5c1b19ab7a04f536c519aca4983ac\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef70a98fdbe9ce6c55837576c60c7af3850\",\n                \"0x02000000\"\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef734abf5cb34d6244378cddbf18e849d96\",\n                \"0xc03b86ae010000000000000000000000\"\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef780d41e5e16056765bc8461851072c9d7\",\n                \"0x080000000000000080e36a09000000000200000001000000000000ca9a3b00000000020000\"\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef78a42f33323cb5ced3b44dd825fda9fcc\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef799e7f93fc6a98f0874fd057f111c4d2d\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7a44704b568d21667356a5a050c118746d366e7fe86e06375e7030000\",\n                \"0xba754e7478944d07a1f7e914422b4d973b0855abeb6f81138fdca35beb474b44\"\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7a86da5a932684f199539836fcb8c886f\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7b06c3320c6ac196d813442e270868d63\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7bdc0bd303e9855813aa8a30d4efc5112\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7df1daeb8986837f21cc5d17596bb78d15153cb1f00942ff401000000\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7df1daeb8986837f21cc5d17596bb78d1b4def25cfda6ef3a00000000\",\n                null\n            ],\n            [\n                \"0x26aa394eea5630e07c48ae0c9558cef7ff553b5a9862a516939d82b3d3d8661a\",\n                null\n            ],\n            [\n                \"0x2b06af9719ac64d755623cda8ddd9b94b1c371ded9e9c565e89ba783c4d5f5f9b4def25cfda6ef3a000000006f3d6b177c8acbd8dc9974cdb3cebfac4d31333c30865ff66c35c1bf898df5c5dd2924d3280e7201\",\n                \"0x9b000000\"\n            ],\n            [\"0x3a65787472696e7369635f696e646578\", null],\n            [\n                \"0x3f1467a096bcd71a5b6a0c8155e208103f2edf3bdf381debe331ab7446addfdc\",\n                \"0x550057381efedcffffffffffffffffff\"\n            ],\n            [\n                \"0x3fba98689ebed1138735e0e7a5a790ab0f41321f75df7ea5127be2db4983c8b2\",\n                \"0x00\"\n            ],\n            [\n                \"0x3fba98689ebed1138735e0e7a5a790ab21a5051453bd3ae7ed269190f4653f3b\",\n                \"0x080000\"\n            ],\n            [\n                \"0x3fba98689ebed1138735e0e7a5a790abb984cfb497221deefcefb70073dcaac1\",\n                \"0x00\"\n            ],\n            [\n                \"0x5f3e4907f716ac89b6347d15ececedca80cc6574281671b299c1727d7ac68cabb4def25cfda6ef3a00000000\",\n                \"0x204e0000183887050ecff59f58658b3df63a16d03a00f92890f1517f48c2f6ccd215e5450e380e00005809fd84af6483070acbb92378e3498dbc02fb47f8e97f006bb83f60d7b2b15d980d000082104c22c383925323bf209d771dec6e1388285abe22c22d50de968467e0bb6ce00b000088ee494d719d68a18aade04903839ea37b6be99552ceceb530674b237afa9166480d0000dc9974cdb3cebfac4d31333c30865ff66c35c1bf898df5c5dd2924d3280e72011c0c0000e240d12c7ad07bb0e7785ee6837095ddeebb7aef84d6ed7ea87da197805b343a0c0d0000\"\n            ],\n            [\n                \"0xae394d879ddf7f99595bc0dd36e355b5bbd108c4899964f707fdaffb82636065\",\n                null\n            ],\n            [\n                \"0xbd2a529379475088d3e29a918cd478721a39ec767bd5269111e6492a1675702a\",\n                \"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\"\n            ],\n            [\n                \"0xd57bce545fb382c34570e5dfbf338f5e326d21bc67a4b34023d577585d72bfd7\",\n                null\n            ],\n            [\n                \"0xd57bce545fb382c34570e5dfbf338f5ea36180b5cfb9f6541f8849df92a6ec93\",\n                \"0x00\"\n            ],\n            [\n                \"0xd57bce545fb382c34570e5dfbf338f5ebddf84c5eb23e6f53af725880d8ffe90\",\n                null\n            ],\n            [\n                \"0xd5c41b52a371aa36c9254ce34324f2a53b996bb988ea8ee15bad3ffd2f68dbda\",\n                \"0x00\"\n            ],\n            [\n                \"0xf0c365c3cf59d671eb72da0e7a4113c49f1f0515f462cdcf84e0f1d6045dfcbb\",\n                \"0x50defc5172010000\"\n            ],\n            [\n                \"0xf0c365c3cf59d671eb72da0e7a4113c4bbd108c4899964f707fdaffb82636065\",\n                null\n            ],\n            [\n                \"0xf68f425cf5645aacb2ae59b51baed90420d49a14a763e1cbc887acd097f92014\",\n                \"0x9501800300008203000082030000840300008503000086030000870300008703000089030000890300008b0300008b0300008d0300008d0300008f0300008f0300009103000092030000920300009403000094030000960300009603000098030000990300009a0300009b0300009b0300009d0300009d0300009f0300009f030000a1030000a2030000a3030000a4030000a5030000a6030000a6030000a8030000a8030000aa030000ab030000ac030000ad030000ae030000af030000b0030000b1030000b1030000b3030000b3030000b5030000b6030000b7030000b8030000b9030000ba030000ba030000bc030000bc030000be030000be030000c0030000c1030000c2030000c2030000c4030000c5030000c5030000c7030000c7030000c9030000c9030000cb030000cc030000cd030000ce030000cf030000d0030000d0030000d2030000d2030000d4030000d4030000d6030000d7030000d8030000d9030000da030000db030000db030000dd030000dd030000df030000e0030000e1030000e2030000e3030000e4030000e4030000\"\n            ],\n            [\n                \"0xf68f425cf5645aacb2ae59b51baed9049b58374218f48eaf5bc23b7b3e7cf08a\",\n                \"0xb3030000\"\n            ],\n            [\n                \"0xf68f425cf5645aacb2ae59b51baed904b97380ce5f4e70fbf9d6b5866eb59527\",\n                \"0x9501800300008203000082030000840300008503000086030000870300008703000089030000890300008b0300008b0300008d0300008d0300008f0300008f0300009103000092030000920300009403000094030000960300009603000098030000990300009a0300009b0300009b0300009d0300009d0300009f0300009f030000a1030000a2030000a3030000a4030000a5030000a6030000a6030000a8030000a8030000aa030000ab030000ac030000ad030000ae030000af030000b0030000b1030000b1030000b3030000b3030000b5030000b6030000b7030000b8030000b9030000ba030000ba030000bc030000bc030000be030000be030000c0030000c1030000c2030000c2030000c4030000c5030000c5030000c7030000c7030000c9030000c9030000cb030000cc030000cd030000ce030000cf030000d0030000d0030000d2030000d2030000d4030000d4030000d6030000d7030000d8030000d9030000da030000db030000db030000dd030000dd030000df030000e0030000e1030000e2030000e3030000e4030000e4030000\"\n            ]\n        ],\n        \"offchainStorageDiff\": [],\n        \"runtimeLogs\": []\n    }\n}\n\n    ```"}
{"page_id": "tutorials-polkadot-sdk-testing-fork-live-chains", "index": 8, "depth": 2, "title": "XCM Testing", "anchor": "xcm-testing", "start_char": 19268, "end_char": 21807, "estimated_token_count": 762, "token_estimator": "heuristic-v1", "text": "## XCM Testing\n\nTo test XCM (Cross-Consensus Messaging) messages between networks, you can fork multiple parachains and a relay chain locally using Chopsticks.\n\n- **`relaychain`**: Relay chain config file.\n- **`parachain`**: Parachain config file.\n\nFor example, to fork Moonbeam, Astar, and Polkadot enabling XCM between them, you can use the following command:\n\n```bash\nnpx @acala-network/chopsticks xcm \\\n--r polkadot \\\n--p moonbeam \\\n--p astar\n```\n\nAfter running it, you should see output similar to the following:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx @acala-network/chopsticks xcm \\</span>\n  <span data-ty>--r polkadot \\</span>\n  <span data-ty>--p moonbeam \\</span>\n  <span data-ty>--p astar</span>\n  <br />\n  <span data-ty>[13:46:07.901] INFO: Loading config file https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/moonbeam.yml</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty>[13:46:12.631] INFO: Moonbeam RPC listening on port 8000</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty>[13:46:12.632] INFO: Loading config file https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/astar.yml</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty> chopsticks::executor TRACE: Calling Metadata_metadata</span>\n  <span data-ty> chopsticks::executor TRACE: Completed Metadata_metadata</span>\n  <span data-ty>[13:46:23.669] INFO: Astar RPC listening on port 8001</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty>[13:46:25.144] INFO (xcm): Connected parachains [2004,2006]</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty>[13:46:25.144] INFO: Loading config file https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot.yml</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty> chopsticks::executor TRACE: Calling Metadata_metadata</span>\n  <span data-ty> chopsticks::executor TRACE: Completed Metadata_metadata</span>\n  <span data-ty>[13:46:53.320] INFO: Polkadot RPC listening on port 8002</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty>[13:46:54.038] INFO (xcm): Connected relaychain 'Polkadot' with parachain 'Moonbeam'</span>\n  <span data-ty> app: \"chopsticks\"</span>\n  <span data-ty>[13:46:55.028] INFO (xcm): Connected relaychain 'Polkadot' with parachain 'Astar'</span>\n  <span data-ty> app: \"chopsticks\"</span>\n</div>\n\n\nNow you can interact with your forked chains using the ports specified in the output."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 38, "end_char": 732, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nZombienet simplifies blockchain development by enabling developers to create temporary, customizable networks for testing and validation. These ephemeral chains are ideal for experimenting with configurations, debugging applications, and validating functionality in a controlled environment.\n\nIn this guide, you'll learn how to define a basic network configuration file, spawn a blockchain network using Zombienet's CLI, and interact with nodes and monitor network activity using tools like Polkadot.js Apps and Prometheus\n\nBy the end of this tutorial, you'll be equipped to deploy and test your own blockchain networks, paving the way for more advanced setups and use cases."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 732, "end_char": 1297, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo successfully complete this tutorial, you must ensure you've first:\n\n- [Installed Zombienet](/develop/toolkit/parachains/spawn-chains/zombienet/get-started/#install-zombienet){target=\\_blank}. This tutorial requires Zombienet version `v1.3.133`. Verify that you're using the specified version to ensure compatibility with the instructions.\n- Reviewed the information in [Configure Zombienet](/develop/toolkit/parachains/spawn-chains/zombienet/get-started/#configure-zombienet){target=\\_blank} and understand how to customize a spawned network."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 2, "depth": 2, "title": "Set Up Local Provider", "anchor": "set-up-local-provider", "start_char": 1297, "end_char": 2341, "estimated_token_count": 238, "token_estimator": "heuristic-v1", "text": "## Set Up Local Provider\n\nIn this tutorial, you will use the Zombienet [local provider](/develop/toolkit/parachains/spawn-chains/zombienet/get-started/#local-provider){target=\\_blank} (also called native provider) that enables you to run nodes as local processes in your development environment.\n\nYou must have the necessary binaries installed (such as `polkadot` and `polkadot-parachain`) to spin up your network successfully.\n\nTo install the required binaries, use the following Zombienet CLI command:\n\n```bash\nzombienet setup polkadot polkadot-parachain\n```\n\nThis command downloads the following binaries:\n\n- `polkadot`\n- `polkadot-execute-worker`\n- `polkadot-parachain`\n- `polkadot-prepare-worker`\n\nFinally, add these binaries to your PATH environment variable to ensure Zombienet can locate them when spawning the network.\n\nFor example, you can move the binaries to a directory in your PATH, such as `/usr/local/bin`:\n\n```bash\nsudo mv ./polkadot ./polkadot-execute-worker ./polkadot-parachain ./polkadot-prepare-worker /usr/local/bin\n```"}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 3, "depth": 2, "title": "Define the Network", "anchor": "define-the-network", "start_char": 2341, "end_char": 3325, "estimated_token_count": 248, "token_estimator": "heuristic-v1", "text": "## Define the Network\n\nZombienet uses a [configuration file](/develop/toolkit/parachains/spawn-chains/zombienet/get-started/#configuration-files){target=\\_blank} to define the ephemeral network that will be spawned. Follow these steps to create and define the configuration file:\n\n1. Create a file named `spawn-a-basic-network.toml`:\n\n    ```bash\n    touch spawn-a-basic-network.toml\n    ```\n\n2. Add the following code to the file you just created:\n\n    ```toml title=\"spawn-a-basic-network.toml\"\n    -[settings]\ntimeout = 120\n\n[relaychain]\n\n[[relaychain.nodes]]\nname = \"alice\"\nvalidator = true\n\n[[relaychain.nodes]]\nname = \"bob\"\nvalidator = true\n\n[[parachains]]\nid = 100\n\n[parachains.collator]\nname = \"collator01\"\n\n    ```\n\nThis configuration file defines a network with the following chains:\n\n- **relaychain**: With two nodes named `alice` and `bob`.\n- **parachain**: With a collator named `collator01`.\n\nSettings also defines a timeout of 120 seconds for the network to be ready."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 4, "depth": 2, "title": "Spawn the Network", "anchor": "spawn-the-network", "start_char": 3325, "end_char": 6703, "estimated_token_count": 1133, "token_estimator": "heuristic-v1", "text": "## Spawn the Network\n\nTo spawn the network, run the following command:\n\n```bash\nzombienet -p native spawn spawn-a-basic-network.toml\n```\n\nThis command will spawn the network defined in the `spawn-a-basic-network.toml` configuration file. The `-p native` flag specifies that the network will be spawned using the native provider.\n\nIf successful, you will see the following output:\n\n-<div id=\"termynal\" class=\"table-termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>zombienet -p native spawn spawn-a-basic-network.toml</span>\n  <table>\n    <thead>\n      <tr>\n        <th colspan=\"2\" class=\"center-header\">Network launched 🚀🚀</th>\n      </tr>\n    </thead>\n    <tr>\n      <th class=\"left-header\">Namespace</th>\n      <td>zombie-75a01b93c92d571f6198a67bcb380fcd</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Provider</th>\n      <td>native</td>\n    </tr>\n    <tr>\n      <th colspan=\"3\" class=\"center-header\">Node Information</th>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Name</th>\n      <td>alice</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Direct Link</th>\n      <td><a href=\"https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:55308#explorer\">https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:55308#explorer</a></td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Prometheus Link</th>\n      <td>http://127.0.0.1:55310/metrics</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Log Cmd</th>\n      <td>tail -f /tmp/zombie-794af21178672e1ff32c612c3c7408dc_-2397036-6717MXDxcS55/alice.log</td>\n    </tr>\n    <tr>\n      <th colspan=\"3\" class=\"center-header\">Node Information</th>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Name</th>\n      <td>bob</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Direct Link</th>\n      <td><a href=\"https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:50312#explorer\">https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:55312#explorer</a></td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Prometheus Link</th>\n      <td>http://127.0.0.1:50634/metrics</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Log Cmd</th>\n      <td>tail -f /tmp/zombie-794af21178672e1ff32c612c3c7408dc_-2397036-6717MXDxcS55/bob.log</td>\n    </tr>\n    <tr>\n      <th colspan=\"3\" class=\"center-header\">Node Information</th>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Name</th>\n      <td>collator01</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Direct Link</th>\n      <td><a href=\"https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:55316#explorer\">https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:55316#explorer</a></td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Prometheus Link</th>\n      <td>http://127.0.0.1:55318/metrics</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Log Cmd</th>\n      <td>tail -f /tmp/zombie-794af21178672e1ff32c612c3c7408dc_-2397036-6717MXDxcS55/collator01.log</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">Parachain ID</th>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th class=\"left-header\">ChainSpec Path</th>\n      <td>/tmp/zombie-794af21178672e1ff32c612c3c7408dc_-2397036-6717MXDxcS55/100-rococo-local.json</td>\n    </tr>\n  </table>\n</div>\n\n\n!!! note \n    If the IPs and ports aren't explicitly defined in the configuration file, they may change each time the network is started, causing the links provided in the output to differ from the example."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 5, "depth": 2, "title": "Interact with the Spawned Network", "anchor": "interact-with-the-spawned-network", "start_char": 6703, "end_char": 6965, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Interact with the Spawned Network\n\nAfter the network is launched, you can interact with it using [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank}. To do so, open your browser and use the provided links listed by the output as `Direct Link`."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 6, "depth": 3, "title": "Connect to the Nodes", "anchor": "connect-to-the-nodes", "start_char": 6965, "end_char": 8310, "estimated_token_count": 366, "token_estimator": "heuristic-v1", "text": "### Connect to the Nodes\n\nUse the [55308 port address](https://polkadot.js.org/apps/?rpc=ws://127.0.0.1:55308#explorer){target=\\_blank} to interact with the same `alice` node used for this tutorial. Ports can change from spawn to spawn so be sure to locate the link in the output when spawning your own node to ensure you are accessing the correct port.\n\nIf you want to interact with the nodes more programmatically, you can also use the [Polkadot.js API](https://polkadot.js.org/docs/api/){target=\\_blank}. For example, the following code snippet shows how to connect to the `alice` node using the Polkadot.js API and log some information about the chain and node:\n\n```typescript\n-import { ApiPromise, WsProvider } from '@polkadot/api';\n\nasync function main() {\n  const wsProvider = new WsProvider('ws://127.0.0.1:55308');\n  const api = await ApiPromise.create({ provider: wsProvider });\n\n  // Retrieve the chain & node information via rpc calls\n  const [chain, nodeName, nodeVersion] = await Promise.all([\n    api.rpc.system.chain(),\n    api.rpc.system.name(),\n    api.rpc.system.version(),\n  ]);\n\n  console.log(\n    `You are connected to chain ${chain} using ${nodeName} v${nodeVersion}`\n  );\n}\n\nmain()\n  .catch(console.error)\n  .finally(() => process.exit());\n\n```\n\nBoth methods allow you to interact easily with the network and its nodes."}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 7, "depth": 3, "title": "Check Metrics", "anchor": "check-metrics", "start_char": 8310, "end_char": 8857, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Check Metrics\n\nYou can also check the metrics of the nodes by accessing the links provided in the output as `Prometheus Link`. [Prometheus](https://prometheus.io/){target=\\_blank} is a monitoring and alerting toolkit that collects metrics from the nodes. By accessing the provided links, you can see the metrics of the nodes in a web interface. So, for example, the following image shows the Prometheus metrics for Bob's node from the Zombienet test:\n\n![](/images/tutorials/polkadot-sdk/testing/spawn-basic-chain/spawn-basic-network-01.webp)"}
{"page_id": "tutorials-polkadot-sdk-testing-spawn-basic-chain", "index": 8, "depth": 3, "title": "Check Logs", "anchor": "check-logs", "start_char": 8857, "end_char": 9528, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "### Check Logs\n\nTo view individual node logs, locate the `Log Cmd` command in Zombienet's startup output. For example, to see what the alice node is doing, find the log command that references `alice.log` in its file path. Note that Zombienet will show you the correct path for your instance when it starts up, so use that path rather than copying from the below example:\n\n```bash\ntail -f  /tmp/zombie-794af21178672e1ff32c612c3c7408dc_-2397036-6717MXDxcS55/alice.log\n```\n\nAfter running this command, you will see the logs of the `alice` node in real-time, which can be useful for debugging purposes. The logs of the `bob` and `collator01` nodes can be checked similarly."}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 193, "end_char": 859, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nDecentralized exchanges (DEXs) are a cornerstone of the DeFi ecosystem, allowing for permissionless token swaps without intermediaries. [Uniswap V2](https://docs.uniswap.org/contracts/v2/overview){target=\\_blank}, with its Automated Market Maker (AMM) model, revolutionized DEXs by enabling liquidity provision for any ERC-20 token pair.\n\nThis tutorial will guide you through how Uniswap V2 works so you can take advantage of it in your projects deployed to Polkadot Hub. By understanding these contracts, you'll gain hands-on experience with one of the most influential DeFi protocols and understand how it functions across blockchain ecosystems."}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 859, "end_char": 1354, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, make sure you have:\n\n- Node.js (v16.0.0 or later) and npm installed.\n- Basic understanding of Solidity and JavaScript.\n- Familiarity with [`hardhat-polkadot`](/develop/smart-contracts/dev-environments/hardhat){target=\\_blank} development environment.\n- Some PAS test tokens to cover transaction fees (obtained from the [Polkadot faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}).\n- Basic understanding of how AMMs and liquidity pools work."}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 2, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1354, "end_char": 3694, "estimated_token_count": 573, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nLet's start by cloning the Uniswap V2 project:\n\n1. Clone the Uniswap V2 repository:\n\n    ```\n    git clone https://github.com/polkadot-developers/polkavm-hardhat-examples.git -b v0.0.6\n    cd polkavm-hardhat-examples/uniswap-v2-polkadot/\n    ```\n\n2. Install the required dependencies:\n\n    ```bash\n    npm install\n    ```\n\n3. Update the `hardhat.config.js` file so the paths for the Substrate node and the ETH-RPC adapter match with the paths on your machine. For more info, check the [Testing your Contract](/develop/smart-contracts/dev-environments/hardhat/#testing-your-contract){target=\\_blank} section in the Hardhat guide.\n\n    ```js title=\"hardhat.config.js\"\n    hardhat: {\n      polkavm: true,\n      nodeConfig: {\n        nodeBinaryPath: '../bin/substrate-node',\n        rpcPort: 8000,\n        dev: true,\n      },\n      adapterConfig: {\n        adapterBinaryPath: '../bin/eth-rpc',\n        dev: true,\n      },\n    },\n    ```\n\n4. Create a `.env` file in your project root to store your private keys (you can use as an example the `env.example` file):\n\n    ```text title=\".env\"\n    LOCAL_PRIV_KEY=\"INSERT_LOCAL_PRIVATE_KEY\"\n    AH_PRIV_KEY=\"INSERT_AH_PRIVATE_KEY\"\n    ```\n\n    Ensure to replace `\"INSERT_LOCAL_PRIVATE_KEY\"` with a private key available in the local environment (you can get them from this [file](https://github.com/paritytech/hardhat-polkadot/blob/main/packages/hardhat-polkadot-node/src/constants.ts#L22){target=\\_blank}). And `\"INSERT_AH_PRIVATE_KEY\"` with the account's private key you want to use to deploy the contracts. You can get this by exporting the private key from your wallet (e.g., MetaMask).\n\n    !!!warning\n        Keep your private key safe, and never share it with anyone. If it is compromised, your funds can be stolen.\n\n5. Compile the contracts:\n\n    ```bash\n    npx hardhat compile\n    ```\n\nIf the compilation is successful, you should see the following output:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat compile</span>\n  <span data-ty>Compiling 12 Solidity files</span>\n  <span data-ty>Successfully compiled 12 Solidity files</span>\n</div>\n\n\nAfter running the above command, you should see the compiled contracts in the `artifacts-pvm` directory. This directory contains the ABI and bytecode of your contracts."}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 3, "depth": 2, "title": "Understanding Uniswap V2 Architecture", "anchor": "understanding-uniswap-v2-architecture", "start_char": 3694, "end_char": 6046, "estimated_token_count": 527, "token_estimator": "heuristic-v1", "text": "## Understanding Uniswap V2 Architecture\n\nBefore interacting with the contracts, it's essential to understand the core architecture that powers Uniswap V2. This model forms the basis of nearly every modern DEX implementation and operates under automated market making, token pair liquidity pools, and deterministic pricing principles.\n\nAt the heart of Uniswap V2 lies a simple but powerful system composed of two major smart contracts:\n\n- **Factory contract**: The factory acts as a registry and creator of new trading pairs. When two ERC-20 tokens are to be traded, the Factory contract is responsible for generating a new Pair contract that will manage that specific token pair’s liquidity pool. It keeps track of all deployed pairs and ensures uniqueness—no duplicate pools can exist for the same token combination.\n- **Pair contract**: Each pair contract is a decentralized liquidity pool that holds reserves of two ERC-20 tokens. These contracts implement the core logic of the AMM, maintaining a constant product invariant (x \\* y = k) to facilitate swaps and price determination. Users can contribute tokens to these pools in return for LP (liquidity provider) tokens, which represent their proportional share of the reserves.\n\nThis minimal architecture enables Uniswap to be highly modular, trustless, and extensible. By distributing responsibilities across these components, developers, and users can engage with the protocol in a composable and predictable manner, making it an ideal foundation for DEX functionality across ecosystems, including Polkadot Hub.\n\nThe project scaffolding is as follows:\n\n```bash\nuniswap-V2-polkadot\n├── bin/\n├── contracts/\n│   ├── interfaces/\n│   │   ├── IERC20.sol\n│   │   ├── IUniswapV2Callee.sol\n│   │   ├── IUniswapV2ERC20.sol\n│   │   ├── IUniswapV2Factory.sol\n│   │   └── IUniswapV2Pair.sol\n│   ├── libraries/\n│   │   ├── Math.sol\n│   │   ├── SafeMath.sol\n│   │   └── UQ112x112.sol\n│   ├── test/\n│   │   └── ERC20.sol\n│   ├── UniswapV2ERC20.sol\n│   ├── UniswapV2Factory.sol\n│   └── UniswapV2Pair.sol\n├── ignition/\n├── scripts/\n│   └── deploy.js\n├── node_modules/\n├── test/\n│   ├── shared/\n│   │   ├── fixtures.js\n│   │   └── utilities.js\n│   ├── UniswapV2ERC20.js\n│   ├── UniswapV2Factory.js\n│   └── UniswapV2Pair.js\n├── .env.example\n├── .gitignore\n├── hardhat.config.js\n├── package.json\n└── README.md\n```"}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 4, "depth": 2, "title": "Test the Contracts", "anchor": "test-the-contracts", "start_char": 6046, "end_char": 8646, "estimated_token_count": 789, "token_estimator": "heuristic-v1", "text": "## Test the Contracts\n\nYou can run the provided test suite to ensure the contracts are working as expected. The tests cover various scenarios, including creating pairs, adding liquidity, and executing swaps.\n\nTo test it locally, you can run the following commands:\n\n1. Spawn a local node for testing:\n\n    ```bash\n    npx hardhat node\n    ```\n\n    This command will spawn a local Substrate node along with the ETH-RPC adapter. The node will be available at `ws://127.0.0.1:8000` and the ETH-RPC adapter at `http://localhost:8545`.\n\n2. In a new terminal, run the tests:\n\n    ```bash\n    npx hardhat test --network localNode\n    ```\n\nThe result should look like this:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat test --network localNode</span>\n  <span data-ty>Compiling 12 Solidity files</span>\n  <span data-ty>Successfully compiled 12 Solidity files</span>\n  <span data-ty></span>\n  <span data-ty>UniswapV2ERC20</span>\n  <span data-ty> ✔ name, symbol, decimals, totalSupply, balanceOf, DOMAIN_SEPARATOR, PERMIT_TYPEHASH (44ms)</span>\n  <span data-ty> ✔ approve (5128ms)</span>\n  <span data-ty> ✔ transfer (5133ms)</span>\n  <span data-ty> ✔ transfer:fail</span>\n  <span data-ty> ✔ transferFrom (6270ms)</span>\n  <span data-ty> ✔ transferFrom:max (6306ms)</span>\n  <span data-ty></span>\n  <span data-ty>UniswapV2Factory</span>\n  <span data-ty> ✔ feeTo, feeToSetter, allPairsLength</span>\n  <span data-ty> ✔ createPair (176ms)</span>\n  <span data-ty> ✔ createPair:reverse (1224ms)</span>\n  <span data-ty> ✔ setFeeTo (1138ms)</span>\n  <span data-ty> ✔ setFeeToSetter (1125ms)</span>\n  <span data-ty></span>\n  <span data-ty>UniswapV2Pair</span>\n  <span data-ty> ✔ mint (11425ms)</span>\n  <span data-ty> ✔ getInputPrice:0 (12590ms)</span>\n  <span data-ty> ✔ getInputPrice:1 (17600ms)</span>\n  <span data-ty> ✔ getInputPrice:2 (17618ms)</span>\n  <span data-ty> ✔ getInputPrice:3 (17704ms)</span>\n  <span data-ty> ✔ getInputPrice:4 (17649ms)</span>\n  <span data-ty> ✔ getInputPrice:5 (17594ms)</span>\n  <span data-ty> ✔ getInputPrice:6 (13643ms)</span>\n  <span data-ty> ✔ optimistic:0 (17647ms)</span>\n  <span data-ty> ✔ optimistic:1 (17946ms)</span>\n  <span data-ty> ✔ optimistic:2 (17657ms)</span>\n  <span data-ty> ✔ optimistic:3 (21625ms)</span>\n  <span data-ty> ✔ swap:token0 (12665ms)</span>\n  <span data-ty> ✔ swap:token1 (17631ms)</span>\n  <span data-ty> ✔ burn (17690ms)</span>\n  <span data-ty> ✔ feeTo:off (23900ms)</span>\n  <span data-ty> ✔ feeTo:on (24991ms)</span>\n  <span data-ty></span>\n  <span data-ty>28 passing (12m)</span>\n</div>"}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 5, "depth": 2, "title": "Deploy the Contracts", "anchor": "deploy-the-contracts", "start_char": 8646, "end_char": 10391, "estimated_token_count": 380, "token_estimator": "heuristic-v1", "text": "## Deploy the Contracts\n\nAfter successfully testing the contracts, you can deploy them to the local node or Polkadot Hub. The deployment script is located in the `scripts` directory and is named `deploy.js`. This script deploys the `Factory` and `Pair` contracts to the network.\n\nTo deploy the contracts, run the following command:\n\n```bash\nnpx hardhat run scripts/deploy.js --network localNode\n```\n\nThis command deploys the contracts to your local blockchain for development and testing. If you want to deploy to Polkadot Hub, you can use the following command:\n\n```bash\nnpx hardhat run scripts/deploy.js --network passetHub\n```\n\nThe command above deploys to the actual Polkadot TestNet. It requires PAS test tokens, persists on the network, and operates under real network conditions.\n\nThe deployment script will output the addresses of the deployed contracts. Save these addresses, as you will need them to interact with the contracts. For example, the output should look like this:\n\n-<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat run scripts/deploy.js --network localNode</span>\n  <span data-ty>Successfully compiled 12 Solidity files</span>\n  <span data-ty>Deploying contracts using 0xf24FF3a9CF04c71Dbc94D0b566f7A27B94566cac</span>\n  <span data-ty>Deploying UniswapV2ERC20...</span>\n  <span data-ty>ETH deployed to : 0x7acc1aC65892CF3547b1b0590066FB93199b430D</span>\n  <span data-ty>Deploying UniswapV2Factory...</span>\n  <span data-ty>Factory deployed to : 0x85b108660f47caDfAB9e0503104C08C1c96e0DA9</span>\n  <span data-ty>Deploying UniswapV2Pair with JsonRpcProvider workaround...</span>\n  <span data-ty>Pair deployed to : 0xF0e46847c8bFD122C4b5EEE1D4494FF7C5FC5104</span>\n</div>"}
{"page_id": "tutorials-smart-contracts-demo-aplications-deploying-uniswap-v2", "index": 6, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 10391, "end_char": 11296, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThis tutorial guided you through deploying Uniswap V2 contracts to Polkadot Hub. This implementation brings the powerful AMM architecture to the Polkadot ecosystem, laying the foundation for the decentralized trading of ERC-20 token pairs.\n\nBy following this guide, you've gained practical experience with:\n\n- Setting up a Hardhat project for deploying to Polkadot Hub.\n- Understanding the Uniswap V2 architecture.\n- Testing Uniswap V2 contracts in a local environment.\n- Deploying contracts to both local and testnet environments.\n\nTo build on this foundation, you could extend this project by implementing functionality to create liquidity pools, execute token swaps, and build a user interface for interacting with your deployment.\n\nThis knowledge can be leveraged to build more complex DeFi applications or to integrate Uniswap V2 functionality into your existing projects on Polkadot."}
{"page_id": "tutorials-smart-contracts-deploy-erc20", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 208, "end_char": 860, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[ERC-20](https://eips.ethereum.org/EIPS/eip-20){target=\\_blank} tokens are fungible tokens commonly used for creating cryptocurrencies, governance tokens, and staking mechanisms. Polkadot Hub enables easy token deployment with Ethereum-compatible smart contracts via PolkaVM.\n\nThis tutorial covers deploying an ERC-20 contract on the Polkadot Hub TestNet using [Polkadot Remix IDE](https://remix.polkadot.io){target=\\_blank}, a web-based development tool. [OpenZeppelin's ERC-20 contracts](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v5.4.0/contracts/token/ERC20){target=\\_blank} are used for security and compliance."}
{"page_id": "tutorials-smart-contracts-deploy-erc20", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 860, "end_char": 1471, "estimated_token_count": 160, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, make sure you have:\n\n- [MetaMask](https://metamask.io/){target=\\_blank} installed and connected to Polkadot Hub. For detailed instructions, see the [Connect Your Wallet](/develop/smart-contracts/wallets){target=\\_blank} section.\n- A funded account with some PAS tokens (you can get them from the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}). To learn how to get test tokens, check out the [Test Tokens](/develop/smart-contracts/connect-to-polkadot#test-tokens){target=\\_blank} section.\n- Basic understanding of Solidity and fungible tokens."}
{"page_id": "tutorials-smart-contracts-deploy-erc20", "index": 2, "depth": 2, "title": "Create the ERC-20 Contract", "anchor": "create-the-erc-20-contract", "start_char": 1471, "end_char": 4848, "estimated_token_count": 816, "token_estimator": "heuristic-v1", "text": "## Create the ERC-20 Contract\n\nTo create the ERC-20 contract, you can follow the steps below:\n\n1. Navigate to the [Polkadot Remix IDE](https://remix.polkadot.io){target=\\_blank}.\n2. Click in the **Create new file** button under the **contracts** folder, and name your contract as `MyToken.sol`.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-1.webp)\n\n3. Now, paste the following ERC-20 contract code into the editor:\n\n    ```solidity title=\"MyToken.sol\"\n    -// SPDX-License-Identifier: MIT\n// Compatible with OpenZeppelin Contracts ^5.0.0\npragma solidity ^0.8.22;\n\nimport {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\nimport {Ownable} from \"@openzeppelin/contracts/access/Ownable.sol\";\n\ncontract MyToken is ERC20, Ownable {\n    constructor(address initialOwner)\n        ERC20(\"MyToken\", \"MTK\")\n        Ownable(initialOwner)\n    {}\n\n    function mint(address to, uint256 amount) public onlyOwner {\n        _mint(to, amount);\n    }\n}\n    ```\n\n    The key components of the code above are:\n\n    - Contract imports:\n\n        - **[`ERC20.sol`](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v5.4.0/contracts/token/ERC20/ERC20.sol){target=\\_blank}**: The base contract for fungible tokens, implementing core functionality like transfers, approvals, and balance tracking.\n        - **[`Ownable.sol`](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v5.4.0/contracts/access/Ownable.sol){target=\\_blank}**: Provides basic authorization control, ensuring only the contract owner can mint new tokens.\n    \n    - Constructor parameters:\n\n        - **`initialOwner`**: Sets the address that will have administrative rights over the contract.\n        - **`\"MyToken\"`**: The full name of your token.\n        - **`\"MTK\"`**: The symbol representing your token in wallets and exchanges.\n\n    - Key functions:\n\n        - **`mint(address to, uint256 amount)`**: Allows the contract owner to create new tokens for any address. The amount should include 18 decimals (e.g., 1 token = 1000000000000000000).\n        - Inherited [Standard ERC-20](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/){target=\\_blank} functions:\n            - **`transfer(address recipient, uint256 amount)`**: Sends a specified amount of tokens to another address.\n            - **`approve(address spender, uint256 amount)`**: Grants permission for another address to spend a specific number of tokens on behalf of the token owner.\n            - **`transferFrom(address sender, address recipient, uint256 amount)`**: Transfers tokens from one address to another, if previously approved.\n            - **`balanceOf(address account)`**: Returns the token balance of a specific address.\n            - **`allowance(address owner, address spender)`**: Checks how many tokens an address is allowed to spend on behalf of another address.\n\n    !!! tip\n        Use the [OpenZeppelin Contracts Wizard](https://wizard.openzeppelin.com/){target=\\_blank} to quickly generate customized smart contracts. Simply configure your contract, copy the generated code, and paste it into Polkadot Remix IDE for deployment. Below is an example of an ERC-20 token contract created with it:\n\n        ![Screenshot of the OpenZeppelin Contracts Wizard showing an ERC-20 contract configuration.](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-2.webp)"}
{"page_id": "tutorials-smart-contracts-deploy-erc20", "index": 3, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 4848, "end_char": 5673, "estimated_token_count": 192, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nThe compilation transforms your Solidity source code into bytecode that can be deployed on the blockchain. During this process, the compiler checks your contract for syntax errors, ensures type safety, and generates the machine-readable instructions needed for blockchain execution. To compile your contract, follow the instructions below:\n\n1. Select the **Solidity Compiler** plugin from the left panel.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-3.webp)\n\n2. Click the **Compile MyToken.sol** button.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-4.webp)\n\n3. If the compilation succeeded, you'll see a green checkmark indicating success in the **Solidity Compiler** icon.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-5.webp)"}
{"page_id": "tutorials-smart-contracts-deploy-erc20", "index": 4, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 5673, "end_char": 7232, "estimated_token_count": 375, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nDeployment is the process of publishing your compiled smart contract to the blockchain, making it permanently available for interaction. During deployment, you'll create a new instance of your contract on the blockchain, which involves:\n\n1. Select the **Deploy & Run Transactions** plugin from the left panel.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-6.webp)\n\n2. Configure the deployment settings.\n    1. From the **ENVIRONMENT** dropdown, select **Injected Provider - Talisman** (check the [Deploying Contracts](/develop/smart-contracts/dev-environments/remix/#deploying-contracts){target=\\_blank} section of the Remix IDE guide for more details).\n    2. From the **ACCOUNT** dropdown, select the account you want to use for the deploy.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-7.webp)\n\n3. Configure the contract parameters:\n\n    1. Enter the address that will own the deployed token contract.\n    2. Click the **Deploy** button to initiate the deployment.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-8.webp)\n\n4. **Talisman will pop up**: Review the transaction details. Click **Approve** to deploy your contract.\n\n     ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-9.webp){: .browser-extension}\n\n    If the deployment process succeeded, you will see the transaction details in the terminal, including the contract address and deployment transaction hash:\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-10.webp)"}
{"page_id": "tutorials-smart-contracts-deploy-erc20", "index": 5, "depth": 2, "title": "Interact with Your ERC-20 Contract", "anchor": "interact-with-your-erc-20-contract", "start_char": 7232, "end_char": 8691, "estimated_token_count": 355, "token_estimator": "heuristic-v1", "text": "## Interact with Your ERC-20 Contract\n\nOnce deployed, you can interact with your contract through Remix:\n\n1. Find your contract under **Deployed/Unpinned Contracts**, and click it to expand the available methods.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-11.webp)\n\n2. To mint new tokens:\n\n    1. Click in the contract to expand its associated methods.\n    2. Expand the **mint** function.\n    3. Enter:\n        - The recipient address.\n        - The amount (remember to add 18 zeros for 1 whole token).\n    4. Click **Transact**.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-12.webp)\n\n3. Click **Approve** to confirm the transaction in the Talisman popup.\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-13.webp){: .browser-extension}\n\n    If the transaction succeeds, you will see the following output in the terminal:\n\n    ![](/images/tutorials/smart-contracts/deploy-erc20/deploy-erc20-14.webp)\n\nOther common functions you can use:\n\n- **`balanceOf(address)`**: Check token balance of any address.\n- **`transfer(address to, uint256 amount)`**: Send tokens to another address.\n- **`approve(address spender, uint256 amount)`**: Allow another address to spend your tokens.\n\nFeel free to explore and interact with the contract's other functions using the same approach - selecting the method, providing any required parameters, and confirming the transaction through Talisman when needed."}
{"page_id": "tutorials-smart-contracts-deploy-nft", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 205, "end_char": 927, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nNon-Fungible Tokens (NFTs) represent unique digital assets commonly used for digital art, collectibles, gaming, and identity verification. Polkadot Hub supports Ethereum-compatible smart contracts through PolkaVM, enabling straightforward NFT deployment.\n\nThis tutorial guides you through deploying an [ERC-721](https://eips.ethereum.org/EIPS/eip-721){target=\\_blank} NFT contract on the Polkadot Hub TestNet using the [Polkadot Remix IDE](https://remix.polkadot.io){target=\\_blank}, a web-based development environment. To ensure security and standard compliance, it uses [OpenZeppelin's NFT contracts](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v5.4.0){target=\\_blank} implementation."}
{"page_id": "tutorials-smart-contracts-deploy-nft", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 927, "end_char": 1685, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, make sure you have:\n\n- [Talisman](https://talisman.xyz/){target=\\_blank} installed and connected to the Polkadot Hub TestNet. Check the [Connect to Polkadot](/develop/smart-contracts/connect-to-polkadot/){target=\\_blank} guide for more information.\n- A funded account with some PAS tokens (you can get them from the [Faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}, noting that the faucet imposes a daily token limit, which may require multiple requests to obtain sufficient funds for testing).\n- Basic understanding of Solidity and NFTs, see the [Solidity Basics](https://soliditylang.org/){target=\\_blank} and the [NFT Overview](https://ethereum.org/en/nft/){target=\\_blank} guides for more details."}
{"page_id": "tutorials-smart-contracts-deploy-nft", "index": 2, "depth": 2, "title": "Create the NFT Contract", "anchor": "create-the-nft-contract", "start_char": 1685, "end_char": 5672, "estimated_token_count": 938, "token_estimator": "heuristic-v1", "text": "## Create the NFT Contract\n\nTo create the NFT contract, you can follow the steps below:\n\n1. Navigate to the [Polkadot Remix IDE](https://remix.polkadot.io/){target=\\_blank}.\n2. Click in the **Create new file** button under the **contracts** folder, and name your contract as `MyNFT.sol`.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-1.webp)\n\n3. Now, paste the following NFT contract code into the editor.\n\n    ```solidity title=\"MyNFT.sol\"\n    -// SPDX-License-Identifier: MIT\n// Compatible with OpenZeppelin Contracts ^5.0.0\npragma solidity ^0.8.22;\n\nimport {ERC721} from \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\nimport {Ownable} from \"@openzeppelin/contracts/access/Ownable.sol\";\n\ncontract MyToken is ERC721, Ownable {\n    uint256 private _nextTokenId;\n\n    constructor(address initialOwner)\n        ERC721(\"MyToken\", \"MTK\")\n        Ownable(initialOwner)\n    {}\n\n    function safeMint(address to) public onlyOwner {\n        uint256 tokenId = _nextTokenId++;\n        _safeMint(to, tokenId);\n    }\n}\n    ```\n\n    The key components of the code above are:\n\n    - Contract imports:\n\n        - **[`ERC721.sol`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v5.4.0/contracts/token/ERC721/ERC721.sol){target=\\_blank}**: The base contract for non-fungible tokens, implementing core NFT functionality like transfers and approvals.\n        - **[`Ownable.sol`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v5.4.0/contracts/access/Ownable.sol){target=\\_blank}**: Provides basic authorization control, ensuring only the contract owner can mint new tokens.\n    \n    - Constructor parameters:\n\n        - **`initialOwner`**: Sets the address that will have administrative rights over the contract.\n        - **`\"MyToken\"`**: The full name of your NFT collection.\n        - **`\"MTK\"`**: The symbol representing your token in wallets and marketplaces.\n\n    - Key functions:\n\n        - **[`_safeMint(to, tokenId)`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v5.4.0/contracts/token/ERC721/ERC721.sol#L304){target=\\_blank}**: An internal function from `ERC721` that safely mints new tokens. It includes checks to ensure the recipient can handle `ERC721` tokens, with the `_nextTokenId` mechanism automatically generating unique sequential token IDs and the `onlyOwner` modifier restricting minting rights to the contract owner.\n        - Inherited [Standard ERC721](https://ethereum.org/en/developers/docs/standards/tokens/erc-721/){target=\\_blank} functions provide a standardized set of methods that enable interoperability across different platforms, wallets, and marketplaces, ensuring that your NFT can be easily transferred, traded, and managed by any system that supports the `ERC721` standard:\n            - **`transferFrom(address from, address to, uint256 tokenId)`**: Transfers a specific NFT from one address to another.\n            - **`safeTransferFrom(address from, address to, uint256 tokenId)`**: Safely transfers an NFT, including additional checks to prevent loss.\n            - **`approve(address to, uint256 tokenId)`**: Grants permission for another address to transfer a specific NFT.\n            - **`setApprovalForAll(address operator, bool approved)`**: Allows an address to manage all of the owner's NFTs.\n            - **`balanceOf(address owner)`**: Returns the number of NFTs owned by a specific address.\n            - **`ownerOf(uint256 tokenId)`**: Returns the current owner of a specific NFT.\n\n    !!! tip\n        Use the [OpenZeppelin Contracts Wizard](https://wizard.openzeppelin.com/){target=\\_blank} to generate customized smart contracts quickly. Simply configure your contract, copy the generated code, and paste it into Polkadot Remix IDE for deployment. Below is an example of an ERC-721 token contract created with it:\n\n        ![Screenshot of the OpenZeppelin Contracts Wizard showing an ERC-721 contract configuration.](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-2.webp)"}
{"page_id": "tutorials-smart-contracts-deploy-nft", "index": 3, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 5672, "end_char": 6445, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nCompilation is a stage that converts your Solidity source code into bytecode suitable for deployment on the blockchain. Throughout this process, the compiler examines your contract for syntax errors, verifies type safety, and produces machine-readable instructions for execution on the blockchain.\n\n1. Select the **Solidity Compiler** plugin from the left panel.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-3.webp)\n\n2. Click in the **Compile MyNFT.sol** button.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-4.webp)\n\n3. If the compilation succeeded, you can see a green checkmark indicating success in the **Solidity Compiler** icon.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-5.webp)"}
{"page_id": "tutorials-smart-contracts-deploy-nft", "index": 4, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 6445, "end_char": 8324, "estimated_token_count": 445, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nDeployment is the process of uploading your compiled smart contract to the blockchain, allowing for interaction. During deployment, you will instantiate your contract on the blockchain, which involves:\n\n1. Select the **Deploy & Run Transactions** plugin from the left panel.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-6.webp)\n\n2. Configure the deployment settings:\n\n    1. From the **ENVIRONMENT** dropdown, select **Injected Provider - Talisman** (check the [Deploying Contracts](/develop/smart-contracts/dev-environments/remix/#deploying-contracts){target=\\_blank} section of the Remix IDE guide for more details).\n    2. From the **ACCOUNT** dropdown, select the account you want to use for the deploy.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-7.webp)\n\n3. Configure the contract parameters:\n\n    1. Enter the address that will own the deployed NFT.\n    2. Click the **Deploy** button to initiate the deployment.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-8.webp)\n\n4. **Talisman will pop up**: Review the transaction details. Click **Approve** to deploy your contract.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-9.webp){: .browser-extension}\n\n    Deploying this contract requires paying gas fees in PAS tokens on the Polkadot Hub TestNet. Ensure your Talisman account is funded with sufficient PAS tokens from the faucet before confirming the transaction, check the [Test Tokens](/develop/smart-contracts/connect-to-polkadot/#test-tokens){target=\\_blank} section for more information. Gas fees cover the computational resources needed to deploy and execute the smart contract on the blockchain.\n\n    If the deployment process succeeded, you will see the following output in the terminal:\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-10.webp)"}
{"page_id": "tutorials-smart-contracts-deploy-nft", "index": 5, "depth": 2, "title": "Interact with Your NFT Contract", "anchor": "interact-with-your-nft-contract", "start_char": 8324, "end_char": 9566, "estimated_token_count": 291, "token_estimator": "heuristic-v1", "text": "## Interact with Your NFT Contract\n\nOnce deployed, you can interact with your contract through Remix:\n\n1. Find your contract under **Deployed/Unpinned Contracts**, and click it to expand the available methods for the contract.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-11.webp)\n\n2. To mint an NFT:\n\n    1. Click on the contract to expand its associated methods.\n    2. Expand the **safeMint** function.\n    3. Enter the recipient address.\n    4. Click **Transact**.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-12.webp)\n\n3. Click **Approve** to confirm the transaction in the Talisman popup.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-13.webp){: .browser-extension}\n\n    If the transaction is successful, the terminal will display the following output, which details the information about the transaction, including the transaction hash, the block number, the associated logs, and so on.\n\n    ![](/images/tutorials/smart-contracts/deploy-nft/deploy-nft-14.webp)\n\nFeel free to explore and interact with the contract's other functions using the same approach - selecting the method, providing any required parameters, and confirming the transaction through Talisman when needed."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-contracts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 199, "end_char": 817, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nCreating [smart contracts](/develop/smart-contracts/overview/){target=\\_blank} is fundamental to blockchain development. While many frameworks and tools are available, understanding how to write a contract from scratch with just a text editor is essential knowledge.\n\nThis tutorial will guide you through creating a basic smart contract that can be used with other tutorials for deployment and integration on Polkadot Hub. To understand how smart contracts work in Polkadot Hub, check the [Smart Contract Basics](/polkadot-protocol/smart-contract-basics/){target=\\_blank} guide for more information."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-contracts", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 817, "end_char": 1269, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, make sure you have:\n\n- A text editor of your choice ([VS Code](https://code.visualstudio.com/){target=\\_blank}, [Sublime Text](https://www.sublimetext.com/){target=\\_blank}, etc.).\n- Basic understanding of programming concepts.\n- Familiarity with the Solidity programming language syntax. For further references, check the official [Solidity documentation](https://docs.soliditylang.org/en/latest/){target=\\_blank}."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-contracts", "index": 2, "depth": 2, "title": "Understanding Smart Contract Structure", "anchor": "understanding-smart-contract-structure", "start_char": 1269, "end_char": 2251, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "## Understanding Smart Contract Structure\n\nLet's explore these components before building the contract:\n\n- **[SPDX license identifier](https://docs.soliditylang.org/en/v0.6.8/layout-of-source-files.html){target=\\_blank}**: A standardized way to declare the license under which your code is released. This helps with legal compliance and is required by the Solidity compiler to avoid warnings.\n- **Pragma directive**: Specifies which version of Solidity compiler should be used for your contract.\n- **Contract declaration**: Similar to a class in object-oriented programming, it defines the boundaries of your smart contract.\n- **State variables**: Data stored directly in the contract that persists between function calls. These represent the contract's \"state\" on the blockchain.\n- **Functions**: Executable code that can read or modify the contract's state variables.\n- **Events**: Notification mechanisms that applications can subscribe to in order to track blockchain changes."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-contracts", "index": 3, "depth": 2, "title": "Create the Smart Contract", "anchor": "create-the-smart-contract", "start_char": 2251, "end_char": 5611, "estimated_token_count": 682, "token_estimator": "heuristic-v1", "text": "## Create the Smart Contract\n\nIn this section, you'll build a simple storage contract step by step. This basic Storage contract is a great starting point for beginners. It introduces key concepts like state variables, functions, and events in a simple way, demonstrating how data is stored and updated on the blockchain. Later, you'll explore each component in more detail to understand what's happening behind the scenes.\n\nThis contract will:\n\n- Store a number.\n- Allow updating the stored number.\n- Emit an event when the number changes.\n\nTo build the smart contract, follow the steps below:\n\n1. Create a new file named `Storage.sol`.\n\n2. Add the SPDX license identifier at the top of the file:\n\n    ```solidity\n    // SPDX-License-Identifier: MIT\n    ```\n\n    This line tells users and tools which license governs your code. The [MIT license](https://opensource.org/license/mit){target=\\_blank} is commonly used for open-source projects. The Solidity compiler requires this line to avoid licensing-related warnings.\n\n3. Specify the Solidity version:\n\n    ```solidity\n    pragma solidity ^0.8.28;\n    ```\n\n    The caret `^` means \"this version or any compatible newer version.\" This helps ensure your contract compiles correctly with the intended compiler features.\n\n4. Create the contract structure:\n\n    ```solidity\n    contract Storage {\n        // Contract code will go here\n    }\n    ```\n\n    This defines a contract named \"Storage\", similar to how you would define a class in other programming languages.\n\n5. Add the state variables and event:\n\n    ```solidity\n    contract Storage {\n        // State variable to store a number\n        uint256 private number;\n        \n        // Event to notify when the number changes\n        event NumberChanged(uint256 newNumber);\n    }\n    ```\n\n    Here, you're defining:\n\n    - A state variable named `number` of type `uint256` (unsigned integer with 256 bits), which is marked as `private` so it can only be accessed via functions within this contract.\n    - An event named `NumberChanged` that will be triggered whenever the number changes. The event includes the new value as data.\n\n6. Add the getter and setter functions:\n\n    ```solidity\n    -// SPDX-License-Identifier: MIT\npragma solidity ^0.8.28;\n\ncontract Storage {\n    // State variable to store our number\n    uint256 private number;\n\n    // Event to notify when the number changes\n    event NumberChanged(uint256 newNumber);\n\n    // Function to store a new number\n    function store(uint256 newNumber) public {\n        number = newNumber;\n        emit NumberChanged(newNumber);\n    }\n\n    // Function to retrieve the stored number\n    function retrieve() public view returns (uint256) {\n        return number;\n    }\n}\n    ```\n\n??? code \"Complete Storage.sol contract\"\n\n    ```solidity title=\"Storage.sol\"\n    -// SPDX-License-Identifier: MIT\npragma solidity ^0.8.28;\n\ncontract Storage {\n    // State variable to store our number\n    uint256 private number;\n\n    // Event to notify when the number changes\n    event NumberChanged(uint256 newNumber);\n\n    // Function to store a new number\n    function store(uint256 newNumber) public {\n        number = newNumber;\n        emit NumberChanged(newNumber);\n    }\n\n    // Function to retrieve the stored number\n    function retrieve() public view returns (uint256) {\n        return number;\n    }\n}\n    ```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-contracts", "index": 4, "depth": 2, "title": "Understanding the Code", "anchor": "understanding-the-code", "start_char": 5611, "end_char": 8178, "estimated_token_count": 524, "token_estimator": "heuristic-v1", "text": "## Understanding the Code\n\nLet's break down the key components of the contract:\n\n- **State Variable**\n\n    - **`uint256 private number`**: A private variable that can only be accessed through the contract's functions.\n    - The `private` keyword prevents direct access from other contracts, but it's important to note that while other contracts cannot read this variable directly, the data itself is still visible on the blockchain and can be read by external tools or applications that interact with the blockchain. \"Private\" in Solidity doesn't mean the data is encrypted or truly hidden.\n    - State variables in Solidity are permanent storage on the blockchain, making them different from variables in traditional programming. Every change to a state variable requires a transaction and costs gas (the fee paid for blockchain operations).\n\n- **Event**\n\n    - **`event NumberChanged(uint256 newNumber)`**: Emitted when the stored number changes.\n    - When triggered, events write data to the blockchain's log, which can be efficiently queried by applications.\n    - Unlike state variables, events cannot be read by smart contracts, only by external applications.\n    - Events are much more gas-efficient than storing data when you only need to notify external systems of changes.\n\n- **Functions**\n\n    - **`store(uint256 newNumber)`**: Updates the stored number and emits an event.\n        - This function changes the state of the contract and requires a transaction to execute.\n        - The `emit` keyword is used to trigger the defined event.\n\n    - **`retrieve()`**: Returns the current stored number.\n        - The `view` keyword indicates that this function only reads data and doesn't modify the contract's state.\n        - View functions don't require a transaction and don't cost gas when called externally.\n\n    For those new to Solidity, this naming pattern (getter/setter functions) is a common design pattern. Instead of directly accessing state variables, the convention is to use functions to control access and add additional logic if needed.\n\nThis basic contract serves as a foundation for learning smart contract development. Real-world contracts often require additional security considerations, more complex logic, and thorough testing before deployment.\n\nFor more detailed information about Solidity types, functions, and best practices, refer to the [Solidity documentation](https://docs.soliditylang.org/en/latest/){target=\\_blank} or this [beginner's guide to Solidity](https://www.tutorialspoint.com/solidity/index.htm){target=\\_blank}."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-contracts", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 8178, "end_char": 8546, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Test and Deploy with Hardhat__\n\n    ---\n\n    Learn how to test and deploy the smart contract you created by using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/tutorials/smart-contracts/launch-your-first-project/test-and-deploy-with-hardhat/)\n\n</div>"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 204, "end_char": 1021, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nDecentralized applications (dApps) have become a cornerstone of the Web3 ecosystem, allowing developers to create applications that interact directly with blockchain networks. Polkadot Hub, a blockchain that supports smart contract functionality, provides an excellent platform for deploying and interacting with dApps.\n\nIn this tutorial, you'll build a complete dApp that interacts with a smart contract deployed on the Polkadot Hub TestNet. It will use [Ethers.js](/develop/smart-contracts/libraries/ethers-js){target=\\_blank} to interact with the blockchain and [Next.js](https://nextjs.org/){target=\\_blank} as the frontend framework. By the end of this tutorial, you'll have a functional dApp that allows users to connect their wallets, read data from the blockchain, and execute transactions."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1021, "end_char": 1481, "estimated_token_count": 111, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, make sure you have:\n\n- [Node.js](https://nodejs.org/en){target=\\_blank} v16 or newer installed on your machine.\n- A crypto wallet (like MetaMask) with some test tokens. For further information, check the [Connect to Polkadot](/develop/smart-contracts/connect-to-polkadot){target=\\_blank} guide.\n- Basic understanding of React and JavaScript.\n- Familiarity with blockchain concepts and Solidity (helpful but not mandatory)."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 2, "depth": 2, "title": "Project Overview", "anchor": "project-overview", "start_char": 1481, "end_char": 2678, "estimated_token_count": 301, "token_estimator": "heuristic-v1", "text": "## Project Overview\n\nThe dApp will interact with a simple Storage contract. For a step-by-step guide on creating it, refer to the [Create Contracts](/tutorials/smart-contracts/launch-your-first-project/create-contracts){target=\\_blank} tutorial. This contract allows:\n\n- Reading a stored number from the blockchain.\n- Updating the stored number with a new value.\n\nThe contract has already been deployed to the Polkadot Hub TestNet for testing purposes: `0x58053f0e8ede1a47a1af53e43368cd04ddcaf66f`. If you want to deploy your own, follow the [Deploying Contracts](/develop/smart-contracts/dev-environments/remix/#deploying-contracts){target=\\_blank} section.\n\nHere's a simplified view of what you'll be building:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-ethers-js/create-dapp-ethers-js-1.webp)\n\nThe general structure of the project should end up as follows:\n\n```bash\nethers-dapp\n├── abis\n│   └── Storage.json\n└── app\n    ├── components\n    │   ├── ReadContract.js\n    │   ├── WalletConnect.js\n    │   └── WriteContract.js\n    ├── favicon.ico\n    ├── globals.css\n    ├── layout.js\n    ├── page.js\n    └── utils\n        ├── contract.js\n        └── ethers.js\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 2678, "end_char": 2925, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nLet's start by creating a new Next.js project:\n\n```bash\nnpx create-next-app ethers-dapp --js --eslint --tailwind --app --yes\ncd ethers-dapp\n```\n\nNext, install the needed dependencies:\n\n```bash\nnpm install ethers@6.13.5\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 4, "depth": 2, "title": "Connect to Polkadot Hub", "anchor": "connect-to-polkadot-hub", "start_char": 2925, "end_char": 4634, "estimated_token_count": 418, "token_estimator": "heuristic-v1", "text": "## Connect to Polkadot Hub\n\nTo interact with the Polkadot Hub, you need to set up an [Ethers.js Provider](/develop/smart-contracts/libraries/ethers-js/#set-up-the-ethersjs-provider){target=\\_blank} that connects to the blockchain. In this example, you will interact with the Polkadot Hub TestNet, so you can experiment safely. Start by creating a new file called `utils/ethers.js` and add the following code:\n\n```javascript title=\"app/utils/ethers.js\"\n-import { JsonRpcProvider } from 'ethers';\n\nexport const PASSET_HUB_CONFIG = {\n  name: 'Passet Hub',\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io/', // Passet Hub testnet RPC\n  chainId: 420420422, // Passet Hub testnet chainId\n  blockExplorer: 'https://blockscout-passet-hub.parity-testnet.parity.io/',\n};\n\nexport const getProvider = () => {\n  return new JsonRpcProvider(PASSET_HUB_CONFIG.rpc, {\n    chainId: PASSET_HUB_CONFIG.chainId,\n    name: PASSET_HUB_CONFIG.name,\n  });\n};\n\n// Helper to get a signer from a provider\nexport const getSigner = async (provider) => {\n  if (window.ethereum) {\n    await window.ethereum.request({ method: 'eth_requestAccounts' });\n    const ethersProvider = new ethers.BrowserProvider(window.ethereum);\n    return ethersProvider.getSigner();\n  }\n  throw new Error('No Ethereum browser provider detected');\n};\n```\n\nThis file establishes a connection to the Polkadot Hub TestNet and provides helper functions for obtaining a [Provider](https://docs.ethers.org/v5/api/providers/provider/){target=_blank} and [Signer](https://docs.ethers.org/v5/api/signer/){target=_blank}. The provider allows you to read data from the blockchain, while the signer enables users to send transactions and modify the blockchain state."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 5, "depth": 2, "title": "Set Up the Smart Contract Interface", "anchor": "set-up-the-smart-contract-interface", "start_char": 4634, "end_char": 6445, "estimated_token_count": 405, "token_estimator": "heuristic-v1", "text": "## Set Up the Smart Contract Interface\n\nFor this dApp, you'll use a simple Storage contract already deployed. So, you need to create an interface to interact with it. First, ensure to create a folder called `abis` at the root of your project, create a file `Storage.json`, and paste the corresponding ABI (Application Binary Interface) of the Storage contract. You can copy and paste the following:\n\n???+ code \"Storage.sol ABI\"\n\n    ```json title=\"abis/Storage.json\"\n    -[\n    {\n        \"inputs\": [\n            {\n                \"internalType\": \"uint256\",\n                \"name\": \"_newNumber\",\n                \"type\": \"uint256\"\n            }\n        ],\n        \"name\": \"setNumber\",\n        \"outputs\": [],\n        \"stateMutability\": \"nonpayable\",\n        \"type\": \"function\"\n    },\n    {\n        \"inputs\": [],\n        \"name\": \"storedNumber\",\n        \"outputs\": [\n            {\n                \"internalType\": \"uint256\",\n                \"name\": \"\",\n                \"type\": \"uint256\"\n            }\n        ],\n        \"stateMutability\": \"view\",\n        \"type\": \"function\"\n    }\n]\n    ```\n\nNow, create a file called `app/utils/contract.js`:\n\n```javascript title=\"app/utils/contract.js\"\n-import { Contract } from 'ethers';\nimport { getProvider } from './ethers';\nimport StorageABI from '../../abis/Storage.json';\n\nexport const CONTRACT_ADDRESS = '0x58053f0e8ede1a47a1af53e43368cd04ddcaf66f';\n\nexport const CONTRACT_ABI = StorageABI;\n\nexport const getContract = () => {\n  const provider = getProvider();\n  return new Contract(CONTRACT_ADDRESS, CONTRACT_ABI, provider);\n};\n\nexport const getSignedContract = async (signer) => {\n  return new Contract(CONTRACT_ADDRESS, CONTRACT_ABI, signer);\n};\n```\n\nThis file defines the contract address, ABI, and functions to create instances of the contract for reading and writing."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 6, "depth": 2, "title": "Create the Wallet Connection Component", "anchor": "create-the-wallet-connection-component", "start_char": 6445, "end_char": 12778, "estimated_token_count": 1450, "token_estimator": "heuristic-v1", "text": "## Create the Wallet Connection Component\n\nNext, let's create a component to handle wallet connections. Create a new file called `app/components/WalletConnect.js`:\n\n```javascript title=\"app/components/WalletConnect.js\"\n-'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport { PASSET_HUB_CONFIG } from '../utils/ethers';\n\nconst WalletConnect = ({ onConnect }) => {\n  const [account, setAccount] = useState(null);\n  const [chainId, setChainId] = useState(null);\n  const [error, setError] = useState(null);\n\n  useEffect(() => {\n    // Check if user already has an authorized wallet connection\n    const checkConnection = async () => {\n      if (window.ethereum) {\n        try {\n          // eth_accounts doesn't trigger the wallet popup\n          const accounts = await window.ethereum.request({\n            method: 'eth_accounts',\n          });\n          if (accounts.length > 0) {\n            setAccount(accounts[0]);\n            const chainIdHex = await window.ethereum.request({\n              method: 'eth_chainId',\n            });\n            setChainId(parseInt(chainIdHex, 16));\n          }\n        } catch (err) {\n          console.error('Error checking connection:', err);\n          setError('Failed to check wallet connection');\n        }\n      }\n    };\n\n    checkConnection();\n\n    if (window.ethereum) {\n      // Setup wallet event listeners\n      window.ethereum.on('accountsChanged', (accounts) => {\n        setAccount(accounts[0] || null);\n        if (accounts[0] && onConnect) onConnect(accounts[0]);\n      });\n\n      window.ethereum.on('chainChanged', (chainIdHex) => {\n        setChainId(parseInt(chainIdHex, 16));\n      });\n    }\n\n    return () => {\n      // Cleanup event listeners\n      if (window.ethereum) {\n        window.ethereum.removeListener('accountsChanged', () => {});\n        window.ethereum.removeListener('chainChanged', () => {});\n      }\n    };\n  }, [onConnect]);\n\n  const connectWallet = async () => {\n    if (!window.ethereum) {\n      setError(\n        'MetaMask not detected! Please install MetaMask to use this dApp.'\n      );\n      return;\n    }\n\n    try {\n      // eth_requestAccounts triggers the wallet popup\n      const accounts = await window.ethereum.request({\n        method: 'eth_requestAccounts',\n      });\n      setAccount(accounts[0]);\n\n      const chainIdHex = await window.ethereum.request({\n        method: 'eth_chainId',\n      });\n      const currentChainId = parseInt(chainIdHex, 16);\n      setChainId(currentChainId);\n\n      // Prompt user to switch networks if needed\n      if (currentChainId !== PASSET_HUB_CONFIG.chainId) {\n        await switchNetwork();\n      }\n\n      if (onConnect) onConnect(accounts[0]);\n    } catch (err) {\n      console.error('Error connecting to wallet:', err);\n      setError('Failed to connect wallet');\n    }\n  };\n\n  const switchNetwork = async () => {\n    try {\n      await window.ethereum.request({\n        method: 'wallet_switchEthereumChain',\n        params: [{ chainId: `0x${PASSET_HUB_CONFIG.chainId.toString(16)}` }],\n      });\n    } catch (switchError) {\n      // Error 4902 means the chain hasn't been added to MetaMask\n      if (switchError.code === 4902) {\n        try {\n          await window.ethereum.request({\n            method: 'wallet_addEthereumChain',\n            params: [\n              {\n                chainId: `0x${PASSET_HUB_CONFIG.chainId.toString(16)}`,\n                chainName: PASSET_HUB_CONFIG.name,\n                rpcUrls: [PASSET_HUB_CONFIG.rpc],\n                blockExplorerUrls: [PASSET_HUB_CONFIG.blockExplorer],\n              },\n            ],\n          });\n        } catch (addError) {\n          setError('Failed to add network to wallet');\n        }\n      } else {\n        setError('Failed to switch network');\n      }\n    }\n  };\n\n  // UI-only disconnection - MetaMask doesn't support programmatic disconnection\n  const disconnectWallet = () => {\n    setAccount(null);\n  };\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto\">\n      {error && <p className=\"text-red-500 text-sm mb-2\">{error}</p>}\n\n      {!account ? (\n        <button\n          onClick={connectWallet}\n          className=\"w-full bg-pink-500 hover:bg-pink-600 text-white font-bold py-2 px-4 rounded-lg transition\"\n        >\n          Connect Wallet\n        </button>\n      ) : (\n        <div className=\"flex flex-col items-center\">\n          <span className=\"text-sm font-mono bg-pink-100 px-2 py-1 rounded-md text-pink-700\">\n            {`${account.substring(0, 6)}...${account.substring(38)}`}\n          </span>\n          <button\n            onClick={disconnectWallet}\n            className=\"mt-3 w-full bg-gray-200 hover:bg-gray-300 text-pink-500 py-2 px-4 rounded-lg transition\"\n          >\n            Disconnect\n          </button>\n          {chainId !== PASSET_HUB_CONFIG.chainId && (\n            <button\n              onClick={switchNetwork}\n              className=\"mt-3 w-full bg-yellow-500 hover:bg-yellow-600 text-white font-bold py-2 px-4 rounded-lg transition\"\n            >\n              Switch to Passet Hub\n            </button>\n          )}\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default WalletConnect;\n```\n\nThis component handles connecting to the wallet, switching networks if necessary, and keeping track of the connected account. \n\nTo integrate this component to your dApp, you need to overwrite the existing boilerplate in `app/page.js` with the following code:\n\n```javascript title=\"app/page.js\"\n-\n-import { useState } from 'react';\n\nimport WalletConnect from './components/WalletConnect';\n-export default function Home() {\n  const [account, setAccount] = useState(null);\n\n  const handleConnect = (connectedAccount) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Ethers.js dApp - Passet Hub Smart Contracts\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n-</section>\n  );\n}\n```\n\nIn your terminal, you can launch your project by running:\n\n```bash\nnpm run dev\n```\n\nAnd you will see the following:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-ethers-js/create-dapp-ethers-js-2.webp)"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 7, "depth": 2, "title": "Read Data from the Blockchain", "anchor": "read-data-from-the-blockchain", "start_char": 12778, "end_char": 15999, "estimated_token_count": 810, "token_estimator": "heuristic-v1", "text": "## Read Data from the Blockchain\n\nNow, let's create a component to read data from the contract. Create a file called `app/components/ReadContract.js`:\n\n```javascript title=\"app/components/ReadContract.js\"\n-'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport { getContract } from '../utils/contract';\n\nconst ReadContract = () => {\n  const [storedNumber, setStoredNumber] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState(null);\n\n  useEffect(() => {\n    // Function to read data from the blockchain\n    const fetchData = async () => {\n      try {\n        setLoading(true);\n        const contract = getContract();\n        // Call the smart contract's storedNumber function\n        const number = await contract.storedNumber();\n        setStoredNumber(number.toString());\n        setError(null);\n      } catch (err) {\n        console.error('Error fetching stored number:', err);\n        setError('Failed to fetch data from the contract');\n      } finally {\n        setLoading(false);\n      }\n    };\n\n    fetchData();\n\n    // Poll for updates every 10 seconds to keep UI in sync with blockchain\n    const interval = setInterval(fetchData, 10000);\n\n    // Clean up interval on component unmount\n    return () => clearInterval(interval);\n  }, []);\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto\">\n      <h2 className=\"text-lg font-bold text-center mb-4\">Contract Data</h2>\n      {loading ? (\n        <div className=\"flex justify-center my-4\">\n          <div className=\"w-6 h-6 border-4 border-pink-500 border-t-transparent rounded-full animate-spin\"></div>\n        </div>\n      ) : error ? (\n        <p className=\"text-red-500 text-center\">{error}</p>\n      ) : (\n        <div className=\"text-center\">\n          <p className=\"text-sm font-mono bg-pink-100 px-2 py-1 rounded-md text-pink-700\">\n            <strong>Stored Number:</strong> {storedNumber}\n          </p>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default ReadContract;\n```\n\nThis component reads the `storedNumber` value from the contract and displays it to the user. It also sets up a polling interval to refresh the data periodically.\n\nTo see this change in your dApp, you need to integrate this component into the `app/page.js` file:\n\n```javascript title=\"app/page.js\"\n-\n-import { useState } from 'react';\n\nimport WalletConnect from './components/WalletConnect';\nimport ReadContract from './components/ReadContract';\n-export default function Home() {\n  const [account, setAccount] = useState(null);\n\n  const handleConnect = (connectedAccount) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Ethers.js dApp - Passet Hub Smart Contracts\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n      <ReadContract />\n-</section>\n  );\n}\n```\n\nYour dApp will automatically be updated to the following:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-ethers-js/create-dapp-ethers-js-3.webp)"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 8, "depth": 2, "title": "Write Data to the Blockchain", "anchor": "write-data-to-the-blockchain", "start_char": 15999, "end_char": 21073, "estimated_token_count": 1231, "token_estimator": "heuristic-v1", "text": "## Write Data to the Blockchain\n\nFinally, let's create a component that allows users to update the stored number. Create a file called `app/components/WriteContract.js`:\n\n```javascript title=\"app/components/WriteContract.js\"\n-'use client';\n\nimport { useState } from 'react';\nimport { getSignedContract } from '../utils/contract';\nimport { ethers } from 'ethers';\n\nconst WriteContract = ({ account }) => {\n  const [newNumber, setNewNumber] = useState('');\n  const [status, setStatus] = useState({ type: null, message: '' });\n  const [isSubmitting, setIsSubmitting] = useState(false);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n\n    // Validation checks\n    if (!account) {\n      setStatus({ type: 'error', message: 'Please connect your wallet first' });\n      return;\n    }\n\n    if (!newNumber || isNaN(Number(newNumber))) {\n      setStatus({ type: 'error', message: 'Please enter a valid number' });\n      return;\n    }\n\n    try {\n      setIsSubmitting(true);\n      setStatus({ type: 'info', message: 'Initiating transaction...' });\n\n      // Get a signer from the connected wallet\n      const provider = new ethers.BrowserProvider(window.ethereum);\n      const signer = await provider.getSigner();\n      const contract = await getSignedContract(signer);\n\n      // Send transaction to blockchain and wait for user confirmation in wallet\n      setStatus({\n        type: 'info',\n        message: 'Please confirm the transaction in your wallet...',\n      });\n\n      // Call the contract's setNumber function\n      const tx = await contract.setNumber(newNumber);\n\n      // Wait for transaction to be mined\n      setStatus({\n        type: 'info',\n        message: 'Transaction submitted. Waiting for confirmation...',\n      });\n      const receipt = await tx.wait();\n\n      setStatus({\n        type: 'success',\n        message: `Transaction confirmed! Transaction hash: ${receipt.hash}`,\n      });\n      setNewNumber('');\n    } catch (err) {\n      console.error('Error updating number:', err);\n\n      // Error code 4001 is MetaMask's code for user rejection\n      if (err.code === 4001) {\n        setStatus({ type: 'error', message: 'Transaction rejected by user.' });\n      } else {\n        setStatus({\n          type: 'error',\n          message: `Error: ${err.message || 'Failed to send transaction'}`,\n        });\n      }\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto space-y-4\">\n      <h2 className=\"text-lg font-bold\">Update Stored Number</h2>\n      {status.message && (\n        <div\n          className={`p-2 rounded-md break-words h-fit text-sm ${\n            status.type === 'error'\n              ? 'bg-red-100 text-red-500'\n              : 'bg-green-100 text-green-700'\n          }`}\n        >\n          {status.message}\n        </div>\n      )}\n      <form onSubmit={handleSubmit} className=\"space-y-4\">\n        <input\n          type=\"number\"\n          placeholder=\"New Number\"\n          value={newNumber}\n          onChange={(e) => setNewNumber(e.target.value)}\n          disabled={isSubmitting || !account}\n          className=\"w-full p-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-pink-400\"\n        />\n        <button\n          type=\"submit\"\n          disabled={isSubmitting || !account}\n          className=\"w-full bg-pink-500 hover:bg-pink-600 text-white font-bold py-2 px-4 rounded-lg transition disabled:bg-gray-300\"\n        >\n          {isSubmitting ? 'Updating...' : 'Update'}\n        </button>\n      </form>\n      {!account && (\n        <p className=\"text-sm text-gray-500\">\n          Connect your wallet to update the stored number.\n        </p>\n      )}\n    </div>\n  );\n};\n\nexport default WriteContract;\n```\n\nThis component allows users to input a new number and send a transaction to update the value stored in the contract. When the transaction is successful, users will see the stored value update in the `ReadContract` component after the transaction is confirmed.\n\nUpdate the `app/page.js` file to integrate all components:\n\n```javascript title=\"app/page.js\"\n-'use client';\n\nimport { useState } from 'react';\n\nimport WalletConnect from './components/WalletConnect';\nimport ReadContract from './components/ReadContract';\nimport WriteContract from './components/WriteContract';\n\nexport default function Home() {\n  const [account, setAccount] = useState(null);\n\n  const handleConnect = (connectedAccount) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Ethers.js dApp - Passet Hub Smart Contracts\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n      <ReadContract />\n      <WriteContract account={account} />\n    </section>\n  );\n}\n```\n\nThe completed UI will display:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-ethers-js/create-dapp-ethers-js-4.webp)"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-ethers-js", "index": 9, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 21073, "end_char": 21887, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nCongratulations! You've built a complete dApp that interacts with a smart contract on the Polkadot Hub TestNet using Ethers.js and Next.js. Your application can now:\n\n- Connect to a user's wallet.\n- Read data from a smart contract.\n- Send transactions to update the contract state.\n\nThese fundamental skills provide the foundation for building more complex dApps on Polkadot Hub. With these building blocks, you can extend your application to interact with more sophisticated smart contracts and create more advanced user interfaces.\n\nTo get started right away with a working example, you can clone the repository and navigate to the implementation:\n\n```\ngit clone https://github.com/polkadot-developers/polkavm-storage-contract-dapps.git -b v0.0.2\ncd polkavm-storage-contract-dapps/ethers-dapp\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 0, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 892, "end_char": 1377, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following:\n\n- [Node.js](https://nodejs.org/en){target=\\_blank} v16 or later installed on your system.\n- A crypto wallet (such as MetaMask) funded with test tokens. Refer to the [Connect to Polkadot](/develop/smart-contracts/connect-to-polkadot){target=\\_blank} guide for more details.\n- A basic understanding of React and JavaScript.\n- Some familiarity with blockchain fundamentals and Solidity (useful but not required)."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 1, "depth": 2, "title": "Project Overview", "anchor": "project-overview", "start_char": 1377, "end_char": 2278, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "## Project Overview\n\nThis dApp will interact with a basic Storage contract. Refer to the [Create Contracts](/tutorials/smart-contracts/launch-your-first-project/create-contracts){target=\\_blank} tutorial for a step-by-step guide on creating this contract. The contract allows:\n\n- Retrieving a stored number from the blockchain.\n- Updating the stored number with a new value.\n\n\nBelow is a high-level overview of what you'll be building:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-viem/create-dapp-viem-1.webp)\n\nYour project directory will be organized as follows:\n\n```bash\nviem-dapp\n├── abis\n│   └── Storage.json\n└── app\n    ├── components\n    │   ├── ReadContract.tsx\n    │   ├── WalletConnect.tsx\n    │   └── WriteContract.tsx\n    ├── favicon.ico\n    ├── globals.css\n    ├── layout.tsx\n    ├── page.tsx\n    └── utils\n        ├── contract.ts\n        └── viem.ts\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 2, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 2278, "end_char": 2425, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nCreate a new Next.js project:\n\n```bash\nnpx create-next-app viem-dapp --ts --eslint --tailwind --app --yes\ncd viem-dapp\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 3, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 2425, "end_char": 2569, "estimated_token_count": 38, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nInstall viem and related packages:\n\n```bash\nnpm install viem@2.23.6\nnpm install --save-dev typescript @types/node\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 4, "depth": 2, "title": "Connect to Polkadot Hub", "anchor": "connect-to-polkadot-hub", "start_char": 2569, "end_char": 4574, "estimated_token_count": 492, "token_estimator": "heuristic-v1", "text": "## Connect to Polkadot Hub\n\nTo interact with Polkadot Hub, you need to set up a [Public Client](https://viem.sh/docs/clients/public#public-client){target=\\_blank} that connects to the blockchain. In this example, you will interact with the Polkadot Hub TestNet, so you can experiment safely. Start by creating a new file called `utils/viem.ts` and add the following code:\n\n```typescript title=\"viem.ts\"\n-import { createPublicClient, http, createWalletClient, custom } from 'viem'\nimport 'viem/window';\n\n\nconst transport = http('https://testnet-passet-hub-eth-rpc.polkadot.io')\n\n// Configure the Passet Hub chain\nexport const passetHub = {\n  id: 420420422,\n  name: 'Passet Hub',\n  network: 'passet-hub',\n  nativeCurrency: {\n    decimals: 18,\n    name: 'PAS',\n    symbol: 'PAS',\n  },\n  rpcUrls: {\n    default: {\n      http: ['https://testnet-passet-hub-eth-rpc.polkadot.io'],\n    },\n  },\n} as const\n\n// Create a public client for reading data\nexport const publicClient = createPublicClient({\n  chain: passetHub,\n  transport\n})\n\n// Create a wallet client for signing transactions\nexport const getWalletClient = async () => {\n  if (typeof window !== 'undefined' && window.ethereum) {\n    const [account] = await window.ethereum.request({ method: 'eth_requestAccounts' });\n    return createWalletClient({\n      chain: passetHub,\n      transport: custom(window.ethereum),\n      account,\n    });\n  }\n  throw new Error('No Ethereum browser provider detected');\n};\n```\n\nThis file initializes a viem client, providing helper functions for obtaining a Public Client and a [Wallet Client](https://viem.sh/docs/clients/wallet#wallet-client){target=\\_blank}. The Public Client enables reading blockchain data, while the Wallet Client allows users to sign and send transactions. Also, note that by importing `'viem/window'` the global `window.ethereum` will be typed as an `EIP1193Provider`, check the [`window` Polyfill](https://viem.sh/docs/typescript#window-polyfill){target=\\_blank} reference for more information."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 5, "depth": 2, "title": "Set Up the Smart Contract Interface", "anchor": "set-up-the-smart-contract-interface", "start_char": 4574, "end_char": 6980, "estimated_token_count": 524, "token_estimator": "heuristic-v1", "text": "## Set Up the Smart Contract Interface\n\nFor this dApp, you'll use a simple [Storage contract](/tutorials/smart-contracts/launch-your-first-project/create-contracts){target=\\_blank} that's already deployed in the Polkadot Hub TestNet: `0x58053f0e8ede1a47a1af53e43368cd04ddcaf66f`. To interact with it, you need to define the contract interface.\n\nCreate a folder called `abis` at the root of your project, then create a file named `Storage.json` and paste the corresponding ABI (Application Binary Interface) of the Storage contract. You can copy and paste the following:\n\n??? code \"Storage.sol ABI\"\n    ```json title=\"Storage.json\"\n    -[\n    {\n        \"inputs\": [\n            {\n                \"internalType\": \"uint256\",\n                \"name\": \"_newNumber\",\n                \"type\": \"uint256\"\n            }\n        ],\n        \"name\": \"setNumber\",\n        \"outputs\": [],\n        \"stateMutability\": \"nonpayable\",\n        \"type\": \"function\"\n    },\n    {\n        \"inputs\": [],\n        \"name\": \"storedNumber\",\n        \"outputs\": [\n            {\n                \"internalType\": \"uint256\",\n                \"name\": \"\",\n                \"type\": \"uint256\"\n            }\n        ],\n        \"stateMutability\": \"view\",\n        \"type\": \"function\"\n    }\n]\n    ```\n\nNext, create a file called `utils/contract.ts`:\n\n```typescript title=\"contract.ts\"\n-import { getContract } from 'viem';\nimport { publicClient, getWalletClient } from './viem';\nimport StorageABI from '../../abis/Storage.json';\n\nexport const CONTRACT_ADDRESS = '0x58053f0e8ede1a47a1af53e43368cd04ddcaf66f';\nexport const CONTRACT_ABI = StorageABI;\n\n// Create a function to get a contract instance for reading\nexport const getContractInstance = () => {\n  return getContract({\n    address: CONTRACT_ADDRESS,\n    abi: CONTRACT_ABI,\n    client: publicClient,\n  });\n};\n\n// Create a function to get a contract instance with a signer for writing\nexport const getSignedContract = async () => {\n  const walletClient = await getWalletClient();\n  return getContract({\n    address: CONTRACT_ADDRESS,\n    abi: CONTRACT_ABI,\n    client: walletClient,\n  });\n};\n```\n\nThis file defines the contract address, ABI, and functions to create a viem [contract instance](https://viem.sh/docs/contract/getContract#contract-instances){target=\\_blank} for reading and writing operations. viem's contract utilities ensure a more efficient and type-safe interaction with smart contracts."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 6, "depth": 2, "title": "Create the Wallet Connection Component", "anchor": "create-the-wallet-connection-component", "start_char": 6980, "end_char": 14072, "estimated_token_count": 1632, "token_estimator": "heuristic-v1", "text": "## Create the Wallet Connection Component\n\nNow, let's create a component to handle wallet connections. Create a new file called `components/WalletConnect.tsx`:\n\n```typescript title=\"WalletConnect.tsx\"\n-\"use client\";\n\nimport React, { useState, useEffect } from \"react\";\nimport { passetHub } from \"../utils/viem\";\n\ninterface WalletConnectProps {\n  onConnect: (account: string) => void;\n}\n\nconst WalletConnect: React.FC<WalletConnectProps> = ({ onConnect }) => {\n  const [account, setAccount] = useState<string | null>(null);\n  const [chainId, setChainId] = useState<number | null>(null);\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Check if user already has an authorized wallet connection\n    const checkConnection = async () => {\n      if (typeof window !== 'undefined' && window.ethereum) {\n        try {\n          // eth_accounts doesn't trigger the wallet popup\n          const accounts = await window.ethereum.request({\n            method: 'eth_accounts',\n          }) as string[];\n          \n          if (accounts.length > 0) {\n            setAccount(accounts[0]);\n            const chainIdHex = await window.ethereum.request({\n              method: 'eth_chainId',\n            }) as string;\n            setChainId(parseInt(chainIdHex, 16));\n            onConnect(accounts[0]);\n          }\n        } catch (err) {\n          console.error('Error checking connection:', err);\n          setError('Failed to check wallet connection');\n        }\n      }\n    };\n\n    checkConnection();\n\n    if (typeof window !== 'undefined' && window.ethereum) {\n      // Setup wallet event listeners\n      window.ethereum.on('accountsChanged', (accounts: string[]) => {\n        setAccount(accounts[0] || null);\n        if (accounts[0]) onConnect(accounts[0]);\n      });\n\n      window.ethereum.on('chainChanged', (chainIdHex: string) => {\n        setChainId(parseInt(chainIdHex, 16));\n      });\n    }\n\n    return () => {\n      // Cleanup event listeners\n      if (typeof window !== 'undefined' && window.ethereum) {\n        window.ethereum.removeListener('accountsChanged', () => {});\n        window.ethereum.removeListener('chainChanged', () => {});\n      }\n    };\n  }, [onConnect]);\n\n  const connectWallet = async () => {\n    if (typeof window === 'undefined' || !window.ethereum) {\n      setError(\n        'MetaMask not detected! Please install MetaMask to use this dApp.'\n      );\n      return;\n    }\n\n    try {\n      // eth_requestAccounts triggers the wallet popup\n      const accounts = await window.ethereum.request({\n        method: 'eth_requestAccounts',\n      }) as string[];\n      \n      setAccount(accounts[0]);\n\n      const chainIdHex = await window.ethereum.request({\n        method: 'eth_chainId',\n      }) as string;\n      \n      const currentChainId = parseInt(chainIdHex, 16);\n      setChainId(currentChainId);\n\n      // Prompt user to switch networks if needed\n      if (currentChainId !== passetHub.id) {\n        await switchNetwork();\n      }\n\n      onConnect(accounts[0]);\n    } catch (err) {\n      console.error('Error connecting to wallet:', err);\n      setError('Failed to connect wallet');\n    }\n  };\n\n  const switchNetwork = async () => {\n    console.log('Switch network')\n    try {\n      await window.ethereum.request({\n        method: 'wallet_switchEthereumChain',\n        params: [{ chainId: `0x${passetHub.id.toString(16)}` }],\n      });\n    } catch (switchError: any) {\n      // Error 4902 means the chain hasn't been added to MetaMask\n      if (switchError.code === 4902) {\n        try {\n          await window.ethereum.request({\n            method: 'wallet_addEthereumChain',\n            params: [\n              {\n                chainId: `0x${passetHub.id.toString(16)}`,\n                chainName: passetHub.name,\n                rpcUrls: [passetHub.rpcUrls.default.http[0]],\n                nativeCurrency: {\n                  name: passetHub.nativeCurrency.name,\n                  symbol: passetHub.nativeCurrency.symbol,\n                  decimals: passetHub.nativeCurrency.decimals,\n                },\n              },\n            ],\n          });\n        } catch (addError) {\n          setError('Failed to add network to wallet');\n        }\n      } else {\n        setError('Failed to switch network');\n      }\n    }\n  };\n\n  // UI-only disconnection - MetaMask doesn't support programmatic disconnection\n  const disconnectWallet = () => {\n    setAccount(null);\n  };\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto\">\n      {error && <p className=\"text-red-500 text-sm mb-2\">{error}</p>}\n\n      {!account ? (\n        <button\n          onClick={connectWallet}\n          className=\"w-full bg-pink-500 hover:bg-pink-600 text-white font-bold py-2 px-4 rounded-lg transition\"\n        >\n          Connect Wallet\n        </button>\n      ) : (\n        <div className=\"flex flex-col items-center\">\n          <span className=\"text-sm font-mono bg-pink-100 px-2 py-1 rounded-md text-pink-700\">\n            {`${account.substring(0, 6)}...${account.substring(38)}`}\n          </span>\n          <button\n            onClick={disconnectWallet}\n            className=\"mt-3 w-full bg-gray-200 hover:bg-gray-300 text-pink-500 py-2 px-4 rounded-lg transition\"\n          >\n            Disconnect\n          </button>\n          {chainId !== passetHub.id && (\n            <button\n              onClick={switchNetwork}\n              className=\"mt-3 w-full bg-yellow-500 hover:bg-yellow-600 text-white font-bold py-2 px-4 rounded-lg transition\"\n            >\n              Switch to Passet Hub\n            </button>\n          )}\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default WalletConnect;\n```\n\nThis component handles connecting to the wallet, switching networks if necessary, and keeping track of the connected account. It provides a button for users to connect their wallet and displays the connected account address once connected.\n\nTo use this component in your dApp, replace the existing boilerplate in `app/page.tsx` with the following code:\n\n```typescript title=\"page.tsx\"\n-\n-import { useState } from \"react\";\nimport WalletConnect from \"./components/WalletConnect\";\n-export default function Home() {\n  const [account, setAccount] = useState<string | null>(null);\n\n  const handleConnect = (connectedAccount: string) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Viem dApp - Passet Hub Smart Contracts\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n-</section>\n  );\n}\n```\n\nNow you're ready to run your dApp. From your project directory, execute:\n\n```bash\nnpm run dev\n```\n\nNavigate to `http://localhost:3000` in your browser, and you should see your dApp with the wallet connection button, the stored number display, and the form to update the number.\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-viem/create-dapp-viem-2.webp)"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 7, "depth": 2, "title": "Create the Read Contract Component", "anchor": "create-the-read-contract-component", "start_char": 14072, "end_char": 17554, "estimated_token_count": 859, "token_estimator": "heuristic-v1", "text": "## Create the Read Contract Component\n\nNow, let's create a component to read data from the contract. Create a file called `components/ReadContract.tsx`:\n\n```typescript title=\"ReadContract.tsx\"\n-'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport { publicClient } from '../utils/viem';\nimport { CONTRACT_ADDRESS, CONTRACT_ABI } from '../utils/contract';\n\nconst ReadContract: React.FC = () => {\n  const [storedNumber, setStoredNumber] = useState<string | null>(null);\n  const [loading, setLoading] = useState<boolean>(true);\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Function to read data from the blockchain\n    const fetchData = async () => {\n      try {\n        setLoading(true);\n        // Call the smart contract's storedNumber function\n        const number = await publicClient.readContract({\n            address: CONTRACT_ADDRESS,\n            abi: CONTRACT_ABI,\n            functionName: 'storedNumber',\n            args: [],\n          }) as bigint;\n\n        setStoredNumber(number.toString());\n        setError(null);\n      } catch (err) {\n        console.error('Error fetching stored number:', err);\n        setError('Failed to fetch data from the contract');\n      } finally {\n        setLoading(false);\n      }\n    };\n\n    fetchData();\n\n    // Poll for updates every 10 seconds to keep UI in sync with blockchain\n    const interval = setInterval(fetchData, 10000);\n\n    // Clean up interval on component unmount\n    return () => clearInterval(interval);\n  }, []);\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto\">\n      <h2 className=\"text-lg font-bold text-center mb-4\">Contract Data</h2>\n      {loading ? (\n        <div className=\"flex justify-center my-4\">\n          <div className=\"w-6 h-6 border-4 border-pink-500 border-t-transparent rounded-full animate-spin\"></div>\n        </div>\n      ) : error ? (\n        <p className=\"text-red-500 text-center\">{error}</p>\n      ) : (\n        <div className=\"text-center\">\n          <p className=\"text-sm font-mono bg-pink-100 px-2 py-1 rounded-md text-pink-700\">\n            <strong>Stored Number:</strong> {storedNumber}\n          </p>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default ReadContract;\n```\n\nThis component reads the `storedNumber` value from the contract and displays it to the user. It also sets up a polling interval to refresh the data periodically, ensuring that the UI stays in sync with the blockchain state.\n\nTo reflect this change in your dApp, incorporate this component into the `app/page.tsx` file.\n\n```typescript title=\"page.tsx\"\n-\n-import { useState } from \"react\";\nimport WalletConnect from \"./components/WalletConnect\";\nimport ReadContract from \"./components/ReadContract\";\n-export default function Home() {\n  const [account, setAccount] = useState<string | null>(null);\n\n  const handleConnect = (connectedAccount: string) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Viem dApp - Passet Hub Smart Contracts\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n      <ReadContract />\n-</section>\n  );\n}\n```\n\nAnd you will see in your browser:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-viem/create-dapp-viem-3.webp)"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 8, "depth": 2, "title": "Create the Write Contract Component", "anchor": "create-the-write-contract-component", "start_char": 17554, "end_char": 25544, "estimated_token_count": 1810, "token_estimator": "heuristic-v1", "text": "## Create the Write Contract Component\n\nFinally, let's create a component that allows users to update the stored number. Create a file called `components/WriteContract.tsx`:\n\n```typescript title=\"WriteContract.tsx\"\n-\"use client\";\n\nimport React, { useState, useEffect } from \"react\";\nimport { publicClient, getWalletClient } from \"../utils/viem\";\nimport { CONTRACT_ADDRESS, CONTRACT_ABI } from \"../utils/contract\";\n\ninterface WriteContractProps {\n  account: string | null;\n}\n\nconst WriteContract: React.FC<WriteContractProps> = ({ account }) => {\n  const [newNumber, setNewNumber] = useState<string>(\"\");\n  const [status, setStatus] = useState<{\n    type: string | null;\n    message: string;\n  }>({\n    type: null,\n    message: \"\",\n  });\n  const [isSubmitting, setIsSubmitting] = useState<boolean>(false);\n  const [isCorrectNetwork, setIsCorrectNetwork] = useState<boolean>(true);\n\n  // Check if the account is on the correct network\n  useEffect(() => {\n    const checkNetwork = async () => {\n      if (!account) return;\n\n      try {\n        // Get the chainId from the public client\n        const chainId = await publicClient.getChainId();\n\n        // Get the user's current chainId from their wallet\n        const walletClient = await getWalletClient();\n        if (!walletClient) return;\n\n        const walletChainId = await walletClient.getChainId();\n\n        // Check if they match\n        setIsCorrectNetwork(chainId === walletChainId);\n      } catch (err) {\n        console.error(\"Error checking network:\", err);\n        setIsCorrectNetwork(false);\n      }\n    };\n\n    checkNetwork();\n  }, [account]);\n\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n\n    // Validation checks\n    if (!account) {\n      setStatus({ type: \"error\", message: \"Please connect your wallet first\" });\n      return;\n    }\n\n    if (!isCorrectNetwork) {\n      setStatus({\n        type: \"error\",\n        message: \"Please switch to the correct network in your wallet\",\n      });\n      return;\n    }\n\n    if (!newNumber || isNaN(Number(newNumber))) {\n      setStatus({ type: \"error\", message: \"Please enter a valid number\" });\n      return;\n    }\n\n    try {\n      setIsSubmitting(true);\n      setStatus({ type: \"info\", message: \"Initiating transaction...\" });\n\n      // Get wallet client for transaction signing\n      const walletClient = await getWalletClient();\n\n      if (!walletClient) {\n        setStatus({ type: \"error\", message: \"Wallet client not available\" });\n        return;\n      }\n\n      // Check if account matches\n      if (\n        walletClient.account?.address.toLowerCase() !== account.toLowerCase()\n      ) {\n        setStatus({\n          type: \"error\",\n          message:\n            \"Connected wallet account doesn't match the selected account\",\n        });\n        return;\n      }\n\n      // Prepare transaction and wait for user confirmation in wallet\n      setStatus({\n        type: \"info\",\n        message: \"Please confirm the transaction in your wallet...\",\n      });\n\n      // Simulate the contract call first\n      console.log('newNumber', newNumber);\n      const { request } = await publicClient.simulateContract({\n        address: CONTRACT_ADDRESS,\n        abi: CONTRACT_ABI,\n        functionName: \"setNumber\",\n        args: [BigInt(newNumber)],\n        account: walletClient.account,\n      });\n\n      // Send the transaction with wallet client\n      const hash = await walletClient.writeContract(request);\n\n      // Wait for transaction to be mined\n      setStatus({\n        type: \"info\",\n        message: \"Transaction submitted. Waiting for confirmation...\",\n      });\n\n      const receipt = await publicClient.waitForTransactionReceipt({\n        hash,\n      });\n\n      setStatus({\n        type: \"success\",\n        message: `Transaction confirmed! Transaction hash: ${receipt.transactionHash}`,\n      });\n\n      setNewNumber(\"\");\n    } catch (err: any) {\n      console.error(\"Error updating number:\", err);\n\n      // Handle specific errors\n      if (err.code === 4001) {\n        // User rejected transaction\n        setStatus({ type: \"error\", message: \"Transaction rejected by user.\" });\n      } else if (err.message?.includes(\"Account not found\")) {\n        // Account not found on the network\n        setStatus({\n          type: \"error\",\n          message:\n            \"Account not found on current network. Please check your wallet is connected to the correct network.\",\n        });\n      } else if (err.message?.includes(\"JSON is not a valid request object\")) {\n        // JSON error - specific to your current issue\n        setStatus({\n          type: \"error\",\n          message:\n            \"Invalid request format. Please try again or contact support.\",\n        });\n      } else {\n        // Other errors\n        setStatus({\n          type: \"error\",\n          message: `Error: ${err.message || \"Failed to send transaction\"}`,\n        });\n      }\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto space-y-4\">\n      <h2 className=\"text-lg font-bold\">Update Stored Number</h2>\n\n      {!isCorrectNetwork && account && (\n        <div className=\"p-2 rounded-md bg-yellow-100 text-yellow-700 text-sm\">\n          ⚠️ You are not connected to the correct network. Please switch\n          networks in your wallet.\n        </div>\n      )}\n\n      {status.message && (\n        <div\n          className={`p-2 rounded-md break-words h-fit text-sm ${\n            status.type === \"error\"\n              ? \"bg-red-100 text-red-500\"\n              : status.type === \"success\"\n              ? \"bg-green-100 text-green-700\"\n              : \"bg-blue-100 text-blue-700\"\n          }`}\n        >\n          {status.message}\n        </div>\n      )}\n\n      <form onSubmit={handleSubmit} className=\"space-y-4\">\n        <input\n          type=\"number\"\n          placeholder=\"New Number\"\n          value={newNumber}\n          onChange={(e) => setNewNumber(e.target.value)}\n          disabled={isSubmitting || !account}\n          className=\"w-full p-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-pink-400\"\n        />\n        <button\n          type=\"submit\"\n          disabled={\n            isSubmitting || !account || (!isCorrectNetwork && !!account)\n          }\n          className=\"w-full bg-pink-500 hover:bg-pink-600 text-white font-bold py-2 px-4 rounded-lg transition disabled:bg-gray-300\"\n        >\n          {isSubmitting ? \"Updating...\" : \"Update\"}\n        </button>\n      </form>\n\n      {!account && (\n        <p className=\"text-sm text-gray-500\">\n          Connect your wallet to update the stored number.\n        </p>\n      )}\n    </div>\n  );\n};\n\nexport default WriteContract;\n```\n\nThis component allows users to input a new number and send a transaction to update the value stored in the contract. It provides appropriate feedback during each step of the transaction process and handles error scenarios.\n\nUpdate the `app/page.tsx` file to integrate all components:\n\n```typescript title=\"page.tsx\"\n-\"use client\";\n\nimport { useState } from \"react\";\nimport WalletConnect from \"./components/WalletConnect\";\nimport ReadContract from \"./components/ReadContract\";\nimport WriteContract from \"./components/WriteContract\";\n\nexport default function Home() {\n  const [account, setAccount] = useState<string | null>(null);\n\n  const handleConnect = (connectedAccount: string) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Viem dApp - Passet Hub Smart Contracts\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n      <ReadContract />\n      <WriteContract account={account} />\n    </section>\n  );\n}\n```\nAfter that, you will see:\n\n![](/images/tutorials/smart-contracts/launch-your-first-project/create-dapp-viem/create-dapp-viem-4.webp)"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 9, "depth": 2, "title": "How It Works", "anchor": "how-it-works", "start_char": 25544, "end_char": 26688, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "## How It Works\n\nLet's examine how the dApp interacts with the blockchain:\n\n1. Wallet connection: \n\n    - The `WalletConnect` component uses the browser's Ethereum provider (MetaMask) to connect to the user's wallet.\n    - It handles network switching to ensure the user is connected to the Polkadot Hub TestNet.\n    - Once connected, it provides the user's account address to the parent component.\n\n2. Reading data:\n\n    - The `ReadContract` component uses viem's `readContract` function to call the `storedNumber` view function.\n    - It periodically polls for updates to keep the UI in sync with the blockchain state.\n    - The component displays a loading indicator while fetching data and handles error states.\n\n3. Writing data:\n\n    - The `WriteContract` component uses viem's `writeContract` function to send a transaction to the `setNumber` function.\n    - It ensures the wallet is connected before allowing a transaction.\n    - The component shows detailed feedback during transaction submission and confirmation.\n    - After a successful transaction, the value displayed in the `ReadContract` component will update on the next poll."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 10, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 26688, "end_char": 27545, "estimated_token_count": 175, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nCongratulations! You've successfully built a fully functional dApp that interacts with a smart contract on Polkadot Hub using viem and Next.js. Your application can now:\n\n- Connect to a user's wallet and handle network switching.\n- Read data from a smart contract and keep it updated.\n- Write data to the blockchain through transactions.\n\nThese fundamental skills provide the foundation for building more complex dApps on Polkadot Hub. With this knowledge, you can extend your application to interact with more sophisticated smart contracts and create advanced user interfaces.\n\nTo get started right away with a working example, you can clone the repository and navigate to the implementation:\n\n```\ngit clone https://github.com/polkadot-developers/polkavm-storage-contract-dapps.git -b v0.0.2\ncd polkavm-storage-contract-dapps/viem-dapp\n```"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-create-dapp-viem", "index": 11, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 27545, "end_char": 27859, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Create a dApp with Wagmi__\n\n    ---\n\n    Learn how to build a decentralized application by using the Wagmi framework.\n\n    [:octicons-arrow-right-24: Get Started](/develop/smart-contracts/libraries/wagmi)\n\n</div>"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 204, "end_char": 843, "estimated_token_count": 136, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter creating a smart contract, the next crucial steps are testing and deployment. Proper testing ensures your contract behaves as expected, while deployment makes your contract available on the blockchain. This tutorial will guide you through using Hardhat, a popular development environment, to test and deploy the `Storage.sol` contract you created in the [Create a Smart Contract](/tutorials/smart-contracts/launch-your-first-project/create-contracts/){target=\\_blank} tutorial. For more information about Hardhat usage, check the [Hardhat guide](/develop/smart-contracts/dev-environments/hardhat/){target=\\_blank}."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 843, "end_char": 1369, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, make sure you have:\n\n- The [`Storage.sol` contract](/tutorials/smart-contracts/launch-your-first-project/create-contracts/#create-the-smart-contract){target=\\_blank} created in the previous tutorial.\n- [Node.js](https://nodejs.org/){target=\\_blank} (v16.0.0 or later) and npm installed.\n- Basic understanding of JavaScript for writing tests.\n- Some PAS test tokens to cover transaction fees (obtained from the [Polkadot faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank})."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 2, "depth": 2, "title": "Setting Up the Development Environment", "anchor": "setting-up-the-development-environment", "start_char": 1369, "end_char": 4383, "estimated_token_count": 707, "token_estimator": "heuristic-v1", "text": "## Setting Up the Development Environment\n\nLet's start by setting up Hardhat for your Storage contract project:\n\n1. Create a new directory for your project and navigate into it:\n\n    ```bash\n    mkdir storage-hardhat\n    cd storage-hardhat\n    ```\n\n2. Initialize a new npm project:\n\n    ```bash\n    npm init -y\n    ```\n\n3. Install `hardhat-polkadot` and all required plugins:\n\n    ```bash\n    npm install --save-dev @parity/hardhat-polkadot@0.1.9 solc@0.8.28\n    ```\n\n    For dependencies compatibility, ensure to install the `@nomicfoundation/hardhat-toolbox` dependency with the `--force` flag:\n\n    ```bash\n    npm install --force @nomicfoundation/hardhat-toolbox \n    ```\n\n5. Initialize a Hardhat project:\n\n    ```bash\n    npx hardhat-polkadot init\n    ```\n\n    Select **Create an empty hardhat.config.js** when prompted.\n\n6. Configure Hardhat by updating the `hardhat.config.js` file:\n\n    ```javascript title=\"hardhat.config.js\"\n    -require(\"@nomicfoundation/hardhat-toolbox\");\n\nrequire(\"@parity/hardhat-polkadot\");\n\nconst { vars } = require(\"hardhat/config\");\n\n/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n  solidity: \"0.8.28\",\n  resolc: {\n    compilerSource: \"npm\",\n  },\n  networks: {\n    hardhat: {\n      polkavm: true,\n      nodeConfig: {\n        nodeBinaryPath: 'INSERT_PATH_TO_SUBSTRATE_NODE',\n        rpcPort: 8000,\n        dev: true,\n      },\n      adapterConfig: {\n        adapterBinaryPath: 'INSERT_PATH_TO_ETH_RPC_ADAPTER',\n        dev: true,\n      },\n    },\n    localNode: {\n      polkavm: true,\n      url: `http://127.0.0.1:8545`,\n    },\n    passetHub: {\n      polkavm: true,\n      url: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      accounts: [vars.get(\"PRIVATE_KEY\")],\n    },\n  },\n};\n    ```\n\n    Ensure that `INSERT_PATH_TO_SUBSTRATE_NODE` and `INSERT_PATH_TO_ETH_RPC_ADAPTER` are replaced with the proper paths to the compiled binaries. \n\n    If you need to build these binaries, follow the [Installation](/develop/smart-contracts/local-development-node#install-the-substrate-node-and-eth-rpc-adapter){target=\\_blank} section on the Local Development Node page.\n\n    The configuration also defines two network settings: \n\n    - **`localNode`**: Runs a PolkaVM instance on `http://127.0.0.1:8545` for local development and testing.\n    - **`passetHub`**: Connects to the the Polkadot Hub TestNet network using a predefined RPC URL and a private key stored in environment variables.\n\n7. Export your private key and save it in your Hardhat environment:\n\n    ```bash\n    npx hardhat vars set PRIVATE_KEY \"INSERT_PRIVATE_KEY\"\n    ```\n\n    Replace `INSERT_PRIVATE_KEY` with your actual private key. \n    \n    For further details on private key exportation, refer to the article [How to export an account's private key](https://support.metamask.io/configure/accounts/how-to-export-an-accounts-private-key/){target=\\_blank}.\n\n    !!! warning\n        Keep your private key safe, and never share it with anyone. If it is compromised, your funds can be stolen."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 3, "depth": 2, "title": "Adding the Smart Contract", "anchor": "adding-the-smart-contract", "start_char": 4383, "end_char": 5681, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "## Adding the Smart Contract\n\n1. Create a new folder called `contracts` and create a `Storage.sol` file. Add the contract code from the previous tutorial:\n\n    ```solidity title=\"Storage.sol\"\n    -// SPDX-License-Identifier: MIT\npragma solidity ^0.8.28;\n\ncontract Storage {\n    // State variable to store our number\n    uint256 private number;\n\n    // Event to notify when the number changes\n    event NumberChanged(uint256 newNumber);\n\n    // Function to store a new number\n    function store(uint256 newNumber) public {\n        number = newNumber;\n        emit NumberChanged(newNumber);\n    }\n\n    // Function to retrieve the stored number\n    function retrieve() public view returns (uint256) {\n        return number;\n    }\n}\n    ```\n\n2. Compile the contract:\n\n    ```bash\n    npx hardhat compile\n    ```\n\n3. If successful, you will see the following output in your terminal:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat compile</span>\n  <span data-ty>Compiling 1 Solidity file</span>\n  <span data-ty>Successfully compiled 1 Solidity file</span>\n</div>\n\n\nAfter compilation, the `artifacts-pvm` and `cache-pvm` folders, containing the metadata and binary files of your compiled contract, will be created in the root of your project."}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 4, "depth": 2, "title": "Writing Tests", "anchor": "writing-tests", "start_char": 5681, "end_char": 11660, "estimated_token_count": 1372, "token_estimator": "heuristic-v1", "text": "## Writing Tests\n\nTesting is a critical part of smart contract development. Hardhat makes it easy to write tests in JavaScript using frameworks like [Mocha](https://mochajs.org/){target=\\_blank} and [Chai](https://www.chaijs.com/){target=\\_blank}.\n\n1. Create a folder for testing called `test`. Inside that directory, create a file named `Storage.js` and add the following code:\n\n    ```javascript title=\"Storage.js\" \n    -\n        // Add your logic here\n    -});\n});\n    ```\n\n    The `beforeEach` hook ensures stateless contract execution by redeploying a fresh instance of the Storage contract before each test case. This approach guarantees that each test starts with a clean and independent contract state by using `ethers.getSigners()` to obtain test accounts and `ethers.getContractFactory('Storage').deploy()` to create a new contract instance.\n\n    Now, you can add custom unit tests to check your contract functionality. Some example tests are available below:\n\n    1. **Initial state verification**: Ensures that the contract starts with a default value of zero, which is a fundamental expectation for the `Storage.sol` contract.\n\n        ```javascript title=\"Storage.js\"\n        -it('Should return 0 initially', async function () {\n      expect(await storage.retrieve()).to.equal(0);\n    });\n        ```\n\n        Explanation:\n\n        - Checks the initial state of the contract.\n        - Verifies that a newly deployed contract has a default value of 0.\n        - Confirms the `retrieve()` method works correctly for a new contract.\n\n    2. **Value storage test**: Validate the core functionality of storing and retrieving a value in the contract.\n\n        ```javascript title=\"Storage.js\"\n        -it('Should update when store is called', async function () {\n      const testValue = 42;\n      // Store a value\n      await storage.store(testValue);\n      // Check if the value was updated\n      expect(await storage.retrieve()).to.equal(testValue);\n    });\n        ```\n\n        Explanation:\n\n        - Demonstrates the ability to store a specific value.\n        - Checks that the stored value can be retrieved correctly.\n        - Verifies the basic write and read functionality of the contract.\n\n    3. **Event emission verification**: Confirm that the contract emits the correct event when storing a value, which is crucial for off-chain tracking.\n\n        ```javascript title=\"Storage.js\"\n        -it('Should emit an event when storing a value', async function () {\n      const testValue = 100;\n      // Check if the NumberChanged event is emitted with the correct value\n      await expect(storage.store(testValue))\n        .to.emit(storage, 'NumberChanged')\n        .withArgs(testValue);\n    });\n        ```\n\n        Explanation:\n\n        - Ensures the `NumberChanged` event is emitted during storage.\n        - Verifies that the event contains the correct stored value.\n        - Validates the contract's event logging mechanism.\n\n    4. **Sequential value storage test**: Check the contract's ability to store multiple values sequentially and maintain the most recent value.\n\n        ```javascript title=\"Storage.js\"\n        -it('Should allow storing sequentially increasing values', async function () {\n      const values = [10, 20, 30, 40];\n\n      for (const value of values) {\n        await storage.store(value);\n        expect(await storage.retrieve()).to.equal(value);\n      }\n    });\n        ```\n\n        Explanation:\n\n        - Verifies that multiple values can be stored in sequence.\n        - Confirms that each new store operation updates the contract's state.\n        - Demonstrates the contract's ability always to reflect the most recently stored value.\n\n    The complete `test/Storage.js` should look like this:\n\n    ???--- code \"View complete script\"\n        ```javascript title=\"Storage.js\"\n        -const { expect } = require('chai');\nconst { ethers } = require('hardhat');\n\ndescribe('Storage', function () {\n  let storage;\n  let owner;\n  let addr1;\n\n  beforeEach(async function () {\n    // Get signers\n    [owner, addr1] = await ethers.getSigners();\n\n    // Deploy the Storage contract\n    const Storage = await ethers.getContractFactory('Storage');\n    storage = await Storage.deploy();\n    await storage.waitForDeployment();\n  });\n\n  describe('Basic functionality', function () {\n    it('Should return 0 initially', async function () {\n      expect(await storage.retrieve()).to.equal(0);\n    });\n\n    it('Should update when store is called', async function () {\n      const testValue = 42;\n      // Store a value\n      await storage.store(testValue);\n      // Check if the value was updated\n      expect(await storage.retrieve()).to.equal(testValue);\n    });\n\n    it('Should emit an event when storing a value', async function () {\n      const testValue = 100;\n      // Check if the NumberChanged event is emitted with the correct value\n      await expect(storage.store(testValue))\n        .to.emit(storage, 'NumberChanged')\n        .withArgs(testValue);\n    });\n\n    it('Should allow storing sequentially increasing values', async function () {\n      const values = [10, 20, 30, 40];\n\n      for (const value of values) {\n        await storage.store(value);\n        expect(await storage.retrieve()).to.equal(value);\n      }\n    });\n  });\n});\n        ```\n\n2. Run the tests:\n\n    ```bash\n    npx hardhat test\n    ```\n\n3. After running the above command, you will see the output showing that all tests have passed:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat test</span>\n  <span data-ty>Storage</span>\n  <span data-ty>Basic functionality</span>\n  <span data-ty> ✔ Should return 0 initially</span>\n  <span data-ty> ✔ Should update when store is called (1126ms)</span>\n  <span data-ty> ✔ Should emit an event when storing a value (1131ms)</span>\n  <span data-ty> ✔ Should allow storing sequentially increasing values (12477ms)</span>\n  <span data-ty>4 passing (31s) </span>\n</div>"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 5, "depth": 2, "title": "Deploying with Ignition", "anchor": "deploying-with-ignition", "start_char": 11660, "end_char": 14613, "estimated_token_count": 789, "token_estimator": "heuristic-v1", "text": "## Deploying with Ignition\n\n[Hardhat's Ignition](https://hardhat.org/ignition/docs/getting-started#overview){target=\\_blank} is a deployment system designed to make deployments predictable and manageable. Let's create a deployment script:\n\n1. Create a new folder called`ignition/modules`. Add a new file named `StorageModule.js` with the following logic:\n\n    ```javascript title=\"StorageModule.js\"\n    -const { buildModule } = require('@nomicfoundation/hardhat-ignition/modules');\n\nmodule.exports = buildModule('StorageModule', (m) => {\n  const storage = m.contract('Storage');\n\n  return { storage };\n});\n    ```\n\n2. Deploy to the local network:\n\n    1. First, start a local node:\n\n        ```bash\n        npx hardhat node\n        ```\n\n    2. Then, in a new terminal window, deploy the contract:\n\n        ```bash\n        npx hardhat ignition deploy ./ignition/modules/StorageModule.js --network localNode\n        ```\n\n    3. If successful, output similar to the following will display in your terminal:\n\n        -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat ignition deploy ./ignition/modules/Storage.js --network localNode</span>\n  <span data-ty>✔ Confirm deploy to network localNode (420420422)? … yes</span>\n  <span data-ty></span>\n  <span data-ty>Hardhat Ignition 🚀</span>\n  <span data-ty></span>\n  <span data-ty>Deploying [ StorageModule ]</span>\n  <span data-ty></span>\n  <span data-ty>Batch #1</span>\n  <span data-ty> Executed StorageModule#Storage</span>\n  <span data-ty></span>\n  <span data-ty>[ StorageModule ] successfully deployed 🚀</span>\n  <span data-ty></span>\n  <span data-ty>Deployed Addresses</span>\n  <span data-ty></span>\n  <span data-ty>StorageModule#Storage - 0xc01Ee7f10EA4aF4673cFff62710E1D7792aBa8f3</span>\n</div>\n\n\n3. Deploy to the Polkadot Hub TestNet:\n\n    1. Make sure your account has enough PAS tokens for gas fees, then run:\n\n        ```bash\n        npx hardhat ignition deploy ./ignition/modules/StorageModule.js --network passetHub\n        ```\n\n    2. After deployment, you'll see the contract address in the console output. Save this address for future interactions.\n\n        -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat ignition deploy ./ignition/modules/Storage.js --network passetHub</span>\n  <span data-ty>✔ Confirm deploy to network localNode (420420422)? … yes</span>\n  <span data-ty></span>\n  <span data-ty>Hardhat Ignition 🚀</span>\n  <span data-ty></span>\n  <span data-ty>Deploying [ StorageModule ]</span>\n  <span data-ty></span>\n  <span data-ty>Batch #1</span>\n  <span data-ty> Executed StorageModule#Storage</span>\n  <span data-ty></span>\n  <span data-ty>[ StorageModule ] successfully deployed 🚀</span>\n  <span data-ty></span>\n  <span data-ty>Deployed Addresses</span>\n  <span data-ty></span>\n  <span data-ty>StorageModule#Storage - 0xE8693cE64b294E26765573398C7Ca5C700E9C85c</span>\n</div>"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 6, "depth": 2, "title": "Interacting with Your Deployed Contract", "anchor": "interacting-with-your-deployed-contract", "start_char": 14613, "end_char": 16442, "estimated_token_count": 462, "token_estimator": "heuristic-v1", "text": "## Interacting with Your Deployed Contract\n\nTo interact with your deployed contract:\n\n1. Create a new folder named `scripts` and add the `interact.js` with the following content:\n\n    ```javascript title=\"interact.js\"\n    -const hre = require('hardhat');\n\nasync function main() {\n  // Replace with your deployed contract address\n  const contractAddress = 'INSERT_DEPLOYED_CONTRACT_ADDRESS';\n\n  // Get the contract instance\n  const Storage = await hre.ethers.getContractFactory('Storage');\n  const storage = await Storage.attach(contractAddress);\n\n  // Get current value\n  const currentValue = await storage.retrieve();\n  console.log('Current stored value:', currentValue.toString());\n\n  // Store a new value\n  const newValue = 42;\n  console.log(`Storing new value: ${newValue}...`);\n  const tx = await storage.store(newValue);\n\n  // Wait for transaction to be mined\n  await tx.wait();\n  console.log('Transaction confirmed');\n\n  // Get updated value\n  const updatedValue = await storage.retrieve();\n  console.log('Updated stored value:', updatedValue.toString());\n}\n\nmain()\n  .then(() => process.exit(0))\n  .catch((error) => {\n    console.error(error);\n    process.exit(1);\n  });\n    ```\n\n    Ensure that `INSERT_DEPLOYED_CONTRACT_ADDRESS` is replaced with the value obtained in the previous step.\n\n2. Run the interaction script:\n\n    ```bash\n    npx hardhat run scripts/interact.js --network passetHub\n    ```\n\n3. If successful, the terminal will show the following output:\n\n    -<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat run scripts/interact.js --network passetHub</span>\n  <span data-ty>Current stored value: 0</span>\n  <span data-ty>Storing new value: 42...</span>\n  <span data-ty>Transaction confirmed</span>\n  <span data-ty>Updated stored value: 42</span>\n</div>"}
{"page_id": "tutorials-smart-contracts-launch-your-first-project-test-and-deploy-with-hardhat", "index": 7, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 16442, "end_char": 17047, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nCongratulations! You've successfully set up a Hardhat development environment, written comprehensive tests for your Storage contract, and deployed it to local and Polkadot Hub TestNet networks. This tutorial covered essential steps in smart contract development, including configuration, testing, deployment, and interaction.\n\nTo get started with a working example right away, you can clone the repository and navigate to the project directory:\n\n```bash\ngit clone https://github.com/polkadot-developers/polkavm-hardhat-examples.git -b v0.0.8\ncd polkavm-hardhat-examples/storage-hardhat\n```"}
