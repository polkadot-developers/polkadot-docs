{"page_id": "get-support-ai-ready-docs", "page_title": "AI Ready Docs", "index": 0, "depth": 2, "title": "How to Use These Files", "anchor": "how-to-use-these-files", "start_char": 286, "end_char": 952, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "## How to Use These Files\n\n- **Quick navigation**: Use `llms.txt` to give models a high-level map of the site.\n- **Lightweight context**: Use `site-index.json` for smaller context windows or when you only need targeted retrieval.\n- **Full content**: Use `llms-full.jsonl` for large-context models or preparing data for RAG pipelines.\n- **Focused bundles**: Use category files (e.g., `basics.md`, `parachains.md`) to limit content to a specific theme or task for more focused responses.\n\nThese AI-ready files do not include any persona or system prompts. They are purely informational and can be used without conflicting with your existing agent or tool prompting."}
{"page_id": "get-support-ai-ready-docs", "page_title": "AI Ready Docs", "index": 1, "depth": 2, "title": "Access LLM Files", "anchor": "access-llm-files", "start_char": 952, "end_char": 7996, "estimated_token_count": 2068, "token_estimator": "heuristic-v1", "text": "## Access LLM Files\n\n| Category                   | Description                                                                                                                                         | File                                                           | Actions                                                                                                                                                                                                                                       |\n|----------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Index                      | Markdown URL index for documentation pages, links to essential repos, and additional resources in the llms.txt standard format.                     | <code style=\"white-space: nowrap;\">llms.txt</code>             | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/llms.txt\" } [:octicons-download-16:](){ .llms-dl data-path=\"/llms.txt\" data-filename=\"llms.txt\" } </div>                                                                 |\n| Site index (JSON)          | Lightweight site index of JSON objects (one per page) with metadata and content previews.                                                           | <code style=\"white-space: nowrap;\">site-index.json</code>      | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/site-index.json\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/site-index.json\" data-filename=\"site-index.json\" } </div>                                      |\n| Full site contents (JSONL) | Full content of documentation site enhanced with metadata.                                                                                          | <code style=\"white-space: nowrap;\">llms-full.jsonl</code>      | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/llms-full.jsonl\" } [:octicons-download-16:](){ .llms-dl data-path=\"/llms-full.jsonl\" data-filename=\"llms-full.jsonl\" } </div>                                            |\n| Basics                     | Polkadot general knowledge base to provide context around overview and beginner-level content.                                                      | <code style=\"white-space: nowrap;\">basics.md</code>            | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/basics.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/basics.md\" data-filename=\"basics.md\" } </div>                                  |\n| Reference                  | Reference material including key functions and glossary.                                                                                            | <code style=\"white-space: nowrap;\">reference.md</code>         | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/reference.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/reference.md\" data-filename=\"reference.md\" } </div>                         |\n| Smart Contracts            | How to develop and deploy Solidity smart contracts on Polkadot Hub.                                                                                 | <code style=\"white-space: nowrap;\">smart-contracts.md</code>   | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/smart-contracts.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/smart-contracts.md\" data-filename=\"smart-contracts.md\" } </div>       |\n| Parachains                 | How-to guides related to building, customizing, deploying, and maintaining a parachain.                                                             | <code style=\"white-space: nowrap;\">parachains.md</code>        | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/parachains.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/parachains.md\" data-filename=\"parachains.md\" } </div>                      |\n| DApps                      | Information and tutorials for application developers.                                                                                               | <code style=\"white-space: nowrap;\">dapps.md</code>             | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/dapps.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/dapps.md\" data-filename=\"dapps.md\" } </div>                                     |\n| Networks                   | Information about the various Polkadot networks (Polkadot, Kusama, Westend, Paseo), their purposes, and how they fit into the development workflow. | <code style=\"white-space: nowrap;\">networks.md</code>          | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/networks.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/networks.md\" data-filename=\"networks.md\" } </div>                            |\n| Polkadot Protocol          | Polkadot's core architecture, including the relay chain, parachains, system chains, interoperability, and main actors.                              | <code style=\"white-space: nowrap;\">polkadot-protocol.md</code> | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/polkadot-protocol.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/polkadot-protocol.md\" data-filename=\"polkadot-protocol.md\" } </div> |\n| Infrastructure             | Operational aspects of supporting the Polkadot network, including how to run a node or validator and staking mechanics.                             | <code style=\"white-space: nowrap;\">infrastructure.md</code>    | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/infrastructure.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/infrastructure.md\" data-filename=\"infrastructure.md\" } </div>          |\n| Tooling                    | An overview of various development tools available for Polkadot development.                                                                        | <code style=\"white-space: nowrap;\">tooling.md</code>           | <div class=\"actions\"> [:octicons-copy-16:](){ .llms-copy data-path=\"/ai/categories/tooling.md\" } [:octicons-download-16:](){ .llms-dl data-path=\"/ai/categories/tooling.md\" data-filename=\"tooling.md\" } </div>                               |\n\n!!! note\n    The `llms-full.jsonl` file may exceed the input limits of some language models due to its size. If you encounter limitations, consider using the smaller `site-index.json` or category bundle files instead."}
{"page_id": "get-support", "page_title": "Support", "index": 0, "depth": 2, "title": "Support Channels", "anchor": "support-channels", "start_char": 433, "end_char": 1896, "estimated_token_count": 453, "token_estimator": "heuristic-v1", "text": "## Support Channels\n\nUse one of the channels below to get live technical support or ask questions.\n\n<div class=\"grid cards support\" markdown>\n\n-   :simple-telegram:{ .sub } **Telegram: Polkadot Developer Support**\n\n    <ul class=\"card-list\">\n    <li> **Whoâ€™s there:** DevRel team and active developer community. </li>\n    <li> **Response time:** Within **2 business days (usually faster)**. </li>\n    <li> **Topics:** Any developer-related question is welcome. </li>\n    </ul>\n\n    ðŸ‘‰ [Join Telegram](https://t.me/substratedevs){target=\\_blank}\n\n-   :simple-discord:{ .sub } **Discord: Polkadot Official Server**\n \n    <ul class=\"card-list\">\n    <li> **Smart contracts:** Ask in `#solidity-smart-contracts` and `#ink_smart-contracts`. </li>\n    <li> **General developer support:** Ask in `#solidity-smart-contracts`. </li>\n    <li> **Response time:** Within **1 business day (usually faster)**. </li>\n    </ul>\n\n    ðŸ‘‰ [Join Discord](https://polkadot-discord.w3f.tools/){target=\\_blank}\n\n-   :simple-matrix:{ .sub } **Matrix: Polkadot Developer Support**\n\n    <ul class=\"card-list\">\n    <li> **Whoâ€™s there:** Parity, W3F, DevRel, and community contributors. </li>\n    <li> **Response time:** Within **1 business day (usually faster)**. </li>\n    <li> **Topics:** Full-spectrum developer support. </li>\n    <li> Bridged with Telegram (all messages synced). </li>\n    </ul>\n\n    ðŸ‘‰ [Join Matrix](https://matrix.to/#/#substratedevs:matrix.org){target=\\_blank}\n\n</div>"}
{"page_id": "get-support", "page_title": "Support", "index": 1, "depth": 2, "title": "Community Resources", "anchor": "community-resources", "start_char": 1896, "end_char": 4187, "estimated_token_count": 667, "token_estimator": "heuristic-v1", "text": "## Community Resources\n\n<div class=\"grid cards support\" markdown>\n\n-   :fontawesome-brands-stack-exchange:{ .sub } **Stack Exchange**\n    \n    <ul class=\"card-list\">\n    <li> Browse commonly asked technical questions. </li>\n    <li> Ask your own and get detailed responses from experienced devs. </li>\n    </ul>\n\n    ðŸ‘‰ [Visit Polkadot Stack Exchange](https://substrate.stackexchange.com/){target=\\_blank}\n\n-   :simple-reddit:{ .sub } **Reddit: r/Polkadot**\n    \n    <ul class=\"card-list\">\n    <li> General discussions and community perspectives. </li>\n    <li> Developer questions are welcome â€” just tag them appropriately. </li>\n    </ul>\n\n    ðŸ‘‰ [Visit r/Polkadot](https://www.reddit.com/r/Polkadot/){target=\\_blank}\n\n-   :simple-youtube:{ .sub } **YouTube: @PolkadotNetwork**\n    \n    <ul class=\"card-list\">\n    <li> Developer tutorials. </li>\n    <li> Ecosystem interviews. </li>\n    <li> Event recordings and walkthroughs. </li>\n    </ul>\n\n    ðŸ‘‰ [Watch on YouTube](https://www.youtube.com/@PolkadotNetwork){target=\\_blank}\n\n-   :fontawesome-brands-x-twitter:{ .sub } **X (Twitter): Official Accounts**\n    \n    - **[@PolkadotDevs](https://x.com/PolkadotDevs){target=\\_blank}**: Updates for developers.\n    - **[@Polkadot](https://x.com/Polkadot){target=\\_blank}**: Network-wide news.\n    - **[@Kusamanetwork](https://x.com/kusamanetwork){target=\\_blank}**: Kusama-specific updates.\n    - **[@Web3Foundation](https://x.com/web3foundation){target=\\_blank}**: Grants, research, and ecosystem programs.\n\n-   :fontawesome-brands-x-twitter:{ .sub } **X (Twitter): Community Accounts**\n\n    - **[@PolkadotDeploy](https://x.com/PolkadotDeploy){target=\\_blank}**: News from the deployment portal and tooling updates.\n\n-   :material-forum:{ .sub } **Polkadot Forum**\n    \n    <ul class=\"card-list\">\n    <li> Join community discussions around the direction of the ecosystem. </li>\n    </ul>\n\n    ðŸ‘‰ [Visit the Polkadot Forum](https://forum.polkadot.network/){target=\\_blank}\n\n-   :material-vote:{ .sub } **Polkassembly: OpenGov**\n    \n    <ul class=\"card-list\">\n    <li> Explore and vote on governance proposals for Polkadot and Kusama. </li>\n    <li> Help shape the future of the network. </li>\n    </ul>\n\n    ðŸ‘‰ [Explore on Polkassembly](https://polkadot.polkassembly.io/){target=\\_blank}\n\n</div>"}
{"page_id": "get-support", "page_title": "Support", "index": 2, "depth": 2, "title": "AI Resources", "anchor": "ai-resources", "start_char": 4187, "end_char": 4621, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## AI Resources\n\n<div class=\"grid cards support\" markdown>\n\n-   :fontawesome-solid-robot:{ .sub } **AI Ready Documentation**\n\n    Access documentation structured and optimized for use with large language models (LLMs) and AI tools. These resources help build AI assistants, power code search, or enable custom tooling trained on Polkadotâ€™s documentation.\n\n    ðŸ‘‰ [Access LLM Files](/get-support/ai-ready-docs/){target=\\_blank}\n\n</div>"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 34, "end_char": 1172, "estimated_token_count": 209, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBlock-producing collators are the backbone of system parachain operations. Unlike RPC or archive nodes, which maintain state, collators actively produce blocks and submit them to relay chain validators for inclusion. They ensure network liveness, censorship resistance, and cross-chain message processing.\n\nCollators maintain fully synced relay chain and parachain nodes, aggregate transactions into blocks, create parachain block candidates, generate state transition proofs (Proof-of-Validity), and send block candidates to relay chain validators. They also enable cross-chain message handling via XCM. While critical for liveness, collators do not secure the networkâ€”security is provided by relay chain validators through the [ELVES protocol](https://wiki.polkadot.com/learn/learn-parachains-protocol/){target=\\_blank}.\n\nThis guide explains how to set up a collator for Polkadot system parachains, covering all key requirements, setting up and registering session keys, and meeting governance approval or invulnerables-list criteria (required for system parachains; non-system parachains may be more permissionless)."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1172, "end_char": 1190, "estimated_token_count": 3, "token_estimator": "heuristic-v1", "text": "## Prerequisites"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 2, "depth": 3, "title": "Hardware Requirements", "anchor": "hardware-requirements", "start_char": 1190, "end_char": 1902, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "### Hardware Requirements\n\nBlock-producing collators require robust hardware for reliable operation, including the following:\n\n- **CPU**: 4+ cores (8+ cores recommended for optimal performance)\n- **Memory**: 32 GB RAM minimum (64 GB recommended)\n- **Storage**:\n    - 200+ GB NVMe SSD (with pruning enabled for both parachain and relay chain)\n    - Fast disk I/O is critical for block production performance\n- **Network**:\n    - Public IP address\n    - 100+ Mbps connection; a stable connection is critical\n    - Open ports:\n        - **30333**: Parachain P2P\n        - **30334**: Relay chain P2P\n\n!!! warning \"Uptime is critical\"\n    Consider redundancy and monitoring to maintain block production reliability."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 3, "depth": 3, "title": "Software Requirements", "anchor": "software-requirements", "start_char": 1902, "end_char": 2159, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "### Software Requirements\n\nRequired software:\n\n- **Operating system**: Ubuntu 22.04 LTS (recommended) or similar Linux distribution\n- **[Docker](https://www.docker.com/get-started/){target=\\_blank}**: Required for obtaining binaries and running containers"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 4, "depth": 3, "title": "Account Requirements", "anchor": "account-requirements", "start_char": 2159, "end_char": 4020, "estimated_token_count": 325, "token_estimator": "heuristic-v1", "text": "### Account Requirements\n\n??? interface \"Need to create an account?\"\n\n    You can generate an account by taking the following steps:\n\n    1. Generate an account key with the `sr25519` scheme using the following command:\n\n        ```bash\n        docker run -it parity/subkey:latest generate --scheme sr25519\n        ```\n\n        The output will be similar to the following:\n\n        <div class=\"termynal\" data-termynal>\n        <span data-ty=\"input\"><span class=\"file-path\"></span>docker run -it parity/subkey:latest generate --scheme sr25519</span>\n        <span data-ty><pre>Secret phrase:       embody rail hour peanut .... badge syrup luggage canvas\n            Network ID:        substrate\n            Secret seed:       0x6498dd3416c491406e2c8283c76760ce4ca018478888b42315e7718778f2c2e1\n            Public key (hex):  0x2202210357e49390d4f8d868da983940fe220a0a0e00bc6feaeda462aa031810\n            Account ID:        0x2202210357e49390d4f8d868da983940fe220a0a0e00bc6feaeda462aa031810\n            Public key (SS58): 5CqJ7n72GvvF5ZzUT2HMj83KyDje4n8sXR8kuiK8HWtfDktF\n            SS58 Address:      5CqJ7n72GvvF5ZzUT2HMj83KyDje4n8sXR8kuiK8HWtfDktF\n        </pre></span>\n        </div>\n\n    2. Save the following items displayed in the output:\n        - Secret phrase (seed) - Keep this secure!\n        - Public key (hex)\n        - Account ID\n        - SS58 Address\n\n        !!! warning\n        \n            Store the secret phrase securely. Never share it. Consider using a hardware wallet for production collators.\n\nYour account must meet the following requirements:\n\n- **Funded account**: For on-chain transactions and potential bonding\n\nYou will also need the following, which are generated or configured later in this guide:\n\n- **Session keys**: For collator identification (generated after node setup)\n- **Node key**: For stable P2P peer ID (recommended)"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 5, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 4020, "end_char": 5331, "estimated_token_count": 302, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nThis guide provides two deployment options. Select the option that best fits your needs:\n\n- **Docker**: Best for simpler setup and maintenance\n- **systemd**: Best for production environments requiring more control\n\n=== \"Docker\"\n\n    1. Pull the Polkadot Parachain Docker image using the latest stable tag on [Docker Hub](https://hub.docker.com/r/parity/polkadot-parachain/tags){target=\\_blank}:\n\n        ```bash\n        docker pull parity/polkadot-parachain:stable2509-2\n        ```\n\n    2. Verify the installation:\n\n        ```bash\n        docker run --rm parity/polkadot-parachain:stable2509-2 --version\n        ```\n\n=== \"systemd\"\n\n    1. Download the `polkadot-parachain` binary using the latest stable [Polkadot SDK release](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank}:\n\n        ```bash\n        wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2509-2/polkadot-parachain\n        ```\n\n    2. Make it executable and move it to your system path:\n        \n        ```bash\n        chmod +x polkadot-parachain\n        sudo mv polkadot-parachain /usr/local/bin/\n        sudo chown root:root /usr/local/bin/polkadot-parachain\n        ```\n\n    3. Verify installation:\n\n        ```bash\n        polkadot-parachain --version\n        ```"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 6, "depth": 2, "title": "Generate Node Key", "anchor": "generate-node-key", "start_char": 5331, "end_char": 5960, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "## Generate Node Key\n\nGenerating a stable node key enables a consistent peer ID across the network. Follow these steps to generate a node key:\n\n1. Create a directory for node data:\n\n    ```bash\n    sudo mkdir -p /var/lib/polkadot-collator\n    ```\n\n2. Generate your node key using Docker:\n\n    ```bash\n    docker run -it parity/subkey:latest generate-node-key > /var/lib/polkadot-collator/node.key\n    ```\n\n3. Locate your peer ID in the displayed output. It will be similar to the following example:\n\n    ```bash\n    12D3KooWExcVYu7Mvjd4kxPVLwN2ZPnZ5NyLZ5ft477wqzfP2q6E\n    ```\n\nBe sure to save the peer ID for future reference."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 7, "depth": 2, "title": "Obtain Chain Specification", "anchor": "obtain-chain-specification", "start_char": 5960, "end_char": 7675, "estimated_token_count": 384, "token_estimator": "heuristic-v1", "text": "## Obtain Chain Specification\n\nDownload the chain specification for your target system parachain using one of the following options:\n\n=== \"Download from Chainspec Collection (Recommended)\"\n\n    Follow these steps to download your specification from the [Chainspec Collection](https://paritytech.github.io/chainspecs/){target=\\_blank}:\n\n    1. Find your target system parachain under the [**List of Chainspecs**](https://paritytech.github.io/chainspecs/#list-of-chainspecs){target=\\_blank}.\n    2. Download the chain specification JSON file.\n    3. Save it as `chain-spec.json`.\n\n=== \"Build Chain Spec from Runtime\"\n\n    Follow these steps to build a chainspec from the runtime:\n\n    1. Clone the runtimes repository and navigate into it:\n\n        ```bash\n        git clone https://github.com/polkadot-fellows/runtimes.git\n        cd runtimes\n        ```\n\n    2. Build the desired runtime. Use the following command for Polkadot Hub:\n\n        ```bash\n        cargo build --release -p asset-hub-polkadot-runtime\n        ```\n\n    3. Install the `chain-spec-builder` dependency:\n\n        ```bash\n        cargo install --locked staging-chain-spec-builder@14.0.0\n        ```\n\n    4. Finally, generate the chain spec:\n\n        ```bash\n        chain-spec-builder create \\\n            --relay-chain polkadot \\\n            --para-id 1000 \\\n            --runtime target/release/wbuild/asset-hub-polkadot-runtime/asset_hub_polkadot_runtime.compact.compressed.wasm \\\n            named-preset production > chain-spec.json\n        ```\n\n        ??? tip \"System Parachain Para IDs\"\n\n            - **Polkadot Hub**: 1000\n            - **Bridge Hub**: 1002\n            - **People Chain**: 1004\n            - **Coretime Chain**: 1005"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 8, "depth": 2, "title": "Run the Collator", "anchor": "run-the-collator", "start_char": 7675, "end_char": 12508, "estimated_token_count": 1138, "token_estimator": "heuristic-v1", "text": "## Run the Collator\n\nUsing your preferred deployment method, take the following steps to set up and run your collator:\n\n=== \"Docker\"\n\n    1. Create a directory for collator data and copy the chain spec:\n\n        ```bash\n        mkdir -p collator-data\n        cp chain-spec.json collator-data/\n        cp /var/lib/polkadot-collator/node.key collator-data/\n        ```\n\n    2. Launch the collator using Docker:\n\n        ```bash\n        docker run -d --name polkadot-collator --restart unless-stopped \\\n          -p 30333:30333 \\\n          -p 30334:30334 \\\n          -p 9944:9944 \\\n          -p 9615:9615 \\\n          -v $(pwd)/collator-data:/data \\\n          -v $(pwd)/chain-spec.json:/chain-spec.json \\\n          parity/polkadot-parachain:stable2509-2 \\\n          --collator \\\n          --chain=/chain-spec.json \\\n          --base-path=/data \\\n          --port=30333 \\\n          --rpc-port=9944 \\\n          --prometheus-port=9615 \\\n          --prometheus-external \\\n          --node-key-file=/data/node.key \\\n          --name=\"INSERT_YOUR_COLLATOR_NAME\" \\\n          --blocks-pruning=256 \\\n          --state-pruning=256 \\\n          --database=paritydb \\\n          -- \\\n          --chain=polkadot \\\n          --port=30334 \\\n          --sync=fast \\\n          --blocks-pruning=256 \\\n          --state-pruning=256 \\\n          --database=paritydb \\\n          --pool-limit=0 \\\n          --rpc-port=0\n        ```\n\n    3. View logs to monitor sync progress:\n\n        ```bash\n        docker logs -f polkadot-collator\n        ```\n\n=== \"systemd\"\n\n    1. Create a dedicated user:\n\n        ```bash\n        sudo useradd -r -s /bin/bash polkadot\n        ```\n\n    2. Copy your chain spec to the directory:\n\n        ```bash\n        sudo cp chain-spec.json /var/lib/polkadot-collator/\n        ```\n\n    3. Set permissions:\n\n        ```bash\n        sudo chown -R polkadot:polkadot /var/lib/polkadot-collator\n        ```\n\n    4. Create a systemd service file:\n\n        ```bash\n        sudo nano /etc/systemd/system/polkadot-collator.service\n        ```\n\n    5. Add the following configuration:\n\n        ```ini title=\"systemd/system/polkadot-collator.service\"\n        [Unit]\n        Description=Polkadot System Parachain Collator\n        After=network.target\n\n        [Service]\n        Type=simple\n        User=polkadot\n        Group=polkadot\n        WorkingDirectory=/var/lib/polkadot-collator\n\n        ExecStart=/usr/local/bin/polkadot-parachain \\\n          --collator \\\n          --chain=/var/lib/polkadot-collator/chain-spec.json \\\n          --base-path=/var/lib/polkadot-collator \\\n          --port=30333 \\\n          --rpc-port=9944 \\\n          --prometheus-port=9615 \\\n          --node-key-file=/var/lib/polkadot-collator/node.key \\\n          --name=\"INSERT_YOUR_COLLATOR_NAME\" \\\n          --blocks-pruning=256 \\\n          --state-pruning=256 \\\n          --database=paritydb \\\n          -- \\\n          --chain=polkadot \\\n          --port=30334 \\\n          --sync=fast \\\n          --blocks-pruning=256 \\\n          --state-pruning=256 \\\n          --database=paritydb \\\n          --pool-limit=0 \\\n          --rpc-port=0\n\n        Restart=always\n        RestartSec=10\n        LimitNOFILE=65536\n\n        [Install]\n        WantedBy=multi-user.target\n        ```\n\n    6. Start the service:\n\n        ```bash\n        sudo systemctl daemon-reload\n        sudo systemctl enable polkadot-collator\n        sudo systemctl start polkadot-collator\n        ```\n\n    7. Check the status:\n\n        ```bash\n        sudo systemctl status polkadot-collator\n        ```\n\n    8. View logs:\n\n        ```bash\n        sudo journalctl -u polkadot-collator -f\n        ```\n\n??? interface \"Configuration Arguments\"\n\n    - **`--collator`**: Enables block production mode.\n    - **`--node-key-file`**: Uses the generated node key for stable peer ID.\n    - **`--name`**: Your collator name (visible in [telemetry](https://telemetry.polkadot.io/){target=\\_blank}).\n    - **`--blocks-pruning=256`**: Keeps the last 256 blocks.\n    - **`--state-pruning=256`**: Keeps the state history of the last 256 blocks.\n    - **`--database=paritydb`**: Uses ParityDB for better performance.\n    - **`--sync=fast`**: Fast sync mode for the relay chain.\n    - **`--pool-limit=0`**: Disables transaction pool on relay chain (not needed for collators).\n    - **`--rpc-port=0` (relay chain)**: Disables RPC on the embedded relay chain node (not needed for collators).\n\nYour collator must sync both the relay chain and parachain before producing blocks. The relay chain uses fast sync to speed up synchronization. Overall sync time depends on:\n\n- Network bandwidth\n- Disk I/O speed\n- Current chain size\n\n!!! warning\n\n    Do not proceed with registration until both chains are fully synced. Monitor sync progress using the log viewing commands in the [Log Management](#commands-for-log-management) section."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 9, "depth": 2, "title": "Generate Session Keys", "anchor": "generate-session-keys", "start_char": 12508, "end_char": 13310, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "## Generate Session Keys\n\nSession keys are cryptographic keys used by your collator node to sign authorship information when producing blocks. They uniquely identify your collator on the network and must be registered on-chain before your collator can participate in block production.\n\nOnce your node is fully synced, use the following command to generate session keys via RPC:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n  -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"author_rotateKeys\", \"params\":[]}' \\\n  http://localhost:9944\n```\n\nThis command returns session keys as a hex string in the terminal. You must save these session keys as you'll need them for on-chain registration. As session keys are stored in the node's database, if you wipe the database, you'll also need to generate new keys."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 10, "depth": 2, "title": "Register Collator for Selection", "anchor": "register-collator-for-selection", "start_char": 13310, "end_char": 14967, "estimated_token_count": 451, "token_estimator": "heuristic-v1", "text": "## Register Collator for Selection\n\nSystem parachains use different mechanisms for selecting collators. A quick breakdown of each mechanism is as follows:\n\n| Method                   | How it Works                                                                                                                                                                                              | Requirements                                                     |\n|--------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|\n| **Invulnerables list**   | Fixed list defined through governance. Most common for system parachains.                                                                                                                                 | Permissioned via governance                                      |\n| **On-chain selection**   | Runtime automatically selects eligible collators. Some parachains use [pallet-collator-selection](https://paritytech.github.io/polkadot-sdk/master/pallet_collator_selection/index.html){target=\\_blank}. | Semi-permissionless (criteria-based; may require bonding tokens) |\n| **Fellowship decisions** | Technical fellowship may manage some system parachain collators.                                                                                                                                          | Permissioned via Fellowship                                      |"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 11, "depth": 3, "title": "Registration Process", "anchor": "registration-process", "start_char": 14967, "end_char": 17760, "estimated_token_count": 605, "token_estimator": "heuristic-v1", "text": "### Registration Process\n\nCollator registration authorizes your node to produce blocks on the network. The parachain's collator selection mechanism uses this on-chain registration to determine which nodes are eligible to author blocks.\n\nThe registration process varies by system parachain. General steps include the following:\n\n1. Check the existing collators for your target parachain:\n    1. Navigate to Polkadot.js Apps and connect to your system parachain.\n    2. Locate **Developer > Chain State**.\n    3. Query **`collatorSelection.invulnerables()`**.\n\n    ![](/images/node-infrastructure/run-a-collator/run-a-collator-01.webp)\n\n2. Prepare a governance proposal for invulnerables-based selection, including the following information:\n\n    - **Draft proposal**: Explain why you should be added as a collator.\n    - **Technical details**: Provide your session keys and account ID.\n    - **Infrastructure**: Describe your hardware and monitoring setup.\n    - **Experience**: Detail your relevant experience.\n\n    Submit the proposal to the relevant governance channels.\n\n3. Once approved (or if using on-chain selection), follow these steps to register session keys using Polkadot.js Apps:\n\n    1. Locate **Developer > Extrinsics**.\n    2. Select your account.\n    3. Choose the **`session.setKeys`** extrinsic.\n    4. Enter the following information:\n        - **`keys`**: Your session keys (from `author_rotateKeys`)\n        - **`proof`**: 0x00 (typically)\n    5. Click **Submit Transaction** and sign the transaction.\n    \n    ![](/images/node-infrastructure/run-a-collator/run-a-collator-02.webp)\n\n4. (Optional - primarily for non-system parachains) If the parachain uses on-chain bonding for collator selection, register as a candidate using Polkadot.js Apps:\n\n    !!! note\n        Most system parachains use invulnerables lists exclusively and do not require this step. Skip to step 5 if you're running a collator for a system parachain.\n\n    1. Locate **Developer > Extrinsics**.\n    2. Select your account.\n    3. Select `collatorSelection.registerAsCandidate`.\n    4. Click **Submit Transaction** and sign the transaction. The required bond amount will be automatically reserved from your account based on the pallet's configured `CandidacyBond`.\n\n    ![](/images/node-infrastructure/run-a-collator/run-a-collator-03.webp)\n\n5. For system parachains using invulnerables lists, await governance approval for your proposal. Once approved, your collator is added to the invulnerables list and will begin producing blocks in the next session or era. \n\n6. Verify your collator is active by monitoring logs for block production messages like \"Prepared block for proposing\" and \"Imported #123\". See the [Log Management](#commands-for-log-management) section for commands for log viewing."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 12, "depth": 2, "title": "Commands for Node Management", "anchor": "commands-for-node-management", "start_char": 17760, "end_char": 18563, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "## Commands for Node Management\n\nUse the following commands to manage your node:\n\n=== \"Docker\"\n\n    - **Stop container**:\n\n        ```bash\n        docker stop polkadot-collator\n        ```\n\n    - **Start container**:\n\n        ```bash\n        docker start polkadot-collator\n        ```\n\n    - **Remove container**:\n\n        ```bash\n        docker rm polkadot-collator\n        ```\n\n=== \"systemd\"\n\n    - **Check status**:\n\n        ```bash\n        sudo systemctl status polkadot-collator\n        ```\n\n    - **Stop service**:\n\n        ```bash\n        sudo systemctl stop polkadot-collator\n        ```\n\n    - **Enable service**:\n\n        ```bash\n        sudo systemctl enable polkadot-collator\n        ```\n\n    - **Start service**:\n\n        ```bash\n        sudo systemctl start polkadot-collator\n        ```"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 13, "depth": 2, "title": "Commands for Log Management", "anchor": "commands-for-log-management", "start_char": 18563, "end_char": 19742, "estimated_token_count": 274, "token_estimator": "heuristic-v1", "text": "## Commands for Log Management\n\nEfficient log management is essential to ensure collator performance and uptime. Use the following commands to help you manage logs to monitor and maintain your collator:\n\n=== \"Docker\"\n\n    - **View logs**:\n\n        ```bash\n        docker logs -f polkadot-collator\n        ```\n\n    - **View recent logs (last 100 lines)**:\n\n        ```bash\n        docker logs --tail 100 polkadot-collator\n        ```\n\n    - **Filter for errors**:\n\n        ```bash\n        docker logs polkadot-collator 2>&1 | grep -i error\n        ```\n\n    - **Filter for block production**:\n\n        ```bash\n        docker logs polkadot-collator 2>&1 | grep -i \"imported\"\n        ```\n\n=== \"systemd\"\n\n    - **View recent logs**:\n\n        ```bash\n        sudo journalctl -u polkadot-collator -n 100\n        ```\n\n    - **Follow logs in real-time**:\n\n        ```bash\n        sudo journalctl -u polkadot-collator -f\n        ```\n\n    - **Filter for errors**:\n\n        ```bash\n        sudo journalctl -u polkadot-collator | grep -i error\n        ```\n\n    - **Filter for block production**:\n\n        ```bash\n        sudo journalctl -u polkadot-collator | grep -i \"imported\"\n        ```"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 14, "depth": 2, "title": "Database Maintenance", "anchor": "database-maintenance", "start_char": 19742, "end_char": 20097, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Database Maintenance\n\nCheck database size periodically using the commands for your selected setup:\n\n=== \"Docker\"\n\n    ```bash\n    # Replace with your mounted data directory path\n    du -sh ./collator-data\n    ```\n\n=== \"systemd\"\n\n    ```bash\n    du -sh /var/lib/polkadot-collator\n    ```\n\nThe collator node automatically prunes based on configuration."}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 15, "depth": 2, "title": "Updates and Upgrades", "anchor": "updates-and-upgrades", "start_char": 20097, "end_char": 22189, "estimated_token_count": 436, "token_estimator": "heuristic-v1", "text": "## Updates and Upgrades\n\nUpdates or upgrades can happen on either the runtime or client. Runtime upgrades are automatically applied via on-chain governance and do not require any manual action on your part. Client upgrades do require a manual binary update process performed via terminal commands as follows:\n\n=== \"Docker\"\n\n    1. Stop the service:\n\n        ```bash\n        sudo systemctl stop polkadot-collator\n        ```\n\n    2. Backup data (recommended):\n\n        ```bash\n        sudo cp -r /var/lib/polkadot-collator /var/lib/polkadot-collator.backup\n        ```\n\n    3. Pull the new Docker image:\n\n        ```bash\n        docker pull parity/polkadot-parachain:<NEW_TAG>\n        ```\n\n    4. Update the image tag in your systemd service file:\n\n        ```bash\n        sudo nano /etc/systemd/system/polkadot-collator.service\n        ```\n\n    5. Reload systemd and restart the service:\n\n        ```bash\n        sudo systemctl daemon-reload\n        sudo systemctl start polkadot-collator\n        ```\n\n    6. Verify the service is running:\n\n        ```bash\n        sudo systemctl status polkadot-collator\n        ```\n\n=== \"systemd\"\n\n    1. Stop the service:\n\n        ```bash\n        sudo systemctl stop polkadot-collator\n        ```\n\n    2. Backup data (recommended):\n\n        ```bash\n        sudo cp -r /var/lib/polkadot-collator /var/lib/polkadot-collator.backup\n        ```\n\n    3. Download the new binary from [GitHub releases](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank}:\n\n        ```bash\n        wget https://github.com/paritytech/polkadot-sdk/releases/download/INSERT_NEW_VERSION/polkadot-parachain\n        chmod +x polkadot-parachain\n        sudo mv polkadot-parachain /usr/local/bin/\n        ```\n\n    4. Verify `polkadot-parachain` version to confirm successful update:\n\n        ```bash\n        polkadot-parachain --version\n        ```\n\n    5. Restart the service:\n\n        ```bash\n        sudo systemctl start polkadot-collator\n        ```\n\n    6. Verify the service is running:\n\n        ```bash\n        sudo systemctl status polkadot-collator\n        ```"}
{"page_id": "node-infrastructure-run-a-collator", "page_title": "Run a Block-Producing Collator", "index": 16, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 22189, "end_char": 22952, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nRunning a collator node is essential for parachain operation and network security. By following this guide, you have set up a production-ready collator that:\n\n- Produces blocks for your parachain and maintains network consensus.\n- Implements comprehensive security measures to protect keys and operations.\n- Supports robust monitoring and alerting for reliable performance.\n- Follows best practices for both Docker and systemd deployments.\n\nAs a collator operator, you play a vital role in your parachain's infrastructure. Regular maintenance, security updates, and monitoring will ensure your collator continues to perform reliably. Stay engaged with your parachain community and keep up with updates to maintain optimal performance and security."}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 653, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nA parachain RPC node provides direct access to a specific parachain on the Polkadot network, enabling developers and applications to interact with its assets, governance, cross-chain messages, and more. Running your own node also supports essential infrastructure tasks, such as block indexing and compatibility with Polkadot SDK tools.\n\nThrough the parachain RPC (WebSocket port 9944, HTTP port 9933), your node acts as the bridge between the parachain and applications. This page walks through setting up a node from scratch, covering hardware requirements and deployment options using Docker or systemd."}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 653, "end_char": 671, "estimated_token_count": 3, "token_estimator": "heuristic-v1", "text": "## Prerequisites"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 2, "depth": 3, "title": "Hardware Requirements", "anchor": "hardware-requirements", "start_char": 671, "end_char": 2308, "estimated_token_count": 392, "token_estimator": "heuristic-v1", "text": "### Hardware Requirements\n\nRPC nodes serving production traffic require robust hardware:\n\n- **CPU**: 8+ cores; 16+ cores for high traffic\n- **Memory**: 64 GB RAM minimum; 128 GB recommended for high traffic\n- **Storage**: Storage requirements vary by parachain. Fast NVMe I/O is critical for RPC query performance\n    - **System parachains**: [Snapshots](https://snapshots.polkadot.io/){target=\\_blank} _may_ be available\n        - **Archive node (complete history)**: Using snapshots, expected storage requirements (including ~822 GB for the pruned relay chain) are:\n            - **Asset Hub**: ~1.2 TB\n            - **Bridge Hub**: ~1.1 TB\n            - **Collectives**: ~1 TB\n            - **People Chain**: ~900 GB\n            - **Coretime**: ~900 GB\n        - **Pruned node (recent state)**: ~200 GB total for both parachain and relay chain \n    - **Non-system parachains**: Consult the parachain team or documentation, then add ~822 GB for the pruned relay chain\n- **Network**:\n    - Public IP address\n    - Stable internet connection with sufficient bandwidth\n    - 1 Gbps connection for high traffic scenarios\n    - Consider DDoS protection and rate limiting for production deployments\n    - Open ports:\n        - **30333**: Parachain P2P\n        - **30334**: Relay chain P2P\n        - **9944**: Polkadot SDK WebSocket RPC\n        - **9933**: Polkadot SDK HTTP RPC\n\n!!! note\n    For development or low-traffic scenarios, you can reduce these requirements proportionally. Consider using a reverse proxy ([nginx](https://nginx.org/){target=\\_blank}, [Caddy](https://caddyserver.com/){target=\\_blank}) for production deployments."}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 3, "depth": 3, "title": "Software Requirements", "anchor": "software-requirements", "start_char": 2308, "end_char": 2712, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "### Software Requirements\n\nRequired software:\n\n- **Operating system**: Ubuntu 22.04 LTS (recommended) or similar Linux distribution\n- **[Docker](https://www.docker.com/get-started/){target=\\_blank}**: Required for obtaining binaries and running containers\n- **[rclone](https://rclone.org/downloads/){target=\\_blank}**: (Optional but recommended) Command-line program for managing files on cloud storage"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 4, "depth": 2, "title": "Obtain the Chain Specification", "anchor": "obtain-the-chain-specification", "start_char": 2712, "end_char": 3031, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "## Obtain the Chain Specification\n\nTo run an RPC node for a parachain, you need its chain specification file. This JSON file defines the network parameters, genesis state, and bootnodes. The process for obtaining the chain spec may differ depending on whether youâ€™re running a system parachain or a regular parachain."}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 5, "depth": 3, "title": "System Parachains", "anchor": "system-parachains", "start_char": 3031, "end_char": 3620, "estimated_token_count": 151, "token_estimator": "heuristic-v1", "text": "### System Parachains\n\nSystem parachain chain specs are available from multiple sources:\n\n- **[Chainspec Collection](https://paritytech.github.io/chainspecs/)**: (Recommended) Choose a file to download from the **List of Chainspecs** section.\n- **[Polkadot SDK repository](https://github.com/paritytech/polkadot-sdk){target=\\_blank}**: Download directly from the Polkadot SDK repository:\n\n    ```bash\n    # Example for People Chain\n    curl -L https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/cumulus/parachains/chain-specs/people-polkadot.json -o chain-spec.json\n    ```"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 6, "depth": 3, "title": "Other Parachains", "anchor": "other-parachains", "start_char": 3620, "end_char": 3746, "estimated_token_count": 23, "token_estimator": "heuristic-v1", "text": "### Other Parachains\n\nFor non-system parachains, check the parachain's documentation for official chain specification files."}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 7, "depth": 2, "title": "Spin Up a Node", "anchor": "spin-up-a-node", "start_char": 3746, "end_char": 14628, "estimated_token_count": 2411, "token_estimator": "heuristic-v1", "text": "## Spin Up a Node\n\nChoose the deployment option that fits your project, and follow the steps in the appropriate tab to complete setup:\n\n- **Docker**: Best for simpler set up and maintenance\n- **systemd**: Best for production environments requiring more control\n\nThis guide uses **People Chain** as an example. To set up a different parachain, replace the chain spec file, snapshot path, and chain name with the corresponding values for your target parachain.\n\nSystem parachain details:\n\n| System Parachain   | Para ID | Chain Spec File            | Snapshot Path                          |\n|--------------------|---------|----------------------------|----------------------------------------|\n| **Bridge Hub**     | 1002    | `bridge-hub-polkadot.json` | `polkadot-bridge-hub-paritydb-archive` |\n| **People Chain**   | 1004    | `people-polkadot.json`     | `polkadot-people-rocksdb-archive`      |\n| **Coretime Chain** | 1005    | `coretime-polkadot.json`   | `polkadot-coretime-rocksdb-archive`    |\n\n=== \"Docker\"\n\n    1. Download your parachain's chain specification as described in [Obtain the Chain Specification](#obtain-the-chain-specification).\n\n    2. (Optional but recommended) Download pre-synced [snapshots](https://snapshots.polkadot.io/){target=\\_blank} to cut initial sync time from days to hours:\n\n        !!! note\n            Snapshots are available for system parachains and the Polkadot relay chain. For other parachains, check with the parachain team for snapshot availability or sync from genesis.\n\n        1. Create new directories:\n\n            ```bash\n            mkdir -p my-node-data/chains/people-polkadot/db\n            mkdir -p my-node-data/chains/polkadot/db\n            ```\n\n        2. Download and save the archive parachain snapshot:\n\n            ```bash\n            # Check https://snapshots.polkadot.io/ for the latest snapshot URL\n            export SNAPSHOT_URL_PARACHAIN=\"https://snapshots.polkadot.io/polkadot-people-rocksdb-archive/INSERT_LATEST\"\n\n            rclone copyurl $SNAPSHOT_URL_PARACHAIN/files.txt files.txt\n            rclone copy --progress --transfers 20 \\\n              --http-url $SNAPSHOT_URL_PARACHAIN \\\n              --no-traverse --http-no-head --disable-http2 \\\n              --inplace --no-gzip-encoding --size-only \\\n              --retries 6 --retries-sleep 10s \\\n              --files-from files.txt :http: my-node-data/chains/people-polkadot/db/\n\n            rm files.txt\n            ```\n\n            ??? interface \"rclone parameters\"\n\n                - **`--transfers 20`**: Uses 20 parallel transfers for faster download\n                - **`--retries 6`**: Automatically retries failed transfers up to 6 times\n                - **`--retries-sleep 10s`**: Waits 10 seconds between retry attempts\n                - **`--size-only`**: Only transfers if sizes differ (prevents unnecessary re-downloads)\n\n        3. Repeat the process for the pruned relay chain snapshot:\n\n            ```bash\n            # Check https://snapshots.polkadot.io/ for the latest snapshot URL\n            export SNAPSHOT_URL_RELAY=\"https://snapshots.polkadot.io/polkadot-rocksdb-prune/INSERT_LATEST\"\n\n            rclone copyurl $SNAPSHOT_URL_RELAY/files.txt files.txt\n            rclone copy --progress --transfers 20 \\\n              --http-url $SNAPSHOT_URL_RELAY \\\n              --no-traverse --http-no-head --disable-http2 \\\n              --inplace --no-gzip-encoding --size-only \\\n              --retries 6 --retries-sleep 10s \\\n              --files-from files.txt :http: my-node-data/chains/polkadot/db/\n\n            rm files.txt\n            ```\n\n    3. Launch the parachain node using the official [Parity Docker image](https://hub.docker.com/r/parity/polkadot-parachain){target=\\_blank}:\n\n        === \"Archive\"\n\n            ```bash\n            docker run -d --name people-chain-rpc --restart unless-stopped \\\n              -p 9944:9944 \\\n              -p 9933:9933 \\\n              -p 9615:9615 \\\n              -p 30334:30334 \\\n              -p 30333:30333 \\\n              -v $(pwd)/people-polkadot.json:/people-polkadot.json \\\n              -v $(pwd)/my-node-data:/data \\\n              parity/polkadot-parachain:stable2509-2 \\\n              --name=PeopleChainRPC \\\n              --base-path=/data \\\n              --chain=/people-polkadot.json \\\n              --prometheus-external \\\n              --prometheus-port 9615 \\\n              --unsafe-rpc-external \\\n              --rpc-port=9944 \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --state-pruning=archive \\\n              --blocks-pruning=archive \\\n              -- \\\n              --base-path=/data \\\n              --chain=polkadot \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n            ```\n\n        === \"Pruned\"\n\n            ```bash\n            docker run -d --name people-chain-rpc --restart unless-stopped \\\n              -p 9944:9944 \\\n              -p 9933:9933 \\\n              -p 9615:9615 \\\n              -p 30334:30334 \\\n              -p 30333:30333 \\\n              -v $(pwd)/people-polkadot.json:/people-polkadot.json \\\n              -v $(pwd)/my-node-data:/data \\\n              parity/polkadot-parachain:stable2509-2 \\\n              --name=PeopleChainRPC \\\n              --base-path=/data \\\n              --chain=/people-polkadot.json \\\n              --prometheus-external \\\n              --prometheus-port 9615 \\\n              --unsafe-rpc-external \\\n              --rpc-port=9944 \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --state-pruning=1000 \\\n              --blocks-pruning=256 \\\n              -- \\\n              --base-path=/data \\\n              --chain=polkadot \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n            ```\n\n        !!! note\n            The `parity/polkadot-parachain` image works for system parachains and parachains built with standard Cumulus templates. For parachains with custom runtimes, check the parachain's documentation for their specific Docker image or binary.\n\n        Refer to the [Port Mappings](#port-mappings) and [Node Configuration Arguments](#node-configuration-arguments) sections for details on the command's configurations.\n\n=== \"systemd\"\n\n    1. Download the `polkadot-parachain` binary from the latest stable [Polkadot SDK release](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank}:\n\n        ```bash\n        # Download the latest stable release (check releases page for current version)\n        wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2509-2/polkadot-parachain\n\n        # Make it executable and move to system path\n        chmod +x polkadot-parachain\n        sudo mv polkadot-parachain /usr/local/bin/\n\n        # Verify installation\n        polkadot-parachain --version\n        ```\n\n    2. Download your parachain's chain specification as described in [Obtain the Chain Specification](#obtain-the-chain-specification).\n\n    3. Create user and directory structures:\n\n        ```bash\n        # Create a dedicated user\n        sudo useradd -r -s /bin/bash polkadot\n        \n        # Create data directory\n        sudo mkdir -p /var/lib/people-chain-rpc\n\n        # Copy the chain spec to the directory\n        sudo cp asset-hub-polkadot.json /var/lib/people-chain-rpc/\n\n        # Set permissions\n        sudo chown -R polkadot:polkadot /var/lib/people-chain-rpc\n        ```\n\n    4. Create a systemd service file for the Polkadot SDK RPC node:\n\n        ```bash\n        sudo nano /etc/systemd/system/people-chain-rpc.service\n        ```\n\n    5. Open the new service file and add the configuration for either an archive (complete history) or pruned (recent state) node:\n\n        === \"Archive\"\n\n            ```ini\n            [Unit]\n            Description=People Chain RPC Node\n            After=network.target\n\n            [Service]\n            Type=simple\n            User=polkadot\n            Group=polkadot\n            WorkingDirectory=/var/lib/people-chain-rpc\n\n            ExecStart=/usr/local/bin/polkadot-parachain \\\n              --name=PeopleChainRPC \\\n              --chain=/var/lib/people-chain-rpc/people-polkadot.json \\\n              --base-path=/var/lib/people-chain-rpc \\\n              --port=30333 \\\n              --rpc-port=9944 \\\n              --rpc-external \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --prometheus-port=9615 \\\n              --prometheus-external \\\n              --state-pruning=archive \\\n              --blocks-pruning=archive \\\n              -- \\\n              --chain=polkadot \\\n              --base-path=/var/lib/people-chain-rpc \\\n              --port=30334 \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n\n            Restart=always\n            RestartSec=10\n            LimitNOFILE=65536\n\n            [Install]\n            WantedBy=multi-user.target\n            ```\n\n        === \"Pruned\"\n\n            ```ini\n            [Unit]\n            Description=People Chain RPC Node\n            After=network.target\n\n            [Service]\n            Type=simple\n            User=polkadot\n            Group=polkadot\n            WorkingDirectory=/var/lib/people-chain-rpc\n\n            ExecStart=/usr/local/bin/polkadot-parachain \\\n              --name=PeopleChainRPC \\\n              --chain=/var/lib/people-chain-rpc/people-polkadot.json \\\n              --base-path=/var/lib/people-chain-rpc \\\n              --port=30333 \\\n              --rpc-port=9944 \\\n              --rpc-external \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --prometheus-port=9615 \\\n              --prometheus-external \\\n              --state-pruning=1000 \\\n              --blocks-pruning=256 \\\n              -- \\\n              --chain=polkadot \\\n              --base-path=/var/lib/people-chain-rpc \\\n              --port=30334 \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n\n            Restart=always\n            RestartSec=10\n            LimitNOFILE=65536\n\n            [Install]\n            WantedBy=multi-user.target\n            ```\n\n        Refer to the [Port Mappings](#port-mappings) and [Node Configuration Arguments](#node-configuration-arguments) sections for details on the command's configurations.\n\n    6. Start the service:\n\n        ```bash\n        # Reload systemd\n        sudo systemctl daemon-reload\n\n        # Enable service to start on boot\n        sudo systemctl enable people-chain-rpc\n        \n        # Start the Polkadot SDK node:\n        sudo systemctl start people-chain-rpc\n        ```"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 8, "depth": 3, "title": "Port Mappings", "anchor": "port-mappings", "start_char": 14628, "end_char": 14834, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "### Port Mappings\n\n- **`9944`**: Polkadot SDK RPC endpoint (WebSocket/HTTP)\n- **`9933`**: Polkadot SDK HTTP RPC endpoint\n- **`9615`**: Prometheus metrics endpoint\n- **`30333/30334`**: P2P networking ports"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 9, "depth": 3, "title": "Node Configuration Parameters", "anchor": "node-configuration-parameters", "start_char": 14834, "end_char": 15460, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "### Node Configuration Parameters\n\n- **`--unsafe-rpc-external`**: Enables external RPC access. **This command should only be used in development or properly secured environments**. For production, use a reverse proxy with authentication.\n- **`--rpc-cors=all`**: Allows all origins for CORS.\n- **`--rpc-methods=safe`**: Only allows safe RPC methods.\n- **`--state-pruning`**: Archive keeps complete state history, pruned keeps last specified number of blocks.\n- **`--blocks-pruning`**: Archive keeps all blocks, pruned keeps last specified number of finalized blocks.\n- **`--prometheus-external`**: Exposes metrics externally."}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 10, "depth": 2, "title": "Monitor Node Synchronization", "anchor": "monitor-node-synchronization", "start_char": 15460, "end_char": 16454, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "## Monitor Node Synchronization\n\nMonitor the node synchronization status:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n-d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_syncState\", \"params\":[]}' \\\nhttp://localhost:9944\n```\n\nWhen synchronization is complete, `currentBlock` will be equal to `highestBlock`:\n\n<div class=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>curl -H \"Content-Type: application/json\" \\\n  -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_syncState\", \"params\":[]}' \\\n  http://localhost:9944</span>\n  <span data-ty><pre>{\n  \"jsonrpc\":\"2.0\",\n  \"id\":1,\n  \"result\":{\n    \"startingBlock\":0,\n    \"currentBlock\":3394816,\n    \"highestBlock\":3394816\n  }\n}\n  </pre></span>\n</div>\n\n!!! tip\n    You can use the `system_health` command to verify your node is running properly.\n\n    ```bash\n    curl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_health\", \"params\":[]}' \\\n    http://localhost:9944\n    ```"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 11, "depth": 2, "title": "Commands for Managing Your Node", "anchor": "commands-for-managing-your-node", "start_char": 16454, "end_char": 17452, "estimated_token_count": 238, "token_estimator": "heuristic-v1", "text": "## Commands for Managing Your Node\n\nUse the following commands to manage your node:\n\n=== \"Docker\"\n\n    - **View node logs**:\n\n        ```bash\n        docker logs -f people-chain-rpc\n        ```\n\n    - **Stop container**:\n\n        ```bash\n        docker stop people-chain-rpc\n        ```\n\n    - **Start container**:\n\n        ```bash\n        docker start people-chain-rpc\n        ```\n\n    - **Remove container**:\n\n        ```bash\n        docker rm people-chain-rpc\n        ```\n\n=== \"systemd\"\n\n    - **Check status**:\n\n        ```bash\n        sudo systemctl status people-chain-rpc\n        ```\n\n    - **View node logs**:\n\n        ```bash\n        sudo journalctl -u people-chain-rpc -f\n        ```\n\n    - **Stop service**:\n\n        ```bash\n        sudo systemctl stop people-chain-rpc\n        ```\n\n    - **Enable service**:\n\n        ```bash\n        sudo systemctl enable people-chain-rpc\n        ```\n\n    - **Start service**:\n\n        ```bash\n        sudo systemctl start people-chain-rpc\n        ```"}
{"page_id": "node-infrastructure-run-a-node-parachain-rpc", "page_title": "Run a Parachain RPC Node", "index": 12, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 17452, "end_char": 18303, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nRunning a parachain RPC node provides critical infrastructure for accessing Polkadot network services. By following this guide, you have set up a production-ready RPC node that:\n\n- Provides reliable access to parachain functionality for applications and users.\n- Supports flexible deployment with both Docker and systemd options.\n- Implements comprehensive monitoring, security, and maintenance practices.\n- Can be adapted for any parachain by substituting the appropriate chain specification.\n\nWhether you're running a node for system parachains (People Chain, Bridge Hub, Coretime Chain) or other parachains in the ecosystem, regular maintenance and monitoring will ensure your RPC node continues to provide reliable service. Stay updated with the latest releases and best practices to keep your infrastructure secure and performant."}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 36, "end_char": 675, "estimated_token_count": 109, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub is the gateway to the Polkadot network, providing access to core services such as asset management, governance, and cross-chain messaging. Running your own RPC node gives developers and applications direct access to these services while also supporting infrastructure tasks like block indexing and SDK tool compatibility.\n\n\n\nThrough the Polkadot SDK node RPC (WebSocket port 9944, HTTP port 9933), your node serves as the bridge between the network and applications. This page guides you through setting up a node from scratch, including hardware requirements and deployment options using Docker or systemd."}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 675, "end_char": 693, "estimated_token_count": 3, "token_estimator": "heuristic-v1", "text": "## Prerequisites"}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 2, "depth": 3, "title": "Hardware Requirements", "anchor": "hardware-requirements", "start_char": 693, "end_char": 1987, "estimated_token_count": 299, "token_estimator": "heuristic-v1", "text": "### Hardware Requirements\n\nRPC nodes serving production traffic require robust hardware. The following should be considered the minimum standard to effectively operate an RPC node:\n\n- **CPU**: 8+ cores; 16+ cores for high traffic\n- **Memory**: 64 GB RAM minimum; 128 GB recommended for high traffic\n- **Storage**:\n    - **Archive node (complete history)**: ~1.2 TB NVMe SSD total (~392 GB for Asset Hub archive + ~822 GB for relay chain pruned snapshot)\n    - **Pruned node (recent state)**: ~200 GB NVMe SSD total (with pruning enabled for both parachain and relay chain)\n    - Fast disk I/O is critical for query performance\n- **Network**:\n    - Public IP address\n    - Stable internet connection with sufficient bandwidth\n    - 1 Gbps connection for high traffic scenarios\n    - Consider DDoS protection and rate limiting for production deployments\n    - Open ports:\n        - **30333**: Parachain P2P\n        - **30334**: Relay chain P2P\n        - **9944**: Polkadot SDK WebSocket RPC\n        - **9933**: Polkadot SDK HTTP RPC\n\n!!! note\n    For development or low-traffic scenarios, you can reduce these requirements proportionally. Consider using a reverse proxy ([nginx](https://nginx.org/){target=\\_blank}, [Caddy](https://caddyserver.com/){target=\\_blank}) for production deployments."}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 3, "depth": 3, "title": "Software Requirements", "anchor": "software-requirements", "start_char": 1987, "end_char": 2391, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "### Software Requirements\n\nRequired software:\n\n- **Operating system**: Ubuntu 22.04 LTS (recommended) or similar Linux distribution\n- **[Docker](https://www.docker.com/get-started/){target=\\_blank}**: Required for obtaining binaries and running containers\n- **[rclone](https://rclone.org/downloads/){target=\\_blank}**: (Optional but recommended) Command-line program for managing files on cloud storage"}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 4, "depth": 2, "title": "Spin Up a Node", "anchor": "spin-up-a-node", "start_char": 2391, "end_char": 12433, "estimated_token_count": 2194, "token_estimator": "heuristic-v1", "text": "## Spin Up a Node\n\nThis guide provides two options for deployment:\n\n- **Docker**: Best for simpler set up and maintenance\n- **systemd**: Best for production environments requiring more control\n\nSelect the best option for your project, then use the steps in the following tabs to complete set up.\n\n=== \"Docker\"\n\n    1. Download the official Polkadot Hub (formerly known as Asset Hub) chain specification file:\n\n        ```bash\n        curl -L https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/cumulus/parachains/chain-specs/asset-hub-polkadot.json -o asset-hub-polkadot.json\n        ```\n\n    2. (Optional but recommended) Download pre-synced snapshots from the [Snapshot Provider](https://snapshots.polkadot.io/){target=\\_blank} to cut initial sync time from days to hours:\n\n        1. Create new directories:\n\n            ```bash\n            mkdir -p my-node-data/chains/asset-hub-polkadot/db\n            mkdir -p my-node-data/chains/polkadot/db\n            ```\n\n        2. Download and save the archive Asset Hub snapshot:\n\n            ```bash\n            # Check https://snapshots.polkadot.io/ for the latest snapshot URL\n            export SNAPSHOT_URL_ASSET_HUB=\"https://snapshots.polkadot.io/polkadot-asset-hub-rocksdb-archive/INSERT_LATEST\"\n\n            rclone copyurl $SNAPSHOT_URL_ASSET_HUB/files.txt files.txt\n            rclone copy --progress --transfers 20 \\\n              --http-url $SNAPSHOT_URL_ASSET_HUB \\\n              --no-traverse --http-no-head --disable-http2 \\\n              --inplace --no-gzip-encoding --size-only \\\n              --retries 6 --retries-sleep 10s \\\n              --files-from files.txt :http: my-node-data/chains/asset-hub-polkadot/db/\n\n            rm files.txt\n            ```\n\n            ??? interface \"rclone parameters\"\n\n                - **`--transfers 20`**: Uses 20 parallel transfers for faster download\n                - **`--retries 6`**: Automatically retries failed transfers up to 6 times\n                - **`--retries-sleep 10s`**: Waits 10 seconds between retry attempts\n                - **`--size-only`**: Only transfers if sizes differ (prevents unnecessary re-downloads)\n\n        3. Repeat the process with the pruned relay chain snapshot:\n\n            ```bash\n            # Check https://snapshots.polkadot.io/ for the latest snapshot URL\n            export SNAPSHOT_URL_RELAY=\"https://snapshots.polkadot.io/polkadot-rocksdb-prune/INSERT_LATEST\"\n\n            rclone copyurl $SNAPSHOT_URL_RELAY/files.txt files.txt\n            rclone copy --progress --transfers 20 \\\n              --http-url $SNAPSHOT_URL_RELAY \\\n              --no-traverse --http-no-head --disable-http2 \\\n              --inplace --no-gzip-encoding --size-only \\\n              --retries 6 --retries-sleep 10s \\\n              --files-from files.txt :http: my-node-data/chains/polkadot/db/\n\n            rm files.txt\n            ```\n\n    3. Launch your Polkadot Hub node using the official [Parity Docker image](https://hub.docker.com/r/parity/polkadot-parachain){target=\\_blank}:\n\n        === \"Archive\"\n\n            ```bash\n            docker run -d --name polkadot-hub-rpc --restart unless-stopped \\\n              -p 9944:9944 \\\n              -p 9933:9933 \\\n              -p 9615:9615 \\\n              -p 30334:30334 \\\n              -p 30333:30333 \\\n              -v $(pwd)/asset-hub-polkadot.json:/asset-hub-polkadot.json \\\n              -v $(pwd)/my-node-data:/data \\\n              parity/polkadot-parachain:stable2509-2 \\\n              --name=PolkadotHubRPC \\\n              --base-path=/data \\\n              --chain=/asset-hub-polkadot.json \\\n              --prometheus-external \\\n              --prometheus-port 9615 \\\n              --unsafe-rpc-external \\\n              --rpc-port=9944 \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --state-pruning=archive \\\n              --blocks-pruning=archive \\\n              -- \\\n              --base-path=/data \\\n              --chain=polkadot \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n            ```\n\n        === \"Pruned\"\n\n            ```bash\n            docker run -d --name polkadot-hub-rpc --restart unless-stopped \\\n              -p 9944:9944 \\\n              -p 9933:9933 \\\n              -p 9615:9615 \\\n              -p 30334:30334 \\\n              -p 30333:30333 \\\n              -v $(pwd)/asset-hub-polkadot.json:/asset-hub-polkadot.json \\\n              -v $(pwd)/my-node-data:/data \\\n              parity/polkadot-parachain:stable2509-2 \\\n              --name=PolkadotHubRPC \\\n              --base-path=/data \\\n              --chain=/asset-hub-polkadot.json \\\n              --prometheus-external \\\n              --prometheus-port 9615 \\\n              --unsafe-rpc-external \\\n              --rpc-port=9944 \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --state-pruning=1000 \\\n              --blocks-pruning=256 \\\n              -- \\\n              --base-path=/data \\\n              --chain=polkadot \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n            ```\n\n        Refer to the [Port Mappings](#port-mappings) and [Node Configuration Arguments](#node-configuration-arguments) sections for details on the command's configurations.\n    \n=== \"systemd\"\n\n    1. Download the `polkadot-parachain` binary from the latest stable [Polkadot SDK release](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank}:\n\n        ```bash\n        # Download the latest stable release (check releases page for current version)\n        wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2509-2/polkadot-parachain\n\n        # Make it executable and move to system path\n        chmod +x polkadot-parachain\n        sudo mv polkadot-parachain /usr/local/bin/\n\n        # Verify installation\n        polkadot-parachain --version\n        ```\n\n    2. Download the Polkadot Hub chain specification:\n\n        ```bash\n        curl -L https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/cumulus/parachains/chain-specs/asset-hub-polkadot.json -o asset-hub-polkadot.json\n        ```\n\n    3. Create user and directory structures:\n\n        ```bash\n        # Create a dedicated user\n        sudo useradd -r -s /bin/bash polkadot\n        \n        # Create data directory\n        sudo mkdir -p /var/lib/polkadot-hub-rpc\n\n        # Copy the chain spec to the directory\n        sudo cp asset-hub-polkadot.json /var/lib/polkadot-hub-rpc/\n\n        # Set permissions\n        sudo chown -R polkadot:polkadot /var/lib/polkadot-hub-rpc\n        ```\n\n    4. Create a systemd service file for the Polkadot SDK RPC node:\n\n        ```bash\n        sudo nano /etc/systemd/system/polkadot-hub-rpc.service\n        ```\n\n    5. Open the new service file and add the configuration for either an archive (complete history) or pruned (recent state) node:\n\n        === \"Archive\"\n\n            ```ini\n            [Unit]\n            Description=Polkadot Hub RPC Node\n            After=network.target\n\n            [Service]\n            Type=simple\n            User=polkadot\n            Group=polkadot\n            WorkingDirectory=/var/lib/polkadot-hub-rpc\n\n            ExecStart=/usr/local/bin/polkadot-parachain \\\n              --name=PolkadotHubRPC \\\n              --chain=/var/lib/polkadot-hub-rpc/asset-hub-polkadot.json \\\n              --base-path=/var/lib/polkadot-hub-rpc \\\n              --port=30333 \\\n              --rpc-port=9944 \\\n              --rpc-external \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --prometheus-port=9615 \\\n              --prometheus-external \\\n              --state-pruning=archive \\\n              --blocks-pruning=archive \\\n              -- \\\n              --chain=polkadot \\\n              --base-path=/var/lib/polkadot-hub-rpc \\\n              --port=30334 \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n\n            Restart=always\n            RestartSec=10\n            LimitNOFILE=65536\n\n            [Install]\n            WantedBy=multi-user.target\n            ```\n\n        === \"Pruned Node\"\n\n            ```ini\n            [Unit]\n            Description=Polkadot Hub RPC Node\n            After=network.target\n\n            [Service]\n            Type=simple\n            User=polkadot\n            Group=polkadot\n            WorkingDirectory=/var/lib/polkadot-hub-rpc\n\n            ExecStart=/usr/local/bin/polkadot-parachain \\\n              --name=PolkadotHubRPC \\\n              --chain=/var/lib/polkadot-hub-rpc/asset-hub-polkadot.json \\\n              --base-path=/var/lib/polkadot-hub-rpc \\\n              --port=30333 \\\n              --rpc-port=9944 \\\n              --rpc-external \\\n              --rpc-cors=all \\\n              --rpc-methods=safe \\\n              --rpc-max-connections=1000 \\\n              --prometheus-port=9615 \\\n              --prometheus-external \\\n              --state-pruning=1000 \\\n              --blocks-pruning=256 \\\n              -- \\\n              --chain=polkadot \\\n              --base-path=/var/lib/polkadot-hub-rpc \\\n              --port=30334 \\\n              --state-pruning=256 \\\n              --blocks-pruning=256 \\\n              --rpc-port=0\n\n            Restart=always\n            RestartSec=10\n            LimitNOFILE=65536\n\n            [Install]\n            WantedBy=multi-user.target\n            ```\n\n        Refer to the [Port Mappings](#port-mappings) and [Node Configuration Arguments](#node-configuration-arguments) sections for details on the command's configurations.\n\n    6. Start the service:\n\n        ```bash\n        # Reload systemd\n        sudo systemctl daemon-reload\n\n        # Enable service to start on boot\n        sudo systemctl enable polkadot-hub-rpc\n        \n        # Start the Polkadot SDK node:\n        sudo systemctl start polkadot-hub-rpc\n        ```"}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 5, "depth": 3, "title": "Port Mappings", "anchor": "port-mappings", "start_char": 12433, "end_char": 12639, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "### Port Mappings\n\n- **`9944`**: Polkadot SDK RPC endpoint (WebSocket/HTTP)\n- **`9933`**: Polkadot SDK HTTP RPC endpoint\n- **`9615`**: Prometheus metrics endpoint\n- **`30333/30334`**: P2P networking ports"}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 6, "depth": 3, "title": "Node Configuration Arguments", "anchor": "node-configuration-arguments", "start_char": 12639, "end_char": 13264, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "### Node Configuration Arguments\n\n- **`--unsafe-rpc-external`**: Enables external RPC access. **This command should only be used in development or properly secured environments**. For production, use a reverse proxy with authentication.\n- **`--rpc-cors=all`**: Allows all origins for CORS.\n- **`--rpc-methods=safe`**: Only allows safe RPC methods.\n- **`--state-pruning`**: Archive keeps complete state history, pruned keeps last specified number of blocks.\n- **`--blocks-pruning`**: Archive keeps all blocks, pruned keeps last specified number of finalized blocks.\n- **`--prometheus-external`**: Exposes metrics externally."}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 7, "depth": 2, "title": "Monitor Node Synchronization", "anchor": "monitor-node-synchronization", "start_char": 13264, "end_char": 14258, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "## Monitor Node Synchronization\n\nMonitor the node synchronization status:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n-d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_syncState\", \"params\":[]}' \\\nhttp://localhost:9944\n```\n\nWhen synchronization is complete, `currentBlock` will be equal to `highestBlock`:\n\n<div class=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>curl -H \"Content-Type: application/json\" \\\n  -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_syncState\", \"params\":[]}' \\\n  http://localhost:9944</span>\n  <span data-ty><pre>{\n  \"jsonrpc\":\"2.0\",\n  \"id\":1,\n  \"result\":{\n    \"startingBlock\":0,\n    \"currentBlock\":3394816,\n    \"highestBlock\":3394816\n  }\n}\n  </pre></span>\n</div>\n\n!!! tip\n    You can use the `system_health` command to verify your node is running properly.\n\n    ```bash\n    curl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"system_health\", \"params\":[]}' \\\n    http://localhost:9944\n    ```"}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 8, "depth": 2, "title": "Commands for Managing Your Node", "anchor": "commands-for-managing-your-node", "start_char": 14258, "end_char": 15256, "estimated_token_count": 238, "token_estimator": "heuristic-v1", "text": "## Commands for Managing Your Node\n\nUse the following commands to manage your node:\n\n=== \"Docker\"\n\n    - **View node logs**:\n\n        ```bash\n        docker logs -f polkadot-hub-rpc\n        ```\n\n    - **Stop container**:\n\n        ```bash\n        docker stop polkadot-hub-rpc\n        ```\n\n    - **Start container**:\n\n        ```bash\n        docker start polkadot-hub-rpc\n        ```\n\n    - **Remove container**:\n\n        ```bash\n        docker rm polkadot-hub-rpc\n        ```\n\n=== \"systemd\"\n\n    - **Check status**:\n\n        ```bash\n        sudo systemctl status polkadot-hub-rpc\n        ```\n\n    - **View node logs**:\n\n        ```bash\n        sudo journalctl -u polkadot-hub-rpc -f\n        ```\n\n    - **Stop service**:\n\n        ```bash\n        sudo systemctl stop polkadot-hub-rpc\n        ```\n\n    - **Enable service**:\n\n        ```bash\n        sudo systemctl enable polkadot-hub-rpc\n        ```\n\n    - **Start service**:\n\n        ```bash\n        sudo systemctl start polkadot-hub-rpc\n        ```"}
{"page_id": "node-infrastructure-run-a-node-polkadot-hub-rpc", "page_title": "Run an RPC Node for Polkadot Hub", "index": 9, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 15256, "end_char": 16086, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nRunning an RPC node for Polkadot Hub provides essential infrastructure for applications and users to interact with the network. By following this guide, you have set up a production-ready RPC node that:\n\n- Provides reliable access to Polkadot Hub's asset management, governance, and cross-chain communication features.\n- Supports both Docker and systemd deployment options for flexibility.\n- Implements proper monitoring, security, and maintenance practices.\n- Serves as a foundation for building and operating Polkadot SDK applications.\n\nRegular maintenance, security updates, and monitoring will ensure your RPC node continues to serve your users reliably. As the Polkadot network evolves, stay informed about updates and best practices through the official channels and community resources listed in this guide."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 613, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBootnodes are essential for helping blockchain nodes discover peers and join the network. When a node starts, it needs to find other nodes, and bootnodes provide an initial point of contact. Once connected, a node can expand its peer connections and play its role in the network, like participating as a validator.\n\nThis guide will walk you through setting up a Polkadot bootnode, configuring P2P, WebSocket (WS), secure WSS connections, and managing network keys. You'll also learn how to test your bootnode to ensure it is running correctly and accessible to other nodes."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 613, "end_char": 986, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you start, you need to have the following prerequisites:\n\n- Verify a working Polkadot (`polkadot`) binary is available on your machine.\n- Ensure you have nginx installed. Please refer to the [Installation Guide](https://nginx.org/en/docs/install.html){target=\\_blank} for help with installation if needed.\n- A VPS or other dedicated server setup."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 2, "depth": 2, "title": "Accessing the Bootnode", "anchor": "accessing-the-bootnode", "start_char": 986, "end_char": 1573, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "## Accessing the Bootnode\n\nBootnodes must be accessible through three key channels to connect with other nodes in the network:\n\n- **P2P**: A direct peer-to-peer connection, set by.\n\n    ```bash\n\n    --listen-addr /ip4/0.0.0.0/tcp/INSERT_PORT\n\n    ```\n    \n    This is not enabled by default on non-validator nodes like archive RPC nodes.\n\n- **P2P/WS**: A WebSocket (WS) connection, also configured via `--listen-addr`.\n- **P2P/WSS**: A secure WebSocket (WSS) connection using SSL, often required for light clients. An SSL proxy is needed, as the node itself cannot handle certificates."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 3, "depth": 2, "title": "Node Key", "anchor": "node-key", "start_char": 1573, "end_char": 2240, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "## Node Key\n\nA node key is the ED25519 key used by `libp2p` to assign your node an identity or peer ID. Generating a known node key for a bootnode is crucial, as it gives you a consistent key that can be placed in chain specifications as a known, reliable bootnode.\n\nStarting a node creates its node key in the `chains/INSERT_CHAIN/network/secret_ed25519` file.\n\nYou can create a node key using:\n\n ``` bash\n polkadot key generate-node-key\n ``` \n \nThis key can be used in the startup command line.\n\nIt is imperative that you backup the node key. If it is included in the `polkadot` binary, it is hardcoded into the binary, which must be recompiled to change the key."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 4, "depth": 2, "title": "Running the Bootnode", "anchor": "running-the-bootnode", "start_char": 2240, "end_char": 3333, "estimated_token_count": 240, "token_estimator": "heuristic-v1", "text": "## Running the Bootnode\n\nA bootnode can be run as follows:\n\n ``` bash\n polkadot --chain polkadot \\\n --name dot-bootnode \\\n --listen-addr /ip4/0.0.0.0/tcp/30310 \\\n --listen-addr /ip4/0.0.0.0/tcp/30311/ws\n ```\n\nThis assigns the p2p to port 30310 and p2p/ws to port 30311. For the p2p/wss port, a proxy must be set up with a DNS name and a corresponding certificate. The following example is for the popular nginx server and enables p2p/wss on port 30312 by adding a proxy to the p2p/ws port 30311:\n\n``` conf title=\"/etc/nginx/sites-enabled/dot-bootnode\"\nserver {\n       listen       30312 ssl http2 default_server;\n       server_name  dot-bootnode.stakeworld.io;\n       root         /var/www/html;\n\n       ssl_certificate \"INSERT_YOUR_CERT\";\n       ssl_certificate_key \"INSERT_YOUR_KEY\";\n\n       location / {\n         proxy_buffers 16 4k;\n         proxy_buffer_size 2k;\n         proxy_pass http://localhost:30311;\n         proxy_http_version 1.1;\n         proxy_set_header Upgrade $http_upgrade;\n         proxy_set_header Connection \"Upgrade\";\n         proxy_set_header Host $host;\n   }\n\n}\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 5, "depth": 2, "title": "Testing Bootnode Connection", "anchor": "testing-bootnode-connection", "start_char": 3333, "end_char": 3727, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Testing Bootnode Connection\n\nIf the preceding node is running with DNS name `dot-bootnode.stakeworld.io`, which contains a proxy with a valid certificate and node-id `12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg` then the following commands should output `syncing 1 peers`.\n\n!!!tip\n    You can add `-lsub-libp2p=trace` on the end to get libp2p trace logging for debugging purposes."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 6, "depth": 3, "title": "P2P", "anchor": "p2p", "start_char": 3727, "end_char": 3993, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### P2P\n\n```bash\npolkadot --chain polkadot \\\n--base-path /tmp/node \\\n--name \"Bootnode testnode\" \\\n--reserved-only \\\n--reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30310/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" \\\n--no-hardware-benchmarks\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 7, "depth": 3, "title": "P2P/WS", "anchor": "p2pws", "start_char": 3993, "end_char": 4265, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### P2P/WS\n\n```bash\npolkadot --chain polkadot \\\n--base-path /tmp/node \\\n--name \"Bootnode testnode\" \\\n--reserved-only \\\n--reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30311/ws/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" \\\n--no-hardware-benchmarks\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-bootnode", "page_title": "Set Up a Bootnode", "index": 8, "depth": 3, "title": "P2P/WSS", "anchor": "p2pwss", "start_char": 4265, "end_char": 4538, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### P2P/WSS\n\n```bash\npolkadot --chain polkadot \\\n--base-path /tmp/node \\\n--name \"Bootnode testnode\" \\\n--reserved-only \\\n--reserved-nodes \"/dns/dot-bootnode.stakeworld.io/tcp/30312/wss/p2p/12D3KooWAb5MyC1UJiEQJk4Hg4B2Vi3AJdqSUhTGYUqSnEqCFMFg\" \\\n--no-hardware-benchmarks\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 945, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRunning a node on Polkadot provides direct interaction with the network, enhanced privacy, and full control over RPC requests, transactions, and data queries. As the backbone of the network, nodes ensure decentralized data propagation, transaction validation, and seamless communication across the ecosystem.\n\nPolkadot supports multiple node types, including pruned, archive, and light nodes, each suited to specific use cases. During setup, you can use configuration flags to choose the node type you wish to run.\n\nThis guide walks you through configuring, securing, and maintaining a node on Polkadot or any Polkadot SDK-based chain. It covers instructions for the different node types and how to safely expose your node's RPC server for external access. Whether you're building a local development environment, powering dApps, or supporting network decentralization, this guide provides all the essentials."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 1, "depth": 2, "title": "Set Up a Node", "anchor": "set-up-a-node", "start_char": 945, "end_char": 1150, "estimated_token_count": 43, "token_estimator": "heuristic-v1", "text": "## Set Up a Node\n\nNow that you're familiar with the different types of nodes, this section will walk you through configuring, securing, and maintaining a node on Polkadot or any Polkadot SDK-based chain."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 2, "depth": 3, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1150, "end_char": 1720, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "### Prerequisites\n\nBefore getting started, ensure the following prerequisites are met:\n\n- Ensure [Rust](https://rust-lang.org/tools/install/){target=\\_blank} is installed on your operating system.\n- [Install the necessary dependencies for the Polkadot SDK](/parachains/install-polkadot-sdk/){target=\\_blank}.\n\n!!! warning\n    This setup is not recommended for validators. If you plan to run a validator, refer to the [Running a Validator](/node-infrastructure/run-a-validator/onboarding-and-offboarding/set-up-validator/){target=\\_blank} guide for proper instructions."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 3, "depth": 3, "title": "Install and Build the Polkadot Binary", "anchor": "install-and-build-the-polkadot-binary", "start_char": 1720, "end_char": 8204, "estimated_token_count": 1578, "token_estimator": "heuristic-v1", "text": "### Install and Build the Polkadot Binary\n\nThis section will walk you through installing and building the Polkadot binary for different operating systems and methods.\n\n??? interface \"macOS\"\n\n    To get started, update and configure the Rust toolchain by running the following commands:\n\n    ```bash\n    source ~/.cargo/env\n\n    rustup default stable\n    rustup update\n\n    rustup update nightly\n    rustup target add wasm32-unknown-unknown --toolchain nightly\n    rustup component add rust-src --toolchain stable-aarch64-apple-darwin\n    ```\n\n    You can verify your installation by running:\n\n    ```bash\n    rustup show\n    rustup +nightly show\n    ```\n\n    You should see output similar to the following:\n\n    <div id=\"termynal\" data-termynal>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>rustup show</span>\n      <span data-ty>rustup +nightly show</span>\n      <span data-ty></span>\n      <span data-ty>active toolchain</span>\n      <span data-ty>----------------</span>\n      <span data-ty></span>\n      <span data-ty>stable-aarch64-apple-darwin (default)</span>\n      <span data-ty>rustc 1.82.0 (f6e511eec 2024-10-15)</span>\n      <span data-ty></span>\n      <span data-ty>active toolchain</span>\n      <span data-ty>----------------</span>\n      <span data-ty></span>\n      <span data-ty>nightly-aarch64-apple-darwin (overridden by +toolchain on the command line) </span>\n      <span data-ty>rustc 1.84.0-nightly (03ee48451 2024-11-18)</span>\n      <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n    </div>\n\n    Then, run the following commands to clone and build the Polkadot binary:\n  \n    ```bash\n    git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\n    cd polkadot-sdk\n    cargo build --release\n    ```\n\n    Depending upon the specs of your machine, compiling the binary may take an hour or more. After building the Polkadot node from source, the executable binary will be located in the `./target/release/polkadot` directory.\n\n??? interface \"Windows\"\n\n    To get started, make sure that you have [WSL and Ubuntu](https://learn.microsoft.com/en-us/windows/wsl/install){target=\\_blank} installed on your Windows machine.\n\n    Once installed, you have a couple options for installing the Polkadot binary:\n\n    - If Rust is installed, then `cargo` can be used similar to the macOS instructions.\n    - Or, the instructions in the Linux section can be used.\n\n??? interface \"Linux (pre-built binary)\"\n\n    To grab the [latest release of the Polkadot binary](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank}, you can use `wget`:\n\n    ```bash\n    wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-INSERT_VERSION/polkadot\n    ```\n    \n    Ensure you note the executable binary's location, as you'll need to use it when running the start-up command. If you prefer, you can specify the output location of the executable binary with the `-O` flag, for example:\n\n    ```bash\n    wget https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-INSERT_VERSION/polkadot \\\n    - O /var/lib/polkadot-data/polkadot\n    ```\n\n    !!!tip\n        The nature of pre-built binaries means that they may not work on your particular architecture or Linux distribution. If you see an error like `cannot execute binary file: Exec format error` it likely means the binary is incompatible with your system. You will either need to compile the binary or use [Docker](#use-docker).\n\n    Ensure that you properly configure the permissions to make the Polkadot release binary executable:\n\n    ```bash\n    sudo chmod +x polkadot\n    ```\n\n??? interface \"Linux (compile binary)\"\n\n    The most reliable (although perhaps not the fastest) way of launching a full node is to compile the binary yourself. Depending on your machine's specs, this may take an hour or more.\n\n    To get started, run the following commands to configure the Rust toolchain:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup update nightly\n    rustup target add wasm32-unknown-unknown --toolchain nightly\n    rustup target add wasm32-unknown-unknown --toolchain stable-x86_64-unknown-linux-gnu\n    rustup component add rust-src --toolchain stable-x86_64-unknown-linux-gnu\n    ```\n\n    You can verify your installation by running:\n\n    ```bash\n    rustup show\n    ```\n\n    You should see output similar to the following:\n\n    <div id=\"termynal\" data-termynal>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>rustup show</span>\n      <span data-ty></span>\n      <span data-ty>active toolchain</span>\n      <span data-ty>----------------</span>\n      <span data-ty></span>\n      <span data-ty>stable-x86_64-unknown-linux-gnu (default)</span>\n      <span data-ty>rustc 1.82.0 (f6e511eec 2024-10-15)</span>\n    </div>\n\n    Once Rust is configured, run the following commands to clone and build Polkadot:\n  \n    ```bash\n    git clone https://github.com/paritytech/polkadot-sdk polkadot-sdk\n    cd polkadot-sdk\n    cargo build --release\n    ```\n\n    Compiling the binary may take an hour or more, depending on your machine's specs. After building the Polkadot node from the source, the executable binary will be located in the `./target/release/polkadot` directory.\n\n??? interface \"Linux (snap package)\"\n\n    Polkadot can be installed as a [snap package](https://snapcraft.io/polkadot){target=\\_blank}. If you don't already have Snap installed, take the following steps to install it:\n\n    ```bash\n    sudo apt update\n    sudo apt install snapd\n    ```\n\n    Install the Polkadot snap package:\n\n    ```bash\n    sudo snap install polkadot\n    ```\n    \n    Before continuing on with the following instructions, check out the [Configure and Run Your Node](#configure-and-run-your-node) section to learn more about the configuration options.\n\n    To configure your Polkadot node with your desired options, you'll run a command similar to the following:\n\n    ```bash\n    sudo snap set polkadot service-args=\"--name=MyName --chain=polkadot\"\n    ```\n\n    Then to start the node service, run:\n\n    ```bash\n    sudo snap start polkadot\n    ```\n\n    You can review the logs to check on the status of the node: \n\n    ```bash\n    snap logs polkadot -f\n    ```\n\n    And at any time, you can stop the node service:\n\n    ```bash\n    sudo snap stop polkadot\n    ```\n\n    You can optionally prevent the service from stopping when snap is updated with the following command:\n\n    ```bash\n    sudo snap set polkadot endure=true\n    ```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 4, "depth": 3, "title": "Use Docker", "anchor": "use-docker", "start_char": 8204, "end_char": 9271, "estimated_token_count": 293, "token_estimator": "heuristic-v1", "text": "### Use Docker\n\nAs an additional option, you can use Docker to run your node in a container. Doing this is more advanced, so it's best left up to those already familiar with Docker or who have completed the other set-up instructions in this guide. You can review the latest versions on [DockerHub](https://hub.docker.com/r/parity/polkadot/tags){target=\\_blank}.\n\nBe aware that when you run Polkadot in Docker, the process only listens on `localhost` by default. If you would like to connect to your node's services (RPC and Prometheus) you need to ensure that you run the node with the `--rpc-external`, and `--prometheus-external` commands.\n\n```bash\ndocker run -p 9944:9944 -p 9615:9615 parity/polkadot:v1.16.2 --name \"my-polkadot-node-calling-home\" --rpc-external --prometheus-external\n```\n\nIf you're running Docker on an Apple Silicon machine (e.g. M4), you'll need to adapt the command slightly:\n\n```bash\ndocker run --platform linux/amd64 -p 9944:9944 -p 9615:9615 parity/polkadot:v1.16.2 --name \"kearsarge-calling-home\" --rpc-external --prometheus-external\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 5, "depth": 2, "title": "Configure and Run Your Node", "anchor": "configure-and-run-your-node", "start_char": 9271, "end_char": 11063, "estimated_token_count": 418, "token_estimator": "heuristic-v1", "text": "## Configure and Run Your Node\n\nNow that you've installed and built the Polkadot binary, the next step is to configure the start-up command depending on the type of node that you want to run. You'll need to modify the start-up command accordingly based on the location of the binary. In some cases, it may be located within theÂ `./target/release/`Â folder, so you'll need to replaceÂ polkadotÂ withÂ `./target/release/polkadot`Â in the following commands.\n\nAlso, note that you can use the same binary for Polkadot as you would for Kusama or any other relay chain. You'll need to use theÂ `--chain`Â flag to differentiate between chains.\n\nThe base commands for running a Polkadot node are as follows:\n\n=== \"Default pruned node\"\n\n    This uses the default pruning value of the last 256 blocks:\n\n    ```bash\n    polkadot --chain polkadot \\\n    --name \"INSERT_NODE_NAME\"\n    ```\n\n=== \"Custom pruned node\"\n\n    You can customize the pruning value, for example, to the last 1000 finalized blocks:\n\n    ```bash\n    polkadot --chain polkadot \\\n    --name INSERT_YOUR_NODE_NAME \\\n    --state-pruning 1000 \\\n    --blocks-pruning archive \\\n    --rpc-cors all \\\n    --rpc-methods safe\n    ```\n\n=== \"Archive node\"\n\n    To support the full state, use the `archive` option:\n\n    ```bash\n    polkadot --chain polkadot \\\n    --name INSERT_YOUR_NODE_NAME \\\n    --state-pruning archive \\\n    --blocks-pruning archive \\\n    ```\n\nIf you want to run an RPC node, please refer to the following [RPC Configurations](#rpc-configurations) section.\n\nTo review a complete list of the available commands, flags, and options, you can use the `--help` flag:\n\n```bash\npolkadot --help\n```\n\nOnce you've fully configured your start-up command, you can execute it in your terminal and your node will start [syncing](#sync-your-node)."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 6, "depth": 3, "title": "RPC Configurations", "anchor": "rpc-configurations", "start_char": 11063, "end_char": 11922, "estimated_token_count": 221, "token_estimator": "heuristic-v1", "text": "### RPC Configurations\n\nThe node startup settings allow you to choose what to expose, how many connections to expose, and which systems should be granted access through the RPC server.\n\n- You can limit the methods to use with `--rpc-methods`; an easy way to set this to a safe mode is `--rpc-methods safe`.\n- You can set your maximum connections through `--rpc-max-connections`, for example, `--rpc-max-connections 200`.\n- By default, localhost and Polkadot.js can access the RPC server. You can change this by setting `--rpc-cors`. To allow access from everywhere, you can use `--rpc-cors all`.\n\nFor a list of important flags when running RPC nodes, refer to the Parity DevOps documentation: [Important Flags for Running an RPC Node](https://paritytech.github.io/devops-guide/guides/rpc_index.html?#important-flags-for-running-an-rpc-node){target=\\_blank}."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 7, "depth": 2, "title": "Sync Your Node", "anchor": "sync-your-node", "start_char": 11922, "end_char": 15590, "estimated_token_count": 1235, "token_estimator": "heuristic-v1", "text": "## Sync Your Node\n\nThe syncing process will take a while, depending on your capacity, processing power, disk speed, and RAM. The process may be completed on a $10 DigitalOcean droplet in about ~36 hours. While syncing, your node name should be visible in gray on Polkadot Telemetry, and once it is fully synced, your node name will appear in white onÂ [Polkadot Telemetry](https://telemetry.polkadot.io/#list/Polkadot){target=_blank}.\n\nA healthy node syncing blocks will output logs like the following:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty>2024-11-19 23:49:57 Parity Polkadot</span>\n  <span data-ty>2024-11-19 23:49:57 âœŒï¸ version 1.14.1-7c4cd60da6d</span>\n  <span data-ty>2024-11-19 23:49:57 â¤ï¸ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2024</span>\n  <span data-ty>2024-11-19 23:49:57 ðŸ“‹ Chain specification: Polkadot</span>\n  <span data-ty>2024-11-19 23:49:57 ðŸ· Node name: myPolkadotNode</span>\n  <span data-ty>2024-11-19 23:49:57 ðŸ‘¤ Role: FULL</span>\n  <span data-ty>2024-11-19 23:49:57 ðŸ’¾ Database: RocksDb at /home/ubuntu/.local/share/polkadot/chains/polkadot/db/full</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ· Local node identity is: 12D3KooWDmhHEgPRJUJnUpJ4TFWn28EENqvKWH4dZGCN9TS51y9h</span>\n  <span data-ty>2024-11-19 23:50:00 Running libp2p network backend</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» Operating system: linux</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» CPU architecture: x86_64</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» Target environment: gnu</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» CPU: Intel(R) Xeon(R) CPU E3-1245 V2 @ 3.40GHz</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» CPU cores: 4</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» Memory: 32001MB</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» Kernel: 5.15.0-113-generic</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» Linux distribution: Ubuntu 22.04.5 LTS</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ’» Virtual machine: no</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ“¦ Highest known block at #9319</span>\n  <span data-ty>2024-11-19 23:50:00 ã€½ï¸ Prometheus exporter started at 127.0.0.1:9615</span>\n  <span data-ty>2024-11-19 23:50:00 Running JSON-RPC server: addr=127.0.0.1:9944, allowed origins=[\"http://localhost:*\", \"http://127.0.0.1:*\", \"https://localhost:*\", \"https://127.0.0.1:*\", \"https://polkadot.js.org\"]</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ CPU score: 671.67 MiBs</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ Memory score: 7.96 GiBs</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ Disk score (seq. writes): 377.87 MiBs</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ Disk score (rand. writes): 147.92 MiBs</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ¥© BEEFY gadget waiting for BEEFY pallet to become available...</span>\n  <span data-ty>2024-11-19 23:50:00 ðŸ” Discovered new external address for our node: /ip4/37.187.93.17/tcp/30333/ws/p2p/12D3KooWDmhHEgPRJUJnUpJ4TFWn28EENqvKWH4dZGCN9TS51y9h</span>\n  <span data-ty>2024-11-19 23:50:01 ðŸ” Discovered new external address for our node: /ip6/2001:41d0:a:3511::1/tcp/30333/ws/p2p/12D3KooWDmhHEgPRJUJnUpJ4TFWn28EENqvKWH4dZGCN9TS51y9h</span>\n  <span data-ty>2024-11-19 23:50:05 âš™ï¸ Syncing, target=#23486325 (5 peers), best: #12262 (0x8fb5â€¦f310), finalized #11776 (0x9de1â€¦32fb), â¬‡ 430.5kiB/s â¬† 17.8kiB/s</span>\n  <span data-ty>2024-11-19 23:50:10 âš™ï¸ Syncing 628.8 bps, target=#23486326 (6 peers), best: #15406 (0x9ce1â€¦2d76), finalized #15360 (0x0e41â€¦a064), â¬‡ 255.0kiB/s â¬† 1.8kiB/s</span>\n</div>\n\nCongratulations, you're now syncing a Polkadot full node! Remember that the process is identical when using any other Polkadot SDK-based chain, although individual chains may have chain-specific flag requirements."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-full-node", "page_title": "Set Up a Node", "index": 8, "depth": 3, "title": "Connect to Your Node", "anchor": "connect-to-your-node", "start_char": 15590, "end_char": 15943, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "### Connect to Your Node\n\nOpen [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/explorer){target=\\_blank} and click the logo in the top left to switch the node. Activate the **Development** toggle and input your node's domain or IP address. The default WSS endpoint for a local node is:\n\n```bash\nws://127.0.0.1:9944\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 27, "end_char": 600, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEnsuring secure WebSocket communication is crucial for maintaining the integrity and security of a Polkadot or Kusama node when interacting with remote clients. This guide walks you through setting up a secure WebSocket (WSS) connection for your node by leveraging SSL encryption with popular web server proxies like nginx or Apache.\n\nBy the end of this guide, you'll be able to secure your node's WebSocket port, enabling safe remote connections without exposing your node to unnecessary risks. The instructions in this guide are for UNIX-based systems."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 1, "depth": 2, "title": "Secure a WebSocket Port", "anchor": "secure-a-websocket-port", "start_char": 600, "end_char": 1053, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "## Secure a WebSocket Port\n\nYou can convert a non-secured WebSocket port to a secure WSS port by placing it behind an SSL-enabled proxy. This approach can be used to secure a bootnode or RPC server. The SSL-enabled apache2/nginx/other proxy server redirects requests to the internal WebSocket and converts it to a secure (WSS) connection. You can use a service like [LetsEncrypt](https://letsencrypt.org/){target=\\_blank} to obtain an SSL certificate."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 2, "depth": 3, "title": "Obtain an SSL Certificate", "anchor": "obtain-an-ssl-certificate", "start_char": 1053, "end_char": 2080, "estimated_token_count": 257, "token_estimator": "heuristic-v1", "text": "### Obtain an SSL Certificate\n\nLetsEncrypt suggests using the [Certbot ACME client](https://letsencrypt.org/getting-started/#with-shell-access/){target=\\_blank} for your respective web server implementation to get a free SSL certificate:\n\n- [nginx](https://certbot.eff.org/instructions?ws=nginx&os=ubuntufocal){target=\\_blank}\n- [apache2](https://certbot.eff.org/instructions?ws=apache&os=ubuntufocal){target=\\_blank}\n \nLetsEncrypt will auto-generate an SSL certificate and include it in your configuration.\n\nWhen connecting, you can generate a self-signed certificate and rely on your node's raw IP address. However, self-signed certificates aren't optimal because you must include the certificate in an allowlist to access it from a browser.\n\nUse the following command to generate a self-signed certificate using OpenSSL:\n\n```bash\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/selfsigned.key -out /etc/ssl/certs/selfsigned.crt\nsudo openssl dhparam -out /etc/ssl/certs/dhparam.pem 2048\n```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 3, "depth": 2, "title": "Install a Proxy Server", "anchor": "install-a-proxy-server", "start_char": 2080, "end_char": 2477, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Install a Proxy Server\n\nThere are a lot of different implementations of a WebSocket proxy; some of the more widely used are [nginx](https://www.f5.com/go/product/welcome-to-nginx){target=\\_blank} and [apache2](https://httpd.apache.org/){target=\\_blank}, both of which are commonly used web server implementations. See the following section for configuration examples for both implementations."}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 4, "depth": 3, "title": "Use nginx", "anchor": "use-nginx", "start_char": 2477, "end_char": 3219, "estimated_token_count": 154, "token_estimator": "heuristic-v1", "text": "### Use nginx\n\n1. Install the `nginx` web server: \n    ```bash\n    apt install nginx\n    ```\n\n2. In an SSL-enabled virtual host, add:\n    ```conf\n    server {\n        (...)\n        location / {\n        proxy_buffers 16 4k;\n        proxy_buffer_size 2k;\n        proxy_pass http://localhost:9944;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"Upgrade\";\n        proxy_set_header Host $host;\n        }\n    }\n    ```\n3. Optionally, you can introduce some form of rate limiting:\n    ```conf\n    http {\n        limit_req_zone  \"$http_x_forwarded_for\" zone=zone:10m rate=2r/s;\n        (...)\n    }\n    location / {\n        limit_req zone=zone burst=5;\n        (...)\n    }\n    ```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 5, "depth": 3, "title": "Use Apache2", "anchor": "use-apache2", "start_char": 3219, "end_char": 5047, "estimated_token_count": 406, "token_estimator": "heuristic-v1", "text": "### Use Apache2\n\nApache2 can run in various modes, including `prefork`, `worker`, and `event`. In this example, the [`event`](https://httpd.apache.org/docs/2.4/mod/event.html){target=\\_blank} mode is recommended for handling higher traffic loads, as it is optimized for performance in such environments. However, depending on the specific requirements of your setup, other modes like `prefork` or `worker` may also be appropriate.\n\n1. Install the `apache2` web server:\n    ```bash\n    apt install apache2\n    a2dismod mpm_prefork\n    a2enmod mpm_event proxy proxy_html proxy_http proxy_wstunnel rewrite ssl\n    ```\n2. The [`mod_proxy_wstunnel`](https://httpd.apache.org/docs/2.4/mod/mod_proxy_wstunnel.html){target=\\_blank} provides support for the tunneling of WebSocket connections to a backend WebSocket server. The connection is automatically upgraded to a WebSocket connection. In an SSL-enabled virtual host add:\n\n    ```apacheconf\n    # (...)\n    SSLProxyEngine on\n    ProxyRequests off\n    ProxyPass / ws://localhost:9944\n    ProxyPassReverse / ws://localhost:9944\n    ```\n    !!!warning \n        Older versions of `mod_proxy_wstunnel` don't upgrade the connection automatically and will need the following config added:\n        ```apacheconf\n        RewriteEngine on\n        RewriteCond %{HTTP:Upgrade} websocket [NC]\n        RewriteRule /(.*) ws://localhost:9944/$1 [P,L]\n        RewriteRule /(.*) http://localhost:9944/$1 [P,L]\n        ```\n\n3. Optionally, some form of rate limiting can be introduced by first running the following command:\n\n    ```bash\n    apt install libapache2-mod-qos\n    a2enmod qos\n    ```\n\n    Then edit `/etc/apache2/mods-available/qos.conf` as follows:\n\n    ```conf\n    # allows max 50 connections from a single IP address:\n    QS_SrvMaxConnPerIP                                 50\n    ```"}
{"page_id": "node-infrastructure-run-a-node-relay-chain-secure-wss", "page_title": "Set Up Secure WebSocket", "index": 6, "depth": 2, "title": "Connect to the Node", "anchor": "connect-to-the-node", "start_char": 5047, "end_char": 5567, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## Connect to the Node\n\n1. Open [Polkadot.js Apps interface](https://polkadot.js.org/apps){target=\\_blank} and click the logo in the top left to switch the node.\n2. Activate the **Development** toggle and input either your node's domain or IP address. Remember to prefix with `wss://` and, if you're using the 443 port, append `:443` as follows:\n\n    ```bash\n    wss://example.com:443\n    ```\n\n![A sync-in-progress chain connected to Polkadot.js UI](/images/node-infrastructure/run-a-node/secure-wss/secure-wss-01.webp)"}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 576, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter setting up your node environment as shown in the [Setup](/node-infrastructure/run-a-validator/onboarding-and-offboarding/set-up-validator/){target=\\_blank} section, you'll need to configure multiple keys for your validator to operate properly. This includes setting up session keys, which are essential for participating in the consensus process, and configuring a node key that maintains a stable network identity. This guide walks you through the key management process, showing you how to generate, store, and register these keys."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 1, "depth": 2, "title": "Set Session Keys", "anchor": "set-session-keys", "start_char": 576, "end_char": 1106, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "## Set Session Keys\n\nSetting up your validator's session keys is essential to associate your node with your stash account on the Polkadot network. Validators use session keys to participate in the consensus process. Your validator can only perform its role in the network by properly setting session keys which consist of several key pairs for different parts of the protocol (e.g., GRANDPA, BABE). These keys must be registered on-chain and associated with your validator node to ensure it can participate in validating blocks."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 2, "depth": 3, "title": "Generate Session Keys", "anchor": "generate-session-keys", "start_char": 1106, "end_char": 4119, "estimated_token_count": 646, "token_estimator": "heuristic-v1", "text": "### Generate Session Keys\n\nThere are multiple ways to create the session keys. It can be done by interacting with the [Polkadot.js Apps UI](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, using the curl command or by using [Subkey](https://paritytech.github.io/polkadot-sdk/master/subkey/index.html){target=\\_blank}.\n\n=== \"Polkadot.js Apps UI\"\n\n    1. In Polkadot.js Apps, connect to your local node, navigate to the **Developer** dropdown, and select the **RPC Calls** option.\n\n    2. Construct an `author_rotateKeys` RPC call and execute it:\n\n        1. Select the **author** endpoint.\n        2. Choose the **rotateKeys()** call.\n        3. Click the **Submit RPC Call** button.\n        4. Copy the hex-encoded public key from the response.\n\n        ![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/key-management/key-management-01.webp)\n\n=== \"Curl\"\n\n    Generate session keys by running the following command on your validator node:\n\n    ``` bash\n    curl -H \"Content-Type: application/json\" \\\n    -d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"author_rotateKeys\", \"params\":[]}' \\\n    http://localhost:9944\n    ```\n\n    This command will return a JSON object. The `result` key is the hex-encoded public part of the newly created session key. Save this for later use.\n    \n    ```json\n    {\"jsonrpc\":\"2.0\",\"result\":\"0xda3861a45e0197f3ca145c2c209f9126e5053fas503e459af4255cf8011d51010\",\"id\":1}\n    ```\n\n=== \"Subkey\"\n\n    To create a keypair for your node's session keys, use the `subkey generate` command. This generates a set of cryptographic keys that must be stored in your node's keystore directory.\n\n    When you run the command, it produces output similar to this example:\n\n    <div id=\"termynal\" data-termynal>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>subkey generate</span>\n      <pre>\n    Secret phrase:       twist buffalo mixture excess device drastic vague mammal fitness punch match hammer\n      Network ID:        substrate\n      Secret seed:       0x5faa9e5defe42b201388d5c2b8202d6625a344abc9aa52943a71f12cb90b88a9\n      Public key (hex):  0x28cc2fdb6e28835e2bbac9a16feb65c23d448c9314ef12fe083b61bab8fc2755\n      Account ID:        0x28cc2fdb6e28835e2bbac9a16feb65c23d448c9314ef12fe083b61bab8fc2755\n      Public key (SS58): 5CzCRpXzHYhuo6G3gYFR3cgV6X3qCNwVt51m8q14ZcChsSXQ\n      SS58 Address:      5CzCRpXzHYhuo6G3gYFR3cgV6X3qCNwVt51m8q14ZcChsSXQ\n      </pre>\n    </div>\n\n    To properly store these keys, create a file in your keystore directory with a specific naming convention. The filename must consist of the hex string `61757261` (which represents \"aura\" in hex) followed by the public key without its `0x` prefix.\n\n    Using the example above, you would create a file named:\n\n    ```\n    ./keystores/6175726128cc2fdb6e28835e2bbac9a16feb65c23d448c9314ef12fe083b61bab8fc2755\n    ```\n\n    And store only the secret phrase in the file:\n\n    ```\n    \"twist buffalo mixture excess device drastic vague mammal fitness punch match hammer\"\n    ```"}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 3, "depth": 3, "title": "Submit Transaction to Set Keys", "anchor": "submit-transaction-to-set-keys", "start_char": 4119, "end_char": 4754, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "### Submit Transaction to Set Keys\n\nNow that you have generated your session keys, you must submit them to the chain. Follow these steps:\n\n1. Go to the **Network > Staking > Accounts** section on Polkadot.js Apps.\n2. Select **Set Session Key** on the bonding account you generated earlier.\n3. Paste the hex-encoded session key string you generated (from either the UI or CLI) into the input field and submit the transaction.\n\n![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/key-management/key-management-02.webp)\n\nOnce the transaction is signed and submitted, your session keys will be registered on-chain."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 4, "depth": 3, "title": "Verify Session Key Setup", "anchor": "verify-session-key-setup", "start_char": 4754, "end_char": 5299, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Verify Session Key Setup\n\nTo verify that your session keys are properly set, you can use one of two RPC calls:\n\n- **`hasKey`**: Checks if the node has a specific key by public key and key type.\n- **`hasSessionKeys`**: Verifies if your node has the full session key string associated with the validator.\n\nFor example, you can [check session keys on the Polkadot.js Apps](https://polkadot.js.org/apps/#/rpc){target=\\_blank} interface or by running an RPC query against your node. Once this is done, your validator node is ready for its role."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 5, "depth": 2, "title": "Set the Node Key", "anchor": "set-the-node-key", "start_char": 5299, "end_char": 6941, "estimated_token_count": 408, "token_estimator": "heuristic-v1", "text": "## Set the Node Key\n\nValidators on Polkadot need a static network key (also known as the node key) to maintain a stable node identity. This key ensures that your validator can maintain a consistent peer ID, even across restarts, which is crucial for maintaining reliable network connections.\n\nStarting with Polkadot version 1.11, validators without a stable network key may encounter the following error on startup:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot --validator --name \"INSERT_NAME_FROM_TELEMETRY\"</span>\n  <span data-ty>Error:</span>\n  <span data-ty>0: Starting an authority without network key</span>\n  <span data-ty>This is not a safe operation because other authorities in the network may depend on your node having a stable identity.</span>\n  <span data-ty>Otherwise these other authorities may not being able to reach you.</span>\n  <span data-ty>If it is the first time running your node you could use one of the following methods:</span>\n  <span data-ty>1. [Preferred] Separately generate the key with: INSERT_NODE_BINARY key generate-node-key --base-path INSERT_YOUR_BASE_PATH</span>\n  <span data-ty>2. [Preferred] Separately generate the key with: INSERT_NODE_BINARY key generate-node-key --file INSERT_YOUR_PATH_TO_NODE_KEY</span>\n  <span data-ty>3. [Preferred] Separately generate the key with: INSERT_NODE_BINARY key generate-node-key --default-base-path</span>\n  <span data-ty>4. [Unsafe] Pass --unsafe-force-node-key-generation and make sure you remove it for subsequent node restarts</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 6, "depth": 3, "title": "Generate the Node Key", "anchor": "generate-the-node-key", "start_char": 6941, "end_char": 7602, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### Generate the Node Key\n\nUse one of the following methods to generate your node key:\n\n=== \"Save to file\"\n\n    The recommended solution is to generate a node key and save it to a file using the following command:\n\n    ``` bash\n    polkadot key generate-node-key --file INSERT_PATH_TO_NODE_KEY\n    ```\n    \n=== \"Use default path\"\n\n    You can also generate the node key with the following command, which will automatically save the key to the base path of your node:\n\n    ``` bash\n    polkadot key generate-node-key --default-base-path\n    ```\n\nSave the file path for reference. You will need it in the next step to configure your node with a static identity."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-key-management", "page_title": "Validator Key Management", "index": 7, "depth": 3, "title": "Set Node Key", "anchor": "set-node-key", "start_char": 7602, "end_char": 8224, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Set Node Key\n\nAfter generating the node key, configure your node to use it by specifying the path to the key file when launching your node. Add the following flag to your validator node's startup command:\n\n``` bash\npolkadot --node-key-file INSERT_PATH_TO_NODE_KEY\n```\n\nFollowing these steps ensures that your node retains its identity, making it discoverable by peers without the risk of conflicting identities across sessions. For further technical background, see Polkadot SDK [Pull Request #3852](https://github.com/paritytech/polkadot-sdk/pull/3852){target=\\_blank} for the rationale behind requiring static keys."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 642, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nSetting up a Polkadot validator node is essential for securing the network and earning staking rewards. This guide walks you through the technical steps to set up a validator, from installing the necessary software to managing keys and synchronizing your node with the chain.\n\nRunning a validator requires a commitment to maintaining a stable, secure infrastructure. Validators are responsible for their own stakes and those of nominators who trust them with their tokens. Proper setup and ongoing management are critical to ensuring smooth operation and avoiding potential penalties such as slashing."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 642, "end_char": 1738, "estimated_token_count": 267, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo get the most from this guide, ensure you've done the following before going forward:\n\n- Read [Validator Requirements](/node-infrastructure/run-a-validator/requirements/){target=\\_blank} and understand the recommended minimum skill level and hardware needs.\n- Read [General Management](/node-infrastructure/run-a-validator/operational-tasks/general-management/){target=\\_blank}, [Upgrade Your Node](/node-infrastructure/run-a-validator/operational-tasks/upgrade-your-node/){target=\\_blank}, and [Pause Validating](/node-infrastructure/run-a-validator/operational-tasks/pause-validating/){target=\\_blank} and understand the tasks required to keep your validator operational.\n- Read [Rewards Payout](/node-infrastructure/run-a-validator/staking-mechanics/rewards/){target=\\_blank} and understand how validator rewards are determined and paid out.\n- Read [Offenses and Slashes](/node-infrastructure/run-a-validator/staking-mechanics/offenses-and-slashes/){target=\\_blank} and understand how validator performance and security can affect tokens staked by you or your nominators."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 2, "depth": 2, "title": "Initial Setup", "anchor": "initial-setup", "start_char": 1738, "end_char": 2294, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Initial Setup\n\nBefore running your validator, you must configure your server environment to meet the operational and security standards required for validating.\n\nYou must use a Linux-based operating system with Kernel 5.16 or later. Configuration includes setting up time synchronization, ensuring critical security features are active, and installing the necessary binaries. Proper setup at this stage is essential to prevent issues like block production errors or being penalized for downtime. Below are the essential steps to get your system ready."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 3, "depth": 3, "title": "Install Network Time Protocol Client", "anchor": "install-network-time-protocol-client", "start_char": 2294, "end_char": 3406, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "### Install Network Time Protocol Client\n\nAccurate timekeeping is critical to ensure your validator is synchronized with the network. Validators need local clocks in sync with the blockchain to avoid missing block authorship opportunities. Using [Network Time Protocol (NTP)](https://en.wikipedia.org/wiki/Network_Time_Protocol){target=\\_blank} is the standard solution to keep your system's clock accurate.\n\nIf you are using Ubuntu version 18.04 or newer, the NTP Client should be installed by default. You can check whether you have the NTP client by running:\n\n```sh\ntimedatectl\n```\n\nIf NTP is running, you should see a message like the following:\n\n``` sh\nSystem clock synchronized: yes\n```\n\nIf NTP is not installed or running, you can install it using:\n\n```sh\nsudo apt-get install ntp\n```\n\nAfter installation, NTP will automatically start. To check its status:\n\n```sh\nsudo ntpq -p\n```\n\nThis command will return a message with the status of the NTP synchronization. Skipping this step could result in your validator node missing blocks due to minor clock drift, potentially affecting its network performance."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 4, "depth": 3, "title": "Verify Landlock is Activated", "anchor": "verify-landlock-is-activated", "start_char": 3406, "end_char": 5003, "estimated_token_count": 319, "token_estimator": "heuristic-v1", "text": "### Verify Landlock is Activated\n\n[Landlock](https://docs.kernel.org/userspace-api/landlock.html){target=\\_blank} is an important security feature integrated into Linux kernels starting with version 5.13. It allows processes, even those without special privileges, to limit their access to the system to reduce the machine's attack surface. This feature is crucial for validators, as it helps ensure the security and stability of the node by preventing unauthorized access or malicious behavior.\n\nTo use Landlock, ensure you use the reference kernel or newer versions. Most Linux distributions should already have Landlock activated. You can check if Landlock is activated on your machine by running the following command as root:\n\n```sh\ndmesg | grep landlock || journalctl -kg landlock\n```\n\nIf Landlock is not activated, your system logs won't show any related output. In this case, you will need to activate it manually or ensure that your Linux distribution supports it. Most modern distributions with the required kernel version should have Landlock activated by default. However, if your system lacks support, you may need to build the kernel with Landlock activated. For more information on doing so, refer to the [official kernel documentation](https://docs.kernel.org/userspace-api/landlock.html#kernel-support){target=\\_blank}.\n\nImplementing Landlock ensures your node operates in a restricted, self-imposed sandbox, limiting potential damage from security breaches or bugs. While not a mandatory requirement, enabling this feature greatly improves the security of your validator setup."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 5, "depth": 2, "title": "Install the Polkadot Binaries", "anchor": "install-the-polkadot-binaries", "start_char": 5003, "end_char": 5429, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Install the Polkadot Binaries\n\nYou must install the Polkadot binaries required to run your validator node. These binaries include the main `polkadot`, `polkadot-prepare-worker`, and `polkadot-execute-worker` binaries. All three are needed to run a fully functioning validator node.\n\nDepending on your preference and operating system setup, there are multiple methods to install these binaries. Below are the main options:"}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 6, "depth": 3, "title": "Install from Official Releases", "anchor": "install-from-official-releases", "start_char": 5429, "end_char": 8219, "estimated_token_count": 622, "token_estimator": "heuristic-v1", "text": "### Install from Official Releases\n\nThe preferred, most straightforward method to install the required binaries is downloading the latest versions from the official releases. You can visit the [Github Releases](https://github.com/paritytech/polkadot-sdk/releases){target=\\_blank} page for the most current versions of the `polkadot`, `polkadot-prepare-worker`, and `polkadot-execute-worker` binaries.\n\nYou can also download the binaries by using the following direct links:\n\n=== \"`polkadot`\"\n\n    ``` bash\n    # Download the binary\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506-2/polkadot\n\n    # Verify signature\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506-2/polkadot.asc\n    \n    gpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\n\n    gpg --verify polkadot.asc\n    ```\n\n=== \"`polkadot-prepare-worker`\"\n\n    ``` bash\n    # Download the binary\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506-2/polkadot-prepare-worker\n\n    # Verify signature\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506-2/polkadot-prepare-worker.asc\n\n    gpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\n\n    gpg --verify polkadot-prepare-worker.asc\n    ```\n\n=== \"`polkadot-execute-worker`\"\n\n    ``` bash\n    # Download the binary\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506-2/polkadot-execute-worker\n\n    # Verify signature\n    curl -LO https://github.com/paritytech/polkadot-sdk/releases/download/polkadot-stable2506-2/polkadot-execute-worker.asc\n\n    gpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\n\n    gpg --verify polkadot-execute-worker.asc\n    ```\n\n\nSignature verification cryptographically ensures the downloaded binaries are authentic and have not been tampered with by using GPG signing keys. Polkadot releases use two different signing keys:\n\n- ParityReleases (release-team@parity.io) with key [`90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE`](https://keyserver.ubuntu.com/pks/lookup?search=90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE&fingerprint=on&op=index){target=\\_blank} for current and new releases.\n- Parity Security Team (security@parity.io) with key [`9D4B2B6EB8F97156D19669A9FF0812D491B96798`](https://keyserver.ubuntu.com/pks/lookup?search=9D4B2B6EB8F97156D19669A9FF0812D491B96798&fingerprint=on&op=index){target=\\_blank} for old releases.\n\n    !!!warning\n        When verifying a signature, a \"Good signature\" message indicates successful verification, while any other output signals a potential security risk."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 7, "depth": 3, "title": "Install with Package Managers", "anchor": "install-with-package-managers", "start_char": 8219, "end_char": 9286, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "### Install with Package Managers\n\nUsers running Debian-based distributions like Ubuntu can install the binaries using the [APT](https://wiki.debian.org/Apt){target=\\_blank} package manager.\n\nExecute the following commands as root to add the official repository and install the binaries:\n\n```bash\n# Import the release-team@parity.io GPG key\ngpg --keyserver hkps://keyserver.ubuntu.com --receive-keys 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE\ngpg --export 90BD75EBBB8E95CB3DA6078F94A4029AB4B35DAE > /usr/share/keyrings/parity.gpg\n\n# Add the Parity repository and update the package index\necho 'deb [signed-by=/usr/share/keyrings/parity.gpg] https://releases.parity.io/deb release main' > /etc/apt/sources.list.d/parity.list\napt update\n\n# Install the `parity-keyring` package - This will ensure the GPG key\n# used by APT remains up-to-date\napt install parity-keyring\n\n# Install polkadot\napt install polkadot\n```\n\nOnce installation completes, verify the binaries are correctly installed by following the steps in the [verify installation](#verify-installation) section."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 8, "depth": 3, "title": "Install with Ansible", "anchor": "install-with-ansible", "start_char": 9286, "end_char": 9643, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "### Install with Ansible\n\nYou can also manage Polkadot installations using Ansible. This approach can be beneficial for users managing multiple validator nodes or requiring automated deployment. The [Parity chain operations Ansible collection](https://github.com/paritytech/ansible-galaxy/){target=\\_blank} provides a Substrate node role for this purpose."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 9, "depth": 3, "title": "Install with Docker", "anchor": "install-with-docker", "start_char": 9643, "end_char": 9926, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "### Install with Docker\n\nIf you prefer using Docker or an OCI-compatible container runtime, the official Polkadot Docker image can be pulled directly from Docker Hub.\n\nTo pull the latest stable image, run the following command:\n\n```bash\ndocker pull parity/polkadot:stable2506-2\n```"}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 10, "depth": 3, "title": "Build from Sources", "anchor": "build-from-sources", "start_char": 9926, "end_char": 10159, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Build from Sources\n\nYou may build the binaries from source by following the instructions on the [Polkadot SDK repository](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/polkadot#building){target=\\_blank}."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-set-up-validator", "page_title": "Set Up a Validator", "index": 11, "depth": 2, "title": "Verify Installation", "anchor": "verify-installation", "start_char": 10159, "end_char": 11915, "estimated_token_count": 430, "token_estimator": "heuristic-v1", "text": "## Verify Installation\n\nOnce the Polkadot binaries are installed, it's essential to verify that everything is set up correctly and that all the necessary components are in place. Follow these steps to ensure the binaries are installed and functioning as expected.\n\n1. **Check the versions**: Run the following commands to verify the versions of the installed binaries.\n\n    ```bash\n    polkadot --version\n    polkadot-execute-worker --version\n    polkadot-prepare-worker --version\n    ```\n\n    The output should show the version numbers for each of the binaries. Ensure that the versions match and are consistent, similar to the following example (the specific version may vary):\n\n    <div id=\"termynal\" data-termynal>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot --version polkadot-execute-worker --version polkadot-prepare-worker --version</span>\n      <span data-ty>1.16.1-36264cb36db</span>\n      <span data-ty>1.16.1-36264cb36db</span>\n      <span data-ty>1.16.1-36264cb36db</span>\n      <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n    </div>\n\n    If the versions do not match or if there is an error, double-check that all the binaries were correctly installed and are accessible within your `$PATH`.\n\n2. **Ensure all binaries are in the same directory**: All the binaries must be in the same directory for the Polkadot validator node to function properly. If the binaries are not in the same location, move them to a unified directory and ensure this directory is added to your system's `$PATH`.\n\n    To verify the `$PATH`, run the following command:\n\n    ```bash\n    echo $PATH\n    ```\n\n    If necessary, you can move the binaries to a shared location, such as `/usr/local/bin/`, and add it to your `$PATH`."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 448, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter configuring your node keys as shown in the [Key Management](/node-infrastructure/run-a-validator/onboarding-and-offboarding/key-management/){target=\\_blank} section and ensuring your system is set up, you're ready to begin the validator setup process. This guide will walk you through choosing a network, synchronizing your node with the blockchain, bonding your DOT tokens, and starting your validator."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 1, "depth": 2, "title": "Choose a Network", "anchor": "choose-a-network", "start_char": 448, "end_char": 1437, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Choose a Network\n\nRunning your validator on a test network like Westend or Kusama is a smart way to familiarize yourself with the process and identify any setup issues in a lower-stakes environment before joining the Polkadot MainNet.\n\n- **Westend**: Polkadot's primary TestNet is open to anyone for testing purposes. Validator slots are intentionally limited to keep the network stable for the Polkadot release process, so it may not support as many validators at any given time.\n- **Kusama**: Often called Polkadot's \"canary network,\" Kusama has real economic value but operates with a faster and more experimental approach. Running a validator here provides an experience closer to MainNet with the benefit of more frequent validation opportunities with an era time of 6 hours vs 24 hours for Polkadot.\n- **Polkadot**: The main network, where validators secure the Polkadot relay chain. It has a slower era time of 24 hours and requires a higher minimum bond amount to participate."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 2, "depth": 2, "title": "Synchronize Chain Data", "anchor": "synchronize-chain-data", "start_char": 1437, "end_char": 4715, "estimated_token_count": 857, "token_estimator": "heuristic-v1", "text": "## Synchronize Chain Data\n\nThe next step is to sync your node with the chosen blockchain network. Synchronization is necessary to download and validate the blockchain data, ensuring your node is ready to participate as a validator. Follow these steps to sync your node:\n\n1. **Start syncing**: You can run a full or warp sync.\n\n    === \"Full sync\"\n\n        Polkadot defaults to using a full sync, which downloads and validates the entire blockchain history from the genesis block. Start the syncing process by running the following command:\n\n        ```sh\n        polkadot\n        ```\n\n        This command starts your Polkadot node in non-validator mode, allowing you to synchronize the chain data.\n\n    === \"Warp sync\"\n\n        You can opt to use warp sync which initially downloads only GRANDPA finality proofs and the latest finalized block's state. Use the following command to start a warp sync:\n\n        ``` bash\n        polkadot --sync warp\n        ```\n\n        Warp sync ensures that your node quickly updates to the latest finalized state. The historical blocks are downloaded in the background as the node continues to operate.\n\n    If you're planning to run a validator on a TestNet, you can specify the chain using the `--chain` flag. For example, the following will run a validator on Kusama:\n\n    ```sh\n    polkadot --chain=kusama\n    ```\n\n2. **Monitor sync progress**: Once the sync starts, you will see a stream of logs providing information about the node's status and progress. Here's an example of what the output might look like:\n\n    <div id=\"termynal\" data-termynal>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot</span>\n      <span data-ty>2021-06-17 03:07:07 Parity Polkadot</span>\n      <span data-ty>2021-06-17 03:07:07 âœŒï¸ version 0.9.5-95f6aa201-x86_64-linux-gnu</span>\n      <span data-ty>2021-06-17 03:07:07 â¤ï¸ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2021</span>\n      <span data-ty>2021-06-17 03:07:07 ðŸ“‹ Chain specification: Polkadot</span>\n      <span data-ty>2021-06-17 03:07:07 ðŸ· Node name: boiling-pet-7554</span>\n      <span data-ty>2021-06-17 03:07:07 ðŸ‘¤ Role: FULL</span>\n      <span data-ty>2021-06-17 03:07:07 ðŸ’¾ Database: RocksDb at /root/.local/share/polkadot/chains/polkadot/db</span>\n      <span data-ty>2021-06-17 03:07:07 â›“ Native runtime: polkadot-9050 (parity-polkadot-0.tx7.au0)</span>\n      <span data-ty>2021-06-17 03:07:10 ðŸ· Local node identity is: 12D3KooWLtXFWf1oGrnxMGmPKPW54xWCHAXHbFh4Eap6KXmxoi9u</span>\n      <span data-ty>2021-06-17 03:07:10 ðŸ“¦ Highest known block at #17914</span>\n      <span data-ty>2021-06-17 03:07:10 ã€½ï¸ Prometheus server started at 127.0.0.1:9615</span>\n      <span data-ty>2021-06-17 03:07:10 Listening for new connections on 127.0.0.1:9944</span>\n      <span data-ty>...</span>\n    </div>\n\n    The output logs provide information such as the current block number, node name, and network connections. Monitor the sync progress and any errors that might occur during the process. Look for information about the latest processed block and compare it with the current highest block using tools like [Telemetry](https://telemetry.polkadot.io/#list/Polkadot%20CC1){target=\\_blank} or [Polkadot.js Apps Explorer](https://polkadot.js.org/apps/#/explorer){target=\\_blank}."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 3, "depth": 3, "title": "Database Snapshot Services", "anchor": "database-snapshot-services", "start_char": 4715, "end_char": 6619, "estimated_token_count": 607, "token_estimator": "heuristic-v1", "text": "### Database Snapshot Services\n\nIf you'd like to speed up the process further, you can use a database snapshot. Snapshots are compressed backups of the blockchain's database directory and can significantly reduce the time required to sync a new node. Here are a few public snapshot providers:\n\n- [Polkachu](https://polkachu.com/substrate_snapshots){target=\\_blank}\n- [Polkashots](https://polkashots.io/){target=\\_blank}\n- [ITRocket](https://itrocket.net/services/mainnet/polkadot/#snapshot){target=\\_blank}\n\n!!!warning\n    Although snapshots are convenient, syncing from scratch is recommended for security purposes. If snapshots become corrupted and most nodes rely on them, the network could inadvertently run on a non-canonical chain.\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot</span>\n  <span data-ty>2021-06-17 03:07:07 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), â¬‡ 2.9kiB/s â¬† 3.7kiB/s</span>\n  <span data-ty>2021-06-17 03:07:12 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), â¬‡ 1.7kiB/s â¬† 2.0kiB/s</span>\n  <span data-ty>2021-06-17 03:07:17 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), â¬‡ 0.9kiB/s â¬† 1.2kiB/s</span>\n  <span data-ty>2021-06-17 03:07:19 Libp2p => Random Kademlia query has yielded empty results</span>\n  <span data-ty>2021-06-17 03:08:00 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), â¬‡ 1.6kiB/s â¬† 1.9kiB/s</span>\n  <span data-ty>2021-06-17 03:08:05 Idle (0 peers), best: #0 (0x3fd7...5baf), finalized #0 (0x3fd7...5baf), â¬‡ 0.6kiB/s â¬† 0.9kiB/s</span>\n  <span data-ty>...</span>\n</div>\n\nIf you see terminal output similar to the preceding, and you are unable to synchronize the chain due to having zero peers, make sure you have libp2p port `30333` activated. It will take some time to discover other peers over the network."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 4, "depth": 2, "title": "Bond DOT", "anchor": "bond-dot", "start_char": 6619, "end_char": 7186, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Bond DOT\n\nOnce your validator node is synced, the next step is bonding DOT. A bonded account, or stash, holds your staked tokens (DOT) that back your validator node. Bonding your DOT means locking it for a period, during which it cannot be transferred or spent but is used to secure your validator's role in the network. Visit the [Minimum Bond Requirement](/node-infrastructure/run-a-validator/requirements/#minimum-bond-requirement) section for details on how much DOT is required.\n\nThe following sections will guide you through bonding DOT for your validator."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 5, "depth": 3, "title": "Bonding DOT on Polkadot.js Apps", "anchor": "bonding-dot-on-polkadotjs-apps", "start_char": 7186, "end_char": 8787, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "### Bonding DOT on Polkadot.js Apps\n\nOnce you're ready to bond your DOT, head over to the [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} staking page by clicking the **Network** dropdown at the top of the page and selecting [**Staking**](https://polkadot.js.org/apps/#/staking/actions){target=\\_blank}.\n\nTo get started with the bond submission, click on the **Accounts** tab, then the **+ Stash** button, and then enter the following information:\n\n1. **Stash account**: Select your stash account (which is the account with the DOT/KSM balance).\n2. **Value bonded**: Enter how much DOT from the stash account you want to bond/stake. You are not required to bond all of the DOT in that account and you may bond more DOT at a later time. Be aware, withdrawing any bonded amount requires waiting for the unbonding period. The unbonding period is seven days for Kusama and 28 days for Polkadot.\n3. **Payment destination**: Add the recipient account for validator rewards. If you'd like to redirect payments to an account that is not the stash account, you can do it by entering the address here. Note that it is extremely unsafe to set an exchange address as the recipient of the staking rewards.\n\nOnce everything is filled in properly, select **Bond** and sign the transaction with your stash account. If successful, you should see an `ExtrinsicSuccess` message.\n\nYour bonded account will be available under **Stashes**. After refreshing the screen, you should now see a card with all your accounts. The bonded amount on the right corresponds to the funds bonded by the stash account."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 6, "depth": 2, "title": "Validate", "anchor": "validate", "start_char": 8787, "end_char": 9015, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## Validate\n\nOnce your validator node is fully synced and ready, the next step is to ensure it's visible on the network and performing as expected. Below are steps for monitoring and managing your node on the Polkadot network."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 7, "depth": 3, "title": "Verify Sync via Telemetry", "anchor": "verify-sync-via-telemetry", "start_char": 9015, "end_char": 9742, "estimated_token_count": 153, "token_estimator": "heuristic-v1", "text": "### Verify Sync via Telemetry\n\nTo confirm that your validator is live and synchronized with the Polkadot network, visit the [Telemetry](https://telemetry.polkadot.io/#list/Polkadot%20CC1){target=\\_blank} page. Telemetry provides real-time information on node performance and can help you check if your validator is connected properly. Search for your node by name. You can search all nodes currently active on the network, which is why you should use a unique name for easy recognition. Now, confirm that your node is fully synced by comparing the block height of your node with the network's latest block. Nodes that are fully synced will appear white in the list, while nodes that are not yet fully synced will appear gray."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 8, "depth": 3, "title": "Activate using Polkadot.js Apps", "anchor": "activate-using-polkadotjs-apps", "start_char": 9742, "end_char": 11056, "estimated_token_count": 352, "token_estimator": "heuristic-v1", "text": "### Activate using Polkadot.js Apps\n\nFollow these steps to use Polkadot.js Apps to activate your validator:\n\n1. In Polkadot.js Apps, navigate to **Network** and select **Staking**:\n\n    ![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/start-validating/start-validating-01.webp)\n\n2. Open the **Accounts** tab and click on **+ Validator**:\n\n    ![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/start-validating/start-validating-02.webp)\n\n3. Set a bond amount in the **value bonded** field and then click **next**:\n\n    ![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/start-validating/start-validating-03.webp)\n\n4. Paste the hex output from `author_rotateKeys`, set the commission, allow or block new nominations, then click **Bond & Validate** to link your validator with its session keys.\n\n    ![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/start-validating/start-validating-04.webp)\n\n    You can also set the **commission** and **blocked** nominations option via `staking.validate` extrinsic. By default, the blocked option is set to FALSE (i.e., the validator accepts nominations).\n\n    ![](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/start-validating/start-validating-05.webp)"}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 9, "depth": 3, "title": "Monitor Validation Status and Slots", "anchor": "monitor-validation-status-and-slots", "start_char": 11056, "end_char": 12009, "estimated_token_count": 219, "token_estimator": "heuristic-v1", "text": "### Monitor Validation Status and Slots\n\nOn the [**Staking**](https://polkadot.js.org/apps/#/staking){target=\\_blank} tab in Polkadot.js Apps, you can see your validator's status, the number of available validator slots, and the nodes that have signaled their intent to validate. Your node may initially appear in the waiting queue, especially if the validator slots are full. The following is an example view of the **Staking** tab:\n\n![staking queue](/images/node-infrastructure/run-a-validator/onboarding-and-offboarding/start-validating/start-validating-06.webp)\n\nThe validator set refreshes each era. If there's an available slot in the next era, your node may be selected to move from the waiting queue to the active validator set, allowing it to start validating blocks. If your validator is not selected, it remains in the waiting queue. Increasing your stake or gaining more nominators may improve your chance of being selected in future eras."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 10, "depth": 2, "title": "Run a Validator Using Systemd", "anchor": "run-a-validator-using-systemd", "start_char": 12009, "end_char": 13034, "estimated_token_count": 220, "token_estimator": "heuristic-v1", "text": "## Run a Validator Using Systemd\n\nRunning your Polkadot validator as a [systemd](https://en.wikipedia.org/wiki/Systemd){target=\\_blank} service is an effective way to ensure its high uptime and reliability. Using systemd allows your validator to automatically restart after server reboots or unexpected crashes, significantly reducing the risk of slashing due to downtime.\n\nThis following sections will walk you through creating and managing a systemd service for your validator, allowing you to seamlessly monitor and control it as part of your Linux system. \n\nEnsure the following requirements are met before proceeding with the systemd setup:\n\n- Confirm your system meets the [requirements](/node-infrastructure/run-a-validator/requirements/){target=\\_blank} for running a validator.\n- Ensure you meet the [minimum bond requirements](https://wiki.polkadot.com/general/chain-state-values/#minimum-validator-bond){target=\\_blank} for validating.\n- Verify the Polkadot binary is [installed](#install-the-polkadot-binaries)."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 11, "depth": 3, "title": "Create the Systemd Service File", "anchor": "create-the-systemd-service-file", "start_char": 13034, "end_char": 14773, "estimated_token_count": 338, "token_estimator": "heuristic-v1", "text": "### Create the Systemd Service File\n\nFirst create a new unit file called `polkadot-validator.service` in `/etc/systemd/system/`:\n\n```bash\ntouch /etc/systemd/system/polkadot-validator.service\n```\n\nIn this unit file, you will write the commands that you want to run on server boot/restart:\n\n```systemd title=\"/etc/systemd/system/polkadot-validator.service\"\n[Unit]\nDescription=Polkadot Node\nAfter=network.target\nDocumentation=https://github.com/paritytech/polkadot-sdk\n\n[Service]\nEnvironmentFile=-/etc/default/polkadot\nExecStart=/usr/bin/polkadot $POLKADOT_CLI_ARGS\nUser=polkadot\nGroup=polkadot\nRestart=always\nRestartSec=120\nCapabilityBoundingSet=\nLockPersonality=true\nNoNewPrivileges=true\nPrivateDevices=true\nPrivateMounts=true\nPrivateTmp=true\nPrivateUsers=true\nProtectClock=true\nProtectControlGroups=true\nProtectHostname=true\nProtectKernelModules=true\nProtectKernelTunables=true\nProtectSystem=strict\nRemoveIPC=true\nRestrictAddressFamilies=AF_INET AF_INET6 AF_NETLINK AF_UNIX\nRestrictNamespaces=false\nRestrictSUIDSGID=true\nSystemCallArchitectures=native\nSystemCallFilter=@system-service\nSystemCallFilter=landlock_add_rule landlock_create_ruleset landlock_restrict_self seccomp mount umount2\nSystemCallFilter=~@clock @module @reboot @swap @privileged\nSystemCallFilter=pivot_root\nUMask=0027\n\n[Install]\nWantedBy=multi-user.target\n```\n\n!!! warning \"Restart delay and equivocation risk\"\n    It is recommended that a node's restart be delayed with `RestartSec` in the case of a crash. It's possible that when a node crashes, consensus votes in GRANDPA aren't persisted to disk. In this case, there is potential to equivocate when immediately restarting. Delaying the restart will allow the network to progress past potentially conflicting votes."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-start-validating", "page_title": "Start Validating", "index": 12, "depth": 3, "title": "Run the Service", "anchor": "run-the-service", "start_char": 14773, "end_char": 15748, "estimated_token_count": 243, "token_estimator": "heuristic-v1", "text": "### Run the Service\n\nActivate the systemd service to start on system boot by running:\n\n```bash\nsystemctl enable polkadot-validator.service\n```\n\nTo start the service manually, use:\n\n```bash\nsystemctl start polkadot-validator.service\n```\n\nCheck the service's status to confirm it is running:\n\n```bash\nsystemctl status polkadot-validator.service\n```\n\nTo view the logs in real-time, use [journalctl](https://www.freedesktop.org/software/systemd/man/latest/journalctl.html){target=\\_blank} like so:\n\n```bash\njournalctl -f -u polkadot-validator\n```\n\nWith these steps, you can effectively manage and monitor your validator as a systemd service.\n\nOnce your validator is active, it's officially part of Polkadot's security infrastructure. For questions or further support, you can reach out to the [Polkadot Validator chat](https://matrix.to/#/!NZrbtteFeqYKCUGQtr:matrix.parity.io?via=matrix.parity.io&via=matrix.org&via=web3.foundation){target=\\_blank} for tips and troubleshooting."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-stop-validating", "page_title": "Stop Validating", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 498, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIf you're ready to stop validating on Polkadot, there are essential steps to ensure a smooth transition while protecting your funds and account integrity. Whether you're taking a break for maintenance or unbonding entirely, you'll need to chill your validator, purge session keys, and unbond your tokens. This guide explains how to use Polkadot's tools and extrinsics to safely withdraw from validation activities, safeguarding your account's future usability."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-stop-validating", "page_title": "Stop Validating", "index": 1, "depth": 2, "title": "Pause Versus Stop", "anchor": "pause-versus-stop", "start_char": 498, "end_char": 920, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Pause Versus Stop\n\nIf you wish to remain a validator or nominator (for example, stopping for planned downtime or server maintenance), submitting the `chill` extrinsic in the `staking` pallet should suffice. Additional steps are only needed to unbond funds or reap an account.\n\nThe following are steps to ensure a smooth stop to validation:\n\n- Chill the validator.\n- Purge validator session keys.\n- Unbond your tokens."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-stop-validating", "page_title": "Stop Validating", "index": 2, "depth": 2, "title": "Chill Validator", "anchor": "chill-validator", "start_char": 920, "end_char": 1500, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Chill Validator\n\nWhen stepping back from validating, the first step is to chill your validator status. This action stops your validator from being considered for the next era without fully unbonding your tokens, which can be useful for temporary pauses like maintenance or planned downtime.\n\nUse the `staking.chill` extrinsic to initiate this. For more guidance on chilling your node, refer to the [Pause Validating](/node-infrastructure/run-a-validator/operational-tasks/pause-validating/){target=\\_blank} guide. You may also claim any pending staking rewards at this point."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-stop-validating", "page_title": "Stop Validating", "index": 3, "depth": 2, "title": "Purge Validator Session Keys", "anchor": "purge-validator-session-keys", "start_char": 1500, "end_char": 2531, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Purge Validator Session Keys\n\nPurging validator session keys is a critical step in removing the association between your validator account and its session keys, which ensures that your account is fully disassociated from validator activities. The `session.purgeKeys` extrinsic removes the reference to your session keys from the stash or staking proxy account that originally set them.\n\nHere are a couple of important things to know about purging keys:\n\n- **Account used to purge keys**: Always use the same account to purge keys you originally used to set them, usually your stash or staking proxy account. Using a different account may leave an unremovable reference to the session keys on the original account, preventing its reaping.\n- **Account reaping issue**: Failing to purge keys will prevent you from reaping (fully deleting) your stash account. If you attempt to transfer tokens without purging, you'll need to rebond, purge the session keys, unbond again, and wait through the unbonding period before any transfer."}
{"page_id": "node-infrastructure-run-a-validator-onboarding-and-offboarding-stop-validating", "page_title": "Stop Validating", "index": 4, "depth": 2, "title": "Unbond Your Tokens", "anchor": "unbond-your-tokens", "start_char": 2531, "end_char": 3229, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Unbond Your Tokens\n\nAfter chilling your node and purging session keys, the final step is to unbond your staked tokens. This action removes them from staking and begins the unbonding period (usually 28 days for Polkadot and seven days for Kusama), after which the tokens will be transferable.\n\nTo unbond tokens, go to **Network > Staking > Account Actions** on Polkadot.js Apps. Select your stash account, click on the dropdown menu, and choose **Unbond Funds**. Alternatively, you can use the `staking.unbond` extrinsic if you handle this via a staking proxy account.\n\nOnce the unbonding period is complete, your tokens will be available for use in transactions or transfers outside of staking."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 759, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nValidator performance is pivotal in maintaining the security and stability of the Polkadot network. As a validator, optimizing your setup ensures efficient transaction processing, minimizes latency, and maintains system reliability during high-demand periods. Proper configuration and proactive monitoring also help mitigate risks like slashing and service interruptions.\n\nThis guide covers essential practices for managing a validator, including performance tuning techniques, security hardening, and tools for real-time monitoring. Whether you're fine-tuning CPU settings, configuring NUMA balancing, or setting up a robust alert system, these steps will help you build a resilient and efficient validator operation."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 1, "depth": 2, "title": "Configuration Optimization", "anchor": "configuration-optimization", "start_char": 759, "end_char": 987, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Configuration Optimization\n\nFor those seeking to optimize their validator's performance, the following configurations can improve responsiveness, reduce latency, and ensure consistent performance during high-demand periods."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 2, "depth": 3, "title": "Deactivate Simultaneous Multithreading", "anchor": "deactivate-simultaneous-multithreading", "start_char": 987, "end_char": 2478, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "### Deactivate Simultaneous Multithreading\n\nPolkadot validators operate primarily in single-threaded mode for critical tasks, so optimizing single-core CPU performance can reduce latency and improve stability. Deactivating simultaneous multithreading (SMT) can prevent virtual cores from affecting performance. SMT is called Hyper-Threading on Intel and 2-way SMT on AMD Zen.\n\nTake the following steps to deactivate every other (vCPU) core:\n\n1. Loop though all the CPU cores and deactivate the virtual cores associated with them:\n\n    ```bash\n    for cpunum in $(cat /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | \\\n    cut -s -d, -f2- | tr ',' '\\n' | sort -un)\n    do\n    echo 0 > /sys/devices/system/cpu/cpu$cpunum/online\n    done\n    ```\n\n2. To permanently save the changes, add `nosmt=force` to the `GRUB_CMDLINE_LINUX_DEFAULT` variable in `/etc/default/grub`:\n\n    ```bash\n    sudo nano /etc/default/grub\n    # Add to GRUB_CMDLINE_LINUX_DEFAULT\n    ```\n\n    ```config title=\"/etc/default/grub\"\n    GRUB_DEFAULT = 0;\n    GRUB_HIDDEN_TIMEOUT = 0;\n    GRUB_HIDDEN_TIMEOUT_QUIET = true;\n    GRUB_TIMEOUT = 10;\n    GRUB_DISTRIBUTOR = `lsb_release -i -s 2> /dev/null || echo Debian`;\n    GRUB_CMDLINE_LINUX_DEFAULT = 'nosmt=force';\n    GRUB_CMDLINE_LINUX = '';\n    ```\n\n3. Update GRUB to apply changes:\n\n    ```bash\n    sudo update-grub\n    ```\n\n4. After the reboot, you should see that half of the cores are offline. To confirm, run:\n\n    ```bash\n    lscpu --extended\n    ```"}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 3, "depth": 3, "title": "Deactivate Automatic NUMA Balancing", "anchor": "deactivate-automatic-numa-balancing", "start_char": 2478, "end_char": 3554, "estimated_token_count": 220, "token_estimator": "heuristic-v1", "text": "### Deactivate Automatic NUMA Balancing\n\nDeactivating NUMA (Non-Uniform Memory Access) balancing for multi-CPU setups helps keep processes on the same CPU node, minimizing latency.\n\nFollow these stpes:\n\n1. Deactivate NUMA balancing in runtime:\n\n    ```bash\n    sysctl kernel.numa_balancing=0\n    ```\n\n2. Deactivate NUMA balancing permanently by adding `numa_balancing=disable` to the GRUB settings:\n\n    ```bash\n    sudo nano /etc/default/grub\n    # Add to GRUB_CMDLINE_LINUX_DEFAULT\n    ```\n\n    ```config title=\"/etc/default/grub\"\n    GRUB_DEFAULT = 0;\n    GRUB_HIDDEN_TIMEOUT = 0;\n    GRUB_HIDDEN_TIMEOUT_QUIET = true;\n    GRUB_TIMEOUT = 10;\n    GRUB_DISTRIBUTOR = `lsb_release -i -s 2> /dev/null || echo Debian`;\n    GRUB_CMDLINE_LINUX_DEFAULT = 'numa_balancing=disable';\n    GRUB_CMDLINE_LINUX = '';\n    ```\n\n3. Update GRUB to apply changes:\n\n    ```bash\n    sudo update-grub\n    ```\n\n4. Confirm the deactivation:\n\n    ```bash\n    sysctl -a | grep 'kernel.numa_balancing'\n    ```\n\nIf you successfully deactivated NUMA balancing, the preceding command should return `0`."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 4, "depth": 3, "title": "Spectre and Meltdown Mitigations", "anchor": "spectre-and-meltdown-mitigations", "start_char": 3554, "end_char": 5210, "estimated_token_count": 319, "token_estimator": "heuristic-v1", "text": "### Spectre and Meltdown Mitigations\n\n[Spectre](https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)){target=\\_blank} and [Meltdown](https://en.wikipedia.org/wiki/Meltdown_(security_vulnerability)){target=\\_blank} are well-known CPU vulnerabilities that exploit speculative execution to access sensitive data. These vulnerabilities have been patched in recent Linux kernels, but the mitigations can slightly impact performance, especially in high-throughput or containerized environments.\n\nIf your security requirements allow it, you can deactivate specific mitigations, such as Spectre V2 and Speculative Store Bypass Disable (SSBD), to improve performance.\n\nTo selectively deactivate the Spectre mitigations, take these steps:\n\n1. Update the `GRUB_CMDLINE_LINUX_DEFAULT` variable in your `/etc/default/grub` configuration:\n\n    ```bash\n    sudo nano /etc/default/grub\n    # Add to GRUB_CMDLINE_LINUX_DEFAULT\n    ```\n\n    ```config title=\"/etc/default/grub\"\n    GRUB_DEFAULT = 0;\n    GRUB_HIDDEN_TIMEOUT = 0;\n    GRUB_HIDDEN_TIMEOUT_QUIET = true;\n    GRUB_TIMEOUT = 10;\n    GRUB_DISTRIBUTOR = `lsb_release -i -s 2> /dev/null || echo Debian`;\n    GRUB_CMDLINE_LINUX_DEFAULT =\n      'spec_store_bypass_disable=prctl spectre_v2_user=prctl';\n    ```\n\n2. Update GRUB to apply changes and then reboot:\n\n    ```bash\n    sudo update-grub\n    sudo reboot\n    ```\n\nThis approach selectively deactivates the Spectre V2 and Spectre V4 mitigations, leaving other protections intact. For full security, keep mitigations activated unless there's a significant performance need, as disabling them could expose the system to potential attacks on affected CPUs."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 5, "depth": 2, "title": "Monitor Your Node", "anchor": "monitor-your-node", "start_char": 5210, "end_char": 5907, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Monitor Your Node\n\nMonitoring your node's performance is critical for network reliability and security. Tools like the following provide valuable insights:\n\n- **[Prometheus](https://prometheus.io/){target=\\_blank}**: An open-source monitoring toolkit for collecting and querying time-series data.\n- **[Grafana](https://grafana.com/){target=\\_blank}**: A visualization tool for real-time metrics, providing interactive dashboards.\n- **[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/){target=\\_blank}**: A tool for managing and routing alerts based on Prometheus data.\n\nThis section covers setting up these tools and configuring alerts to notify you of potential issues."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 6, "depth": 3, "title": "Environment Setup", "anchor": "environment-setup", "start_char": 5907, "end_char": 6601, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "### Environment Setup\n\nBefore installing Prometheus, ensure the environment is set up securely by running Prometheus with restricted user privileges.\n\nFollow these steps:\n\n1. Create a Prometheus user to ensure Prometheus runs with minimal permissions:\n\n    ```bash\n    sudo useradd --no-create-home --shell /usr/sbin/nologin prometheus\n    ```\n\n2. Create directories for configuration and data storage:\n\n    ```bash\n    sudo mkdir /etc/prometheus\n    sudo mkdir /var/lib/prometheus\n    ```\n  \n3. Change directory ownership to ensure Prometheus has access:\n\n    ```bash\n    sudo chown -R prometheus:prometheus /etc/prometheus\n    sudo chown -R prometheus:prometheus /var/lib/prometheus\n    ```"}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 7, "depth": 3, "title": "Install and Configure Prometheus", "anchor": "install-and-configure-prometheus", "start_char": 6601, "end_char": 9085, "estimated_token_count": 545, "token_estimator": "heuristic-v1", "text": "### Install and Configure Prometheus\n\nAfter setting up the environment, install and configure the latest version of Prometheus as follows:\n\n1. Download Prometheus for your system architecture from the [releases page](https://github.com/prometheus/prometheus/releases/){target=\\_blank}. Replace `INSERT_RELEASE_DOWNLOAD` with the release binary URL (e.g., `https://github.com/prometheus/prometheus/releases/download/v3.0.0/prometheus-3.0.0.linux-amd64.tar.gz`):\n\n    ```bash\n    sudo apt-get update && sudo apt-get upgrade\n    wget INSERT_RELEASE_DOWNLOAD_LINK\n    tar xfz prometheus-*.tar.gz\n    cd prometheus-3.0.0.linux-amd64\n    ```\n\n2. Set up Prometheus:\n\n    1. Copy binaries:\n\n        ```bash\n        sudo cp ./prometheus /usr/local/bin/\n        sudo cp ./promtool /usr/local/bin/\n        sudo cp ./prometheus /usr/local/bin/\n        ```\n\n    2. Copy directories and assign ownership of these files to the `prometheus` user:\n\n        ```bash\n        sudo cp -r ./consoles /etc/prometheus\n        sudo cp -r ./console_libraries /etc/prometheus\n        sudo chown -R prometheus:prometheus /etc/prometheus/consoles\n        sudo chown -R prometheus:prometheus /etc/prometheus/console_libraries\n        ```\n\n    3. Clean up the download directory:\n\n        ```bash\n        cd .. && rm -r prometheus*\n        ```\n\n3. Create `prometheus.yml` to define global settings, rule files, and scrape targets:\n\n    ```bash\n    sudo nano /etc/prometheus/prometheus.yml\n    ```\n\n    {% raw %}\n    ```yaml title=\"prometheus-config.yml\"\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n\n    rule_files:\n      # - \"first.rules\"\n      # - \"second.rules\"\n\n    scrape_configs:\n      - job_name: 'prometheus'\n        scrape_interval: 5s\n        static_configs:\n          - targets: ['localhost:9090']\n      - job_name: 'substrate_node'\n        scrape_interval: 5s\n        static_configs:\n          - targets: ['localhost:9615']\n    ```\n    {% endraw %}\n\n    Prometheus is scraped every 5 seconds in this example configuration file, ensuring detailed internal metrics. Node metrics with customizable intervals are scraped from port `9615` by default.\n\n4. Verify the configuration with `promtool`, an open source monitoring tool:\n\n    ```bash\n    promtool check config /etc/prometheus/prometheus.yml\n    ```\n\n5. Save the configuration and change the ownership of the file to `prometheus` user:\n\n    ```bash\n    sudo chown prometheus:prometheus /etc/prometheus/prometheus.yml\n    ```"}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 8, "depth": 3, "title": "Start Prometheus", "anchor": "start-prometheus", "start_char": 9085, "end_char": 10918, "estimated_token_count": 410, "token_estimator": "heuristic-v1", "text": "### Start Prometheus\n\n1. Launch Prometheus with the appropriate configuration file, storage location, and necessary web resources, running it with restricted privileges for security:\n\n    ```bash\n    sudo -u prometheus /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml \\\n    --storage.tsdb.path /var/lib/prometheus/ \\\n    --web.console.templates=/etc/prometheus/consoles \\\n    --web.console.libraries=/etc/prometheus/console_libraries\n    ```\n\n    If you set the server up properly, you should see terminal output similar to the following:\n\n    \n2. Verify you can access the Prometheus interface by navigating to:\n\n    ```text\n    http://SERVER_IP_ADDRESS:9090/graph\n    ```\n\n    If the interface appears to work as expected, exit the process using `Control + C`.\n\n3. Create a systemd service file to ensure Prometheus starts on boot:\n\n    ```bash\n    sudo nano /etc/systemd/system/prometheus.service\n    ```\n\n    ```bash title=\"prometheus.service\"\n    [Unit]\n    Description=Prometheus Monitoring\n    Wants=network-online.target\n    After=network-online.target\n\n    [Service]\n    User=prometheus\n    Group=prometheus\n    Type=simple\n    ExecStart=/usr/local/bin/prometheus \\\n     --config.file /etc/prometheus/prometheus.yml \\\n     --storage.tsdb.path /var/lib/prometheus/ \\\n     --web.console.templates=/etc/prometheus/consoles \\\n     --web.console.libraries=/etc/prometheus/console_libraries\n    ExecReload=/bin/kill -HUP $MAINPID\n\n    [Install]\n    WantedBy=multi-user.target\n\n    ```\n\n4. Reload systemd and enable the service to start on boot:\n\n    ```bash\n    sudo systemctl daemon-reload && sudo systemctl enable prometheus && sudo systemctl start prometheus\n    ```\n\n5. Verify the service is running by visiting the Prometheus interface again at:\n\n    ```text\n    http://SERVER_IP_ADDRESS:9090/\n    ```"}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 9, "depth": 3, "title": "Install and Configure Grafana", "anchor": "install-and-configure-grafana", "start_char": 10918, "end_char": 14586, "estimated_token_count": 921, "token_estimator": "heuristic-v1", "text": "### Install and Configure Grafana\n\nThis guide follows [Grafana's canonical installation instructions](https://grafana.com/docs/grafana/latest/setup-grafana/installation/debian/#install-from-apt-repository){target=\\_blank}.\n\nTo install and configure Grafana, follow these steps:\n\n1. Install Grafana prerequisites:\n\n    ```bash\n    sudo apt-get install -y apt-transport-https software-properties-common wget    \n    ```\n\n2. Import the [GPG key](https://gnupg.org/){target=\\_blank}:\n\n    ```bash\n    sudo mkdir -p /etc/apt/keyrings/\n    wget -q -O - https://apt.grafana.com/gpg.key | gpg --dearmor | sudo tee /etc/apt/keyrings/grafana.gpg > /dev/null\n    ```\n\n3. Configure the stable release repo and update packages:\n\n    ```bash\n    echo \"deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\n    sudo apt-get update\n    ```\n\n4. Install the latest stable version of Grafana:\n\n    ```bash\n    sudo apt-get install grafana\n    ```\n\nTo configure Grafana, take these steps:\n\n1. Configure Grafana to start automatically on boot and start the service:\n\n    ```bash\n    sudo systemctl daemon-reload\n    sudo systemctl enable grafana-server.service\n    sudo systemctl start grafana-server\n    ```\n\n2. Check if Grafana is running:\n\n    ```bash\n    sudo systemctl status grafana-server\n    ```\n\n    If necessary, you can stop or restart the service with the following commands:\n\n    ```bash\n    sudo systemctl stop grafana-server\n    sudo systemctl restart grafana-server\n    ```\n\n3. Access Grafana by navigating to the following URL and logging in with the default username and password (`admin`):\n\n    ```text\n    http://SERVER_IP_ADDRESS:3000/login\n    ```\n\n    !!! tip \"Change default port\"\n        To change Grafana's port, edit `/usr/share/grafana/conf/defaults.ini`:\n\n        ```bash\n        sudo vim /usr/share/grafana/conf/defaults.ini\n        ```\n\n        Modify the `http_port` value, then restart Grafana:\n\n        ```bash\n        sudo systemctl restart grafana-server\n        ```\n\n![Grafana login screen](/images/node-infrastructure/run-a-validator/operational-tasks/general-management/general-management-01.webp)\n\nTo visualize node metrics, follow these steps:\n\n1. Select the gear icon to access **Data Sources** settings.\n2. Select **Add data source** to define the data source.\n\n    ![Select Prometheus](/images/node-infrastructure/run-a-validator/operational-tasks/general-management/general-management-02.webp)\n\n3. Select **Prometheus**.\n\n    ![Save and test](/images/node-infrastructure/run-a-validator/operational-tasks/general-management/general-management-03.webp)\n\n4. Enter `http://localhost:9090` in the **URL** field and click **Save & Test**. If **\"Data source is working\"** appears, your connection is configured correctly.\n\n    ![Import dashboard](/images/node-infrastructure/run-a-validator/operational-tasks/general-management/general-management-04.webp)\n\n5. Select **Import** from the left menu, choose **Prometheus** from the dropdown, and click **Import**.\n\n6. Start your Polkadot node by running `./polkadot`. You should now be able to monitor node performance, block height, network traffic, and tasks tasks on the Grafana dashboard.\n\n    ![Live dashboard](/images/node-infrastructure/run-a-validator/operational-tasks/general-management/general-management-05.webp)\n\nThe [Grafana dashboards](https://grafana.com/grafana/dashboards){target=\\_blank} page features user created dashboards made available for public use. For an example, see the [Substrate Node Metrics](https://grafana.com/grafana/dashboards/21715-substrate-node-metrics/){target=\\_blank} dashboard."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 10, "depth": 3, "title": "Install and Configure Alertmanager", "anchor": "install-and-configure-alertmanager", "start_char": 14586, "end_char": 22142, "estimated_token_count": 1677, "token_estimator": "heuristic-v1", "text": "### Install and Configure Alertmanager\n\n[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/){target=\\_blank} is an optional component that complements Prometheus by managing alerts and notifying users about potential issues.\n\nFollow these steps to install and configure Alertmanager:\n\n1. Download Alertmanager for your system architecture from the [releases page](https://github.com/prometheus/alertmanager/releases){target=\\_blank}. Replace `INSERT_RELEASE_DOWNLOAD` with the release binary URL (e.g., `https://github.com/prometheus/alertmanager/releases/download/v0.28.0-rc.0/alertmanager-0.28.0-rc.0.linux-amd64.tar.gz`):\n\n    ```bash\n    wget INSERT_RELEASE_DOWNLOAD_LINK\n    tar -xvzf alertmanager*\n    ```\n\n2. Copy the binaries to the system directory and set permissions:\n\n    ```bash\n    cd alertmanager-0.28.0-rc.0.linux-amd64\n    sudo cp ./alertmanager /usr/local/bin/\n    sudo cp ./amtool /usr/local/bin/\n    sudo chown prometheus:prometheus /usr/local/bin/alertmanager\n    sudo chown prometheus:prometheus /usr/local/bin/amtool\n    ```\n\n3. Create the `alertmanager.yml` configuration file under `/etc/alertmanager`:\n\n    ```bash\n    sudo mkdir /etc/alertmanager\n    sudo nano /etc/alertmanager/alertmanager.yml\n    ```\n\n    Generate an [app password in your Google account](https://support.google.com/accounts/answer/185833?hl=en){target=\\_blank} to enable email notifications from Alertmanager. Then, add the following code to the configuration file to define email notifications using your  email and app password: \n\n    {% raw %}\n    ```yml title=\"alertmanager.yml\"\n    global:\n      resolve_timeout: 1m\n\n    route:\n      receiver: 'gmail-notifications'\n\n    receivers:\n      - name: 'gmail-notifications'\n        email_configs:\n          - to: INSERT_YOUR_EMAIL\n            from: INSERT_YOUR_EMAIL\n            smarthost: smtp.gmail.com:587\n            auth_username: INSERT_YOUR_EMAIL\n            auth_identity: INSERT_YOUR_EMAIL\n            auth_password: INSERT_YOUR_APP_PASSWORD\n            send_resolved: true\n\n    ```\n    {% endraw %}\n\n\n    ```bash\n    sudo chown -R prometheus:prometheus /etc/alertmanager\n    ```\n\n4. Configure Alertmanager as a service by creating a systemd service file:\n\n    ```bash\n    sudo nano /etc/systemd/system/alertmanager.service\n    ```\n\n    {% raw %}\n    ```yml title=\"alertmanager.service\"\n    [Unit]\n    Description=AlertManager Server Service\n    Wants=network-online.target\n    After=network-online.target\n\n    [Service]\n    User=root\n    Group=root\n    Type=simple\n    ExecStart=/usr/local/bin/alertmanager --config.file /etc/alertmanager/alertmanager.yml --web.external-url=http://SERVER_IP:9093 --cluster.advertise-address='0.0.0.0:9093'\n\n    [Install]\n    WantedBy=multi-user.target\n\n    ```\n    {% endraw %}\n\n5. Reload and enable the service:\n\n    ```bash\n    sudo systemctl daemon-reload\n    sudo systemctl enable alertmanager\n    sudo systemctl start alertmanager\n    ```\n\n6. Verify the service status:\n\n    ```bash\n    sudo systemctl status alertmanager\n    ```\n\n    If you have configured Alertmanager properly, the **Active** field should display **active (running)** similar to below:\n\n    <div id=\"termynal\" data-termynal>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>sudo systemctl status alertmanager</span>\n      <span data-ty>alertmanager.service - AlertManager Server Service</span>\n      <span data-ty>Loaded: loaded (/etc/systemd/system/alertmanager.service; enabled; vendor preset: enabled)</span>\n      <span data-ty>Active: active (running) since Thu 2020-08-20 22:01:21 CEST; 3 days ago</span>\n      <span data-ty>Main PID: 20592 (alertmanager)</span>\n      <span data-ty>Tasks: 70 (limit: 9830)</span>\n      <span data-ty>CGroup: /system.slice/alertmanager.service</span>\n      <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n    </div>\n\n#### Grafana Plugin\n\nThere is an [Alertmanager plugin in Grafana](https://grafana.com/grafana/plugins/alertmanager/){target=\\_blank} that can help you monitor alert information.\n\nFollow these steps to use the plugin:\n\n1. Install the plugin:\n\n    ```bash\n    sudo grafana-cli plugins install camptocamp-prometheus-alertmanager-datasource\n    ```\n\n2. Restart Grafana:\n\n    ```bash\n    sudo systemctl restart grafana-server\n    ```\n\n3. Configure Alertmanager as a data source in your Grafana dashboard (`SERVER_IP:3000`):\n\n    1. Go to **Configuration** > **Data Sources** and search for **Prometheus Alertmanager**.\n    2. Enter the server URL and port for the Alertmanager service, and select **Save & Test** to verify the connection.\n\n4. Import the [8010](https://grafana.com/grafana/dashboards/8010-prometheus-alertmanager/){target=\\_blank} dashboard for Alertmanager, selecting **Prometheus Alertmanager** in the last column, then select **Import**.\n\n#### Integrate Alertmanager\n\nComplete the integration by following these steps to enable communication between Prometheus and Alertmanager and configure detection and alert rules:\n\n1. Update the `etc/prometheus/prometheus.yml` configuration file to include the following code:\n\n    {% raw %}\n    ```yml title=\"prometheus.yml\"\n    rule_files:\n      - 'rules.yml'\n\n    alerting:\n      alertmanagers:\n        - static_configs:\n            - targets:\n                - localhost:9093\n    ```\n    {% endraw %}\n\n    Expand the following item to view the complete `prometheus.yml` file.\n\n    ??? code \"prometheus.yml\"\n\n        {% raw %}\n        ```yml title=\"prometheus.yml\"\n        global:\n          scrape_interval: 15s\n          evaluation_interval: 15s\n\n        rule_files:\n          - 'rules.yml'\n\n        alerting:\n          alertmanagers:\n            - static_configs:\n                - targets:\n                    - localhost:9093\n\n        scrape_configs:\n          - job_name: 'prometheus'\n            scrape_interval: 5s\n            static_configs:\n              - targets: ['localhost:9090']\n          - job_name: 'substrate_node'\n            scrape_interval: 5s\n            static_configs:\n              - targets: ['localhost:9615']\n\n        ```\n        {% endraw %}\n\n2. Create the rules file for detection and alerts:\n\n    ```bash\n    sudo nano /etc/prometheus/rules.yml\n    ```\n\n    Add a sample rule to trigger email notifications for node downtime over five minutes:\n\n    {% raw %}\n    ```yml title=\"rules.yml\"\n    groups:\n      - name: alert_rules\n        rules:\n          - alert: InstanceDown\n            expr: up == 0\n            for: 5m\n            labels:\n              severity: critical\n            annotations:\n              summary: 'Instance [{{ $labels.instance }}] down'\n              description: '[{{ $labels.instance }}] of job [{{ $labels.job }}] has been down for more than 5 minutes.'\n\n    ```\n    {% endraw %}\n\n    If any of the conditions defined in the rules file are met, an alert will be triggered. For more on alert rules, refer to [Alerting Rules](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/){target=\\_blank} and [additional alerts](https://samber.github.io/awesome-prometheus-alerts/rules.html){target=\\_blank}.\n\n3. Update the file ownership to `prometheus`:\n\n    ```bash\n    sudo chown prometheus:prometheus rules.yml\n    ```\n\n4. Validate the rules syntax:\n\n    ```bash\n    sudo -u prometheus promtool check rules rules.yml\n    ```\n\n5. Restart Prometheus and Alertmanager:\n\n    ```bash\n    sudo systemctl restart prometheus && sudo systemctl restart alertmanager\n    ```\n\nNow you will receive an email alert if one of your rule triggering conditions is met."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 11, "depth": 2, "title": "Secure Your Validator", "anchor": "secure-your-validator", "start_char": 22142, "end_char": 22494, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Secure Your Validator\n\nValidators in Polkadot's Proof of Stake (PoS) network play a critical role in maintaining network integrity and security by keeping the network in consensus and verifying state transitions. To ensure optimal performance and minimize risks, validators must adhere to strict guidelines around security and reliable operations."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 12, "depth": 3, "title": "Key Management", "anchor": "key-management", "start_char": 22494, "end_char": 23783, "estimated_token_count": 271, "token_estimator": "heuristic-v1", "text": "### Key Management\n\nThough they don't transfer funds, session keys are essential for validators as they sign messages related to consensus and parachains. Securing session keys is crucial as allowing them to be exploited or used across multiple nodes can lead to a loss of staked funds via [slashing](/node-infrastructure/run-a-validator/staking-mechanics/offenses-and-slashes/){target=\\_blank}.\n\nGiven the current limitations in high-availability setups and the risks associated with double-signing, itâ€™s recommended to run only a single validator instance. Keys should be securely managed, and processes automated to minimize human error.\n\nThere are two approaches for generating session keys:\n\n- **Generate and store in node**: Using the `author.rotateKeys` RPC call. For most users, generating keys directly within the client is recommended. You must submit a session certificate from your staking proxy to register new keys. See the [How to Validate](/node-infrastructure/run-a-validator/onboarding-and-offboarding/set-up-validator/){target=\\_blank} guide for instructions on setting keys.\n\n- **Generate outside node and insert**: Using the `author.setKeys` RPC call. This flexibility accommodates advanced security setups and should only be used by experienced validator operators."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 13, "depth": 3, "title": "Signing Outside the Client", "anchor": "signing-outside-the-client", "start_char": 23783, "end_char": 24075, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Signing Outside the Client\n\nPolkadot plans to support external signing, allowing session keys to reside in secure environments like Hardware Security Modules (HSMs). However, these modules can sign any payload they receive, potentially enabling an attacker to perform slashable actions."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 14, "depth": 3, "title": "Secure-Validator Mode", "anchor": "secure-validator-mode", "start_char": 24075, "end_char": 24836, "estimated_token_count": 169, "token_estimator": "heuristic-v1", "text": "### Secure-Validator Mode\n\nPolkadot's Secure-Validator mode offers an extra layer of protection through strict filesystem, networking, and process sandboxing. This secure mode is activated by default if the machine meets the following requirements:\n\n- **Linux (x86-64 architecture)**: Usually Intel or AMD.\n- **Enabled `seccomp`**: This kernel feature facilitates a more secure approach for process management on Linux. Verify by running.\n\n    ```bash\n    cat /boot/config-`uname -r` | grep CONFIG_SECCOMP=\n    ```\n\n    If `seccomp` is enabled, you should see output similar to the following:\n\n    ```bash\n    CONFIG_SECCOMP=y\n    ```\n\n!!! tip \n    Optionally, **Linux 5.13** may also be used, as it provides access to even more strict filesystem protections."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 15, "depth": 3, "title": "Linux Best Practices", "anchor": "linux-best-practices", "start_char": 24836, "end_char": 25294, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "### Linux Best Practices\n\nFollow these best practices to keep your validator secure:\n\n- Use a non-root user for all operations.\n- Regularly apply OS security patches.\n- Enable and configure a firewall.\n- Use key-based SSH authentication; deactivate password-based login.\n- Regularly back up data and harden your SSH configuration. Visit this [SSH guide](https://blog.stribik.technology/2015/01/04/secure-secure-shell.html){target=\\_blank} for more details."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 16, "depth": 3, "title": "Validator Best Practices", "anchor": "validator-best-practices", "start_char": 25294, "end_char": 26052, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### Validator Best Practices\n\nAdditional best practices can add an additional layer of security and operational reliability:\n\n- Only run the Polkadot binary, and only listen on the configured p2p port.\n- Run on bare-metal machines, as opposed to virtual machines.\n- Provisioning of the validator machine should be automated and defined in code which is kept in private version control, reviewed, audited, and tested.\n- Generate and provide session keys in a secure way.\n- Start Polkadot at boot and restart if stopped for any reason.\n- Run Polkadot as a non-root user.\n- Establish and maintain an on-call rotation for managing alerts.\n- Establish and maintain a clear protocol with actions to perform for each level of each alert with an escalation policy."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-general-management", "page_title": "General Management", "index": 17, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 26052, "end_char": 26666, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- [Certus One's Knowledge Base](https://knowledgebase.certus.com/FAQ/){target=\\_blank}\n- [EOS Block Producer Security List](https://github.com/slowmist/eos-bp-nodes-security-checklist){target=\\_blank}\n- [HSM Policies and the Importance of Validator Security](https://medium.com/loom-network/hsm-policies-and-the-importance-of-validator-security-ec8a4cc1b6f){target=\\_blank}\n\nFor additional guidance, connect with other validators and the Polkadot engineering team in the [Polkadot Validator Lounge](https://matrix.to/#/#polkadotvalidatorlounge:web3.foundation){target=\\_blank} on Element."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-pause-validating", "page_title": "Pause Validating", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 554, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIf you need to temporarily stop participating in Polkadot staking activities without fully unbonding your funds, chilling your account allows you to do so efficiently. Chilling removes your node from active validation or nomination in the next era while keeping your funds bonded, making it ideal for planned downtimes or temporary pauses.\n\nThis guide covers the steps for chilling as a validator or nominator, using the `chill` and `chillOther` extrinsics, and how these affect your staking status and nominations."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-pause-validating", "page_title": "Pause Validating", "index": 1, "depth": 2, "title": "Chilling Your Node", "anchor": "chilling-your-node", "start_char": 554, "end_char": 1176, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Chilling Your Node\n\nIf you need to temporarily step back from staking without unbonding your funds, you can \"chill\" your account. Chilling pauses your active staking participation, setting your account to inactive in the next era while keeping your funds bonded.\n\nTo chill your account, go to the **Network > Staking > Account Actions** page on [Polkadot.js Apps](https://polkadot.js.org/apps){target=\\_blank}, and select **Stop**. Alternatively, you can call the [`chill`](https://paritytech.github.io/polkadot-sdk/master/pallet_staking/enum.Call.html#variant.chill){target=\\_blank} extrinsic in the Staking pallet."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-pause-validating", "page_title": "Pause Validating", "index": 2, "depth": 2, "title": "Staking Election Timing Considerations", "anchor": "staking-election-timing-considerations", "start_char": 1176, "end_char": 1777, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Staking Election Timing Considerations\n\nWhen a node actively participates in staking but then chills, it will continue contributing for the remainder of the current era. However, its eligibility for the next election depends on the chill status at the start of the new era:\n\n- **Chilled during previous era**: Will not participate in the current era election and will remain inactive until reactivated.\n- **Chilled during current era**: Will not be selected for the next era's election.\n- **Chilled after current era**: May be selected if it was active during the previous era and is now chilled."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-pause-validating", "page_title": "Pause Validating", "index": 3, "depth": 2, "title": "Chilling as a Nominator", "anchor": "chilling-as-a-nominator", "start_char": 1777, "end_char": 2554, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Chilling as a Nominator\n\nWhen you choose to chill as a nominator, your active nominations are reset. Upon re-entering the nominating process, you must reselect validators to support manually. Depending on preferences, these can be the same validators as before or a new set. Remember that your previous nominations wonâ€™t be saved or automatically reactivated after chilling.\n\nWhile chilled, your nominator account remains bonded, preserving your staked funds without requiring a full unbonding process. When youâ€™re ready to start nominating again, you can issue a new nomination call to activate your bond with a fresh set of validators. This process bypasses the need for re-bonding, allowing you to maintain your stake while adjusting your involvement in active staking."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-pause-validating", "page_title": "Pause Validating", "index": 4, "depth": 2, "title": "Chilling as a Validator", "anchor": "chilling-as-a-validator", "start_char": 2554, "end_char": 3452, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## Chilling as a Validator\n\nWhen you chill as a validator, your active validator status is paused. Although your nominators remain bonded to you, the validator bond will no longer appear as an active choice for new or revised nominations until reactivated. Any existing nominators who take no action will still have their stake linked to the validator, meaning they donâ€™t need to reselect the validator upon reactivation. However, if nominators adjust their stakes while the validator is chilled, they will not be able to nominate the chilled validator until it resumes activity.\n\nUpon reactivating as a validator, you must also reconfigure your validator preferences, such as commission rate and other parameters. These can be set to match your previous configuration or updated as desired. This step is essential for rejoining the active validator set and regaining eligibility for nominations."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-pause-validating", "page_title": "Pause Validating", "index": 5, "depth": 2, "title": "Chill Other", "anchor": "chill-other", "start_char": 3452, "end_char": 4439, "estimated_token_count": 191, "token_estimator": "heuristic-v1", "text": "## Chill Other\n\nHistorical constraints in the runtime prevented unlimited nominators and validators from being supported. These constraints created a need for checks to keep the size of the staking system manageable. One of these checks is the `chillOther` extrinsic, allowing users to chill accounts that no longer met standards such as minimum staking requirements set through on-chain governance.\n\nThis control mechanism included a `ChillThreshold`, which was structured to define how close to the maximum number of nominators or validators the staking system would be allowed to get before users could start chilling one another. With the passage of [Referendum #90](https://polkadot-old.polkassembly.io/referendum/90){target=\\_blank}, the value for `maxNominatorCount` on Polkadot was set to `None`, effectively removing the limit on how many nominators and validators can participate. This means the `ChillThreshold` will never be met; thus, `chillOther` no longer has any effect."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 821, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUpgrading a Polkadot validator node is essential for staying current with network updates and maintaining optimal performance. This guide covers routine and extended maintenance scenarios, including software upgrades and major server changes. Following these steps, you can manage session keys and transition smoothly between servers without risking downtime, slashing, or network disruptions. The process requires strategic planning, especially if you need to perform long-lead maintenance, ensuring your validator remains active and compliant.\n\nThis guide will allow validators to seamlessly substitute an active validator server to allow for maintenance operations. The process can take several hours, so ensure you understand the instructions first and plan accordingly."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 821, "end_char": 1376, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore beginning the upgrade process for your validator node, ensure the following:\n\n- You have a fully functional validator setup with all required binaries installed. See [Set Up a Validator](/node-infrastructure/run-a-validator/onboarding-and-offboarding/set-up-validator/){target=\\_blank} and [Validator Requirements](/node-infrastructure/run-a-validator/requirements/){target=\\_blank} for additional guidance.\n- Your VPS infrastructure has enough capacity to run a secondary validator instance temporarily for the upgrade process."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 2, "depth": 2, "title": "Session Keys", "anchor": "session-keys", "start_char": 1376, "end_char": 2089, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "## Session Keys\n\nSession keys are used to sign validator operations and establish a connection between your validator node and your staking proxy account. These keys are stored in the client, and any change to them requires a waiting period. Specifically, if you modify your session keys, the change will take effect only after the current session is completed and two additional sessions have passed.\n\nRemembering this delayed effect when planning upgrades is crucial to ensure that your validator continues to function correctly and avoids interruptions. To learn more about session keys and their importance, visit the [Keys section](https://wiki.polkadot.com/learn/learn-cryptography/#keys){target=\\_blank}."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 3, "depth": 2, "title": "Keystore", "anchor": "keystore", "start_char": 2089, "end_char": 2882, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "## Keystore\n\nYour validator server's `keystore` folder holds the private keys needed for signing network-level transactions. It is important not to duplicate or transfer this folder between validator instances. Doing so could result in multiple validators signing with the duplicate keys, leading to severe consequences such as [equivocation slashing](/node-infrastructure/run-a-validator/staking-mechanics/offenses-and-slashes/#equivocation-slash){target=\\_blank}. Instead, always generate new session keys for each validator instance.\n\nThe default path to the `keystore` is as follows:\n\n```bash\n/home/polkadot/.local/share/polkadot/chains/<chain>/keystore\n```\n\nTaking care to manage your keys securely ensures that your validator operates safely and without the risk of slashing penalties."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 4, "depth": 2, "title": "Upgrade Using Backup Validator", "anchor": "upgrade-using-backup-validator", "start_char": 2882, "end_char": 3134, "estimated_token_count": 41, "token_estimator": "heuristic-v1", "text": "## Upgrade Using Backup Validator\n\nThe following instructions outline how to temporarily switch between two validator nodes. The original active validator is referred to as Validator A and the backup node used for maintenance purposes as Validator B."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 5, "depth": 3, "title": "Session `N`", "anchor": "session-n", "start_char": 3134, "end_char": 4086, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Session `N`\n\n1. **Start Validator B**: Launch a secondary node and wait until it is fully synced with the network. Once synced, start it with the `--validator` flag. This node will now act as Validator B.\n2. **Generate session keys**: Create new session keys specifically for Validator B.\n3. **Submit the `set_key` extrinsic**: Use your staking proxy account to submit a `set_key` extrinsic, linking the session keys for Validator B to your staking setup.\n4. **Record the session**: Make a note of the session in which you executed this extrinsic.\n5. **Wait for session changes**: Allow the current session to end and then wait for two additional full sessions for the new keys to take effect.\n\n!!! warning \"Keep Validator A running\"\n\n      It is crucial to keep Validator A operational during this entire waiting period. Since `set_key` does not take effect immediately, turning off Validator A too early may result in chilling or even slashing."}
{"page_id": "node-infrastructure-run-a-validator-operational-tasks-upgrade-your-node", "page_title": "Upgrade a Validator Node", "index": 6, "depth": 3, "title": "Session `N+3`", "anchor": "session-n3", "start_char": 4086, "end_char": 5647, "estimated_token_count": 378, "token_estimator": "heuristic-v1", "text": "### Session `N+3`\n\nAt this stage, Validator B becomes your active validator. You can now safely perform any maintenance tasks on Validator A.\n\nComplete the following steps when you are ready to bring Validator A back online:\n\n1. **Start Validator A**: Launch Validator A, sync the blockchain database, and ensure it is running with the `--validator` flag.\n2. **Generate new session keys for Validator A**: Create fresh session keys for Validator A.\n3. **Submit the `set_key` extrinsic**: Using your staking proxy account, submit a `set_key` extrinsic with the new Validator A session keys.\n4. **Record the session**: Again, make a note of the session in which you executed this extrinsic.\n\nKeep Validator B active until the session during which you executed the `set-key` extrinsic completes plus two additional full sessions have passed. Once Validator A has successfully taken over, you can safely stop Validator B. This process helps ensure a smooth handoff between nodes and minimizes the risk of downtime or penalties. Verify the transition by checking for finalized blocks in the new session. The logs should indicate the successful change, similar to the example below:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>INSERT_COMMAND</span>\n  <span data-ty>2019-10-28 21:44:13 Applying authority set change scheduled at block #450092</span>\n  <span data-ty>2019-10-28 21:44:13 Applying GRANDPA set change to new set with 20 authorities</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "node-infrastructure-run-a-validator-requirements", "page_title": "Validator Requirements", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 26, "end_char": 981, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRunning a validator in the Polkadot ecosystem is essential for maintaining network security and decentralization. Validators are responsible for validating transactions and adding new blocks to the chain, ensuring the system operates smoothly. In return for their services, validators earn rewards. However, the role comes with inherent risks, such as slashing penalties for misbehavior or technical failures. If youâ€™re new to validation, starting on Kusama provides a lower-stakes environment to gain valuable experience before progressing to the Polkadot network.\n\nThis guide covers everything you need to know about becoming a validator, including system requirements, staking prerequisites, and infrastructure setup. Whether youâ€™re deploying on a VPS or running your node on custom hardware, youâ€™ll learn how to optimize your validator for performance and security, ensuring compliance with network standards while minimizing risks."}
{"page_id": "node-infrastructure-run-a-validator-requirements", "page_title": "Validator Requirements", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 981, "end_char": 2392, "estimated_token_count": 300, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nRunning a validator requires solid system administration skills and a secure, well-maintained infrastructure. Below are the primary requirements you need to be aware of before getting started:\n\n- **System administration expertise**: Handling technical anomalies and maintaining node infrastructure is critical. Validators must be able to troubleshoot and optimize their setup.\n- **Security**: Ensure your setup follows best practices for securing your node. Refer to the [Secure Your Validator](/node-infrastructure/run-a-validator/operational-tasks/general-management/#secure-your-validator){target=\\_blank} section to learn about important security measures.\n- **Network choice**: Start with [Kusama](/node-infrastructure/run-a-validator/onboarding-and-offboarding/set-up-validator/#run-a-kusama-validator){target=\\_blank} to gain experience. Look for \"Adjustments for Kusama\" throughout these guides for tips on adapting the provided instructions for the Kusama network.\n- **Staking requirements**: A minimum amount of native token (KSM or DOT) is required to be elected into the validator set. The required stake can come from your own holdings or from nominators.\n- **Risk of slashing**: Any DOT you stake is at risk if your setup fails or your validator misbehaves. If youâ€™re unsure of your ability to maintain a reliable validator, consider nominating your DOT to a trusted validator."}
{"page_id": "node-infrastructure-run-a-validator-requirements", "page_title": "Validator Requirements", "index": 2, "depth": 2, "title": "Minimum Hardware Requirements", "anchor": "minimum-hardware-requirements", "start_char": 2392, "end_char": 3556, "estimated_token_count": 251, "token_estimator": "heuristic-v1", "text": "## Minimum Hardware Requirements\n\nPolkadot validators rely on high-performance hardware to process blocks efficiently. The recommended minimum hardware requirements to ensure a fully functional and performant validator are as follows:\n\n- CPU:\n\n    - x86-64 compatible.\n    - Eight physical cores @ 3.4 GHz.\n    - Processor:\n        - **Intel**: Ice Lake or newer (Xeon or Core series)\n        - **AMD**: Zen3 or newer (EPYC or Ryzen)\n    - Simultaneous multithreading disabled:\n        - **Intel**: Hyper-Threading\n        - **AMD**: SMT\n    - [Single-threaded performance](https://www.cpubenchmark.net/singleThread.html){target=\\_blank} is prioritized over higher cores count.\n\n- Storage:\n\n    - **NVMe SSD**: At least 2 TB for blockchain data recommended (prioritize latency rather than throughput).\n    - Storage requirements will increase as the chain grows. For current estimates, see the [current chain snapshot](https://stakeworld.io/docs/dbsize){target=\\_blank}.\n\n- Memory:\n\n    - 32 GB DDR4 ECC\n\n- Network:\n\n    - Symmetric networking speed of 500 Mbit/s is required to handle large numbers of parachains and ensure congestion control during peak times."}
{"page_id": "node-infrastructure-run-a-validator-requirements", "page_title": "Validator Requirements", "index": 3, "depth": 2, "title": "VPS Provider List", "anchor": "vps-provider-list", "start_char": 3556, "end_char": 6075, "estimated_token_count": 575, "token_estimator": "heuristic-v1", "text": "## VPS Provider List\n\nWhen selecting a VPS provider for your validator node, prioritize reliability, consistent performance, and adherence to the specific hardware requirements set for Polkadot validators. The following server types have been tested and showed acceptable performance in benchmark tests. However, this is not an endorsement and actual performance may vary depending on your workload and VPS provider.\n\nBe aware that some providers may overprovision the underlying host and use shared storage such as NVMe over TCP, which appears as local storage. These setups might result in poor or inconsistent performance. Benchmark your infrastructure before deploying.\n\n- **[Google Cloud Platform (GCP)](https://cloud.google.com/){target=\\_blank}**: `c2` and `c2d` machine families offer high-performance configurations suitable for validators.\n- **[Amazon Web Services (AWS)](https://aws.amazon.com/){target=\\_blank}**: `c6id` machine family provides strong performance, particularly for I/O-intensive workloads.\n- **[OVH](https://www.ovhcloud.com/en-au/){target=\\_blank}**: Can be a budget-friendly solution if it meets your minimum hardware specifications.\n- **[Digital Ocean](https://www.digitalocean.com/){target=\\_blank}**: Popular among developers, Digital Ocean's premium droplets offer configurations suitable for medium to high-intensity workloads.\n- **[Vultr](https://www.vultr.com/){target=\\_blank}**: Offers flexibility with plans that may meet validator requirements, especially for high-bandwidth needs.\n- **[Linode](https://www.linode.com/){target=\\_blank}**: Provides detailed documentation, which can be helpful for setup.\n- **[Scaleway](https://www.scaleway.com/en/){target=\\_blank}**: Offers high-performance cloud instances that can be suitable for validator nodes.\n- **[OnFinality](https://onfinality.io/en){target=\\_blank}**: Specialized in blockchain infrastructure, OnFinality provides validator-specific support and configurations.\n\n!!! warning \"Acceptable use policies\"\n    Different VPS providers have varying acceptable use policies, and not all allow cryptocurrency-related activities. \n\n    For example, Digital Ocean, requires explicit permission to use servers for cryptocurrency mining and defines unauthorized mining as [network abuse](https://www.digitalocean.com/legal/acceptable-use-policy#network-abuse){target=\\_blank} in their acceptable use policy. \n    \n    Review the terms for your VPS provider to avoid account suspension or server shutdown due to policy violations."}
{"page_id": "node-infrastructure-run-a-validator-requirements", "page_title": "Validator Requirements", "index": 4, "depth": 2, "title": "Minimum Bond Requirement", "anchor": "minimum-bond-requirement", "start_char": 6075, "end_char": 6840, "estimated_token_count": 196, "token_estimator": "heuristic-v1", "text": "## Minimum Bond Requirement\n\nBefore bonding DOT, ensure you meet the minimum bond requirement to start a validator instance. The minimum bond is the least DOT you need to stake to enter the validator set. To become eligible for rewards, your validator node must be nominated by enough staked tokens.\n\nFor example, on November 19, 2024, the minimum stake backing a validator in Polkadot's era 1632 was 1,159,434.248 DOT. You can check the current minimum stake required using these tools:\n\n- [**Chain State Values**](https://wiki.polkadot.com/general/chain-state-values/){target=\\_blank}\n- [**Subscan**](https://polkadot.subscan.io/validator_list?status=validator){target=\\_blank}\n- [**Staking Dashboard**](https://staking.polkadot.cloud/#/overview){target=\\_blank}"}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 674, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn Polkadot's Nominated Proof of Stake (NPoS) system, validator misconduct is deterred through a combination of slashing, disabling, and reputation penalties. Validators and nominators who stake tokens face consequences for validator misbehavior, which range from token slashes to restrictions on network participation.\n\nThis page outlines the types of offenses recognized by Polkadot, including block equivocations and invalid votes, as well as the corresponding penalties. While some parachains may implement additional custom slashing mechanisms, this guide focuses on the offenses tied to staking within the Polkadot ecosystem."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 1, "depth": 2, "title": "Offenses", "anchor": "offenses", "start_char": 674, "end_char": 1106, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Offenses\n\nPolkadot is a public permissionless network. As such, it has a mechanism to disincentivize offenses and incentivize good behavior. You can review theÂ [parachain protocol](https://wiki.polkadot.com/learn/learn-parachains-protocol/#parachain-protocol){target=\\_blank} to understand better the terminology used to describe offenses. Polkadot validator offenses fall into two categories: invalid votes and equivocations."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 2, "depth": 3, "title": "Invalid Votes", "anchor": "invalid-votes", "start_char": 1106, "end_char": 1733, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "### Invalid Votes\n\nA validator will be penalized for inappropriate voting activity during the block inclusion and approval processes. The invalid voting related offenses are as follows:\n\n- **Backing an invalid block**: A para-validator backs an invalid block for inclusion in a fork of the relay chain.\n- **`ForInvalid` vote**: When acting as a secondary checker, the validator votes in favor of an invalid block.\n- **`AgainstValid` vote**: When acting as a secondary checker, the validator votes against a valid block. This type of vote wastes network resources required to resolve the disparate votes and resulting dispute."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 3, "depth": 3, "title": "Equivocations", "anchor": "equivocations", "start_char": 1733, "end_char": 2746, "estimated_token_count": 197, "token_estimator": "heuristic-v1", "text": "### Equivocations\n\nEquivocation occurs when a validator produces statements that conflict with each other when producing blocks or voting. Unintentional equivocations usually occur when duplicate signing keys reside on the validator host. If keys are never duplicated, the probability of an honest equivocation slash decreases to near zero. The equivocation related offenses are as follows:\n\n- **Equivocation**: The validator produces two or more of the same block or vote.\n    - **GRANDPA and BEEFY equivocation**: The validator signs two or more votes in the same round on different chains.\n    - **BABE equivocation**: The validator produces two or more blocks on the relay chain in the same time slot.\n- **Double seconded equivocation**: The validator attempts to second, or back, more than one block in the same round.\n- **Seconded and valid equivocation**: The validator seconds, or backs, a block and then attempts to hide their role as the responsible backer by later placing a standard validation vote."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 4, "depth": 2, "title": "Penalties", "anchor": "penalties", "start_char": 2746, "end_char": 2924, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Penalties\n\nOn Polkadot, offenses to the network incur different penalties depending on severity. There are three main penalties: slashing, disabling, and reputation changes."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 5, "depth": 3, "title": "Slashing", "anchor": "slashing", "start_char": 2924, "end_char": 13705, "estimated_token_count": 2520, "token_estimator": "heuristic-v1", "text": "### Slashing\n\nValidators engaging in bad actor behavior in the network may be subject to slashing if they commit a qualifying offense. When a validator is slashed, they and their nominators lose a percentage of their staked DOT or KSM, from as little as 0.01% up to 100% based on the severity of the offense. Nominators are evaluated for slashing against their active validations at any given time. Validator nodes are evaluated as discrete entities, meaning an operator can't attempt to mitigate the offense on another node they operate in order to avoid a slash. \n\nAny slashed DOT or KSM will be added to the [Treasury](https://wiki.polkadot.com/learn/learn-polkadot-opengov-treasury/){target=\\_blank} rather than burned or distributed as rewards. Moving slashed funds to the Treasury allows tokens to be quickly moved away from malicious validators while maintaining the ability to revert faulty slashes when needed.\n\nA nominator with a very large bond may nominate several validators in a single era. In this case, a slash is proportionate to the amount staked to the offending validator. Stake allocation and validator activation is controlled by the [PhragmÃ©n algorithm](https://wiki.polkadot.com/learn/learn-phragmen/#algorithm){target=\\_blank}.\n\nA validator slash creates an `unapplied` state transition. You can view pending slashes on [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Frpc.polkadot.io#/staking/slashes){target=\\_blank}. The UI will display the slash per validator, the affected nominators, and the slash amounts. The unapplied state includes a 27-day grace period during which a governance proposal can be made to reverse the slash. Once this grace period expires, the slash is applied.\n\n#### Equivocation Slash\n\nThe Web3 Foundation's [Slashing mechanisms](https://research.web3.foundation/Polkadot/security/slashing/amounts){target=\\_blank} page provides guidelines for evaluating the security threat level of different offenses and determining penalties proportionate to the threat level of the offense. Offenses requiring coordination between validators or extensive computational costs to the system will typically call for harsher penalties than those more likely to be unintentional than malicious. A description of potential offenses for each threat level and the corresponding penalties is as follows:\n\n- **Level 1**: Honest misconduct such as isolated cases of unresponsiveness.\n    - **Penalty**: Validator can be kicked out or slashed up to 0.1% of stake in the validator slot.\n- **Level 2**: Misconduct that can occur honestly but is a sign of bad practices. Examples include repeated cases of unresponsiveness and isolated cases of equivocation.\n    - **Penalty**: Slash of up to 1% of stake in the validator slot.\n- **Level 3**: Misconduct that is likely intentional but of limited effect on the performance or security of the network. This level will typically include signs of coordination between validators. Examples include repeated cases of equivocation or isolated cases of unjustified voting on GRANDPA.\n    - **Penalty**: Reduction in networking reputation metrics, slash of up to 10% of stake in the validator slot.\n- **Level 4**: Misconduct that poses severe security or monetary risk to the system or mass collusion. Examples include signs of extensive coordination, creating a serious security risk to the system, or forcing the system to use extensive resources to counter the misconduct.\n    - **Penalty**: Slash of up to 100% of stake in the validator slot.\n\nSee the next section to understand how slash amounts for equivocations are calculated. If you want to know more details about slashing, please look at the research page on [Slashing mechanisms](https://research.web3.foundation/Polkadot/security/slashing/amounts){target=\\_blank}.\n\n#### Slash Calculation for Equivocation\n\nThe slashing penalty for GRANDPA, BABE, and BEEFY equivocations is calculated using the formula below, where `x` represents the number of offenders and `n` is the total number of validators in the active set:\n\n```text\nmin((3 * x / n )^2, 1)\n```\n\nThe following scenarios demonstrate how this formula means slash percentages can increase exponentially based on the number of offenders involved compared to the size of the validator pool:\n\n- **Minor offense**: Assume 1 validator out of a 100 validator active set equivocates in a slot. A single validator committing an isolated offense is most likely a mistake rather than malicious attack on the network. This offense results in a 0.09% slash to the stake in the validator slot.\n\n    ``` mermaid\n    flowchart LR\n    N[\"Total Validators = 100\"]\n    X[\"Offenders = 1\"]\n    F[\"min((3 * 1 / 100)^2, 1) = 0.0009\"]\n    G[\"0.09% slash of stake\"]\n\n    N --> F\n    X --> F\n    F --> G\n    ```\n\n- **Moderate offense**: Assume 5 validators out a 100 validator active set equivocate in a slot. This is a slightly more serious event as there may be some element of coordination involved. This offense results in a 2.25% slash to the stake in the validator slot.\n\n    ``` mermaid\n    flowchart LR\n    N[\"Total Validators = 100\"]\n    X[\"Offenders = 5\"]\n    F[\"min((3 * 5 / 100)^2, 1) = 0.0225\"]\n    G[\"2.25% slash of stake\"]\n\n    N --> F\n    X --> F\n    F --> G\n    ```\n\n- **Major offense**: Assume 20 validators out a 100 validator active set equivocate in a slot. This is a major security threat as it possible represents a coordinated attack on the network. This offense results in a 36% slash and all slashed validators will also be chilled.\n    ``` mermaid\n    flowchart LR\n    N[\"Total Validators = 100\"]\n    X[\"Offenders = 20\"]\n    F[\"min((3 * 20 / 100)^2, 1) = 0.36\"]\n    G[\"36% slash of stake\"]\n\n    N --> F\n    X --> F\n    F --> G\n    ```\n\nThe examples above show the risk of nominating or running many validators in the active set. While rewards grow linearly (two validators will get you approximately twice as many staking rewards as one), slashing grows exponentially. Going from a single validator equivocating to two validators equivocating causes a slash four time as much as the single validator.\n\nValidators may run their nodes on multiple machines to ensure they can still perform validation work if one of their nodes goes down. Still, validator operators should be cautious when setting these up. Equivocation is possible if they don't coordinate well in managing signing machines.\n\n#### Best Practices to Avoid Slashing\n\nThe following are advised to node operators to ensure that they obtain pristine binaries or source code and to ensure the security of their node:\n\n- Always download either source files or binaries from the official Parity repository.\n- Verify the hash of downloaded files.\n- Use the W3F secure validator setup or adhere to its principles.\n- Ensure essential security items are checked, use a firewall, manage user access, use SSH certificates.\n- Avoid using your server as a general-purpose system. Hosting a validator on your workstation or one that hosts other services increases the risk of maleficence.\n- Avoid cloning servers (copying all contents) when migrating to new hardware. If an image is needed, create it before generating keys.\n- High Availability (HA) systems are generally not recommended as equivocation may occur if concurrent operations happenâ€”such as when a failed server restarts or two servers are falsely online simultaneously.\n- Copying the keystore folder when moving a database between instances can cause equivocation. Even brief use of duplicated keystores can result in slashing.\n\nBelow are some examples of small equivocations that happened in the past:\n\n| Network  | Era  | Event Type         | Details                                                                                                                                                                                                                                                                                                                                                             | Action Taken                                                                                                                      |\n|----------|------|--------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|\n| Polkadot | 774  | Small Equivocation | [The validator](https://matrix.to/#/!NZrbtteFeqYKCUGQtr:matrix.parity.io/$165562246360408hKCfC:matrix.org?via=matrix.parity.io&via=corepaper.org&via=matrix.org){target=\\_blank} migrated servers and cloned the keystore folder. The on-chain event can be viewed on [Subscan](https://polkadot.subscan.io/extrinsic/11190109-0?event=11190109-5){target=\\_blank}. | The validator didn't submit a request for the slash to be canceled.                                                               |\n| Kusama   | 3329 | Small Equivocation | The validator operated a test machine with cloned keys. The test machine was online simultaneously as the primary, which resulted in a slash.                                                                                                                                                                                                                       | The validator requested a slash cancellation, but the council declined.                                                           |\n| Kusama   | 3995 | Small Equivocation | The validator noticed several errors, after which the client crashed, and a slash was applied. The validator recorded all events and opened GitHub issues to allow for technical opinions to be shared.                                                                                                                                                             | The validator requested to cancel the slash. The council approved the request as they believed the error wasn't operator-related. |\n\n#### Slashing Across Eras\n\nThere are three main difficulties to account for with slashing in NPoS:\n\n- A nominator can nominate multiple validators and be slashed as a result of actions taken by any of them.\n- Until slashed, the stake is reused from era to era.\n- Slashable offenses can be found after the fact and out of order.\n\nTo balance this, the system applies only the maximum slash a participant can receive in a given time period rather than the sum. This ensures protection from excessive slashing."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 6, "depth": 3, "title": "Disabling", "anchor": "disabling", "start_char": 13705, "end_char": 14617, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "### Disabling\n\nThe disabling mechanism is triggered when validators commit serious infractions, such as backing invalid blocks or engaging in equivocations. Disabling stops validators from performing specific actions after they have committed an offense. Disabling is further divided into:\n\n- **On-chain disabling**: Lasts for a whole era and stops validators from authoring blocks, backing, and initiating a dispute.\n- **Off-chain disabling**: Lasts for a session, is caused by losing a dispute, and stops validators from initiating a dispute.\n\nOff-chain disabling is always a lower priority than on-chain disabling. Off-chain disabling prioritizes disabling first backers and then approval checkers.\n\nThe material in this guide reflects the changes introduced in Stage 4. For more details, see the [State of Disabling issue](https://github.com/paritytech/polkadot-sdk/issues/4359){target=\\_blank} on GitHub."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 7, "depth": 3, "title": "Reputation Changes", "anchor": "reputation-changes", "start_char": 14617, "end_char": 15241, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "### Reputation Changes\n\nSome minor offenses, such as spamming, are only punished by networking reputation changes. Validators use a reputation metric when choosing which peers to connect with. The system adds reputation if a peer provides valuable data and behaves appropriately. If they provide faulty or spam data, the system reduces their reputation. If a validator loses enough reputation, their peers will temporarily close their channels to them. This helps in fighting against Denial of Service (DoS) attacks. Performing validator tasks under reduced reputation will be harder, resulting in lower validator rewards."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-offenses-and-slashes", "page_title": "Offenses and Slashes", "index": 8, "depth": 3, "title": "Penalties by Offense", "anchor": "penalties-by-offense", "start_char": 15241, "end_char": 15427, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Penalties by Offense\n\nRefer to the Polkadot Wiki's [offenses page](https://wiki.polkadot.com/learn/learn-offenses/){target=\\_blank} for a summary of penalties for specific offenses."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-rewards", "page_title": "Rewards Payout", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 621, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUnderstanding how rewards are distributed to validators and nominators is essential for network participants. In Polkadot and Kusama, validators earn rewards based on their era points, which are accrued through actions like block production and parachain validation.\n\nThis guide explains the payout scheme, factors influencing rewards, and how multiple validators affect returns. Validators can also share rewards with nominators, who contribute by staking behind them. By following the payout mechanics, validators can optimize their earnings and better engage with their nominators."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-rewards", "page_title": "Rewards Payout", "index": 1, "depth": 2, "title": "Era Points", "anchor": "era-points", "start_char": 621, "end_char": 1497, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## Era Points\n\nThe Polkadot ecosystem measures its reward cycles in a unit called an era. Kusama eras are approximately 6 hours long, and Polkadot eras are 24 hours long. At the end of each era, validators are paid proportionally to the amount of era points they have collected. Era points are reward points earned for payable actions like:\n\n- Issuing validity statements for parachain blocks.\n    \n- Producing a non-uncle block in the relay chain.\n- Producing a reference to a previously unreferenced uncle block.\n- Producing a referenced uncle block.\n\nAn uncle block is a relay chain block that is valid in every regard but has failed to become canonical. This can happen when two or more validators are block producers in a single slot, and the block produced by one validator reaches the next block producer before the others. The lagging blocks are called uncle blocks."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-rewards", "page_title": "Rewards Payout", "index": 2, "depth": 2, "title": "Reward Variance", "anchor": "reward-variance", "start_char": 1497, "end_char": 4038, "estimated_token_count": 564, "token_estimator": "heuristic-v1", "text": "## Reward Variance\n\nRewards in Polkadot and Kusama staking systems can fluctuate due to differences in era points earned by para-validators and non-para-validators. Para-validators generally contribute more to the overall reward distribution due to their role in validating parachain blocks, thus influencing the variance in staking rewards.\n\nTo illustrate this relationship:\n\n- Para-validator era points tend to have a higher impact on the expected value of staking rewards compared to non-para-validator points.\n- The variance in staking rewards increases as the total number of validators grows relative to the number of para-validators.\n- In simpler terms, when more validators are added to the active set without increasing the para-validator pool, the disparity in rewards between validators becomes more pronounced.\n\nHowever, despite this increased variance, rewards tend to even out over time due to the continuous rotation of para-validators across eras. The network's design ensures that over multiple eras, each validator has an equal opportunity to participate in para-validation, eventually leading to a balanced distribution of rewards.\n\n??? interface \"Probability in Staking Rewards\"\n\n    This should only serve as a high-level overview of the probabilistic nature for staking rewards.\n\n    Let:\n\n    - `pe` = para-validator era points\n    - `ne` = non-para-validator era points\n    - `EV` = expected value of staking rewards\n\n    Then, `EV(pe)` has more influence on the `EV` than `EV(ne)`.\n\n    Since `EV(pe)` has a more weighted probability on the `EV`, the increase in variance against the `EV` becomes apparent between the different validator pools (aka. validators in the active set and the ones chosen to para-validate).\n\n    Also, let:\n\n    - `v` = the variance of staking rewards\n    - `p` = number of para-validators\n    - `w` = number validators in the active set\n    - `e` = era\n\n    Then, `v` &#8593; if `w` &#8593;, as this reduces `p` : `w`, with respect to `e`.\n\n    Increased `v` is expected, and initially keeping `p` &#8595; using the same para-validator set for all parachains ensures [availability](https://spec.polkadot.network/chapter-anv){target=\\_blank} and [voting](https://wiki.polkadot.com/learn/learn-polkadot-opengov/){target=\\_blank}. In addition, despite `v` &#8593; on an `e` to `e` basis, over time, the amount of rewards each validator receives will equal out based on the continuous selection of para-validators.\n\n    There are plans to scale the active para-validation set in the future."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-rewards", "page_title": "Rewards Payout", "index": 3, "depth": 2, "title": "Payout Scheme", "anchor": "payout-scheme", "start_char": 4038, "end_char": 5459, "estimated_token_count": 328, "token_estimator": "heuristic-v1", "text": "## Payout Scheme\n\nValidator rewards are distributed equally among all validators in the active set, regardless of the total stake behind each validator. However, individual payouts may differ based on the number of era points a validator has earned. Although factors like network connectivity can affect era points, well-performing validators should accumulate similar totals over time.\n\nValidators can also receive tips from users, which incentivize them to include certain transactions in their blocks. Validators retain 100% of these tips.\n\nRewards are paid out in the network's native token (DOT for Polkadot and KSM for Kusama). \n\nThe following example illustrates a four member validator set with their names, amount they have staked, and how payout of rewards is divided. This scenario assumes all validators earned the same amount of era points and no one received tips: \n\n``` mermaid\nflowchart TD\n    A[\"Alice (18 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    D[\"Dave (7 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> D\n```\n\nNote that this is different than most other Proof of Stake (PoS) systems. As long as a validator is in the validator set, it will receive the same block reward as every other validator. Validator Alice, who had 18 DOT staked, received the same 2 DOT reward in this era as Dave, who had only 7 DOT staked."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-rewards", "page_title": "Rewards Payout", "index": 4, "depth": 2, "title": "Running Multiple Validators", "anchor": "running-multiple-validators", "start_char": 5459, "end_char": 7070, "estimated_token_count": 423, "token_estimator": "heuristic-v1", "text": "## Running Multiple Validators\n\nRunning multiple validators can offer a more favorable risk/reward ratio compared to running a single one. If you have sufficient DOT or nominators staking on your validators, maintaining multiple validators within the active set can yield higher rewards.\n\nIn the preceding section, with 18 DOT staked and no nominators, Alice earned 2 DOT in one era. This example uses DOT, but the same principles apply for KSM on the Kusama network. By managing stake across multiple validators, you can potentially increase overall returns. Recall the set of validators from the preceding section:\n\n``` mermaid\nflowchart TD\n    A[\"Alice (18 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    D[\"Dave (7 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> D \n```\n\nNow, assume Alice decides to split their stake and run two validators, each with a nine DOT stake. This validator set only has four spots and priority is given to validators with a larger stake. In this example, Dave has the smallest stake and loses his spot in the validator set. Now, Alice will earn two shares of the total payout each era as illustrated below:\n\n``` mermaid\nflowchart TD\n    A[\"Alice (9 DOT)\"]\n    F[\"Alice (9 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> F \n```\n\nWith enough stake, you could run more than two validators. However, each validator must have enough stake behind it to maintain a spot in the validator set."}
{"page_id": "node-infrastructure-run-a-validator-staking-mechanics-rewards", "page_title": "Rewards Payout", "index": 5, "depth": 2, "title": "Nominators and Validator Payments", "anchor": "nominators-and-validator-payments", "start_char": 7070, "end_char": 10907, "estimated_token_count": 990, "token_estimator": "heuristic-v1", "text": "## Nominators and Validator Payments\n\nA nominator's stake allows them to vote for validators and earn a share of the rewards without managing a validator node. Although staking rewards depend on validator activity during an era, validators themselves never control or own nominator rewards. To trigger payouts, anyone can call the `staking.payoutStakers` or `staking.payoutStakerByPage` methods, which mint and distribute rewards directly to the recipients. This trustless process ensures nominators receive their earned rewards.\n\nValidators set a commission rate as a percentage of the block reward, affecting how rewards are shared with nominators. A 0% commission means the validator keeps only rewards from their self-stake, while a 100% commission means they retain all rewards, leaving none for nominators.\n\nThe following examples model splitting validator payments between nominator and validator using various commission percentages. For simplicity, these examples assume a Polkadot-SDK based relay chain that uses DOT as a native token and a single nominator per validator. Calculations of KSM reward payouts for Kusama follow the same formula. \n\nStart with the original validator set from the previous section: \n\n``` mermaid\nflowchart TD\n    A[\"Alice (18 DOT)\"]\n    B[\"Bob (9 DOT)\"]\n    C[\"Carol (8 DOT)\"]\n    D[\"Dave (7 DOT)\"]\n    E[\"Payout (8 DOT total)\"]\n    E --\"2 DOT\"--> A\n    E --\"2 DOT\"--> B\n    E --\"2 DOT\"--> C\n    E --\"2 DOT\"--> D \n```\n\nThe preceding diagram shows each validator receiving a 2 DOT payout, but doesn't account for sharing rewards with nominators. The following diagram shows what nominator payout might look like for validator Alice. Alice has a 20% commission rate and holds 50% of the stake for their validator:\n\n``` mermaid\n\nflowchart TD\n    A[\"Gross Rewards = 2 DOT\"]\n    E[\"Commission = 20%\"]\n    F[\"Alice Validator Payment = 0.4 DOT\"]\n    G[\"Total Stake Rewards = 1.6 DOT\"]\n    B[\"Alice Validator Stake = 18 DOT\"]\n    C[\"9 DOT Alice (50%)\"]\n    H[\"Alice Stake Reward = 0.8 DOT\"]\n    I[\"Total Alice Validator Reward = 1.2 DOT\"]\n    D[\"9 DOT Nominator (50%)\"]\n    J[\"Total Nominator Reward = 0.8 DOT\"]\n    \n    A --> E\n    E --(2 x 0.20)--> F\n    F --(2 - 0.4)--> G\n    B --> C\n    B --> D\n    C --(1.6 x 0.50)--> H\n    H --(0.4 + 0.8)--> I\n    D --(1.60 x 0.50)--> J\n```\n\nNotice the validator commission rate is applied against the gross amount of rewards for the era. The validator commission is subtracted from the total rewards. After the commission is paid to the validator, the remaining amount is split among stake owners according to their percentage of the total stake. A validator's total rewards for an era include their commission plus their piece of the stake rewards. \n\nNow, consider a different scenario for validator Bob where the commission rate is 40%, and Bob holds 33% of the stake for their validator:\n\n``` mermaid\n\nflowchart TD\n    A[\"Gross Rewards = 2 DOT\"]\n    E[\"Commission = 40%\"]\n    F[\"Bob Validator Payment = 0.8 DOT\"]\n    G[\"Total Stake Rewards = 1.2 DOT\"]\n    B[\"Bob Validator Stake = 9 DOT\"]\n    C[\"3 DOT Bob (33%)\"]\n    H[\"Bob Stake Reward = 0.4 DOT\"]\n    I[\"Total Bob Validator Reward = 1.2 DOT\"]\n    D[\"6 DOT Nominator (67%)\"]\n    J[\"Total Nominator Reward = 0.8 DOT\"]\n    \n    A --> E\n    E --(2 x 0.4)--> F\n    F --(2 - 0.8)--> G\n    B --> C\n    B --> D\n    C --(1.2 x 0.33)--> H\n    H --(0.8 + 0.4)--> I\n    D --(1.2 x 0.67)--> J\n```\n\nBob holds a smaller percentage of their node's total stake, making their stake reward smaller than Alice's. In this scenario, Bob makes up the difference by charging a 40% commission rate and ultimately ends up with the same total payment as Alice. Each validator will need to find their ideal balance between the amount of stake and commission rate to attract nominators while still making running a validator worthwhile."}
{"page_id": "node-infrastructure", "page_title": "Node Infrastructure", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 32, "end_char": 473, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot network relies on various types of nodes to maintain security, provide data access, and produce blocks. This section covers everything you need to know about running infrastructure for the Polkadot ecosystem.\n\nWhether you want to provide RPC endpoints for applications, produce blocks for a parachain, or secure the relay chain as a validator, this guide will help you understand your options and get started."}
{"page_id": "node-infrastructure", "page_title": "Node Infrastructure", "index": 1, "depth": 2, "title": "Node Types", "anchor": "node-types", "start_char": 473, "end_char": 488, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Node Types"}
{"page_id": "node-infrastructure", "page_title": "Node Infrastructure", "index": 2, "depth": 3, "title": "RPC Nodes", "anchor": "rpc-nodes", "start_char": 488, "end_char": 1925, "estimated_token_count": 275, "token_estimator": "heuristic-v1", "text": "### RPC Nodes\n\nRPC nodes provide API access to blockchain data without participating in consensus. They are essential infrastructure for:\n\n- **Applications and dApps**: Query blockchain state and submit transactions.\n- **Block explorers**: Index and display blockchain data.\n- **Wallets**: Check balances and broadcast transactions.\n- **Development**: Test and debug applications.\n\nRPC nodes can be run for both the relay chain and parachains, with varying levels of data retention:\n\n- **Pruned nodes**: Keep recent state and a limited number of finalized blocks. Suitable for most applications that only need the current state and recent history. More efficient in terms of storage and sync time.\n- **Archive nodes**: Maintain complete historical state and all blocks since genesis. Required for block explorers, analytics platforms, or applications that need to query historical data at any point in time.\n\n**Transaction Broadcasting**: RPC nodes play a crucial role in transaction submission and propagation. When a client submits a transaction via RPC methods like `author_submitExtrinsic`, the node validates the transaction format, adds it to its local transaction pool, and broadcasts it across the P2P network. Block producers (collators or validators) then pick up these transactions from their pools for inclusion in blocks. This makes RPC nodes the primary gateway for users and applications to interact with the blockchain."}
{"page_id": "node-infrastructure", "page_title": "Node Infrastructure", "index": 3, "depth": 3, "title": "Collators", "anchor": "collators", "start_char": 1925, "end_char": 2583, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "### Collators\n\nCollators are block producers for parachains. They perform critical functions:\n\n- **Collect transactions**: Aggregate user transactions into blocks.\n- **Produce blocks**: Create parachain block candidates.\n- **Generate and package PoV**: Generate the Proof-of-Validity containing the state transition proof and necessary witness data for validation.\n- **Submit to validators**: Send block candidates and PoVs to relay chain validators.\n\nUnlike validators, collators do not provide security guaranteesâ€”that responsibility lies with the relay chain validators. However, collators are essential for parachain liveness and censorship resistance."}
{"page_id": "node-infrastructure", "page_title": "Node Infrastructure", "index": 4, "depth": 3, "title": "Validators", "anchor": "validators", "start_char": 2583, "end_char": 3331, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "### Validators\n\nValidators secure the Polkadot relay chain through [Nominated Proof of Stake (NPoS)](https://wiki.polkadot.network/docs/learn-staking){target=\\_blank}. They:\n\n- **Validate blocks**: Verify parachain blocks and relay chain transactions.\n- **Participate in consensus**: Run [BABE](https://wiki.polkadot.network/docs/learn-consensus#babe-block-production){target=\\_blank} and [GRANDPA](https://wiki.polkadot.network/docs/learn-consensus#grandpa-finality-gadget){target=\\_blank} protocols.\n- **Earn rewards**: Receive staking rewards for honest behavior.\n- **Risk slashing**: Face penalties for misbehavior or downtime.\n\nRunning a validator requires significant technical expertise, reliable infrastructure, and a stake of DOT tokens."}
{"page_id": "node-infrastructure", "page_title": "Node Infrastructure", "index": 5, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 3331, "end_char": 3954, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\n<div class=\"grid cards\" markdown>\n\n-   **Run RPC Nodes**\n\n    ---\n\n    Provide API access for applications, explorers, and wallets.\n\n    [:octicons-arrow-right-24: Run a Node](/node-infrastructure/run-a-node/polkadot-hub-rpc/)\n\n-   **Run a Collator**\n\n    ---\n\n    Produce blocks for system parachains or your own parachain.\n\n    [:octicons-arrow-right-24: Run a Collator](/node-infrastructure/run-a-collator/)\n\n-   **Run a Validator**\n\n    ---\n\n    Secure the relay chain and earn staking rewards.\n\n    [:octicons-arrow-right-24: Run a Validator](/node-infrastructure/run-a-validator/requirements/)\n\n</div>"}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 41, "end_char": 1382, "estimated_token_count": 270, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank} provides a functional runtime that includes default [FRAME](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank} development modules ([pallets](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/pallet/index.html){target=\\_blank}) to help you get started building a custom parachain. However, you'll often need to extend your runtime by adding additional pallets to enable new functionality.\n\nEach pallet has specific configuration requirements, including the necessary parameters and types that enable its functionality. This guide walks you through the complete process of adding an existing pallet to your runtime and configuring it properly using `pallet-utility` as a practical example.\n\nThe Utility pallet offers batch transaction capabilities, enabling multiple calls to be dispatched together, as well as origin manipulation functionality for advanced use cases.\n\nIn this guide, you'll learn how to:\n\n- Update runtime dependencies to integrate a new pallet\n- Configure pallet-specific Rust traits to enable the pallet's functionality\n- Run your parachain locally to test the new pallet"}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 1, "depth": 2, "title": "Check Prerequisites", "anchor": "check-prerequisites", "start_char": 1382, "end_char": 1664, "estimated_token_count": 72, "token_estimator": "heuristic-v1", "text": "## Check Prerequisites\n\nBefore you begin, ensure you have:\n\n- [Polkadot SDK dependencies installed](/parachains/install-polkadot-sdk/){target=\\_blank}\n- A working [Polkadot SDK development environment](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank}"}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 2, "depth": 2, "title": "Add an Existing Polkadot SDK Pallet to Your Runtime", "anchor": "add-an-existing-polkadot-sdk-pallet-to-your-runtime", "start_char": 1664, "end_char": 1898, "estimated_token_count": 39, "token_estimator": "heuristic-v1", "text": "## Add an Existing Polkadot SDK Pallet to Your Runtime\n\nAdding a pallet to your parachain runtime involves configuring dependencies, implementing the pallet's configuration trait, and registering the pallet in the runtime construct."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 3, "depth": 3, "title": "Add an Existing Pallet as a Dependency", "anchor": "add-an-existing-pallet-as-a-dependency", "start_char": 1898, "end_char": 3227, "estimated_token_count": 346, "token_estimator": "heuristic-v1", "text": "### Add an Existing Pallet as a Dependency\n\nThe Polkadot SDK utilizes a monorepo structure, where multiple pallets are available as features of theÂ `polkadot-sdk`Â dependency. A list of pallets can be found in the [`substrate/frame` directory](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame){target=\\_blank} of the Polkadot SDK repository.\n\nFor [`pallet-utility`](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/utility){target=\\_blank}, you need to add it as a dependency in the features array:\n\n1. Open the `runtime/Cargo.toml` file.\n2. Locate the `[dependencies]` section.\n3. Find the `polkadot-sdk` dependency.\n4. Add `pallet-utility` to the features array:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    polkadot-sdk = { workspace = true, features = [\n        \"pallet-utility\",\n        \"cumulus-pallet-aura-ext\",\n        \"cumulus-pallet-session-benchmarking\",\n        # ... other features\n    ], default-features = false }\n    ```\n\n!!! note\n    If you're adding a custom pallet that isn't part of the Polkadot SDK, you would add it as a separate dependency:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    custom-pallet = { path = \"../pallets/custom-pallet\", default-features = false }\n    ```\n\n    Ensure it's included in the workspace members section of the root `Cargo.toml` file."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 4, "depth": 3, "title": "Enable Standard Library Features", "anchor": "enable-standard-library-features", "start_char": 3227, "end_char": 4335, "estimated_token_count": 276, "token_estimator": "heuristic-v1", "text": "### Enable Standard Library Features\n\nThe Polkadot SDK runtime compiles to both a native binary (for running unit tests), which includes standard Rust library functions, and a WebAssembly (Wasm) binary (a more compact size for production use), which does not include the standard library. Since `pallet-utility` is part of the `polkadot-sdk` dependency, its `std` feature is already included when you enable `polkadot-sdk/std`.\n\nTo verify that the standard library features are enabled:\n\n1. In the `runtime/Cargo.toml` file, locate the `[features]` section.\n2. Ensure `polkadot-sdk/std` is included in the `std` array:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    [features]\n    default = [\"std\"]\n    std = [\n        \"codec/std\",\n        \"cumulus-pallet-parachain-system/std\",\n        \"log/std\",\n        \"polkadot-sdk/std\",\n        \"scale-info/std\",\n        # ... other features\n    ]\n    ```\n\n!!! note\n    If you're adding a custom pallet, you must explicitly add its `std` feature:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    std = [\n        # ... other features\n        \"custom-pallet/std\",\n    ]\n    ```"}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 5, "depth": 3, "title": "Review the Config Trait", "anchor": "review-the-config-trait", "start_char": 4335, "end_char": 6095, "estimated_token_count": 393, "token_estimator": "heuristic-v1", "text": "### Review the Config Trait\n\nEvery pallet defines a Rust trait called `Config` that specifies the types and parameters needed for the pallet to function within a runtime. Before implementing the configuration, you should understand what the pallet requires.\n\nThe `pallet-utility` Config trait requires the following types:\n\n```rust\npub trait Config: frame_system::Config {\n    /// The overarching event type\n    type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n    /// The overarching call type\n    type RuntimeCall: Parameter \n        + Dispatchable<RuntimeOrigin = Self::RuntimeOrigin>\n        + GetDispatchInfo\n        + From<frame_system::Call<Self>>;\n\n    /// The caller origin, overarching type of all pallets origins\n    type PalletsOrigin: Parameter + Into<<Self as frame_system::Config>::RuntimeOrigin>;\n\n    /// Weight information for extrinsics in this pallet\n    type WeightInfo: WeightInfo;\n}\n```\n\nThis configuration requires:\n\n- **`RuntimeEvent`**: Links the pallet's events to the runtime's event system.\n- **`RuntimeCall`**: Allows the utility pallet to dispatch calls from other pallets, which is needed for batch operations.\n- **`PalletsOrigin`**: Enables origin manipulation for dispatching calls as other pallets.\n- **`WeightInfo`**: Provides weight calculations for pallet operations.\n\n!!! tip\n    You can view a pallet's `Config` trait requirements in the [Polkadot SDK Rust docs](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/index.html){target=\\_blank}. Search for the pallet's name and check the type defined by its [`Config`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/your_first_pallet/pallet/trait.Config.html){target=\\_blank} trait."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 6, "depth": 3, "title": "Implement the Config Trait", "anchor": "implement-the-config-trait", "start_char": 6095, "end_char": 6728, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### Implement the Config Trait\n\nNow you'll implement the pallet's `Config` trait in your runtime to provide the concrete types the pallet needs.\n\nTo implement the Config trait:\n\n1. Open the `runtime/src/configs/mod.rs` file.\n2. Add the following implementation at the end of the file:\n\n    ```rust title=\"runtime/src/configs/mod.rs\"\n    /// Configure the utility pallet\n    impl pallet_utility::Config for Runtime {\n        type RuntimeEvent = RuntimeEvent;\n        type RuntimeCall = RuntimeCall;\n        type PalletsOrigin = OriginCaller;\n        type WeightInfo = pallet_utility::weights::SubstrateWeight<Runtime>;\n    }\n    ```"}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 7, "depth": 3, "title": "Add to Runtime Construct", "anchor": "add-to-runtime-construct", "start_char": 6728, "end_char": 8494, "estimated_token_count": 350, "token_estimator": "heuristic-v1", "text": "### Add to Runtime Construct\n\nThe final step is to register the pallet in the runtime construct using the [`#[frame_support::runtime]` macro](https://paritytech.github.io/polkadot-sdk/master/frame_support/attr.runtime.html){target=\\_blank}. This macro generates the necessary boilerplate code for including pallets in the runtime.\n\nTo add the pallet to the runtime construct:\n\n1. Open the `runtime/src/lib.rs` file.\n2. Locate the `#[frame_support::runtime]` section (usually near the end of the file).\n3. Add your pallet with a unique `pallet_index`:\n\n    ```rust title=\"runtime/src/lib.rs\"\n    #[frame_support::runtime]\n    mod runtime {\n        #[runtime::runtime]\n        #[runtime::derive(\n            RuntimeCall,\n            RuntimeEvent,\n            RuntimeError,\n            RuntimeOrigin,\n            RuntimeTask,\n            RuntimeFreezeReason,\n            RuntimeHoldReason,\n            RuntimeSlashReason,\n            RuntimeLockId,\n            RuntimeViewFunction\n        )]\n        pub struct Runtime;\n\n        #[runtime::pallet_index(0)]\n        pub type System = frame_system;\n\n        #[runtime::pallet_index(1)]\n        pub type ParachainSystem = cumulus_pallet_parachain_system;\n\n        #[runtime::pallet_index(2)]\n        pub type Timestamp = pallet_timestamp;\n\n        // ... other pallets\n\n        #[runtime::pallet_index(50)]\n        pub type Utility = pallet_utility;\n    }\n    ```\n\nWhen adding the pallet:\n\n- Assign a unique `pallet_index` that doesn't conflict with existing pallets. The index determines the pallet's position in the runtime.\n- Use a descriptive name for the pallet instance, such as `Utility` for `pallet_utility`.\n\n!!! warning\n    Each pallet must have a unique index. Duplicate indices will cause compilation errors."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 8, "depth": 3, "title": "Verify the Runtime Compiles", "anchor": "verify-the-runtime-compiles", "start_char": 8494, "end_char": 8968, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "### Verify the Runtime Compiles\n\nAfter adding and configuring your pallet in the runtime, verify that everything is set up correctly by compiling the runtime.\n\nTo compile the runtime:\n\n1. Navigate to the root directory of your project.\n2. Run the following command:\n\n    ```bash\n    cargo build --release\n    ```\n\n3. Ensure the build completes successfully without errors.\n\nThis command validates the pallet configurations and prepares the build for testing or deployment."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 9, "depth": 2, "title": "Run Your Chain Locally", "anchor": "run-your-chain-locally", "start_char": 8968, "end_char": 9494, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "## Run Your Chain Locally\n\nNow that you've added the pallet to your runtime, you can launch your parachain locally to test the new functionality using the [Polkadot Omni Node](https://crates.io/crates/polkadot-omni-node){target=\\_blank}. For instructions on setting up the Polkadot Omni Node and [Polkadot Chain Spec Builder](https://crates.io/crates/staging-chain-spec-builder){target=\\_blank}, refer to the [Set Up a Parachain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank} guide."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 10, "depth": 3, "title": "Generate a Chain Specification", "anchor": "generate-a-chain-specification", "start_char": 9494, "end_char": 10049, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "### Generate a Chain Specification\n\nCreate a new chain specification file with the updated runtime by running the following command from your project's root directory using the `chain-spec-builder` tool:\n\n```bash\nchain-spec-builder create -t development \\\n--relay-chain paseo \\\n--para-id 1000 \\\n--runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\nnamed-preset development\n```\n\nThis command generates a chain specification file, `chain_spec.json`, for your parachain with the updated runtime."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 11, "depth": 3, "title": "Start the Parachain Node", "anchor": "start-the-parachain-node", "start_char": 10049, "end_char": 10333, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "### Start the Parachain Node\n\nLaunch the parachain using the Polkadot Omni Node with the generated chain specification by running the following command:\n\n```bash\npolkadot-omni-node --chain ./chain_spec.json --dev\n```\n\nVerify the node starts successfully and begins producing blocks."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 12, "depth": 3, "title": "Interact with the Pallet", "anchor": "interact-with-the-pallet", "start_char": 10333, "end_char": 11300, "estimated_token_count": 273, "token_estimator": "heuristic-v1", "text": "### Interact with the Pallet\n\nUse the Polkadot.js Apps interface to verify you can interact with the new pallet.\n\nTo interact with the pallet:\n\n1. Navigate to [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/extrinsics){target=\\_blank}.\n2. Ensure you're connected to your local node at `ws://127.0.0.1:9944`.\n3. Go to the **Developer** > **Extrinsics** tab.\n4. In the **submit the following extrinsic** section, locate **utility** in the pallet dropdown.\n5. Verify you can see the available extrinsics, such as:\n    - **`batch(calls)`**: Dispatch multiple calls in a single transaction.\n    - **`batchAll(calls)`**: Dispatch multiple calls, stopping on the first error.\n    - **`asDerivative(index, call)`**: Dispatch a call as a derivative account.\n\n    ![](/images/parachains/customize-runtime/add-existing-pallets/add-pallets-01.webp)\n\nYou can now test the pallet's functionality by submitting transactions through the interface."}
{"page_id": "parachains-customize-runtime-add-existing-pallets", "page_title": "Add an Existing Pallet to the Runtime", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 11300, "end_char": 11893, "estimated_token_count": 151, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Add Multiple Pallet Instances__\n\n    ---\n\n    Learn how to implement multiple instances of the same pallet in your Polkadot SDK-based runtime.\n\n    [:octicons-arrow-right-24: Get Started](/parachains/customize-runtime/add-pallet-instances/)\n\n-   <span class=\"badge guide\">Guide</span> __Make a Custom Pallet__\n\n    ---\n\n    Learn how to create custom pallets using FRAME.\n\n    [:octicons-arrow-right-24: Get Started](/parachains/customize-runtime/pallet-development/create-a-pallet/)\n\n</div>"}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 33, "end_char": 1429, "estimated_token_count": 257, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank} provides a solid foundation for building custom parachains. While most pallets are typically included as single instances within a runtime, some scenarios benefit from running multiple instances of the same pallet with different configurations. This approach lets you reuse pallet logic without reimplementing it, enabling diverse functionality from a single codebase.\n\nFor example, you could create multiple governance councils with different voting rules, or several token systems with distinct parameters. The Polkadot SDK makes this possible through instantiable pallets, which allow multiple independent instances of the same pallet to coexist within a runtime.\n\nThis guide demonstrates how to add and configure multiple instances of a pallet to your runtime using [`pallet-collective`](https://paritytech.github.io/polkadot-sdk/master/pallet_collective/index.html){target=\\_blank} as a practical example. The same process applies to other instantiable pallets.\n\nIn this guide, you'll learn how to:\n\n- Identify instantiable pallets and understand their structure.\n- Configure multiple instances of the same pallet with unique parameters.\n- Register multiple pallet instances in your runtime.\n- Run your parachain locally to test multiple pallet instances."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 1, "depth": 2, "title": "Check Prerequisites", "anchor": "check-prerequisites", "start_char": 1429, "end_char": 1746, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Check Prerequisites\n\nBefore you begin, ensure you have:\n\n- A working [Polkadot SDK development environment](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank}.\n- Basic understanding of [adding pallets to a runtime](/parachains/customize-runtime/add-existing-pallets/){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 2, "depth": 2, "title": "Understanding Instantiable Pallets", "anchor": "understanding-instantiable-pallets", "start_char": 1746, "end_char": 2047, "estimated_token_count": 46, "token_estimator": "heuristic-v1", "text": "## Understanding Instantiable Pallets\n\nNot all pallets support multiple instances. Instantiable pallets are specifically designed to allow multiple independent copies within the same runtime. These pallets include an additional generic parameter `I` that creates a unique identity for each instance."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 3, "depth": 3, "title": "Identifying an Instantiable Pallet", "anchor": "identifying-an-instantiable-pallet", "start_char": 2047, "end_char": 2700, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "### Identifying an Instantiable Pallet\n\nYou can identify an instantiable pallet by examining its `Pallet` struct definition. An instantiable pallet will include both the standard generic `T` (for the runtime configuration) and the instantiation generic `I`:\n\n```rust\n#[pallet::pallet]\npub struct Pallet<T, I = ()>(PhantomData<(T, I)>);\n```\n\nThe `I` generic parameter:\n\n- Creates a unique type identity for each pallet instance.\n- Appears throughout the pallet's components (`Config` trait, storage items, events, errors).\n- Defaults to `()` (unit type) when only one instance is needed.\n- Must be explicitly specified when creating multiple instances."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 4, "depth": 3, "title": "How Instance Generics Work", "anchor": "how-instance-generics-work", "start_char": 2700, "end_char": 3241, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### How Instance Generics Work\n\nThe instantiation generic `I` affects how the pallet's types are structured:\n\n- **`Config` trait**: `trait Config<I: 'static = ()>` - accepts the instance parameter.\n- **Storage items**: Automatically namespaced by instance to prevent conflicts.\n- **Events**: `Event<T, I>` - includes instance information.\n- **Calls**: `Call<T, I>` - dispatched to the correct instance.\n\nThis design ensures that multiple instances of the same pallet maintain completely separate states and don't interfere with each other."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 5, "depth": 2, "title": "Add Multiple Instances of a Pallet to Your Runtime", "anchor": "add-multiple-instances-of-a-pallet-to-your-runtime", "start_char": 3241, "end_char": 3644, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Add Multiple Instances of a Pallet to Your Runtime\n\nAdding multiple pallet instances involves the same basic steps as adding a single pallet, but with specific configuration for each instance.\n\nIn this example, you'll add two instances of [`pallet-collective`](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/collective){target=\\_blank} to create different governance bodies."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 6, "depth": 3, "title": "Add the Pallet as a Dependency", "anchor": "add-the-pallet-as-a-dependency", "start_char": 3644, "end_char": 4276, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "### Add the Pallet as a Dependency\n\nFirst, ensure the instantiable pallet is available in your runtime dependencies. For `pallet-collective`, add it as a feature of the `polkadot-sdk` dependency:\n\n1. Open the `runtime/Cargo.toml` file.\n2. Locate the `[dependencies]` section.\n3. Find the `polkadot-sdk` dependency.\n4. Add `pallet-collective` to the features array:\n\n    ```toml title=\"Cargo.toml\"\n    polkadot-sdk = { workspace = true, features = [\n        \"pallet-collective\",\n        \"cumulus-pallet-aura-ext\",\n        \"cumulus-pallet-session-benchmarking\",\n        # ... other features\n    ], default-features = false }\n    ```"}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 7, "depth": 3, "title": "Enable Standard Library Features", "anchor": "enable-standard-library-features", "start_char": 4276, "end_char": 4789, "estimated_token_count": 136, "token_estimator": "heuristic-v1", "text": "### Enable Standard Library Features\n\nEnsure the pallet's standard library features are enabled for native builds:\n\n1. In the `runtime/Cargo.toml` file, locate the `[features]` section.\n2. Ensure `polkadot-sdk/std` is included in the `std` array:\n\n    ```toml title=\"Cargo.toml\"\n    [features]\n    default = [\"std\"]\n    std = [\n        \"codec/std\",\n        \"cumulus-pallet-parachain-system/std\",\n        \"log/std\",\n        \"polkadot-sdk/std\",\n        \"scale-info/std\",\n        # ... other features\n    ]\n    ```"}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 8, "depth": 3, "title": "Review the Config Trait", "anchor": "review-the-config-trait", "start_char": 4789, "end_char": 6518, "estimated_token_count": 357, "token_estimator": "heuristic-v1", "text": "### Review the Config Trait\n\nBefore configuring multiple instances, understand what the pallet requires. The `pallet-collective` `Config` trait is defined with the instance generic:\n\n```rust\npub trait Config<I: 'static = ()>: frame_system::Config {\n    /// The runtime origin type\n    type RuntimeOrigin: From<RawOrigin<Self::AccountId, I>>;\n\n    /// The runtime call type\n    type Proposal: Parameter \n        + Dispatchable<RuntimeOrigin = Self::RuntimeOrigin>\n        + From<frame_system::Call<Self>>;\n\n    /// The overarching event type\n    type RuntimeEvent: From<Event<Self, I>> \n        + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n    /// Duration in blocks for a motion to remain active\n    type MotionDuration: Get<BlockNumberFor<Self>>;\n\n    /// Maximum number of proposals allowed at once\n    type MaxProposals: Get<u32>;\n\n    /// Maximum number of members in the collective\n    type MaxMembers: Get<u32>;\n\n    /// Default voting strategy when a member abstains\n    type DefaultVote: DefaultVote;\n\n    /// Origin that can modify the members\n    type SetMembersOrigin: EnsureOrigin<Self::RuntimeOrigin>;\n\n    /// Weight information for extrinsics\n    type WeightInfo: WeightInfo;\n\n    /// Maximum weight for a proposal\n    type MaxProposalWeight: Get<Weight>;\n\n    /// Origin that can disapprove proposals\n    type DisapproveOrigin: EnsureOrigin<Self::RuntimeOrigin>;\n\n    /// Origin that can kill proposals\n    type KillOrigin: EnsureOrigin<Self::RuntimeOrigin>;\n\n    /// Consideration mechanism (e.g., deposits)\n    type Consideration: Consideration<Self::AccountId>;\n}\n```\n\nThis configuration enables the collective pallet to manage a group of accounts that can propose and vote on proposals together."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 9, "depth": 3, "title": "Define Pallet Parameters", "anchor": "define-pallet-parameters", "start_char": 6518, "end_char": 7464, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "### Define Pallet Parameters\n\nBefore implementing the `Config` trait for each instance, define the common parameters that both instances will use. These parameters are defined once and can be shared across instances or customized per instance.\n\nTo define pallet parameters:\n\n1. Open the `runtime/src/configs/mod.rs` file.\n2. Add parameter type definitions for the collective pallet:\n\n    ```rust title=\"runtime/src/configs/mod.rs\"\n    parameter_types! {\n        pub const MotionDuration: BlockNumber = 24 * HOURS;\n        pub const MaxProposals: u32 = 100;\n        pub const MaxMembers: u32 = 100;\n        pub MaxProposalWeight: Weight = Perbill::from_percent(50) * RuntimeBlockWeights::get().max_block;\n    }\n    ```\n\n!!! tip\n    You can define separate parameters for each instance if you need different configurations. For example, you might want a technical committee with a shorter motion duration and fewer members than a general council."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 10, "depth": 3, "title": "Create Instance Type Definitions", "anchor": "create-instance-type-definitions", "start_char": 7464, "end_char": 8373, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "### Create Instance Type Definitions\n\nEach pallet instance needs a unique type identifier. The Polkadot SDK provides numbered instance types (`Instance1`, `Instance2`, etc.) that you can use to create these identifiers.\n\nIn the `runtime/src/configs/mod.rs` file, add type definitions for each instance:\n\n```rust title=\"runtime/src/configs/mod.rs\"\n// Technical Committee instance\npub type TechnicalCollective = pallet_collective::Instance1;\n\n// Council instance  \npub type CouncilCollective = pallet_collective::Instance2;\n```\n\nThese type aliases:\n\n- Create distinct identities for each instance.\n- Make your code more readable and maintainable.\n- Are used when implementing the `Config` trait and adding to the runtime construct.\n\n!!! note\n    The names `TechnicalCollective` and `CouncilCollective` are descriptive examples. Choose names that reflect the purpose of each instance in your specific use case."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 11, "depth": 3, "title": "Implement Config Trait for First Instance", "anchor": "implement-config-trait-for-first-instance", "start_char": 8373, "end_char": 10156, "estimated_token_count": 377, "token_estimator": "heuristic-v1", "text": "### Implement Config Trait for First Instance\n\nNow implement the `Config` trait for your first instance. The implementation includes the instance type as a generic parameter.\n\nIn the `runtime/src/configs/mod.rs` file, add the following implementation:\n\n```rust title=\"runtime/src/configs/mod.rs\"\n/// Configure the Technical Committee collective\nimpl pallet_collective::Config<TechnicalCollective> for Runtime {\n    type RuntimeOrigin = RuntimeOrigin;\n    type Proposal = RuntimeCall;\n    type RuntimeEvent = RuntimeEvent;\n    type MotionDuration = MotionDuration;\n    type MaxProposals = MaxProposals;\n    type MaxMembers = MaxMembers;\n    type DefaultVote = pallet_collective::MoreThanMajorityThenPrimeDefaultVote;\n    type SetMembersOrigin = EnsureRoot<AccountId>;\n    type WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\n    type MaxProposalWeight = MaxProposalWeight;\n    type DisapproveOrigin = EnsureRoot<Self::AccountId>;\n    type KillOrigin = EnsureRoot<Self::AccountId>;\n    type Consideration = ();\n}\n```\n\nKey configuration details:\n\n- **`RuntimeOrigin`, `RuntimeCall`, `RuntimeEvent`**: Connect to the runtime's aggregated types.\n- **`MotionDuration`**: How long proposals remain active (5 days in this example).\n- **`MaxProposals`**: Maximum number of active proposals (100).\n- **`MaxMembers`**: Maximum collective members (100).\n- **`DefaultVote`**: Voting strategy when members abstain (majority with prime member tiebreaker).\n- **`SetMembersOrigin`**: Who can modify membership (root in this example).\n- **`MaxProposalWeight`**: Maximum computational weight for proposals (50% of block weight).\n- **`DisapproveOrigin`/`KillOrigin`**: Who can reject proposals (root in this example).\n- **`Consideration`**: Deposit mechanism (none in this example)."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 12, "depth": 3, "title": "Implement Config Trait for Second Instance", "anchor": "implement-config-trait-for-second-instance", "start_char": 10156, "end_char": 11449, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "### Implement Config Trait for Second Instance\n\nImplement the `Config` trait for your second instance with the same or a different configuration.\n\nIn the `runtime/src/configs/mod.rs` file, add the following implementation:\n\n```rust title=\"runtime/src/configs/mod.rs\"\n/// Configure the Council collective\nimpl pallet_collective::Config<CouncilCollective> for Runtime {\n    type RuntimeOrigin = RuntimeOrigin;\n    type Proposal = RuntimeCall;\n    type RuntimeEvent = RuntimeEvent;\n    type MotionDuration = MotionDuration;\n    type MaxProposals = MaxProposals;\n    type MaxMembers = MaxMembers;\n    type DefaultVote = pallet_collective::MoreThanMajorityThenPrimeDefaultVote;\n    type SetMembersOrigin = EnsureRoot<AccountId>;\n    type WeightInfo = pallet_collective::weights::SubstrateWeight<Runtime>;\n    type MaxProposalWeight = MaxProposalWeight;\n    type DisapproveOrigin = EnsureRoot<Self::AccountId>;\n    type KillOrigin = EnsureRoot<Self::AccountId>;\n    type Consideration = ();\n}\n```\n\n!!! tip\n    While this example uses identical configurations for both instances, you can customize each instance's parameters to serve different purposes. For example, you might configure the technical committee with stricter voting requirements or shorter motion durations than the general council."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 13, "depth": 3, "title": "Add Instances to Runtime Construct", "anchor": "add-instances-to-runtime-construct", "start_char": 11449, "end_char": 13334, "estimated_token_count": 360, "token_estimator": "heuristic-v1", "text": "### Add Instances to Runtime Construct\n\nThe final configuration step is registering both pallet instances in the runtime construct. Each instance needs a unique pallet index and must specify its instance type.\n\nTo add the pallet instances to the runtime construct:\n\n1. Open the `runtime/src/lib.rs` file.\n2. Locate the `#[frame_support::runtime]` section.\n3. Add both pallet instances with unique indices:\n\n    ```rust title=\"runtime/src/lib.rs\"\n    #[frame_support::runtime]\n    mod runtime {\n        #[runtime::runtime]\n        #[runtime::derive(\n            RuntimeCall,\n            RuntimeEvent,\n            RuntimeError,\n            RuntimeOrigin,\n            RuntimeTask,\n            RuntimeFreezeReason,\n            RuntimeHoldReason,\n            RuntimeSlashReason,\n            RuntimeLockId,\n            RuntimeViewFunction\n        )]\n        pub struct Runtime;\n\n        #[runtime::pallet_index(0)]\n        pub type System = frame_system;\n\n        #[runtime::pallet_index(1)]\n        pub type ParachainSystem = cumulus_pallet_parachain_system;\n\n        // ... other pallets\n\n        #[runtime::pallet_index(50)]\n        pub type TechnicalCommittee = pallet_collective<TechnicalCollective>;\n\n        #[runtime::pallet_index(51)]\n        pub type Council = pallet_collective<CouncilCollective>;\n    }\n    ```\n\nImportant considerations when adding instances:\n\n- **Unique indices**: Each instance must have a different `pallet_index`.\n- **Instance type**: Specify the instance type in angle brackets (e.g., `<TechnicalCollective>`).\n- **Descriptive names**: Use names that reflect the instance's purpose (e.g., `TechnicalCommittee`, `Council`).\n- **Index management**: Track which indices are used to avoid conflicts.\n\n!!! warning\n    Duplicate pallet indices will cause compilation errors. Keep a list of used indices to prevent conflicts when adding new pallets or instances."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 14, "depth": 3, "title": "Verify the Runtime Compiles", "anchor": "verify-the-runtime-compiles", "start_char": 13334, "end_char": 13784, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "### Verify the Runtime Compiles\n\nAfter adding and configuring both pallet instances, verify that everything is set up correctly by compiling the runtime from your project's root directory:\n\n```bash\ncargo build --release\n```\n\nEnsure the build completes successfully without errors.\n\nThis command validates:\n\n- All pallet instances are properly configured\n- No index conflicts exist\n- Type definitions are correct\n- Dependencies are properly resolved"}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 15, "depth": 2, "title": "Run Your Chain Locally", "anchor": "run-your-chain-locally", "start_char": 13784, "end_char": 14326, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Run Your Chain Locally\n\nNow that you've added multiple pallet instances to your runtime, you can launch your parachain locally to test the new functionality using the [Polkadot Omni Node](https://crates.io/crates/polkadot-omni-node){target=\\_blank}. For instructions on setting up the Polkadot Omni Node and [Polkadot Chain Spec Builder](https://crates.io/crates/staging-chain-spec-builder){target=\\_blank}, refer to the [Set Up the Parachain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank} page."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 16, "depth": 3, "title": "Generate a Chain Specification", "anchor": "generate-a-chain-specification", "start_char": 14326, "end_char": 14894, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "### Generate a Chain Specification\n\nCreate a new chain specification file with the updated runtime containing both pallet instances by running the following command from your project's root directory:\n\n```bash\nchain-spec-builder create -t development \\\n    --relay-chain paseo \\\n    --para-id 1000 \\\n    --runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    named-preset development\n```\n\nThis command generates a chain specification file (`chain_spec.json`) for your parachain with the updated runtime."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 17, "depth": 3, "title": "Start the Parachain Node", "anchor": "start-the-parachain-node", "start_char": 14894, "end_char": 15228, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "### Start the Parachain Node\n\nLaunch the parachain using the Polkadot Omni Node with the generated chain specification:\n\n```bash\npolkadot-omni-node --chain ./chain_spec.json --dev\n```\n\nVerify the node starts successfully and begins producing blocks. You should see log messages indicating that both pallet instances are initialized."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 18, "depth": 3, "title": "Interact with Both Pallet Instances", "anchor": "interact-with-both-pallet-instances", "start_char": 15228, "end_char": 16583, "estimated_token_count": 358, "token_estimator": "heuristic-v1", "text": "### Interact with Both Pallet Instances\n\nUse the Polkadot.js Apps interface to verify you can interact with both pallet instances independently.\n\nTo interact with the pallet instances:\n\n1. Navigate to [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/extrinsics){target=\\_blank}.\n2. Ensure you're connected to your local node at `ws://127.0.0.1:9944`.\n3. Go to the **Developer** > **Extrinsics** tab.\n4. In the **submit the following extrinsic** section, open the pallet dropdown. Verify that both pallet instances appear and contain the expected extrinsics.\n\n    === \"Technical Committee\"\n\n        Select **`technicalCommittee`** and open the extrinsics dropdown.\n\n        ![](/images/parachains/customize-runtime/add-pallet-instances/add-pallet-instances-01.webp)\n\n    === \"Council\"\n\n        Select **`council`** and open the extrinsics dropdown.\n\n        ![](/images/parachains/customize-runtime/add-pallet-instances/add-pallet-instances-02.webp)\n\nEach instance should display the following extrinsics (this is not an exhaustive list):\n\n- **`close(proposalHash, index, proposalWeightBound, lengthBound)`**: Close voting.\n- **`propose(threshold, proposal, lengthBound)`**: Submit a proposal.\n- **`setMembers(newMembers, prime, oldCount)`**: Update membership.\n- **`vote(proposal, index, approve)`**: Vote on a proposal."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 19, "depth": 3, "title": "Test Instance Independence", "anchor": "test-instance-independence", "start_char": 16583, "end_char": 17641, "estimated_token_count": 227, "token_estimator": "heuristic-v1", "text": "### Test Instance Independence\n\nVerify that both instances operate independently by testing their separate functionality.\n\nTo test instance independence:\n\n1. In Polkadot.js Apps, go to **Developer** > **Chain state**.\n2. Query storage for each instance:\n\n    === \"Technical Committee\"\n\n        Select **`technicalCommittee` > `members()`** to view technical committee members.\n\n        ![](/images/parachains/customize-runtime/add-pallet-instances/add-pallet-instances-03.webp)\n\n    === \"Council\"\n\n        Select **`council` > `members()`** to view council members.\n\n        ![](/images/parachains/customize-runtime/add-pallet-instances/add-pallet-instances-04.webp)\n\n3. Verify that:\n    - Each instance maintains separate storage.\n    - Changes to one instance don't affect the other.\n    - Both instances can process proposals simultaneously.\n\nYou can now use both collective instances for different governance purposes in your parachain, such as technical decisions that require expertise and general governance decisions that require broader consensus."}
{"page_id": "parachains-customize-runtime-add-pallet-instances", "page_title": "Add Multiple Pallet Instances", "index": 20, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 17641, "end_char": 17945, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Make a Custom Pallet__\n\n    ---\n\n    Learn how to create custom pallets using FRAME.\n\n    [:octicons-arrow-right-24: Reference](/parachains/customize-runtime/pallet-development/create-a-pallet/)\n\n</div>"}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 36, "end_char": 724, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhen building your custom blockchain with the Polkadot SDK, you can add smart contract capabilities through specialized pallets. These pallets enable users to deploy and execute smart contracts, enhancing your chain's programmability and allowing developers to build decentralized applications on your network.\n\nThis guide covers three approaches to adding smart contracts to your blockchain:\n\n- **[`pallet-revive`](#pallet-revive)**: Modern unified solution supporting both PolkaVM and EVM bytecode\n- **[Frontier](#frontier)**: Ethereum compatibility layer for Polkadot SDK-based chains\n- **[`pallet-contracts`](#pallet-contracts-legacy)**: Wasm smart contract support"}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 1, "depth": 2, "title": "pallet-revive", "anchor": "pallet-revive", "start_char": 724, "end_char": 1046, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "## pallet-revive\n\n[`pallet-revive`](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/revive){target=\\_blank} is the modern smart contract solution for Polkadot SDK-based chains. It provides a unified execution environment that supports both PolkaVM and EVM bytecode through dual execution backends."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 2, "depth": 3, "title": "Core Components", "anchor": "core-components", "start_char": 1046, "end_char": 1841, "estimated_token_count": 230, "token_estimator": "heuristic-v1", "text": "### Core Components\n\n**Essential Pallet:**\n**[`pallet-revive`](https://github.com/paritytech/polkadot-sdk/tree/master/substrate/frame/revive){target=\\_blank}** provides the core smart contract execution environment with [PolkaVM](https://github.com/polkadot-developers/polkadot-docs/blob/71e1b51bb42ef55e20c2f3b953db86e8c26cd591/smart-contracts/for-eth-devs/dual-vm-stack.md#upgrade-to-polkavm){target=\\_blank} and [REVM](https://github.com/polkadot-developers/polkadot-docs/blob/71e1b51bb42ef55e20c2f3b953db86e8c26cd591/smart-contracts/for-eth-devs/dual-vm-stack.md#migrate-from-evm){target=\\_blank} backends.\n\n**RPC Adapter:**\n**[`pallet-revive-eth-rpc`](https://crates.io/crates/pallet-revive-eth-rpc){target=\\_blank}** adds full Ethereum RPC compatibility for Ethereum tooling integration."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 3, "depth": 3, "title": "Supported Languages and Compilers", "anchor": "supported-languages-and-compilers", "start_char": 1841, "end_char": 2463, "estimated_token_count": 196, "token_estimator": "heuristic-v1", "text": "### Supported Languages and Compilers\n\n`pallet-revive` accepts smart contracts from multiple languages and compilation paths:\n\n| Language | Compiler | Output Bytecode | Execution Backend |\n|----------|----------|-----------------|-------------------|\n| Solidity | `resolc` | PolkaVM | PolkaVM |\n| Solidity | `solc` | EVM | REVM |\n| Rust (ink!) | `cargo-contract` | PolkaVM | PolkaVM | \n\nAny language that can compile to PolkaVM bytecode and utilize `pallet-revive`'s host functions (via [`pallet-revive-uapi`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive_uapi/index.html){target=\\_blank}) is supported."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 4, "depth": 3, "title": "How It Works", "anchor": "how-it-works", "start_char": 2463, "end_char": 2723, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "### How It Works\n\n**Dual Execution Model:**\n\n1. **PolkaVM Backend**: Executes PolkaVM bytecode with native performance optimization.\n2. **REVM Backend**: Implements EVM bytecode for compatibility with existing Ethereum contracts, ensuring seamless migration."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 5, "depth": 3, "title": "Key Benefits", "anchor": "key-benefits", "start_char": 2723, "end_char": 3199, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "### Key Benefits\n\n- **Unified platform**: Deploys both PolkaVM-optimized and EVM-compatible contracts using a single pallet.\n- **Performance**: PolkaVM execution provides improved performance compared to the traditional EVM, leveraging the [RISC-V](https://en.wikipedia.org/wiki/RISC-V){target=\\_blank} architecture to map instructions to the CPU and requires little transpiling.\n- **Ethereum compatibility**: Supports full integration with Ethereum tooling via RPC adapter."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 6, "depth": 3, "title": "Implementation Examples", "anchor": "implementation-examples", "start_char": 3199, "end_char": 3489, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### Implementation Examples\n\nSee a real-world implementation in the [Polkadot Hub TestNet](https://github.com/paseo-network/runtimes/blob/c965c42a4e0bc9d1e9cc0a340322bc3b8e347bcf/system-parachains/asset-hub-paseo/src/lib.rs#L1122-L1157){target=\\_blank} in the Polkadot Fellows repository."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 7, "depth": 2, "title": "Frontier", "anchor": "frontier", "start_char": 3489, "end_char": 3786, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "## Frontier\n\n[Frontier](https://github.com/polkadot-evm/frontier){target=\\_blank} is the Ethereum compatibility layer designed for maximum compatibility with the Ethereum ecosystem. It's the ideal choice when you need seamless integration with existing Ethereum tools, dApps, and infrastructure."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 8, "depth": 3, "title": "Integration Options", "anchor": "integration-options", "start_char": 3786, "end_char": 3888, "estimated_token_count": 15, "token_estimator": "heuristic-v1", "text": "### Integration Options\n\nFrontier offers flexible integration depending on your compatibility needs:"}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 9, "depth": 3, "title": "EVM Execution Only", "anchor": "evm-execution-only", "start_char": 3888, "end_char": 4228, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "### EVM Execution Only\n\nFor basic EVM support using Polkadot SDK native APIs:\n\n- **[`pallet-evm`](https://github.com/polkadot-evm/frontier/tree/master/frame/evm){target=\\_blank}**: Provides the core EVM execution environment.\n\nThis configuration allows EVM contract execution but requires using Polkadot SDK-specific APIs for interaction."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 10, "depth": 3, "title": "Full Ethereum Compatibility", "anchor": "full-ethereum-compatibility", "start_char": 4228, "end_char": 4798, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "### Full Ethereum Compatibility\n\nFor complete Ethereum ecosystem integration with Ethereum RPC support:\n\n- **[`pallet-evm`](https://github.com/polkadot-evm/frontier/tree/master/frame/evm){target=\\_blank}**: Integrates core EVM execution environment.\n- **[`pallet-ethereum`](https://github.com/polkadot-evm/frontier/tree/master/frame/ethereum){target=\\_blank}**: Emulates Ethereum blocks and handles Ethereum-formatted transactions.\n- **[`fc-rpc`](https://github.com/polkadot-evm/frontier/tree/master/client/rpc){target=\\_blank}**: Provides Ethereum JSON-RPC endpoints."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 11, "depth": 3, "title": "Key Benefits", "anchor": "key-benefits-2", "start_char": 4798, "end_char": 5253, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "### Key Benefits\n\n- **Ethereum tooling compatibility**: Full compatibility with MetaMask, Hardhat, Remix, Foundry, and other Ethereum development tools.\n- **Minimal-friction migration**: Deployment of existing Ethereum dApps with minimal or no modifications.\n- **Native Ethereum formats**: Support for Ethereum transaction formats, signatures, and gas mechanics.\n- **Block emulation**: Ethereum-style block structure within Substrate's block production."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 12, "depth": 3, "title": "Implementation Examples", "anchor": "implementation-examples-2", "start_char": 5253, "end_char": 5720, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "### Implementation Examples\n\nProduction implementations demonstrate Frontier's capabilities:\n\n- **Moonbeam**: See their implementation of [`pallet-evm`](https://github.com/moonbeam-foundation/moonbeam/blob/9e2ddbc9ae8bf65f11701e7ccde50075e5fe2790/runtime/moonbeam/src/lib.rs#L532){target=\\_blank} and [`pallet-ethereum`](https://github.com/moonbeam-foundation/moonbeam/blob/9e2ddbc9ae8bf65f11701e7ccde50075e5fe2790/runtime/moonbeam/src/lib.rs#L698){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 13, "depth": 2, "title": "pallet-contracts (Legacy)", "anchor": "pallet-contracts-legacy", "start_char": 5720, "end_char": 6051, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## pallet-contracts (Legacy)\n\n[`pallet-contracts`](https://docs.rs/pallet-contracts/latest/pallet_contracts/index.html#contracts-pallet){target=\\_blank} is the original Wasm-based smart contract pallet for Polkadot SDK chains. While still functional, it's considered legacy as development efforts have shifted to `pallet-revive`."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 14, "depth": 3, "title": "Implementation Example", "anchor": "implementation-example", "start_char": 6051, "end_char": 6304, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "### Implementation Example\n\nFor reference, Astar's implementation of [`pallet-contracts`](https://github.com/AstarNetwork/Astar/blob/b6f7a408d31377130c3713ed52941a06b5436402/runtime/astar/src/lib.rs#L693){target=\\_blank} demonstrates production usage."}
{"page_id": "parachains-customize-runtime-add-smart-contract-functionality", "page_title": "Add Smart Contract Functionality", "index": 15, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6304, "end_char": 6655, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Add a Pallet to the Runtime__\n\n    ---\n\n    Learn the step-by-step process for integrating Polkadot SDK pallets into your blockchain's runtime.\n\n    [:octicons-arrow-right-24: Get Started](/parachains/customize-runtime/add-existing-pallets/)\n\n</div>"}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 662, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBenchmarking is the process of measuring the computational resources (execution time and storage) required by your pallet's extrinsics. Accurate [weight](https://paritytech.github.io/polkadot-sdk/master/frame_support/weights/index.html){target=\\_blank} calculations are essential for ensuring your blockchain can process transactions efficiently while protecting against denial-of-service attacks.\n\nThis guide demonstrates how to benchmark a pallet and incorporate the resulting weight values. This example uses the custom counter pallet from previous guides in this series, but you can replace it with the code from another pallet if desired."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 662, "end_char": 1698, "estimated_token_count": 257, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have:\n\n- A pallet to benchmark. If you followed the pallet development tutorials, you can use the counter pallet from the [Create a Pallet](/parachains/customize-runtime/pallet-development/create-a-pallet/){target=\\_blank} guide. You can also follow these steps to benchmark a custom pallet by updating the `benchmarking.rs` functions, and instances of usage in future steps, to calculate weights using your specific pallet functionality.\n- Basic understanding of [computational complexity](https://en.wikipedia.org/wiki/Computational_complexity){target=\\_blank}.\n- Familiarity with [Rust's testing framework](https://doc.rust-lang.org/book/ch11-00-testing.html){target=\\_blank}.\n- Familiarity setting up the Polkadot Omni Node and [Polkadot Chain Spec Builder](https://crates.io/crates/staging-chain-spec-builder){target=\\_blank}. Refer to the [Set Up a Parachain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank} guide for instructions if needed."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 2, "depth": 2, "title": "Create the Benchmarking Module", "anchor": "create-the-benchmarking-module", "start_char": 1698, "end_char": 3422, "estimated_token_count": 452, "token_estimator": "heuristic-v1", "text": "## Create the Benchmarking Module\n\nCreate a new file `benchmarking.rs` in your pallet's `src` directory and add the following code:\n\n```rust title=\"pallets/pallet-custom/src/benchmarking.rs\"\n#![cfg(feature = \"runtime-benchmarks\")]\n\nuse super::*;\nuse frame::deps::frame_benchmarking::v2::*;\nuse frame::benchmarking::prelude::RawOrigin;\n\n#[benchmarks]\nmod benchmarks {\n    use super::*;\n\n    #[benchmark]\n    fn set_counter_value() {\n        let new_value: u32 = 100;\n\n        #[extrinsic_call]\n        _(RawOrigin::Root, new_value);\n\n        assert_eq!(CounterValue::<T>::get(), new_value);\n    }\n\n    #[benchmark]\n    fn increment() {\n        let caller: T::AccountId = whitelisted_caller();\n        let amount: u32 = 50;\n\n        #[extrinsic_call]\n        _(RawOrigin::Signed(caller.clone()), amount);\n\n        assert_eq!(CounterValue::<T>::get(), amount);\n        assert_eq!(UserInteractions::<T>::get(caller), 1);\n    }\n\n    #[benchmark]\n    fn decrement() {\n        // First, set the counter to a non-zero value\n        CounterValue::<T>::put(100);\n\n        let caller: T::AccountId = whitelisted_caller();\n        let amount: u32 = 30;\n\n        #[extrinsic_call]\n        _(RawOrigin::Signed(caller.clone()), amount);\n\n        assert_eq!(CounterValue::<T>::get(), 70);\n        assert_eq!(UserInteractions::<T>::get(caller), 1);\n    }\n\n    impl_benchmark_test_suite!(Pallet, crate::mock::new_test_ext(), crate::mock::Test);\n}\n```\n\nThis module contains all the [benchmarking definitions](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/index.html){target=\\_blank} for your pallet. If you are benchmarking a different pallet, update the testing logic as needed to test your pallet's functionality."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 3, "depth": 2, "title": "Define the Weight Trait", "anchor": "define-the-weight-trait", "start_char": 3422, "end_char": 4493, "estimated_token_count": 226, "token_estimator": "heuristic-v1", "text": "## Define the Weight Trait\n\nAdd a `weights` module to your pallet that defines the `WeightInfo` trait using the following code:\n\n```rust title=\"pallets/pallet-custom/src/weights.rs\"\n#[frame::pallet]\npub mod pallet {\n    use frame::prelude::*;\n    pub use weights::WeightInfo;\n\n    pub mod weights {\n        use frame::prelude::*;\n\n        pub trait WeightInfo {\n            fn set_counter_value() -> Weight;\n            fn increment() -> Weight;\n            fn decrement() -> Weight;\n        }\n\n        impl WeightInfo for () {\n            fn set_counter_value() -> Weight {\n                Weight::from_parts(10_000, 0)\n            }\n            fn increment() -> Weight {\n                Weight::from_parts(15_000, 0)\n            }\n            fn decrement() -> Weight {\n                Weight::from_parts(15_000, 0)\n            }\n        }\n    }\n\n    // ... rest of pallet\n}\n```\n\nThe `WeightInfo for ()` implementation provides placeholder weights for development. If you are using a different pallet, update the `weights` module to use your pallet's function names."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 4, "depth": 2, "title": "Add WeightInfo to Config", "anchor": "add-weightinfo-to-config", "start_char": 4493, "end_char": 5318, "estimated_token_count": 200, "token_estimator": "heuristic-v1", "text": "## Add WeightInfo to Config \n\nUpdate your pallet's `Config` trait to include `WeightInfo` by adding the following code:\n\n```rust title=\"pallets/pallet-custom/src/lib.rs\"\n#[pallet::config]\npub trait Config: frame_system::Config {\n    type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n    #[pallet::constant]\n    type CounterMaxValue: Get<u32>;\n\n    type WeightInfo: weights::WeightInfo;\n}\n```\n\nThe [`WeightInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_system/weights/trait.WeightInfo.html){target=\\_blank} trait provides an abstraction layer that allows weights to be swapped at runtime configuration. By making `WeightInfo` an associated type in the `Config` trait, you will enable each runtime that uses your pallet to specify which weight implementation to use."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 5, "depth": 2, "title": "Update Extrinsic Weight Annotations", "anchor": "update-extrinsic-weight-annotations", "start_char": 5318, "end_char": 6606, "estimated_token_count": 311, "token_estimator": "heuristic-v1", "text": "## Update Extrinsic Weight Annotations\n\nReplace the placeholder weights in your extrinsics with calls to the `WeightInfo` trait by adding the following code:\n\n```rust title=\"pallets/pallet-custom/src/lib.rs\"\n#[pallet::call]\nimpl<T: Config> Pallet<T> {\n    #[pallet::call_index(0)]\n    #[pallet::weight(T::WeightInfo::set_counter_value())]\n    pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n        // ... implementation\n    }\n\n    #[pallet::call_index(1)]\n    #[pallet::weight(T::WeightInfo::increment())]\n    pub fn increment(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n        // ... implementation\n    }\n\n    #[pallet::call_index(2)]\n    #[pallet::weight(T::WeightInfo::decrement())]\n    pub fn decrement(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n        // ... implementation\n    }\n}\n```\n\nBy calling `T::WeightInfo::function_name()` instead of using hardcoded `Weight::from_parts()` values, your extrinsics automatically use whichever weight implementation is configured in the runtime. You can switch between placeholder weights for testing and benchmarked weights for production easily, without changing any pallet code.\n\nIf you are using a different pallet, be sure to update the functions for `WeightInfo` accordingly."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 6, "depth": 2, "title": "Include the Benchmarking Module", "anchor": "include-the-benchmarking-module", "start_char": 6606, "end_char": 7143, "estimated_token_count": 141, "token_estimator": "heuristic-v1", "text": "## Include the Benchmarking Module\n\nAt the top of your `lib.rs`, add the module declaration by adding the following code:\n\n```rust title=\"pallets/pallet-custom/src/lib.rs\"\n#![cfg_attr(not(feature = \"std\"), no_std)]\n\nextern crate alloc;\nuse alloc::vec::Vec;\n\npub use pallet::*;\n\n#[cfg(feature = \"runtime-benchmarks\")]\nmod benchmarking;\n\n// Additional pallet code\n```\n\nThe `#[cfg(feature = \"runtime-benchmarks\")]` attribute ensures that benchmarking code is only compiled when explicitly needed to keep your production runtime efficient."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 7, "depth": 2, "title": "Configure Pallet Dependencies", "anchor": "configure-pallet-dependencies", "start_char": 7143, "end_char": 8053, "estimated_token_count": 212, "token_estimator": "heuristic-v1", "text": "## Configure Pallet Dependencies\n\nUpdate your pallet's `Cargo.toml` to enable the benchmarking feature by adding the following code:\n\n```toml title=\"pallets/pallet-custom/Cargo.toml\"\n[dependencies]\ncodec = { features = [\"derive\"], workspace = true }\nscale-info = { features = [\"derive\"], workspace = true }\nframe = { features = [\"experimental\", \"runtime\"], workspace = true }\n\n[features]\ndefault = [\"std\"]\nruntime-benchmarks = [\n    \"frame/runtime-benchmarks\",\n]\nstd = [\n    \"codec/std\",\n    \"scale-info/std\",\n    \"frame/std\",\n]\n```\n\nThe Cargo feature flag system lets you conditionally compile code based on which features are enabled. By defining a `runtime-benchmarks` feature that cascades to FRAME's benchmarking features, you create a clean way to build your pallet with or without benchmarking support, ensuring all necessary dependencies are available when needed but excluded from production builds."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 8, "depth": 2, "title": "Update Mock Runtime", "anchor": "update-mock-runtime", "start_char": 8053, "end_char": 8552, "estimated_token_count": 109, "token_estimator": "heuristic-v1", "text": "## Update Mock Runtime\n\nAdd the `WeightInfo` type to your test configuration in `mock.rs` by adding the following code:\n\n```rust title=\"pallets/pallet-custom/src/mock.rs\"\nimpl pallet_custom::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = ConstU32<1000>;\n    type WeightInfo = ();\n}\n```\n\nIn your mock runtime for testing, use the placeholder `()` implementation of `WeightInfo`, since unit tests focus on verifying functional correctness rather than performance."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 9, "depth": 2, "title": "Configure Runtime Benchmarking", "anchor": "configure-runtime-benchmarking", "start_char": 8552, "end_char": 10337, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "## Configure Runtime Benchmarking\n\nTo execute benchmarks, your pallet must be integrated into the runtime's benchmarking infrastructure. Follow these steps to update the runtime configuration:\n\n1. **Update `runtime/Cargo.toml`**: Add your pallet to the runtime's `runtime-benchmarks` feature as follows:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    runtime-benchmarks = [\n        \"cumulus-pallet-parachain-system/runtime-benchmarks\",\n        \"hex-literal\",\n        \"pallet-parachain-template/runtime-benchmarks\",\n        \"polkadot-sdk/runtime-benchmarks\",\n        \"pallet-custom/runtime-benchmarks\",\n    ]\n    ```\n\n    When you build the runtime with `--features runtime-benchmarks`, this configuration ensures all necessary benchmarking code across all pallets (including yours) is included.\n\n2. **Update runtime configuration**: Using the the placeholder implementation, run development benchmarks as follows:\n\n    ```rust title=\"runtime/src/configs/mod.rs\"\n    impl pallet_custom::Config for Runtime {\n        type RuntimeEvent = RuntimeEvent;\n        type CounterMaxValue = ConstU32<1000>;\n        type WeightInfo = ();\n    }\n    ```\n\n3. **Register benchmarks**: Add your pallet to the benchmark list in `runtime/src/benchmarks.rs` as follows:\n\n    ```rust title=\"runtime/src/benchmarks.rs\"\n    polkadot_sdk::frame_benchmarking::define_benchmarks!(\n        [frame_system, SystemBench::<Runtime>]\n        [pallet_balances, Balances]\n        // ... other pallets\n        [pallet_custom, CustomPallet]\n    );\n    ```\n\n    The [`define_benchmarks!`](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/macro.define_benchmarks.html){target=\\_blank} macro creates the infrastructure that allows the benchmarking CLI tool to discover and execute your pallet's benchmarks."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 10, "depth": 2, "title": "Test Benchmark Compilation", "anchor": "test-benchmark-compilation", "start_char": 10337, "end_char": 11329, "estimated_token_count": 245, "token_estimator": "heuristic-v1", "text": "## Test Benchmark Compilation\n\nRun the following command to verify your benchmarks compile and run as tests:\n\n```bash\ncargo test -p pallet-custom --features runtime-benchmarks\n```\n\nYou will see terminal output similar to the following as your benchmark tests pass:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>cargo test -p pallet-custom --features runtime-benchmarks</span>\n  <span data-ty>test benchmarking::benchmarks::bench_set_counter_value ... ok</span>\n  <span data-ty>test benchmarking::benchmarks::bench_increment ... ok</span>\n  <span data-ty>test benchmarking::benchmarks::bench_decrement ... ok</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>\n\nThe `impl_benchmark_test_suite!` macro generates unit tests for each benchmark. Running these tests verifies that your benchmarks compile correctly, execute without panicking, and pass their assertions, catching issues early before building the entire runtime."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 11, "depth": 2, "title": "Build the Runtime with Benchmarks", "anchor": "build-the-runtime-with-benchmarks", "start_char": 11329, "end_char": 12024, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Build the Runtime with Benchmarks\n\nCompile the runtime with benchmarking enabled to generate the Wasm binary using the following command:\n\n```bash\ncargo build --release --features runtime-benchmarks\n```\n\nThis command produces the runtime WASM file needed for benchmarking, typically located at: `target/release/wbuild/parachain-template-runtime/parachain_template_runtime.wasm`\n\nThe build includes all the benchmarking infrastructure and special host functions needed for measurement. The resulting WASM runtime contains your benchmark code and can communicate with the benchmarking tool's execution environment. You'll create a different build later for operating your chain in production."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 12, "depth": 2, "title": "Install the Benchmarking Tool", "anchor": "install-the-benchmarking-tool", "start_char": 12024, "end_char": 12589, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Install the Benchmarking Tool\n\nInstall the `frame-omni-bencher` CLI tool using the following command:\n\n```bash\ncargo install frame-omni-bencher --locked\n```\n\n[`frame-omni-bencher`](https://paritytech.github.io/polkadot-sdk/master/frame_omni_bencher/index.html){target=\\_blank} is the official Polkadot SDK tool designed explicitly for FRAME pallet benchmarking. It provides a standardized way to execute benchmarks, measure execution times and storage operations, and generate properly formatted weight files with full integration into the FRAME weight system."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 13, "depth": 2, "title": "Download the Weight Template", "anchor": "download-the-weight-template", "start_char": 12589, "end_char": 13391, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Download the Weight Template\n\nDownload the official weight template file using the following commands:\n\n```bash\ncurl -L https://raw.githubusercontent.com/paritytech/polkadot-sdk/refs/tags/polkadot-stable2412/substrate/.maintain/frame-weight-template.hbs \\\n--output ./pallets/pallet-custom/frame-weight-template.hbs\n```\n\nThe weight template is a Handlebars file that transforms raw benchmark data into a correctly formatted Rust source file. It defines the structure of the generated `weights.rs` file, including imports, trait definitions, documentation comments, and formatting. Using the official template ensures your weight files follow the Polkadot SDK conventions and include all necessary metadata, such as benchmark execution parameters, storage operation counts, and hardware information."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 14, "depth": 2, "title": "Execute Benchmarks", "anchor": "execute-benchmarks", "start_char": 13391, "end_char": 15443, "estimated_token_count": 423, "token_estimator": "heuristic-v1", "text": "## Execute Benchmarks\n\nRun benchmarks for your pallet to generate weight files using the following commands:\n\n```bash\nframe-omni-bencher v1 benchmark pallet \\\n    --runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.wasm \\\n    --pallet pallet_custom \\\n    --extrinsic \"\" \\\n    --template ./pallets/pallet-custom/frame-weight-template.hbs \\\n    --output ./pallets/pallet-custom/src/weights.rs\n```\n\nBenchmarks execute against the compiled WASM runtime rather than native code because WASM is what actually runs in production on the blockchain. WASM execution can have different performance characteristics than native code due to compilation and sandboxing overhead, so benchmarking against the WASM ensures your weight measurements reflect real-world conditions.\n\n??? note \"Additional customization\"\n\n    You can customize benchmark execution with additional parameters for more detailed measurements, as shown in the sample code below:\n\n    ```bash\n    frame-omni-bencher v1 benchmark pallet \\\n        --runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.wasm \\\n        --pallet pallet_custom \\\n        --extrinsic \"\" \\\n        --steps 50 \\\n        --repeat 20 \\\n        --template ./pallets/pallet-custom/frame-weight-template.hbs \\\n        --output ./pallets/pallet-custom/src/weights.rs\n    ```\n    \n    - **`--steps 50`**: Number of different input values to test when using linear components (default: 50). More steps provide finer granularity for detecting complexity trends but increase benchmarking time.\n    - **`--repeat 20`**: Number of repetitions for each measurement (default: 20). More repetitions improve statistical accuracy by averaging out variance, reducing the impact of system noise, and providing more reliable weight estimates.\n    - **`--heap-pages 4096`**: WASM heap pages allocation. Affects available memory during execution.\n    - **`--wasm-execution compiled`**: WASM execution method. Use `compiled` for performance closest to production conditions."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 15, "depth": 2, "title": "Use Generated Weights", "anchor": "use-generated-weights", "start_char": 15443, "end_char": 19238, "estimated_token_count": 851, "token_estimator": "heuristic-v1", "text": "## Use Generated Weights\n\nAfter running benchmarks, a `weights.rs` file is generated containing measured weights based on actual measurements of your code running on real hardware, accounting for the specific complexity of your logic, storage access patterns, and computational requirements.\n\nFollow these steps to use the generated weights with your pallet:\n\n1. Integrate the generated weights by adding the weights module to your pallet's `lib.rs` as follows:\n\n    ```rust title=\"pallets/pallet-custom/src/lib.rs\"\n    #![cfg_attr(not(feature = \"std\"), no_std)]\n\n    extern crate alloc;\n    use alloc::vec::Vec;\n\n    pub use pallet::*;\n\n    #[cfg(feature = \"runtime-benchmarks\")]\n    mod benchmarking;\n\n    pub mod weights;\n\n    #[frame::pallet]\n    pub mod pallet {\n        use super::*;\n        use frame::prelude::*;\n        use crate::weights::WeightInfo;\n        // ... rest of pallet\n    }\n    ```\n\n    Unlike the benchmarking module (which is only needed when running benchmarks), the weights module must be available in all builds because the runtime needs to call the weight functions during regular operation to calculate transaction fees and enforce block limits.\n\n2. Update your runtime configuration to use the generated weights instead of the placeholder `()` implementation by adding the following code:\n\n    ```rust title=\"runtime/src/configs/mod.rs\"\n    impl pallet_custom::Config for Runtime {\n        type RuntimeEvent = RuntimeEvent;\n        type CounterMaxValue = ConstU32<1000>;\n        type WeightInfo = pallet_custom::weights::SubstrateWeight<Runtime>;\n    }\n    ```\n\n    This change activates your benchmarked weights in the production runtime. Now, when users submit transactions that call your pallet's extrinsics, the runtime will use the actual measured weights to calculate fees and enforce block limits.\n\n??? code \"Example generated weight file\"\n    \n    The generated `weights.rs` file will look similar to this:\n\n    ```rust title=\"pallets/pallet-custom/src/weights.rs\"\n    //! Autogenerated weights for `pallet_custom`\n    //!\n    //! THIS FILE WAS AUTO-GENERATED USING THE SUBSTRATE BENCHMARK CLI VERSION 32.0.0\n    //! DATE: 2025-01-15, STEPS: `50`, REPEAT: `20`\n\n    #![cfg_attr(rustfmt, rustfmt_skip)]\n    #![allow(unused_parens)]\n    #![allow(unused_imports)]\n    #![allow(missing_docs)]\n\n    use frame_support::{traits::Get, weights::{Weight, constants::RocksDbWeight}};\n    use core::marker::PhantomData;\n\n    pub trait WeightInfo {\n        fn set_counter_value() -> Weight;\n        fn increment() -> Weight;\n        fn decrement() -> Weight;\n    }\n\n    pub struct SubstrateWeight<T>(PhantomData<T>);\n    impl<T: frame_system::Config> WeightInfo for SubstrateWeight<T> {\n        fn set_counter_value() -> Weight {\n            Weight::from_parts(8_234_000, 0)\n                .saturating_add(T::DbWeight::get().reads(1))\n                .saturating_add(T::DbWeight::get().writes(1))\n        }\n\n        fn increment() -> Weight {\n            Weight::from_parts(12_456_000, 0)\n                .saturating_add(T::DbWeight::get().reads(2))\n                .saturating_add(T::DbWeight::get().writes(2))\n        }\n\n        fn decrement() -> Weight {\n            Weight::from_parts(11_987_000, 0)\n                .saturating_add(T::DbWeight::get().reads(2))\n                .saturating_add(T::DbWeight::get().writes(2))\n        }\n    }\n    ```\n\n    The actual numbers in your `weights.rs` file will vary based on your hardware and implementation complexity. The [`DbWeight`](https://paritytech.github.io/polkadot-sdk/master/frame_support/weights/struct.RuntimeDbWeight.html){target=\\_blank} accounts for database read and write operations.\n\nCongratulations, you've successfully benchmarked a pallet and updated your runtime to use the generated weight values."}
{"page_id": "parachains-customize-runtime-pallet-development-benchmark-pallet", "page_title": "Benchmark Your Pallet", "index": 16, "depth": 2, "title": "Related Resources", "anchor": "related-resources", "start_char": 19238, "end_char": 19779, "estimated_token_count": 153, "token_estimator": "heuristic-v1", "text": "## Related Resources\n\n- [FRAME Benchmarking Documentation](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/index.html){target=\\_blank}\n- [Weight Struct Documentation](https://paritytech.github.io/polkadot-sdk/master/frame_support/weights/struct.Weight.html){target=\\_blank}\n- [Benchmarking v2 API](https://paritytech.github.io/polkadot-sdk/master/frame_benchmarking/v2/index.html){target=\\_blank}\n- [frame-omni-bencher Tool](https://paritytech.github.io/polkadot-sdk/master/frame_omni_bencher/index.html){target=\\_blank}"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 26, "end_char": 847, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Framework for Runtime Aggregation of Modular Entities (FRAME)](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank} provides a powerful set of tools for blockchain development through modular components called [pallets](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/pallet/index.html){target=\\_blank}. These Rust-based runtime modules allow you to build custom blockchain functionality with precision and flexibility. While FRAME includes a library of pre-built pallets, its true strength lies in creating custom pallets tailored to your specific needs.\n\nIn this guide, you'll learn how to build a custom counter pallet from scratch that demonstrates core pallet development concepts."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 847, "end_char": 1217, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have:\n\n- [Polkadot SDK dependencies installed](/parachains/install-polkadot-sdk/){target=\\_blank}.\n- A [Polkadot SDK Parchain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank} set up locally.\n- Basic familiarity with [FRAME concepts](/parachains/customize-runtime/){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 2, "depth": 2, "title": "Core Pallet Components", "anchor": "core-pallet-components", "start_char": 1217, "end_char": 2092, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Core Pallet Components\n\nAs you build your custom pallet, you'll work with these key sections:\n\n- **Imports and dependencies**: Bring in necessary FRAME libraries and external modules.\n- **Runtime configuration trait**: Specify types and constants for pallet-runtime interaction.\n- **Runtime events**: Define signals that communicate state changes.\n- **Runtime errors**: Define error types returned from dispatchable calls.\n- **Runtime storage**: Declare on-chain storage items for your pallet's state.\n- **Genesis configuration**: Set initial blockchain state.\n- **Dispatchable functions (extrinsics)**: Create callable functions for user interactions.\n\nFor additional macros beyond those covered here, refer to the [pallet_macros](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/index.html){target=\\_blank} section of the Polkadot SDK Docs."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 3, "depth": 2, "title": "Create the Pallet Project", "anchor": "create-the-pallet-project", "start_char": 2092, "end_char": 2831, "estimated_token_count": 180, "token_estimator": "heuristic-v1", "text": "## Create the Pallet Project\n\nBegin by creating a new Rust library project for your custom pallet within the [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank}:\n\n1. Navigate to the root directory of your parachain template:\n\n    ```bash\n    cd polkadot-sdk-parachain-template\n    ```\n\n2. Navigate to the `pallets` directory:\n\n    ```bash\n    cd pallets\n    ```\n\n3. Create a new Rust library project:\n\n    ```bash\n    cargo new --lib pallet-custom\n    ```\n\n4. Enter the new project directory:\n\n    ```bash\n    cd pallet-custom\n    ```\n\n5. Verify the project structure. It should look like:\n\n    ```\n    pallet-custom/\n    â”œâ”€â”€ Cargo.toml\n    â””â”€â”€ src/\n        â””â”€â”€ lib.rs\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 4, "depth": 2, "title": "Configure Dependencies", "anchor": "configure-dependencies", "start_char": 2831, "end_char": 4724, "estimated_token_count": 386, "token_estimator": "heuristic-v1", "text": "## Configure Dependencies\n\nTo integrate your custom pallet into the Polkadot SDK-based runtime, configure the `Cargo.toml` file with the required dependencies. Since your pallet exists within the parachain template workspace, you'll use workspace inheritance to maintain version consistency.\n\n1. Open `Cargo.toml` and replace its contents with:\n\n    ```toml title=\"pallet-custom/Cargo.toml\"\n    [package]\n        name = \"pallet-custom\"\n        description = \"A custom counter pallet for demonstration purposes.\"\n        version = \"0.1.0\"\n        license = \"Unlicense\"\n        authors.workspace = true\n        homepage.workspace = true\n        repository.workspace = true\n        edition.workspace = true\n        publish = false\n\n        [package.metadata.docs.rs]\n        targets = [\"x86_64-unknown-linux-gnu\"]\n\n        [dependencies]\n        codec = { features = [\"derive\"], workspace = true }\n        scale-info = { features = [\"derive\"], workspace = true }\n        frame = { features = [\"experimental\", \"runtime\"], workspace = true }\n\n        [features]\n        default = [\"std\"]\n        std = [\n            \"codec/std\",\n            \"scale-info/std\",\n            \"frame/std\",\n        ]\n    ```\n\n    !!!note \"Version Management\"\n        The parachain template uses workspace inheritance to maintain consistent dependency versions across all packages. The actual versions are defined in the root `Cargo.toml` file, ensuring compatibility throughout the project. By using `workspace = true`, your pallet automatically inherits the correct versions.\n\n2. The parachain template already includes `pallets/*` in the workspace members, so your new pallet is automatically recognized. Verify this by checking the root `Cargo.toml`:\n\n    ```toml title=\"Cargo.toml\"\n        [workspace.members]\n        members = [\n            \"node\",\n            \"pallets/*\",\n            \"runtime\",\n        ]\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 5, "depth": 2, "title": "Initialize the Pallet Structure", "anchor": "initialize-the-pallet-structure", "start_char": 4724, "end_char": 5916, "estimated_token_count": 269, "token_estimator": "heuristic-v1", "text": "## Initialize the Pallet Structure\n\nWith dependencies configured, set up the basic scaffold that will hold your pallet's logic:\n\n1. Open `src/lib.rs` and delete all existing content.\n\n2. Add the initial scaffold structure using the unified `frame` dependency:\n\n    ```rust title=\"src/lib.rs\"\n    #![cfg_attr(not(feature = \"std\"), no_std)]\n\n    pub use pallet::*;\n\n    #[frame::pallet]\n    pub mod pallet {\n        use frame::prelude::*;\n\n        #[pallet::pallet]\n        pub struct Pallet<T>(_);\n\n        #[pallet::config]\n        pub trait Config: frame_system::Config {\n            // Configuration will be added here\n        }\n\n        #[pallet::storage]\n        pub type CounterValue<T> = StorageValue<_, u32, ValueQuery>;\n\n        #[pallet::call]\n        impl<T: Config> Pallet<T> {\n            // Dispatchable functions will be added here\n        }\n    }\n    ```\n\n    This setup starts with a minimal scaffold without events and errors. These will be added in the following sections after the `Config` trait is correctly configured with the required `RuntimeEvent` type.\n\n3. Verify it compiles using the following command:\n\n    ```bash\n    cargo build --package pallet-custom\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 6, "depth": 2, "title": "Configure the Pallet", "anchor": "configure-the-pallet", "start_char": 5916, "end_char": 7187, "estimated_token_count": 319, "token_estimator": "heuristic-v1", "text": "## Configure the Pallet\n\nThe [`Config`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html){target=\\_blank} trait exposes configurable options and links your pallet to the runtime. All types and constants the pallet depends on must be declared here. These types are defined generically and become concrete when the pallet is instantiated at runtime.\n\nReplace the [`#[pallet::config]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.config.html){target=\\_blank} section with:\n\n```rust title=\"src/lib.rs\"\n#[pallet::config]\npub trait Config: frame_system::Config {\n    /// The overarching runtime event type.\n    type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n    /// Maximum value the counter can reach.\n    #[pallet::constant]\n    type CounterMaxValue: Get<u32>;\n}\n\n```\n\nKey configuration elements include the following:\n\n- **[`RuntimeEvent`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html#associatedtype.RuntimeEvent){target=\\_blank}**: Required for the pallet to emit events that the runtime can process.\n- **`CounterMaxValue`**: A constant that sets an upper limit on counter values, configurable per runtime."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 7, "depth": 2, "title": "Define Events", "anchor": "define-events", "start_char": 7187, "end_char": 8602, "estimated_token_count": 345, "token_estimator": "heuristic-v1", "text": "## Define Events\n\nEvents inform external entities (dApps, explorers, users) about significant runtime changes. Event details are included in the node's metadata, making them accessible to external tools.\n\nThe [`#[pallet::generate_deposit]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.generate_deposit.html){target=\\_blank} macro automatically generates a `deposit_event` function that converts your pallet's events into the `RuntimeEvent` type and deposits them via [`frame_system::Pallet::deposit_event`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.deposit_event){target=\\_blank}.\n\nAdd the [`#[pallet::event]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.event.html){target=\\_blank} section after the `Config` trait:\n\n```rust title=\"src/lib.rs\"\n#[pallet::event]\n#[pallet::generate_deposit(pub(super) fn deposit_event)]\npub enum Event<T: Config> {\n    /// Counter value was explicitly set. [new_value]\n    CounterValueSet {\n        new_value: u32,\n    },\n    /// Counter was incremented. [new_value, who, amount]\n    CounterIncremented {\n        new_value: u32,\n        who: T::AccountId,\n        amount: u32,\n    },\n    /// Counter was decremented. [new_value, who, amount]\n    CounterDecremented {\n        new_value: u32,\n        who: T::AccountId,\n        amount: u32,\n    },\n}\n\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 8, "depth": 2, "title": "Define Errors", "anchor": "define-errors", "start_char": 8602, "end_char": 9507, "estimated_token_count": 221, "token_estimator": "heuristic-v1", "text": "## Define Errors\n\nErrors indicate when and why a call fails. Use informative names and descriptions, as error documentation is included in the node's metadata.\n\nError types must implement the [`TypeInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_prelude/trait.TypeInfo.html){target=\\_blank} trait, and runtime errors can be up to 4 bytes in size.\n\nAdd the [`#[pallet::error]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.error.html){target=\\_blank} section after the events:\n\n```rust title=\"src/lib.rs\"\n#[pallet::error]\npub enum Error<T> {\n    /// The counter value has not been set yet.\n    NoneValue,\n    /// Arithmetic operation would cause overflow.\n    Overflow,\n    /// Arithmetic operation would cause underflow.\n    Underflow,\n    /// The counter value would exceed the maximum allowed value.\n    CounterMaxValueExceeded,\n}\n\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 9, "depth": 2, "title": "Add Storage Items", "anchor": "add-storage-items", "start_char": 9507, "end_char": 10621, "estimated_token_count": 283, "token_estimator": "heuristic-v1", "text": "## Add Storage Items\n\nStorage items persist state on-chain. This pallet uses two storage items:\n\n- **`CounterValue`**: Stores the current counter value.\n- **`UserInteractions`**: Tracks interaction counts per user account.\n\nThe initial scaffold already includes the `CounterValue` storage item. Now add the `UserInteractions` storage map after it:\n\n```rust title=\"src/lib.rs\"\n/// Tracks the number of interactions per user.\n#[pallet::storage]\npub type UserInteractions<T: Config> = StorageMap<_, Blake2_128Concat, T::AccountId, u32, ValueQuery>;\n```\n\nYour storage section should now look like this:\n\n```rust title=\"src/lib.rs\"\n/// The current value of the counter.\n#[pallet::storage]\npub type CounterValue<T> = StorageValue<_, u32, ValueQuery>;\n\n/// Tracks the number of interactions per user.\n#[pallet::storage]\npub type UserInteractions<T: Config> = StorageMap<_, Blake2_128Concat, T::AccountId, u32, ValueQuery>;\n```\n\nFor more storage types and patterns, explore the [Polkadot SDK storage documentation](https://paritytech.github.io/polkadot-sdk/master/frame_support/storage/types/index.html){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 10, "depth": 2, "title": "Configure Genesis State", "anchor": "configure-genesis-state", "start_char": 10621, "end_char": 12447, "estimated_token_count": 416, "token_estimator": "heuristic-v1", "text": "## Configure Genesis State\n\nGenesis configuration allows you to set the initial state of your pallet when the blockchain first starts and is essential for both production networks and testing environments. It is beneficial for:\n\n- Setting initial parameter values.\n- Pre-allocating resources or accounts.\n- Establishing starting conditions for testing.\n- Configuring network-specific initial state.\n\nAdd the [`#[pallet::genesis_config]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.genesis_config.html){target=\\_blank} and [`#[pallet::genesis_build]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.genesis_build.html){target=\\_blank} sections after your storage items:\n\n```rust title=\"src/lib.rs\"\n#[pallet::genesis_config]\n#[derive(DefaultNoBound)]\npub struct GenesisConfig<T: Config> {\n    /// Initial value for the counter\n    pub initial_counter_value: u32,\n    /// Pre-populated user interactions\n    pub initial_user_interactions: Vec<(T::AccountId, u32)>,\n}\n\n#[pallet::genesis_build]\nimpl<T: Config> BuildGenesisConfig for GenesisConfig<T> {\n    fn build(&self) {\n        // Set the initial counter value\n        CounterValue::<T>::put(self.initial_counter_value);\n\n        // Set initial user interactions\n        for (account, count) in &self.initial_user_interactions {\n            UserInteractions::<T>::insert(account, count);\n        }\n    }\n}\n\n```\n\nGenesis configuration components include the following:\n\n- **`GenesisConfig` struct**: Defines what can be configured at genesis.\n- **`#[derive(DefaultNoBound)]`**: Provides sensible defaults (empty vec and 0 for the counter).\n- **`BuildGenesisConfig` implementation**: Executes the logic to set initial storage values.\n- **`build()` method**: Called once when the blockchain initializes."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 11, "depth": 2, "title": "Implement Dispatchable Functions", "anchor": "implement-dispatchable-functions", "start_char": 12447, "end_char": 15604, "estimated_token_count": 753, "token_estimator": "heuristic-v1", "text": "## Implement Dispatchable Functions\n\nDispatchable functions (extrinsics) allow users to interact with your pallet and trigger state changes. Each function must:\n\n- Return a [`DispatchResult`](https://paritytech.github.io/polkadot-sdk/master/frame_support/dispatch/type.DispatchResult.html){target=\\_blank}.\n- Be annotated with a weight (computational cost).\n- Have an explicit call index for backward compatibility.\n\nReplace the [`#[pallet::call]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.call.html){target=\\_blank} section with:\n\n```rust title=\"src/lib.rs\"\n#[pallet::call]\nimpl<T: Config> Pallet<T> {\n    /// Set the counter to a specific value. Root origin only.\n    #[pallet::call_index(0)]\n    #[pallet::weight(0)]\n    pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n        // Ensure the caller is root\n        ensure_root(origin)?;\n\n        // Validate the new value doesn't exceed the maximum\n        ensure!(new_value <= T::CounterMaxValue::get(), Error::<T>::CounterMaxValueExceeded);\n\n        // Update storage\n        CounterValue::<T>::put(new_value);\n\n        // Emit event\n        Self::deposit_event(Event::CounterValueSet { new_value });\n\n        Ok(())\n    }\n\n    /// Increment the counter by a specified amount.\n    #[pallet::call_index(1)]\n    #[pallet::weight(0)]\n    pub fn increment(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n        // Ensure the caller is signed\n        let who = ensure_signed(origin)?;\n\n        // Get current counter value\n        let current_value = CounterValue::<T>::get();\n\n        // Check for overflow\n        let new_value = current_value.checked_add(amount).ok_or(Error::<T>::Overflow)?;\n\n        // Ensure new value doesn't exceed maximum\n        ensure!(new_value <= T::CounterMaxValue::get(), Error::<T>::CounterMaxValueExceeded);\n\n        // Update counter storage\n        CounterValue::<T>::put(new_value);\n\n        // Track user interaction\n        UserInteractions::<T>::mutate(&who, |count| {\n            *count = count.saturating_add(1);\n        });\n\n        // Emit event\n        Self::deposit_event(Event::CounterIncremented {\n            new_value,\n            who,\n            amount,\n        });\n\n        Ok(())\n    }\n\n    /// Decrement the counter by a specified amount.\n    #[pallet::call_index(2)]\n    #[pallet::weight(0)]\n    pub fn decrement(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n        // Ensure the caller is signed\n        let who = ensure_signed(origin)?;\n\n        // Get current counter value\n        let current_value = CounterValue::<T>::get();\n\n        // Check for underflow\n        let new_value = current_value.checked_sub(amount).ok_or(Error::<T>::Underflow)?;\n\n        // Update counter storage\n        CounterValue::<T>::put(new_value);\n\n        // Track user interaction\n        UserInteractions::<T>::mutate(&who, |count| {\n            *count = count.saturating_add(1);\n        });\n\n        // Emit event\n        Self::deposit_event(Event::CounterDecremented {\n            new_value,\n            who,\n            amount,\n        });\n\n        Ok(())\n    }\n}\n\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 12, "depth": 3, "title": "Dispatchable Function Details", "anchor": "dispatchable-function-details", "start_char": 15604, "end_char": 16558, "estimated_token_count": 237, "token_estimator": "heuristic-v1", "text": "### Dispatchable Function Details\n\n???+ interface \"`set_counter_value`\"\n\n    - **Access**: Root origin only (privileged operations).\n    - **Purpose**: Set counter to a specific value.\n    - **Validations**: New value must not exceed `CounterMaxValue`.\n    - **State changes**: Updates `CounterValue` storage.\n    - **Events**: Emits `CounterValueSet`.\n\n??? interface \"`increment`\"\n\n    - **Access**: Any signed account.\n    - **Purpose**: Increase counter by specified amount.\n    - **Validations**: Checks for overflow and max value compliance.\n    - **State changes**: Updates `CounterValue` and `UserInteractions`.\n    - **Events**: Emits `CounterIncremented`.\n\n??? interface \"`decrement`\"\n\n    - **Access**: Any signed account.\n    - **Purpose**: Decrease counter by specified amount.\n    - **Validations**: Checks for underflow.\n    - **State changes**: Updates `CounterValue` and `UserInteractions`.\n    - **Events**: Emits `CounterDecremented`."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 13, "depth": 2, "title": "Verify Pallet Compilation", "anchor": "verify-pallet-compilation", "start_char": 16558, "end_char": 21051, "estimated_token_count": 938, "token_estimator": "heuristic-v1", "text": "## Verify Pallet Compilation\n\nBefore proceeding, ensure your pallet compiles without errors by running the following command:\n\n```bash\ncargo build --package pallet-custom\n```\n\nIf you encounter errors, carefully review the code against this guide. Once the build completes successfully, your custom pallet is ready for integration.\n\n??? code \"Complete Pallet Implementation\"\n    \n    ```rust title=\"src/lib.rs\"\n    #![cfg_attr(not(feature = \"std\"), no_std)]\n\n    pub use pallet::*;\n\n    #[frame::pallet]\n    pub mod pallet {\n        use frame::prelude::*;\n\n        #[pallet::pallet]\n        pub struct Pallet<T>(_);\n\n        #[pallet::config]\n        pub trait Config: frame_system::Config {\n            type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n            #[pallet::constant]\n            type CounterMaxValue: Get<u32>;\n        }\n\n        #[pallet::event]\n        #[pallet::generate_deposit(pub(super) fn deposit_event)]\n        pub enum Event<T: Config> {\n            CounterValueSet {\n                new_value: u32,\n            },\n            CounterIncremented {\n                new_value: u32,\n                who: T::AccountId,\n                amount: u32,\n            },\n            CounterDecremented {\n                new_value: u32,\n                who: T::AccountId,\n                amount: u32,\n            },\n        }\n\n        #[pallet::error]\n        pub enum Error<T> {\n            NoneValue,\n            Overflow,\n            Underflow,\n            CounterMaxValueExceeded,\n        }\n\n        #[pallet::storage]\n        pub type CounterValue<T> = StorageValue<_, u32, ValueQuery>;\n\n        #[pallet::storage]\n        pub type UserInteractions<T: Config> = StorageMap<\n            _,\n            Blake2_128Concat,\n            T::AccountId,\n            u32,\n            ValueQuery\n        >;\n\n        #[pallet::genesis_config]\n        #[derive(DefaultNoBound)]\n        pub struct GenesisConfig<T: Config> {\n            pub initial_counter_value: u32,\n            pub initial_user_interactions: Vec<(T::AccountId, u32)>,\n        }\n\n        #[pallet::genesis_build]\n        impl<T: Config> BuildGenesisConfig for GenesisConfig<T> {\n            fn build(&self) {\n                CounterValue::<T>::put(self.initial_counter_value);\n                for (account, count) in &self.initial_user_interactions {\n                    UserInteractions::<T>::insert(account, count);\n                }\n            }\n        }\n\n        #[pallet::call]\n        impl<T: Config> Pallet<T> {\n            #[pallet::call_index(0)]\n            #[pallet::weight(0)]\n            pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n                ensure_root(origin)?;\n                ensure!(new_value <= T::CounterMaxValue::get(), Error::<T>::CounterMaxValueExceeded);\n                CounterValue::<T>::put(new_value);\n                Self::deposit_event(Event::CounterValueSet { new_value });\n                Ok(())\n            }\n\n            #[pallet::call_index(1)]\n            #[pallet::weight(0)]\n            pub fn increment(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n                let who = ensure_signed(origin)?;\n                let current_value = CounterValue::<T>::get();\n                let new_value = current_value.checked_add(amount).ok_or(Error::<T>::Overflow)?;\n                ensure!(new_value <= T::CounterMaxValue::get(), Error::<T>::CounterMaxValueExceeded);\n                CounterValue::<T>::put(new_value);\n                UserInteractions::<T>::mutate(&who, |count| {\n                    *count = count.saturating_add(1);\n                });\n                Self::deposit_event(Event::CounterIncremented { new_value, who, amount });\n                Ok(())\n            }\n\n            #[pallet::call_index(2)]\n            #[pallet::weight(0)]\n            pub fn decrement(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n                let who = ensure_signed(origin)?;\n                let current_value = CounterValue::<T>::get();\n                let new_value = current_value.checked_sub(amount).ok_or(Error::<T>::Underflow)?;\n                CounterValue::<T>::put(new_value);\n                UserInteractions::<T>::mutate(&who, |count| {\n                    *count = count.saturating_add(1);\n                });\n                Self::deposit_event(Event::CounterDecremented { new_value, who, amount });\n                Ok(())\n            }\n        }\n    }\n\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 14, "depth": 2, "title": "Add the Pallet to Your Runtime", "anchor": "add-the-pallet-to-your-runtime", "start_char": 21051, "end_char": 21177, "estimated_token_count": 25, "token_estimator": "heuristic-v1", "text": "## Add the Pallet to Your Runtime\n\nNow that your custom pallet is complete, you can integrate it into the parachain runtime."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 15, "depth": 3, "title": "Add Runtime Dependency", "anchor": "add-runtime-dependency", "start_char": 21177, "end_char": 21753, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "### Add Runtime Dependency\n\n1. In the `runtime/Cargo.toml`, add your custom pallet to the `[dependencies]` section:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    [dependencies]\n    # Local dependencies\n    pallet-custom = { path = \"../pallets/pallet-custom\", default-features = false }\n    \n    # Other dependencies\n    ```\n\n2. Enable the `std` feature by adding it to the `[features]` section:\n\n    ```toml title=\"runtime/Cargo.toml\"\n    [features]\n    default = [\"std\"]\n    std = [\n        \"codec/std\",\n        \"pallet-custom/std\",\n        # ... other features\n    ]\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 16, "depth": 3, "title": "Implement the Config Trait", "anchor": "implement-the-config-trait", "start_char": 21753, "end_char": 22324, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "### Implement the Config Trait\n\nAt the end of the `runtime/src/configs/mod.rs` file, add the implementation: \n\n```rust title=\"runtime/src/configs/mod.rs\"\n/// Configure the custom counter pallet\nimpl pallet_custom::Config for Runtime {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = ConstU32<1000>;\n}\n```\n\nThis configuration:\n\n- Links the pallet's events to the runtime's event system.\n- Sets a maximum counter value of 1000 using [`ConstU32`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/struct.ConstU32.html){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 17, "depth": 3, "title": "Add to Runtime Construct", "anchor": "add-to-runtime-construct", "start_char": 22324, "end_char": 23326, "estimated_token_count": 214, "token_estimator": "heuristic-v1", "text": "### Add to Runtime Construct\n\nIn the `runtime/src/lib.rs` file, locate the [`#[frame_support::runtime]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/attr.runtime.html){target=\\_blank} section and add your pallet with a unique `pallet_index`:\n\n```rust title=\"runtime/src/lib.rs\"\n#[frame_support::runtime]\nmod runtime {\n    #[runtime::runtime]\n    #[runtime::derive(\n        RuntimeCall,\n        RuntimeEvent,\n        RuntimeError,\n        RuntimeOrigin,\n        RuntimeTask,\n        RuntimeFreezeReason,\n        RuntimeHoldReason,\n        RuntimeSlashReason,\n        RuntimeLockId,\n        RuntimeViewFunction\n    )]\n    pub struct Runtime;\n\n    #[runtime::pallet_index(0)]\n    pub type System = frame_system;\n\n    // ... other pallets\n\n    #[runtime::pallet_index(51)]\n    pub type CustomPallet = pallet_custom;\n}\n```\n\n!!!warning\n    Each pallet must have a unique index. Duplicate indices will cause compilation errors. Choose an index that doesn't conflict with existing pallets."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 18, "depth": 3, "title": "Configure Genesis for Your Runtime", "anchor": "configure-genesis-for-your-runtime", "start_char": 23326, "end_char": 23824, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "### Configure Genesis for Your Runtime\n\nTo set initial values for your pallet when the chain starts, you'll need to configure the genesis in your chain specification. Genesis configuration is typically done in the `node/src/chain_spec.rs` file or when generating the chain specification.\n\nFor development and testing, you can use the default values provided by the `#[derive(DefaultNoBound)]` macro. For production networks, you'll want to explicitly set these values in your chain specification."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 19, "depth": 3, "title": "Verify Runtime Compilation", "anchor": "verify-runtime-compilation", "start_char": 23824, "end_char": 24047, "estimated_token_count": 41, "token_estimator": "heuristic-v1", "text": "### Verify Runtime Compilation\n\nCompile the runtime to ensure everything is configured correctly:\n\n```bash\ncargo build --release\n```\n\nThis command validates all pallet configurations and prepares the build for deployment."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 20, "depth": 2, "title": "Run Your Chain Locally", "anchor": "run-your-chain-locally", "start_char": 24047, "end_char": 24522, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## Run Your Chain Locally\n\nLaunch your parachain locally to test the new pallet functionality using the [Polkadot Omni Node](https://crates.io/crates/polkadot-omni-node){target=\\_blank}. For instructions on setting up the Polkadot Omni Node and [Polkadot Chain Spec Builder](https://crates.io/crates/staging-chain-spec-builder){target=\\_blank}, refer to the [Set Up a Parachain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank} guide."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 21, "depth": 3, "title": "Generate a Chain Specification", "anchor": "generate-a-chain-specification", "start_char": 24522, "end_char": 24931, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "### Generate a Chain Specification\n\nCreate a chain specification file with the updated runtime:\n\n```bash\nchain-spec-builder create -t development \\\n--relay-chain paseo \\\n--para-id 1000 \\\n--runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\nnamed-preset development\n```\n\nThis command generates a `chain_spec.json` that includes your custom pallet."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 22, "depth": 3, "title": "Start the Parachain Node", "anchor": "start-the-parachain-node", "start_char": 24931, "end_char": 25114, "estimated_token_count": 44, "token_estimator": "heuristic-v1", "text": "### Start the Parachain Node\n\nLaunch the parachain:\n\n```bash\npolkadot-omni-node --chain ./chain_spec.json --dev\n```\n\nVerify the node starts successfully and begins producing blocks."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 23, "depth": 2, "title": "Interact with Your Pallet", "anchor": "interact-with-your-pallet", "start_char": 25114, "end_char": 25886, "estimated_token_count": 234, "token_estimator": "heuristic-v1", "text": "## Interact with Your Pallet\n\nUse the Polkadot.js Apps interface to test your pallet:\n\n1. Navigate to [Polkadot.js Apps](https://polkadot.js.org/apps/?rpc=ws%3A%2F%2F127.0.0.1%3A9944#/extrinsics){target=\\_blank}.\n\n2. Ensure you're connected to your local node at `ws://127.0.0.1:9944`.\n\n3. Go to **Developer** > **Extrinsics**.\n\n4. Locate **customPallet** in the pallet dropdown.\n\n5. You should see the available extrinsics:\n\n    - **`increment(amount)`**: Increase the counter by a specified amount.\n    - **`decrement(amount)`**: Decrease the counter by a specified amount.\n    - **`setCounterValue(newValue)`**: Set counter to a specific value (requires sudo/root).\n\n![](/images/parachains/customize-runtime/pallet-development/create-a-pallet/create-a-pallet-01.webp)"}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 24, "depth": 2, "title": "Key Takeaways", "anchor": "key-takeaways", "start_char": 25886, "end_char": 26609, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "## Key Takeaways\n\nYou've successfully created and integrated a custom pallet into a Polkadot SDK-based runtime. You have now successfully:\n\n- Defined runtime-specific types and constants via the `Config` trait.\n- Implemented on-chain state using `StorageValue` and `StorageMap`.\n- Created signals to communicate state changes to external systems.\n- Established clear error handling with descriptive error types.\n- Configured initial blockchain state for both production and testing.\n- Built callable functions with proper validation and access control.\n- Added the pallet to a runtime and tested it locally.\n\nThese components form the foundation for developing sophisticated blockchain logic in Polkadot SDK-based chains."}
{"page_id": "parachains-customize-runtime-pallet-development-create-a-pallet", "page_title": "Create a Custom Pallet", "index": 25, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 26609, "end_char": 26958, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Mock Your Runtime__\n\n    ---\n\n    Learn to create a mock runtime environment for testing your pallet in isolation before integration.\n\n    [:octicons-arrow-right-24: Continue](/parachains/customize-runtime/pallet-development/mock-runtime/)\n\n</div>"}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 806, "estimated_token_count": 158, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nTesting is a critical part of pallet development. Before integrating your pallet into a full runtime, you need a way to test its functionality in isolation. A mock runtime provides a minimal, simulated blockchain environment where you can verify your pallet's logic without the overhead of running a full node.\n\nIn this guide, you'll learn how to create a mock runtime for the custom counter pallet built in the [Make a Custom Pallet](/parachains/customize-runtime/pallet-development/create-a-pallet/){target=\\_blank} guide. This mock runtime will enable you to write comprehensive unit tests that verify:\n\n- Dispatchable function behavior.\n- Storage state changes.\n- Event emission.\n- Error handling.\n- Access control and origin validation.\n- Genesis configuration."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 806, "end_char": 1203, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have:\n\n- Completed the [Make a Custom Pallet](/parachains/customize-runtime/pallet-development/create-a-pallet/){target=\\_blank} guide.\n- The custom counter pallet from the Make a Custom Pallet guide. Available in `pallets/pallet-custom`.\n- Basic understanding of [Rust testing](https://doc.rust-lang.org/book/ch11-00-testing.html){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 2, "depth": 2, "title": "Understand Mock Runtimes", "anchor": "understand-mock-runtimes", "start_char": 1203, "end_char": 1737, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "## Understand Mock Runtimes\n\nA mock runtime is a minimal implementation of the runtime environment that:\n\n- Simulates blockchain state to provide storage and state management.\n- Satisfies your pallet's `Config` trait requirements.\n- Allows isolated testing without external dependencies.\n- Supports genesis configuration to set initial blockchain state for tests.\n- Provides instant feedback on code changes for a faster development cycle.\n\nMock runtimes are used exclusively for testing and are never deployed to a live blockchain."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 3, "depth": 2, "title": "Create the Mock Runtime Module", "anchor": "create-the-mock-runtime-module", "start_char": 1737, "end_char": 2478, "estimated_token_count": 200, "token_estimator": "heuristic-v1", "text": "## Create the Mock Runtime Module\n\nStart by creating a new module file within your pallet to house the mock runtime code.\n\n1. Navigate to your pallet directory:\n\n    ```bash\n    cd pallets/pallet-custom/src\n    ```\n\n2. Create a new file named `mock.rs`:\n\n    ```bash\n    touch mock.rs\n    ```\n\n3. Next, open `src/lib.rs` and add the mock module declaration at the top of the file, right after the `pub use pallet::*;` line:\n\n    ```rust title=\"src/lib.rs\"\n    #![cfg_attr(not(feature = \"std\"), no_std)]\n\n    pub use pallet::*;\n\n    #[cfg(test)]\n    mod mock;\n\n    #[frame::pallet]\n    pub mod pallet {\n        // ... existing pallet code\n    }\n\n    ```\n\n    The `#[cfg(test)]` attribute ensures this module is only compiled during testing."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 4, "depth": 2, "title": "Set Up Basic Mock", "anchor": "set-up-basic-mock", "start_char": 2478, "end_char": 3554, "estimated_token_count": 253, "token_estimator": "heuristic-v1", "text": "## Set Up Basic Mock\n\nOpen `src/mock.rs` and add the foundational imports and type definitions:\n\n```rust title=\"src/mock.rs\"\nuse crate as pallet_custom;\nuse frame::{\n    deps::{\n        frame_support::{ derive_impl, traits::ConstU32 },\n        sp_io,\n        sp_runtime::{ traits::IdentityLookup, BuildStorage },\n    },\n    prelude::*,\n};\n\ntype Block = frame_system::mocking::MockBlock<Test>;\n\n// Configure a mock runtime to test the pallet.\nframe::deps::frame_support::construct_runtime!(\n        pub enum Test\n        {\n            System: frame_system,\n            CustomPallet: pallet_custom,\n        }\n    );\n```\n\nThe preceding code includes the following key components: \n\n- **[`construct_runtime!`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/runtime/apis/trait.ConstructRuntimeApi.html#tymethod.construct_runtime_api){target=\\_blank}**: Macro that builds a minimal runtime with only the pallets needed for testing.\n- **`Test`**: The mock runtime type used in tests.\n- **`Block`**: Type alias for the mock block type that the runtime will use."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 5, "depth": 2, "title": "Implement Essential Configuration", "anchor": "implement-essential-configuration", "start_char": 3554, "end_char": 4653, "estimated_token_count": 243, "token_estimator": "heuristic-v1", "text": "## Implement Essential Configuration\n\nThe [`frame_system`](https://paritytech.github.io/polkadot-sdk/master/frame_system/index.html){target=\\_blank} pallet provides core blockchain functionality and is required by all other pallets. Configure it for the test environment as follows:\n\n```rust title=\"src/mock.rs\"\n#[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\nimpl frame_system::Config for Test {\n    type Block = Block;\n    type AccountId = u64;\n    type Lookup = IdentityLookup<Self::AccountId>;\n}\n```\n\nThis simplified configuration for testing includes the following:\n\n- **`#[derive_impl]`**: Automatically provides sensible test defaults for most `frame_system::Config` types.\n- **`AccountId = u64`**: Uses simple integers instead of cryptographic account IDs.\n- **`Lookup = IdentityLookup`**: Direct account ID mapping (no address conversion).\n- **`Block = Block`**: Uses the mock block type we defined earlier.\n\nThis approach is much more concise than manually specifying every configuration type, as the `TestDefaultConfig` preset provides appropriate defaults for testing."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 6, "depth": 2, "title": "Implement Your Pallet's Configuration", "anchor": "implement-your-pallets-configuration", "start_char": 4653, "end_char": 5328, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "## Implement Your Pallet's Configuration\n\nNow implement the `Config` trait for your custom pallet. This trait must match the one defined in your pallet's `src/lib.rs`:\n\n```rust title=\"src/mock.rs\"\nimpl pallet_custom::Config for Test {\n    type RuntimeEvent = RuntimeEvent;\n    type CounterMaxValue = ConstU32<1000>;\n}\n```\n\nConfiguration details include:\n\n- **`RuntimeEvent`**: Connects your pallet's events to the mock runtime's event system.\n- **`CounterMaxValue`**: Sets the maximum counter value to 1000, matching the production configuration.\n\nThe configuration here should mirror what you'll use in production unless you specifically need different values for testing."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 7, "depth": 2, "title": "Configure Genesis Storage", "anchor": "configure-genesis-storage", "start_char": 5328, "end_char": 5612, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## Configure Genesis Storage\n\nGenesis storage defines the initial state of your blockchain before any blocks are produced. Since your counter pallet includes the genesis configuration (added in the previous guide), you can now set up test environments with different initial states."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 8, "depth": 3, "title": "Basic Test Environment", "anchor": "basic-test-environment", "start_char": 5612, "end_char": 6239, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "### Basic Test Environment\n\nCreate a helper function for the default test environment:\n\n```rust title=\"src/mock.rs\"\n// Build genesis storage according to the mock runtime.\npub fn new_test_ext() -> sp_io::TestExternalities {\n    let mut t = frame_system::GenesisConfig::<Test>::default().build_storage().unwrap();\n\n    (pallet_custom::GenesisConfig::<Test> {\n        initial_counter_value: 0,\n        initial_user_interactions: vec![],\n    })\n        .assimilate_storage(&mut t)\n        .unwrap();\n\n    t.into()\n}\n```\n\nThis function creates a clean blockchain state with an initial counter value of 0 and no user interactions."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 9, "depth": 3, "title": "Custom Genesis Configurations", "anchor": "custom-genesis-configurations", "start_char": 6239, "end_char": 7931, "estimated_token_count": 373, "token_estimator": "heuristic-v1", "text": "### Custom Genesis Configurations\n\nFor testing specific scenarios, create additional helper functions with customized genesis states:\n\n```rust title=\"src/mock.rs\"\n// Helper function to create a test externalities with a specific initial counter value\npub fn new_test_ext_with_counter(initial_value: u32) -> sp_io::TestExternalities {\n    let mut t = frame_system::GenesisConfig::<Test>::default().build_storage().unwrap();\n\n    (pallet_custom::GenesisConfig::<Test> {\n        initial_counter_value: initial_value,\n        initial_user_interactions: vec![],\n    })\n        .assimilate_storage(&mut t)\n        .unwrap();\n\n    t.into()\n}\n\n// Helper function to create a test externalities with initial user interactions\npub fn new_test_ext_with_interactions(\n    initial_value: u32,\n    interactions: Vec<(u64, u32)>\n) -> sp_io::TestExternalities {\n    let mut t = frame_system::GenesisConfig::<Test>::default().build_storage().unwrap();\n\n    (pallet_custom::GenesisConfig::<Test> {\n        initial_counter_value: initial_value,\n        initial_user_interactions: interactions,\n    })\n        .assimilate_storage(&mut t)\n        .unwrap();\n\n    t.into()\n}\n```\n\nKey methods used in this step include:\n\n- **[`BuildStorage::build_storage()`](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/trait.BuildStorage.html#method.build_storage){target=\\_blank}**: Creates the initial storage state.\n- **[`assimilate_storage`](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/trait.BuildStorage.html#method.assimilate_storage){target=\\_blank}**: Merges pallet genesis config into the existing storage.\n\nYou can chain multiple `assimilate_storage` calls to configure multiple pallets."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 10, "depth": 2, "title": "Verify Mock Compilation", "anchor": "verify-mock-compilation", "start_char": 7931, "end_char": 10853, "estimated_token_count": 564, "token_estimator": "heuristic-v1", "text": "## Verify Mock Compilation\n\nBefore proceeding to write tests, ensure your mock runtime compiles correctly:\n\n```bash\ncargo test --package pallet-custom --lib\n```\n\nThis command compiles the test code (including the mock and genesis configuration) without running tests yet. Address any compilation errors before continuing.\n\n??? code \"Complete mock runtime script\"\n\n    Here's the complete `mock.rs` file for reference:\n\n    ```rust title=\"src/mock.rs\"\n    use crate as pallet_custom;\n    use frame::{\n        deps::{\n            frame_support::{ derive_impl, traits::ConstU32 },\n            sp_io,\n            sp_runtime::{ traits::IdentityLookup, BuildStorage },\n        },\n        prelude::*,\n    };\n\n    type Block = frame_system::mocking::MockBlock<Test>;\n\n    // Configure a mock runtime to test the pallet.\n    frame::deps::frame_support::construct_runtime!(\n            pub enum Test\n            {\n                System: frame_system,\n                CustomPallet: pallet_custom,\n            }\n        );\n\n    #[derive_impl(frame_system::config_preludes::TestDefaultConfig)]\n    impl frame_system::Config for Test {\n        type Block = Block;\n        type AccountId = u64;\n        type Lookup = IdentityLookup<Self::AccountId>;\n    }\n\n    impl pallet_custom::Config for Test {\n        type RuntimeEvent = RuntimeEvent;\n        type CounterMaxValue = ConstU32<1000>;\n    }\n\n    // Build genesis storage according to the mock runtime.\n    pub fn new_test_ext() -> sp_io::TestExternalities {\n        let mut t = frame_system::GenesisConfig::<Test>::default().build_storage().unwrap();\n\n        (pallet_custom::GenesisConfig::<Test> {\n            initial_counter_value: 0,\n            initial_user_interactions: vec![],\n        })\n            .assimilate_storage(&mut t)\n            .unwrap();\n\n        t.into()\n    }\n\n    // Helper function to create a test externalities with a specific initial counter value\n    pub fn new_test_ext_with_counter(initial_value: u32) -> sp_io::TestExternalities {\n        let mut t = frame_system::GenesisConfig::<Test>::default().build_storage().unwrap();\n\n        (pallet_custom::GenesisConfig::<Test> {\n            initial_counter_value: initial_value,\n            initial_user_interactions: vec![],\n        })\n            .assimilate_storage(&mut t)\n            .unwrap();\n\n        t.into()\n    }\n\n    // Helper function to create a test externalities with initial user interactions\n    pub fn new_test_ext_with_interactions(\n        initial_value: u32,\n        interactions: Vec<(u64, u32)>\n    ) -> sp_io::TestExternalities {\n        let mut t = frame_system::GenesisConfig::<Test>::default().build_storage().unwrap();\n\n        (pallet_custom::GenesisConfig::<Test> {\n            initial_counter_value: initial_value,\n            initial_user_interactions: interactions,\n        })\n            .assimilate_storage(&mut t)\n            .unwrap();\n\n        t.into()\n    }\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 11, "depth": 2, "title": "Key Takeaways", "anchor": "key-takeaways", "start_char": 10853, "end_char": 11416, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Key Takeaways\n\nYou've successfully created a mock runtime with a genesis configuration for your custom pallet. You can now:\n\n- Test your pallet without a full runtime.\n- Set initial blockchain state for different test scenarios.\n- Create different genesis setups for various testing needs.\n- Use this minimal setup to test all pallet functionality.\n\nThe mock runtime with a genesis configuration is essential for test-driven development, enabling you to verify logic under different initial conditions before integrating it into the actual parachain runtime."}
{"page_id": "parachains-customize-runtime-pallet-development-mock-runtime", "page_title": "Mock Your Runtime", "index": 12, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 11416, "end_char": 11766, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Pallet Unit Testing__\n\n    ---\n\n    Learn to write comprehensive unit tests for your pallet using the mock runtime you just created.\n\n    [:octicons-arrow-right-24: Continue](/parachains/customize-runtime/pallet-development/pallet-testing/)\n\n</div>"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 684, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUnit testing in the Polkadot SDK helps ensure that the functions provided by a pallet behave as expected. It also confirms that data and events associated with a pallet are processed correctly during interactions. With your mock runtime in place from the [previous guide](/parachains/customize-runtime/pallet-development/mock-runtime/), you can now write comprehensive tests that verify your pallet's behavior in isolation.\n\nIn this guide, you'll learn how to:\n\n- Structure test modules effectively.\n- Test dispatchable functions.\n- Verify storage changes.\n- Check event emission.\n- Test error conditions.\n- Use genesis configurations in tests."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 684, "end_char": 1147, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you:\n\n- Completed the [Make a Custom Pallet](/parachains/customize-runtime/pallet-development/create-a-pallet/) guide.\n- Completed the [Mock Your Runtime](/parachains/customize-runtime/pallet-development/mock-runtime/) guide.\n- Configured custom counter pallet with mock runtime in `pallets/pallet-custom`.\n- Understood the basics of [Rust testing](https://doc.rust-lang.org/book/ch11-00-testing.html){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 2, "depth": 2, "title": "Understanding FRAME Testing Tools", "anchor": "understanding-frame-testing-tools", "start_char": 1147, "end_char": 1409, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Understanding FRAME Testing Tools\n\n[FRAME](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank} provides specialized testing macros and utilities that make pallet testing more efficient."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 3, "depth": 3, "title": "Assertion Macros", "anchor": "assertion-macros", "start_char": 1409, "end_char": 2154, "estimated_token_count": 203, "token_estimator": "heuristic-v1", "text": "### Assertion Macros\n\n- **[`assert_ok!`](https://paritytech.github.io/polkadot-sdk/master/frame_support/macro.assert_ok.html){target=\\_blank}** - Asserts that a dispatchable call succeeds.\n- **[`assert_noop!`](https://paritytech.github.io/polkadot-sdk/master/frame_support/macro.assert_noop.html){target=\\_blank}** - Asserts that a call fails without changing state (no operation).\n- **[`assert_eq!`](https://doc.rust-lang.org/std/macro.assert_eq.html){target=\\_blank}** - Standard Rust equality assertion.\n\n!!!info \"`assert_noop!` Explained\"\n    Use `assert_noop!` to ensure the operation fails without any state changes. This is critical for testing error conditions - it verifies both that the error occurs AND that no storage was modified."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 4, "depth": 3, "title": "System Pallet Test Helpers", "anchor": "system-pallet-test-helpers", "start_char": 2154, "end_char": 3150, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "### System Pallet Test Helpers\n\nThe [`frame_system`](https://paritytech.github.io/polkadot-sdk/master/frame_system/index.html){target=\\_blank} pallet provides useful methods for testing:\n\n- **[`System::events()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.events){target=\\_blank}** - Returns all events emitted during the test.\n- **[`System::assert_last_event()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.assert_last_event){target=\\_blank}** - Asserts the last event matches expectations.\n- **[`System::set_block_number()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.set_block_number){target=\\_blank}** - Sets the current block number.\n\n!!!info \"Events and Block Number\"\n    Events are not emitted on block 0 (genesis block). If you need to test events, ensure you set the block number to at least 1 using `System::set_block_number(1)`."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 5, "depth": 3, "title": "Origin Types", "anchor": "origin-types", "start_char": 3150, "end_char": 3941, "estimated_token_count": 230, "token_estimator": "heuristic-v1", "text": "### Origin Types\n\n- **[`RuntimeOrigin::root()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/enum.RawOrigin.html#variant.Root){target=\\_blank}** - Root/sudo origin for privileged operations.\n- **[`RuntimeOrigin::signed(account)`](https://paritytech.github.io/polkadot-sdk/master/frame_system/enum.RawOrigin.html#variant.Signed){target=\\_blank}** - Signed origin from a specific account.\n- **[`RuntimeOrigin::none()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/enum.RawOrigin.html#variant.None){target=\\_blank}** - No origin (typically fails for most operations).\n\nLearn more about origins in the [FRAME Origin reference document](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/frame_origin/index.html){target=\\_blank}."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 6, "depth": 2, "title": "Create the Tests Module", "anchor": "create-the-tests-module", "start_char": 3941, "end_char": 4548, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "## Create the Tests Module\n\nCreate a new file for your tests within the pallet directory:\n\n1. Navigate to your pallet directory:\n\n    ```bash\n    cd pallets/pallet-custom/src\n    ```\n\n2. Create a new file named `tests.rs`:\n\n    ```bash\n    touch tests.rs\n    ```\n\n3. Open `src/lib.rs` and add the tests module declaration after the mock module:\n\n    ```rust title=\"src/lib.rs\"\n    #![cfg_attr(not(feature = \"std\"), no_std)]\n\n    pub use pallet::*;\n\n    #[cfg(test)]\n    mod mock;\n\n    #[cfg(test)]\n    mod tests;\n\n    #[frame::pallet]\n    pub mod pallet {\n        // ... existing pallet code\n    }\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 7, "depth": 2, "title": "Set Up the Test Module", "anchor": "set-up-the-test-module", "start_char": 4548, "end_char": 9226, "estimated_token_count": 1011, "token_estimator": "heuristic-v1", "text": "## Set Up the Test Module\n\nOpen `src/tests.rs` and add the basic structure with necessary imports:\n\n```rust\nuse crate::{mock::*, Error, Event};\nuse frame::deps::frame_support::{assert_noop, assert_ok};\nuse frame::deps::sp_runtime::DispatchError;\n```\n\nThis setup imports:\n\n- The mock runtime and test utilities from `mock.rs`\n- Your pallet's `Error` and `Event` types\n- FRAME's assertion macros via `frame::deps`\n- `DispatchError` for testing origin checks\n\n???+ code \"Complete Pallet Code Reference\"\n    Here's the complete pallet code that you'll be testing throughout this guide:\n\n    ```rust\n    #![cfg_attr(not(feature = \"std\"), no_std)]\n\n    pub use pallet::*;\n\n    #[frame::pallet]\n    pub mod pallet {\n        use frame::prelude::*;\n\n        #[pallet::pallet]\n        pub struct Pallet<T>(_);\n\n        #[pallet::config]\n        pub trait Config: frame_system::Config {\n            type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;\n\n            #[pallet::constant]\n            type CounterMaxValue: Get<u32>;\n        }\n\n        #[pallet::event]\n        #[pallet::generate_deposit(pub(super) fn deposit_event)]\n        pub enum Event<T: Config> {\n            CounterValueSet {\n                new_value: u32,\n            },\n            CounterIncremented {\n                new_value: u32,\n                who: T::AccountId,\n                amount: u32,\n            },\n            CounterDecremented {\n                new_value: u32,\n                who: T::AccountId,\n                amount: u32,\n            },\n        }\n\n        #[pallet::error]\n        pub enum Error<T> {\n            NoneValue,\n            Overflow,\n            Underflow,\n            CounterMaxValueExceeded,\n        }\n\n        #[pallet::storage]\n        pub type CounterValue<T> = StorageValue<_, u32, ValueQuery>;\n\n        #[pallet::storage]\n        pub type UserInteractions<T: Config> = StorageMap<\n            _,\n            Blake2_128Concat,\n            T::AccountId,\n            u32,\n            ValueQuery\n        >;\n\n        #[pallet::genesis_config]\n        #[derive(DefaultNoBound)]\n        pub struct GenesisConfig<T: Config> {\n            pub initial_counter_value: u32,\n            pub initial_user_interactions: Vec<(T::AccountId, u32)>,\n        }\n\n        #[pallet::genesis_build]\n        impl<T: Config> BuildGenesisConfig for GenesisConfig<T> {\n            fn build(&self) {\n                CounterValue::<T>::put(self.initial_counter_value);\n                for (account, count) in &self.initial_user_interactions {\n                    UserInteractions::<T>::insert(account, count);\n                }\n            }\n        }\n\n        #[pallet::call]\n        impl<T: Config> Pallet<T> {\n            #[pallet::call_index(0)]\n            #[pallet::weight(0)]\n            pub fn set_counter_value(origin: OriginFor<T>, new_value: u32) -> DispatchResult {\n                ensure_root(origin)?;\n                ensure!(new_value <= T::CounterMaxValue::get(), Error::<T>::CounterMaxValueExceeded);\n                CounterValue::<T>::put(new_value);\n                Self::deposit_event(Event::CounterValueSet { new_value });\n                Ok(())\n            }\n\n            #[pallet::call_index(1)]\n            #[pallet::weight(0)]\n            pub fn increment(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n                let who = ensure_signed(origin)?;\n                let current_value = CounterValue::<T>::get();\n                let new_value = current_value.checked_add(amount).ok_or(Error::<T>::Overflow)?;\n                ensure!(new_value <= T::CounterMaxValue::get(), Error::<T>::CounterMaxValueExceeded);\n                CounterValue::<T>::put(new_value);\n                UserInteractions::<T>::mutate(&who, |count| {\n                    *count = count.saturating_add(1);\n                });\n                Self::deposit_event(Event::CounterIncremented { new_value, who, amount });\n                Ok(())\n            }\n\n            #[pallet::call_index(2)]\n            #[pallet::weight(0)]\n            pub fn decrement(origin: OriginFor<T>, amount: u32) -> DispatchResult {\n                let who = ensure_signed(origin)?;\n                let current_value = CounterValue::<T>::get();\n                let new_value = current_value.checked_sub(amount).ok_or(Error::<T>::Underflow)?;\n                CounterValue::<T>::put(new_value);\n                UserInteractions::<T>::mutate(&who, |count| {\n                    *count = count.saturating_add(1);\n                });\n                Self::deposit_event(Event::CounterDecremented { new_value, who, amount });\n                Ok(())\n            }\n        }\n    }\n\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 8, "depth": 2, "title": "Write Your First Test", "anchor": "write-your-first-test", "start_char": 9226, "end_char": 9334, "estimated_token_count": 22, "token_estimator": "heuristic-v1", "text": "## Write Your First Test\n\nLet's start with a simple test to verify the increment function works correctly."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 9, "depth": 3, "title": "Test Basic Increment", "anchor": "test-basic-increment", "start_char": 9334, "end_char": 10412, "estimated_token_count": 238, "token_estimator": "heuristic-v1", "text": "### Test Basic Increment\n\nTest that the increment function increases counter value and emits events.\n\n```rust\n#[test]\nfn increment_works() {\n    new_test_ext().execute_with(|| {\n        // Set block number to 1 so events are registered\n        System::set_block_number(1);\n\n        let account = 1u64;\n\n        // Increment by 50\n        assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 50));\n        assert_eq!(crate::CounterValue::<Test>::get(), 50);\n\n        // Check event was emitted\n        System::assert_last_event(\n            Event::CounterIncremented {\n                new_value: 50,\n                who: account,\n                amount: 50,\n            }\n            .into(),\n        );\n\n        // Check user interactions were tracked\n        assert_eq!(crate::UserInteractions::<Test>::get(account), 1);\n    });\n}\n```\n\nRun your first test:\n\n```bash\ncargo test --package pallet-custom increment_works\n```\n\nYou should see:\n\n```\nrunning 1 test\ntest tests::increment_works ... ok\n```\n\nCongratulations! You've written and run your first pallet test."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 10, "depth": 2, "title": "Test Error Conditions", "anchor": "test-error-conditions", "start_char": 10412, "end_char": 10557, "estimated_token_count": 28, "token_estimator": "heuristic-v1", "text": "## Test Error Conditions\n\nNow let's test that our pallet correctly handles errors. Error testing is crucial to ensure your pallet fails safely."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 11, "depth": 3, "title": "Test Overflow Protection", "anchor": "test-overflow-protection", "start_char": 10557, "end_char": 11072, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "### Test Overflow Protection\n\nTest that incrementing at u32::MAX fails with Overflow error.\n\n```rust\n#[test]\nfn increment_fails_on_overflow() {\n    new_test_ext_with_counter(u32::MAX).execute_with(|| {\n        // Attempt to increment when at max u32 should fail\n        assert_noop!(\n            CustomPallet::increment(RuntimeOrigin::signed(1), 1),\n            Error::<Test>::Overflow\n        );\n    });\n}\n```\n\nTest overflow protection:\n\n```bash\ncargo test --package pallet-custom increment_fails_on_overflow\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 12, "depth": 3, "title": "Test Underflow Protection", "anchor": "test-underflow-protection", "start_char": 11072, "end_char": 11584, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "### Test Underflow Protection\n\nTest that decrementing below zero fails with Underflow error.\n\n```rust\n#[test]\nfn decrement_fails_on_underflow() {\n    new_test_ext_with_counter(10).execute_with(|| {\n        // Attempt to decrement below zero should fail\n        assert_noop!(\n            CustomPallet::decrement(RuntimeOrigin::signed(1), 11),\n            Error::<Test>::Underflow\n        );\n    });\n}\n```\n\nVerify underflow protection:\n\n```bash\ncargo test --package pallet-custom decrement_fails_on_underflow\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 13, "depth": 2, "title": "Test Access Control", "anchor": "test-access-control", "start_char": 11584, "end_char": 11688, "estimated_token_count": 17, "token_estimator": "heuristic-v1", "text": "## Test Access Control\n\nVerify that origin checks work correctly and unauthorized access is prevented."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 14, "depth": 3, "title": "Test Root-Only Access", "anchor": "test-root-only-access", "start_char": 11688, "end_char": 12453, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "### Test Root-Only Access\n\nTest that set_counter_value requires root origin and rejects signed origins.\n\n```rust\n#[test]\nfn set_counter_value_requires_root() {\n    new_test_ext().execute_with(|| {\n        let alice = 1u64;\n\n        // When: non-root user tries to set counter\n        // Then: should fail with BadOrigin\n        assert_noop!(\n            CustomPallet::set_counter_value(RuntimeOrigin::signed(alice), 100),\n            DispatchError::BadOrigin\n        );\n\n        // But root should succeed\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 100));\n        assert_eq!(crate::CounterValue::<Test>::get(), 100);\n    });\n}\n```\n\nTest access control:\n\n```bash\ncargo test --package pallet-custom set_counter_value_requires_root\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 15, "depth": 2, "title": "Test Event Emission", "anchor": "test-event-emission", "start_char": 12453, "end_char": 12540, "estimated_token_count": 16, "token_estimator": "heuristic-v1", "text": "## Test Event Emission\n\nVerify that events are emitted correctly with the right data."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 16, "depth": 3, "title": "Test Event Data", "anchor": "test-event-data", "start_char": 12540, "end_char": 13720, "estimated_token_count": 264, "token_estimator": "heuristic-v1", "text": "### Test Event Data\n\nThe [`increment_works`](/parachains/customize-runtime/pallet-development/pallet-testing/#test-basic-increment) test (shown earlier) already demonstrates event testing by:\n\n1. Setting the block number to 1 to enable event emission.\n2. Calling the dispatchable function.\n3. Using `System::assert_last_event()` to verify the correct event was emitted with expected data.\n\nThis pattern applies to all dispatchables that emit events. For a dedicated event-only test focusing on the `set_counter_value` function:\n\nTest that set_counter_value updates storage and emits correct event.\n\n```rust\n#[test]\nfn set_counter_value_works() {\n    new_test_ext().execute_with(|| {\n        // Set block number to 1 so events are registered\n        System::set_block_number(1);\n\n        // Set counter to 100\n        assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 100));\n        assert_eq!(crate::CounterValue::<Test>::get(), 100);\n\n        // Check event was emitted\n        System::assert_last_event(Event::CounterValueSet { new_value: 100 }.into());\n    });\n}\n```\n\nRun the event test:\n\n```bash\ncargo test --package pallet-custom set_counter_value_works\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 17, "depth": 2, "title": "Test Genesis Configuration", "anchor": "test-genesis-configuration", "start_char": 13720, "end_char": 13803, "estimated_token_count": 12, "token_estimator": "heuristic-v1", "text": "## Test Genesis Configuration\n\nVerify that genesis configuration works correctly."}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 18, "depth": 3, "title": "Test Genesis Setup", "anchor": "test-genesis-setup", "start_char": 13803, "end_char": 14422, "estimated_token_count": 160, "token_estimator": "heuristic-v1", "text": "### Test Genesis Setup\n\nTest that genesis configuration correctly initializes counter and user interactions.\n\n```rust\n#[test]\nfn genesis_config_works() {\n    new_test_ext_with_interactions(42, vec![(1, 5), (2, 10)]).execute_with(|| {\n        // Check initial counter value\n        assert_eq!(crate::CounterValue::<Test>::get(), 42);\n\n        // Check initial user interactions\n        assert_eq!(crate::UserInteractions::<Test>::get(1), 5);\n        assert_eq!(crate::UserInteractions::<Test>::get(2), 10);\n    });\n}\n```\n\nTest genesis configuration:\n\n```bash\ncargo test --package pallet-custom genesis_config_works\n```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 19, "depth": 2, "title": "Run All Tests", "anchor": "run-all-tests", "start_char": 14422, "end_char": 24762, "estimated_token_count": 2250, "token_estimator": "heuristic-v1", "text": "## Run All Tests\n\nNow run all your tests together:\n\n```bash\ncargo test --package pallet-custom\n```\n\nYou should see all tests passing:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\">$ cargo test --package pallet-custom</span>\n  <span data-ty>running 15 tests</span>\n  <span data-ty>test mock::__construct_runtime_integrity_test::runtime_integrity_tests ... ok</span>\n  <span data-ty>test mock::test_genesis_config_builds ... ok</span>\n  <span data-ty>test tests::decrement_fails_on_underflow ... ok</span>\n  <span data-ty>test tests::decrement_tracks_multiple_interactions ... ok</span>\n  <span data-ty>test tests::decrement_works ... ok</span>\n  <span data-ty>test tests::different_users_tracked_separately ... ok</span>\n  <span data-ty>test tests::genesis_config_works ... ok</span>\n  <span data-ty>test tests::increment_fails_on_overflow ... ok</span>\n  <span data-ty>test tests::increment_respects_max_value ... ok</span>\n  <span data-ty>test tests::increment_tracks_multiple_interactions ... ok</span>\n  <span data-ty>test tests::increment_works ... ok</span>\n  <span data-ty>test tests::mixed_increment_and_decrement_works ... ok</span>\n  <span data-ty>test tests::set_counter_value_requires_root ... ok</span>\n  <span data-ty>test tests::set_counter_value_respects_max_value ... ok</span>\n  <span data-ty>test tests::set_counter_value_works ... ok</span>\n  <span data-ty></span>\n  <span data-ty>test result: ok. 15 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out</span>\n</div>\n\n!!!note \"Mock Runtime Tests\"\n    You'll notice 2 additional tests from the `mock` module:\n\n    - `mock::__construct_runtime_integrity_test::runtime_integrity_tests` - Auto-generated test that validates runtime construction\n    - `mock::test_genesis_config_builds` - Validates that genesis configuration builds correctly\n\n    These tests are automatically generated from your mock runtime setup and help ensure the test environment itself is valid.\n\nCongratulations! You have a well-tested pallet covering the essential testing patterns!\n\nThese tests demonstrate comprehensive coverage including basic operations, error conditions, access control, event emission, state management, and genesis configuration. As you build more complex pallets, you'll apply these same patterns to test additional functionality.\n\n??? code \"Full Test Suite Code\"\n    Here's the complete `tests.rs` file for quick reference:\n\n    ```rust\n    use crate::{mock::*, Error, Event};\n    use frame::deps::frame_support::{assert_noop, assert_ok};\n    use frame::deps::sp_runtime::DispatchError;\n\n    #[test]\n    fn set_counter_value_works() {\n        new_test_ext().execute_with(|| {\n            // Set block number to 1 so events are registered\n            System::set_block_number(1);\n\n            // Set counter to 100\n            assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 100));\n            assert_eq!(crate::CounterValue::<Test>::get(), 100);\n\n            // Check event was emitted\n            System::assert_last_event(Event::CounterValueSet { new_value: 100 }.into());\n        });\n    }\n\n    #[test]\n    fn set_counter_value_requires_root() {\n        new_test_ext().execute_with(|| {\n            // Attempt to set counter with non-root origin should fail\n            assert_noop!(\n                CustomPallet::set_counter_value(RuntimeOrigin::signed(1), 100),\n                DispatchError::BadOrigin\n            );\n        });\n    }\n\n    #[test]\n    fn set_counter_value_respects_max_value() {\n        new_test_ext().execute_with(|| {\n            // Attempt to set counter above max value (1000) should fail\n            assert_noop!(\n                CustomPallet::set_counter_value(RuntimeOrigin::root(), 1001),\n                Error::<Test>::CounterMaxValueExceeded\n            );\n\n            // Setting to exactly max value should work\n            assert_ok!(CustomPallet::set_counter_value(RuntimeOrigin::root(), 1000));\n            assert_eq!(crate::CounterValue::<Test>::get(), 1000);\n        });\n    }\n\n    #[test]\n    fn increment_works() {\n        new_test_ext().execute_with(|| {\n            // Set block number to 1 so events are registered\n            System::set_block_number(1);\n\n            let account = 1u64;\n\n            // Increment by 50\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 50));\n            assert_eq!(crate::CounterValue::<Test>::get(), 50);\n\n            // Check event was emitted\n            System::assert_last_event(\n                Event::CounterIncremented {\n                    new_value: 50,\n                    who: account,\n                    amount: 50,\n                }\n                .into(),\n            );\n\n            // Check user interactions were tracked\n            assert_eq!(crate::UserInteractions::<Test>::get(account), 1);\n        });\n    }\n\n    #[test]\n    fn increment_tracks_multiple_interactions() {\n        new_test_ext().execute_with(|| {\n            let account = 1u64;\n\n            // Increment multiple times\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 10));\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 20));\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 30));\n\n            // Check counter value\n            assert_eq!(crate::CounterValue::<Test>::get(), 60);\n\n            // Check user interactions were tracked (should be 3)\n            assert_eq!(crate::UserInteractions::<Test>::get(account), 3);\n        });\n    }\n\n    #[test]\n    fn increment_fails_on_overflow() {\n        new_test_ext_with_counter(u32::MAX).execute_with(|| {\n            // Attempt to increment when at max u32 should fail\n            assert_noop!(\n                CustomPallet::increment(RuntimeOrigin::signed(1), 1),\n                Error::<Test>::Overflow\n            );\n        });\n    }\n\n    #[test]\n    fn increment_respects_max_value() {\n        new_test_ext_with_counter(950).execute_with(|| {\n            // Incrementing past max value (1000) should fail\n            assert_noop!(\n                CustomPallet::increment(RuntimeOrigin::signed(1), 51),\n                Error::<Test>::CounterMaxValueExceeded\n            );\n\n            // Incrementing to exactly max value should work\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(1), 50));\n            assert_eq!(crate::CounterValue::<Test>::get(), 1000);\n        });\n    }\n\n    #[test]\n    fn decrement_works() {\n        new_test_ext_with_counter(100).execute_with(|| {\n            // Set block number to 1 so events are registered\n            System::set_block_number(1);\n\n            let account = 2u64;\n\n            // Decrement by 30\n            assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(account), 30));\n            assert_eq!(crate::CounterValue::<Test>::get(), 70);\n\n            // Check event was emitted\n            System::assert_last_event(\n                Event::CounterDecremented {\n                    new_value: 70,\n                    who: account,\n                    amount: 30,\n                }\n                .into(),\n            );\n\n            // Check user interactions were tracked\n            assert_eq!(crate::UserInteractions::<Test>::get(account), 1);\n        });\n    }\n\n    #[test]\n    fn decrement_fails_on_underflow() {\n        new_test_ext_with_counter(10).execute_with(|| {\n            // Attempt to decrement below zero should fail\n            assert_noop!(\n                CustomPallet::decrement(RuntimeOrigin::signed(1), 11),\n                Error::<Test>::Underflow\n            );\n        });\n    }\n\n    #[test]\n    fn decrement_tracks_multiple_interactions() {\n        new_test_ext_with_counter(100).execute_with(|| {\n            let account = 3u64;\n\n            // Decrement multiple times\n            assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(account), 10));\n            assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(account), 20));\n\n            // Check counter value\n            assert_eq!(crate::CounterValue::<Test>::get(), 70);\n\n            // Check user interactions were tracked (should be 2)\n            assert_eq!(crate::UserInteractions::<Test>::get(account), 2);\n        });\n    }\n\n    #[test]\n    fn mixed_increment_and_decrement_works() {\n        new_test_ext_with_counter(50).execute_with(|| {\n            let account = 4u64;\n\n            // Mix of increment and decrement\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 25));\n            assert_eq!(crate::CounterValue::<Test>::get(), 75);\n\n            assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(account), 15));\n            assert_eq!(crate::CounterValue::<Test>::get(), 60);\n\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account), 10));\n            assert_eq!(crate::CounterValue::<Test>::get(), 70);\n\n            // Check user interactions were tracked (should be 3)\n            assert_eq!(crate::UserInteractions::<Test>::get(account), 3);\n        });\n    }\n\n    #[test]\n    fn different_users_tracked_separately() {\n        new_test_ext().execute_with(|| {\n            let account1 = 1u64;\n            let account2 = 2u64;\n\n            // User 1 increments\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account1), 10));\n            assert_ok!(CustomPallet::increment(RuntimeOrigin::signed(account1), 10));\n\n            // User 2 decrements\n            assert_ok!(CustomPallet::decrement(RuntimeOrigin::signed(account2), 5));\n\n            // Check counter value (10 + 10 - 5 = 15)\n            assert_eq!(crate::CounterValue::<Test>::get(), 15);\n\n            // Check user interactions are tracked separately\n            assert_eq!(crate::UserInteractions::<Test>::get(account1), 2);\n            assert_eq!(crate::UserInteractions::<Test>::get(account2), 1);\n        });\n    }\n\n    #[test]\n    fn genesis_config_works() {\n        new_test_ext_with_interactions(42, vec![(1, 5), (2, 10)]).execute_with(|| {\n            // Check initial counter value\n            assert_eq!(crate::CounterValue::<Test>::get(), 42);\n\n            // Check initial user interactions\n            assert_eq!(crate::UserInteractions::<Test>::get(1), 5);\n            assert_eq!(crate::UserInteractions::<Test>::get(2), 10);\n        });\n    }\n    ```"}
{"page_id": "parachains-customize-runtime-pallet-development-pallet-testing", "page_title": "Unit Test Pallets", "index": 20, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 24762, "end_char": 25145, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Benchmark Your Pallet__\n\n    ---\n\n    Learn how to benchmark extrinsics in your custom pallet to generate precise weight calculations suitable for production use.\n\n    [:octicons-arrow-right-24: Integrate](/parachains/customize-runtime/pallet-development/benchmark-pallet/)\n\n</div>"}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 26, "end_char": 776, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nA blockchain runtime is more than just a fixed set of rulesâ€”it's a dynamic foundation that you can shape to match your specific needs. With Polkadot SDK's [FRAME (Framework for Runtime Aggregation of Modularized Entities)](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank}, customizing your runtime is straightforward and modular. Instead of building everything from scratch, you combine pre-built pallets with your own custom logic to create a runtime suited to your blockchain's purpose.\n\n\n\nThis overview explains how runtime customization works, introduces the building blocks you'll use, and guides you through the key patterns for extending your runtime."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 1, "depth": 2, "title": "Understanding Your Runtime", "anchor": "understanding-your-runtime", "start_char": 776, "end_char": 1555, "estimated_token_count": 158, "token_estimator": "heuristic-v1", "text": "## Understanding Your Runtime\n\nThe runtime is the core logic of your blockchainâ€”it processes transactions, manages state, and enforces the rules that govern your network. When a transaction arrives at your blockchain, the [`frame_executive`](https://paritytech.github.io/polkadot-sdk/master/frame_executive/index.html){target=\\_blank} pallet receives it and routes it to the appropriate pallet for execution.\n\nThink of your runtime as a collection of specialized modules, each handling a different aspect of your blockchain. Need token balances? Use the Balances pallet. Want governance? Add the Governance pallets. Need something custom? Create your own pallet. By mixing and matching these modules, you build a runtime that's efficient, secure, and tailored to your use case."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 2, "depth": 2, "title": "Runtime Architecture", "anchor": "runtime-architecture", "start_char": 1555, "end_char": 2107, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## Runtime Architecture\n\nThe following diagram shows how FRAME components work together to form your runtime:\n\n![](/images/parachains/customize-runtime/index/frame-overview-01.webp)\n\nThe main components are:\n\n- **`frame_executive`**: Routes all incoming transactions to the correct pallet for execution.\n- **Pallets**: Domain-specific modules that implement your blockchain's features and business logic.\n- **`frame_system`**: Provides core runtime primitives and storage.\n- **`frame_support`**: Utilities and macros that simplify pallet development."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 3, "depth": 2, "title": "Building Blocks: Pallets", "anchor": "building-blocks-pallets", "start_char": 2107, "end_char": 2699, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Building Blocks: Pallets\n\n[Pallets](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/pallet/index.html){target=\\_blank} are the fundamental units of runtime customization. Each pallet encapsulates specific functionality and can be independently developed, tested, and integrated.\n\nA pallet can implement virtually any blockchain feature you need:\n\n- Expose new transactions that users can submit.\n- Store data on-chain.\n- Enforce business rules and validation logic.\n- Emit events to notify users of state changes.\n- Handle errors gracefully."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 4, "depth": 3, "title": "Pre-Built Pallets vs. Custom Pallets", "anchor": "pre-built-pallets-vs-custom-pallets", "start_char": 2699, "end_char": 3363, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "### Pre-Built Pallets vs. Custom Pallets\n\nFRAME provides a comprehensive library of [pre-built pallets](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/substrate/frame){target=\\_blank} for common blockchain features, including consensus, staking, balances, governance, and more. These pallets are battle-tested, optimized, and ready to use.\n\nHowever, you're not limited to pre-built functionality. When pre-built pallets don't meet your needs, you can create custom pallets with entirely custom logic. The real power of FRAME is the flexibility to use pre-built modules for standard features while building your own for unique requirements."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 5, "depth": 3, "title": "Pallet Structure", "anchor": "pallet-structure", "start_char": 3363, "end_char": 4678, "estimated_token_count": 372, "token_estimator": "heuristic-v1", "text": "### Pallet Structure\n\nFRAME uses Rust macros extensively, allowing you to focus on your pallet's logic while the framework handles boilerplate and integration code.\n\nA typical pallet looks like this:\n\n```rust\npub use pallet::*;\n\n#[frame_support::pallet]\npub mod pallet {\n  use frame_support::pallet_prelude::*;\n  use frame_system::pallet_prelude::*;\n\n  #[pallet::pallet]\n  #[pallet::generate_store(pub(super) trait Store)]\n  pub struct Pallet<T>(_);\n\n  #[pallet::config]  // snip\n  #[pallet::event]   // snip\n  #[pallet::error]   // snip\n  #[pallet::storage] // snip\n  #[pallet::call]    // snip\n}\n```\n\nEvery pallet can implement these core macros:\n\n- **`#[frame_support::pallet]`**: Marks your module as a FRAME pallet.\n- **`#[pallet::pallet]`**: Designates the struct that holds pallet metadata.\n- **`#[pallet::config]`**: Defines configuration and associated types.\n- **`#[pallet::event]`**: Defines events emitted by your pallet.\n- **`#[pallet::error]`**: Defines error types your pallet can return.\n- **`#[pallet::storage]`**: Defines on-chain storage items.\n- **`#[pallet::call]`**: Defines dispatchable functions (transactions).\n\nFor a comprehensive reference, see the [`pallet_macros` documentation](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/index.html){target=\\_blank}."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 6, "depth": 2, "title": "How Runtime Customization Works", "anchor": "how-runtime-customization-works", "start_char": 4678, "end_char": 5596, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## How Runtime Customization Works\n\nCustomizing your runtime typically follows these patterns:\n\n**Adding Pre-Built Pallets**: Select pallets from the FRAME library and integrate them into your runtime configuration. This is the fastest way to add functionality.\n\n**Creating Custom Pallets**: Write custom pallets for features that don't exist in the pre-built library. Custom pallets follow the same structure as pre-built ones and integrate seamlessly.\n\n**Combining Multiple Pallets**: Layer multiple pallets together to create complex behaviors. Pallets can call each other and share storage when needed.\n\n**Configuring Pallet Parameters**: Most pallets are configurableâ€”you can adjust their behavior through configuration traits without modifying their code.\n\nThe following diagram illustrates how pallets combine to form a complete runtime:\n\n![](/images/parachains/customize-runtime/index/frame-overview-02.webp)"}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 7, "depth": 2, "title": "Starting Templates", "anchor": "starting-templates", "start_char": 5596, "end_char": 7219, "estimated_token_count": 357, "token_estimator": "heuristic-v1", "text": "## Starting Templates\n\nThe easiest way to begin customizing your runtime is with a starter template. These templates provide a pre-configured foundation so you can focus on customization rather than setup.\n\n- **[Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank}**: The recommended choice for most developers, it includes pre-configured pallets for common features (balances, block production, governance), a complete runtime setup, and built-in parachain consensus support. This template offers the best balance of features and learning opportunities.\n\n- **[Polkadot SDK Minimal Template](https://github.com/paritytech/polkadot-sdk-minimal-template){target=\\_blank}**: Provides a bare-bones runtime with only essential components. Choose this if you want maximum flexibility and prefer building from a clean slate.\n\n- **[Polkadot SDK Solochain Template](https://github.com/paritytech/polkadot-sdk/tree/master/templates/solochain){target=\\_blank}**: Designed for building standalone blockchains with moderate features, simple consensus, and several core pallets. Use this if you want a sovereign blockchain independent of a relay chain.\n\n- **[OpenZeppelin Runtime Templates](https://github.com/OpenZeppelin/polkadot-runtime-templates){target=\\_blank}**: Provides security-focused configurations following industry best practices. The [generic-template](https://github.com/OpenZeppelin/polkadot-runtime-templates/tree/main/generic-template){target=\\_blank} includes curated pallet selections and production-ready defaultsâ€”ideal if security is your top priority."}
{"page_id": "parachains-customize-runtime", "page_title": "Overview of FRAME", "index": 8, "depth": 2, "title": "Key Customization Scenarios", "anchor": "key-customization-scenarios", "start_char": 7219, "end_char": 8259, "estimated_token_count": 232, "token_estimator": "heuristic-v1", "text": "## Key Customization Scenarios\n\nThis section covers the most common customization patterns you'll encounter:\n\n- **[Add Existing Pallets to Your Runtime](/parachains/customize-runtime/add-existing-pallets/)**: Integrate pre-built pallets from the FRAME library with minimal configuration.\n\n- **[Add Multiple Instances of a Pallet](/parachains/customize-runtime/add-pallet-instances/)**: Run multiple instances of the same pallet with different configurationsâ€”useful for multi-token systems or parallel features.\n\n- **[Add Smart Contract Functionality](/parachains/customize-runtime/add-smart-contract-functionality/)**: Enable smart contract execution on your parachain using Contracts pallets.\n\n- **[Create Custom Pallets](/parachains/customize-runtime/pallet-development/create-a-pallet/)**: Build entirely custom pallets for features unique to your blockchain.\n\n- **[Test Your Runtime](/parachains/customize-runtime/pallet-development/pallet-testing/)**: Unit test pallets and mock complete runtimes to ensure everything works correctly."}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 0, "depth": 2, "title": "Quick Start Guides", "anchor": "quick-start-guides", "start_char": 186, "end_char": 1325, "estimated_token_count": 345, "token_estimator": "heuristic-v1", "text": "## Quick Start Guides\n\nQuick start guides help developers set up and interact with the Polkadot parachain ecosystem using various tools and frameworks.\n\n|                                            Tutorial                                            |         Tools         |                               Description                               |\n|:----------------------------------------------------------------------------------------------:|:---------------------:|:-----------------------------------------------------------------------:|\n| [Set Up the Parachain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/) |     Polkadot SDK      | Learn how to set up and run the Polkadot SDK Parachain Template locally |\n|            [Launch a Local Parachain](/parachains/testing/run-a-parachain-network/)            | Zombienet, Chopsticks |           Set up a local development environment for testing            |\n|              [Fork an Existing Parachain](/parachains/testing/fork-a-parachain/)               |      Chopsticks       |           Create a local fork of a live parachain for testing           |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 1, "depth": 2, "title": "Launch a Simple Parachain", "anchor": "launch-a-simple-parachain", "start_char": 1325, "end_char": 2319, "estimated_token_count": 305, "token_estimator": "heuristic-v1", "text": "## Launch a Simple Parachain\n\nLearn the fundamentals of launching and deploying a parachain to the Polkadot network.\n\n|                                            Tutorial                                            |                                Description                                |\n|:----------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------:|\n| [Set Up the Parachain Template](/parachains/launch-a-parachain/set-up-the-parachain-template/) |                               Polkadot SDK                                |\n|            [Deploy to Polkadot](/parachains/launch-a-parachain/deploy-to-polkadot/)            |       Step-by-step tutorial to deploying your parachain to Polkadot       |\n|               [Obtain Coretime](/parachains/launch-a-parachain/obtain-coretime/)               | Learn how to acquire blockspace using Polkadot's coretime model (RegionX) |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 2, "depth": 2, "title": "Customize Your Runtime", "anchor": "customize-your-runtime", "start_char": 2319, "end_char": 3289, "estimated_token_count": 298, "token_estimator": "heuristic-v1", "text": "## Customize Your Runtime\n\nBuild custom functionality for your parachain by composing and creating pallets.\n\n|                                              Tutorial                                               |                            Description                            |\n|:---------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------:|\n|     [Add Existing Pallets to the Runtime](/parachains/customize-runtime/add-existing-pallets/)      |       Integrate pre-built pallets from the FRAME ecosystem        |\n|      [Add Multiple Instances of a Pallet](/parachains/customize-runtime/add-pallet-instances/)      |      Configure and use multiple instances of the same pallet      |\n| [Add Smart Contract Functionality](/parachains/customize-runtime/add-smart-contract-functionality/) | Enable smart contract capabilities using Contracts or EVM pallets |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 3, "depth": 3, "title": "Pallet Development", "anchor": "pallet-development", "start_char": 3289, "end_char": 4359, "estimated_token_count": 317, "token_estimator": "heuristic-v1", "text": "### Pallet Development\n\nDeep dive into creating and managing custom pallets for your parachain.\n\n|                                             Tutorial                                              |                        Description                        |\n|:-------------------------------------------------------------------------------------------------:|:---------------------------------------------------------:|\n|    [Create a Custom Pallet](/parachains/customize-runtime/pallet-development/create-a-pallet/)    |       Build a pallet from scratch with custom logic       |\n|        [Mock Your Runtime](/parachains/customize-runtime/pallet-development/mock-runtime/)        |       Set up a mock runtime environment for testing       |\n|      [Pallet Unit Testing](/parachains/customize-runtime/pallet-development/pallet-testing/)      |      Write comprehensive tests for your pallet logic      |\n| [Benchmark the Custom Pallet](/parachains/customize-runtime/pallet-development/benchmark-pallet/) | Measure and optimize pallet performance with benchmarking |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 4, "depth": 2, "title": "Testing", "anchor": "testing", "start_char": 4359, "end_char": 4983, "estimated_token_count": 213, "token_estimator": "heuristic-v1", "text": "## Testing\n\nTest your parachain in various environments before production deployment.\n\n|                                Tutorial                                 |                       Description                       |\n|:-----------------------------------------------------------------------:|:-------------------------------------------------------:|\n|        [Fork a Parachain](/parachains/testing/fork-a-parachain/)        |    Use Chopsticks to create a local fork for testing    |\n| [Run a Parachain Network](/parachains/testing/run-a-parachain-network/) | Launch a complete parachain test network with Zombienet |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 5, "depth": 2, "title": "Runtime Upgrades and Maintenance", "anchor": "runtime-upgrades-and-maintenance", "start_char": 4983, "end_char": 5772, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "## Runtime Upgrades and Maintenance\n\nManage your parachain's lifecycle with forkless upgrades and maintenance operations.\n\n|                                 Tutorial                                  |                     Description                      |\n|:-------------------------------------------------------------------------:|:----------------------------------------------------:|\n|   [Runtime Upgrades](/parachains/runtime-maintenance/runtime-upgrades/)   |   Perform forkless runtime upgrades via governance   |\n| [Storage Migrations](/parachains/runtime-maintenance/storage-migrations/) |  Safely migrate storage when updating runtime logic  |\n|  [Unlock Parachains](/parachains/runtime-maintenance/unlock-parachains/)  | Understand parachain lifecycle and unlock mechanisms |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 6, "depth": 2, "title": "Interoperability", "anchor": "interoperability", "start_char": 5772, "end_char": 6561, "estimated_token_count": 255, "token_estimator": "heuristic-v1", "text": "## Interoperability\n\nConfigure your parachain for cross-chain communication using XCM (Cross-Consensus Messaging).\n\n|                                                  Tutorial                                                  |                      Description                       |\n|:----------------------------------------------------------------------------------------------------------:|:------------------------------------------------------:|\n|     [Open HRMP Channels Between Parachains](/parachains/interoperability/channels-between-parachains/)     | Establish communication channels with other parachains |\n| [Open HRMP Channels with System Parachains](/parachains/interoperability/channels-with-system-parachains/) |   Connect with Asset Hub and other system parachains   |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 7, "depth": 2, "title": "Integrations", "anchor": "integrations", "start_char": 6561, "end_char": 7190, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Integrations\n\nIntegrate your parachain with essential ecosystem tools and services.\n\n|                    Tutorial                    |                      Description                       |\n|:----------------------------------------------:|:------------------------------------------------------:|\n|  [Wallets](/parachains/integrations/wallets/)  |     Integrate wallet support for user interactions     |\n| [Indexers](/parachains/integrations/indexers/) | Set up indexing solutions for querying blockchain data |\n|  [Oracles](/parachains/integrations/oracles/)  |    Connect your parachain to off-chain data sources    |"}
{"page_id": "parachains-get-started", "page_title": "Get Started with Parachain Development", "index": 8, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 7190, "end_char": 7423, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- [Polkadot SDK Documentation](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html)\n- [Polkadot Wiki - Parachains](https://wiki.polkadot.network/docs/learn-parachains/)"}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 0, "depth": 2, "title": "Install Dependencies: macOS", "anchor": "install-dependencies-macos", "start_char": 495, "end_char": 656, "estimated_token_count": 28, "token_estimator": "heuristic-v1", "text": "## Install Dependencies: macOS\n\nYou can install Rust and set up a Substrate development environment on Apple macOS computers with Intel or Apple M1 processors."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 1, "depth": 3, "title": "Before You Begin {: #before-you-begin-mac-os }", "anchor": "before-you-begin-before-you-begin-mac-os", "start_char": 656, "end_char": 1113, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "### Before You Begin {: #before-you-begin-mac-os }\n\nBefore you install Rust and set up your development environment on macOS, verify that your computer meets the following basic requirements:\n\n- Operating system version is 10.7 Lion or later.\n- Processor speed of at least 2 GHz. Note that 3 GHz is recommended.\n- Memory of at least 8 GB RAM. Note that 16 GB is recommended.\n- Storage of at least 10 GB of available space.\n- Broadband Internet connection."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 2, "depth": 3, "title": "Install Homebrew", "anchor": "install-homebrew", "start_char": 1113, "end_char": 1964, "estimated_token_count": 206, "token_estimator": "heuristic-v1", "text": "### Install Homebrew\n\nIn most cases, you should use Homebrew to install and manage packages on macOS computers. If you don't already have Homebrew installed on your local computer, you should download and install it before continuing.\n\nTo install Homebrew:\n\n1. Open the Terminal application.\n2. Download and install Homebrew by running the following command:\n\n    ```bash\n    /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n    ```\n\n3. Verify Homebrew has been successfully installed by running the following command:\n\n    ```bash\n    brew --version\n    ```\n\n    The command displays output similar to the following:\n\n    <div id=\"termynal\" data-termynal markdown>\n      <span data-ty=\"input\"><span class=\"file-path\"></span>brew --version</span>\n      <span data-ty>Homebrew 4.3.15</span>\n    </div>"}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 3, "depth": 3, "title": "Support for Apple Silicon", "anchor": "support-for-apple-silicon", "start_char": 1964, "end_char": 2136, "estimated_token_count": 37, "token_estimator": "heuristic-v1", "text": "### Support for Apple Silicon\n\nProtobuf must be installed before the build process can begin. To install it, run the following command:\n\n```bash\nbrew install protobuf\n```"}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 4, "depth": 3, "title": "Install Required Packages and Rust {: #install-required-packages-and-rust-mac-os }", "anchor": "install-required-packages-and-rust-install-required-packages-and-rust-mac-os", "start_char": 2136, "end_char": 3585, "estimated_token_count": 315, "token_estimator": "heuristic-v1", "text": "### Install Required Packages and Rust {: #install-required-packages-and-rust-mac-os }\n\nBecause the blockchain requires standard cryptography to support the generation of public/private key pairs and the validation of transaction signatures, you must also have a package that provides cryptography, such as `openssl`.\n\nTo install `openssl` and the Rust toolchain on macOS:\n\n1. Open the Terminal application.\n2. Ensure you have an updated version of Homebrew by running the following command:\n\n    ```bash\n    brew update\n    ```\n\n3. Install the `openssl` package by running the following command:\n\n    ```bash\n    brew install openssl\n    ```\n\n4. Download the `rustup` installation program and use it to install Rust by running the following command:\n\n    ```bash\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n\n5. Follow the prompts displayed to proceed with a default installation.\n6. Update your current shell to include Cargo by running the following command:\n\n    ```bash\n    source ~/.cargo/env\n    ```\n\n7. Configure the Rust toolchain to default to the latest stable version by running the following commands:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup target add wasm32-unknown-unknown\n    rustup component add rust-src\n    ```\n\n8. Install `cmake` using the following command:\n\n    ```bash\n    brew install cmake\n    ```\n\n9. Proceed to [Build the Polkadot SDK](#build-the-polkadot-sdk)."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 5, "depth": 2, "title": "Install Dependencies: Linux", "anchor": "install-dependencies-linux", "start_char": 3585, "end_char": 3983, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Install Dependencies: Linux\n\nRust supports most Linux distributions. Depending on the specific distribution and version of the operating system you use, you might need to add some software dependencies to your environment. In general, your development environment should include a linker or a C-compatible compiler, such as `clang`, and an appropriate integrated development environment (IDE)."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 6, "depth": 3, "title": "Before You Begin {: #before-you-begin-linux }", "anchor": "before-you-begin-before-you-begin-linux", "start_char": 3983, "end_char": 4735, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "### Before You Begin {: #before-you-begin-linux }\n\nCheck the documentation for your operating system for information about the installed packages and how to download and install any additional packages you might need. For example, if you use Ubuntu, you can use the Ubuntu Advanced Packaging Tool (`apt`) to install the `build-essential` package:\n\n```bash\nsudo apt install build-essential\n```\n\nAt a minimum, you need the following packages before you install Rust:\n\n```text\nclang curl git make\n```\n\nBecause the blockchain requires standard cryptography to support the generation of public/private key pairs and the validation of transaction signatures, you must also have a package that provides cryptography, such as `libssl-dev` or `openssl-devel`."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 7, "depth": 3, "title": "Install Required Packages and Rust {: #install-required-packages-and-rust-linux }", "anchor": "install-required-packages-and-rust-install-required-packages-and-rust-linux", "start_char": 4735, "end_char": 7130, "estimated_token_count": 492, "token_estimator": "heuristic-v1", "text": "### Install Required Packages and Rust {: #install-required-packages-and-rust-linux }\n\nTo install the Rust toolchain on Linux:\n\n1. Open a terminal shell.\n2. Check the packages installed on the local computer by running the appropriate package management command for your Linux distribution.\n3. Add any package dependencies you are missing to your local development environment by running the appropriate package management command for your Linux distribution:\n\n    === \"Ubuntu\"\n\n        ```bash\n        sudo apt install --assume-yes git clang curl libssl-dev protobuf-compiler\n        ```\n\n    === \"Debian\"\n\n        ```sh\n        sudo apt install --assume-yes git clang curl libssl-dev llvm libudev-dev make protobuf-compiler\n        ```\n\n    === \"Arch\"\n\n        ```sh\n        pacman -Syu --needed --noconfirm curl git clang make protobuf\n        ```\n\n    === \"Fedora\"\n\n        ```sh\n        sudo dnf update\n        sudo dnf install clang curl git openssl-devel make protobuf-compiler\n        ```\n\n    === \"OpenSUSE\"\n\n        ```sh\n        sudo zypper install clang curl git openssl-devel llvm-devel libudev-devel make protobuf\n        ```\n\n    Remember that different distributions might use different package managers and bundle packages in different ways. For example, depending on your installation selections, Ubuntu Desktop and Ubuntu Server might have different packages and different requirements. However, the packages listed in the command-line examples are applicable to many common Linux distributions, including Debian, Linux Mint, MX Linux, and Elementary OS.\n\n4. Download the `rustup` installation program and use it to install Rust by running the following command:\n\n    ```bash\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n\n5. Follow the prompts displayed to proceed with a default installation.\n6. Update your current shell to include Cargo by running the following command:\n\n    ```bash\n    source $HOME/.cargo/env\n    ```\n\n7. Verify your installation by running the following command:\n\n    ```bash\n    rustc --version\n    ```\n\n8. Configure the Rust toolchain to default to the latest stable version by running the following commands:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup target add wasm32-unknown-unknown\n    rustup component add rust-src\n    ```\n\n9. Proceed to [Build the Polkadot SDK](#build-the-polkadot-sdk)."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 8, "depth": 2, "title": "Install Dependencies: Windows (WSL)", "anchor": "install-dependencies-windows-wsl", "start_char": 7130, "end_char": 7723, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "## Install Dependencies: Windows (WSL)\n\nIn general, UNIX-based operating systemsâ€”like macOS or Linuxâ€”provide a better development environment for building Substrate-based blockchains.\n\nHowever, suppose your local computer uses Microsoft Windows instead of a UNIX-based operating system. In that case, you can configure it with additional software to make it a suitable development environment for building Substrate-based blockchains. To prepare a development environment on a Microsoft Windows computer, you can use Windows Subsystem for Linux (WSL) to emulate a UNIX operating environment."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 9, "depth": 3, "title": "Before You Begin {: #before-you-begin-windows-wls }", "anchor": "before-you-begin-before-you-begin-windows-wls", "start_char": 7723, "end_char": 8306, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "### Before You Begin {: #before-you-begin-windows-wls }\n\nBefore installing on Microsoft Windows, verify the following basic requirements:\n\n- You have a computer running a supported Microsoft Windows operating system:\n    - **For Windows desktop**: You must be running Microsoft Windows 10, version 2004 or later, or Microsoft Windows 11 to install WSL.\n    - **For Windows server**: You must be running Microsoft Windows Server 2019, or later, to install WSL on a server operating system.\n- You have a good internet connection and access to a shell terminal on your local computer."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 10, "depth": 3, "title": "Set Up Windows Subsystem for Linux", "anchor": "set-up-windows-subsystem-for-linux", "start_char": 8306, "end_char": 10587, "estimated_token_count": 496, "token_estimator": "heuristic-v1", "text": "### Set Up Windows Subsystem for Linux\n\nWSL enables you to emulate a Linux environment on a computer that uses the Windows operating system. The primary advantage of this approach for Substrate development is that you can use all of the code and command-line examples as described in the Substrate documentation. For example, you can run common commandsâ€”such as `ls` and `ps`â€”unmodified. By using WSL, you can avoid configuring a virtual machine image or a dual-boot operating system.\n\nTo prepare a development environment using WSL:\n\n1. Check your Windows version and build number to see if WSL is enabled by default.\n\n    If you have Microsoft Windows 10, version 2004 (Build 19041 and higher), or Microsoft Windows 11, WSL is available by default and you can continue to the next step.\n\n    If you have an older version of Microsoft Windows installed, see the [WSL manual installation steps for older versions](https://learn.microsoft.com/en-us/windows/wsl/install-manual){target=\\_blank}. If you are installing on an older version of Microsoft Windows, you can download and install WLS 2 if your computer has Windows 10, version 1903 or higher.\n\n2. Select **Windows PowerShell** or **Command Prompt** from the **Start** menu, right-click, then **Run as administrator**.\n\n3. In the PowerShell or Command Prompt terminal, run the following command:\n\n    ```bash\n    wsl --install\n    ```\n\n    This command enables the required WSL 2 components that are part of the Windows operating system, downloads the latest Linux kernel, and installs the Ubuntu Linux distribution by default.\n\n    If you want to review the other Linux distributions available, run the following command:\n\n    ```bash\n    wsl --list --online\n    ```\n\n4. After the distribution is downloaded, close the terminal.\n\n5. Click the **Start** menu, select **Shut down or sign out**, then click **Restart** to restart the computer.\n\n    Restarting the computer is required to start the installation of the Linux distribution. It can take a few minutes for the installation to complete after you restart.\n\n    For more information about setting up WSL as a development environment, see the [Set up a WSL development environment](https://learn.microsoft.com/en-us/windows/wsl/setup/environment){target=\\_blank} docs."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 11, "depth": 3, "title": "Install Required Packages and Rust {: #install-required-packages-and-rust-windows-wls }", "anchor": "install-required-packages-and-rust-install-required-packages-and-rust-windows-wls", "start_char": 10587, "end_char": 12164, "estimated_token_count": 356, "token_estimator": "heuristic-v1", "text": "### Install Required Packages and Rust {: #install-required-packages-and-rust-windows-wls }\n\nTo install the Rust toolchain on WSL:\n\n1. Click the **Start** menu, then select **Ubuntu**.\n2. Type a UNIX user name to create a user account.\n3. Type a password for your UNIX user, then retype the password to confirm it.\n4. Download the latest updates for the Ubuntu distribution using the Ubuntu Advanced Packaging Tool (`apt`) by running the following command:\n\n    ```bash\n    sudo apt update\n    ```\n\n5. Add the required packages for the Ubuntu distribution by running the following command:\n\n    ```bash\n    sudo apt install --assume-yes git clang curl libssl-dev llvm libudev-dev make protobuf-compiler\n    ```\n\n6. Download the `rustup` installation program and use it to install Rust for the Ubuntu distribution by running the following command:\n\n    ```bash\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n\n7. Follow the prompts displayed to proceed with a default installation.\n\n8. Update your current shell to include Cargo by running the following command:\n\n    ```bash\n    source ~/.cargo/env\n    ```\n\n9. Verify your installation by running the following command:\n\n    ```bash\n    rustc --version\n    ```\n\n10. Configure the Rust toolchain to use the latest stable version as the default toolchain by running the following commands:\n\n    ```bash\n    rustup default stable\n    rustup update\n    rustup target add wasm32-unknown-unknown\n    rustup component add rust-src\n    ```\n\n11. Proceed to [Build the Polkadot SDK](#build-the-polkadot-sdk)."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 12, "depth": 2, "title": "Build the Polkadot SDK", "anchor": "build-the-polkadot-sdk", "start_char": 12164, "end_char": 12307, "estimated_token_count": 26, "token_estimator": "heuristic-v1", "text": "## Build the Polkadot SDK\n\nAfter installing all dependencies, you can now clone and compile the Polkadot SDK repository to verify your setup."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 13, "depth": 3, "title": "Clone the Polkadot SDK", "anchor": "clone-the-polkadot-sdk", "start_char": 12307, "end_char": 12538, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Clone the Polkadot SDK\n\n1. Clone the Polkadot SDK repository:\n\n    ```bash\n    git clone https://github.com/paritytech/polkadot-sdk.git\n    ```\n\n2. Navigate into the project directory:\n\n    ```bash\n    cd polkadot-sdk\n    ```"}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 14, "depth": 3, "title": "Compile the Polkadot SDK", "anchor": "compile-the-polkadot-sdk", "start_char": 12538, "end_char": 12912, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "### Compile the Polkadot SDK\n\nCompile the entire Polkadot SDK repository to ensure your environment is properly configured:\n\n```bash\ncargo build --release --locked\n```\n\n!!!note\n    This initial compilation will take significant time, depending on your machine specifications. It compiles all components of the Polkadot SDK to verify your toolchain is correctly configured."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 15, "depth": 3, "title": "Verify the Build", "anchor": "verify-the-build", "start_char": 12912, "end_char": 13686, "estimated_token_count": 168, "token_estimator": "heuristic-v1", "text": "### Verify the Build\n\nOnce the build completes successfully, verify the installation by checking the compiled binaries:\n\n```bash\nls target/release\n```\n\nYou should see several binaries, including:\n\n- `polkadot`: The Polkadot relay chain node.\n- `polkadot-parachain`: The parachain collator node.\n- `polkadot-omni-node`:The omni node for running parachains.\n- `substrate-node`: The kitchensink node with many pre-configured pallets.\n\nVerify the Polkadot binary works by checking its version:\n\n```bash\n./target/release/polkadot --version\n```\n\nThis should display version information similar to:\n\n```bash\npolkadot 1.16.0-1234abcd567\n```\n\nIf you see the version output without errors, your development environment is correctly configured and ready for Polkadot SDK development!"}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 16, "depth": 2, "title": "Optional: Run the Kitchensink Node", "anchor": "optional-run-the-kitchensink-node", "start_char": 13686, "end_char": 14214, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Optional: Run the Kitchensink Node\n\nThe Polkadot SDK includes a feature-rich node called \"kitchensink\" located at `substrate/bin/node`. This node comes pre-configured with many pallets and features from the Polkadot SDK, making it an excellent reference for exploring capabilities and understanding how different components work together.\n\n!!!note\n    If you've already compiled the Polkadot SDK in the previous step, the `substrate-node` binary is already built and ready to use. You can skip directly to running the node."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 17, "depth": 3, "title": "Run the Kitchensink Node in Development Mode", "anchor": "run-the-kitchensink-node-in-development-mode", "start_char": 14214, "end_char": 14804, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "### Run the Kitchensink Node in Development Mode\n\nFrom the `polkadot-sdk` root directory, start the kitchensink node in development mode:\n\n```bash\n./target/release/substrate-node --dev\n```\n\nThe `--dev` flag enables development mode, which:\n\n- Runs a single-node development chain.\n- Produces and finalizes blocks automatically.\n- Uses pre-configured development accounts (Alice, Bob, etc.).\n- Deletes all data when stopped, ensuring a clean state on restart.\n\n\nYou should see log output indicating the node is running and producing blocks, with increasing block numbers after `finalized`."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 18, "depth": 3, "title": "Interact with the Kitchensink Node", "anchor": "interact-with-the-kitchensink-node", "start_char": 14804, "end_char": 15697, "estimated_token_count": 225, "token_estimator": "heuristic-v1", "text": "### Interact with the Kitchensink Node\n\nThe kitchensink node is accessible at `ws://localhost:9944`. Open [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} in your browser to explore its features and connect to the local node.\n\n1. Click the network icon in the top left corner.\n2. Scroll to **Development** and select **Local Node**.\n3. Click **Switch** to connect to your local node.\n\n![](/images/parachains/install-polkadot-sdk/install-polkadot-sdk-1.webp)\n\nOnce connected, the interface updates its color scheme to indicate a successful connection to the local node.\n\n![](/images/parachains/install-polkadot-sdk/install-polkadot-sdk-2.webp)\n\nYou can now explore the various pallets and features included in the kitchensink node, making it a valuable reference as you develop your own blockchain applications.\n\nTo stop the node, press `Control-C` in the terminal."}
{"page_id": "parachains-install-polkadot-sdk", "page_title": "Install Polkadot SDK", "index": 19, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 15697, "end_char": 16051, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   __Get Started with Parachain Development__\n\n    ---\n\n    Practical examples and tutorials for building and deploying Polkadot parachains, covering everything from launch to customization and cross-chain messaging.\n\n    [:octicons-arrow-right-24: Get Started](/parachains/get-started/)\n \n</div>"}
{"page_id": "parachains-integrations-indexers", "page_title": "Indexers", "index": 0, "depth": 2, "title": "The Challenge of Blockchain Data Access", "anchor": "the-challenge-of-blockchain-data-access", "start_char": 12, "end_char": 649, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## The Challenge of Blockchain Data Access\n\nBlockchain data is inherently sequential and distributed, with information stored chronologically across numerous blocks. While retrieving data from a single block through JSON-RPC API calls is straightforward, more complex queries that span multiple blocks present significant challenges:\n\n- Data is scattered and unorganized across the blockchain.\n- Retrieving large datasets can take days or weeks to sync.\n- Complex operations (like aggregations, averages, or cross-chain queries) require additional processing.\n- Direct blockchain queries can impact dApp performance and responsiveness."}
{"page_id": "parachains-integrations-indexers", "page_title": "Indexers", "index": 1, "depth": 2, "title": "What is a Blockchain Indexer?", "anchor": "what-is-a-blockchain-indexer", "start_char": 649, "end_char": 1211, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## What is a Blockchain Indexer?\n\nA blockchain indexer is a specialized infrastructure tool that processes, organizes, and stores blockchain data in an optimized format for efficient querying. Think of it as a search engine for blockchain data that:\n\n- Continuously monitors the blockchain for new blocks and transactions.\n- Processes and categorizes this data according to predefined schemas.\n- Stores the processed data in an easily queryable database.\n- Provides efficient APIs (typically [GraphQL](https://graphql.org/){target=\\_blank}) for data retrieval."}
{"page_id": "parachains-integrations-indexers", "page_title": "Indexers", "index": 2, "depth": 2, "title": "Indexer Implementations", "anchor": "indexer-implementations", "start_char": 1211, "end_char": 2230, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "## Indexer Implementations\n\n<div class=\"grid cards\" markdown>\n\n-   __Subsquid__\n\n    ---\n\n    Subsquid is a data network that allows rapid and cost-efficient retrieval of blockchain data from 100+ chains using Subsquid's decentralized data lake and open-source SDK. In simple terms, Subsquid can be considered an ETL (extract, transform, and load) tool with a GraphQL server included. It enables comprehensive filtering, pagination, and even full-text search capabilities. Subsquid has native and full support for EVM and Substrate data, even within the same project.\n\n    [:octicons-arrow-right-24: Reference](https://www.sqd.ai/){target=\\_blank}\n\n-   __Subquery__\n\n    ---\n\n    SubQuery is a fast, flexible, and reliable open-source data decentralised infrastructure network that provides both RPC and indexed data to consumers worldwide.\n    It provides custom APIs for your web3 project across multiple supported chains.\n\n    [:octicons-arrow-right-24: Reference](https://subquery.network/){target=\\_blank}\n\n</div>"}
{"page_id": "parachains-integrations-oracles", "page_title": "Oracles", "index": 0, "depth": 2, "title": "What is a Blockchain Oracle?", "anchor": "what-is-a-blockchain-oracle", "start_char": 11, "end_char": 749, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## What is a Blockchain Oracle?\n\nOracles enable blockchains to access external data sources. Since blockchains operate as isolated networks, they cannot natively interact with external systems - this limitation is known as the \"blockchain oracle problem.\" Oracles solves this by extracting data from external sources (like APIs, IoT devices, or other blockchains), validating it, and submitting it on-chain.\n\nWhile simple oracle implementations may rely on a single trusted provider, more sophisticated solutions use decentralized networks where multiple providers stake assets and reach consensus on data validity. Typical applications include DeFi price feeds, weather data for insurance contracts, and cross-chain asset verification."}
{"page_id": "parachains-integrations-oracles", "page_title": "Oracles", "index": 1, "depth": 2, "title": "Oracle Implementations", "anchor": "oracle-implementations", "start_char": 749, "end_char": 1343, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Oracle Implementations\n\n<div class=\"grid cards\" markdown>\n\n-   __Acurast__\n\n    ---\n\n    Acurast is a decentralized, serverless cloud platform that uses a distributed network of mobile devices for oracle services, addressing centralized trust and data ownership issues. In the Polkadot ecosystem, it allows developers to define off-chain data and computation needs, which are processed by these devices acting as decentralized oracle nodes, delivering results to Substrate (Wasm) and EVM environments.\n\n    [:octicons-arrow-right-24: Reference](https://acurast.com/){target=\\_blank}\n\n</div>"}
{"page_id": "parachains-integrations-wallets", "page_title": "Wallets", "index": 0, "depth": 2, "title": "What is a Blockchain Wallet?", "anchor": "what-is-a-blockchain-wallet", "start_char": 11, "end_char": 761, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## What is a Blockchain Wallet?\n\nA wallet serves as your gateway to interacting with blockchain networks. Rather than storing funds, wallets secure your private keys, controlling access to your blockchain assets. Your private key provides complete control over all permitted transactions on your blockchain account, making it essential to keep it secure.\n\nWallet types fall into two categories based on their connection to the internet:\n\n- **[Hot wallets](#hot-wallets)**: Online storage through websites, browser extensions or smartphone apps.\n- **[Cold wallets](#cold-wallets)**: Offline storage using hardware devices or air-gapped systems.\n- **[Wallet tools](#wallet-tools)**: Libraries and SDKs for integrating wallet functionality into dApps."}
{"page_id": "parachains-integrations-wallets", "page_title": "Wallets", "index": 1, "depth": 2, "title": "Hot Wallets", "anchor": "hot-wallets", "start_char": 761, "end_char": 2329, "estimated_token_count": 342, "token_estimator": "heuristic-v1", "text": "## Hot Wallets\n\n<div class=\"grid cards\" markdown>\n\n-   __Nova Wallet__\n\n    ---\n\n    A non-custodial, mobile-first wallet for managing assets and interacting with the Polkadot and Kusama ecosystems. It supports staking, governance, cross-chain transfers, and crowdloans. With advanced features, seamless multi-network support, and strong security, Nova Wallet empowers users to explore the full potential of Polkadot parachains on the go.\n\n    [:octicons-arrow-right-24: Reference](https://novawallet.io/){target=\\_blank}\n\n-   __Talisman__\n\n    ---\n\n    A non-custodial web browser extension that allows you to manage your portfolio and interact with Polkadot and Ethereum applications. It supports Web3 apps, asset storage, and account management across over 150 Polkadot SDK-based and EVM networks. Features include NFT management, Ledger support, fiat on-ramp, and portfolio tracking.\n\n    [:octicons-arrow-right-24: Reference](https://talisman.xyz/){target=\\_blank}\n\n-  __Subwallet__\n\n    ---\n\n    A non-custodial web browser extension and mobile wallet for Polkadot and Ethereum. Track, send, receive, and monitor multi-chain assets on 150+ networks. Import account with seed phrase, private key, QR code, and JSON file. Import token & NFT, attach read-only account. XCM Transfer, NFT Management, Parity Signer & Ledger support, light clients support, EVM dApp support, MetaMask compatibility, custom endpoints, fiat on-ramp, phishing detection, transaction history.\n\n    [:octicons-arrow-right-24: Reference](https://www.subwallet.app/){target=\\_blank}\n\n</div>"}
{"page_id": "parachains-integrations-wallets", "page_title": "Wallets", "index": 2, "depth": 2, "title": "Cold Wallets", "anchor": "cold-wallets", "start_char": 2329, "end_char": 3027, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "## Cold Wallets\n\n<div class=\"grid cards\" markdown>\n\n-   __Ledger__\n\n    ---\n\n    A hardware wallet that securely stores cryptocurrency private keys offline, protecting them from online threats. Using a secure chip and the Ledger Live app allows safe transactions and asset management while keeping keys secure.\n\n    [:octicons-arrow-right-24: Reference](https://www.ledger.com/){target=\\_blank}\n\n-   __Polkadot Vault__\n\n    ---\n\n    This cold storage solution lets you use a phone in airplane mode as an air-gapped wallet, turning any spare phone, tablet, or iOS/Android device into a hardware wallet.\n\n    [:octicons-arrow-right-24: Reference](https://vault.novasama.io/){target=\\_blank}\n\n</div>"}
{"page_id": "parachains-integrations-wallets", "page_title": "Wallets", "index": 3, "depth": 2, "title": "Wallet Tools", "anchor": "wallet-tools", "start_char": 3027, "end_char": 3587, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "## Wallet Tools\n\n<div class=\"grid cards\" markdown>\n\n-   __LunoKit__\n\n    ---\n\n    A React library for integrating Polkadot wallet connections into dApps. It offers a unified API for major wallets like Polkadot.js, SubWallet, Talisman, Nova Wallet, PolkaGate, WalletConnect, Enkrypt, Fearless, and Mimir. Includes customizable UI components, React hooks, full TypeScript and multi-chain support, and flexible integration with APIs such as Dedot, PAPI, or Polkadot.js.\n\n    [:octicons-arrow-right-24: Reference](https://www.lunolab.xyz/){target=\\_blank}\n\n</div>"}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 44, "end_char": 1023, "estimated_token_count": 166, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nFor establishing communication channels between parachains on the Polkadot network using the Horizontal Relay-routed Message Passing (HRMP) protocol, the following steps are required:\n\n1. **Channel request**: The parachain that wants to open an HRMP channel must make a request to the parachain it wishes to have an open channel with.\n2. **Channel acceptance**: The other parachain must then accept this request to complete the channel establishment.\n\nThis process results in a unidirectional HRMP channel, where messages can flow in only one direction between the two parachains.\n\nAn additional HRMP channel must be established in the opposite direction to enable bidirectional communication. This requires repeating the request and acceptance process but with the parachains reversing their roles.\n\nOnce both unidirectional channels are established, the parachains can send messages back and forth freely through the bidirectional HRMP communication channel."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1023, "end_char": 1267, "estimated_token_count": 40, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore proceeding, ensure you meet the following requirements:\n\n- Blockchain network with a relay chain and at least two connected parachains.\n- Wallet with sufficient funds to execute transactions on the participant chains."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 2, "depth": 2, "title": "Procedure to Initiate an HRMP Channel", "anchor": "procedure-to-initiate-an-hrmp-channel", "start_char": 1267, "end_char": 1444, "estimated_token_count": 32, "token_estimator": "heuristic-v1", "text": "## Procedure to Initiate an HRMP Channel\n\nThis example will demonstrate how to open a channel between parachain 2500 and parachain 2600, using Rococo Local as the relay chain."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 3, "depth": 3, "title": "Fund Sender Sovereign Account", "anchor": "fund-sender-sovereign-account", "start_char": 1444, "end_char": 3064, "estimated_token_count": 356, "token_estimator": "heuristic-v1", "text": "### Fund Sender Sovereign Account\n\n\nThe [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=_blank} for parachain 2500 on the relay chain must be funded so it can take care of any XCM transact fees.\n\nUse [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} UI to connect to the relay chain and transfer funds from your account to the parachain 2500 sovereign account.\n\n![](/images/parachains/interoperability/channels-common/channels-01.webp)\n\n??? note \"Calculating Parachain Sovereign Account\"\n    To generate the sovereign account address for a parachain, you'll need to follow these steps:\n\n    1. Determine if the parachain is an \"up/down\" chain (parent or child) or a \"sibling\" chain:\n\n        - Up/down chains use the prefix `0x70617261` (which decodes to `b\"para\"`).\n        - Sibling chains use the prefix `0x7369626c` (which decodes to `b\"sibl\"`).\n\n    2. Calculate the u32 scale encoded value of the parachain ID:\n\n        - Parachain 2500 would be encoded as `c4090000`.\n\n    3. Combine the prefix and parachain ID encoding to form the full sovereign account address:\n\n        The sovereign account of parachain 2500 in relay chain will be `0x70617261c4090000000000000000000000000000000000000000000000000000`\n        and the SS58 format of this address is `5Ec4AhPSY2GEE4VoHUVheqv5wwq2C1HMKa7c9fVJ1WKivX1Y`.\n    \n    To perform this conversion, you can also use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=_blank}."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 4, "depth": 3, "title": "Create Channel Opening Extrinsic", "anchor": "create-channel-opening-extrinsic", "start_char": 3064, "end_char": 4003, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "### Create Channel Opening Extrinsic\n\n1. In Polkadot.js Apps, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n    ![](/images/parachains/interoperability/channels-common/channels-02.webp)\n\n2. Construct an `hrmpInitOpenChannel` extrinsic call:\n\n    1. Select the **`hrmp`** pallet.\n    2. Choose the **`hrmpInitOpenChannel`** extrinsic.\n    3. Fill in the parameters:\n        - **`recipient`**: Parachain ID of the target chain (in this case, 2600).\n        - **`proposedMaxCapacity`**: Max number of messages that can be pending in the channel at once.\n        - **`proposedMaxMessageSize`**: Max message size that could be put into the channel.\n    4. Copy the encoded call data.\n\n    ![](/images/parachains/interoperability/channels-between-parachains/parachains-01.webp)\n\n    The encoded call data for opening a channel with parachain 2600 is `0x3c00280a00000800000000001000`."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 5, "depth": 3, "title": "Craft and Submit the XCM Message from the Sender", "anchor": "craft-and-submit-the-xcm-message-from-the-sender", "start_char": 4003, "end_char": 7428, "estimated_token_count": 715, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM Message from the Sender\n\nTo initiate the HRMP channel opening process, you need to create an XCM message that includes the encoded `hrmpInitOpenChannel` call data from the previous step. This message will be sent from your parachain to the relay chain.\n\nThis example uses the `sudo` pallet to dispatch the extrinsic. Verify the XCM configuration of the parachain you're working with and ensure you're using an origin with the necessary privileges to execute the `polkadotXcm.send` extrinsic.\n\nThe XCM message should contain the following instructions:\n\n- **`WithdrawAsset`**: Withdraws assets from the origin's ownership and places them in the Holding Register.\n- **`BuyExecution`**: Pays for the execution of the current message using the assets in the Holding Register.\n- **`Transact`**: Execute the encoded transaction call.\n- **`RefundSurplus`**: Increases the Refunded Weight Register to the value of the Surplus Weight Register, attempting to reclaim any excess fees paid via BuyExecution.\n- **`DepositAsset`**: Subtracts assets from the Holding Register and deposits equivalent on-chain assets under the specified beneficiary's ownership.\n\n!!!note \n    For more detailed information about XCM's functionality, complexities, and instruction set, refer to the [xcm-format](https://github.com/polkadot-fellows/xcm-format){target=_blank} documentation.\n\nIn essence, this process withdraws funds from the parachain's sovereign account to the XCVM Holding Register, then uses these funds to purchase execution time for the XCM `Transact` instruction, executes `Transact`, refunds any unused execution time and deposits any remaining funds into a specified account.\n\nTo send the XCM message to the relay chain, connect to parachain 2500 in Polkadot.js Apps. Fill in the required parameters as shown in the image below, ensuring that you:\n\n1. Replace the **`call`** field with your encoded `hrmpInitOpenChannel` call data from the previous step.\n2. Use the correct beneficiary information.\n3. Click the **Submit Transaction** button to dispatch the XCM message to the relay chain.\n\n![](/images/parachains/interoperability/channels-between-parachains/parachains-02.webp)\n\n!!! note\n    The exact process and parameters for submitting this XCM message may vary depending on your specific parachain and relay chain configurations. Always refer to the most current documentation for your particular network setup.\n\nAfter submitting the XCM message to initiate the HRMP channel opening, you should verify that the request was successful. Follow these steps to check the status of your channel request:\n\n1. Using Polkadot.js Apps, connect to the relay chain and navigate to the **Developer** dropdown, then select the **Chain state** option.\n\n    ![](/images/parachains/interoperability/channels-common/channels-03.webp)\n\n2. Query the HRMP open channel requests:\n\n    1. Select **`hrmp`**.\n    2. Choose the **`hrmpOpenChannelRequests`** call.\n    3. Click the **+** button to execute the query.\n    4. Check the status of all pending channel requests.\n\n    ![](/images/parachains/interoperability/channels-between-parachains/parachains-03.webp)\n\nIf your channel request was successful, you should see an entry for your parachain ID in the list of open channel requests. This confirms that your request has been properly registered on the relay chain and is awaiting acceptance by the target parachain."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 6, "depth": 2, "title": "Procedure to Accept an HRMP Channel", "anchor": "procedure-to-accept-an-hrmp-channel", "start_char": 7428, "end_char": 7612, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Procedure to Accept an HRMP Channel\n\nFor the channel to be fully established, the target parachain must accept the channel request by submitting an XCM message to the relay chain."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 7, "depth": 3, "title": "Fund Receiver Sovereign Account", "anchor": "fund-receiver-sovereign-account", "start_char": 7612, "end_char": 7958, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "### Fund Receiver Sovereign Account\n\nBefore proceeding, ensure that the sovereign account of parachain 2600 on the relay chain is funded. This account will be responsible for covering any XCM transact fees.\nTo fund the account, follow the same process described in the previous section, [Fund Sovereign Account](#fund-sender-sovereign-account)."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 8, "depth": 3, "title": "Create Channel Accepting Extrinsic", "anchor": "create-channel-accepting-extrinsic", "start_char": 7958, "end_char": 8704, "estimated_token_count": 175, "token_estimator": "heuristic-v1", "text": "### Create Channel Accepting Extrinsic\n\n1. In Polkadot.js Apps, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n    ![](/images/parachains/interoperability/channels-common/channels-02.webp)\n\n2. Construct an `hrmpAcceptOpenChannel` extrinsic call:\n\n    1. Select the **`hrmp`** pallet.\n    2. Choose the **`hrmpAcceptOpenChannel`** extrinsic.\n    3. Fill in the parameters:\n        - **`sender`**: Parachain ID of the requesting chain (in this case, 2500).\n    4. Copy the encoded call data.\n\n    ![](/images/parachains/interoperability/channels-between-parachains/parachains-04.webp)\n    \n    The encoded call data for accepting a channel with parachain 2500 should be `0x3c01c4090000`."}
{"page_id": "parachains-interoperability-channels-between-parachains", "page_title": "Opening HRMP Channels Between Parachains", "index": 9, "depth": 3, "title": "Craft and Submit the XCM Message from the Receiver", "anchor": "craft-and-submit-the-xcm-message-from-the-receiver", "start_char": 8704, "end_char": 10934, "estimated_token_count": 482, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM Message from the Receiver\n\nTo accept the HRMP channel opening, you need to create and submit an XCM message that includes the encoded `hrmpAcceptOpenChannel` call data from the previous step. This process is similar to the one described in the previous section, [Craft and Submit the XCM Message](#craft-and-submit-the-xcm-message-from-the-sender), with a few key differences:\n\n- Use the encoded call data for `hrmpAcceptOpenChannel` obtained in step 2 of this section.\n- In the last XCM instruction (DepositAsset), set the beneficiary to parachain 2600's sovereign account to receive any surplus funds.\n\nTo send the XCM message to the relay chain, connect to parachain 2600 in Polkadot.js Apps. Fill in the required parameters as shown in the image below, ensuring that you:\n\n1. Replace the **`call`** field with your encoded `hrmpAcceptOpenChannel` call data from the previous step.\n2. Use the correct beneficiary information.\n3. Click the **Submit Transaction** button to dispatch the XCM message to the relay chain.\n\n![](/images/parachains/interoperability/channels-between-parachains/parachains-05.webp)\n\nAfter submitting the XCM message to accept the HRMP channel opening, verify that the channel has been set up correctly.\n\n1. Using Polkadot.js Apps, connect to the relay chain and navigate to the **Developer** dropdown, then select the **Chain state** option.\n\n    ![](/images/parachains/interoperability/channels-common/channels-01.webp)\n\n2. Query the HRMP channels:\n\n    1. Select **`hrmp`**.\n    2. Choose the **`hrmpChannels`** call.\n    3. Click the **+** button to execute the query.\n    4. Check the status of the opened channel.\n\n    ![](/images/parachains/interoperability/channels-between-parachains/parachains-06.webp)\n\nIf the channel has been successfully established, you should see the channel details in the query results.\n\nBy following these steps, you will have successfully accepted the HRMP channel request and established a unidirectional channel between the two parachains. \n\n!!! note\n    Remember that for full bidirectional communication, you'll need to repeat this process in the opposite direction, with parachain 2600 initiating a channel request to parachain 2500."}
{"page_id": "parachains-interoperability-channels-with-system-parachains", "page_title": "Opening HRMP Channels with System Parachains", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 48, "end_char": 827, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nWhile establishing Horizontal Relay-routed Message Passing (HRMP) channels between regular parachains involves a two-step request and acceptance procedure, opening channels with system parachains follows a more straightforward approach.\n\nSystem parachains are specialized chains that provide core functionality to the Polkadot network. Examples include Asset Hub for cross-chain asset transfers and Bridge Hub for connecting to external networks. Given their critical role, establishing communication channels with these system parachains has been optimized for efficiency and ease of use.\n\nAny parachain can establish a bidirectional channel with a system chain through a single operation, requiring just one XCM message from the parachain to the relay chain."}
{"page_id": "parachains-interoperability-channels-with-system-parachains", "page_title": "Opening HRMP Channels with System Parachains", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 827, "end_char": 1146, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nTo successfully complete this process, you'll need to have the following in place:\n\n- Access to a blockchain network consisting of:\n    - A relay chain\n    - A parachain\n    - An Asset Hub system chain\n- A wallet containing enough funds to cover transaction fees on each of the participating chains."}
{"page_id": "parachains-interoperability-channels-with-system-parachains", "page_title": "Opening HRMP Channels with System Parachains", "index": 2, "depth": 2, "title": "Procedure to Establish an HRMP Channel", "anchor": "procedure-to-establish-an-hrmp-channel", "start_char": 1146, "end_char": 1338, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Procedure to Establish an HRMP Channel\n\nThis guide demonstrates opening an HRMP channel between parachain 2500 and system chain Asset Hub (parachain 1000) on the Rococo Local relay chain."}
{"page_id": "parachains-interoperability-channels-with-system-parachains", "page_title": "Opening HRMP Channels with System Parachains", "index": 3, "depth": 3, "title": "Fund Parachain Sovereign Account", "anchor": "fund-parachain-sovereign-account", "start_char": 1338, "end_char": 2961, "estimated_token_count": 357, "token_estimator": "heuristic-v1", "text": "### Fund Parachain Sovereign Account\n\nThe [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=_blank} for parachain 2500 on the relay chain must be funded so it can take care of any XCM transact fees.\n\nUse [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} UI to connect to the relay chain and transfer funds from your account to the parachain 2500 sovereign account.\n\n![](/images/parachains/interoperability/channels-common/channels-01.webp)\n\n??? note \"Calculating Parachain Sovereign Account\"\n    To generate the sovereign account address for a parachain, you'll need to follow these steps:\n\n    1. Determine if the parachain is an \"up/down\" chain (parent or child) or a \"sibling\" chain:\n\n        - Up/down chains use the prefix `0x70617261` (which decodes to `b\"para\"`).\n        - Sibling chains use the prefix `0x7369626c` (which decodes to `b\"sibl\"`).\n\n    2. Calculate the u32 scale encoded value of the parachain ID:\n\n        - Parachain 2500 would be encoded as `c4090000`.\n\n    3. Combine the prefix and parachain ID encoding to form the full sovereign account address:\n\n        The sovereign account of parachain 2500 in relay chain will be `0x70617261c4090000000000000000000000000000000000000000000000000000`\n        and the SS58 format of this address is `5Ec4AhPSY2GEE4VoHUVheqv5wwq2C1HMKa7c9fVJ1WKivX1Y`.\n    \n    To perform this conversion, you can also use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=\\_blank}."}
{"page_id": "parachains-interoperability-channels-with-system-parachains", "page_title": "Opening HRMP Channels with System Parachains", "index": 4, "depth": 3, "title": "Create Establish Channel with System Extrinsic", "anchor": "create-establish-channel-with-system-extrinsic", "start_char": 2961, "end_char": 3767, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "### Create Establish Channel with System Extrinsic\n\n1. In Polkadot.js Apps, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n    ![](/images/parachains/interoperability/channels-common/channels-02.webp)\n\n2. Construct an `establish_channel_with_system` extrinsic call:\n\n    1. Select the **`hrmp`** pallet.\n    2. Choose the **`establish_channel_with_system`** extrinsic.\n    3. Fill in the parameters:\n        - **`target_system_chain`**: Parachain ID of the target system chain (in this case, 1000).\n    4. Copy the encoded call data.\n    ![](/images/parachains/interoperability/channels-with-system-parachains/system-parachains-01.webp)\n\n    The encoded call data for establishing a channel with system parachain 1000 should be `0x3c0ae8030000`."}
{"page_id": "parachains-interoperability-channels-with-system-parachains", "page_title": "Opening HRMP Channels with System Parachains", "index": 5, "depth": 3, "title": "Craft and Submit the XCM Message", "anchor": "craft-and-submit-the-xcm-message", "start_char": 3767, "end_char": 7203, "estimated_token_count": 671, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM Message\n\nConnect to parachain 2500 using Polkadot.js Apps to send the XCM message to the relay chain. Input the necessary parameters as illustrated in the image below. Make sure to:\n\n1. Insert your previously encoded `establish_channel_with_system` call data into the **`call`** field.\n2. Provide beneficiary details.\n3. Dispatch the XCM message to the relay chain by clicking the **Submit Transaction** button.\n\n![](/images/parachains/interoperability/channels-with-system-parachains/system-parachains-02.webp)\n\n!!! note\n    The exact process and parameters for submitting this XCM message may vary depending on your specific parachain and relay chain configurations. Always refer to the most current documentation for your particular network setup.\n\nAfter successfully submitting the XCM message to the relay chain, two [`HrmpSystemChannelOpened`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/hrmp/pallet/enum.Event.html#variant.HrmpSystemChannelOpened){target=\\_blank} events are emitted, indicating that the channels are now present in storage under [`HrmpOpenChannelRequests`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/hrmp/pallet/storage_types/struct.HrmpOpenChannelRequests.html){target=\\_blank}. However, the channels are not actually set up until the start of the next session, at which point bidirectional communication between parachain 2500 and system chain 1000 is established.\n\nTo verify this, wait for the next session and then follow these steps:\n\n1. Using Polkadot.js Apps, connect to the relay chain and navigate to the **Developer** dropdown, then select **Chain state**.\n\n    ![](/images/parachains/interoperability/channels-common/channels-03.webp)\n\n2. Query the HRMP channels:\n\n    1. Select **`hrmp`** from the options.\n    2. Choose the **`hrmpChannels`** call.\n    3. Click the **+** button to execute the query.\n\n    ![](/images/parachains/interoperability/channels-with-system-parachains/system-parachains-03.webp)\n    \n3. Examine the query results. You should see output similar to the following:\n\n    ```json\n    [\n        [\n            [\n                {\n                    \"sender\": 1000,\n                    \"recipient\": 2500\n                }\n            ],\n            {\n                \"maxCapacity\": 8,\n                \"maxTotalSize\": 8192,\n                \"maxMessageSize\": 1048576,\n                \"msgCount\": 0,\n                \"totalSize\": 0,\n                \"mqcHead\": null,\n                \"senderDeposit\": 0,\n                \"recipientDeposit\": 0\n            }\n        ],\n        [\n            [\n                {\n                    \"sender\": 2500,\n                    \"recipient\": 1000\n                }\n            ],\n            {\n                \"maxCapacity\": 8,\n                \"maxTotalSize\": 8192,\n                \"maxMessageSize\": 1048576,\n                \"msgCount\": 0,\n                \"totalSize\": 0,\n                \"mqcHead\": null,\n                \"senderDeposit\": 0,\n                \"recipientDeposit\": 0\n            }\n        ]\n    ]\n\n    ```\n\nThe output confirms the successful establishment of two HRMP channels:\n\n- From chain 1000 (system chain) to chain 2500 (parachain).\n- From chain 2500 (parachain) to chain 1000 (system chain).\n\nThis bidirectional channel enables direct communication between the system chain and the parachain, allowing for cross-chain message passing."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 696, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadotâ€™s unique value lies in its ability to enable interoperability between parachains and other blockchain systems. At the core of this capability is XCM (Cross-Consensus Messaging)â€”a flexible messaging format that facilitates communication and collaboration between independent consensus systems.\n\nWith XCM, one chain can send intents to another one, fostering a more interconnected ecosystem. Although it was developed specifically for Polkadot, XCM is a universal format, usable in any blockchain environment. This guide provides an overview of XCMâ€™s core principles, design, and functionality, alongside practical examples of its implementation."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 1, "depth": 2, "title": "Messaging Format", "anchor": "messaging-format", "start_char": 696, "end_char": 1570, "estimated_token_count": 153, "token_estimator": "heuristic-v1", "text": "## Messaging Format\n\nXCM is not a protocol but a standardized [messaging format](https://github.com/polkadot-fellows/xcm-format){target=\\_blank}. It defines the structure and behavior of messages but does not handle their delivery. This separation allows developers to focus on crafting instructions for target systems without worrying about transmission mechanics.\n\nXCM messages are intent-driven, outlining desired actions for the receiving blockchain to consider and potentially alter its state. These messages do not directly execute changes; instead, they rely on the host chain's environment to interpret and implement them. By utilizing asynchronous composability, XCM facilitates efficient execution where messages can be processed independently of their original order, similar to how RESTful services handle HTTP requests without requiring sequential processing."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 2, "depth": 2, "title": "The Four Principles of XCM", "anchor": "the-four-principles-of-xcm", "start_char": 1570, "end_char": 2506, "estimated_token_count": 174, "token_estimator": "heuristic-v1", "text": "## The Four Principles of XCM\n\nXCM adheres to four guiding principles that ensure robust and reliable communication across consensus systems:\n\n- **Asynchronous**: XCM messages operate independently of sender acknowledgment, avoiding delays due to blocked processes.\n- **Absolute**: XCM messages are guaranteed to be delivered and interpreted accurately, in order, and timely. Once a message is sent, one can be sure it will be processed as intended.\n- **Asymmetric**: XCM messages follow the 'fire and forget' paradigm meaning no automatic feedback is provided to the sender. Any results must be communicated separately to the sender with an additional message back to the origin.\n- **Agnostic**: XCM operates independently of the specific consensus mechanisms, making it compatible across diverse systems.\n\nThese principles guarantee that XCM provides a reliable framework for cross-chain communication, even in complex environments."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 3, "depth": 2, "title": "The XCM Tech Stack", "anchor": "the-xcm-tech-stack", "start_char": 2506, "end_char": 2870, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## The XCM Tech Stack\n\n![Diagram of the XCM tech stack](/images/parachains/interoperability/get-started/intro-to-xcm-01.webp)\n\nThe XCM tech stack is designed to facilitate seamless interoperable communication between chains that reside within the Polkadot ecosystem. XCM can be used to express the meaning of the messages over each of the communication channels."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 4, "depth": 2, "title": "Core Functionalities of XCM", "anchor": "core-functionalities-of-xcm", "start_char": 2870, "end_char": 3866, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## Core Functionalities of XCM\n\nXCM enhances cross-consensus communication by introducing several powerful features:\n\n- **Programmability**: Supports dynamic message handling, allowing for more comprehensive use cases. Includes branching logic, safe dispatches for version checks, and asset operations like NFT management.\n- **Functional Multichain Decomposition**: Enables mechanisms such as remote asset locking, asset namespacing, and inter-chain state referencing, with contextual message identification.\n- **Bridging**: Establishes a universal reference framework for multi-hop setups, connecting disparate systems like Ethereum and Bitcoin with the Polkadot relay chain acting as a universal location.\n\nThe standardized format for messages allows parachains to handle tasks like user balances, governance, and staking, freeing the Polkadot relay chain to focus on shared security. These features make XCM indispensable for implementing scalable and interoperable blockchain applications."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 5, "depth": 2, "title": "XCM Example", "anchor": "xcm-example", "start_char": 3866, "end_char": 6837, "estimated_token_count": 687, "token_estimator": "heuristic-v1", "text": "## XCM Example\n\nThe following is a simplified XCM message demonstrating a token transfer from Alice to Bob on the same chain (ParaA).\n\n```rust\nlet message = Xcm(vec![\n    WithdrawAsset((Here, amount).into()),\n    BuyExecution { \n        fees: (Here, amount).into(), \n        weight_limit: WeightLimit::Unlimited \n    },\n    DepositAsset {\n        assets: All.into(),\n        beneficiary: MultiLocation {\n            parents: 0,\n            interior: Junction::AccountId32 {\n                network: None,\n                id: BOB.clone().into()\n            }.into(),\n        }.into()\n    }\n]);\n```\n\nThe message consists of three instructions described as follows:\n\n- **[WithdrawAsset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#withdrawasset){target=\\_blank}**: Transfers a specified number of tokens from Alice's account to a holding register.\n\n    ```rust\n        WithdrawAsset((Here, amount).into()),\n    ```\n\n    - **`Here`**: The native parachain token.\n    - **`amount`**: The number of tokens that are transferred.\n\n    The first instruction takes as an input the MultiAsset that should be withdrawn. The MultiAsset describes the native parachain token with the `Here` keyword. The `amount` parameter is the number of tokens that are transferred. The withdrawal account depends on the origin of the message. In this example the origin of the message is Alice. The `WithdrawAsset` instruction moves `amount` number of native tokens from Alice's account into the holding register.\n\n- **[BuyExecution](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#buyexecution){target=\\_blank}**: Allocates fees to cover the execution weight of the XCM instructions.\n\n    \n\n    ```rust\n        BuyExecution { \n            fees: (Here, amount).into(), \n            weight_limit: WeightLimit::Unlimited \n        },\n    ```\n\n    - **`fees`**: Describes the asset in the holding register that should be used to pay for the weight.\n    - **`weight_limit`**: Defines the maximum fees that can be used to buy weight.\n\n- **[DepositAsset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#depositasset){target=\\_blank}**: Moves the remaining tokens from the holding register to Bobâ€™s account.\n\n    ```rust\n        DepositAsset {\n            assets: All.into(),\n            beneficiary: MultiLocation {\n                parents: 0,\n                interior: Junction::AccountId32 {\n                    network: None,\n                    id: BOB.clone().into()\n                }.into(),\n            }.into()\n        }\n    ```\n\n    - **`All`**: The wildcard for the asset(s) to be deposited. In this case, all assets in the holding register should be deposited.\n    \nThis step-by-step process showcases how XCM enables precise state changes within a blockchain system. You can find a complete XCM message example in the [XCM repository](https://github.com/paritytech/xcm-docs/blob/main/examples/src/0_first_look/mod.rs){target=\\_blank}."}
{"page_id": "parachains-interoperability-get-started", "page_title": "Get Started with XCM", "index": 6, "depth": 2, "title": "Overview", "anchor": "overview", "start_char": 6837, "end_char": 7410, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "## Overview\n\nXCM revolutionizes cross-chain communication by enabling use cases such as:\n\n- Token transfers between blockchains.\n- Asset locking for cross-chain smart contract interactions.\n- Remote execution of functions on other blockchains.\n\nThese functionalities empower developers to build innovative, multi-chain applications, leveraging the strengths of various blockchain networks. To stay updated on XCMâ€™s evolving format or contribute, visit the [XCM repository](https://github.com/paritytech/xcm-docs/blob/main/examples/src/0_first_look/mod.rs){target=\\_blank}."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 451, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPreviously, you learned how to [choose and set up a parachain template](/parachains/launch-a-parachain/set-up-the-parachain-template/){target=\\_blank}. Now, you'll take the next step towards a production-like environment by deploying your parachain to the Polkadot TestNet. Deploying to a TestNet is a crucial step for validating your parachain's functionality and preparing it for eventual MainNet deployment."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 1, "depth": 2, "title": "Get Started with an Account and Tokens", "anchor": "get-started-with-an-account-and-tokens", "start_char": 451, "end_char": 2432, "estimated_token_count": 540, "token_estimator": "heuristic-v1", "text": "## Get Started with an Account and Tokens\n\nTo perform any action on the Polkadot TestNet, you need PAS tokens, which can be requested from the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=0){target=\\_blank}. To store the tokens, you must have access to a Polkadot-SDK-compatible wallet. Go to the [Polkadot Wallets](https://polkadot.com/get-started/wallets/){target=\\_blank} page to view different options for a Polkadot wallet, or use the [Polkadot.js browser extension](https://polkadot.js.org/extension/){target=\\_blank}, which is suitable for development purposes.\n\n!!!warning \n    Development keys and accounts should never hold assets of actual value and should not be used for production.\n\nThe [Polkadot.js Apps](https://polkadot.js.org/apps/){target=\\_blank} interface can be used to get you started for testing purposes.\n\nTo prepare an account, follow these steps:\n\n1. Open the [Polkadot.js Apps: Paseo](https://polkadot.js.org/apps/?rpc=wss://paseo.dotters.network#/explorer){target=\\_blank} interface and connect to the Polkadot TestNet (Paseo).\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-1.webp)\n\n2. Navigate to the **Accounts** section:\n\n    1. Click on the **Accounts** tab in the top menu.\n    2. Select the **Accounts** option from the dropdown menu.\n  \n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-2.webp)\n\n3. Copy the address of the account you want to use for the parachain deployment.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-3.webp)\n\n4. Visit the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=0){target=\\_blank} and paste the copied address in the input field. Ensure that the network is set to Paseo and click on the **Get some PASs** button.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-4.webp)\n\n    After a few seconds, you will receive 5000 PAS tokens in your account."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 2, "depth": 2, "title": "Reserve a Parachain Identifier", "anchor": "reserve-a-parachain-identifier", "start_char": 2432, "end_char": 3589, "estimated_token_count": 303, "token_estimator": "heuristic-v1", "text": "## Reserve a Parachain Identifier\n\nYou must reserve a parachain identifier (ID) before registering your parachain on Paseo. You'll be assigned the next available identifier.\n\nTo reserve a parachain identifier, follow these steps:\n\n1. Navigate to the **Parachains** section:\n\n    1. Click on the **Network** tab in the top menu.\n    2. Select the **Parachains** option from the dropdown menu.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-5.webp)\n\n2. Register a ParaId:\n\n    1. Select the **Parathreads** tab.\n    2. Click on the **+ ParaId** button.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-6.webp)\n\n3. Review the transaction and click on the **+ Submit** button.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-7.webp)\n\n    For this case, the next available parachain identifier is `4508`.\n\n4. After submitting the transaction, you can navigate to the **Explorer** tab and check the list of recent events for successful `registrar.Reserved`.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-8.webp)"}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 3, "depth": 2, "title": "Generate Custom Keys for Your Collators", "anchor": "generate-custom-keys-for-your-collators", "start_char": 3589, "end_char": 5601, "estimated_token_count": 410, "token_estimator": "heuristic-v1", "text": "## Generate Custom Keys for Your Collators\n\nTo securely deploy your parachain, it is essential to generate custom keys specifically for your collators (block producers). You should generate two sets of keys for each collator:\n\n\n\n- **Account keys**: Used to interact with the network and manage funds. These should be protected carefully and should never exist on the filesystem of the collator node.\n\n- **Session keys**: Used in block production to identify your node and its blocks on the network. These keys are stored in the parachain keystore and function as disposable \"hot wallet\" keys. If these keys are leaked, someone could impersonate your node, which could result in the slashing of your funds. To minimize these risks, rotating your session keys frequently is essential. Treat them with the same level of caution as you would a hot wallet to ensure the security of your node.\n\nTo perform this step, you can use [subkey](https://docs.rs/crate/subkey/latest){target=\\_blank}, a command-line tool for generating and managing keys:\n\n```bash\ndocker run -it parity/subkey:latest generate --scheme sr25519\n```\n\nThe output should look similar to the following:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>docker run -it parity/subkey:latest generate --scheme sr25519</span>\n  <span> <br />Secret phrase: lemon play remain picture leopard frog mad bridge hire hazard best buddy <br />Network ID: substrate <br />Secret seed: 0xb748b501de061bae1fcab1c0b814255979d74d9637b84e06414a57a1a149c004 <br />Public key (hex): 0xf4ec62ec6e70a3c0f8dcbe0531e2b1b8916cf16d30635bbe9232f6ed3f0bf422 <br />Account ID: 0xf4ec62ec6e70a3c0f8dcbe0531e2b1b8916cf16d30635bbe9232f6ed3f0bf422 <br />Public key (SS58): 5HbqmBBJ5ALUzho7tw1k1jEgKBJM7dNsQwrtfSfUskT1a3oe <br />SS58 Address: 5HbqmBBJ5ALUzho7tw1k1jEgKBJM7dNsQwrtfSfUskT1a3oe </span>\n</div>\n\nEnsure that this command is executed twice to generate the keys for both the account and session keys. Save them for future reference."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 4, "depth": 2, "title": "Generate the Chain Specification", "anchor": "generate-the-chain-specification", "start_char": 5601, "end_char": 14694, "estimated_token_count": 1451, "token_estimator": "heuristic-v1", "text": "## Generate the Chain Specification\n\nPolkadot SDK-based parachains are defined by a file called the chain specification, or chain spec for short. There are two types of chain spec files:\n\n\n\n- **Plain chain spec**: A human-readable JSON file that can be modified to suit your parachain's requirements. It serves as a template for initial configuration and includes human-readable keys and structures.\n- **Raw chain spec**: A binary-encoded file used to start your parachain node. This file is generated from the plain chain spec and contains the encoded information necessary for the parachain node to synchronize with the blockchain network. It ensures compatibility across different runtime versions by providing data in a format directly interpretable by the node's runtime, regardless of upgrades since the chain's genesis.\n\nThe chain spec file is only required during the initial blockchain creation (genesis). You do not need to generate a new chain spec when performing runtime upgrades after your chain is already running.\n\nThe files required to register a parachain must specify the correct relay chain to connect to and the parachain identifier you have been assigned. To make these changes, you must build and modify the chain specification file for your parachain. In this tutorial, the relay chain is `paseo`, and the parachain identifier is `4508`.\n\nTo define your chain specification:\n\n1. Generate the plain chain specification for the parachain template node by running the following command. Make sure to use the `*.compact.compressed.wasm` version of your compiled runtime when generating your chain specification, and replace `INSERT_PARA_ID` with the ID you obtained in the [Reserve a Parachain Identifier](#reserve-a-parachain-identifier) section:\n\n    ```bash\n    chain-spec-builder \\\n    --chain-spec-path ./plain_chain_spec.json \\\n    create \\\n    --relay-chain paseo \\\n    --para-id INSERT_PARA_ID \\\n    --runtime target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    named-preset local_testnet\n    ```\n\n2. Edit the `plain_chain_spec.json` file:\n\n    - Update the `name`, `id`, and `protocolId` fields to unique values for your parachain.\n    - Change `para_id` and `parachainInfo.parachainId` fields to the parachain ID you obtained previously. Make sure to use a number without quotes.\n    - Modify the `balances` field to specify the initial balances for your accounts in SS58 format.\n    - Insert the account IDs and session keys in SS58 format generated for your collators in the `collatorSelection.invulnerables` and `session.keys` fields.\n    - Modify the `sudo` value to specify the account that will have sudo access to the parachain.\n  \n    ```json\n    {\n        \"bootNodes\": [],\n        \"chainType\": \"Live\",\n        \"codeSubstitutes\": {},\n        \"genesis\": {\n            \"runtimeGenesis\": {\n                \"code\": \"0x...\",\n                \"patch\": {\n                    \"aura\": {\n                        \"authorities\": []\n                    },\n                    \"auraExt\": {},\n                    \"balances\": {\n                        \"balances\": [[\"INSERT_SUDO_ACCOUNT\", 1152921504606846976]]\n                    },\n                    \"collatorSelection\": {\n                        \"candidacyBond\": 16000000000,\n                        \"desiredCandidates\": 0,\n                        \"invulnerables\": [\"INSERT_ACCOUNT_ID_COLLATOR_1\"]\n                    },\n                    \"parachainInfo\": {\n                        \"parachainId\": \"INSERT_PARA_ID\"\n                    },\n                    \"parachainSystem\": {},\n                    \"polkadotXcm\": {\n                        \"safeXcmVersion\": 4\n                    },\n                    \"session\": {\n                        \"keys\": [\n                            [\n                                \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n                                \"INSERT_ACCOUNT_ID_COLLATOR_1\",\n                                {\n                                    \"aura\": \"INSERT_SESSION_KEY_COLLATOR_1\"\n                                }\n                            ]\n                        ],\n                        \"nonAuthorityKeys\": []\n                    },\n                    \"sudo\": {\n                        \"key\": \"INSERT_SUDO_ACCOUNT\"\n                    },\n                    \"system\": {},\n                    \"transactionPayment\": {\n                        \"multiplier\": \"1000000000000000000\"\n                    }\n                }\n            }\n        },\n        \"id\": \"INSERT_ID\",\n        \"name\": \"INSERT_NAME\",\n        \"para_id\": \"INSERT_PARA_ID\",\n        \"properties\": {\n            \"tokenDecimals\": 12,\n            \"tokenSymbol\": \"UNIT\"\n        },\n        \"protocolId\": \"INSERT_PROTOCOL_ID\",\n        \"relay_chain\": \"paseo\",\n        \"telemetryEndpoints\": null\n    }\n\n    ```\n\n    For this tutorial, the `plain_chain_spec.json` file should look similar to the following. Take into account that the same account is being used for the collator and sudo, which must not be the case in a production environment:\n\n    ??? code \"View complete script\"\n\n        ```json title=\"plain_chain_spec.json\"\n        {\n            \"bootNodes\": [],\n            \"chainType\": \"Live\",\n            \"codeSubstitutes\": {},\n            \"genesis\": {\n                \"runtimeGenesis\": {\n                    \"code\": \"0x...\",\n                    \"patch\": {\n                        \"aura\": {\n                            \"authorities\": []\n                        },\n                        \"auraExt\": {},\n                        \"balances\": {\n                            \"balances\": [\n                                [\n                                    \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\",\n                                    1152921504606846976\n                                ]\n                            ]\n                        },\n                        \"collatorSelection\": {\n                            \"candidacyBond\": 16000000000,\n                            \"desiredCandidates\": 0,\n                            \"invulnerables\": [\n                                \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\"\n                            ]\n                        },\n                        \"parachainInfo\": {\n                            \"parachainId\": 4508\n                        },\n                        \"parachainSystem\": {},\n                        \"polkadotXcm\": {\n                            \"safeXcmVersion\": 4\n                        },\n                        \"session\": {\n                            \"keys\": [\n                                [\n                                    \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\",\n                                    \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\",\n                                    {\n                                        \"aura\": \"5GcAKNdYcw5ybb2kAnta8WVFyiQbGJ5od3aH9MsgYDmVcrhJ\"\n                                    }\n                                ]\n                            ],\n                            \"nonAuthorityKeys\": []\n                        },\n                        \"sudo\": {\n                            \"key\": \"5F9Zteceg3Q4ywi63AxQNVb2b2r5caFSqjQxBkCrux6j8ZpS\"\n                        },\n                        \"system\": {},\n                        \"transactionPayment\": {\n                            \"multiplier\": \"1000000000000000000\"\n                        }\n                    }\n                }\n            },\n            \"id\": \"custom\",\n            \"name\": \"Custom\",\n            \"para_id\": 4508,\n            \"properties\": {\n                \"tokenDecimals\": 12,\n                \"tokenSymbol\": \"UNIT\"\n            },\n            \"protocolId\": null,\n            \"relay_chain\": \"paseo\",\n            \"telemetryEndpoints\": null\n        }\n\n        ```\n\n3. Save your changes and close the plain text chain specification file.\n\n4. Convert the modified plain chain specification file to a raw chain specification file:\n\n    ```bash\n    chain-spec-builder \\\n    --chain-spec-path ./raw_chain_spec.json \\\n    convert-to-raw plain_chain_spec.json\n    ```\n\n    You should now see your chain specification containing SCALE-encoded hex values versus plain text.\n\n\n!!!note \"`para_id` Considerations\"\n\n    The `para_id` field in JSON chain specifications, added through the [`chain-spec-builder`](https://paritytech.github.io/polkadot-sdk/master/staging_chain_spec_builder/index.html){target=\\_blank} command, is used by nodes for configuration purposes. Beginning with Polkadot SDK release `stable2509`, runtimes can optionally implement the [`cumulus_primitives_core::GetParachainInfo`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/trait.GetParachainInfo.html){target=\\_blank} trait as an alternative method for parachain identification.\n\n    However, the `para_id` field will remain supported in chain specifications for backwards compatibility. This ensures that nodes can still sync from genesis or from runtime states that existed before the `GetParachainInfo` runtime API was introduced."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 5, "depth": 2, "title": "Export Required Files", "anchor": "export-required-files", "start_char": 14694, "end_char": 15180, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Export Required Files\n\nTo prepare the parachain collator to be registered on Paseo, follow these steps:\n\n1. Export the Wasm runtime for the parachain by running the following command:\n\n    ```bash\n    polkadot-omni-node export-genesis-wasm \\\n    --chain raw_chain_spec.json para-wasm\n    ```\n\n2. Export the genesis state for the parachain by running the following command:\n\n    ```bash\n    polkadot-omni-node export-genesis-head \\\n    --chain raw_chain_spec.json para-state\n    ```"}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 6, "depth": 2, "title": "Register a Parathread", "anchor": "register-a-parathread", "start_char": 15180, "end_char": 16425, "estimated_token_count": 306, "token_estimator": "heuristic-v1", "text": "## Register a Parathread\n\nOnce you have the genesis state and runtime, you can now register these with your parachain ID.\n\n1. Go to the [Parachains > Parathreads](https://polkadot.js.org/apps/#/parachains/parathreads){target=\\_blank} tab, and select **+ Parathread**.\n   \n2. You should see fields to place your runtime Wasm and genesis state respectively, along with the parachain ID. Select your parachain ID, and upload `para-wasm` in the **code** field and `para-state` in the **initial state** field.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-9.webp)\n   \n3. Confirm your details and click the **+ Submit** button, where there should be a new Parathread with your parachain ID and an active **Deregister** button.\n\n    ![](/images/parachains/launch-a-parachain/deploy-to-polkadot/deploy-to-polkadot-10.webp)\n\nYour parachain's runtime logic and genesis are now part of the relay chain. The next step is to ensure you are able to run a collator to produce blocks for your parachain.\n\n!!!note \n    You may need to wait several hours for your parachain to onboard. Until it has onboarded, you will be unable to purchase coretime, and therefore will not be able to perform transactions on your network."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 7, "depth": 2, "title": "Start the Collator Node", "anchor": "start-the-collator-node", "start_char": 16425, "end_char": 19152, "estimated_token_count": 681, "token_estimator": "heuristic-v1", "text": "## Start the Collator Node\n\nBefore starting a collator, you need to generate a node key. This key is responsible for communicating with other nodes over Libp2p:\n\n```bash\npolkadot-omni-node key generate-node-key \\\n--base-path data \\\n--chain raw_chain_spec.json\n```\n\nAfter running the command, you should see the following output, indicating the base path now has a suitable node key: \n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>polkadot-omni-node key generate-node-key --base-path data --chain raw_chain_spec.json</span>\n  <br />\n  <span data-ty=\"progress\">Generating key in \"/data/chains/custom/network/secret_ed25519\"</span>\n  <span data-ty=\"progress\">12D3KooWKGW964eG4fAwsNMFdckbj3GwhpmSGFU9dd8LFAVAa4EE</span>\n</div>\n\nYou must have the ports for the collator publicly accessible and discoverable to enable parachain nodes to peer with Paseo validator nodes to produce blocks. You can specify the ports with the `--port` command-line option. You can start the collator with a command similar to the following:\n\n```bash\npolkadot-omni-node --collator \\\n--chain raw_chain_spec.json \\\n--base-path data \\\n--port 40333 \\\n--rpc-port 8845 \\\n--force-authoring \\\n--node-key-file ./data/chains/custom/network/secret_ed25519 \\\n-- \\\n--sync warp \\\n--chain paseo \\\n--port 50343 \\\n--rpc-port 9988\n```\n\nIn this example, the first `--port` setting specifies the port for the collator node, and the second `--port` specifies the embedded relay chain node port. The first `--rpc-port` setting specifies the port you can connect to the collator. The second `--rpc-port` specifies the port for connecting to the embedded relay chain.\n\nBefore proceeding, ensure that the collator node is running. Then, open a new terminal and insert your generated session key into the collator keystore by running the following command. Use the same port specified in the `--rpc-port` parameter when starting the collator node (`8845` in this example) to connect to it. Replace `INSERT_SECRET_PHRASE` and `INSERT_PUBLIC_KEY_HEX_FORMAT` with the values from the session key you generated in the [Generate Custom Keys for Your Collators](#generate-custom-keys-for-your-collators) section:\n\n```bash\ncurl -H \"Content-Type: application/json\" \\\n--data '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"author_insertKey\",\n  \"params\":[\n    \"aura\",\n    \"INSERT_SECRET_PHRASE\",\n    \"INSERT_PUBLIC_KEY_HEX_FORMAT\"\n  ],\n  \"id\":1\n}' \\\nhttp://localhost:8845\n```\n\nIf successful, you should see the following response:\n\n```json\n{\"jsonrpc\":\"2.0\",\"result\":null,\"id\":1}\n```\n\nOnce your collator is synced with the Paseo relay chain, and your parathread finished onboarding, it will be ready to start producing blocks. This process may take some time."}
{"page_id": "parachains-launch-a-parachain-deploy-to-polkadot", "page_title": "Deploy on Polkadot", "index": 8, "depth": 2, "title": "Producing Blocks", "anchor": "producing-blocks", "start_char": 19152, "end_char": 20159, "estimated_token_count": 209, "token_estimator": "heuristic-v1", "text": "## Producing Blocks\n\nWith your parachain collator operational, the next step is acquiring coretime. This is essential for ensuring your parachain's security through the relay chain. [Agile Coretime](https://wiki.polkadot.com/learn/learn-agile-coretime/){target=\\_blank} enhances Polkadot's resource management, offering developers greater economic adaptability. Once you have configured your parachain, you can follow two paths:\n\n- Bulk coretime is purchased via the Broker pallet on the respective coretime system parachain. You can purchase bulk coretime on the coretime chain and assign the purchased core to the registered `ParaID`.\n- On-demand coretime is ordered via the [`OnDemand`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/on_demand/index.html){target=\\_blank} pallet, which is located on the respective relay chain.\n\nOnce coretime is correctly assigned to your parachain, whether bulk or on-demand, blocks should be produced (provided your collator is running)."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 1043, "estimated_token_count": 223, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAfter deploying a parachain to Paseo in the [Deploy on Polkadot](/parachains/launch-a-parachain/deploy-to-polkadot/){target=\\_blank} tutorial, the next critical step is obtaining coretime. Coretime is the mechanism through which validation resources are allocated from the relay chain to your parachain. Your parachain can only produce and finalize blocks on the relay chain by obtaining coretime.\n\nThere are two primary ways to obtain coretime:\n\n- **[On-demand coretime](#order-on-demand-coretime)**: Purchase coretime on a block-by-block basis, ideal for variable or unpredictable workloads.\n- **[Bulk coretime](#purchase-bulk-coretime)**: Obtain a core or portion of a core for an extended period (up to 28 days), requiring renewal upon lease expiration.\n\nIn this tutorial, you will:\n\n- Understand the different coretime options available.\n- Learn how to purchase a core via bulk coretime.\n- Assign your parachain to a core for block production.\n- Explore on-demand coretime as an alternative approach."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1043, "end_char": 1679, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore proceeding, ensure you have the following:\n\n- A parachain ID reserved on Paseo.\n- A properly configured chain specification file (both plain and raw versions).\n- A registered parathread with the correct genesis state and runtime.\n- A synced collator node running and connected to the Paseo relay chain.\n- [PAS tokens](https://faucet.polkadot.io/?parachain=1005){target=\\_blank} in your account on the Coretime Chain for transaction fees.\n\nIf you haven't completed these prerequisites, start by referring to the [Deploy on Polkadot](/parachains/launch-a-parachain/deploy-to-polkadot/){target=\\_blank} tutorial."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 2, "depth": 2, "title": "Order On-Demand Coretime", "anchor": "order-on-demand-coretime", "start_char": 1679, "end_char": 1933, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Order On-Demand Coretime\n\nOn-demand coretime allows you to purchase validation resources on a per-block basis. This approach is useful when you don't need continuous block production or want to test your parachain before committing to bulk coretime."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 3, "depth": 3, "title": "On-Demand Extrinsics", "anchor": "on-demand-extrinsics", "start_char": 1933, "end_char": 2688, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "### On-Demand Extrinsics\n\nThere are two extrinsics available for ordering on-demand coretime:\n\n- **[`onDemand.placeOrderAllowDeath`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/on_demand/pallet/struct.Pallet.html#method.place_order_allow_death){target=\\_blank}**: Will [reap](https://wiki.polkadot.com/learn/learn-accounts/#existential-deposit-and-reaping){target=\\_blank} the account once the provided funds are depleted.\n- **[`onDemand.placeOrderKeepAlive`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/on_demand/pallet/struct.Pallet.html#method.place_order_keep_alive){target=\\_blank}**: Includes a check to prevent reaping the account, ensuring it remains alive even if funds run out."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 4, "depth": 3, "title": "Place an On-Demand Order", "anchor": "place-an-on-demand-order", "start_char": 2688, "end_char": 4003, "estimated_token_count": 315, "token_estimator": "heuristic-v1", "text": "### Place an On-Demand Order\n\nTo place an on-demand coretime order, follow these steps:\n\n1. Open the [Polkadot.js Apps interface connected to the Polkadot TestNet (Paseo)](https://polkadot.js.org/apps/?rpc=wss://paseo.dotters.network){target=\\_blank}.\n\n2. Navigate to **Developer > Extrinsics** in the top menu.\n\n3. Select the account that registered your parachain ID.\n\n4. From the **submit the following extrinsic** dropdown, select **onDemand** and then choose **placeOrderAllowDeath** as the extrinsic.\n\n5. Configure the parameters:\n\n    - **maxAmount**: The maximum amount of tokens you're willing to spend (e.g., `1000000000000`). This value may vary depending on network conditions.\n    - **paraId**: Your reserved parachain ID (e.g., `4508`).\n\n6. Review the transaction details and click **Submit Transaction**.\n\n![Placing an on-demand order for coretime](/images/parachains/launch-a-parachain/obtain-coretime/obtain-coretime-01.webp)\n\nUpon successful submission, your parachain will produce a new block. You can verify this by checking your collator node logs, which should display output confirming block production.\n\n!!!note\n    Each successful on-demand extrinsic will trigger one block production cycle. For continuous block production, you'll need to place multiple orders or consider bulk coretime."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 5, "depth": 2, "title": "Purchase Bulk Coretime", "anchor": "purchase-bulk-coretime", "start_char": 4003, "end_char": 5195, "estimated_token_count": 294, "token_estimator": "heuristic-v1", "text": "## Purchase Bulk Coretime\n\nBulk coretime offers a cost-effective way to maintain continuous block production. It lets you reserve a core for up to 28 days and renew it as needed.\n\nYou can purchase and manage cores on the [Coretime Chain](https://wiki.polkadot.com/learn/learn-system-chains/#coretime-chain){target=\\_blank}, a system parachain that runs the [`pallet_broker`](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/index.html){target=\\_blank} to handle core sales, allocation, and renewal across the Polkadot ecosystem.\n\n!!!tip\n    Paseo has a unique process for obtaining coretime cores. Refer to the [PAS-10 Onboard Paras Coretime](https://github.com/paseo-network/paseo-action-submission/blob/main/pas/PAS-10-Onboard-paras-coretime.md#summary){target=\\_blank} guide for detailed instructions.\n\nThis tutorial shows you how to purchase bulk coretime using the [RegionX Coretime Marketplace](https://app.regionx.tech){target=\\_blank}, a user-friendly interface for buying and managing cores on both the Polkadot TestNet and production networks.\n\n![RegionX home page with Wallet connected](/images/parachains/launch-a-parachain/obtain-coretime/obtain-coretime-02.webp)"}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 6, "depth": 3, "title": "Connect Your Wallet to RegionX", "anchor": "connect-your-wallet-to-regionx", "start_char": 5195, "end_char": 5429, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### Connect Your Wallet to RegionX\n\n1. Visit the [RegionX App](https://app.regionx.tech){target=\\_blank}.\n\n2. Click the **Connect Wallet** button in the upper right corner.\n\n3. Select your wallet provider and approve the connection."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 7, "depth": 3, "title": "Obtain Coretime Chain Funds", "anchor": "obtain-coretime-chain-funds", "start_char": 5429, "end_char": 6509, "estimated_token_count": 249, "token_estimator": "heuristic-v1", "text": "### Obtain Coretime Chain Funds\n\nTo purchase a core, you need funds on the Coretime Chain. You can fund your account directly on the Coretime Chain using the Polkadot Faucet:\n\n1. Visit the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=0){target=\\_blank}.\n\n2. Select the **Coretime (Paseo)** network from the dropdown menu.\n\n3. Paste your wallet address in the input field.\n\n4. Click **Get some PASs** to receive 5000 PAS tokens.\n\n!!!note\n    The Polkadot Faucet has a daily limit of 5,000 PAS tokens per account. If you need more tokens than this limit allows, you have two options:\n    \n    - Return to the faucet on consecutive days to accumulate additional tokens.\n    - Create additional accounts, fund each one separately, and then transfer the tokens to your primary account that will be making the bulk coretime purchase.\n\n    Alternatively, to expedite the process, you can send a message to theÂ [Paseo Support channel](https://matrix.to/#/#paseo-testnet-support:parity.io){target=\\_blank} on Matrix, and the Paseo team will assist you in funding your account."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 8, "depth": 3, "title": "Purchase a Core", "anchor": "purchase-a-core", "start_char": 6509, "end_char": 7257, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "### Purchase a Core\n\n1. From the RegionX home page, ensure the correct network is selected using the network switch in the top right corner (set to **Paseo**).\n\n2. Review the information displayed on the home page, including:\n    - **Cores Remaining**: Number of available cores\n    - **Cores Offered**: Total cores in the current sale\n    - **Current price**: The price per core in PAS tokens\n    - **Auction Phase Status**: Current phase and progress\n\n3. Click the **Purchase New Core** button displayed on the page.\n\n4. A modal will appear detailing the transaction details and fees. Review the information carefully.\n\n5. Click **Ok** and sign the transaction using your connected wallet.\n\n6. Wait for the transaction to be confirmed on-chain."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 9, "depth": 3, "title": "Verify Your Purchase", "anchor": "verify-your-purchase", "start_char": 7257, "end_char": 7562, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### Verify Your Purchase\n\n1. Once the transaction is confirmed, navigate to [**My Regions**](https://app.regionx.tech/regions){target=\\_blank} from the left menu.\n\n2. You should see your newly purchased core listed in your dashboard.\n\nCongratulations! You've successfully purchased a core using RegionX."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 10, "depth": 3, "title": "Assign Your Parachain to the Core", "anchor": "assign-your-parachain-to-the-core", "start_char": 7562, "end_char": 8604, "estimated_token_count": 245, "token_estimator": "heuristic-v1", "text": "### Assign Your Parachain to the Core\n\nWith your core purchased, you now need to assign your parachain to it for block production:\n\n1. From the **My Regions** page, click on your core to select it.\n\n2. Click the **Assign** option from the left-hand menu.\n\n3. A modal will appear, allowing you to add a new task.\n\n4. Click **Add Task** and enter the following information:\n\n    - **Parachain ID**: Your reserved parachain identifier\n    - **Project Name**: The name of your parachain project\n\n5. Click **Add Task** to proceed.\n\n6. Select your parachain task from the list.\n\n7. Set the core's **Finality** setting:\n\n    - **Provisional**: Allows interlacing and partitioning of the core, but the region cannot be renewed as-is.\n    - **Final**: Prevents modification of the core but allows renewal. Choose this if you plan to renew the core.\n\n8. Sign and submit the transaction.\n\nOnce confirmed, your parachain will be assigned to the core and should begin producing blocks (provided your collator is running and synced with the relay chain)."}
{"page_id": "parachains-launch-a-parachain-obtain-coretime", "page_title": "Obtain Coretime", "index": 11, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 8604, "end_char": 9049, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\nYour parachain is now set up for block production. Consider the following:\n\n- **Monitor your collator**: Keep your collator node running and monitor its performance.\n- **Plan coretime renewal**: If using bulk coretime, plan to renew your core before the current lease expires.\n- **Explore runtime upgrades**: Once comfortable with your setup, explore how to upgrade your parachain's runtime without interrupting block production."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 46, "end_char": 1141, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot SDK](https://github.com/paritytech/polkadot-sdk){target=\\_blank} includes several [templates](/parachains/customize-runtime/#starting-templates){target=\\_blank} designed to help you quickly start building your own blockchain. Each template offers a different level of configuration, from minimal setups to feature-rich environments, allowing you to choose the foundation that best fits your project's needs.\n\nAmong these, the [Parachain Template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank} provides a preconfigured runtime with commonly used pallets, making it an ideal starting point for most parachain development projects.\n\nThis guide walks you through the full process of working with this template. You will:\n\n- Set up the Polkadot SDK Parachain Template.\n- Understand the project structure and key components.\n- Verify your template is ready for development.\n- Run the parachain template locally in development mode.\n\nBy the end of this guide, you'll have a working template ready to customize and deploy as a parachain."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1141, "end_char": 2110, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have done the following:\n\n- Completed the [Install Polkadot SDK](/parachains/install-polkadot-sdk/){target=\\_blank} guide and successfully installed [Rust](https://rust-lang.org/){target=\\_blank} and the required packages to set up your development environment.\n\nFor this tutorial series, you need to use Rust `1.86`. Newer versions of the compiler may not work with this parachain template version.\n\nRun the following commands to set up the correct Rust version:\n\n=== \"macOS\"\n\n    ```bash\n    rustup install 1.86\n    rustup default 1.86\n    rustup target add wasm32-unknown-unknown --toolchain 1.86-aarch64-apple-darwin\n    rustup component add rust-src --toolchain 1.86-aarch64-apple-darwin\n    ```\n\n=== \"Ubuntu\"\n\n    ```bash\n    rustup toolchain install 1.86.0\n    rustup default 1.86.0\n    rustup target add wasm32-unknown-unknown --toolchain 1.86.0\n    rustup component add rust-src --toolchain 1.86.0\n    ```"}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 2, "depth": 2, "title": "Polkadot SDK Utility Tools", "anchor": "polkadot-sdk-utility-tools", "start_char": 2110, "end_char": 3326, "estimated_token_count": 303, "token_estimator": "heuristic-v1", "text": "## Polkadot SDK Utility Tools\n\nThis tutorial requires two essential tools:\n\n- [**Chain spec builder**](https://crates.io/crates/staging-chain-spec-builder/10.0.0){target=\\_blank}: A Polkadot SDK utility for generating chain specifications. Refer to the [Generate Chain Specs](/parachains/launch-a-parachain/deploy-to-polkadot/#generate-the-chain-specification){target=\\_blank} documentation for detailed usage.\n    \n    Install it by executing the following command:\n    \n    ```bash\n    cargo install --locked staging-chain-spec-builder@10.0.0\n    ```\n\n    This command installs the `chain-spec-builder` binary.\n\n- [**Polkadot Omni Node**](https://crates.io/crates/polkadot-omni-node/0.5.0){target=\\_blank}: A white-labeled binary, released as a part of Polkadot SDK that can act as the collator of a parachain in production, with all the related auxiliary functionalities that a normal collator node has: RPC server, archiving state, etc. Moreover, it can also run the Wasm blob of the parachain locally for testing and development.\n\n    To install it, run the following command:\n\n    ```bash\n    cargo install --locked polkadot-omni-node@0.5.0\n    ```\n\n    This command installs the `polkadot-omni-node` binary."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 3, "depth": 2, "title": "Clone the Template", "anchor": "clone-the-template", "start_char": 3326, "end_char": 3899, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "## Clone the Template\n\nThe [Polkadot SDK Parachain Template](https://github.com/paritytech/polkadot-sdk-parachain-template){target=\\_blank} provides a ready-to-use development environment for building with the [Polkadot SDK](https://github.com/paritytech/polkadot-sdk){target=\\_blank}. Follow these steps to set up the template:\n\n1. Clone the template repository:\n\n    ```bash\n    git clone https://github.com/paritytech/polkadot-sdk-parachain-template.git parachain-template\n    ```\n\n2. Navigate into the project directory:\n\n    ```bash\n    cd parachain-template\n    ```"}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 4, "depth": 2, "title": "Explore the Project Structure", "anchor": "explore-the-project-structure", "start_char": 3899, "end_char": 5124, "estimated_token_count": 244, "token_estimator": "heuristic-v1", "text": "## Explore the Project Structure\n\nBefore building the template, take a moment to familiarize yourself with its structure. Understanding this organization will help you navigate the codebase as you develop your parachain.\n\nThe template follows a standard Polkadot SDK project layout:\n\n```text\nparachain-template/\nâ”œâ”€â”€ node/              # Node implementation and client\nâ”œâ”€â”€ pallets/           # Custom pallets for your parachain\nâ”œâ”€â”€ runtime/           # Runtime configuration and logic\nâ”œâ”€â”€ Cargo.toml         # Workspace configuration\nâ””â”€â”€ README.md          # Documentation\n```\n\nKey directories explained:\n\n- **runtime/**: Contains your parachain's state transition function and pallet configuration. This is where you'll define what your blockchain can do.\n- **node/**: Houses the client implementation that runs your blockchain, handles networking, and manages the database.\n- **pallets/**: Where you'll create custom business logic modules (pallets) for your specific use case.\n- **Cargo.toml**: The workspace configuration that ties all components together.\n\n!!!note\n    The runtime is compiled to WebAssembly (Wasm), enabling forkless upgrades. The node binary remains constant while the runtime can be updated on-chain."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 5, "depth": 2, "title": "Compile the Runtime", "anchor": "compile-the-runtime", "start_char": 5124, "end_char": 6088, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "## Compile the Runtime\n\nNow that you understand the template structure, let's compile the runtime to ensure everything is working correctly.\n\n1. Compile the runtime:\n\n    ```bash\n    cargo build --release --locked\n    ```\n\n    !!!tip\n        Initial compilation may take several minutes, depending on your machine specifications. Use the `--release` flag for improved runtime performance compared to the default `--debug` build. If you need to troubleshoot issues, the `--debug` build provides better diagnostics.\n        \n        For production deployments, consider using a dedicated `--profile production` flag - this can provide an additional 15-30% performance improvement over the standard `--release` profile.\n\n2. Upon successful compilation, you should see output indicating the build was successful. The compiled runtime will be located at:\n    \n    `./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm`"}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 6, "depth": 2, "title": "Verify the Build", "anchor": "verify-the-build", "start_char": 6088, "end_char": 6421, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Verify the Build\n\nAfter compilation completes, verify that the runtime was created successfully by checking for the Wasm blob:\n\n```bash\nls -la ./target/release/wbuild/parachain-template-runtime/\n```\n\nYou should see the `parachain_template_runtime.compact.compressed.wasm` file in the output, confirming the build was successful."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 7, "depth": 2, "title": "Run the Node Locally", "anchor": "run-the-node-locally", "start_char": 6421, "end_char": 8135, "estimated_token_count": 343, "token_estimator": "heuristic-v1", "text": "## Run the Node Locally\n\nAfter successfully compiling your runtime, you can spin up a local chain and produce blocks. This process will start your local parachain using the Polkadot Omni Node and allow you to interact with it. You'll first need to generate a chain specification that defines your network's identity, initial connections, and genesis state, providing the foundational configuration for how your nodes connect and what initial state they agree upon.\n\nFollow these steps to launch your node in development mode:\n\n1. Generate the chain specification file of your parachain:\n\n    ```bash\n    chain-spec-builder create -t development \\\n    --relay-chain paseo \\\n    --para-id 1000 \\\n    --runtime ./target/release/wbuild/parachain-template-runtime/parachain_template_runtime.compact.compressed.wasm \\\n    named-preset development\n    ```\n\n2. Start the Omni Node with the generated chain spec. You'll start it in development mode (without a relay chain config), producing and finalizing blocks:\n\n    ```bash\n    polkadot-omni-node --chain ./chain_spec.json --dev\n    ```\n\n    The `--dev` option does the following:\n\n    - Deletes all active data (keys, blockchain database, networking information) when stopped.\n    - Ensures a clean working state each time you restart the node.\n\n3. Verify that your node is running by reviewing the terminal output. You should see log messages indicating block production and finalization.\n\n4. Confirm that your blockchain is producing new blocks by checking if the number after `finalized` is increasing in the output.\n\nThe details of the log output will be explored in a later tutorial. For now, knowing that your node is running and producing blocks is sufficient."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 8, "depth": 2, "title": "Interact with the Node", "anchor": "interact-with-the-node", "start_char": 8135, "end_char": 9701, "estimated_token_count": 412, "token_estimator": "heuristic-v1", "text": "## Interact with the Node\n\nWhen running the template node, it's accessible by default at `ws://localhost:9944`. To interact with your node using the [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} interface, follow these steps:\n\n1. Open [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} in your web browser and click the network icon (which should be the Polkadot logo) in the top left corner:\n    \n    ![](/images/parachains/launch-a-parachain/set-up-the-parachain-template/parachain-template-01.webp)\n\n2. Connect to your local node:\n\n    1. Scroll to the bottom and select **Development**.\n    2. Choose **Custom**.\n    3. Enter `ws://localhost:9944` in the **custom endpoint** input field.\n    4. Click the **Switch** button.\n    \n    ![](/images/parachains/launch-a-parachain/set-up-the-parachain-template/parachain-template-02.webp)\n\n3. Once connected, you should see **parachain-template-runtime** in the top left corner, with the interface displaying information about your local blockchain.\n    \n    ![](/images/parachains/launch-a-parachain/set-up-the-parachain-template/parachain-template-03.webp)\n\nYou are now connected to your local node and can interact with it through the Polkadot.js Apps interface. This tool enables you to explore blocks, execute transactions, and interact with your blockchain's features. For in-depth guidance on using the interface effectively, refer to the [Polkadot.js Guides](https://wiki.polkadot.com/general/polkadotjs/){target=\\_blank} available on the Polkadot Wiki."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 9, "depth": 2, "title": "Stop the Node", "anchor": "stop-the-node", "start_char": 9701, "end_char": 10207, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Stop the Node\n\nWhen you're done exploring your local node, you can stop it to remove any state changes you've made. Since you started the node with the `--dev` option, stopping the node will purge all persistent block data, allowing you to start fresh the next time.\n\nTo stop the local node:\n\n1. Return to the terminal window where the node output is displayed.\n2. Press `Control-C` to stop the running process.\n3. Verify that your terminal returns to the prompt in the `parachain-template` directory."}
{"page_id": "parachains-launch-a-parachain-set-up-the-parachain-template", "page_title": "Set Up the Polkadot SDK Parachain Template", "index": 10, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10207, "end_char": 10613, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Deploy to Polkadot__\n\n    ---\n\n    Learn how to deploy your parachain template to a relay chain testnet. Configure your chain specification, register as a parachain, and start producing blocks.\n\n    [:octicons-arrow-right-24: Get Started](/parachains/launch-a-parachain/deploy-to-polkadot/)\n\n</div>"}
{"page_id": "parachains-runtime-maintenance-runtime-upgrades", "page_title": "Runtime Upgrades", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 926, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nOne of the defining features of Polkadot SDK-based blockchains is the ability to perform forkless runtime upgrades. Unlike traditional blockchains, which require hard forks and node coordination for upgrades, Polkadot networks enable seamless updates without network disruption.\n\nForkless upgrades are achieved through WebAssembly (Wasm) runtimes stored on-chain, which can be securely swapped and upgraded as part of the blockchain's state. By leveraging decentralized consensus, runtime updates can happen trustlessly, ensuring continuous improvement and evolution without halting operations.\n\nThis guide explains how Polkadot's runtime versioning, Wasm deployment, and storage migrations enable these upgrades, ensuring the blockchain evolves smoothly and securely. You'll also learn how different upgrade processes apply to solo chains and parachains, depending on the network setup."}
{"page_id": "parachains-runtime-maintenance-runtime-upgrades", "page_title": "Runtime Upgrades", "index": 1, "depth": 2, "title": "How Runtime Upgrades Work", "anchor": "how-runtime-upgrades-work", "start_char": 926, "end_char": 1650, "estimated_token_count": 165, "token_estimator": "heuristic-v1", "text": "## How Runtime Upgrades Work\n\nIn FRAME, the [`system`](https://paritytech.github.io/polkadot-sdk/master/frame_system/index.html){target=\\_blank} pallet uses the [`set_code`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/enum.Call.html#variant.set_code){target=\\_blank} extrinsic to update the Wasm code for the runtime. This method allows solo chains to upgrade without disruption. \n\nFor parachains, upgrades are more complex. Parachains must first call `authorize_upgrade`, followed by `apply_authorized_upgrade`, to ensure the relay chain approves and applies the changes. Additionally, changes to current functionality that impact storage often require a [storage migration](#storage-migrations)."}
{"page_id": "parachains-runtime-maintenance-runtime-upgrades", "page_title": "Runtime Upgrades", "index": 2, "depth": 3, "title": "Runtime Versioning", "anchor": "runtime-versioning", "start_char": 1650, "end_char": 4915, "estimated_token_count": 664, "token_estimator": "heuristic-v1", "text": "### Runtime Versioning\n\nThe executor is the component that selects the runtime execution environment to communicate with. Although you can override the default execution strategies for custom scenarios, in most cases, the executor selects the appropriate binary to use by evaluating and comparing key parameters from the native and Wasm runtime binaries.\n\nThe runtime includes a [runtime version struct](https://paritytech.github.io/polkadot-sdk/master/sp_version/struct.RuntimeVersion.html){target=\\_blank} to provide the needed parameter information to the executor process. A sample runtime version struct might look as follows:\n\n```rust\npub const VERSION: RuntimeVersion = RuntimeVersion {\n    spec_name: create_runtime_str!(\"node-template\"),\n    impl_name: create_runtime_str!(\"node-template\"),\n    authoring_version: 1,\n    spec_version: 1,\n    impl_version: 1,\n    apis: RUNTIME_API_VERSIONS,\n    transaction_version: 1,\n};\n```\n\nThe struct provides the following parameter information to the executor:\n\n- **`spec_name`**: The identifier for the different runtimes.\n- **`impl_name`**: The name of the implementation of the spec. Serves only to differentiate code of different implementation teams.\n- **`authoring_version`**: The version of the authorship interface. An authoring node won't attempt to author blocks unless this is equal to its native runtime.\n- **`spec_version`**: The version of the runtime specification. A full node won't attempt to use its native runtime in substitute for the on-chain Wasm runtime unless the `spec_name`, `spec_version`, and `authoring_version` are all the same between the Wasm and native binaries. Updates to the `spec_version` can be automated as a CI process. This parameter is typically incremented when there's an update to the `transaction_version`.\n- **`impl_version`**: The version of the implementation of the specification. Nodes can ignore this. It is only used to indicate that the code is different. As long as the `authoring_version` and the `spec_version` are the same, the code might have changed, but the native and Wasm binaries do the same thing. In general, only non-logic-breaking optimizations would result in a change of the `impl_version`.\n- **`transaction_version`**: The version of the interface for handling transactions. This parameter can be useful to synchronize firmware updates for hardware wallets or other signing devices to verify that runtime transactions are valid and safe to sign. This number must be incremented if there is a change in the index of the pallets in the `construct_runtime!` macro or if there are any changes to dispatchable functions, such as the number of parameters or parameter types. If `transaction_version` is updated, then the `spec_version` must also be updated.\n- **`apis`**: A list of supported [runtime APIs](https://paritytech.github.io/polkadot-sdk/master/sp_api/macro.impl_runtime_apis.html){target=\\_blank} along with their versions.\n\nThe executor follows the same consensus-driven logic for both the native runtime and the Wasm runtime before deciding which to execute. Because runtime versioning is a manual process, there is a risk that the executor could make incorrect decisions if the runtime version is misrepresented or incorrectly defined."}
{"page_id": "parachains-runtime-maintenance-runtime-upgrades", "page_title": "Runtime Upgrades", "index": 3, "depth": 3, "title": "Accessing the Runtime Version", "anchor": "accessing-the-runtime-version", "start_char": 4915, "end_char": 5431, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "### Accessing the Runtime Version\n\nThe runtime version can be accessed through the `state.getRuntimeVersion` RPC endpoint, which accepts an optional block identifier. It can also be accessed through the runtime metadata to understand the APIs the runtime exposes and how to interact with them.\n\nThe runtime metadata should only change when the chain's [runtime `spec_version`](https://paritytech.github.io/polkadot-sdk/master/sp_version/struct.RuntimeVersion.html#structfield.spec_version){target=\\_blank} changes."}
{"page_id": "parachains-runtime-maintenance-runtime-upgrades", "page_title": "Runtime Upgrades", "index": 4, "depth": 2, "title": "Storage Migrations", "anchor": "storage-migrations", "start_char": 5431, "end_char": 5837, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Storage Migrations\n\nSome runtime upgrades require updating how data is stored to match new formats or layouts. This process is called a Storage Migration. It ensures the runtime can interpret existing state correctly after an upgrade.\n\nFor detailed guidance, scenarios, and implementation patterns, see the [Storage Migrations](/parachains/runtime-maintenance/storage-migrations/){target=\\_blank} page."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 1307, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nStorage migrations are a crucial part of the runtime upgrade process. They allow you to update the [storage items](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.storage.html){target=\\_blank} of your blockchain, adapting to changes in the runtime. Whenever you change the encoding or data types used to represent data in storage, you'll need to provide a storage migration to ensure the runtime can correctly interpret the existing stored values in the new runtime state.\n\nStorage migrations must be executed precisely during the runtime upgrade process to ensure data consistency and prevent [runtime panics](https://doc.rust-lang.org/std/macro.panic.html){target=\\_blank}. The migration code needs to run as follows:\n\n- After the new runtime is deployed.\n- Before any other code from the new runtime executes.\n- Before any [`on_initialize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_initialize){target=\\_blank} hooks run.\n- Before any transactions are processed.\n\nThis timing is critical because the new runtime expects data to be in the updated format. Any attempt to decode the old data format without proper migration could result in runtime panics or undefined behavior."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 1, "depth": 2, "title": "Storage Migration Scenarios", "anchor": "storage-migration-scenarios", "start_char": 1307, "end_char": 4349, "estimated_token_count": 635, "token_estimator": "heuristic-v1", "text": "## Storage Migration Scenarios\n\nA storage migration is necessary whenever a runtime upgrade changes the storage layout or the encoding/interpretation of existing data. Even if the underlying data type appears to still \"fit\" the new storage representation, a migration may be required if the interpretation of the stored values has changed.\n\nStorage migrations ensure data consistency and prevent corruption during runtime upgrades. Below are common scenarios categorized by their impact on storage and migration requirements:\n\n- Migration required:\n    - Reordering or mutating fields of an existing data type to change the encoded/decoded data representation.\n    - Removal of a pallet or storage item warrants cleaning up storage via a migration to avoid state bloat.\n\n- Migration not required:\n    - Adding a new storage item would not require any migration since no existing data needs transformation.\n    - Adding or removing an extrinsic introduces no new interpretation of preexisting data, so no migration is required.\n\nThe following are some common scenarios where a storage migration is needed:\n\n- **Changing data types**: Changing the underlying data type requires a migration to convert the existing values.\n\n    ```rust\n    #[pallet::storage]\n    pub type FooValue = StorageValue<_, Foo>;\n    // old\n    pub struct Foo(u32)\n    // new\n    pub struct Foo(u64)\n    ```\n\n- **Changing data representation**: Modifying the representation of the stored data, even if the size appears unchanged, requires a migration to ensure the runtime can correctly interpret the existing values.\n\n    ```rust\n    #[pallet::storage]\n    pub type FooValue = StorageValue<_, Foo>;\n    // old\n    pub struct Foo(u32)\n    // new\n    pub struct Foo(i32)\n    // or\n    pub struct Foo(u16, u16)\n    ```\n\n- **Extending an enum**: Adding new variants to an enum requires a migration if you reorder existing variants, insert new variants between existing ones, or change the data type of existing variants. No migration is required when adding new variants at the end of the enum.\n\n    ```rust\n    #[pallet::storage]\n    pub type FooValue = StorageValue<_, Foo>;\n    // old\n    pub enum Foo { A(u32), B(u32) }\n    // new (New variant added at the end. No migration required)\n    pub enum Foo { A(u32), B(u32), C(u128) }\n    // new (Reordered variants. Requires migration)\n    pub enum Foo { A(u32), C(u128), B(u32) }\n    ```\n\n- **Changing the storage key**: Modifying the storage key, even if the underlying data type remains the same, requires a migration to ensure the runtime can locate the correct stored values.\n\n    ```rust\n    #[pallet::storage]\n    pub type FooValue = StorageValue<_, u32>;\n    // new\n    #[pallet::storage]\n    pub type BarValue = StorageValue<_, u32>;\n    ```\n\n!!!warning\n    In general, any change to the storage layout or data encoding used in your runtime requires careful consideration of the need for a storage migration. Overlooking a necessary migration can lead to undefined behavior or data loss during a runtime upgrade."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 2, "depth": 2, "title": "Implement Storage Migrations", "anchor": "implement-storage-migrations", "start_char": 4349, "end_char": 4975, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Implement Storage Migrations\n\nThe [`OnRuntimeUpgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.OnRuntimeUpgrade.html){target=\\_blank} trait provides the foundation for implementing storage migrations in your runtime. Here's a detailed look at its essential functions:\n\n```rust\npub trait OnRuntimeUpgrade {\n    fn on_runtime_upgrade() -> Weight { ... }\n    fn try_on_runtime_upgrade(checks: bool) -> Result<Weight, TryRuntimeError> { ... }\n    fn pre_upgrade() -> Result<Vec<u8>, TryRuntimeError> { ... }\n    fn post_upgrade(_state: Vec<u8>) -> Result<(), TryRuntimeError> { ... }\n}\n```"}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 3, "depth": 3, "title": "Core Migration Function", "anchor": "core-migration-function", "start_char": 4975, "end_char": 6007, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Core Migration Function\n\nThe [`on_runtime_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_runtime_upgrade){target=\\_blank} function executes when the FRAME Executive pallet detects a runtime upgrade. Important considerations when using this function include:\n\n- It runs before any pallet's `on_initialize` hooks.\n- Critical storage items (like [`block_number`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.block_number){target=\\_blank}) may not be set.\n- Execution is mandatory and must be completed.\n- Careful weight calculation is required to prevent bricking the chain.\n\nWhen implementing the migration logic, your code must handle several vital responsibilities. A migration implementation must do the following to operate correctly:\n\n- Read existing storage values in their original format.\n- Transform data to match the new format.\n- Write updated values back to storage.\n- Calculate and return consumed weight."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 4, "depth": 3, "title": "Migration Testing Hooks", "anchor": "migration-testing-hooks", "start_char": 6007, "end_char": 8023, "estimated_token_count": 399, "token_estimator": "heuristic-v1", "text": "### Migration Testing Hooks\n\nThe `OnRuntimeUpgrade` trait provides some functions designed specifically for testing migrations. These functions never execute on-chain but are essential for validating migration behavior in test environments. The migration test hooks are as follows:\n\n- **[`try_on_runtime_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.OnRuntimeUpgrade.html#method.try_on_runtime_upgrade){target=\\_blank}**: This function serves as the primary orchestrator for testing the complete migration process. It coordinates the execution flow from `pre-upgrade` checks through the actual migration to `post-upgrade` verification. Handling the entire migration sequence ensures that storage modifications occur correctly and in the proper order. Preserving this sequence is particularly valuable when testing multiple dependent migrations, where the execution order matters.\n\n- **[`pre_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.pre_upgrade){target=\\_blank}**: Before a runtime upgrade begins, the `pre_upgrade` function performs preliminary checks and captures the current state. It returns encoded state data that can be used for `post-upgrade` verification. This function must never modify storage: it should only read and verify the existing state. The data it returns includes critical state values that should remain consistent or transform predictably during migration.\n\n- **[`post_upgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.post_upgrade){target=\\_blank}**: After the migration completes, `post_upgrade` validates its success. It receives the state data captured by `pre_upgrade` to verify that the migration was executed correctly. This function checks for storage consistency and ensures all data transformations are completed as expected. Like `pre_upgrade`, it operates exclusively in testing environments and should not modify storage."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 5, "depth": 3, "title": "Migration Structure", "anchor": "migration-structure", "start_char": 8023, "end_char": 14864, "estimated_token_count": 1637, "token_estimator": "heuristic-v1", "text": "### Migration Structure\n\nThere are two approaches to implementing storage migrations. The first method involves directly implementing `OnRuntimeUpgrade` on structs. This approach requires manually checking the on-chain storage version against the new [`StorageVersion`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/struct.StorageVersion.html){target=\\_blank} and executing the transformation logic only when the check passes. This version verification prevents multiple executions of the migration during subsequent runtime upgrades.\n\nThe recommended approach is to implement [`UncheckedOnRuntimeUpgrade`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.UncheckedOnRuntimeUpgrade.html){target=\\_blank} and wrap it with [`VersionedMigration`](https://paritytech.github.io/polkadot-sdk/master/frame_support/migrations/struct.VersionedMigration.html){target=\\_blank}. `VersionedMigration` implements `OnRuntimeUpgrade` and handles storage version management automatically, following best practices and reducing potential errors.\n\n`VersionedMigration` requires five type parameters:\n\n- **`From`**: The source version for the upgrade.\n- **`To`**: The target version for the upgrade.\n- **`Inner`**: The `UncheckedOnRuntimeUpgrade` implementation.\n- **`Pallet`**: The pallet being upgraded.\n- **`Weight`**: The runtime's [`RuntimeDbWeight`](https://paritytech.github.io/polkadot-sdk/master/frame_support/weights/struct.RuntimeDbWeight.html){target=\\_blank} implementation.\n\nExamine the following migration example that transforms a simple `StorageValue` storing a `u32` into a more complex structure that tracks both current and previous values using the `CurrentAndPreviousValue` struct:\n\n- Old `StorageValue` format:\n\n    ```rust\n    #[pallet::storage]\n    pub type Value<T: Config> = StorageValue<_, u32>;\n    ```\n\n- New `StorageValue` format:\n\n    ```rust\n    /// Example struct holding the most recently set [`u32`] and the\n    /// second most recently set [`u32`] (if one existed).\n    #[docify::export]\n    #[derive(\n    \tClone, Eq, PartialEq, Encode, Decode, RuntimeDebug, scale_info::TypeInfo, MaxEncodedLen,\n    )]\n    pub struct CurrentAndPreviousValue {\n    \t/// The most recently set value.\n    \tpub current: u32,\n    \t/// The previous value, if one existed.\n    \tpub previous: Option<u32>,\n    }\n    #[pallet::storage]\n    \tpub type Value<T: Config> = StorageValue<_, CurrentAndPreviousValue>;\n    ```\n\n- Migration:\n\n    ```rust\n    use frame_support::{\n    \tstorage_alias,\n    \ttraits::{Get, UncheckedOnRuntimeUpgrade},\n    };\n\n    #[cfg(feature = \"try-runtime\")]\n    use alloc::vec::Vec;\n\n    /// Collection of storage item formats from the previous storage version.\n    ///\n    /// Required so we can read values in the v0 storage format during the migration.\n    mod v0 {\n    \tuse super::*;\n\n    \t/// V0 type for [`crate::Value`].\n    \t#[storage_alias]\n    \tpub type Value<T: crate::Config> = StorageValue<crate::Pallet<T>, u32>;\n    }\n\n    /// Implements [`UncheckedOnRuntimeUpgrade`], migrating the state of this pallet from V0 to V1.\n    ///\n    /// In V0 of the template [`crate::Value`] is just a `u32`. In V1, it has been upgraded to\n    /// contain the struct [`crate::CurrentAndPreviousValue`].\n    ///\n    /// In this migration, update the on-chain storage for the pallet to reflect the new storage\n    /// layout.\n    pub struct InnerMigrateV0ToV1<T: crate::Config>(core::marker::PhantomData<T>);\n\n    impl<T: crate::Config> UncheckedOnRuntimeUpgrade for InnerMigrateV0ToV1<T> {\n    \t/// Return the existing [`crate::Value`] so we can check that it was correctly set in\n    \t/// `InnerMigrateV0ToV1::post_upgrade`.\n    \t#[cfg(feature = \"try-runtime\")]\n    \tfn pre_upgrade() -> Result<Vec<u8>, sp_runtime::TryRuntimeError> {\n    \t\tuse codec::Encode;\n\n    \t\t// Access the old value using the `storage_alias` type\n    \t\tlet old_value = v0::Value::<T>::get();\n    \t\t// Return it as an encoded `Vec<u8>`\n    \t\tOk(old_value.encode())\n    \t}\n\n    \t/// Migrate the storage from V0 to V1.\n    \t///\n    \t/// - If the value doesn't exist, there is nothing to do.\n    \t/// - If the value exists, it is read and then written back to storage inside a\n    \t/// [`crate::CurrentAndPreviousValue`].\n    \tfn on_runtime_upgrade() -> frame_support::weights::Weight {\n    \t\t// Read the old value from storage\n    \t\tif let Some(old_value) = v0::Value::<T>::take() {\n    \t\t\t// Write the new value to storage\n    \t\t\tlet new = crate::CurrentAndPreviousValue { current: old_value, previous: None };\n    \t\t\tcrate::Value::<T>::put(new);\n    \t\t\t// One read + write for taking the old value, and one write for setting the new value\n    \t\t\tT::DbWeight::get().reads_writes(1, 2)\n    \t\t} else {\n    \t\t\t// No writes since there was no old value, just one read for checking\n    \t\t\tT::DbWeight::get().reads(1)\n    \t\t}\n    \t}\n\n    \t/// Verifies the storage was migrated correctly.\n    \t///\n    \t/// - If there was no old value, the new value should not be set.\n    \t/// - If there was an old value, the new value should be a [`crate::CurrentAndPreviousValue`].\n    \t#[cfg(feature = \"try-runtime\")]\n    \tfn post_upgrade(state: Vec<u8>) -> Result<(), sp_runtime::TryRuntimeError> {\n    \t\tuse codec::Decode;\n    \t\tuse frame_support::ensure;\n\n    \t\tlet maybe_old_value = Option::<u32>::decode(&mut &state[..]).map_err(|_| {\n    \t\t\tsp_runtime::TryRuntimeError::Other(\"Failed to decode old value from storage\")\n    \t\t})?;\n\n    \t\tmatch maybe_old_value {\n    \t\t\tSome(old_value) => {\n    \t\t\t\tlet expected_new_value =\n    \t\t\t\t\tcrate::CurrentAndPreviousValue { current: old_value, previous: None };\n    \t\t\t\tlet actual_new_value = crate::Value::<T>::get();\n\n    \t\t\t\tensure!(actual_new_value.is_some(), \"New value not set\");\n    \t\t\t\tensure!(\n    \t\t\t\t\tactual_new_value == Some(expected_new_value),\n    \t\t\t\t\t\"New value not set correctly\"\n    \t\t\t\t);\n    \t\t\t},\n    \t\t\tNone => {\n    \t\t\t\tensure!(crate::Value::<T>::get().is_none(), \"New value unexpectedly set\");\n    \t\t\t},\n    \t\t};\n    \t\tOk(())\n    \t}\n    }\n\n    /// [`UncheckedOnRuntimeUpgrade`] implementation [`InnerMigrateV0ToV1`] wrapped in a\n    /// [`VersionedMigration`](frame_support::migrations::VersionedMigration), which ensures that:\n    /// - The migration only runs once when the on-chain storage version is 0\n    /// - The on-chain storage version is updated to `1` after the migration executes\n    /// - Reads/Writes from checking/settings the on-chain storage version are accounted for\n    pub type MigrateV0ToV1<T> = frame_support::migrations::VersionedMigration<\n    \t0, // The migration will only execute when the on-chain storage version is 0\n    \t1, // The on-chain storage version will be set to 1 after the migration is complete\n    \tInnerMigrateV0ToV1<T>,\n    \tcrate::pallet::Pallet<T>,\n    \t<T as frame_system::Config>::DbWeight,\n    >;\n    ```"}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 6, "depth": 3, "title": "Migration Organization", "anchor": "migration-organization", "start_char": 14864, "end_char": 15556, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "### Migration Organization\n\nBest practices recommend organizing migrations in a separate module within your pallet. Here's the recommended file structure:\n\n```plain\nmy-pallet/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ lib.rs       # Main pallet implementation\nâ”‚   â””â”€â”€ migrations/  # All migration-related code\nâ”‚       â”œâ”€â”€ mod.rs   # Migrations module definition\nâ”‚       â”œâ”€â”€ v1.rs    # V0 -> V1 migration\nâ”‚       â””â”€â”€ v2.rs    # V1 -> V2 migration\nâ””â”€â”€ Cargo.toml\n```\n\nThis structure provides several benefits:\n\n- Separates migration logic from core pallet functionality.\n- Makes migrations easier to test and maintain.\n- Provides explicit versioning of storage changes.\n- Simplifies the addition of future migrations."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 7, "depth": 3, "title": "Scheduling Migrations", "anchor": "scheduling-migrations", "start_char": 15556, "end_char": 16131, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "### Scheduling Migrations\n\nTo execute migrations during a runtime upgrade, you must configure them in your runtime's Executive pallet. Add your migrations in `runtime/src/lib.rs`:\n\n```rust\n/// Tuple of migrations (structs that implement `OnRuntimeUpgrade`)\ntype Migrations = (\n    pallet_my_pallet::migrations::v1::Migration,\n    // More migrations can be added here\n);\npub type Executive = frame_executive::Executive<\n    Runtime,\n    Block,\n    frame_system::ChainContext<Runtime>,\n    Runtime,\n    AllPalletsWithSystem,\n    Migrations, // Include migrations here\n>;\n\n```"}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 8, "depth": 2, "title": "Single-Block Migrations", "anchor": "single-block-migrations", "start_char": 16131, "end_char": 17219, "estimated_token_count": 196, "token_estimator": "heuristic-v1", "text": "## Single-Block Migrations\n\nSingle-block migrations execute their logic within one block immediately following a runtime upgrade. They run as part of the runtime upgrade process through the `OnRuntimeUpgrade` trait implementation and must be completed before any other runtime logic executes.\n\nWhile single-block migrations are straightforward to implement and provide immediate data transformation, they carry significant risks. The most critical consideration is that they must complete within one block's weight limits. This is especially crucial for parachains, where exceeding block weight limits will brick the chain.\n\nUse single-block migrations only when you can guarantee:\n\n- The migration has a bounded execution time.\n- Weight calculations are thoroughly tested.\n- Total weight will never exceed block limits.\n\nFor a complete implementation example of a single-block migration, refer to the [single-block migration example]( https://paritytech.github.io/polkadot-sdk/master/pallet_example_single_block_migrations/index.html){target=\\_blank} in the Polkadot SDK documentation."}
{"page_id": "parachains-runtime-maintenance-storage-migrations", "page_title": "Storage Migrations", "index": 9, "depth": 2, "title": "Multi Block Migrations", "anchor": "multi-block-migrations", "start_char": 17219, "end_char": 18500, "estimated_token_count": 230, "token_estimator": "heuristic-v1", "text": "## Multi Block Migrations\n\nMulti-block migrations distribute the migration workload across multiple blocks, providing a safer approach for production environments. The migration state is tracked in storage, allowing the process to pause and resume across blocks.\n\nThis approach is essential for production networks and parachains as the risk of exceeding block weight limits is eliminated. Multi-block migrations can safely handle large storage collections, unbounded data structures, and complex nested data types where weight consumption might be unpredictable.\n\nMulti-block migrations are ideal when dealing with:\n\n- Large-scale storage migrations.\n- Unbounded storage items or collections.\n- Complex data structures with uncertain weight costs.\n\nThe primary trade-off is increased implementation complexity, as you must manage the migration state and handle partial completion scenarios. However, multi-block migrations' significant safety benefits and operational reliability are typically worth the increased complexity.\n\nFor a complete implementation example of multi-block migrations, refer to the [official example](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/substrate/frame/examples/multi-block-migrations){target=\\_blank} in the Polkadot SDK."}
{"page_id": "parachains-runtime-maintenance-unlock-parachains", "page_title": "Unlock a Parachain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 1073, "estimated_token_count": 180, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nParachain locks are a critical security mechanism in the Polkadot ecosystem designed to maintain decentralization during the parachain lifecycle. These locks prevent potential centralization risks that could emerge during the early stages of parachain operation.\n\nThe locking system follows strict, well-defined conditions that distribute control across multiple authorities:\n\n- Relay chain governance has the authority to lock any parachain.\n- A parachain can lock its own lock.\n- Parachain managers have permission to lock the parachain.\n- Parachains are locked automatically when they successfully produce their first block.\n\nSimilarly, unlocking a parachain follows controlled procedures:\n\n- Relay chain governance retains the authority to unlock any parachain.\n- A parachain can unlock its own lock.\n\nThis document guides you through checking a parachain's lock status and safely executing the unlock procedure from a parachain using [XCM (Cross-Consensus Messaging)](/parachains/interoperability/get-started/){target=\\_blank}."}
{"page_id": "parachains-runtime-maintenance-unlock-parachains", "page_title": "Unlock a Parachain", "index": 1, "depth": 2, "title": "Check If the Parachain Is Locked", "anchor": "check-if-the-parachain-is-locked", "start_char": 1073, "end_char": 2103, "estimated_token_count": 262, "token_estimator": "heuristic-v1", "text": "## Check If the Parachain Is Locked\n\nBefore unlocking a parachain, you should verify its current lock status. This can be done through the Polkadot.js interface:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the relay chain, navigate to the **Developer** dropdown and select the **Chain State** option.\n\n2. Query the parachain locked status:\n    1. Select **`registrar`**.\n    2. Choose the **`paras`** option.\n    3. Input the parachain ID you want to check as a parameter (e.g. `2006`).\n    4. Click the **+** button to execute the query.\n    5. Check the status of the parachain lock.\n        - **`manager`**: The account that has placed a deposit for registering this parachain.\n        - **`deposit`**: The amount reserved by the `manager` account for the registration.\n        - **`locked`**: Whether the parachain registration should be locked from being controlled by the manager.\n\n    ![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-1.webp)"}
{"page_id": "parachains-runtime-maintenance-unlock-parachains", "page_title": "Unlock a Parachain", "index": 2, "depth": 2, "title": "How to Unlock a Parachain", "anchor": "how-to-unlock-a-parachain", "start_char": 2103, "end_char": 2758, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## How to Unlock a Parachain\n\nUnlocking a parachain requires sending an XCM (Cross-Consensus Message) to the relay chain from the parachain itself, sending a message with Root origin, or this can be accomplished through the relay chain's governance mechanism, executing a root call.\n\nIf sending an XCM, the parachain origin must have proper authorization, typically from either the parachain's sudo pallet (if enabled) or its governance system.\n\nThis guide demonstrates the unlocking process using a parachain with the sudo pallet. For parachains using governance-based authorization instead, the process will require adjustments to how the XCM is sent."}
{"page_id": "parachains-runtime-maintenance-unlock-parachains", "page_title": "Unlock a Parachain", "index": 3, "depth": 3, "title": "Prepare the Unlock Call", "anchor": "prepare-the-unlock-call", "start_char": 2758, "end_char": 4174, "estimated_token_count": 341, "token_estimator": "heuristic-v1", "text": "### Prepare the Unlock Call\n\nBefore sending the XCM, you need to construct the relay chain call that will be executed. Follow these steps to prepare the `registrar.removeLock` extrinsic:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the relay chain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n2. Build the `registrar.removeLock` extrinsic:\n\n    1. Select the **registrar** pallet.\n    2. Choose the **removeLock** extrinsic.\n    3. Fill in the parachain ID parameter (e.g., `2006`).\n    4. Copy the **encoded call data**.\n\n    ![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-2.webp)\n\n    To ensure your encoded call data is correct, check this [example](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fdot-rpc.stakeworld.io#/extrinsics/decode/0x4604d6070000){target=\\_blank} of a decoded `removeLock` call for parachain 2006. Your encoded data should follow the same pattern.\n\n3. Determine the transaction weight required for executing the call. You can estimate this by executing the `transactionPaymentCallApi.queryCallInfo` runtime call with the encoded call data previously obtained:\n\n    ![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-3.webp)\n\n    This weight information is crucial for properly configuring your XCM message's execution parameters in the next steps."}
{"page_id": "parachains-runtime-maintenance-unlock-parachains", "page_title": "Unlock a Parachain", "index": 4, "depth": 3, "title": "Fund the Sovereign Account", "anchor": "fund-the-sovereign-account", "start_char": 4174, "end_char": 6016, "estimated_token_count": 396, "token_estimator": "heuristic-v1", "text": "### Fund the Sovereign Account\n\nFor a successful XCM execution, the [sovereign account](https://github.com/polkadot-fellows/xcm-format/blob/10726875bd3016c5e528c85ed6e82415e4b847d7/README.md?plain=1#L50){target=\\_blank} of your parachain on the relay chain must have sufficient funds to cover transaction fees. The sovereign account is a deterministic address derived from your parachain ID.\n\nYou can identify your parachain's sovereign account using either of these methods:\n\n=== \"Runtime API\"\n\n    Execute the `locationToAccountApi.convertLocation` runtime API call to convert your parachain's location into its sovereign account address on the relay chain.\n\n    ![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-7.webp)\n\n=== \"Substrate Utilities\"\n\n    Use the **\"Para ID\" to Address** section in [Substrate Utilities](https://www.shawntabrizi.com/substrate-js-utilities/){target=\\_blank} with the **Child** option selected.\n\n=== \"Manual Calculation\"\n\n    1. Identify the appropriate prefix:\n\n        - For parent/child chains use the prefix `0x70617261` (which decodes to `b\"para\"`).\n         \n    2. Encode your parachain ID as a u32 SCALE value:\n        \n\n        - For parachain 2006, this would be `d6070000`.\n\n    3. Combine the prefix with the encoded ID to form the sovereign account address:\n\n        - **Hex**: `0x70617261d6070000000000000000000000000000000000000000000000000000`\n        - **SS58 format**: `5Ec4AhPW97z4ZyYkd3mYkJrSeZWcwVv4wiANES2QrJi1x17F`\n\nYou can transfer funds to this account from any account on the relay chain using a standard transfer. To calculate the amount needed, refer to the [XCM Payment API](https://paritytech.github.io/polkadot-sdk/master/xcm_runtime_apis/fees/trait.XcmPaymentApi.html){target=\\_blank}. The calculation will depend on the XCM built in the next step."}
{"page_id": "parachains-runtime-maintenance-unlock-parachains", "page_title": "Unlock a Parachain", "index": 5, "depth": 3, "title": "Craft and Submit the XCM", "anchor": "craft-and-submit-the-xcm", "start_char": 6016, "end_char": 9197, "estimated_token_count": 710, "token_estimator": "heuristic-v1", "text": "### Craft and Submit the XCM\n\nWith the call data prepared and the sovereign account funded, you can now construct and send the XCM from your parachain to the relay chain. The XCM will need to perform several operations in sequence:\n\n1. Withdraw DOT from your parachain's sovereign account.\n2. Buy execution to pay for transaction fees.\n3. Execute the `registrar.removeLock` extrinsic.\n4. Return any unused funds to your sovereign account.\n\nHere's how to submit this XCM using Astar (Parachain 2006) as an example:\n\n1. In [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}, connect to the parachain, navigate to the **Developer** dropdown and select the **Extrinsics** option.\n\n2. Create a `sudo.sudo` extrinsic that executes `polkadotXcm.send`:\n\n    1. Use the `sudo.sudo` extrinsic to execute the following call as Root.\n    2. Select the **polkadotXcm** pallet.\n    3. Choose the **send** extrinsic.\n    4. Set the **dest** parameter as the relay chain.\n\n    ![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-4.webp)\n\n3. Construct the XCM and submit it:\n\n    1. Add a **WithdrawAsset** instruction.\n    2. Add a **BuyExecution** instruction.\n        - **fees**:\n            - **id**: The asset location to use for the fee payment. In this example, the relay chain native asset is used.\n            - **fun**: Select `Fungible` and use the same amount you withdrew from the sovereign account in the previous step.\n        - **weightLimit**: Use `Unlimited`.\n    3. Add a **Transact** instruction with the following parameters:\n        - **originKind**: Use `Native`.\n        - **requireWeightAtMost**: Use the weight calculated previously.\n        - **call**: Use the encoded call data generated before.\n    4. Add a **RefundSurplus** instruction.\n    5. Add a **DepositAsset** instruction to send the remaining funds to the parachain sovereign account.\n    6. Click the **Submit Transaction** button.\n\n    ![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-5.webp)\n\n    If the amount withdrawn in the first instruction is exactly the amount needed to pay the transaction fees, instructions 4 and 5 can be omitted.\n\n    To validate your XCM, examine the following reference [extrinsic](https://polkadot.js.org/apps/?rpc=wss%3A%2F%2Fastar.public.curie.radiumblock.co%2Fws#/extrinsics/decode/0x63003300040100041400040000000700e40b5402130000000700e40b540200060042d3c91800184604d6070000140d0100000100591f){target=_blank} showing the proper instruction sequence and parameter formatting. Following this structure will help ensure successful execution of your message.\n\nAfter submitting the transaction, wait for it to be finalized and then verify that your parachain has been successfully unlocked by following the steps described in the [Check if the Parachain is Locked](#check-if-the-parachain-is-locked) section. If the parachain shows as unlocked, your operation has been successful. If it still appears locked, verify that your XCM transaction was processed correctly and consider troubleshooting the XCM built.\n\n![](/images/parachains/runtime-maintenance/unlock-parachains/unlock-parachain-6.webp)"}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 37, "end_char": 1215, "estimated_token_count": 242, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Chopsticks](https://github.com/AcalaNetwork/chopsticks/){target=\\_blank}, developed by the [Acala Foundation](https://github.com/AcalaNetwork){target=\\_blank}, is a versatile tool tailored for developers working on Polkadot SDK-based blockchains. With Chopsticks, you can fork live chains locally, replay blocks to analyze extrinsics, and simulate complex scenarios like XCM interactions all without deploying to a live network.\n\nThis guide walks you through installing Chopsticks and provides information on configuring a local blockchain fork. By streamlining testing and experimentation, Chopsticks empowers developers to innovate and accelerate their blockchain projects within the Polkadot ecosystem.\n\nFor additional support and information, please reach out through [GitHub Issues](https://github.com/AcalaNetwork/chopsticks/issues){target=_blank}.\n\n!!! warning\n    Chopsticks uses [Smoldot](https://github.com/smol-dot/smoldot){target=_blank} light client, which only supports the native Polkadot SDK API. Consequently, a Chopsticks-based fork doesn't support Ethereum JSON-RPC calls, meaning you cannot use it to fork your chain and connect Metamask."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1215, "end_char": 1522, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- [Node.js](https://nodejs.org/en/){target=\\_blank}.\n- A package manager such as [npm](https://www.npmjs.com/){target=\\_blank}, which should be installed with Node.js by default, or [Yarn](https://yarnpkg.com/){target=\\_blank}."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 2, "depth": 2, "title": "Install Chopsticks", "anchor": "install-chopsticks", "start_char": 1522, "end_char": 1814, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Install Chopsticks\n\nYou can install Chopsticks globally or locally in your project. Choose the option that best fits your development workflow. This documentation explains the features of Chopsticks version `1.2.2`. Make sure you're using the correct version to match these instructions."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 3, "depth": 3, "title": "Global Installation", "anchor": "global-installation", "start_char": 1814, "end_char": 2057, "estimated_token_count": 61, "token_estimator": "heuristic-v1", "text": "### Global Installation\n\nTo install Chopsticks globally, allowing you to use it across multiple projects, run:\n\n```bash\nnpm i -g @acala-network/chopsticks@1.2.2\n```\n\nNow, you should be able to run the `chopsticks` command from your terminal."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 4, "depth": 3, "title": "Local Installation", "anchor": "local-installation", "start_char": 2057, "end_char": 2546, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "### Local Installation\n\nTo use Chopsticks in a specific project, first create a new directory and initialize a Node.js project:\n\n```bash\nmkdir my-chopsticks-project\ncd my-chopsticks-project\nnpm init -y\n```\n\nThen, install Chopsticks as a local dependency:\n\n```bash\nnpm i @acala-network/chopsticks@1.2.2\n```\n\nFinally, you can run Chopsticks using the `npx` command. To see all available options and commands, run it with the `--help` flag:\n\n```bash\nnpx @acala-network/chopsticks --help\n```"}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 5, "depth": 2, "title": "Configure Chopsticks", "anchor": "configure-chopsticks", "start_char": 2546, "end_char": 3895, "estimated_token_count": 360, "token_estimator": "heuristic-v1", "text": "## Configure Chopsticks\n\nTo run Chopsticks, you need to configure some parameters. This can be set either through using a configuration file or the command line interface (CLI). The parameters that can be configured are as follows:\n\n- **`genesis`**: The link to a parachain's raw genesis file to build the fork from, instead of an endpoint.\n- **`timestamp`**: Timestamp of the block to fork from.\n- **`endpoint`**: The endpoint of the parachain to fork.\n- **`block`**: Use to specify at which block hash or number to replay the fork.\n- **`wasm-override`**: Path of the Wasm to use as the parachain runtime, instead of an endpoint's runtime.\n- **`db`**: Path to the name of the file that stores or will store the parachain's database.\n- **`config`**: Path or URL of the config file.\n- **`port`**: The port to expose an endpoint on.\n- **`build-block-mode`**: How blocks should be built in the fork: batch, manual, instant.\n- **`import-storage`**: A pre-defined JSON/YAML storage path to override in the parachain's storage.\n- **`allow-unresolved-imports`**: Whether to allow Wasm unresolved imports when using a Wasm to build the parachain.\n- **`html`**: Include to generate storage diff preview between blocks.\n- **`mock-signature-host`**: Mock signature host so that any signature starts with `0xdeadbeef` and filled by `0xcd` is considered valid."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 6, "depth": 3, "title": "Configuration File", "anchor": "configuration-file", "start_char": 3895, "end_char": 5094, "estimated_token_count": 271, "token_estimator": "heuristic-v1", "text": "### Configuration File\n\nThe Chopsticks source repository includes a collection of [YAML](https://yaml.org/){target=\\_blank} files that can be used to set up various Polkadot SDK chains locally. You can download these configuration files from the [repository's `configs` folder](https://github.com/AcalaNetwork/chopsticks/tree/master/configs){target=\\_blank}.\n\nAn example of a configuration file for Polkadot is as follows:\n\n{% raw %}\n```yaml\nendpoint:\n  - wss://rpc.ibp.network/polkadot\n  - wss://polkadot-rpc.dwellir.com\nmock-signature-host: true\nblock: ${env.POLKADOT_BLOCK_NUMBER}\ndb: ./db.sqlite\nruntime-log-level: 5\n\nimport-storage:\n  System:\n    Account:\n      - - - 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\n        - providers: 1\n          data:\n            free: '10000000000000000000'\n  ParasDisputes:\n    $removePrefix: ['disputes'] # those can makes block building super slow\n\n```\n{% endraw %}\n\nThe configuration file allows you to modify the storage of the forked network by rewriting the pallet, state component and value that you want to change. For example, Polkadot's file rewrites Alice's `system.Account` storage so that the free balance is set to `10000000000000000000`."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 7, "depth": 3, "title": "CLI Flags", "anchor": "cli-flags", "start_char": 5094, "end_char": 5275, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "### CLI Flags\n\nAlternatively, all settings (except for genesis and timestamp) can be configured via command-line flags, providing a comprehensive method to set up the environment."}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 8, "depth": 2, "title": "WebSocket Commands", "anchor": "websocket-commands", "start_char": 5275, "end_char": 10559, "estimated_token_count": 1272, "token_estimator": "heuristic-v1", "text": "## WebSocket Commands\n\nChopstick's internal WebSocket server has special endpoints that allow the manipulation of the local Polkadot SDK chain.\n\nThese are the methods that can be invoked and their parameters:\n\n- **dev_newBlock** (newBlockParams): Generates one or more new blocks.\n\n    === \"Parameters\"\n\n        - **`newBlockParams` ++\"NewBlockParams\"++**: The parameters to build the new block with. Where the `NewBlockParams` interface includes the following properties.\n\n            - **`count` ++\"number\"++**: The number of blocks to build.\n            - **`dmp` ++\"{ msg: string, sentAt: number }[]\"++**: The downward messages to include in the block.\n            - **`hrmp` ++\"Record<string | number, { data: string, sentAt: number }[]>\"++**: The horizontal messages to include in the block.\n            - **`to` ++\"number\"++**: The block number to build to.\n            - **`transactions` ++\"string[]\"++**: The transactions to include in the block.\n            - **`ump` ++\"Record<number, string[]>\"++**: The upward messages to include in the block.\n            - **`unsafeBlockHeight` ++\"number\"++**: Build block using a specific block height (unsafe).\n\n    === \"Example\"\n\n        ```js\n        import { ApiPromise, WsProvider } from '@polkadot/api';\n\n        async function main() {\n          const wsProvider = new WsProvider('ws://localhost:8000');\n          const api = await ApiPromise.create({ provider: wsProvider });\n          await api.isReady;\n          await api.rpc('dev_newBlock', { count: 1 });\n        }\n\n        main();\n\n        ```\n\n- **dev_setBlockBuildMode** (buildBlockMode): Sets block build mode.\n\n    === \"Parameter\"\n    \n        - **`buildBlockMode` ++\"BuildBlockMode\"++**: The build mode. Can be any of the following modes:\n\n            ```ts\n            export enum BuildBlockMode {\n              Batch = 'Batch', /** One block per batch (default) */\n              Instant = 'Instant', /** One block per transaction */\n              Manual = 'Manual', /** Only build when triggered */\n            }\n            ```\n            \n    === \"Example\"\n\n        ```js\n        import { ApiPromise, WsProvider } from '@polkadot/api';\n\n        async function main() {\n          const wsProvider = new WsProvider('ws://localhost:8000');\n          const api = await ApiPromise.create({ provider: wsProvider });\n          await api.isReady;\n          await api.rpc('dev_setBlockBuildMode', 'Instant');\n        }\n\n        main();\n\n        ```\n\n- **dev_setHead** (hashOrNumber): Sets the head of the blockchain to a specific hash or number.\n\n    === \"Parameter\"\n\n        - **`hashOrNumber` ++\"string | number\"++**: The block hash or number to set as head.\n\n    === \"Example\"\n\n        ```js\n        import { ApiPromise, WsProvider } from '@polkadot/api';\n\n        async function main() {\n          const wsProvider = new WsProvider('ws://localhost:8000');\n          const api = await ApiPromise.create({ provider: wsProvider });\n          await api.isReady;\n          await api.rpc('dev_setHead', 500);\n        }\n\n        main();\n\n        ```\n\n- **dev_setRuntimeLogLevel** (runtimeLogLevel): Sets the runtime log level.\n\n    === \"Parameter\"\n\n        - **`runtimeLogLevel` ++\"number\"++**: The runtime log level to set.\n\n    === \"Example\"\n\n        ```js\n        import { ApiPromise, WsProvider } from '@polkadot/api';\n\n        async function main() {\n          const wsProvider = new WsProvider('ws://localhost:8000');\n          const api = await ApiPromise.create({ provider: wsProvider });\n          await api.isReady;\n          await api.rpc('dev_setRuntimeLogLevel', 1);\n        }\n\n        main();\n\n        ```\n\n- **dev_setStorage** (values, blockHash): Creates or overwrites the value of any storage.\n\n    === \"Parameters\"\n\n        - **`values` ++\"object\"++**: JSON object resembling the path to a storage value.\n        - **`blockHash` ++\"string\"++**: The block hash to set the storage value.\n\n    === \"Example\"\n\n        ```js\n        import { ApiPromise, WsProvider } from '@polkadot/api';\n\n        import { Keyring } from '@polkadot/keyring';\n        async function main() {\n          const wsProvider = new WsProvider('ws://localhost:8000');\n          const api = await ApiPromise.create({ provider: wsProvider });\n          await api.isReady;\n          const keyring = new Keyring({ type: 'ed25519' });\n          const bob = keyring.addFromUri('//Bob');\n          const storage = {\n            System: {\n              Account: [[[bob.address], { data: { free: 100000 }, nonce: 1 }]],\n            },\n          };\n          await api.rpc('dev_setStorage', storage);\n        }\n\n        main();\n\n        ```\n\n- **dev_timeTravel** (date): Sets the timestamp of the block to a specific date\".\n\n    === \"Parameter\"\n\n        - **`date` ++\"string\"++**: Timestamp or date string to set. All future blocks will be sequentially created after this point in time.\n\n    === \"Example\"\n\n        ```js\n        import { ApiPromise, WsProvider } from '@polkadot/api';\n\n        async function main() {\n          const wsProvider = new WsProvider('ws://localhost:8000');\n          const api = await ApiPromise.create({ provider: wsProvider });\n          await api.isReady;\n          await api.rpc('dev_timeTravel', '2030-08-15T00:00:00');\n        }\n\n        main();\n\n        ```"}
{"page_id": "parachains-testing-fork-a-parachain", "page_title": "Fork a Parachain Using Chopsticks", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10559, "end_char": 10934, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Chopsticks Documentation__\n\n    ---\n\n    For reference documentation on the methods exposed by Chopsticks, see the official Chopsticks documentation.\n\n    [:octicons-arrow-right-24: Get Started](https://acalanetwork.github.io/chopsticks/docs/){target=\\_blank}\n\n</div>"}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 43, "end_char": 795, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nZombienet is a robust testing framework designed for Polkadot SDK-based blockchain networks. It enables developers to efficiently deploy and test ephemeral blockchain environments on platforms like Kubernetes, Podman, and native setups. With its simple and versatile CLI, Zombienet provides an all-in-one solution for spawning networks, running tests, and validating performance.\n\nThis guide will outline the different installation methods for Zombienet, provide step-by-step instructions for setting up on various platforms, and highlight essential provider-specific features and requirements.\n\nBy following this guide, Zombienet will be up and running quickly, ready to streamline your blockchain testing and development workflows."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 1, "depth": 2, "title": "Install Zombienet", "anchor": "install-zombienet", "start_char": 795, "end_char": 5049, "estimated_token_count": 901, "token_estimator": "heuristic-v1", "text": "## Install Zombienet\n\nZombienet releases are available on the [Zombienet repository](https://github.com/paritytech/zombienet){target=\\_blank}.\n\nMultiple options are available for installing Zombienet, depending on the user's preferences and the environment where it will be used. The following section will guide you through the installation process for each option.\n\n=== \"Use the executable\"\n\n    Install Zombienet using executables by visiting the [latest release](https://github.com/paritytech/zombienet/releases){target=\\_blank} page and selecting the appropriate asset for your operating system. You can download the executable and move it to a directory in your PATH. \n\n    Each release includes executables for Linux and macOS. Executables are generated using [pkg](https://github.com/vercel/pkg){target=\\_blank}, which allows the Zombienet CLI to operate without requiring Node.js to be installed. \n\n    Then, ensure the downloaded file is executable:\n\n    ```bash\n    chmod +x zombienet-macos-arm64\n    ```\n\n    Finally, you can run the following command to check if the installation was successful. If so, it will display the version of the installed Zombienet:\n\n    ```bash\n    ./zombienet-macos-arm64 version\n    ```\n\n    If you want to add the `zombienet` executable to your PATH, you can move it to a directory in your PATH, such as `/usr/local/bin`:\n\n    ```bash\n    mv zombienet-macos-arm64 /usr/local/bin/zombienet\n    ```\n\n    Now you can refer to the `zombienet` executable directly.\n\n    ```bash\n    zombienet version\n    ```\n\n=== \"Use Nix\"\n\n    For Nix users, the Zombienet repository provides a [`flake.nix`](https://github.com/paritytech/zombienet/blob/main/flake.nix){target=\\_blank} file to install Zombienet making it easy to incorporate Zombienet into Nix-based projects.\n    \n    To install Zombienet utilizing Nix, users can run the following command, triggering the fetching of the flake and subsequently installing the Zombienet package:\n\n    ```bash\n    nix run github:paritytech/zombienet/INSERT_ZOMBIENET_VERSION -- \\\n    spawn INSERT_ZOMBIENET_CONFIG_FILE_NAME.toml\n    ```\n\n    Replace the `INSERT_ZOMBIENET_VERSION` with the desired version of Zombienet and the `INSERT_ZOMBIENET_CONFIG_FILE_NAME` with the name of the configuration file you want to use.\n\n    To run the command above, you need to have [Flakes](https://nixos.wiki/wiki/Flakes#Enable_flakes){target=\\_blank} enabled.\n\n    Alternatively, you can also include the Zombienet binary in the PATH for the current shell using the following command:\n    \n    ```bash\n    nix shell github:paritytech/zombienet/INSERT_ZOMBIENET_VERSION\n    ```\n\n=== \"Use Docker\"\n\n    Zombienet can also be run using Docker. The Zombienet repository provides a Docker image that can be used to run the Zombienet CLI. To run Zombienet using Docker, you can use the following command:\n\n    ```bash\n    docker run -it --rm \\\n    -v $(pwd):/home/nonroot/zombie-net/host-current-files \\\n    paritytech/zombienet\n    ```\n\n    The command above will run the Zombienet CLI inside a Docker container and mount the current directory to the `/home/nonroot/zombie-net/host-current-files` directory. This allows Zombienet to access the configuration file and other files in the current directory. If you want to mount a different directory, replace `$(pwd)` with the desired directory path.\n\n    Inside the Docker container, you can run the Zombienet CLI commands. First, you need to set up Zombienet to download the necessary binaries:\n\n    ```bash\n    npm run zombie -- setup polkadot polkadot-parachain\n    ```\n\n    After that, you need to add those binaries to the PATH:\n\n    ```bash\n    export PATH=/home/nonroot/zombie-net:$PATH\n    ```\n\n    Finally, you can run the Zombienet CLI commands. For example, to spawn a network using a specific configuration file, you can run the following command:\n\n    ```bash\n    npm run zombie -- -p native spawn host-current-files/minimal.toml\n    ```\n\n    The command above mounts the current directory to the `/workspace` directory inside the Docker container, allowing Zombienet to access the configuration file and other files in the current directory. If you want to mount a different directory, replace `$(pwd)` with the desired directory path."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 2, "depth": 2, "title": "Providers", "anchor": "providers", "start_char": 5049, "end_char": 5832, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "## Providers\n\nZombienet supports different backend providers for running the nodes. At this moment, [Kubernetes](https://kubernetes.io/){target=\\_blank}, [Podman](https://podman.io/){target=\\_blank}, and local providers are supported, which can be declared as `kubernetes`, `podman`, or `native`, respectively.\n\nTo use a particular provider, you can specify it in the network file or use the `--provider` flag in the CLI:\n\n```bash\nzombienet spawn network.toml --provider INSERT_PROVIDER\n```\n\nAlternatively, you can set the provider in the network file:\n\n```toml\n[settings]\nprovider = \"INSERT_PROVIDER\"\n...\n```\n\nIt's important to note that each provider has specific requirements and associated features. The following sections cover each provider's requirements and added features."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 3, "depth": 3, "title": "Kubernetes", "anchor": "kubernetes", "start_char": 5832, "end_char": 7361, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "### Kubernetes\n\nKubernetes is a portable, extensible, open-source platform for managing containerized workloads and services. Zombienet is designed to be compatible with a variety of Kubernetes clusters, including: \n\n- [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine){target=\\_blank}\n- [Docker Desktop](https://docs.docker.com/desktop/features/kubernetes/){target=\\_blank}\n- [kind](https://kind.sigs.k8s.io/){target=\\_blank}\n\n#### Requirements\n    \nTo effectively interact with your cluster, you'll need to ensure that [`kubectl`](https://kubernetes.io/docs/reference/kubectl/){target=\\_blank} is installed on your system. This Kubernetes command-line tool allows you to run commands against Kubernetes clusters. If you don't have `kubectl` installed, you can follow the instructions provided in the [Kubernetes documentation](https://kubernetes.io/docs/tasks/tools/#kubectl){target=\\_blank}.\n\nTo create resources such as namespaces, pods, and CronJobs within the target cluster, you must grant your user or service account the appropriate permissions. These permissions are essential for managing and deploying applications effectively within Kubernetes.\n\n#### Features\n    \nIf available, Zombienet uses the Prometheus operator to oversee monitoring and visibility. This configuration ensures that only essential networking-related pods are deployed. Using the Prometheus operator, Zombienet improves its ability to monitor and manage network activities within the Kubernetes cluster efficiently."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 4, "depth": 3, "title": "Podman", "anchor": "podman", "start_char": 7361, "end_char": 8957, "estimated_token_count": 374, "token_estimator": "heuristic-v1", "text": "### Podman\n\nPodman is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers and container images on Linux-based systems. Zombienet supports Podman rootless as a provider on Linux machines. Although Podman has support for macOS through an internal virtual machine (VM), the Zombienet provider code requires Podman to run natively on Linux.\n\n#### Requirements\n     \nTo use Podman as a provider, you need to have Podman installed on your system. You can install Podman by following the instructions provided on the [Podman website](https://podman.io/getting-started/installation){target=\\_blank}.\n\n#### Features\n    \nUsing Podman, Zombienet deploys additional pods to enhance the monitoring and visibility of the active network. Specifically, pods for [Prometheus](https://prometheus.io/){target=\\_blank}, [Tempo](https://grafana.com/docs/tempo/latest/operations/monitor/){target=\\_blank}, and [Grafana](https://grafana.com/){target=\\_blank} are included in the deployment. Grafana is configured with Prometheus and Tempo as data sources.\n\nUpon launching Zombienet, access to these monitoring services is facilitated through specific URLs provided in the output:\n\n- **Prometheus**: `http://127.0.0.1:34123`\n- **Tempo**: `http://127.0.0.1:34125`\n- **Grafana**: `http://127.0.0.1:41461`\n\nIt's important to note that Grafana is deployed with default administrator access. \n    \nWhen network operations cease, either from halting a running spawn with the `Ctrl+C` command or test completion, Zombienet automatically removes all associated pods."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 5, "depth": 3, "title": "Local Provider", "anchor": "local-provider", "start_char": 8957, "end_char": 10917, "estimated_token_count": 420, "token_estimator": "heuristic-v1", "text": "### Local Provider\n\nThe Zombienet local provider, also called native, enables you to run nodes as local processes in your environment.\n\n#### Requirements\n     \nYou must have the necessary binaries for your network (such as `polkadot` and `polkadot-parachain`). These binaries should be available in your PATH, allowing Zombienet to spawn the nodes as local processes.\n\nTo install the necessary binaries, you can use the Zombienet CLI command:\n\n```bash\nzombienet setup polkadot polkadot-parachain\n```\n\nThis command will download and prepare the necessary binaries for Zombienet's use.\n\nIf you need to use a custom binary, ensure the binary is available in your PATH. You can also specify the binary path in the network configuration file. The following example uses the custom [OpenZeppelin template](https://github.com/OpenZeppelin/polkadot-runtime-templates){target=\\_blank}:\n\nFirst, clone the OpenZeppelin template repository using the following command:\n\n```bash\ngit clone https://github.com/OpenZeppelin/polkadot-runtime-templates \\\n&& cd polkadot-runtime-templates/generic-template\n```\n\nNext, run the command to build the custom binary:\n\n```bash\ncargo build --release\n```\n\nFinally, add the custom binary to your PATH as follows:\n\n```bash\nexport PATH=$PATH:INSERT_PATH_TO_RUNTIME_TEMPLATES/parachain-template-node/target/release\n```\n\nAlternatively, you can specify the binary path in the network configuration file. The local provider exclusively utilizes the command configuration for nodes, which supports both relative and absolute paths. You can employ the `default_command` configuration to specify the binary for spawning all nodes in the relay chain.\n\n```toml\n[relaychain]\nchain = \"rococo-local\"\ndefault_command = \"./bin-v1.6.0/polkadot\"\n\n[parachain]\nid = 1000\n\n    [parachain.collators]\n    name = \"collator01\"\n    command = \"./target/release/parachain-template-node\"\n```\n\n#### Features\n\nThe local provider does not offer any additional features."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 6, "depth": 2, "title": "Configure Zombienet", "anchor": "configure-zombienet", "start_char": 10917, "end_char": 11529, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Configure Zombienet\n\nEffective network configuration is crucial for deploying and managing blockchain systems. Zombienet simplifies this process by offering versatile configuration options in both JSON and TOML formats. Whether setting up a simple test network or a complex multi-node system, Zombienet's tools provide the flexibility to customize every aspect of your network's setup.\n\nThe following sections will explore the structure and usage of Zombienet configuration files, explain key settings for network customization, and walk through CLI commands and flags to optimize your development workflow."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 7, "depth": 3, "title": "Configuration Files", "anchor": "configuration-files", "start_char": 11529, "end_char": 12007, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "### Configuration Files\n\nThe network configuration file can be either JSON or TOML format. The Zombienet repository also provides a collection of [example configuration files](https://github.com/paritytech/zombienet/tree/main/examples){target=\\_blank} that can be used as a reference.\n\nEach section may include provider-specific keys that aren't recognized by other providers. For example, if you use the local provider, any references to images for nodes will be disregarded."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 8, "depth": 3, "title": "CLI Usage", "anchor": "cli-usage", "start_char": 12007, "end_char": 13702, "estimated_token_count": 469, "token_estimator": "heuristic-v1", "text": "### CLI Usage\n\nZombienet provides a CLI that allows interaction with the tool. The CLI can receive commands and flags to perform different kinds of operations. These operations use the following syntax:\n\n```bash\nzombienet <arguments> <commands>\n```\n\nThe following sections will guide you through the primary usage of the Zombienet CLI and the available commands and flags.\n\n#### CLI Commands\n\n- **`spawn <networkConfig>`**: Spawn the network defined in the [configuration file](#configuration-files).\n- **`test <testFile>`**: Run tests on the spawned network using the assertions and tests defined in the test file.\n- **`setup <binaries>`**: Set up the Zombienet development environment to download and use the `polkadot` or `polkadot-parachain` executable.\n- **`convert <filePath>`**: Transforms a [polkadot-launch](https://github.com/paritytech/polkadot-launch){target=\\_blank} configuration file with a `.js` or `.json` extension into a Zombienet configuration file.\n- **`version`**: Prints Zombienet version.\n- **`help`**: Prints help information.\n\n#### CLI Flags\n\nYou can use the following flags to customize the behavior of the CLI:\n\n- **`-p`, `--provider`**: Override the [provider](#providers) to use.\n- **`-d`, `--dir`**: Specify a directory path for placing the network files instead of using the default temporary path.\n- **`-f`, `--force`**: Force override all prompt commands.\n- **`-l`, `--logType`**: Type of logging on the console. Defaults to `table`.\n- **`-m`, `--monitor`**: Start as monitor and don't auto clean up network.\n- **`-c`, `--spawn-concurrency`**: Number of concurrent spawning processes to launch. Defaults to `1`.\n- **`-h`, `--help`**: Display help for command."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 9, "depth": 3, "title": "Settings", "anchor": "settings", "start_char": 13702, "end_char": 16895, "estimated_token_count": 866, "token_estimator": "heuristic-v1", "text": "### Settings\n\nThrough the keyword `settings`, it's possible to define the general settings for the network. The available keys are:\n\n- **`global_volumes?`** ++\"GlobalVolume[]\"++: A list of global volumes to use.\n\n    ??? child \"`GlobalVolume` interface definition\"\n        ```js\n        export interface GlobalVolume {\n          name: string;\n          fs_type: string;\n          mount_path: string;\n        }\n        ```\n\n- **`bootnode`** ++\"boolean\"++: Add bootnode to network. Defaults to `true`.\n- **`bootnode_domain?`** ++\"string\"++: Domain to use for bootnode.\n- **`timeout`** ++\"number\"++: Global timeout to use for spawning the whole network.\n- **`node_spawn_timeout?`** ++\"number\"++: Timeout to spawn pod/process.\n- **`grafana?`** ++\"boolean\"++: Deploy an instance of Grafana.\n- **`prometheus?`** ++\"boolean\"++: Deploy an instance of Prometheus.\n- **`telemetry?`** ++\"boolean\"++: Enable telemetry for the network.\n- **`jaeger_agent?`** ++\"string\"++: The Jaeger agent endpoint passed to the nodes. Only available on Kubernetes.\n- **`tracing_collator_url?`** ++\"string\"++: The URL of the tracing collator used to query by the tracing assertion. Should be tempo query compatible.\n- **`tracing_collator_service_name?`** ++\"string\"++: Service name for tempo query frontend. Only available on Kubernetes. Defaults to `tempo-tempo-distributed-query-frontend`.\n- **`tracing_collator_service_namespace?`** ++\"string\"++: Namespace where tempo is running. Only available on Kubernetes. Defaults to `tempo`.\n- **`tracing_collator_service_port?`** ++\"number\"++: Port of the query instance of tempo. Only available on Kubernetes. Defaults to `3100`.\n- **`enable_tracing?`** ++\"boolean\"++: Enable the tracing system. Only available on Kubernetes. Defaults to `true`.\n- **`provider`** ++\"string\"++: Provider to use. Default is `kubernetes`\".\n- **`polkadot_introspector?`** ++\"boolean\"++: Deploy an instance of polkadot-introspector. Only available on Podman and Kubernetes. Defaults to `false`.\n- **`backchannel?`** ++\"boolean\"++: Deploy an instance of backchannel server. Only available on Kubernetes. Defaults to `false`.\n- **`image_pull_policy?`** ++\"string\"++: Image pull policy to use in the network. Possible values are `Always`, `IfNotPresent`, and `Never`.\n- **`local_ip?`** ++\"string\"++: IP used for exposing local services (rpc/metrics/monitors). Defaults to `\"127.0.0.1\"`.\n- **`global_delay_network_global_settings?`** ++\"number\"++: Delay in seconds to apply to the network.\n- **`node_verifier?`** ++\"string\"++: Specify how to verify node readiness or deactivate by using `None`. Possible values are `None` and `Metric`. Defaults to `Metric`.\n\nFor example, the following configuration file defines a minimal example for the settings:\n\n=== \"TOML\"\n\n    ```toml title=\"base-example.toml\"\n    [settings]\n    timeout = 1000\n    bootnode = false\n    provider = \"kubernetes\"\n    backchannel = false\n    # ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"base-example.json\"\n    {\n        \"settings\": {\n            \"timeout\": 1000,\n            \"bootnode\": false,\n            \"provider\": \"kubernetes\",\n            \"backchannel\": false,\n            \"...\": {}\n        },\n        \"...\": {}\n    }\n\n    ```"}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 10, "depth": 3, "title": "Relay Chain Configuration", "anchor": "relay-chain-configuration", "start_char": 16895, "end_char": 28449, "estimated_token_count": 2794, "token_estimator": "heuristic-v1", "text": "### Relay Chain Configuration\n\nYou can use the `relaychain` keyword to define further parameters for the relay chain at start-up. The available keys are:\n\n- **`default_command?`** ++\"string\"++: The default command to run. Defaults to `polkadot`.\n- **`default_image?`** ++\"string\"++: The default Docker image to use.\n- **`default_resources?`** ++\"Resources\"++: Represents the resource limits/reservations the nodes need by default. Only available on Kubernetes.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`default_db_snapshot?`** ++\"string\"++: The default database snapshot to use.\n- **`default_prometheus_prefix`** ++\"string\"++: A parameter for customizing the metric's prefix. Defaults to `substrate`.\n- **`default_substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`default_keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`chain`** ++\"string\"++: The chain name.\n- **`chain_spec_path?`** ++\"string\"++: Path to the chain spec file. Should be the plain version to allow customizations.\n- **`chain_spec_command?`** ++\"string\"++: Command to generate the chain spec. It can't be used in combination with `chain_spec_path`.\n- **`default_args?`** ++\"string[]\"++: An array of arguments to use as default to pass to the command.\n- **`default_overrides?`** ++\"Override[]\"++: An array of overrides to upload to the node.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        } \n        ```\n\n- **`random_nominators_count?`** ++\"number\"++: If set and the stacking pallet is enabled, Zombienet will generate the input quantity of nominators and inject them into the genesis.\n- **`max_nominations`** ++\"number\"++: The max number of nominations allowed by a nominator. Should match the value set in the runtime. Defaults to `24`.\n- **`nodes?`** ++\"Node[]\"++: An array of nodes to spawn. It is further defined in the [Node Configuration](#node-configuration) section.\n- **`node_groups?`** ++\"NodeGroup[]\"++: An array of node groups to spawn. It is further defined in the [Node Group Configuration](#node-group-configuration) section.\n- **`total_node_in_group?`** ++\"number\"++: The total number of nodes in the group. Defaults to `1`.\n- **`genesis`** ++\"JSON\"++: The genesis configuration.\n- **`default_delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\n#### Node Configuration\n\nOne specific key capable of receiving more subkeys is the `nodes` key. This key is used to define further parameters for the nodes. The available keys:\n\n- **`name`** ++\"string\"++: Name of the node. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Override default Docker image to use for this node.\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`command_with_args?`** ++\"string\"++: Override default command and arguments.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n\n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`validator`** ++\"boolean\"++: Pass the `--validator` flag to the command. Defaults to `true`.\n- **`invulnerable`** ++\"boolean\"++: If true, add the node to invulnerables in the chain spec. Defaults to `false`.\n- **`balance`** ++\"number\"++: Balance to set in balances for node's account. Defaults to `2000000000000`.\n- **`bootnodes?`** ++\"string[]\"++: Array of bootnodes to use.\n- **`add_to_bootnodes?`** ++\"boolean\"++: Add this node to the bootnode list. Defaults to `false`.\n- **`ws_port?`** ++\"number\"++: WS port to use.\n- **`rpc_port?`** ++\"number\"++: RPC port to use.\n- **`prometheus_port?`** ++\"number\"++: Prometheus port to use.\n- **`p2p_cert_hash?`** ++\"string\"++: Libp2p certhash to use with webRTC transport.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\nThe following configuration file defines a minimal example for the relay chain, including the `nodes` key:\n\n=== \"TOML\"\n\n    ```toml title=\"relaychain-example-nodes.toml\"\n    [relaychain]\n    default_command = \"polkadot\"\n    default_image = \"polkadot-debug:master\"\n    chain = \"rococo-local\"\n    chain_spec_path = \"INSERT_PATH_TO_CHAIN_SPEC\"\n    default_args = [\"--chain\", \"rococo-local\"]\n\n    [[relaychain.nodes]]\n    name = \"alice\"\n    validator = true\n    balance = 1000000000000\n\n    [[relaychain.nodes]]\n    name = \"bob\"\n    validator = true\n    balance = 1000000000000\n    # ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"relaychain-example-nodes.json\"\n    {\n        \"relaychain\": {\n            \"default_command\": \"polkadot\",\n            \"default_image\": \"polkadot-debug:master\",\n            \"chain\": \"rococo-local\",\n            \"chain_spec_path\": \"INSERT_PATH_TO_CHAIN-SPEC.JSON\",\n            \"default_args\": [\"--chain\", \"rococo-local\"],\n            \"nodes\": [\n                {\n                    \"name\": \"alice\",\n                    \"validator\": true,\n                    \"balance\": 1000000000000\n                },\n                {\n                    \"name\": \"bob\",\n                    \"validator\": true,\n                    \"balance\": 1000000000000\n                }\n            ]\n        }\n    }\n\n    ```\n\n#### Node Group Configuration\n\nThe `node_groups` key defines further parameters for the node groups. The available keys are:\n\n- **`name`** ++\"string\"++: Name of the node. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Override default Docker image to use for this node.\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n    \n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`overrides?`** ++\"Override[]\"++: Array of overrides definitions.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`count`** ++\"number | string\"++: Number of nodes to launch for this group.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\nThe following configuration file defines a minimal example for the relay chain, including the `node_groups` key:\n\n=== \"TOML\"\n\n    ```toml title=\"relaychain-example-node-groups.toml\"\n    [relaychain]\n    default_command = \"polkadot\"\n    default_image = \"polkadot-debug:master\"\n    chain = \"rococo-local\"\n    chain_spec_path = \"INSERT_PATH_TO_CHAIN_SPEC\"\n    default_args = [\"--chain\", \"rococo-local\"]\n\n    [[relaychain.node_groups]]\n    name = \"group-1\"\n    count = 2\n    image = \"polkadot-debug:master\"\n    command = \"polkadot\"\n    args = [\"--chain\", \"rococo-local\"]\n    # ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"relaychain-example-node-groups.json\"\n    {\n        \"relaychain\": {\n            \"default_command\": \"polkadot\",\n            \"default_image\": \"polkadot-debug:master\",\n            \"chain\": \"rococo-local\",\n            \"chain_spec_path\": \"INSERT_PATH_TO_CHAIN-SPEC.JSON\",\n            \"default_args\": [\"--chain\", \"rococo-local\"],\n            \"node_groups\": [\n                {\n                    \"name\": \"group-1\",\n                    \"count\": 2,\n                    \"image\": \"polkadot-debug:master\",\n                    \"command\": \"polkadot\",\n                    \"args\": [\"--chain\", \"rococo-local\"]\n                }\n            ],\n            \"...\": {}\n        },\n        \"...\": {}\n    }\n\n    ```"}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 11, "depth": 3, "title": "Parachain Configuration", "anchor": "parachain-configuration", "start_char": 28449, "end_char": 39622, "estimated_token_count": 2716, "token_estimator": "heuristic-v1", "text": "### Parachain Configuration\n\nThe `parachain` keyword defines further parameters for the parachain. The available keys are:\n\n- **`id`** ++\"number\"++: The id to assign to this parachain. Must be unique.\n- **`chain?`** ++\"string\"++: The chain name.\n- **`force_decorator?`** ++\"string\"++: Force the use of a specific decorator.\n- **`genesis?`** ++\"JSON\"++: The genesis configuration.\n- **`balance?`** ++\"number\"++: Balance to set in balances for parachain's account.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\n- **`add_to_genesis?`** ++\"boolean\"++: Flag to add parachain to genesis or register in runtime. Defaults to `true`.\n- **`register_para?`** ++\"boolean\"++: Flag to specify whether the para should be registered. The `add_to_genesis` flag must be set to false for this flag to have any effect. Defaults to `true`.\n- **`onboard_as_parachain?`** ++\"boolean\"++: Flag to specify whether the para should be onboarded as a parachain, rather than remaining a parathread. Defaults to `true`.\n- **`genesis_wasm_path?`** ++\"string\"++: Path to the Wasm file to use.\n- **`genesis_wasm_generator?`** ++\"string\"++: Command to generate the Wasm file.\n- **`genesis_state_path?`** ++\"string\"++: Path to the state file to use.\n- **`genesis_state_generator?`** ++\"string\"++: Command to generate the state file.\n- **`chain_spec_path?`** ++\"string\"++: Path to the chain spec file.\n- **`chain_spec_command?`** ++\"string\"++: Command to generate the chain spec.\n- **`cumulus_based?`** ++\"boolean\"++: Flag to use cumulus command generation. Defaults to `true`.\n- **`bootnodes?`** ++\"string[]\"++: Array of bootnodes to use.\n- **`prometheus_prefix?`** ++\"string\"++: Parameter for customizing the metric's prefix for all parachain nodes/collators. Defaults to `substrate`.\n- **`collator?`** ++\"Collator\"++: Further defined in the [Collator Configuration](#collator-configuration) section.\n- **`collator_groups?`** ++\"CollatorGroup[]\"++: An array of collator groups to spawn. It is further defined in the [Collator Groups Configuration](#collator-groups-configuration) section.\n \nFor example, the following configuration file defines a minimal example for the parachain:\n\n=== \"TOML\"\n\n    ```toml title=\"parachain-example.toml\"\n    [parachain]\n    id = 100\n    add_to_genesis = true\n    cumulus_based = true\n    genesis_wasm_path = \"INSERT_PATH_TO_WASM\"\n    genesis_state_path = \"INSERT_PATH_TO_STATE\"\n    # ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"parachain-example.json\"\n    {\n        \"parachain\": {\n            \"id\": 100,\n            \"add_to_genesis\": true,\n            \"cumulus_based\": true,\n            \"genesis_wasm_path\": \"INSERT_PATH_TO_WASM\",\n            \"genesis_state_path\": \"INSERT_PATH_TO_STATE\",\n            \"...\": {}\n        },\n        \"...\": {}\n    }\n\n    ```\n\n#### Collator Configuration\n\nOne specific key capable of receiving more subkeys is the `collator` key. This key defines further parameters for the nodes. The available keys are:\n\n- **`name`** ++\"string\"++: Name of the collator. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Image to use for the collator.\n- **`command_with_args?`** ++\"string\"++: Overrides both command and arguments for the collator.\n- **`validator`** ++\"boolean\"++: Pass the `--validator` flag to the command. Defaults to `true`.\n- **`invulnerable`** ++\"boolean\"++: If true, add the collator to invulnerables in the chain spec. Defaults to `false`.\n- **`balance`** ++\"number\"++: Balance to set in balances for collator's account. Defaults to `2000000000000`.\n- **`bootnodes?`** ++\"string[]\"++: Array of bootnodes to use.\n- **`add_to_bootnodes?`** ++\"boolean\"++: Add this collator to the bootnode list. Defaults to `false`.\n- **`ws_port?`** ++\"number\"++: WS port to use.\n- **`rpc_port?`** ++\"number\"++: RPC port to use.\n- **`prometheus_port?`** ++\"number\"++: Prometheus port to use.\n- **`p2p_port?`** ++\"number\"++: P2P port to use.\n- **`p2p_cert_hash?`** ++\"string\"++: Libp2p certhash to use with webRTC transport.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n\n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`overrides?`** ++\"Override[]\"++: Array of overrides definitions.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n\nThe configuration file below defines a minimal example for the collator:\n\n=== \"TOML\"\n\n    ```toml title=\"collator-example.toml\"\n    [parachain]\n    id = 100\n    add_to_genesis = true\n    cumulus_based = true\n    genesis_wasm_path = \"INSERT_PATH_TO_WASM\"\n    genesis_state_path = \"INSERT_PATH_TO_STATE\"\n\n    [[parachain.collators]]\n    name = \"alice\"\n    image = \"polkadot-parachain\"\n    command = \"polkadot-parachain\"\n    # ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"collator-example.json\"\n    {\n        \"parachain\": {\n            \"id\": 100,\n            \"add_to_genesis\": true,\n            \"cumulus_based\": true,\n            \"genesis_wasm_path\": \"INSERT_PATH_TO_WASM\",\n            \"genesis_state_path\": \"INSERT_PATH_TO_STATE\",\n            \"collators\": [\n                {\n                    \"name\": \"alice\",\n                    \"image\": \"polkadot-parachain\",\n                    \"command\": \"polkadot-parachain\",\n                    \"...\": {}\n                }\n            ]\n        },\n        \"...\": {}\n    }\n\n    ```\n\n#### Collator Groups Configuration\n\nThe `collator_groups` key defines further parameters for the collator groups. The available keys are:\n\n- **`name`** ++\"string\"++: Name of the node. Any whitespace will be replaced with a dash (for example, `new alice` will be converted to `new-alice`).\n- **`image?`** ++\"string\"++: Override default Docker image to use for this node.\n- **`command?`** ++\"string\"++: Override default command to run.\n- **`args?`** ++\"string[]\"++: Arguments to be passed to the command.\n- **`env?`** ++\"envVars[]\"++: Environment variables to set in the container.\n\n    ??? child \"`envVars` interface definition\"\n        ```js\n        export interface EnvVars {\n          name: string;\n          value: string;\n        }\n        ```\n\n- **`overrides?`** ++\"Override[]\"++: Array of overrides definitions.\n\n    ??? child \"`Override` interface definition\"\n        ```js\n        export interface Override {\n          local_path: string;\n          remote_name: string;\n        }\n        ```\n\n- **`prometheus_prefix?`** ++\"string\"++: Customizes the metric's prefix for the specific node. Defaults to `substrate`.\n- **`db_snapshot?`** ++\"string\"++: Database snapshot to use.\n- **`substrate_cli_args_version?`** ++\"SubstrateCliArgsVersion\"++: Set the Substrate CLI arguments version directly to skip binary evaluation overhead.\n\n    ??? child \"`SubstrateCliArgsVersion` enum definition\"\n        ```js\n        export enum SubstrateCliArgsVersion {\n          V0 = 0,\n          V1 = 1,\n          V2 = 2,\n          V3 = 3,\n        }\n        ```\n\n- **`resources?`** ++\"Resources\"++: Represent the resources limits/reservations needed by the node.\n\n    ??? child \"`Resources` interface definition\"\n        ```js\n        export interface Resources {\n          resources: {\n            requests?: {\n              memory?: string;\n              cpu?: string;\n            };\n            limits?: {\n              memory?: string;\n              cpu?: string;\n            };\n          };\n        }\n        ```\n\n- **`keystore_key_types?`** ++\"string[]\"++: Defines which keystore keys should be created.\n- **`count`** ++\"number | string\"++: Number of nodes to launch for this group.\n- **`delay_network_settings?`** ++\"DelayNetworkSettings\"++: Sets the expected configuration to delay the network.\n\n    ??? child \"`DelayNetworkSettings` interface definition\"\n        ```js\n        export interface DelayNetworkSettings {\n          latency: string;\n          correlation?: string; // should be parsable as float by k8s\n          jitter?: string;\n        }\n        ```\n\nFor instance, the configuration file below defines a minimal example for the collator groups:\n\n=== \"TOML\"\n\n    ```toml title=\"collator-groups-example.toml\"\n    [parachain]\n    id = 100\n    add_to_genesis = true\n    cumulus_based = true\n    genesis_wasm_path = \"INSERT_PATH_TO_WASM\"\n    genesis_state_path = \"INSERT_PATH_TO_STATE\"\n\n    [[parachain.collator_groups]]\n    name = \"group-1\"\n    count = 2\n    image = \"polkadot-parachain\"\n    command = \"polkadot-parachain\"\n    # ...\n\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"collator-groups-example.json\"\n    {\n        \"parachain\": {\n            \"id\": 100,\n            \"add_to_genesis\": true,\n            \"cumulus_based\": true,\n            \"genesis_wasm_path\": \"INSERT_PATH_TO_WASM\",\n            \"genesis_state_path\": \"INSERT_PATH_TO_STATE\",\n            \"collator_groups\": [\n                {\n                    \"name\": \"group-1\",\n                    \"count\": 2,\n                    \"image\": \"polkadot-parachain\",\n                    \"command\": \"polkadot-parachain\",\n                    \"...\": {}\n                }\n            ]\n        },\n        \"...\": {}\n    }\n\n    ```"}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 12, "depth": 3, "title": "XCM Configuration", "anchor": "xcm-configuration", "start_char": 39622, "end_char": 40553, "estimated_token_count": 206, "token_estimator": "heuristic-v1", "text": "### XCM Configuration\n\nYou can use the `hrmp_channels` keyword to define further parameters for the XCM channels at start-up. The available keys are:\n\n- **`hrmp_channels`** ++\"HrmpChannelsConfig[]\"++: Array of Horizontal Relay-routed Message Passing (HRMP) channel configurations.\n\n    ??? child \"`HrmpChannelsConfig` interface definition\"\n        ```js\n        export interface HrmpChannelsConfig {\n          sender: number;\n          recipient: number;\n          max_capacity: number;\n          max_message_size: number;\n        }\n        ```\n        Each of the `HrmpChannelsConfig` keys are defined as follows:\n\n        - **`sender` ++\"number\"++**: Parachain ID of the sender.\n        - **`recipient` ++\"number\"++**: Parachain ID of the recipient.\n        - **`max_capacity` ++\"number\"++**: Maximum capacity of the HRMP channel.\n        - **`max_message_size` ++\"number\"++**: Maximum message size allowed in the HRMP channel."}
{"page_id": "parachains-testing-run-a-parachain-network", "page_title": "Run a Parachain Network", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 40553, "end_char": 41209, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-  <span class=\"badge external\">External</span> __Zombienet Support__\n\n    ---\n\n    [Parity Technologies](https://www.parity.io/){target=\\_blank} has designed and developed this framework, now maintained by the Zombienet team. \n\n    For further support and information, refer to the following contact points:\n\n    [:octicons-arrow-right-24: Zombienet repository](https://github.com/paritytech/zombienet){target=\\_blank}\n\n    [:octicons-arrow-right-24: Element public channel](https://matrix.to/#/!FWyuEyNvIFygLnWNMh:parity.io?via=parity.io&via=matrix.org&via=web3.foundation){target=\\_blank}\n\n</div>"}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 0, "depth": 2, "title": "Authority", "anchor": "authority", "start_char": 416, "end_char": 897, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "## Authority\n\nThe role in a blockchain that can participate in consensus mechanisms. \n\n- **[GRANDPA](#grandpa)**: The authorities vote on chains they consider final.\n- **[Blind Assignment of Blockchain Extension](#blind-assignment-of-blockchain-extension-babe) (BABE)**: The authorities are also [block authors](#block-author).\n\nAuthority sets can be used as a basis for consensus mechanisms such as the [Nominated Proof of Stake (NPoS)](#nominated-proof-of-stake-npos) protocol."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 1, "depth": 2, "title": "Authority Round (Aura)", "anchor": "authority-round-aura", "start_char": 897, "end_char": 1416, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Authority Round (Aura)\n\nA deterministic [consensus](#consensus) protocol where block production is limited to a rotating list of [authorities](#authority) that take turns creating blocks. In authority round (Aura) consensus, most online authorities are assumed to be honest. It is often used in combination withÂ [GRANDPA](#grandpa)Â as aÂ [hybrid consensus](#hybrid-consensus)Â protocol.\n\nLearn more by reading the official [Aura consensus algorithm](https://openethereum.github.io/Aura){target=\\_blank} wiki article."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 2, "depth": 2, "title": "Blind Assignment of Blockchain Extension (BABE)", "anchor": "blind-assignment-of-blockchain-extension-babe", "start_char": 1416, "end_char": 1930, "estimated_token_count": 124, "token_estimator": "heuristic-v1", "text": "## Blind Assignment of Blockchain Extension (BABE)\n\nA [block authoring](#block-author) protocol similar to [Aura](#authority-round-aura), except [authorities](#authority) win [slots](#slot) based on a Verifiable Random Function (VRF) instead of the round-robin selection method. The winning authority can select a chain and submit a new block.\n\nLearn more by reading the official Web3 Foundation [BABE research document](https://research.web3.foundation/Polkadot/protocols/block-production/Babe){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 3, "depth": 2, "title": "Block Author", "anchor": "block-author", "start_char": 1930, "end_char": 2099, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Block Author\n\nThe node responsible for the creation of a block, also called _block producers_. In a Proof of Work (PoW) blockchain, these nodes are called _miners_."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 4, "depth": 2, "title": "Byzantine Fault Tolerance (BFT)", "anchor": "byzantine-fault-tolerance-bft", "start_char": 2099, "end_char": 2527, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Byzantine Fault Tolerance (BFT)\n\nThe ability of a distributed computer network to remain operational if a certain proportion of its nodes or [authorities](#authority) are defective or behaving maliciously. A distributed network is typically considered Byzantine fault tolerant if it can remain functional, with up to one-third of nodes assumed to be defective, offline, actively malicious, and part of a coordinated attack."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 5, "depth": 3, "title": "Byzantine Failure", "anchor": "byzantine-failure", "start_char": 2527, "end_char": 2667, "estimated_token_count": 26, "token_estimator": "heuristic-v1", "text": "### Byzantine Failure\n\nThe loss of a network service due to node failures that exceed the proportion of nodes required to reach consensus."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 6, "depth": 3, "title": "Practical Byzantine Fault Tolerance (pBFT)", "anchor": "practical-byzantine-fault-tolerance-pbft", "start_char": 2667, "end_char": 3007, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "### Practical Byzantine Fault Tolerance (pBFT)\n\nAn early approach to Byzantine fault tolerance (BFT), practical Byzantine fault tolerance (pBFT) systems tolerate Byzantine behavior from up to one-third of participants.\n\nThe communication overhead for such systems is `O(nÂ²)`, where `n` is the number of nodes (participants) in the system."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 7, "depth": 3, "title": "Preimage", "anchor": "preimage", "start_char": 3007, "end_char": 3284, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### Preimage\n\nA preimage is the data that is input into a hash function to calculate a hash. Since a hash function is a [one-way function](https://en.wikipedia.org/wiki/One-way_function){target=\\_blank}, the output, the hash, cannot be used to reveal the input, the preimage."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 8, "depth": 2, "title": "Call", "anchor": "call", "start_char": 3284, "end_char": 3561, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Call\n\nIn the context of pallets containing functions to be dispatched to the runtime, `Call` is an enumeration data type that describes the functions that can be dispatched with one variant per pallet. A `Call` represents a [dispatch](#dispatchable) data structure object."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 9, "depth": 2, "title": "Chain Specification", "anchor": "chain-specification", "start_char": 3561, "end_char": 4014, "estimated_token_count": 84, "token_estimator": "heuristic-v1", "text": "## Chain Specification \n\nA chain specification file defines the properties required to run a node in an active or new Polkadot SDK-built network. It often contains the initial genesis runtime code, network properties (such as the network's name), the initial state for some pallets, and the boot node list. The chain specification file makes it easy to use a single Polkadot SDK codebase as the foundation for multiple independently configured chains."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 10, "depth": 2, "title": "Collator", "anchor": "collator", "start_char": 4014, "end_char": 4353, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Collator\n\nAn [author](#block-author) of a [parachain](#parachain) network.\nThey aren't [authorities](#authority) in themselves, as they require a [relay chain](#relay-chain) to coordinate [consensus](#consensus).\n\nMore details are found on the [Polkadot Collator Wiki](https://wiki.polkadot.com/learn/learn-collator/){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 11, "depth": 2, "title": "Collective", "anchor": "collective", "start_char": 4353, "end_char": 4593, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Collective\n\nMost often used to refer to an instance of the Collective pallet on Polkadot SDK-based networks such as [Kusama](#kusama) or [Polkadot](#polkadot) if the Collective pallet is part of the FRAME-based runtime for the network."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 12, "depth": 2, "title": "Consensus", "anchor": "consensus", "start_char": 4593, "end_char": 4984, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Consensus\n\nConsensus is the process blockchain nodes use to agree on a chain's canonical fork. It is composed of [authorship](#block-author), finality, and [fork-choice rule](#fork-choice-rulestrategy). In the Polkadot ecosystem, these three components are usually separate and the term consensus often refers specifically to authorship.\n\nSee also [hybrid consensus](#hybrid-consensus)."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 13, "depth": 2, "title": "Consensus Algorithm", "anchor": "consensus-algorithm", "start_char": 4984, "end_char": 5546, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Consensus Algorithm\n\nEnsures a set of [actors](#authority)â€”who don't necessarily trust each otherâ€”can reach an agreement about the state as the result of some computation. Most consensus algorithms assume that up to one-third of the actors or nodes can be [Byzantine fault tolerant](#byzantine-fault-tolerance-bft).\n\nConsensus algorithms are generally concerned with ensuring two properties:\n\n- **Safety**: Indicating that all honest nodes eventually agreed on the state of the chain.\n- **Liveness**: Indicating the ability of the chain to keep progressing."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 14, "depth": 2, "title": "Consensus Engine", "anchor": "consensus-engine", "start_char": 5546, "end_char": 5885, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Consensus Engine\n\nThe node subsystem responsible for consensus tasks.\n\nFor detailed information about the consensus strategies of the [Polkadot](#polkadot) network, see the [Polkadot Consensus](/reference/polkadot-hub/consensus-and-security/pos-consensus/){target=\\_blank} blog series.\n\nSee also [hybrid consensus](#hybrid-consensus)."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 15, "depth": 2, "title": "Coretime", "anchor": "coretime", "start_char": 5885, "end_char": 6685, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Coretime\n\nThe time allocated for utilizing a core, measured in relay chain blocks. There are two types of coretime: *on-demand* and *bulk*.\n\nOn-demand coretime refers to coretime acquired through bidding in near real-time for the validation of a single parachain block on one of the cores reserved specifically for on-demand orders. They are available as an on-demand coretime pool. Set of cores that are available on-demand. Cores reserved through bulk coretime could also be made available in the on-demand coretime pool, in parts or in entirety.\n\nBulk coretime is a fixed duration of continuous coretime represented by an NFT that can be split, shared, or resold. It is managed by the [Broker pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_broker/index.html){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 16, "depth": 2, "title": "Development Phrase", "anchor": "development-phrase", "start_char": 6685, "end_char": 7343, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## Development Phrase\n\nA [mnemonic phrase](https://en.wikipedia.org/wiki/Mnemonic#For_numerical_sequences_and_mathematical_operations){target=\\_blank} that is intentionally made public.\n\nWell-known development accounts, such as Alice, Bob, Charlie, Dave, Eve, and Ferdie, are generated from the same secret phrase:\n\n```\nbottom drive obey lake curtain smoke basket hold race lonely fit walk\n```\n\nMany tools in the Polkadot SDK ecosystem, such as [`subkey`](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/substrate/bin/utils/subkey){target=\\_blank}, allow you to implicitly specify an account using a derivation path such as `//Alice`."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 17, "depth": 2, "title": "Digest", "anchor": "digest", "start_char": 7343, "end_char": 7655, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Digest\n\nAn extensible field of the [block header](#header) that encodes information needed by several actors in a blockchain network, including:\n\n- [Light clients](#light-client) for chain synchronization.\n- Consensus engines for block verification.\n- The runtime itself, in the case of pre-runtime digests."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 18, "depth": 2, "title": "Dispatchable", "anchor": "dispatchable", "start_char": 7655, "end_char": 7953, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "## Dispatchable\n\nFunction objects that act as the entry points in FRAME [pallets](#pallet). Internal or external entities can call them to interact with the blockchainâ€™s state. They are a core aspect of the runtime logic, handling [transactions](#transaction) and other state-changing operations."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 19, "depth": 2, "title": "Events", "anchor": "events", "start_char": 7953, "end_char": 8385, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "## Events\n\nA means of recording that some particular [state](#state) transition happened.\n\nIn the context of [FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities), events are composable data types that each [pallet](#pallet) can individually define. Events in FRAME are implemented as a set of transient storage items inspected immediately after a block has been executed and reset during block initialization."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 20, "depth": 2, "title": "Executor", "anchor": "executor", "start_char": 8385, "end_char": 9021, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## Executor\n\nA means of executing a function call in a given [runtime](#runtime) with a set of dependencies.\nThere are two orchestration engines in Polkadot SDK, _WebAssembly_ and _native_.\n\n- The _native executor_ uses a natively compiled runtime embedded in the node to execute calls. This is a performance optimization available to up-to-date nodes.\n\n- The _WebAssembly executor_ uses a [Wasm](#webassembly-wasm) binary and a Wasm interpreter to execute calls. The binary is guaranteed to be up-to-date regardless of the version of the blockchain node because it is persisted in the [state](#state) of the Polkadot SDK-based chain."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 21, "depth": 2, "title": "Existential Deposit", "anchor": "existential-deposit", "start_char": 9021, "end_char": 9761, "estimated_token_count": 179, "token_estimator": "heuristic-v1", "text": "## Existential Deposit\n\nThe minimum balance an account is allowed to have in the [Balances pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_balances/index.html){target=\\_blank}. Accounts cannot be created with a balance less than the existential deposit amount. \n\nIf an account balance drops below this amount, the Balances pallet uses [a FRAME System API](https://paritytech.github.io/substrate/master/frame_system/pallet/struct.Pallet.html#method.dec_ref){target=\\_blank} to drop its references to that account.\n\nIf the Balances pallet reference to an account is dropped, the account can be [reaped](https://paritytech.github.io/substrate/master/frame_system/pallet/struct.Pallet.html#method.allow_death){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 22, "depth": 2, "title": "Extrinsic", "anchor": "extrinsic", "start_char": 9761, "end_char": 10377, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Extrinsic\n\nA general term for data that originates outside the runtime, is included in a block, and leads to some action. This includes user-initiated transactions and inherent transactions placed into the block by the block builder.\n\nIt is a SCALE-encoded array typically consisting of a version number, signature, and varying data types indicating the resulting runtime function to be called. Extrinsics can take two forms: [inherents](#inherent-transactions) and [transactions](#transaction). \n\nFor more technical details, see the [Polkadot spec](https://spec.polkadot.network/id-extrinsics){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 23, "depth": 2, "title": "Fork Choice Rule/Strategy", "anchor": "fork-choice-rulestrategy", "start_char": 10377, "end_char": 10723, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Fork Choice Rule/Strategy\n\nA fork choice rule or strategy helps determine which chain is valid when reconciling several network forks. A common fork choice rule is the [longest chain](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/struct.LongestChain.html){target=\\_blank}, in which the chain with the most blocks is selected."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 24, "depth": 2, "title": "FRAME (Framework for Runtime Aggregation of Modularized Entities)", "anchor": "frame-framework-for-runtime-aggregation-of-modularized-entities", "start_char": 10723, "end_char": 11169, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## FRAME (Framework for Runtime Aggregation of Modularized Entities)\n\nEnables developers to create blockchain [runtime](#runtime) environments from a modular set of components called [pallets](#pallet). It utilizes a set of procedural macros to construct runtimes.\n\n[Visit the Polkadot SDK docs for more details on FRAME.](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank}"}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 25, "depth": 2, "title": "Full Node", "anchor": "full-node", "start_char": 11169, "end_char": 11448, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## Full Node\n\nA node that prunes historical states, keeping only recently finalized block states to reduce storage needs. Full nodes provide current chain state access and allow direct submission and validation of [extrinsics](#extrinsic), maintaining network decentralization."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 26, "depth": 2, "title": "Genesis Configuration", "anchor": "genesis-configuration", "start_char": 11448, "end_char": 11783, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## Genesis Configuration\n\nA mechanism for specifying the initial state of a blockchain. By convention, this initial state or first block is commonly referred to as the genesis state or genesis block. The genesis configuration for Polkadot SDK-based chains is accomplished by way of a [chain specification](#chain-specification) file."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 27, "depth": 2, "title": "GRANDPA", "anchor": "grandpa", "start_char": 11783, "end_char": 12135, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## GRANDPA\n\nA deterministic finality mechanism for blockchains that is implemented in the [Rust](https://rust-lang.org/){target=\\_blank} programming language.\n\nThe [formal specification](https://github.com/w3f/consensus/blob/master/pdf/grandpa-old.pdf){target=\\_blank} is maintained by the [Web3 Foundation](https://web3.foundation/){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 28, "depth": 2, "title": "Header", "anchor": "header", "start_char": 12135, "end_char": 12375, "estimated_token_count": 44, "token_estimator": "heuristic-v1", "text": "## Header\n\nA structure that aggregates the information used to summarize a block. Primarily, it consists of cryptographic information used by [light clients](#light-client) to get minimally secure but very efficient chain synchronization."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 29, "depth": 2, "title": "Hybrid Consensus", "anchor": "hybrid-consensus", "start_char": 12375, "end_char": 12789, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Hybrid Consensus\n\nA blockchain consensus protocol that consists of independent or loosely coupled mechanisms for [block production](#block-author) and finality.\n\nHybrid consensus allows the chain to grow as fast as probabilistic consensus protocols, such as [Aura](#authority-round-aura), while maintaining the same level of security as deterministic finality consensus protocols, such as [GRANDPA](#grandpa)."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 30, "depth": 2, "title": "Inherent Transactions", "anchor": "inherent-transactions", "start_char": 12789, "end_char": 13255, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Inherent Transactions\n\nA special type of unsigned transaction, referred to as _inherents_, that enables a block authoring node to insert information that doesn't require validation directly into a block.\n\nOnly the block-authoring node that calls the inherent transaction function can insert data into its block. In general, validators assume the data inserted using an inherent transaction is valid and reasonable even if it can't be deterministically verified."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 31, "depth": 2, "title": "JSON-RPC", "anchor": "json-rpc", "start_char": 13255, "end_char": 13596, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## JSON-RPC\n\nA stateless, lightweight remote procedure call protocol encoded in JavaScript Object Notation (JSON). JSON-RPC provides a standard way to call functions on a remote system by using JSON.\n\nFor Polkadot SDK, this protocol is implemented through the [Parity JSON-RPC](https://github.com/paritytech/jsonrpc){target=\\_blank} crate."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 32, "depth": 2, "title": "Keystore", "anchor": "keystore", "start_char": 13596, "end_char": 13681, "estimated_token_count": 16, "token_estimator": "heuristic-v1", "text": "## Keystore\n\nA subsystem for managing keys for the purpose of producing new blocks."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 33, "depth": 2, "title": "Kusama", "anchor": "kusama", "start_char": 13681, "end_char": 14375, "estimated_token_count": 174, "token_estimator": "heuristic-v1", "text": "## Kusama\n\n[Kusama](https://kusama.network/){target=\\_blank} is a Polkadot SDK-based blockchain that implements a design similar to the [Polkadot](#polkadot) network.\n\nKusama is a [canary](https://en.wiktionary.org/wiki/canary_in_a_coal_mine){target=\\_blank} network and is referred to as [Polkadot's \"wild cousin.\"](https://wiki.polkadot.com/learn/learn-comparisons-kusama/){target=\\_blank}.\n\nAs a canary network, Kusama is expected to be more stable than a test network like [Westend](#westend) but less stable than a production network like [Polkadot](#polkadot). Kusama is controlled by its network participants and is intended to be stable enough to encourage meaningful experimentation."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 34, "depth": 2, "title": "libp2p", "anchor": "libp2p", "start_char": 14375, "end_char": 14651, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "## libp2p\n\nA peer-to-peer networking stack that allows the use of many transport mechanisms, including WebSockets (usable in a web browser).\n\nPolkadot SDK uses the [Rust implementation](https://github.com/libp2p/rust-libp2p){target=\\_blank} of the `libp2p` networking stack."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 35, "depth": 2, "title": "Light Client", "anchor": "light-client", "start_char": 14651, "end_char": 14989, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Light Client\n\nA type of blockchain node that doesn't store the [chain state](#state) or produce blocks.\n\nA light client can verify cryptographic primitives and provides a [remote procedure call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call){target=\\_blank} server, enabling blockchain users to interact with the network."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 36, "depth": 2, "title": "Metadata", "anchor": "metadata", "start_char": 14989, "end_char": 15185, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Metadata\n\nData that provides information about one or more aspects of a system.\nThe metadata that exposes information about a Polkadot SDK blockchain enables you to interact with that system."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 37, "depth": 2, "title": "Nominated Proof of Stake (NPoS)", "anchor": "nominated-proof-of-stake-npos", "start_char": 15185, "end_char": 15412, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Nominated Proof of Stake (NPoS)\n\nA method for determining [validators](#validator) or _[authorities](#authority)_ based on a willingness to commit their stake to the proper functioning of one or more block-producing nodes."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 38, "depth": 2, "title": "Oracle", "anchor": "oracle", "start_char": 15412, "end_char": 15649, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "## Oracle\n\nAn entity that connects a blockchain to a non-blockchain data source. Oracles enable the blockchain to access and act upon information from existing data sources and incorporate data from non-blockchain systems and services."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 39, "depth": 2, "title": "Origin", "anchor": "origin", "start_char": 15649, "end_char": 16139, "estimated_token_count": 126, "token_estimator": "heuristic-v1", "text": "## Origin\n\nA [FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities) primitive that identifies the source of a [dispatched](#dispatchable) function call into the [runtime](#runtime). The FRAME System pallet defines three built-in [origins](#origin). As a [pallet](#pallet) developer, you can also define custom origins, such as those defined by the [Collective pallet](https://paritytech.github.io/substrate/master/pallet_collective/enum.RawOrigin.html){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 40, "depth": 2, "title": "Pallet", "anchor": "pallet", "start_char": 16139, "end_char": 16430, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Pallet\n\nA module that can be used to extend the capabilities of a [FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities)-based [runtime](#runtime).\nPallets bundle domain-specific logic with runtime primitives like [events](#events) and [storage items](#storage-item)."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 41, "depth": 2, "title": "Parachain", "anchor": "parachain", "start_char": 16430, "end_char": 16686, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Parachain\n\nA parachain is a blockchain that derives shared infrastructure and security from a _[relay chain](#relay-chain)_.\nYou can learn more about parachains on the [Polkadot Wiki](https://wiki.polkadot.com/learn/learn-parachains/){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 42, "depth": 2, "title": "Paseo", "anchor": "paseo", "start_char": 16686, "end_char": 17140, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "## Paseo\n\nPaseo TestNet provisions testing on Polkadot's \"production\" runtime, which means less chance of feature or code mismatch when developing parachain apps. Specifically, after the [Polkadot Technical fellowship](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank} proposes a runtime upgrade for Polkadot, this TestNet is updated, giving a period where the TestNet will be ahead of Polkadot to allow for testing."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 43, "depth": 2, "title": "Polkadot", "anchor": "polkadot", "start_char": 17140, "end_char": 17441, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Polkadot\n\nThe [Polkadot network](https://polkadot.com/){target=\\_blank} is a blockchain that serves as the central hub of a heterogeneous blockchain network. It serves the role of the [relay chain](#relay-chain) and provides shared infrastructure and security to support [parachains](#parachain)."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 44, "depth": 2, "title": "Polkadot Cloud", "anchor": "polkadot-cloud", "start_char": 17441, "end_char": 18079, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Polkadot Cloud\n\nPolkadot Cloud is a platform for deploying resilient, customizable and scalable Web3 applications through Polkadot's functionality. It encompasses the wider Polkadot network infrastructure and security layer where parachains operate. The platform enables users to launch Ethereum-compatible chains, build specialized blockchains, and flexibly manage computing resources through on-demand or bulk coretime purchases. Initially launched with basic parachain functionality, Polkadot Cloud has evolved to offer enhanced flexibility with features like coretime, elastic scaling, and async backing for improved performance."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 45, "depth": 2, "title": "Polkadot Hub", "anchor": "polkadot-hub", "start_char": 18079, "end_char": 18487, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Polkadot Hub\n\nPolkadot Hub is a Layer 1 platform that serves as the primary entry point to the Polkadot ecosystem, providing essential functionality without requiring parachain deployment. It offers core services including smart contracts, identity management, staking, governance, and interoperability with other ecosystems, making it simple and fast for both builders and users to get started in Web3."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 46, "depth": 2, "title": "PolkaVM", "anchor": "polkavm", "start_char": 18487, "end_char": 18770, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## PolkaVM\n\nPolkaVM is a custom virtual machine optimized for performance, leveraging a RISC-V-based architecture to support Solidity and any language that compiles to RISC-V. It is specifically designed for the Polkadot ecosystem, enabling smart contract deployment and execution."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 47, "depth": 2, "title": "Relay Chain", "anchor": "relay-chain", "start_char": 18770, "end_char": 19086, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Relay Chain\n\nRelay chains are blockchains that provide shared infrastructure and security to the [parachains](#parachain) in the network. In addition to providing [consensus](#consensus) capabilities, relay chains allow parachains to communicate and exchange digital assets without needing to trust one another."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 48, "depth": 2, "title": "Rococo", "anchor": "rococo", "start_char": 19086, "end_char": 19338, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Rococo\n\nA [parachain](#parachain) test network for the Polkadot network. The [Rococo](#rococo) network is a Polkadot SDK-based blockchain with an October 14, 2024 deprecation date. Development teams are encouraged to use the Paseo TestNet instead."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 49, "depth": 2, "title": "Runtime", "anchor": "runtime", "start_char": 19338, "end_char": 19675, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Runtime\n\nThe runtime represents the [state transition function](#state-transition-function-stf) for a blockchain. In Polkadot SDK, the runtime is stored as a [Wasm](#webassembly-wasm) binary in the chain state. The Runtime is stored under a unique state key and can be modified during the execution of the state transition function."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 50, "depth": 2, "title": "Slot", "anchor": "slot", "start_char": 19675, "end_char": 19955, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Slot\n\nA fixed, equal interval of time used by consensus engines such as [Aura](#authority-round-aura) and [BABE](#blind-assignment-of-blockchain-extension-babe). In each slot, a subset of [authorities](#authority) is permitted, or obliged, to [author](#block-author) a block."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 51, "depth": 2, "title": "Sovereign Account", "anchor": "sovereign-account", "start_char": 19955, "end_char": 20457, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Sovereign Account\n\nThe unique account identifier for each chain in the relay chain ecosystem. It is often used in cross-consensus (XCM) interactions to sign XCM messages sent to the relay chain or other chains in the ecosystem.\n\nThe sovereign account for each chain is a root-level account that can only be accessed using the Sudo pallet or through governance. The account identifier is calculated by concatenating the Blake2 hash of a specific text string and the registered parachain identifier."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 52, "depth": 2, "title": "SS58 Address Format", "anchor": "ss58-address-format", "start_char": 20457, "end_char": 21010, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## SS58 Address Format\n\nA public key address based on the Bitcoin [`Base-58-check`](https://en.bitcoin.it/wiki/Base58Check_encoding){target=\\_blank} encoding. Each Polkadot SDK SS58 address uses a `base-58` encoded value to identify a specific account on a specific Polkadot SDK-based chain\n\nThe [canonical `ss58-registry`](https://github.com/paritytech/ss58-registry){target=\\_blank} provides additional details about the address format used by different Polkadot SDK-based chains, including the network prefix and website used for different networks"}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 53, "depth": 2, "title": "State Transition Function (STF)", "anchor": "state-transition-function-stf", "start_char": 21010, "end_char": 21239, "estimated_token_count": 46, "token_estimator": "heuristic-v1", "text": "## State Transition Function (STF)\n\nThe logic of a blockchain that determines how the state changes when a block is processed. In Polkadot SDK, the state transition function is effectively equivalent to the [runtime](#runtime)."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 54, "depth": 2, "title": "Storage Item", "anchor": "storage-item", "start_char": 21239, "end_char": 21602, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Storage Item\n\n[FRAME](#frame-framework-for-runtime-aggregation-of-modularized-entities) primitives that provide type-safe data persistence capabilities to the [runtime](#runtime).\nLearn more in the [storage items](https://paritytech.github.io/polkadot-sdk/master/frame_support/storage/types/index.html){target=\\_blank} reference document in the Polkadot SDK."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 55, "depth": 2, "title": "Substrate", "anchor": "substrate", "start_char": 21602, "end_char": 21880, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Substrate\n\nA flexible framework for building modular, efficient, and upgradeable blockchains. Substrate is written in the [Rust](https://rust-lang.org/){target=\\_blank} programming language and is maintained by [Parity Technologies](https://www.parity.io/){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 56, "depth": 2, "title": "Transaction", "anchor": "transaction", "start_char": 21880, "end_char": 22171, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Transaction\n\nAn [extrinsic](#extrinsic) that includes a signature that can be used to verify the account authorizing it inherently or via [signed extensions](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/signed_extensions/index.html){target=\\_blank}."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 57, "depth": 2, "title": "Transaction Era", "anchor": "transaction-era", "start_char": 22171, "end_char": 22450, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Transaction Era\n\nA definable period expressed as a range of block numbers during which a transaction can be included in a block.\nTransaction eras are used to protect against transaction replay attacks if an account is reaped and its replay-protecting nonce is reset to zero."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 58, "depth": 2, "title": "Trie (Patricia Merkle Tree)", "anchor": "trie-patricia-merkle-tree", "start_char": 22450, "end_char": 23196, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Trie (Patricia Merkle Tree)\n\nA data structure used to represent sets of key-value pairs and enables the items in the data set to be stored and retrieved using a cryptographic hash. Because incremental changes to the data set result in a new hash, retrieving data is efficient even if the data set is very large. With this data structure, you can also prove whether the data set includes any particular key-value pair without access to the entire data set.\n\nIn Polkadot SDK-based blockchains, state is stored in a trie data structure that supports the efficient creation of incremental digests. This trie is exposed to the [runtime](#runtime) as [a simple key/value map](#storage-item) where both keys and values can be arbitrary byte arrays."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 59, "depth": 2, "title": "Validator", "anchor": "validator", "start_char": 23196, "end_char": 23399, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "## Validator\n\nA validator is a node that participates in the consensus mechanism of the network. Its roles include block production, transaction validation, network integrity, and security maintenance."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 60, "depth": 2, "title": "WebAssembly (Wasm)", "anchor": "webassembly-wasm", "start_char": 23399, "end_char": 23858, "estimated_token_count": 111, "token_estimator": "heuristic-v1", "text": "## WebAssembly (Wasm)\n\nAn execution architecture that allows for the efficient, platform-neutral expression of\ndeterministic, machine-executable logic.\n\n[Wasm](https://webassembly.org/){target=\\_blank} can be compiled from many languages, including\nthe [Rust](https://rust-lang.org/){target=\\_blank} programming language. Polkadot SDK-based chains use a Wasm binary to provide portable [runtimes](#runtime) that can be included as part of the chain's state."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 61, "depth": 2, "title": "Weight", "anchor": "weight", "start_char": 23858, "end_char": 24584, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## Weight\n\nA convention used in Polkadot SDK-based blockchains to measure and manage the time it takes to validate a block.\nPolkadot SDK defines one unit of weight as one picosecond of execution time on reference hardware.\n\nThe maximum block weight should be equivalent to one-third of the target block time with an allocation of one-third each for:\n\n- Block construction\n- Network propagation\n- Import and verification\n\nBy defining weights, you can trade-off the number of transactions per second and the hardware required to maintain the target block time appropriate for your use case. Weights are defined in the runtime, meaning you can tune them using runtime updates to keep up with hardware and software improvements."}
{"page_id": "reference-glossary", "page_title": "Glossary", "index": 62, "depth": 2, "title": "Westend", "anchor": "westend", "start_char": 24584, "end_char": 24727, "estimated_token_count": 32, "token_estimator": "heuristic-v1", "text": "## Westend\n\nWestend is a Parity-maintained, Polkadot SDK-based blockchain that serves as a test network for the [Polkadot](#polkadot) network."}
{"page_id": "reference-governance-origins-tracks", "page_title": "Origins and Tracks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 833, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's OpenGov system empowers decentralized decision-making and active community participation by tailoring the governance process to the impact of proposed changes. Through a system of origins and tracks, OpenGov ensures that every referendum receives the appropriate scrutiny, balancing security, inclusivity, and efficiency.\n\nThis guide will help you understand the role of origins in classifying proposals by privilege and priority. You will learn how tracks guide proposals through tailored stages like voting, confirmation, and enactment and how to select the correct origin for your referendum to align with community expectations and network governance.\n\nOrigins and tracks are vital in streamlining the governance workflow and maintaining Polkadot's resilience and adaptability."}
{"page_id": "reference-governance-origins-tracks", "page_title": "Origins and Tracks", "index": 1, "depth": 2, "title": "Origins", "anchor": "origins", "start_char": 833, "end_char": 1886, "estimated_token_count": 200, "token_estimator": "heuristic-v1", "text": "## Origins\n\nOrigins are the foundation of Polkadot's OpenGov governance system. They categorize proposals by privilege and define their decision-making rules. Each origin corresponds to a specific level of importance and risk, guiding how referendums progress through the governance process.\n\n- High-privilege origins like Root Origin govern critical network changes, such as core software upgrades.\n- Lower-privilege origins like Small Spender handle minor requests, such as community project funding under 10,000 DOT.\n\nProposers select an origin based on the nature of their referendum. Origins determine parameters like approval thresholds, required deposits, and timeframes for voting and confirmation. Each origin is paired with a track, which acts as a roadmap for the proposal's lifecycle, including preparation, voting, and enactment.\n\nFor a detailed list of origins and their associated parameters, see the [Polkadot OpenGov Origins](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/){target=\\_blank} entry in the Polkadot Wiki."}
{"page_id": "reference-governance-origins-tracks", "page_title": "Origins and Tracks", "index": 2, "depth": 2, "title": "Tracks", "anchor": "tracks", "start_char": 1886, "end_char": 2836, "estimated_token_count": 175, "token_estimator": "heuristic-v1", "text": "## Tracks\n\nTracks define a referendum's journey from submission to enactment, tailoring governance parameters to the impact of proposed changes. Each track operates independently and includes several key stages:\n\n- **Preparation**: Time for community discussion before voting begins.\n- **Voting**: Period for token holders to cast their votes.\n- **Decision**: Finalization of results and determination of the proposal's outcome.\n- **Confirmation**: Period to verify sustained community support before enactment.\n- **Enactment**: Final waiting period before the proposal takes effect.\n\nTracks customize these stages with parameters like decision deposit requirements, voting durations, and approval thresholds, ensuring proposals from each origin receive the required scrutiny and process. For example, a runtime upgrade in the Root Origin track will have longer timeframes and stricter thresholds than a treasury request in the Small Spender track."}
{"page_id": "reference-governance-origins-tracks", "page_title": "Origins and Tracks", "index": 3, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 2836, "end_char": 3333, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- For a list of origins and tracks for Polkadot and Kusama, including associated parameters, see the [Origins and Tracks Info](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#origins-and-tracks-info){target=\\_blank} entry in the Polkadot Wiki.\n\n- For a deeper dive into the approval and support system, see the [Approval and Support](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#approval-and-support){target=\\_blank} entry of the Polkadot Wiki."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 852, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadotâ€™s governance system exemplifies decentralized decision-making, empowering its community of stakeholders to shape the networkâ€™s future through active participation. The latest evolution, OpenGov, builds on Polkadotâ€™s foundation by providing a more inclusive and efficient governance model.\n\nThis guide will explain the principles and structure of OpenGov and walk you through its key components, such as Origins, Tracks, and Delegation. You will learn about improvements over earlier governance systems, including streamlined voting processes and enhanced stakeholder participation.\n\nWith OpenGov, Polkadot achieves a flexible, scalable, and democratic governance framework that allows multiple proposals to proceed simultaneously, ensuring the network evolves in alignment with its community's needs."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 1, "depth": 2, "title": "Governance Evolution", "anchor": "governance-evolution", "start_char": 852, "end_char": 1816, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Governance Evolution\n\nPolkadotâ€™s governance journey began with [Governance V1](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#governance-summary){target=\\_blank}, a system that proved effective in managing treasury funds and protocol upgrades. However, it faced limitations, such as:\n\n- Slow voting cycles, causing delays in decision-making.\n- Inflexibility in handling multiple referendums, restricting scalability.\n\nTo address these challenges, Polkadot introduced OpenGov, a governance model designed for greater inclusivity, efficiency, and scalability. OpenGov replaces the centralized structures of Governance V1, such as the Council and Technical Committee, with a fully decentralized and dynamic framework.\n\nFor a full comparison of the historic and current governance models, visit the [Gov1 vs. Polkadot OpenGov](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#gov1-vs-polkadot-opengov){target=\\_blank} section of the Polkadot Wiki."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 2, "depth": 2, "title": "OpenGov Key Features", "anchor": "opengov-key-features", "start_char": 1816, "end_char": 2574, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "## OpenGov Key Features\n\nOpenGov transforms Polkadotâ€™s governance into a decentralized, stakeholder-driven model, eliminating centralized decision-making bodies like the Council. Key enhancements include:\n\n- **Decentralization**: Shifts all decision-making power to the public, ensuring a more democratic process.\n- **Enhanced delegation**: Allows users to delegate their votes to trusted experts across specific governance tracks.\n- **Simultaneous referendums**: Multiple proposals can progress at once, enabling faster decision-making.\n- **Polkadot Technical Fellowship**: A broad, community-driven group replacing the centralized Technical Committee.\n\nThis new system ensures Polkadot governance remains agile and inclusive, even as the ecosystem grows."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 3, "depth": 2, "title": "Origins and Tracks", "anchor": "origins-and-tracks", "start_char": 2574, "end_char": 3654, "estimated_token_count": 248, "token_estimator": "heuristic-v1", "text": "## Origins and Tracks\n\nIn OpenGov, origins and tracks are central to managing proposals and votes.\n\n- **Origin**: Determines the authority level of a proposal (e.g., Treasury, Root) which decides the track of all referendums from that origin.\n- **Track**: Define the procedural flow of a proposal, such as voting duration, approval thresholds, and enactment timelines.\n\nDevelopers must be aware that referendums from different origins and tracks will take varying amounts of time to reach approval and enactment. The [Polkadot Technical Fellowship](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank} has the option to shorten this timeline by whitelisting a proposal and allowing it to be enacted through the [Whitelist Caller](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#whitelisted-caller){target=\\_blank} origin.\n\nVisit [Origins and Tracks Info](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#origins-and-tracks){target=\\_blank} for details on current origins and tracks, associated terminology, and parameters."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 4, "depth": 2, "title": "Referendums", "anchor": "referendums", "start_char": 3654, "end_char": 4505, "estimated_token_count": 178, "token_estimator": "heuristic-v1", "text": "## Referendums\n\nIn OpenGov, anyone can submit a referendum, fostering an open and participatory system. The timeline for a referendum depends on the privilege level of the origin with more significant changes offering more time for community voting and participation before enactment. \n\nThe timeline for an individual referendum includes four distinct periods:\n\n- **Lead-in**: A minimum amount of time to allow for community participation, available room in the origin, and payment of the decision deposit. Voting is open during this period.\n- **Decision**: Voting continues.\n- **Confirmation**: Referendum must meet [approval and support](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#approval-and-support){target=\\_blank} criteria during entire period to avoid rejection.\n- **Enactment**: Changes approved by the referendum are executed."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 5, "depth": 3, "title": "Vote on Referendums", "anchor": "vote-on-referendums", "start_char": 4505, "end_char": 5146, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### Vote on Referendums\n\nVoters can vote with their tokens on each referendum. Polkadot uses a voluntary token locking mechanism, called conviction voting, as a way for voters to increase their voting power. A token holder signals they have a stronger preference for approving a proposal based upon their willingness to lock up tokens. Longer voluntary token locks are seen as a signal of continual approval and translate to increased voting weight.\n\nSee [Voting on a Referendum](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#voting-on-a-referendum){target=\\_blank} for a deeper look at conviction voting and related token locks."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 6, "depth": 3, "title": "Delegate Voting Power", "anchor": "delegate-voting-power", "start_char": 5146, "end_char": 5929, "estimated_token_count": 168, "token_estimator": "heuristic-v1", "text": "### Delegate Voting Power\n\nThe OpenGov system also supports multi-role delegations, allowing token holders to assign their voting power on different tracks to entities with expertise in those areas. \n\nFor example, if a token holder lacks the technical knowledge to evaluate proposals on the [Root track](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#root){target=\\_blank}, they can delegate their voting power for that track to an expert they trust to vote in the best interest of the network. This ensures informed decision-making across tracks while maintaining flexibility for token holders.\n\nVisit [Multirole Delegation](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#multirole-delegation){target=\\_blank} for more details on delegating voting power."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 7, "depth": 3, "title": "Cancel a Referendum", "anchor": "cancel-a-referendum", "start_char": 5929, "end_char": 6702, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "### Cancel a Referendum\n\nPolkadot OpenGov has two origins for rejecting ongoing referendums: \n\n- [**Referendum Canceller**](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#referendum-canceller){target=\\_blank}: Cancels an active referendum when non-malicious errors occur and refunds the deposits to the originators.\n- [**Referendum Killer**](https://wiki.polkadot.com/learn/learn-polkadot-opengov-origins/#referendum-killer){target=\\_blank}: Used for urgent, malicious cases this origin instantly terminates an active referendum and slashes deposits.\n\nSee [Cancelling, Killing, and Blacklisting](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#cancelling-killing--blacklisting){target=\\_blank} for additional information on rejecting referendums."}
{"page_id": "reference-governance", "page_title": "On-Chain Governance Overview", "index": 8, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 6702, "end_char": 7493, "estimated_token_count": 230, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\n- **[Democracy pallet](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/substrate/frame/democracy/src){target=\\_blank}**: Handles administration of general stakeholder voting.\n- **[Gov2: Polkadotâ€™s Next Generation of Decentralised Governance](https://medium.com/polkadot-network/gov2-polkadots-next-generation-of-decentralised-governance-4d9ef657d11b){target=\\_blank}**: Medium article by Gavin Wood.\n- **[Polkadot Direction](https://matrix.to/#/#Polkadot-Direction:parity.io){target=\\_blank}**: Matrix Element client.\n- **[Polkassembly](https://polkadot.polkassembly.io/){target=\\_blank}**: OpenGov dashboard and UI.\n- **[Polkadot.js Apps Governance](https://polkadot.js.org/apps/#/referenda){target=\\_blank}**: Overview of active referendums."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 597, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAccounts are essential for managing identity, transactions, and governance on the network in the Polkadot SDK. Understanding these components is critical for seamless development and operation on the network, whether you're building or interacting with Polkadot-based chains.\n\nThis page will guide you through the essential aspects of accounts, including their data structure, balance types, reference counters, and address formats. Youâ€™ll learn how accounts are managed within the runtime, how balances are categorized, and how addresses are encoded and validated."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 1, "depth": 2, "title": "Account Data Structure", "anchor": "account-data-structure", "start_char": 597, "end_char": 862, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "## Account Data Structure\n\nAccounts are foundational to any blockchain, and the Polkadot SDK provides a flexible management system. This section explains how the Polkadot SDK defines accounts and manages their lifecycle through data structures within the runtime."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 2, "depth": 3, "title": "Account", "anchor": "account", "start_char": 862, "end_char": 3162, "estimated_token_count": 569, "token_estimator": "heuristic-v1", "text": "### Account\n\nThe [`Account` data type](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/type.Account.html){target=\\_blank} is a storage map within the [System pallet](https://paritytech.github.io/polkadot-sdk/master/src/frame_system/lib.rs.html){target=\\_blank} that links an account ID to its corresponding data. This structure is fundamental for mapping account-related information within the chain.\n\nThe code snippet below shows how accounts are defined:\n\n```rs\n /// The full account information for a particular account ID.\n \t#[pallet::storage]\n \t#[pallet::getter(fn account)]\n \tpub type Account<T: Config> = StorageMap<\n \t\t_,\n \t\tBlake2_128Concat,\n \t\tT::AccountId,\n \t\tAccountInfo<T::Nonce, T::AccountData>,\n \t\tValueQuery,\n \t>;\n```\n\nThe preceding code block defines a storage map named `Account`. The `StorageMap` is a type of on-chain storage that maps keys to values. In the `Account` map, the key is an account ID, and the value is the account's information. Here, `T` represents the generic parameter for the runtime configuration, which is defined by the pallet's configuration trait (`Config`).\n\nThe `StorageMap` consists of the following parameters:\n\n- **`_`**: Used in macro expansion and acts as a placeholder for the storage prefix type. Tells the macro to insert the default prefix during expansion.\n- **`Blake2_128Concat`**: The hashing function applied to keys in the storage map.\n- **`T: :AccountId`**: Represents the key type, which corresponds to the accountâ€™s unique ID.\n- **`AccountInfo<T: :Nonce, T::AccountData>`**: The value type stored in the map. For each account ID, the map stores an `AccountInfo` struct containing:\n\n    - **`T::Nonce`**: A nonce for the account, which is incremented with each transaction to ensure transaction uniqueness.\n    - **`T: :AccountData`**: Custom account data defined by the runtime configuration, which could include balances, locked funds, or other relevant information.\n    \n- **`ValueQuery`**: Defines how queries to the storage map behave when no value is found; returns a default value instead of `None`.\n\nFor a detailed explanation of storage maps, see the [`StorageMap`](https://paritytech.github.io/polkadot-sdk/master/frame_support/storage/types/struct.StorageMap.html){target=\\_blank} entry in the Rust docs."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 3, "depth": 3, "title": "Account Info", "anchor": "account-info", "start_char": 3162, "end_char": 5825, "estimated_token_count": 617, "token_estimator": "heuristic-v1", "text": "### Account Info\n\nThe `AccountInfo` structure is another key element within the [System pallet](https://paritytech.github.io/polkadot-sdk/master/src/frame_system/lib.rs.html){target=\\_blank}, providing more granular details about each account's state. This structure tracks vital data, such as the number of transactions and the accountâ€™s relationships with other modules.\n\n```rs\n/// Information of an account.\n#[derive(Clone, Eq, PartialEq, Default, RuntimeDebug, Encode, Decode, TypeInfo, MaxEncodedLen)]\npub struct AccountInfo<Nonce, AccountData> {\n\t/// The number of transactions this account has sent.\n\tpub nonce: Nonce,\n\t/// The number of other modules that currently depend on this account's existence. The account\n\t/// cannot be reaped until this is zero.\n\tpub consumers: RefCount,\n\t/// The number of other modules that allow this account to exist. The account may not be reaped\n\t/// until this and `sufficients` are both zero.\n\tpub providers: RefCount,\n\t/// The number of modules that allow this account to exist for their own purposes only. The\n\t/// account may not be reaped until this and `providers` are both zero.\n\tpub sufficients: RefCount,\n\t/// The additional data that belongs to this account. Used to store the balance(s) in a lot of\n\t/// chains.\n\tpub data: AccountData,\n}\n```\n\nThe `AccountInfo` structure includes the following components:\n\n- **`nonce`**: Tracks the number of transactions initiated by the account, which ensures transaction uniqueness and prevents replay attacks.\n- **`consumers`**: Counts how many other modules or pallets rely on this accountâ€™s existence. The account cannot be removed from the chain (reaped) until this count reaches zero.\n- **`providers`**: Tracks how many modules permit this accountâ€™s existence. An account can only be reaped once both `providers` and `sufficients` are zero.\n- **`sufficients`**: Represents the number of modules that allow the account to exist for internal purposes, independent of any other modules.\n- **`AccountData`**: A flexible data structure that can be customized in the runtime configuration, usually containing balances or other user-specific data.\n\nThis structure helps manage an account's state and prevents its premature removal while it is still referenced by other on-chain data or modules. The [`AccountInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_system/struct.AccountInfo.html){target=\\_blank} structure can vary as long as it satisfies the trait bounds defined by the `AccountData` associated type in the [`frame-system::pallet::Config`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/trait.Config.html){target=\\_blank} trait."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 4, "depth": 3, "title": "Account Reference Counters", "anchor": "account-reference-counters", "start_char": 5825, "end_char": 10918, "estimated_token_count": 1040, "token_estimator": "heuristic-v1", "text": "### Account Reference Counters\n\nPolkadot SDK uses reference counters to track an accountâ€™s dependencies across different runtime modules. These counters ensure that accounts remain active while data is associated with them.\n\nThe reference counters include:\n\n- **`consumers`**: Prevents account removal while other pallets still rely on the account.\n- **`providers`**: Ensures an account is active before other pallets store data related to it.\n- **`sufficients`**: Indicates the accountâ€™s independence, ensuring it can exist even without a native token balance, such as when holding sufficient alternative assets.\n\n#### Providers Reference Counters\n\nThe `providers` counter ensures that an account is ready to be depended upon by other runtime modules. For example, it is incremented when an account has a balance above the existential deposit, which marks the account as active.\n\nThe system requires this reference counter to be greater than zero for the `consumers` counter to be incremented, ensuring the account is stable before any dependencies are added.\n\n#### Consumers Reference Counters\n\nThe `consumers` counter ensures that the account cannot be reaped until all references to it across the runtime have been removed. This check prevents the accidental deletion of accounts that still have active on-chain data.\n\nIt is the userâ€™s responsibility to clear out any data from other runtime modules if they wish to remove their account and reclaim their existential deposit.\n\n#### Sufficients Reference Counter\n\nThe `sufficients` counter tracks accounts that can exist independently without relying on a native account balance. This is useful for accounts holding other types of assets, like tokens, without needing a minimum balance in the native token.\n\nFor instance, the [Assets pallet](https://paritytech.github.io/polkadot-sdk/master/pallet_assets/index.html){target=\\_blank}, may increment this counter for an account holding sufficient tokens.\n\n#### Account Deactivation\n\nIn Polkadot SDK-based chains, an account is deactivated when its reference counters (such as `providers`, `consumers`, and `sufficient`) reach zero. These counters ensure the account remains active as long as other runtime modules or pallets reference it.\n\nWhen all dependencies are cleared and the counters drop to zero, the account becomes deactivated and may be removed from the chain (reaped). This is particularly important in Polkadot SDK-based blockchains, where accounts with balances below the existential deposit threshold are pruned from storage to conserve state resources.\n\nEach pallet that references an account has cleanup functions that decrement these counters when the pallet no longer depends on the account. Once these counters reach zero, the account is marked for deactivation.\n\n#### Updating Counters\n\nThe Polkadot SDK provides runtime developers with various methods to manage account lifecycle events, such as deactivation or incrementing reference counters. These methods ensure that accounts cannot be reaped while still in use.\n\nThe following helper functions manage these counters:\n\n- **`inc_consumers()`**: Increments the `consumer` reference counter for an account, signaling that another pallet depends on it.\n- **`dec_consumers()`**: Decrements the `consumer` reference counter, signaling that a pallet no longer relies on the account.\n- **`inc_providers()`**: Increments the `provider` reference counter, ensuring the account remains active.\n- **`dec_providers()`**: Decrements the `provider` reference counter, allowing for account deactivation when no longer in use.\n- **`inc_sufficients()`**: Increments the `sufficient` reference counter for accounts that hold sufficient assets.\n- **`dec_sufficients()`**: Decrements the `sufficient` reference counter.\n\nTo ensure proper account cleanup and lifecycle management, a corresponding decrement should be made for each increment action.\n\nThe `System` pallet offers three query functions to assist developers in tracking account states:\n\n- **[`can_inc_consumer()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.can_inc_consumer){target=\\_blank}**: Checks if the account can safely increment the consumer reference.\n- **[`can_dec_provider()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.can_dec_provider){target=\\_blank}**: Ensures that no consumers exist before allowing the decrement of the provider counter.\n- **[`is_provider_required()`](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html#method.is_provider_required){target=\\_blank}**: Verifies whether the account still has any active consumer references.\n\nThis modular and flexible system of reference counters tightly controls the lifecycle of accounts in Polkadot SDK-based blockchains, preventing the accidental removal or retention of unneeded accounts. You can refer to the [System pallet Rust docs](https://paritytech.github.io/polkadot-sdk/master/frame_system/pallet/struct.Pallet.html){target=\\_blank} for more details."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 5, "depth": 2, "title": "Account Balance Types", "anchor": "account-balance-types", "start_char": 10918, "end_char": 12838, "estimated_token_count": 465, "token_estimator": "heuristic-v1", "text": "## Account Balance Types\n\nIn the Polkadot ecosystem, account balances are categorized into different types based on how the funds are utilized and their availability. These balance types determine the actions that can be performed, such as transferring tokens, paying transaction fees, or participating in governance activities. Understanding these balance types helps developers manage user accounts and implement balance-dependent logic.\n\n!!! note \"A more efficient distribution of account balance types is in development\"\n    Soon, pallets in the Polkadot SDK will implement the [`Fungible` trait](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/tokens/fungible/index.html){target=\\_blank} (see the [tracking issue](https://github.com/paritytech/polkadot-sdk/issues/226){target=\\_blank} for more details). For example, the [`transaction-storage`](https://paritytech.github.io/polkadot-sdk/master/pallet_transaction_storage/index.html){target=\\_blank} pallet changed the implementation of the [`Currency`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/tokens/currency/index.html){target=\\_blank} trait (see the [Refactor transaction storage pallet to use fungible traits](https://github.com/paritytech/polkadot-sdk/pull/1800){target=\\_blank} PR for further details):\n\n    ```rust\n    type BalanceOf<T> = <<T as Config>::Currency as Currency<<T as frame_system::Config>::AccountId>>::Balance;\n    ```\n    \n    To the [`Fungible`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/tokens/fungible/index.html){target=\\_blank} trait:\n\n    ```rust\n    type BalanceOf<T> = <<T as Config>::Currency as FnInspect<<T as frame_system::Config>::AccountId>>::Balance;\n    ```\n    \n    This update will enable more efficient use of account balances, allowing the free balance to be utilized for on-chain activities such as setting proxies and managing identities."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 6, "depth": 3, "title": "Balance Types", "anchor": "balance-types", "start_char": 12838, "end_char": 15313, "estimated_token_count": 601, "token_estimator": "heuristic-v1", "text": "### Balance Types\n\nThe five main balance types are:\n\n- **Free balance**: Represents the total tokens available to the account for any on-chain activity, including staking, governance, and voting. However, it may not be fully spendable or transferrable if portions of it are locked or reserved.\n- **Locked balance**: Portions of the free balance that cannot be spent or transferred because they are tied up in specific activities like [staking](https://wiki.polkadot.com/learn/learn-staking/#nominating-validators){target=\\_blank}, [vesting](https://wiki.polkadot.com/learn/learn-guides-transfers/#vested-transfers-with-the-polkadot-js-ui){target=\\_blank}, or participating in [governance](https://wiki.polkadot.com/learn/learn-polkadot-opengov/#voting-on-a-referendum){target=\\_blank}. While the tokens remain part of the free balance, they are non-transferable for the duration of the lock.\n- **Reserved balance**: Funds locked by specific system actions, such as setting up an [identity](https://wiki.polkadot.com/learn/learn-identity/){target=\\_blank}, creating [proxies](https://wiki.polkadot.com/learn/learn-proxies/){target=\\_blank}, or submitting [deposits for governance proposals](https://wiki.polkadot.com/learn/learn-guides-polkadot-opengov/#claiming-opengov-deposits){target=\\_blank}. These tokens are not part of the free balance and cannot be spent unless they are unreserved.\n- **Spendable balance**: The portion of the free balance that is available for immediate spending or transfers. It is calculated by subtracting the maximum of locked or reserved amounts from the free balance, ensuring that existential deposit limits are met.\n- **Untouchable balance**: Funds that cannot be directly spent or transferred but may still be utilized for on-chain activities, such as governance participation or staking. These tokens are typically tied to certain actions or locked for a specific period.\n\nThe spendable balance is calculated as follows:\n\n```text\nspendable = free - max(locked - reserved, ED)\n```\n\nHere, `free`, `locked`, and `reserved` are defined above. The `ED` represents the [existential deposit](https://wiki.polkadot.com/learn/learn-accounts/#existential-deposit-and-reaping){target=\\_blank}, the minimum balance required to keep an account active and prevent it from being reaped. You may find you can't see all balance types when looking at your account via a wallet. Wallet providers often display only spendable, locked, and reserved balances."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 7, "depth": 3, "title": "Locks", "anchor": "locks", "start_char": 15313, "end_char": 17490, "estimated_token_count": 458, "token_estimator": "heuristic-v1", "text": "### Locks\n\nLocks are applied to an account's free balance, preventing that portion from being spent or transferred. Locks are automatically placed when an account participates in specific on-chain activities, such as staking or governance. Although multiple locks may be applied simultaneously, they do not stack. Instead, the largest lock determines the total amount of locked tokens.\n\nLocks follow these basic rules:\n\n- If different locks apply to varying amounts, the largest lock amount takes precedence.\n- If multiple locks apply to the same amount, the lock with the longest duration governs when the balance can be unlocked.\n\n#### Locks Example\n\nConsider an example where an account has 80 DOT locked for both staking and governance purposes like so:\n\n- 80 DOT is staked with a 28-day lock period.\n- 24 DOT is locked for governance with a 1x conviction and a 7-day lock period.\n- 4 DOT is locked for governance with a 6x conviction and a 224-day lock period.\n\nIn this case, the total locked amount is 80 DOT because only the largest lock (80 DOT from staking) governs the locked balance. These 80 DOT will be released at different times based on the lock durations. In this example, the 24 DOT locked for governance will be released first since the shortest lock period is seven days. The 80 DOT stake with a 28-day lock period is released next. Now, all that remains locked is the 4 DOT for governance. After 224 days, all 80 DOT (minus the existential deposit) will be free and transferable.\n\n![Illustration of Lock Example](/images/reference/parachains/accounts/accounts-01.webp)\n\n#### Edge Cases for Locks\n\nIn scenarios where multiple convictions and lock periods are active, the lock duration and amount are determined by the longest period and largest amount. For example, if you delegate with different convictions and attempt to undelegate during an active lock period, the lock may be extended for the full amount of tokens. For a detailed discussion on edge case lock behavior, see this [Stack Exchange post](https://substrate.stackexchange.com/questions/5067/delegating-and-undelegating-during-the-lock-period-extends-it-for-the-initial-am){target=\\_blank}."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 8, "depth": 3, "title": "Balance Types on Polkadot.js", "anchor": "balance-types-on-polkadotjs", "start_char": 17490, "end_char": 20529, "estimated_token_count": 603, "token_estimator": "heuristic-v1", "text": "### Balance Types on Polkadot.js\n\nPolkadot.js provides a user-friendly interface for managing and visualizing various account balances on Polkadot and Kusama networks. When interacting with Polkadot.js, you will encounter multiple balance types that are critical for understanding how your funds are distributed and restricted. This section explains how different balances are displayed in the Polkadot.js UI and what each type represents.\n\n![](/images/reference/parachains/accounts/accounts-02.webp)\n\nThe most common balance types displayed on Polkadot.js are:\n\n- **Total balance**: The total number of tokens available in the account. This includes all tokens, whether they are transferable, locked, reserved, or vested. However, the total balance does not always reflect what can be spent immediately. In this example, the total balance is 0.6274 KSM.\n\n- **Transferable balance**: Shows how many tokens are immediately available for transfer. It is calculated by subtracting the locked and reserved balances from the total balance. For example, if an account has a total balance of 0.6274 KSM and a transferable balance of 0.0106 KSM, only the latter amount can be sent or spent freely.\n\n- **Vested balance**: Tokens that allocated to the account but released according to a specific schedule. Vested tokens remain locked and cannot be transferred until fully vested. For example, an account with a vested balance of 0.2500 KSM means that this amount is owned but not yet transferable.\n\n- **Locked balance**: Tokens that are temporarily restricted from being transferred or spent. These locks typically result from participating in staking, governance, or vested transfers. In Polkadot.js, locked balances do not stackâ€”only the largest lock is applied. For instance, if an account has 0.5500 KSM locked for governance and staking, the locked balance would display 0.5500 KSM, not the sum of all locked amounts.\n\n- **Reserved balance**: Refers to tokens locked for specific on-chain actions, such as setting an identity, creating a proxy, or making governance deposits. Reserved tokens are not part of the free balance, but can be freed by performing certain actions. For example, removing an identity would unreserve those funds.\n\n- **Bonded balance**: The tokens locked for staking purposes. Bonded tokens are not transferable until they are unbonded after the unbonding period.\n\n- **Redeemable balance**: The number of tokens that have completed the unbonding period and are ready to be unlocked and transferred again. For example, if an account has a redeemable balance of 0.1000 KSM, those tokens are now available for spending.\n\n- **Democracy balance**: Reflects the number of tokens locked for governance activities, such as voting on referenda. These tokens are locked for the duration of the governance action and are only released after the lock period ends.\n\nBy understanding these balance types and their implications, developers and users can better manage their funds and engage with on-chain activities more effectively."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 9, "depth": 2, "title": "Address Formats", "anchor": "address-formats", "start_char": 20529, "end_char": 20988, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Address Formats\n\nThe SS58 address format is a core component of the Polkadot SDK that enables accounts to be uniquely identified across Polkadot-based networks. This format is a modified version of Bitcoin's Base58Check encoding, specifically designed to accommodate the multi-chain nature of the Polkadot ecosystem. SS58 encoding allows each chain to define its own set of addresses while maintaining compatibility and checksum validation for security."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 10, "depth": 3, "title": "Basic Format", "anchor": "basic-format", "start_char": 20988, "end_char": 22230, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "### Basic Format\n\nSS58 addresses consist of three main components:\n\n```text\nbase58encode(concat(<address-type>, <address>, <checksum>))\n```\n\n- **Address type**: A byte or set of bytes that define the network (or chain) for which the address is intended. This ensures that addresses are unique across different Polkadot SDK-based chains.\n- **Address**: The public key of the account encoded as bytes.\n- **Checksum**: A hash-based checksum which ensures that addresses are valid and unaltered. The checksum is derived from the concatenated address type and address components, ensuring integrity.\n\nThe encoding process transforms the concatenated components into a Base58 string, providing a compact and human-readable format that avoids easily confused characters (e.g., zero '0', capital 'O', lowercase 'l'). This encoding function ([`encode`](https://docs.rs/bs58/latest/bs58/fn.encode.html){target=\\_blank}) is implemented exactly as defined in Bitcoin and IPFS specifications, using the same alphabet as both implementations.\n\nFor more details about the SS58 address format implementation, see the [`Ss58Codec`](https://paritytech.github.io/polkadot-sdk/master/sp_core/crypto/trait.Ss58Codec.html){target=\\_blank} trait in the Rust Docs."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 11, "depth": 3, "title": "Address Type", "anchor": "address-type", "start_char": 22230, "end_char": 23165, "estimated_token_count": 203, "token_estimator": "heuristic-v1", "text": "### Address Type\n\nThe address type defines how an address is interpreted and to which network it belongs. Polkadot SDK uses different prefixes to distinguish between various chains and address formats:\n\n- **Address types `0-63`**: Simple addresses, commonly used for network identifiers.\n- **Address types `64-127`**: Full addresses that support a wider range of network identifiers.\n- **Address types `128-255`**: Reserved for future address format extensions.\n\nFor example, Polkadotâ€™s main network uses an address type of 0, while Kusama uses 2. This ensures that addresses can be used without confusion between networks.\n\nThe address type is always encoded as part of the SS58 address, making it easy to quickly identify the network. Refer to the [SS58 registry](https://github.com/paritytech/ss58-registry){target=\\_blank} for the canonical listing of all address type identifiers and how they map to Polkadot SDK-based networks."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 12, "depth": 3, "title": "Address Length", "anchor": "address-length", "start_char": 23165, "end_char": 24359, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "### Address Length\n\nSS58 addresses can have different lengths depending on the specific format. Address lengths range from as short as 3 to 35 bytes, depending on the complexity of the address and network requirements. This flexibility allows SS58 addresses to adapt to different chains while providing a secure encoding mechanism.\n\n| Total | Type | Raw account | Checksum |\n|-------|------|-------------|----------|\n| 3     | 1    | 1           | 1        |\n| 4     | 1    | 2           | 1        |\n| 5     | 1    | 2           | 2        |\n| 6     | 1    | 4           | 1        |\n| 7     | 1    | 4           | 2        |\n| 8     | 1    | 4           | 3        |\n| 9     | 1    | 4           | 4        |\n| 10    | 1    | 8           | 1        |\n| 11    | 1    | 8           | 2        |\n| 12    | 1    | 8           | 3        |\n| 13    | 1    | 8           | 4        |\n| 14    | 1    | 8           | 5        |\n| 15    | 1    | 8           | 6        |\n| 16    | 1    | 8           | 7        |\n| 17    | 1    | 8           | 8        |\n| 35    | 1    | 32          | 2        |\n\nSS58 addresses also support different payload sizes, allowing a flexible range of account identifiers."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 13, "depth": 3, "title": "Checksum Types", "anchor": "checksum-types", "start_char": 24359, "end_char": 24824, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "### Checksum Types\n\nA checksum is applied to validate SS58 addresses. Polkadot SDK uses a Blake2b-512 hash function to calculate the checksum, which is appended to the address before encoding. The checksum length can vary depending on the address format (e.g., 1-byte, 2-byte, or longer), providing varying levels of validation strength.\n\nThe checksum ensures that an address is not modified or corrupted, adding an extra layer of security for account management."}
{"page_id": "reference-parachains-accounts", "page_title": "Polkadot SDK Accounts", "index": 14, "depth": 3, "title": "Validating Addresses", "anchor": "validating-addresses", "start_char": 24824, "end_char": 29604, "estimated_token_count": 1074, "token_estimator": "heuristic-v1", "text": "### Validating Addresses\n\nSS58 addresses can be validated using the subkey command-line interface or the Polkadot.js API. These tools help ensure an address is correctly formatted and valid for the intended network. The following sections will provide an overview of how validation works with these tools.\n\n#### Using Subkey\n\n[Subkey](https://paritytech.github.io/polkadot-sdk/master/subkey/index.html){target=\\_blank} is a CLI tool provided by Polkadot SDK for generating and managing keys. It can inspect and validate SS58 addresses.\n\nThe `inspect` command gets a public key and an SS58 address from the provided secret URI. The basic syntax for the `subkey inspect` command is:\n\n```bash\nsubkey inspect [flags] [options] uri\n```\n\nFor the `uri` command-line argument, you can specify the secret seed phrase, a hex-encoded private key, or an SS58 address. If the input is a valid address, the `subkey` program displays the corresponding hex-encoded public key, account identifier, and SS58 addresses.\n\nFor example, to inspect the public keys derived from a secret seed phrase, you can run a command similar to the following:\n\n```bash\nsubkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\"\n```\n\nThe command displays output similar to the following:\n\n<div id=\"termynal\" data-termynal markdown>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>subkey inspect \"caution juice atom organ advance problem want pledge someone senior holiday very\"</span>\n  <span data-ty>Secret phrase `caution juice atom organ advance problem want pledge someone senior holiday very` is account:</span>\n  <span data-ty> Secret seed: 0xc8fa03532fb22ee1f7f6908b9c02b4e72483f0dbd66e4cd456b8f34c6230b849</span>\n  <span data-ty> Public key (hex): 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746</span>\n  <span data-ty> Public key (SS58): 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR</span>\n  <span data-ty> Account ID: 0xd6a3105d6768e956e9e5d41050ac29843f98561410d3a47f9dd5b3b227ab8746</span>\n  <span data-ty> SS58 Address: 5Gv8YYFu8H1btvmrJy9FjjAWfb99wrhV3uhPFoNEr918utyR</span>\n</div>\n\nThe `subkey` program assumes an address is based on a public/private key pair. If you inspect an address, the command returns the 32-byte account identifier.\n\nHowever, not all addresses in Polkadot SDK-based networks are based on keys.\n\nDepending on the command-line options you specify and the input you provided, the command output might also display the network for which the address has been encoded. For example:\n\n```bash\nsubkey inspect \"12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU\"\n```\n\nThe command displays output similar to the following:\n\n<div id=\"termynal\" data-termynal markdown>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>subkey inspect \"12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU\"</span>\n  <span data-ty>Public Key URI `12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU` is account:</span>\n  <span data-ty> Network ID/Version: polkadot</span>\n  <span data-ty> Public key (hex): 0x46ebddef8cd9bb167dc30878d7113b7e168e6f0646beffd77d69d39bad76b47a</span>\n  <span data-ty> Account ID: 0x46ebddef8cd9bb167dc30878d7113b7e168e6f0646beffd77d69d39bad76b47a</span>\n  <span data-ty> Public key (SS58): 12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU</span>\n  <span data-ty> SS58 Address: 12bzRJfh7arnnfPPUZHeJUaE62QLEwhK48QnH9LXeK2m1iZU</span>\n</div>\n\n#### Using Polkadot.js API\n\nTo verify an address in JavaScript or TypeScript projects, you can use the functions built into the [Polkadot.js API](https://polkadot.js.org/docs/){target=\\_blank}. For example:\n\n```js\n// Import Polkadot.js API dependencies\nconst { decodeAddress, encodeAddress } = require('@polkadot/keyring');\nconst { hexToU8a, isHex } = require('@polkadot/util');\n\n// Specify an address to test.\nconst address = 'INSERT_ADDRESS_TO_TEST';\n\n// Check address\nconst isValidSubstrateAddress = () => {\n  try {\n    encodeAddress(isHex(address) ? hexToU8a(address) : decodeAddress(address));\n\n    return true;\n  } catch (error) {\n    return false;\n  }\n};\n\n// Query result\nconst isValid = isValidSubstrateAddress();\nconsole.log(isValid);\n\n```\n\nIf the function returns `true`, the specified address is a valid address.\n\n#### Other SS58 Implementations\n\nSupport for encoding and decoding Polkadot SDK SS58 addresses has been implemented in several other languages and libraries.\n\n- **Crystal**: [`wyhaines/base58.cr`](https://github.com/wyhaines/base58.cr){target=\\_blank}\n- **Go**: [`itering/subscan-plugin`](https://github.com/itering/subscan-plugin){target=\\_blank}\n- **Python**: [`polkascan/py-scale-codec`](https://github.com/polkascan/py-scale-codec){target=\\_blank}\n- **TypeScript**: [`subsquid/squid-sdk`](https://github.com/subsquid/squid-sdk){target=\\_blank}"}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 10, "end_char": 693, "estimated_token_count": 126, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nIn the Polkadot SDK, blocks are fundamental to the functioning of the blockchain, serving as containers for [transactions](/reference/parachains/blocks-transactions-fees/transactions/){target=\\_blank} and changes to the chain's state. Blocks consist of headers and an array of transactions, ensuring the integrity and validity of operations on the network. This guide explores the essential components of a block, the process of block production, and how blocks are validated and imported across the network. By understanding these concepts, developers can better grasp how blockchains maintain security, consistency, and performance within the Polkadot ecosystem."}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 1, "depth": 2, "title": "What is a Block?", "anchor": "what-is-a-block", "start_char": 693, "end_char": 1830, "estimated_token_count": 226, "token_estimator": "heuristic-v1", "text": "## What is a Block?\n\nIn the Polkadot SDK, a block is a fundamental unit that encapsulates both the header and an array of transactions. The block header includes critical metadata to ensure the integrity and sequence of the blockchain. Here's a breakdown of its components:\n\n- **Block height**: Indicates the number of blocks created in the chain so far.\n- **Parent hash**: The hash of the previous block, providing a link to maintain the blockchain's immutability.\n- **Transaction root**: Cryptographic digest summarizing all transactions in the block.\n- **State root**: A cryptographic digest representing the post-execution state.\n- **Digest**: Additional information that can be attached to a block, such as consensus-related messages.\n\nEach transaction is part of a series that is executed according to the runtime's rules. The transaction root is a cryptographic digest of this series, which prevents alterations and enables succinct verification by light clients. This verification process allows light clients to confirm whether a transaction exists in a block with only the block header, avoiding downloading the entire block."}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 2, "depth": 2, "title": "Block Production", "anchor": "block-production", "start_char": 1830, "end_char": 2154, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Block Production\n\nWhen an authoring node is authorized to create a new block, it selects transactions from the transaction queue based on priority. This step, known as block production, relies heavily on the executive module to manage the initialization and finalization of blocks. The process is summarized as follows:"}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 3, "depth": 3, "title": "Initialize Block", "anchor": "initialize-block", "start_char": 2154, "end_char": 3023, "estimated_token_count": 199, "token_estimator": "heuristic-v1", "text": "### Initialize Block\n\nThe block initialization process begins with a series of function calls that prepare the block for transaction execution:\n\n1. **Call `on_initialize`**: The executive module calls theÂ [`on_initialize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_initialize){target=\\_blank}Â hook from the system pallet and other runtime pallets to prepare for the block's transactions.\n2. **Coordinate runtime calls**: Coordinates function calls in the order defined by the transaction queue.\n3. **Verify information**: Once [`on_initialize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_initialize){target=\\_blank}Â functions are executed, the executive module checks the parent hash in the block header and the trie root to verify information is consistent."}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 4, "depth": 3, "title": "Finalize Block", "anchor": "finalize-block", "start_char": 3023, "end_char": 3897, "estimated_token_count": 209, "token_estimator": "heuristic-v1", "text": "### Finalize Block\n\nOnce transactions are processed, the block must be finalized before being broadcast to the network. The finalization steps are as follows:\n\n1. **Call `on_finalize`**: The executive module calls the [`on_finalize`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_finalize){target=\\_blank} hooks in each pallet to ensure any remaining state updates or checks are completed before the block is sealed and published.\n2. **Verify information**: The block's digest and storage root in the header are checked against the initialized block to ensure consistency.\n3. **Call `on_idle`**: TheÂ [`on_idle`](https://paritytech.github.io/polkadot-sdk/master/frame_support/traits/trait.Hooks.html#method.on_idle){target=\\_blank} hook is triggered to process any remaining tasks using the leftover weight from the block."}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 5, "depth": 2, "title": "Block Authoring and Import", "anchor": "block-authoring-and-import", "start_char": 3897, "end_char": 4399, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Block Authoring and Import\n\nOnce the block is finalized, it is gossiped to other nodes in the network. Nodes follow this procedure:\n\n1. **Receive transactions**: The authoring node collects transactions from the network.\n2. **Validate**: Transactions are checked for validity.\n3. **Queue**: Valid transactions are placed in the transaction pool for execution.\n4. **Execute**: State changes are made as the transactions are executed.\n5. **Publish**: The finalized block is broadcast to the network."}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 6, "depth": 3, "title": "Block Import Queue", "anchor": "block-import-queue", "start_char": 4399, "end_char": 6005, "estimated_token_count": 401, "token_estimator": "heuristic-v1", "text": "### Block Import Queue\n\nAfter a block is published, other nodes on the network can import it into their chain state. The block import queue is part of the outer node in every Polkadot SDK-based node and ensures incoming blocks are valid before adding them to the node's state.\n\nIn most cases, you don't need to know details about how transactions are gossiped or how other nodes on the network import blocks. The following traits are relevant, however, if you plan to write any custom consensus logic or want a deeper dive into the block import queue:\n\n- **[`ImportQueue`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/trait.ImportQueue.html){target=\\_blank}**: The trait that defines the block import queue.\n- **[`Link`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/trait.Link.html){target=\\_blank}**: The trait that defines the link between the block import queue and the network.\n- **[`BasicQueue`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/struct.BasicQueue.html){target=\\_blank}**: A basic implementation of the block import queue.\n- **[`Verifier`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/import_queue/trait.Verifier.html){target=\\_blank}**: The trait that defines the block verifier.\n- **[`BlockImport`](https://paritytech.github.io/polkadot-sdk/master/sc_consensus/block_import/trait.BlockImport.html){target=\\_blank}**: The trait that defines the block import process.\n\nThese traits govern how blocks are validated and imported across the network, ensuring consistency and security."}
{"page_id": "reference-parachains-blocks-transactions-fees-blocks", "page_title": "Blocks", "index": 7, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 6005, "end_char": 6252, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nTo learn more about the block structure in the Polkadot SDK runtime, see the [`Block` reference](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/traits/trait.Block.html){target=\\_blank} entry in the Rust Docs."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 0, "depth": 2, "title": "Introductions", "anchor": "introductions", "start_char": 33, "end_char": 2267, "estimated_token_count": 408, "token_estimator": "heuristic-v1", "text": "## Introductions\n\nWhen transactions are executed, or data is stored on-chain, the activity changes the chain's state and consumes blockchain resources. Because the resources available to a blockchain are limited, managing how operations on-chain consume them is important. In addition to being limited in practical terms, such as storage capacity, blockchain resources represent a potential attack vector for malicious users. For example, a malicious user might attempt to overload the network with messages to stop the network from producing new blocks. To protect blockchain resources from being drained or overloaded, you need to manage how they are made available and how they are consumed. The resources to be aware of include:\n\n- Memory usage\n- Storage input and output\n- Computation\n- Transaction and block size\n- State database size\n\nThe Polkadot SDK provides block authors with several ways to manage access to resources and to prevent individual components of the chain from consuming too much of any single resource. Two of the most important mechanisms available to block authors areÂ weightsÂ andÂ transaction fees.\n\n[Weights](/reference/glossary/#weight){target=\\_blank}Â manage the time it takes to validate a block and characterize the time it takes to execute the calls in the block's body. By controlling the execution time a block can consume, weights set limits on storage input, output, and computation.\n\nSome of the weight allowed for a block is consumed as part of the block's initialization and finalization. The weight might also be used to execute mandatory inherent extrinsic calls. To help ensure blocks donâ€™t consume too much execution time and prevent malicious users from overloading the system with unnecessary calls, weights are combined withÂ transaction fees.\n\n[Transaction fees](/reference/parachains/blocks-transactions-fees/transactions/#transaction-fees){target=\\_blank} provide an economic incentive to limit execution time, computation, and the number of calls required to perform operations. Transaction fees are also used to make the blockchain economically sustainable because they are typically applied to transactions initiated by users and deducted before a transaction request is executed."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 1, "depth": 2, "title": "How Fees are Calculated", "anchor": "how-fees-are-calculated", "start_char": 2267, "end_char": 3592, "estimated_token_count": 287, "token_estimator": "heuristic-v1", "text": "## How Fees are Calculated\n\nThe final fee for a transaction is calculated using the following parameters:\n\n- **`base fee`**: This is the minimum amount a user pays for a transaction. It is declared aÂ base weightÂ in the runtime and converted to a fee using theÂ [`WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank}Â conversion.\n- **`weight fee`**: A fee proportional to the execution time (input and output and computation) that a transaction consumes.\n- **`length fee`**: A fee proportional to the encoded length of the transaction.\n- **`tip`**: An optional tip to increase the transactionâ€™s priority, giving it a higher chance to be included in the transaction queue.\n\nThe base fee and proportional weight and length fees constitute theÂ inclusion fee. The inclusion fee is the minimum fee that must be available for a transaction to be included in a block.\n\n```text\ninclusion fee = base fee + weight fee + length fee\n```\n\nTransaction fees are withdrawn before the transaction is executed. After the transaction is executed, the weight can be adjusted to reflect the resources used. If a transaction uses fewer resources than expected, the transaction fee is corrected, and the adjusted transaction fee is deposited."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 2, "depth": 2, "title": "Using the Transaction Payment Pallet", "anchor": "using-the-transaction-payment-pallet", "start_char": 3592, "end_char": 4931, "estimated_token_count": 309, "token_estimator": "heuristic-v1", "text": "## Using the Transaction Payment Pallet\n\nTheÂ [Transaction Payment pallet](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/substrate/frame/transaction-payment){target=\\_blank}Â provides the basic logic for calculating the inclusion fee. You can also use the Transaction Payment pallet to:\n\n- Convert a weight value into a deductible fee based on a currency type usingÂ [`Config::WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank}.\n- Update the fee for the next block by defining a multiplier based on the chainâ€™s final state at the end of the previous block usingÂ [`Config::FeeMultiplierUpdate`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.FeeMultiplierUpdate){target=\\_blank}.\n- Manage the withdrawal, refund, and deposit of transaction fees usingÂ [`Config::OnChargeTransaction`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.OnChargeTransaction){target=\\_blank}.\n\nYou can learn more about these configuration traits in theÂ [Transaction PaymentÂ documentation](https://paritytech.github.io/polkadot-sdk/master/pallet_transaction_payment/index.html){target=\\_blank}."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 3, "depth": 3, "title": "Understanding the Inclusion Fee", "anchor": "understanding-the-inclusion-fee", "start_char": 4931, "end_char": 6255, "estimated_token_count": 278, "token_estimator": "heuristic-v1", "text": "### Understanding the Inclusion Fee\n\nThe formula for calculating the inclusion fee is as follows:\n\n```text\ninclusion_fee = base_fee + length_fee + [targeted_fee_adjustment * weight_fee]\n```\n\nAnd then, for calculating the final fee:\n\n```text\nfinal_fee = inclusion_fee + tip\n```\n\nIn the first formula, theÂ `targeted_fee_adjustment`Â is a multiplier that can tune the final fee based on the networkâ€™s congestion.\n\n- TheÂ `base_fee`Â derived from the base weight covers inclusion overhead like signature verification.\n- TheÂ `length_fee`Â is a per-byte fee that is multiplied by the length of the encoded extrinsic.\n- TheÂ `weight_fee`Â fee is calculated using two parameters:\n  - TheÂ `ExtrinsicBaseWeight`Â that is declared in the runtime and applies to all extrinsics.\n  - TheÂ `#[pallet::weight]`Â annotation that accounts for an extrinsic's complexity.\n\nTo convert the weight to `Currency`, the runtime must define a `WeightToFee` struct that implements a conversion function, [`Convert<Weight,Balance>`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/struct.Pallet.html#method.weight_to_fee){target=\\_blank}.\n\nNote that the extrinsic sender is charged the inclusion fee before the extrinsic is invoked. The fee is deducted from the sender's balance even if the transaction fails upon execution."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 4, "depth": 3, "title": "Accounts with an Insufficient Balance", "anchor": "accounts-with-an-insufficient-balance", "start_char": 6255, "end_char": 6816, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "### Accounts with an Insufficient Balance\n\nIf an account does not have a sufficient balance to pay the inclusion fee and remain aliveâ€”that is, enough to pay the inclusion fee and maintain the minimumÂ existential depositâ€”then you should ensure the transaction is canceled so that no fee is deducted and the transaction does not begin execution.\n\nThe Polkadot SDK doesn't enforce this rollback behavior. However, this scenario would be rare because the transaction queue and block-making logic perform checks to prevent it before adding an extrinsic to a block."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 5, "depth": 3, "title": "Fee Multipliers", "anchor": "fee-multipliers", "start_char": 6816, "end_char": 8034, "estimated_token_count": 260, "token_estimator": "heuristic-v1", "text": "### Fee Multipliers\n\nThe inclusion fee formula always results in the same fee for the same input. However, weight can be dynamic andâ€”based on howÂ [`WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank}Â is definedâ€”the final fee can include some degree of variability.\nThe Transaction Payment pallet provides theÂ [`FeeMultiplierUpdate`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.FeeMultiplierUpdate){target=\\_blank}Â configurable parameter to account for this variability.\n\nThe Polkadot network inspires the default update function and implements a targeted adjustment in which a target saturation level of block weight is defined. If the previous block is more saturated, the fees increase slightly. Similarly, if the last block has fewer transactions than the target, fees are decreased by a small amount. For more information about fee multiplier adjustments, see theÂ [Web3 Research Page](https://research.web3.foundation/Polkadot/overview/token-economics#relay-chain-transaction-fees-and-per-block-transaction-limits){target=\\_blank}."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 6, "depth": 2, "title": "Transactions with Special Requirements", "anchor": "transactions-with-special-requirements", "start_char": 8034, "end_char": 9446, "estimated_token_count": 277, "token_estimator": "heuristic-v1", "text": "## Transactions with Special Requirements\n\nInclusion fees must be computable before execution and can only represent fixed logic. Some transactions warrant limiting resources with other strategies. For example:\n\n- Bonds are a type of fee that might be returned or slashed after some on-chain event. For example, you might want to require users to place a bond to participate in a vote. The bond might then be returned at the end of the referendum or slashed if the voter attempted malicious behavior.\n- Deposits are fees that might be returned later. For example, you might require users to pay a deposit to execute an operation that uses storage. The userâ€™s deposit could be returned if a subsequent operation frees up storage.\n- Burn operations are used to pay for a transaction based on its internal logic. For example, a transaction might burn funds from the sender if the transaction creates new storage items to pay for the increased state size.\n- Limits enable you to enforce constant or configurable limits on specific operations. For example, the default [Staking pallet](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/substrate/frame/staking){target=\\_blank} only allows nominators to nominate 16 validators to limit the complexity of the validator election process.\n\nIt is important to note that if you query the chain for a transaction fee, it only returns the inclusion fee."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 7, "depth": 2, "title": "Default Weight Annotations", "anchor": "default-weight-annotations", "start_char": 9446, "end_char": 10104, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "## Default Weight Annotations\n\nAll dispatchable functions in the Polkadot SDK must specify a weight. The way of doing that is using the annotation-based system that lets you combine fixed values for database read/write weight and/or fixed values based on benchmarks. The most basic example would look like this:\n\n```rust\n#[pallet::weight(100_000)]\nfn my_dispatchable() {\n    // ...\n}\n```\n\nNote that theÂ [`ExtrinsicBaseWeight`](https://crates.parity.io/frame_support/weights/constants/struct.ExtrinsicBaseWeight.html){target=\\_blank}Â is automatically added to the declared weight to account for the costs of simply including an empty extrinsic into a block."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 8, "depth": 3, "title": "Weights and Database Read/Write Operations", "anchor": "weights-and-database-readwrite-operations", "start_char": 10104, "end_char": 11244, "estimated_token_count": 264, "token_estimator": "heuristic-v1", "text": "### Weights and Database Read/Write Operations\n\nTo make weight annotations independent of the deployed database backend, they are defined as a constant and then used in the annotations when expressing database accesses performed by the dispatchable:\n\n```rust\n#[pallet::weight(T::DbWeight::get().reads_writes(1, 2) + 20_000)]\nfn my_dispatchable() {\n    // ...\n}\n```\n\nThis dispatchable allows one database to read and two to write, in addition to other things that add the additional 20,000. Database access is generally every time a value declared inside theÂ [`#[pallet::storage]`](https://paritytech.github.io/polkadot-sdk/master/frame_support/pallet_macros/attr.storage.html){target=\\_blank}Â block is accessed. However, unique accesses are counted because after a value is accessed, it is cached, and reaccessing it does not result in a database operation. That is:\n\n- Multiple reads of the exact value count as one read.\n- Multiple writes of the exact value count as one write.\n- Multiple reads of the same value, followed by a write to that value, count as one read and one write.\n- A write followed by a read-only counts as one write."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 9, "depth": 3, "title": "Dispatch Classes", "anchor": "dispatch-classes", "start_char": 11244, "end_char": 13982, "estimated_token_count": 571, "token_estimator": "heuristic-v1", "text": "### Dispatch Classes\n\nDispatches are broken into three classes:\n\n- Normal\n- Operational\n- Mandatory\n\nIf a dispatch is not defined asÂ `Operational`Â orÂ `Mandatory`Â in the weight annotation, the dispatch is identified asÂ `Normal`Â by default. You can specify that the dispatchable uses another class like this:\n\n```rust\n#[pallet::dispatch((DispatchClass::Operational))]\nfn my_dispatchable() {\n    // ...\n}\n```\n\nThis tuple notation also allows you to specify a final argument determining whether the user is charged based on the annotated weight. If you don't specify otherwise,Â `Pays::Yes`Â is assumed:\n\n```rust\n#[pallet::dispatch(DispatchClass::Normal, Pays::No)]\nfn my_dispatchable() {\n    // ...\n}\n```\n\n#### Normal Dispatches\n\nDispatches in this class represent normal user-triggered transactions. These types of dispatches only consume a portion of a block's total weight limit. For information about the maximum portion of a block that can be consumed for normal dispatches, seeÂ [`AvailableBlockRatio`](https://paritytech.github.io/polkadot-sdk/master/frame_system/limits/struct.BlockLength.html){target=\\_blank}. Normal dispatches are sent to theÂ transaction pool.\n\n#### Operational Dispatches\n\nUnlike normal dispatches, which representÂ the usageÂ of network capabilities, operational dispatches are those thatÂ provideÂ network capabilities. Operational dispatches can consume the entire weight limit of a block. They are not bound by theÂ [`AvailableBlockRatio`](https://paritytech.github.io/polkadot-sdk/master/frame_system/limits/struct.BlockLength.html){target=\\_blank}. Dispatches in this class are given maximum priority and are exempt from paying theÂ [`length_fee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/){target=\\_blank}.\n\n#### Mandatory Dispatches\n\nMandatory dispatches are included in a block even if they cause the block to surpass its weight limit. You can only use the mandatory dispatch class forÂ inherent transactionsÂ that the block author submits. This dispatch class is intended to represent functions in the block validation process. Because these dispatches are always included in a block regardless of the function weight, the validation process must prevent malicious nodes from abusing the function to craft valid but impossibly heavy blocks. You can typically accomplish this by ensuring that:\n\n- The operation performed is always light.\n- The operation can only be included in a block once.\n\nTo make it more difficult for malicious nodes to abuse mandatory dispatches, they cannot be included in blocks that return errors. This dispatch class serves the assumption that it is better to allow an overweight block to be created than not to allow any block to be created at all."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 10, "depth": 3, "title": "Dynamic Weights", "anchor": "dynamic-weights", "start_char": 13982, "end_char": 14529, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Dynamic Weights\n\nIn addition to purely fixed weights and constants, the weight calculation can consider the input arguments of a dispatchable. The weight should be trivially computable from the input arguments with some basic arithmetic:\n\n```rust\nuse frame_support:: {\n    dispatch:: {\n        DispatchClass::Normal,\n        Pays::Yes,\n    },\n   weights::Weight,\n};\n\n#[pallet::weight(FunctionOf(\n  |args: (&Vec<User>,)| args.0.len().saturating_mul(10_000),\n  )\n]\nfn handle_users(origin, calls: Vec<User>) {\n    // Do something per user\n}\n```"}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 11, "depth": 2, "title": "Post Dispatch Weight Correction", "anchor": "post-dispatch-weight-correction", "start_char": 14529, "end_char": 15153, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Post Dispatch Weight Correction\n\nDepending on the execution logic, a dispatchable function might consume less weight than was prescribed pre-dispatch. To correct weight, the function declares a different return type and returns its actual weight:\n\n```rust\n#[pallet::weight(10_000 + 500_000_000)]\nfn expensive_or_cheap(input: u64) -> DispatchResultWithPostInfo {\n    let was_heavy = do_calculation(input);\n\n    if (was_heavy) {\n        // None means \"no correction\" from the weight annotation.\n        Ok(None.into())\n    } else {\n        // Return the actual weight consumed.\n        Ok(Some(10_000).into())\n    }\n}\n```"}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 12, "depth": 2, "title": "Custom Fees", "anchor": "custom-fees", "start_char": 15153, "end_char": 15269, "estimated_token_count": 20, "token_estimator": "heuristic-v1", "text": "## Custom Fees\n\nYou can also define custom fee systems through custom weight functions or inclusion fee functions."}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 13, "depth": 3, "title": "Custom Weights", "anchor": "custom-weights", "start_char": 15269, "end_char": 19797, "estimated_token_count": 1044, "token_estimator": "heuristic-v1", "text": "### Custom Weights\n\nInstead of using the default weight annotations, you can create a custom weight calculation type using theÂ weightsÂ module. The custom weight calculation type must implement the following traits:\n\n- [`WeighData<T>`](https://crates.parity.io/frame_support/weights/trait.WeighData.html){target=\\_blank}Â to determine the weight of the dispatch.\n- [`ClassifyDispatch<T>`](https://crates.parity.io/frame_support/weights/trait.ClassifyDispatch.html){target=\\_blank}Â to determine the class of the dispatch.\n- [`PaysFee<T>`](https://crates.parity.io/frame_support/weights/trait.PaysFee.html){target=\\_blank}Â to determine whether the sender of the dispatch pays fees.\n \nThe Polkadot SDK then bundles the output information of the three traits into theÂ [`DispatchInfo`](https://paritytech.github.io/polkadot-sdk/master/frame_support/dispatch/struct.DispatchInfo.html){target=\\_blank} struct and provides it by implementing theÂ [`GetDispatchInfo`](https://docs.rs/frame-support/latest/frame_support/dispatch/trait.GetDispatchInfo.html){target=\\_blank}Â for allÂ `Call`Â variants and opaque extrinsic types. This is used internally by the System and Executive modules.\n\n`ClassifyDispatch`,Â `WeighData`, andÂ `PaysFee`Â are generic overÂ T, which gets resolved into the tuple of all dispatch arguments except for the origin. The following example illustrates aÂ structÂ that calculates the weight asÂ `m * len(args)`,Â whereÂ `m`Â is a given multiplier andÂ argsÂ is the concatenated tuple of all dispatch arguments. In this example, the dispatch class isÂ `Operational`Â if the transaction has more than 100 bytes of length in arguments and will pay fees if the encoded length exceeds 10 bytes.\n\n```rust\nstruct LenWeight(u32);\nimpl<T> WeighData<T> for LenWeight {\n    fn weigh_data(&self, target: T) -> Weight {\n        let multiplier = self.0;\n        let encoded_len = target.encode().len() as u32;\n        multiplier * encoded_len\n    }\n}\n\nimpl<T> ClassifyDispatch<T> for LenWeight {\n    fn classify_dispatch(&self, target: T) -> DispatchClass {\n        let encoded_len = target.encode().len() as u32;\n        if encoded_len > 100 {\n            DispatchClass::Operational\n        } else {\n            DispatchClass::Normal\n        }\n    }\n}\n\nimpl<T> PaysFee<T> {\n    fn pays_fee(&self, target: T) -> Pays {\n        let encoded_len = target.encode().len() as u32;\n        if encoded_len > 10 {\n            Pays::Yes\n        } else {\n            Pays::No\n        }\n    }\n}\n```\n\nA weight calculator function can also be coerced to the final type of the argument instead of defining it as a vague type that can be encoded. The code would roughly look like this:\n\n```rust\nstruct CustomWeight;\nimpl WeighData<(&u32, &u64)> for CustomWeight {\n    fn weigh_data(&self, target: (&u32, &u64)) -> Weight {\n        ...\n    }\n}\n\n// given a dispatch:\n#[pallet::call]\nimpl<T: Config<I>, I: 'static> Pallet<T, I> {\n    #[pallet::weight(CustomWeight)]\n    fn foo(a: u32, b: u64) { ... }\n}\n```\n\nIn this example, the `CustomWeight` can only be used in conjunction with a dispatch with a particular signature `(u32, u64)`, as opposed to `LenWeight`, which can be used with anything because there aren't any assumptions about `<T>`.\n\n#### Custom Inclusion Fee\n\nThe following example illustrates how to customize your inclusion fee. You must configure the appropriate associated types in the respective module.\n\n```rust\n// Assume this is the balance type\ntype Balance = u64;\n\n// Assume we want all the weights to have a `100 + 2 * w` conversion to fees\nstruct CustomWeightToFee;\nimpl WeightToFee<Weight, Balance> for CustomWeightToFee {\n    fn convert(w: Weight) -> Balance {\n        let a = Balance::from(100);\n        let b = Balance::from(2);\n        let w = Balance::from(w);\n        a + b * w\n    }\n}\n\nparameter_types! {\n    pub const ExtrinsicBaseWeight: Weight = 10_000_000;\n}\n\nimpl frame_system::Config for Runtime {\n    type ExtrinsicBaseWeight = ExtrinsicBaseWeight;\n}\n\nparameter_types! {\n    pub const TransactionByteFee: Balance = 10;\n}\n\nimpl transaction_payment::Config {\n    type TransactionByteFee = TransactionByteFee;\n    type WeightToFee = CustomWeightToFee;\n    type FeeMultiplierUpdate = TargetedFeeAdjustment<TargetBlockFullness>;\n}\n\nstruct TargetedFeeAdjustment<T>(sp_std::marker::PhantomData<T>);\nimpl<T: Get<Perquintill>> WeightToFee<Fixed128, Fixed128> for TargetedFeeAdjustment<T> {\n    fn convert(multiplier: Fixed128) -> Fixed128 {\n        // Don't change anything. Put any fee update info here.\n        multiplier\n    }\n}\n```"}
{"page_id": "reference-parachains-blocks-transactions-fees-fees", "page_title": "Transactions Weights and Fees", "index": 14, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 19797, "end_char": 20800, "estimated_token_count": 233, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nYou now know the weight system, how it affects transaction fee computation, and how to specify weights for your dispatchable calls. The next step is determining the correct weight for your dispatchable operations. You can use SubstrateÂ benchmarking functionsÂ andÂ frame-benchmarkingÂ calls to test your functions with different parameters and empirically determine the proper weight in their worst-case scenarios.\n\n- [Benchmark](/parachains/customize-runtime/pallet-development/benchmark-pallet/)\n- [`SignedExtension`](https://paritytech.github.io/polkadot-sdk/master/sp_runtime/traits/trait.SignedExtension.html){target=\\_blank}\n- [Custom weights for the Example pallet](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506-2/substrate/frame/examples/basic/src/weights.rs){target=\\_blank}\n- [Web3 Foundation Research](https://research.web3.foundation/Polkadot/overview/token-economics#relay-chain-transaction-fees-and-per-block-transaction-limits){target=\\_blank}"}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 655, "estimated_token_count": 108, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nTransactions are essential components of blockchain networks, enabling state changes and the execution of key operations. In the Polkadot SDK, transactions, often called extrinsics, come in multiple forms, including signed, unsigned, and inherent transactions.\n\nThis guide walks you through the different transaction types and how they're formatted, validated, and processed within the Polkadot ecosystem. You'll also learn how to customize transaction formats and construct transactions for FRAME-based runtimes, ensuring a complete understanding of how transactions are built and executed in Polkadot SDK-based chains."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 1, "depth": 2, "title": "What Is a Transaction?", "anchor": "what-is-a-transaction", "start_char": 655, "end_char": 1674, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## What Is a Transaction?\n\nIn the Polkadot SDK, transactions represent operations that modify the chain's state, bundled into blocks for execution. The term extrinsic is often used to refer to any data that originates outside the runtime and is included in the chain. While other blockchain systems typically refer to these operations as \"transactions,\" the Polkadot SDK adopts the broader term \"extrinsic\" to capture the wide variety of data types that can be added to a block.\n\nThere are three primary types of transactions (extrinsics) in the Polkadot SDK:\n\n- **Signed transactions**: Signed by the submitting account, often carrying transaction fees.\n- **Unsigned transactions**: Submitted without a signature, often requiring custom validation logic.\n- **Inherent transactions**: Typically inserted directly into blocks by block authoring nodes, without gossiping between peers.\n\nEach type serves a distinct purpose, and understanding when and how to use each is key to efficiently working with the Polkadot SDK."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 2, "depth": 3, "title": "Signed Transactions", "anchor": "signed-transactions", "start_char": 1674, "end_char": 2838, "estimated_token_count": 221, "token_estimator": "heuristic-v1", "text": "### Signed Transactions\n\nSigned transactions require an account's signature and typically involve submitting a request to execute a runtime call. The signature serves as a form of cryptographic proof that the sender has authorized the action, using their private key. These transactions often involve a transaction fee to cover the cost of execution and incentivize block producers.\n\nSigned transactions are the most common type of transaction and are integral to user-driven actions, such as token transfers. For instance, when you transfer tokens from one account to another, the sending account must sign the transaction to authorize the operation.\n\nFor example, the [`pallet_balances::Call::transfer_allow_death`](https://paritytech.github.io/polkadot-sdk/master/pallet_balances/pallet/struct.Pallet.html#method.transfer_allow_death){target=\\_blank} extrinsic in the Balances pallet allows you to transfer tokens. Since your account initiates this transaction, your account key is used to sign it. You'll also be responsible for paying the associated transaction fee, with the option to include an additional tip to incentivize faster inclusion in the block."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 3, "depth": 3, "title": "Unsigned Transactions", "anchor": "unsigned-transactions", "start_char": 2838, "end_char": 4091, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "### Unsigned Transactions\n\nUnsigned transactions do not require a signature or account-specific data from the sender. Unlike signed transactions, they do not come with any form of economic deterrent, such as fees, which makes them susceptible to spam or replay attacks. Custom validation logic must be implemented to mitigate these risks and ensure these transactions are secure.\n\nUnsigned transactions typically involve scenarios where including a fee or signature is unnecessary or counterproductive. However, due to the absence of fees, they require careful validation to protect the network. For example, [`pallet_im_online::Call::heartbeat`](https://paritytech.github.io/polkadot-sdk/master/pallet_im_online/pallet/struct.Pallet.html#method.heartbeat){target=\\_blank} extrinsic allows validators to send a heartbeat signal, indicating they are active. Since only validators can make this call, the logic embedded in the transaction ensures that the sender is a validator, making the need for a signature or fee redundant.\n\nUnsigned transactions are more resource-intensive than signed ones because custom validation is required, but they play a crucial role in certain operational scenarios, especially when regular user accounts aren't involved."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 4, "depth": 3, "title": "Inherent Transactions", "anchor": "inherent-transactions", "start_char": 4091, "end_char": 5815, "estimated_token_count": 327, "token_estimator": "heuristic-v1", "text": "### Inherent Transactions\n\nInherent transactions are a specialized type of unsigned transaction that is used primarily for block authoring. Unlike signed or other unsigned transactions, inherent transactions are added directly by block producers and are not broadcasted to the network or stored in the transaction queue. They don't require signatures or the usual validation steps and are generally used to insert system-critical data directly into blocks.\n\nA key example of an inherent transaction is inserting a timestamp into each block. The [`pallet_timestamp::Call::now`](https://paritytech.github.io/polkadot-sdk/master/pallet_timestamp/pallet/struct.Pallet.html#method.now-1){target=\\_blank} extrinsic allows block authors to include the current time in the block they are producing. Since the block producer adds this information, there is no need for transaction validation, like signature verification. The validation in this case is done indirectly by the validators, who check whether the timestamp is within an acceptable range before finalizing the block.\n\nAnother example is the [`paras_inherent::Call::enter`](https://paritytech.github.io/polkadot-sdk/master/polkadot_runtime_parachains/paras_inherent/pallet/struct.Pallet.html#method.enter){target=\\_blank} extrinsic, which enables parachain collator nodes to send validation data to the relay chain. This inherent transaction ensures that the necessary parachain data is included in each block without the overhead of gossiped transactions.\n\nInherent transactions serve a critical role in block authoring by allowing important operational data to be added directly to the chain without needing the validation processes required for standard transactions."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 5, "depth": 2, "title": "Transaction Formats", "anchor": "transaction-formats", "start_char": 5815, "end_char": 6164, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Transaction Formats\n\nUnderstanding the structure of signed and unsigned transactions is crucial for developers building on Polkadot SDK-based chains. Whether you're optimizing transaction processing, customizing formats, or interacting with the transaction pool, knowing the format of extrinsics, Polkadot's term for transactions, is essential."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 6, "depth": 3, "title": "Types of Transaction Formats", "anchor": "types-of-transaction-formats", "start_char": 6164, "end_char": 7058, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "### Types of Transaction Formats\n\nIn Polkadot SDK-based chains, extrinsics can fall into three main categories:\n\n- **Unchecked extrinsics**: Typically used for signed transactions that require validation. They contain a signature and additional data, such as a nonce and information for fee calculation. Unchecked extrinsics are named as such because they require validation checks before being accepted into the transaction pool.\n- **Checked extrinsics**: Typically used for inherent extrinsics (unsigned transactions); these don't require signature verification. Instead, they carry information such as where the extrinsic originates and any additional data required for the block authoring process.\n- **Opaque extrinsics**: Used when the format of an extrinsic is not yet fully committed or finalized. They are still decodable, but their structure can be flexible depending on the context."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 7, "depth": 3, "title": "Signed Transaction Data Structure", "anchor": "signed-transaction-data-structure", "start_char": 7058, "end_char": 8020, "estimated_token_count": 195, "token_estimator": "heuristic-v1", "text": "### Signed Transaction Data Structure\n\nA signed transaction typically includes the following components:\n\n- **Signature**: Verifies the authenticity of the transaction sender.\n- **Call**: The actual function or method call the transaction is requesting (for example, transferring funds).\n- **Nonce**: Tracks the number of prior transactions sent from the account, helping to prevent replay attacks.\n- **Tip**: An optional incentive to prioritize the transaction in block inclusion.\n- **Additional data**: Includes details such as spec version, block hash, and genesis hash to ensure the transaction is valid within the correct runtime and chain context.\n\nHere's a simplified breakdown of how signed transactions are typically constructed in a Polkadot SDK runtime:\n\n``` code\n<signing account ID> + <signature> + <additional data>\n```\n\nEach part of the signed transaction has a purpose, ensuring the transaction's authenticity and context within the blockchain."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 8, "depth": 3, "title": "Signed Extensions", "anchor": "signed-extensions", "start_char": 8020, "end_char": 10654, "estimated_token_count": 610, "token_estimator": "heuristic-v1", "text": "### Signed Extensions\n\nPolkadot SDK also provides the concept of [signed extensions](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/signed_extensions/index.html){target=\\_blank}, which allow developers to extend extrinsics with additional data or validation logic before they are included in a block. The [`SignedExtension`](https://paritytech.github.io/try-runtime-cli/sp_runtime/traits/trait.SignedExtension.html){target=\\_blank} set helps enforce custom rules or protections, such as ensuring the transaction's validity or calculating priority.\n\nThe transaction queue regularly calls signed extensions to verify a transaction's validity before placing it in the ready queue. This safeguard ensures transactions won't fail in a block. Signed extensions are commonly used to enforce validation logic and protect the transaction pool from spam and replay attacks.\n\nIn FRAME, a signed extension can hold any of the following types by default:\n\n- **[`AccountId`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/runtime/types_common/type.AccountId.html){target=\\_blank}**: To encode the sender's identity.\n- **[`Call`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/traits/trait.SignedExtension.html#associatedtype.Call){target=\\_blank}**: To encode the pallet call to be dispatched. This data is used to calculate transaction fees.\n- **[`AdditionalSigned`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/traits/trait.SignedExtension.html#associatedtype.AdditionalSigned){target=\\_blank}**: To handle any additional data to go into the signed payload allowing you to attach any custom logic prior to dispatching a transaction.\n- **[`Pre`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/traits/trait.SignedExtension.html#associatedtype.Pre){target=\\_blank}**: To encode the information that can be passed from before a call is dispatched to after it gets dispatched.\n\nSigned extensions can enforce checks like:\n\n- **[`CheckSpecVersion`](https://paritytech.github.io/polkadot-sdk/master/src/frame_system/extensions/check_spec_version.rs.html){target=\\_blank}**: Ensures the transaction is compatible with the runtime's current version.\n- **[`CheckWeight`](https://paritytech.github.io/polkadot-sdk/master/frame_system/struct.CheckWeight.html){target=\\_blank}**: Calculates the weight (or computational cost) of the transaction, ensuring the block doesn't exceed the maximum allowed weight.\n\nThese extensions are critical in the transaction lifecycle, ensuring that only valid and prioritized transactions are processed."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 9, "depth": 2, "title": "Transaction Construction", "anchor": "transaction-construction", "start_char": 10654, "end_char": 10991, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Transaction Construction\n\nBuilding transactions in the Polkadot SDK involves constructing a payload that can be verified, signed, and submitted for inclusion in a block. Each runtime in the Polkadot SDK has its own rules for validating and executing transactions, but there are common patterns for constructing a signed transaction."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 10, "depth": 3, "title": "Construct a Signed Transaction", "anchor": "construct-a-signed-transaction", "start_char": 10991, "end_char": 12900, "estimated_token_count": 404, "token_estimator": "heuristic-v1", "text": "### Construct a Signed Transaction\n\nA signed transaction in the Polkadot SDK includes various pieces of data to ensure security, prevent replay attacks, and prioritize processing. Here's an overview of how to construct one:\n\n1. **Construct the unsigned payload**: Gather the necessary information for the call, including:\n\n    - **Pallet index**: Identifies the pallet where the runtime function resides.\n    - **Function index**: Specifies the particular function to call in the pallet.\n    - **Parameters**: Any additional arguments required by the function call.\n\n2. **Create a signing payload**: Once the unsigned payload is ready, additional data must be included:\n\n    - **Transaction nonce**: Unique identifier to prevent replay attacks.\n    - **Era information**: Defines how long the transaction is valid before it's dropped from the pool.\n    - **Block hash**: Ensures the transaction doesn't execute on the wrong chain or fork.\n\n3. **Sign the payload**: Using the sender's private key, sign the payload to ensure that the transaction can only be executed by the account holder.\n4. **Serialize the signed payload**: Once signed, the transaction must be serialized into a binary format, ensuring the data is compact and easy to transmit over the network.\n5. **Submit the serialized transaction**: Finally, submit the serialized transaction to the network, where it will enter the transaction pool and wait for processing by an authoring node.\n\nThe following is an example of how a signed transaction might look:\n\n``` rust\nnode_runtime::UncheckedExtrinsic::new_signed(\n    function.clone(),                                      // some call\n    sp_runtime::AccountId32::from(sender.public()).into(), // some sending account\n    node_runtime::Signature::Sr25519(signature.clone()),   // the account's signature\n    extra.clone(),                                         // the signed extensions\n)\n```"}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 11, "depth": 3, "title": "Transaction Encoding", "anchor": "transaction-encoding", "start_char": 12900, "end_char": 13898, "estimated_token_count": 225, "token_estimator": "heuristic-v1", "text": "### Transaction Encoding\n\nBefore a transaction is sent to the network, it is serialized and encoded using a structured encoding process that ensures consistency and prevents tampering:\n\n- **`[1]`**: Compact encoded length in bytes of the entire transaction.\n- **`[2]`**: AÂ u8Â containing 1 byte to indicate whether the transaction is signed or unsigned (1 bit) and the encoded transaction version ID (7 bits).\n- **`[3]`**: If signed, this field contains an account ID, an SR25519 signature, and some extra data.\n- **`[4]`**: Encoded call data, including pallet and function indices and any required arguments.\n\nThis encoded format ensures consistency and efficiency in processing transactions across the network. By adhering to this format, applications can construct valid transactions and pass them to the network for execution.\n\nTo learn more about how compact encoding works usingÂ SCALE, see the [SCALE Codec](https://github.com/paritytech/parity-scale-codec){target=\\_blank} README on GitHub."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 12, "depth": 3, "title": "Customize Transaction Construction", "anchor": "customize-transaction-construction", "start_char": 13898, "end_char": 14538, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Customize Transaction Construction\n\nAlthough the basic steps for constructing transactions are consistent across Polkadot SDK-based chains, developers can customize transaction formats and validation rules. For example:\n\n- **Custom pallets**: You can define new pallets with custom function calls, each with its own parameters and validation logic.\n- **Signed extensions**: Developers can implement custom extensions that modify how transactions are prioritized, validated, or included in blocks.\n\nBy leveraging Polkadot SDK's modular design, developers can create highly specialized transaction logic tailored to their chain's needs."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 13, "depth": 2, "title": "Lifecycle of a Transaction", "anchor": "lifecycle-of-a-transaction", "start_char": 14538, "end_char": 15016, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Lifecycle of a Transaction\n\nIn the Polkadot SDK, transactions are often referred to as extrinsics because the data in transactions originates outside of the runtime. These transactions contain data that initiates changes to the chain state. The most common type of extrinsic is a signed transaction, which is cryptographically verified and typically incurs a fee. This section focuses on how signed transactions are processed, validated, and ultimately included in a block."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 14, "depth": 3, "title": "Define Transaction Properties", "anchor": "define-transaction-properties", "start_char": 15016, "end_char": 15747, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "### Define Transaction Properties\n\nThe Polkadot SDK runtime defines key transaction properties, such as:\n\n- **Transaction validity**: Ensures the transaction meets all runtime requirements.\n- **Signed or unsigned**: Identifies whether a transaction needs to be signed by an account.\n- **State changes**: Determines how the transaction modifies the state of the chain.\n\nPallets, which compose the runtime's logic, define the specific transactions that your chain supports. When a user submits a transaction, such as a token transfer, it becomes a signed transaction, verified by the user's account signature. If the account has enough funds to cover fees, the transaction is executed, and the chain's state is updated accordingly."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 15, "depth": 3, "title": "Process on a Block Authoring Node", "anchor": "process-on-a-block-authoring-node", "start_char": 15747, "end_char": 16444, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "### Process on a Block Authoring Node\n\nIn Polkadot SDK-based networks, some nodes are authorized to author blocks. These nodes validate and process transactions. When a transaction is sent to a node that can produce blocks, it undergoes a lifecycle that involves several stages, including validation and execution. Non-authoring nodes gossip the transaction across the network until an authoring node receives it. The following diagram illustrates the lifecycle of a transaction that's submitted to a network and processed by an authoring node.\n\n![Transaction lifecycle diagram](/images/reference/parachains/blocks-transactions-fees/transactions/transactions-01.webp){ style=\"background:white\" }"}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 16, "depth": 3, "title": "Validate and Queue", "anchor": "validate-and-queue", "start_char": 16444, "end_char": 18688, "estimated_token_count": 436, "token_estimator": "heuristic-v1", "text": "### Validate and Queue\n\nOnce a transaction reaches an authoring node, it undergoes an initial validation process to ensure it meets specific conditions defined in the runtime. This validation includes checks for:\n\n- **Correct nonce**: Ensures the transaction is sequentially valid for the account.\n- **Sufficient funds**: Confirms the account can cover any associated transaction fees.\n- **Signature validity**: Verifies that the sender's signature matches the transaction data.\n\nAfter these checks, valid transactions are placed in the transaction pool, where they are queued for inclusion in a block. The transaction pool regularly re-validates queued transactions to ensure they remain valid before being processed. To reach consensus, two-thirds of the nodes must agree on the order of the transactions executed and the resulting state change. Transactions are validated and queued on the local node in a transaction pool to prepare for consensus.\n\n#### Transaction Pool\n\nThe transaction pool is responsible for managing valid transactions. It ensures that only transactions that pass initial validity checks are queued. Transactions that fail validation, expire, or become invalid for other reasons are removed from the pool.\n\nThe transaction pool organizes transactions into two queues:\n\n- **Ready queue**: Transactions that are valid and ready to be included in a block.\n- **Future queue**: Transactions that are not yet valid but could be in the future, such as transactions with a nonce too high for the current state.\n\nDetails on how the transaction pool validates transactions, including fee and signature handling, can be found in the [`validate_transaction`](https://paritytech.github.io/polkadot-sdk/master/sp_transaction_pool/runtime_api/trait.TaggedTransactionQueue.html#method.validate_transaction){target=\\_blank} method.\n\n#### Invalid Transactions\n\nIf a transaction is invalid, for example, due to an invalid signature or insufficient funds, it is rejected and won't be added to the block. Invalid transactions might be rejected for reasons such as:\n\n- The transaction has already been included in a block.\n- The transaction's signature does not match the sender.\n- The transaction is too large to fit in the current block."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 17, "depth": 3, "title": "Transaction Ordering and Priority", "anchor": "transaction-ordering-and-priority", "start_char": 18688, "end_char": 19326, "estimated_token_count": 128, "token_estimator": "heuristic-v1", "text": "### Transaction Ordering and Priority\n\nWhen a node is selected as the next block author, it prioritizes transactions based on weight, length, and tip amount. The goal is to fill the block with high-priority transactions without exceeding its maximum size or computational limits. Transactions are ordered as follows:\n\n- **Inherents first**: Inherent transactions, such as block timestamp updates, are always placed first.\n- **Nonce-based ordering**: Transactions from the same account are ordered by their nonce.\n- **Fee-based ordering**: Among transactions with the same nonce or priority level, those with higher fees are prioritized."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 18, "depth": 3, "title": "Transaction Execution", "anchor": "transaction-execution", "start_char": 19326, "end_char": 19943, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "### Transaction Execution\n\nOnce a block author selects transactions from the pool, the transactions are executed in priority order. As each transaction is processed, the state changes are written directly to the chain's storage. It's important to note that these changes are not cached, meaning a failed transaction won't revert earlier state changes, which could leave the block in an inconsistent state.\n\nEvents are also written to storage. Runtime logic should not emit an event before performing the associated actions. If the associated transaction fails after the event was emitted, the event will not revert."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 19, "depth": 2, "title": "Transaction Mortality", "anchor": "transaction-mortality", "start_char": 19943, "end_char": 21474, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "## Transaction Mortality\n\nTransactions in the network can be configured as either mortal (with expiration) or immortal (without expiration). Every transaction payload contains a block checkpoint (reference block number and hash) and an era/validity period that determines how many blocks after the checkpoint the transaction remains valid.\n\nWhen a transaction is submitted, the network validates it against these parameters. If the transaction is not included in a block within the specified validity window, it is automatically removed from the transaction queue.\n\n- **Mortal transactions**: Have a finite lifespan and will expire after a specified number of blocks. For example, a transaction with a block checkpoint of 1000 and a validity period of 64 blocks will be valid from blocks 1000 to 1064.\n\n- **Immortal transactions**: Never expire and remain valid indefinitely. To create an immortal transaction, set the block checkpoint to 0 (genesis block), use the genesis hash as a reference, and set the validity period to 0.\n\nHowever, immortal transactions pose significant security risks through replay attacks. If an account is reaped (balance drops to zero, account removed) and later re-funded, malicious actors can replay old immortal transactions.\n\nThe blockchain maintains only a limited number of prior block hashes for reference validation, called `BlockHashCount`. If your validity period exceeds `BlockHashCount`, the effective validity period becomes the minimum of your specified period and the block hash count."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 20, "depth": 2, "title": "Unique Identifiers for Extrinsics", "anchor": "unique-identifiers-for-extrinsics", "start_char": 21474, "end_char": 23370, "estimated_token_count": 427, "token_estimator": "heuristic-v1", "text": "## Unique Identifiers for Extrinsics\n\nTransaction hashes are **not unique identifiers** in Polkadot SDK-based chains.\n\nKey differences from traditional blockchains:\n\n- Transaction hashes serve only as fingerprints of transaction information.\n- Multiple valid transactions can share the same hash.\n- Hash uniqueness assumptions lead to serious issues.\n\nFor example, when an account is reaped (removed due to insufficient balance) and later recreated, it resets to nonce 0, allowing identical transactions to be valid at different points:\n\n| Block | Extrinsic Index | Hash | Origin    | Nonce | Call                | Result                        |\n|-------|----------------|------|-----------|-------|---------------------|-------------------------------|\n| 100   | 0              | 0x01 | Account A | 0     | Transfer 5 DOT to B | Account A reaped              |\n| 150   | 5              | 0x02 | Account B | 4     | Transfer 7 DOT to A | Account A created (nonce = 0) |\n| 200   | 2              | 0x01 | Account A | 0     | Transfer 5 DOT to B | Successful transaction        |\n\nNotice that blocks 100 and 200 contain transactions with identical hashes (0x01) but are completely different, valid operations occurring at different times.\n\nAdditional complexity comes from Polkadot SDK's origin abstraction. Origins can represent collectives, governance bodies, or other non-account entities that don't maintain nonces like regular accounts and might dispatch identical calls multiple times with the same hash values. Each execution occurs in different chain states with different results.\n\nThe correct way to uniquely identify an extrinsic on a Polkadot SDK-based chain is to use the block ID (height or hash) and the extrinsic index. Since the Polkadot SDK defines blocks as headers plus ordered arrays of extrinsics, the index position within a canonical block provides guaranteed uniqueness."}
{"page_id": "reference-parachains-blocks-transactions-fees-transactions", "page_title": "Transactions", "index": 21, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 23370, "end_char": 23610, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nFor a video overview of the lifecycle of transactions and the types of transactions that exist, see the [Transaction lifecycle](https://www.youtube.com/watch?v=3pfM0GOp02c){target=\\_blank} seminar from Parity Tech."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 612, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nUnderstanding and leveraging on-chain data is a fundamental aspect of blockchain development. Whether you're building frontend applications or backend systems, accessing and decoding runtime metadata is vital to interacting with the blockchain. This guide introduces you to the tools and processes for generating and retrieving metadata, explains its role in application development, and outlines the additional APIs available for interacting with a Polkadot node. By mastering these components, you can ensure seamless communication between your applications and the blockchain."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 1, "depth": 2, "title": "Application Development", "anchor": "application-development", "start_char": 612, "end_char": 1674, "estimated_token_count": 195, "token_estimator": "heuristic-v1", "text": "## Application Development\n\nYou might not be directly involved in building frontend applications as a blockchain developer. However, most applications that run on a blockchain require some form of frontend or user-facing client to enable users or other programs to access and modify the data that the blockchain stores. For example, you might develop a browser-based, mobile, or desktop application that allows users to submit transactions, post articles, view their assets, or track previous activity. The backend for that application is configured in the runtime logic for your blockchain, but the frontend client makes the runtime features accessible to your users.\n\nFor your custom chain to be useful to others, you'll need to provide a client application that allows users to view, interact with, or update information that the blockchain keeps track of. In this article, you'll learn how to expose information about your runtime so that client applications can use it, see examples of the information exposed, and explore tools and libraries that use it."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 2, "depth": 2, "title": "Understand Metadata", "anchor": "understand-metadata", "start_char": 1674, "end_char": 2274, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "## Understand Metadata\n\nPolkadot SDK-based blockchain networks are designed to expose their runtime information, allowing developers to learn granular details regarding pallets, RPC calls, and runtime APIs. The metadata also exposes their related documentation. The chain's metadata is [SCALE-encoded](/reference/parachains/data-encoding/){target=\\_blank}, allowing for the development of browser-based, mobile, or desktop applications to support the chain's runtime upgrades seamlessly. It is also possible to develop applications compatible with multiple Polkadot SDK-based chains simultaneously."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 3, "depth": 2, "title": "Expose Runtime Information as Metadata", "anchor": "expose-runtime-information-as-metadata", "start_char": 2274, "end_char": 3873, "estimated_token_count": 282, "token_estimator": "heuristic-v1", "text": "## Expose Runtime Information as Metadata\n\nTo interact with a node or the state of the blockchain, you need to know how to connect to the chain and access the exposed runtime features. This interaction involves a Remote Procedure Call (RPC) through a node endpoint address, commonly through a secure web socket connection.\n\nAn application developer typically needs to know the contents of the runtime logic, including the following details:\n\n- Version of the runtime the application is connecting to.\n- Supported APIs.\n- Implemented pallets.\n- Defined functions and corresponding type signatures.\n- Defined custom types.\n- Exposed parameters users can set.\n\nAs the Polkadot SDK is modular and provides a composable framework for building blockchains, there are limitless opportunities to customize the schema of properties. Each runtime can be configured with its properties, including function calls and types, which can be changed over time with runtime upgrades.\n\nThe Polkadot SDK enables you to generate the runtime metadata schema to capture information unique to a runtime. The metadata for a runtime describes the pallets in use and types defined for a specific runtime version. The metadata includes information about each pallet's storage items, functions, events, errors, and constants. The metadata also provides type definitions for any custom types included in the runtime.\n\nMetadata provides a complete inventory of a chain's runtime. It is key to enabling client applications to interact with the node, parse responses, and correctly format message payloads sent back to that chain."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 4, "depth": 2, "title": "Generate Metadata", "anchor": "generate-metadata", "start_char": 3873, "end_char": 5179, "estimated_token_count": 297, "token_estimator": "heuristic-v1", "text": "## Generate Metadata\n\nTo efficiently use the blockchain's networking resources and minimize the data transmitted over the network, the metadata schema is encoded using the [Parity SCALE Codec](https://github.com/paritytech/parity-scale-codec?tab=readme-ov-file#parity-scale-codec){target=\\_blank}. This encoding is done automatically through the [`scale-info`](https://docs.rs/scale-info/latest/scale_info/){target=\\_blank}crate.\n\nAt a high level, generating the metadata involves the following steps:\n\n1. The pallets in the runtime logic expose callable functions, types, parameters, and documentation that need to be encoded in the metadata.\n2. The `scale-info` crate collects type information for the pallets in the runtime, builds a registry of the pallets that exist in a particular runtime, and the relevant types for each pallet in the registry. The type information is detailed enough to enable encoding and decoding for every type.\n3. The [`frame-metadata`](https://github.com/paritytech/frame-metadata){target=\\_blank} crate describes the structure of the runtime based on the registry provided by the `scale-info` crate.\n4. Nodes provide the RPC method `state_getMetadata` to return a complete description of all the types in the current runtime as a hex-encoded vector of SCALE-encoded bytes."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 5, "depth": 2, "title": "Retrieve Runtime Metadata", "anchor": "retrieve-runtime-metadata", "start_char": 5179, "end_char": 5695, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Retrieve Runtime Metadata\n\nThe type information provided by the metadata enables applications to communicate with nodes using different runtime versions and across chains that expose different calls, events, types, and storage items. The metadata also allows libraries to generate a substantial portion of the code needed to communicate with a given node, enabling libraries like [`subxt`](https://github.com/paritytech/subxt){target=\\_blank} to generate frontend interfaces that are specific to a target chain."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 6, "depth": 3, "title": "Use Polkadot.js", "anchor": "use-polkadotjs", "start_char": 5695, "end_char": 6146, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "### Use Polkadot.js\n\nVisit the [Polkadot.js Portal](https://polkadot.js.org/apps/#/rpc){target=\\_blank} and select the **Developer** dropdown in the top banner. Select **RPC Calls** to make the call to request metadata. Follow these steps to make the RPC call:\n\n1. Select **state** as the endpoint to call.\n2. Select **`getMetadata(at)`** as the method to call.\n3. Click **Submit RPC call** to submit the call and return the metadata in JSON format."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 7, "depth": 3, "title": "Use Curl", "anchor": "use-curl", "start_char": 6146, "end_char": 6460, "estimated_token_count": 95, "token_estimator": "heuristic-v1", "text": "### Use Curl \n\nYou can fetch the metadata for the network by calling the node's RPC endpoint. This request returns the metadata in bytes rather than human-readable JSON:\n\n```sh\ncurl -H \"Content-Type: application/json\" \\\n-d '{\"id\":1, \"jsonrpc\":\"2.0\", \"method\": \"state_getMetadata\"}' \\\nhttps://rpc.polkadot.io\n\n```"}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 8, "depth": 3, "title": "Use Subxt", "anchor": "use-subxt", "start_char": 6460, "end_char": 6826, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "### Use Subxt\n\n[`subxt`](https://github.com/paritytech/subxt){target=\\_blank} may also be used to fetch the metadata of any data in a human-readable JSON format: \n\n```sh\nsubxt metadata  --url wss://rpc.polkadot.io --format json > spec.json\n```\n\nAnother option is to use the [`subxt` explorer web UI](https://paritytech.github.io/subxt-explorer/#/){target=\\_blank}."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 9, "depth": 2, "title": "Client Applications and Metadata", "anchor": "client-applications-and-metadata", "start_char": 6826, "end_char": 7379, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Client Applications and Metadata\n\nThe metadata exposes the expected way to decode each type, meaning applications can send, retrieve, and process application information without manual encoding and decoding. Client applications must use the [SCALE codec library](https://github.com/paritytech/parity-scale-codec?tab=readme-ov-file#parity-scale-codec){target=\\_blank} to encode and decode RPC payloads to use the metadata. Client applications use the metadata to interact with the node, parse responses, and format message payloads sent to the node."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 10, "depth": 2, "title": "Metadata Format", "anchor": "metadata-format", "start_char": 7379, "end_char": 9561, "estimated_token_count": 466, "token_estimator": "heuristic-v1", "text": "## Metadata Format\n\nAlthough the SCALE-encoded bytes can be decoded using the `frame-metadata` and [`parity-scale-codec`](https://github.com/paritytech/parity-scale-codec){target=\\_blank} libraries, there are other tools, such as `subxt` and the Polkadot-JS API, that can convert the raw data to human-readable JSON format.\n\nThe types and type definitions included in the metadata returned by the `state_getMetadata` RPC call depend on the runtime's metadata version.\n\nIn general, the metadata includes the following information:\n\n- A constant identifying the file as containing metadata.\n- The version of the metadata format used in the runtime.\n- Type definitions for all types used in the runtime and generated by the `scale-info` crate.\n- Pallet information for the pallets included in the runtime in the order that they are defined in the `construct_runtime` macro.\n\n!!!tip \n    Depending on the frontend library used (such as the [Polkadot API](https://papi.how/){target=\\_blank}), they may format the metadata differently than the raw format shown.\n\nThe following example illustrates a condensed and annotated section of metadata decoded and converted to JSON:\n\n```json\n[\n    1635018093,\n    {\n        \"V14\": {\n            \"types\": {\n                \"types\": [{}]\n            },\n            \"pallets\": [{}],\n            \"extrinsic\": {\n                \"ty\": 126,\n                \"version\": 4,\n                \"signed_extensions\": [{}]\n            },\n            \"ty\": 141\n        }\n    }\n]\n\n```\n\nThe constant `1635018093` is a magic number that identifies the file as a metadata file. The rest of the metadata is divided into the `types`, `pallets`, and `extrinsic` sections:\n\n- The `types` section contains an index of the types and information about each type's type signature.\n- The `pallets` section contains information about each pallet in the runtime.\n- The `extrinsic` section describes the type identifier and transaction format version that the runtime uses.\n\nDifferent extrinsic versions can have varying formats, especially when considering [signed transactions](/reference/parachains/blocks-transactions-fees/transactions/#signed-transactions){target=\\_blank}."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 11, "depth": 3, "title": "Pallets", "anchor": "pallets", "start_char": 9561, "end_char": 15081, "estimated_token_count": 986, "token_estimator": "heuristic-v1", "text": "### Pallets\n\nThe following is a condensed and annotated example of metadata for a single element in the `pallets` array (the [`sudo`](https://paritytech.github.io/polkadot-sdk/master/pallet_sudo/index.html){target=\\_blank} pallet):\n\n```json\n{\n    \"name\": \"Sudo\",\n    \"storage\": {\n        \"prefix\": \"Sudo\",\n        \"entries\": [\n            {\n                \"name\": \"Key\",\n                \"modifier\": \"Optional\",\n                \"ty\": {\n                    \"Plain\": 0\n                },\n                \"default\": [0],\n                \"docs\": [\"The `AccountId` of the sudo key.\"]\n            }\n        ]\n    },\n    \"calls\": {\n        \"ty\": 117\n    },\n    \"event\": {\n        \"ty\": 42\n    },\n    \"constants\": [],\n    \"error\": {\n        \"ty\": 124\n    },\n    \"index\": 8\n}\n\n```\n\nEvery element metadata contains the name of the pallet it represents and information about its storage, calls, events, and errors. You can look up details about the definition of the calls, events, and errors by viewing the type index identifier. The type index identifier is the `u32` integer used to access the type information for that item. For example, the type index identifier for calls in the Sudo pallet is 117. If you view information for that type identifier in the `types` section of the metadata, it provides information about the available calls, including the documentation for each call.\n\nFor example, the following is a condensed excerpt of the calls for the Sudo pallet:\n\n```json\n{\n    \"id\": 117,\n    \"type\": {\n        \"path\": [\"pallet_sudo\", \"pallet\", \"Call\"],\n        \"params\": [\n            {\n                \"name\": \"T\",\n                \"type\": null\n            }\n        ],\n        \"def\": {\n            \"variant\": {\n                \"variants\": [\n                    {\n                        \"name\": \"sudo\",\n                        \"fields\": [\n                            {\n                                \"name\": \"call\",\n                                \"type\": 114,\n                                \"typeName\": \"Box<<T as Config>::RuntimeCall>\"\n                            }\n                        ],\n                        \"index\": 0,\n                        \"docs\": [\n                            \"Authenticates sudo key, dispatches a function call with `Root` origin\"\n                        ]\n                    },\n                    {\n                        \"name\": \"sudo_unchecked_weight\",\n                        \"fields\": [\n                            {\n                                \"name\": \"call\",\n                                \"type\": 114,\n                                \"typeName\": \"Box<<T as Config>::RuntimeCall>\"\n                            },\n                            {\n                                \"name\": \"weight\",\n                                \"type\": 8,\n                                \"typeName\": \"Weight\"\n                            }\n                        ],\n                        \"index\": 1,\n                        \"docs\": [\n                            \"Authenticates sudo key, dispatches a function call with `Root` origin\"\n                        ]\n                    },\n                    {\n                        \"name\": \"set_key\",\n                        \"fields\": [\n                            {\n                                \"name\": \"new\",\n                                \"type\": 103,\n                                \"typeName\": \"AccountIdLookupOf<T>\"\n                            }\n                        ],\n                        \"index\": 2,\n                        \"docs\": [\n                            \"Authenticates current sudo key, sets the given AccountId (`new`) as the new sudo\"\n                        ]\n                    },\n                    {\n                        \"name\": \"sudo_as\",\n                        \"fields\": [\n                            {\n                                \"name\": \"who\",\n                                \"type\": 103,\n                                \"typeName\": \"AccountIdLookupOf<T>\"\n                            },\n                            {\n                                \"name\": \"call\",\n                                \"type\": 114,\n                                \"typeName\": \"Box<<T as Config>::RuntimeCall>\"\n                            }\n                        ],\n                        \"index\": 3,\n                        \"docs\": [\n                            \"Authenticates sudo key, dispatches a function call with `Signed` origin from a given account\"\n                        ]\n                    }\n                ]\n            }\n        }\n    }\n}\n\n```\n\nFor each field, you can access type information and metadata for the following:\n\n- **Storage metadata**: Provides the information required to enable applications to get information for specific storage items.\n- **Call metadata**: Includes information about the runtime calls defined by the `#[pallet]` macro including call names, arguments and documentation.\n- **Event metadata**: Provides the metadata generated by the `#[pallet::event]` macro, including the name, arguments, and documentation for each pallet event.\n- **Constants metadata**: Provides metadata generated by the `#[pallet::constant]` macro, including the name, type, and hex-encoded value of the constant.\n- **Error metadata**: Provides metadata generated by the `#[pallet::error]` macro, including the name and documentation for each pallet error.\n\n!!!tip\n    Type identifiers change from time to time, so you should avoid relying on specific type identifiers in your applications."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 12, "depth": 3, "title": "Extrinsic", "anchor": "extrinsic", "start_char": 15081, "end_char": 17205, "estimated_token_count": 384, "token_estimator": "heuristic-v1", "text": "### Extrinsic\n\nThe runtime generates extrinsic metadata and provides useful information about transaction format. When decoded, the metadata contains the transaction version and the list of signed extensions.\n\nFor example:\n\n```json\n{\n    \"extrinsic\": {\n        \"ty\": 126,\n        \"version\": 4,\n        \"signed_extensions\": [\n            {\n                \"identifier\": \"CheckNonZeroSender\",\n                \"ty\": 132,\n                \"additional_signed\": 41\n            },\n            {\n                \"identifier\": \"CheckSpecVersion\",\n                \"ty\": 133,\n                \"additional_signed\": 4\n            },\n            {\n                \"identifier\": \"CheckTxVersion\",\n                \"ty\": 134,\n                \"additional_signed\": 4\n            },\n            {\n                \"identifier\": \"CheckGenesis\",\n                \"ty\": 135,\n                \"additional_signed\": 11\n            },\n            {\n                \"identifier\": \"CheckMortality\",\n                \"ty\": 136,\n                \"additional_signed\": 11\n            },\n            {\n                \"identifier\": \"CheckNonce\",\n                \"ty\": 138,\n                \"additional_signed\": 41\n            },\n            {\n                \"identifier\": \"CheckWeight\",\n                \"ty\": 139,\n                \"additional_signed\": 41\n            },\n            {\n                \"identifier\": \"ChargeTransactionPayment\",\n                \"ty\": 140,\n                \"additional_signed\": 41\n            }\n        ]\n    },\n    \"ty\": 141\n}\n\n```\n\nThe type system is [composite](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/reference_docs/frame_runtime_types/index.html){target=\\_blank}, meaning each type identifier contains a reference to a specific type or to another type identifier that provides information about the associated primitive types.\n\nFor example, you can encode the `BitVec<Order, Store>` type, but to decode it properly, you must know the types used for the `Order` and `Store` types. To find type information for `Order` and `Store`, you can use the path in the decoded JSON to locate their type identifiers."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 13, "depth": 2, "title": "Included RPC APIs", "anchor": "included-rpc-apis", "start_char": 17205, "end_char": 18317, "estimated_token_count": 302, "token_estimator": "heuristic-v1", "text": "## Included RPC APIs\n\nA standard node comes with the following APIs to interact with a node:\n\n- **[`AuthorApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/author/trait.AuthorApiServer.html){target=\\_blank}**: Make calls into a full node, including authoring extrinsics and verifying session keys.\n- **[`ChainApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/chain/trait.ChainApiServer.html){target=\\_blank}**: Retrieve block header and finality information.\n- **[`OffchainApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/offchain/trait.OffchainApiServer.html){target=\\_blank}**: Make RPC calls for off-chain workers.\n- **[`StateApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/state/trait.StateApiServer.html){target=\\_blank}**: Query information about on-chain state such as runtime version, storage items, and proofs.\n- **[`SystemApiServer`](https://paritytech.github.io/polkadot-sdk/master/sc_rpc/system/trait.SystemApiServer.html){target=\\_blank}**: Retrieve information about network state, such as connected peers and node roles."}
{"page_id": "reference-parachains-chain-data", "page_title": "Chain Data", "index": 14, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 18317, "end_char": 18650, "estimated_token_count": 101, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nThe following tools can help you locate and decode metadata:\n\n- [Subxt Explorer](https://paritytech.github.io/subxt-explorer/#/){target=\\_blank}\n- [Metadata Portal ðŸŒ—](https://github.com/paritytech/metadata-portal){target=\\_blank}\n- [De[code] Sub[strate]](https://github.com/paritytech/desub){target=\\_blank}"}
{"page_id": "reference-parachains-consensus-async-backing", "page_title": "Asynchronous Backing", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 24, "end_char": 1148, "estimated_token_count": 215, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAsynchronous backing often shortened to _Async Backing_ is a parachain protocol feature that significantly improves performance, enabling parachains to produce blocks twice as fast (every 6 seconds instead of every 12) and to provide 4x more execution time per block (2 seconds instead of 0.5). \n\nTechnically, async backing is a parachain [configuration](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/relay_chain/struct.AsyncBackingParams.html){target=\\_blank} that allows collators and validators to build blocks ahead of the relay chain during the generation and backing stages of the [Inclusion Pipeline](/reference/parachains/consensus/inclusion-pipeline){target=\\_blank} by using unincluded segments, which are chains of parachain blocks that have not yet been fully included in the relay chain. This decouples parachain block production from relay chain inclusion, improves coretime efficiency, and enables the parallel processing required for parachains to further scale throughput using [Elastic Scaling](/reference/parachains/consensus/elastic-scaling){target=\\_blank}."}
{"page_id": "reference-parachains-consensus-async-backing", "page_title": "Asynchronous Backing", "index": 1, "depth": 2, "title": "Configurations", "anchor": "configurations", "start_char": 1148, "end_char": 2044, "estimated_token_count": 199, "token_estimator": "heuristic-v1", "text": "## Configurations\nThe following configurations can be set by on-chain governance, dictating how many blocks ahead of the relay chain a given parachain's collators can run:\n\n- [**`max_candidate_depth`**](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/relay_chain/struct.AsyncBackingParams.html#structfield.max_candidate_depth){target=\\_blank}: the number of parablocks a collator can produce that are not yet included in the relay chain. A value of `2` means that there can be a maximum of 3 unincluded parablocks at any given time.\n- [**`allowed_ancestry_len`**](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/relay_chain/struct.AsyncBackingParams.html#structfield.allowed_ancestry_len){target=\\_blank}: the oldest relay parent a parablock can be built on top of. A value of `1` means collators can start building blocks 6 seconds in advance."}
{"page_id": "reference-parachains-consensus-async-backing", "page_title": "Asynchronous Backing", "index": 2, "depth": 2, "title": "Synchronous VS. Asynchronous Processing", "anchor": "synchronous-vs-asynchronous-processing", "start_char": 2044, "end_char": 8095, "estimated_token_count": 1385, "token_estimator": "heuristic-v1", "text": "## Synchronous VS. Asynchronous Processing\n\nThe Polkadot-parachain protocol originally operated in synchronous mode, where both collators and validators drew context exclusively from the relay parent of the prior parablock, which lives on the relay chain. This made the Backing and Generation steps tightly coupled to the prior parablock completing the entire inclusion pipeline. As a result, one parablock could only be processed every other relay block, with just 0.5 seconds assigned for execution.\n\n```mermaid\n---\n    displayMode: compact\n    config:\n        themeCSS: \"\n            #item1 { fill: #450693; stroke: #450693; } \\n\n            #item2 { fill: #8C00FF; stroke: #8C00FF; } \\n\n            #item3 { fill: #FFC400; stroke: #FFC400; } \\n\n            #r     { fill: #eb4172; stroke:none; font-size: 20px; } \\n\n            svg text { font-size: 20px !important; } \\n\n            svg .sectionTitle { font-size: 20px !important; } \\n    #p1padTop { display: none; } \\n\n\n            /* Hide ALL task labels by default */\n            text.taskText,\n            text.taskTextOutside,\n            [class*='taskText'] tspan { display: none !important; } \\n\n\n            /* Show labels for the 'r' group (inside or outside, incl. tspans) */\n            text.taskText[id^='r'],\n            text.taskTextOutside[id^='r'],\n            text[id^='r'] tspan { display: inline !important; font-size: 20px; fill: var(--white) !important; } \\n\n\n            /* Keep section titles styled */\n            .sectionTitle { fill: var(--md-default-fg-color) !important; font-weight: 700; font-size: 18px; } \\n\n\n            /* Hide the first two section titles (F1, F2). Change indexes if needed. */\n            .sectionTitle:nth-of-type(1),\n            .sectionTitle:nth-of-type(2) { display: none !important; } \\n\n\n            /* Also hide SPACING row labels on the left */\n            text.taskTextOutside[id^='p1padTop'] { display: none !important; } \\n\n\n            .grid .tick text { fill: var(--md-default-fg-color) !important; font-size: 20px !important; }\n\n        \"\n        themeVariables:\n            sectionBkgColor: '#fff'\n        gantt:\n            numberSectionStyles: 1\n            barHeight: 70\n            gridLineStartPadding: 100\n---\n%%{init: {\"gantt\": {\"barHeight\": 70 }}}%%\ngantt\n    dateFormat YYYY\n    axisFormat %y\n    tickInterval '10year'\n\n    section F1\n    R1 : r, 1905, 1907\n    R2 : r, 1911, 1913\n    R3 : r, 1917, 1919\n    R4 : r, 1923, 1925\n\n    section F2\n    SPACING : p1padTop, 1901, 1924\n\n    section P1\n    X          : item1, 1900, 1901\n    Backing    : item2, 1901, 1906\n    Inclusion  : item3, 1906, 1912\n\n    section P2\n    X          : item1, 1912, 1913\n    Backing    : item2, 1913, 1918\n    Inclusion  : item3, 1918, 1924\n    \n\n```\n\nThe modern protocol now uses asynchronous backing, where both collators and validators have access to [unincluded segments](/reference/parachains/consensus/inclusion-pipeline){target=\\_blank} as an additional context source. The Backing and Generation steps are no longer coupled to the prior block completing the full inclusion pipeline. Instead, the prior parablock only needs to complete the generation step and be added to the Unincluded Segments before the next parablock can begin the Backing and Generation steps.\n\nThis results in one parablock being processed every relay block (instead of every other relay block), and allows for more time to execute during the Generation step (0.5s â†’ 2s).\n\n```mermaid\n---\n    displayMode: compact\n    config:\n        themeCSS: \"\n            #item1 { fill: #450693; stroke: #450693; } \\n\n            #item2 { fill: #8C00FF; stroke: #8C00FF; } \\n\n            #item3 { fill: #FFC400; stroke: #FFC400; } \\n\n            #r     { fill: #eb4172; stroke:none; font-size: 20px; } \\n\n            svg text { font-size: 20px !important; } \\n\n            svg .sectionTitle { font-size: 20px !important; } \\n    #p1padTop { display: none; } \\n\n\n            /* Hide ALL task labels by default */\n            text.taskText,\n            text.taskTextOutside,\n            [class*='taskText'] tspan { display: none !important; } \\n\n\n            /* Show labels for the 'r' group (inside or outside, incl. tspans) */\n            text.taskText[id^='r'],\n            text.taskTextOutside[id^='r'],\n            text[id^='r'] tspan { display: inline !important; font-size: 20px; color: var(--white) !important; } \\n\n\n            /* Keep section titles styled */\n            .sectionTitle { fill: var(--md-default-fg-color) !important; font-weight: 700; font-size: 18px; } \\n\n\n            /* Hide the first two section titles (F1, F2). Change indexes if needed. */\n            .sectionTitle:nth-of-type(1),\n            .sectionTitle:nth-of-type(2) { display: none !important; } \\n\n\n            /* Also hide SPACING row labels on the left */\n            text.taskTextOutside[id^='p1padTop'] { display: none !important; } \\n\n\n            .taskTextOutsideRight { fill: var(--md-default-fg-color) !important; font-size: 20px !important; }\n\n            .grid .tick text { fill: var(--md-default-fg-color) !important; font-size: 20px !important; }\n        \"\n        themeVariables:\n            sectionBkgColor: '#fff'\n        gantt:\n            numberSectionStyles: 1\n            barHeight: 70\n            gridLineStartPadding: 100\n---\n%%{init: {\"gantt\": {\"barHeight\": 70 }}}%%\ngantt\n    dateFormat YYYY\n    axisFormat %y\n    tickInterval '10year'\n\n    section F1\n    R1 : r, 1905, 1907\n    R2 : r, 1911, 1913\n    R3 : r, 1917, 1919\n    R4 : r, 1923, 1925\n    R5 : r, 1929, 1931\n\n    section F2\n    SPACING : p1padTop, 1901, 1930\n\n    section P1\n    X         : item1, 1900, 1902\n    Backing   : item2, 1902, 1912\n    Inclusion : item3, 1912, 1918\n\n    section P2\n    X         : item1, 1906, 1908\n    Backing   : item2, 1908, 1918\n    Inclusion : item3, 1918, 1924\n    \n    section P3\n    X         : item1, 1912, 1914\n    Backing   : item2, 1914, 1924f\n    Inclusion : item3, 1924, 1930\n\n    section P4\n    X         : item1, 1918, 1920\n    Backing   : item2, 1920, 1930\n```"}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 842, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's architecture delivers scalability and security through its shared security model, where the relay chain coordinates and validates multiple parallel chains. \n\nElastic scaling enhances this architecture by allowing parachains to utilize multiple computational cores simultaneously, breaking the previous 1:1 relationship between parachain and relay chain blocks.\n\nThis technical advancement enables parachains to process multiple blocks within a single relay chain block, significantly increasing throughput capabilities. By leveraging [Agile Coretime](/polkadot-protocol/architecture/polkadot-chain/agile-coretime){target=\\_blank}, parachains can dynamically adjust their processing capacity based on demand, creating an efficient and responsive infrastructure for high-throughput applications."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 1, "depth": 2, "title": "How Elastic Scaling Works", "anchor": "how-elastic-scaling-works", "start_char": 842, "end_char": 4212, "estimated_token_count": 710, "token_estimator": "heuristic-v1", "text": "## How Elastic Scaling Works\n\nElastic scaling enables parachains to process multiple blocks in parallel by utilizing additional cores on the relay chain. This section provides a technical analysis of the performance advantages and details of the implementation.\n\nConsider a parachain that needs to process four consecutive parablocks. With traditional single-core allocation, the validation process follows a strictly sequential pattern. Each parablock undergoes a two-phase process on the relay chain:\n\n1. **Backing phase**: Validators create and distribute validity statements.\n2. **Inclusion phase**: The parablock is included in the relay chain after availability verification.\n\nThroughout the following diagrams, specific notation is used to represent different components of the system:\n\n- **R1, R2, ...**: Relay chain blocks (produced at ~6-second intervals).\n- **P1, P2, ...**: Parachain blocks that need validation and inclusion.\n- **C1, C2, ...**: Cores on the relay chain.\n\nIn the single-core scenario (assuming a 6-second relay chain block time), processing four parablocks requires approximately 30 seconds:\n\n```mermaid\nsequenceDiagram\n    participant R1 as R1\n    participant R2 as R2\n    participant R3 as R3\n    participant R4 as R4\n    participant R5 as R5\n    \n    Note over R1,R5: Single Core Scenario\n    \n    rect rgb(200, 220, 240)\n    Note right of R1: Core C1\n    R1->>R1: Back P1\n    R2->>R2: Include P1\n    R2->>R2: Back P2\n    R3->>R3: Include P2\n    R3->>R3: Back P3\n    R4->>R4: Include P3\n    R4->>R4: Back P4\n    R5->>R5: Include P4\n    end\n```\n\nWith elastic scaling utilizing two cores simultaneously, the same four parablocks can be processed in approximately 18 seconds:\n\n```mermaid\nsequenceDiagram\n    participant R1 as R1\n    participant R2 as R2\n    participant R3 as R3\n    participant R4 as R4\n    participant R5 as R5\n    \n    Note over R1,R3: Multi-Core Scenario\n    \n    rect rgb(200, 220, 240)\n    Note right of R1: Core C1\n    R1->>R1: Back P1\n    R2->>R2: Include P1\n    R2->>R2: Back P2\n    R3->>R3: Include P2\n    end\n    \n    rect rgb(220, 200, 240)\n    Note right of R1: Core C2\n    R1->>R1: Back P3\n    R2->>R2: Include P3\n    R2->>R2: Back P4\n    R3->>R3: Include P4\n    end\n```\n\nTo help interpret the sequence diagrams above, note the following key elements:\n\n- The horizontal axis represents time progression through relay chain blocks (R1-R5).\n- Each colored rectangle shows processing on a specific core (C1 or C2).\n- In the single-core scenario, all blocks must be processed sequentially on one core.\n- In the multi-core scenario, blocks are processed in parallel across multiple cores, reducing total time.\n\nThe relay chain processes these multiple parablocks as independent validation units during the backing, availability, and approval phases. However, during inclusion, it verifies that their state roots align properly to maintain chain consistency.\n\nFrom an implementation perspective:\n\n- **Parachain side**: Collators must increase their block production rate to utilize multiple cores fully.\n- **Validation process**: Each core operates independently, but with coordinated state verification.\n- **Resource management**: Cores are dynamically allocated based on parachain requirements.\n- **State consistency**: While backed and processed in parallel, the parablocks maintain sequential state transitions."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 2, "depth": 2, "title": "Benefits of Elastic Scaling", "anchor": "benefits-of-elastic-scaling", "start_char": 4212, "end_char": 6001, "estimated_token_count": 288, "token_estimator": "heuristic-v1", "text": "## Benefits of Elastic Scaling\n\n- **Increased throughput**: Multiple concurrent cores enable parachains to process transactions at multiples of their previous capacity. By allowing multiple parachain blocks to be validated within each relay chain block cycle, applications can achieve significantly higher transaction volumes.\n\n- **Lower latency**: Transaction finality improves substantially with multi-core processing. Parachains currently achieve 2-second latency with three cores, with projected improvements to 500ms using 12 cores, enabling near-real-time application responsiveness.\n\n- **Resource efficiency**: Applications acquire computational resources precisely matched to their needs, eliminating wasteful over-provisioning. Coretime can be purchased at granular intervals (blocks, hours, days), creating cost-effective operations, particularly for applications with variable transaction patterns.\n\n- **Scalable growth**: New applications can launch with minimal initial resource commitment and scale dynamically as adoption increases. This eliminates the traditional paradox of either over-allocating resources (increasing costs) or under-allocating (degrading performance) during growth phases.\n\n- **Workload distribution**: Parachains intelligently distribute workloads across cores during peak demand periods and release resources when traffic subsides. Paired with secondary coretime markets, this ensures maximum resource utilization across the entire network ecosystem.\n\n- **Reliable performance**: End-users experience reliable application performance regardless of network congestion levels. Applications maintain responsiveness even during traffic spikes, eliminating performance degradation that commonly impacts blockchain applications during high-demand periods."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 3, "depth": 2, "title": "Use Cases", "anchor": "use-cases", "start_char": 6001, "end_char": 6369, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Use Cases\n\nElastic scaling enables applications to dynamically adjust their resource consumption based on real-time demand. This is especially valuable for decentralized applications where usage patterns can be highly variable. The following examples illustrate common scenarios where elastic scaling delivers significant performance and cost-efficiency benefits."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 4, "depth": 3, "title": "Handling Sudden Traffic Spikes", "anchor": "handling-sudden-traffic-spikes", "start_char": 6369, "end_char": 6786, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "### Handling Sudden Traffic Spikes\n\nMany decentralized applications experience unpredictable, high-volume traffic bursts, especially in gaming, DeFi protocols, NFT auctions, messaging platforms, and social media. Elastic scaling allows these systems to acquire additional coretime during peak usage and release it during quieter periods, ensuring responsiveness without incurring constant high infrastructure costs."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 5, "depth": 3, "title": "Supporting Early-Stage Growth", "anchor": "supporting-early-stage-growth", "start_char": 6786, "end_char": 7168, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### Supporting Early-Stage Growth\n\nStartups and new projects often begin with uncertain or volatile demand. With elastic scaling, teams can launch with minimal compute resources (e.g., a single core) and gradually scale as adoption increases. This prevents overprovisioning and enables cost-efficient growth until the application is ready for more permanent or horizontal scaling."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 6, "depth": 3, "title": "Scaling Massive IoT Networks", "anchor": "scaling-massive-iot-networks", "start_char": 7168, "end_char": 7556, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "### Scaling Massive IoT Networks\n\nInternet of Things (IoT) applications often involve processing data from millions of devices in real time. Elastic scaling supports this need by enabling high-throughput transaction processing as demand fluctuates. Combined with Polkadotâ€™s shared security model, it provides a reliable and privacy-preserving foundation for large-scale IoT deployments."}
{"page_id": "reference-parachains-consensus-elastic-scaling", "page_title": "Elastic Scaling", "index": 7, "depth": 3, "title": "Powering Real-Time, Low-Latency Systems", "anchor": "powering-real-time-low-latency-systems", "start_char": 7556, "end_char": 7871, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Powering Real-Time, Low-Latency Systems\n\nApplications like payment processors, trading platforms, gaming engines, or real-time data feeds require fast, consistent performance. Elastic scaling can reduce execution latency during demand spikes, helping ensure low-latency, reliable service even under heavy load."}
{"page_id": "reference-parachains-consensus-inclusion-pipeline", "page_title": "Inclusion Pipeline", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 1086, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe inclusion pipeline is the multi-stage process through which every parachain block (parablock) is validated and secured before being finalized in the Polkadot relay chain. This pipeline ensures that all parachain blocks meet validity requirements through progressive verification by multiple sets of validators.\n\nThe pipeline exists to provide Polkadot's security guarantees, rather than relying on a single validator group. Each parablock passes through multiple validation stages with different validator sets, ensuring that invalid blocks cannot be finalized even if some validators are malicious or compromised.\n\nWhether a parachain uses synchronous or [asynchronous backing](/reference/parachains/consensus/async-backing){target=\\_blank}, all parablocks follow the same inclusion pipeline. The difference is in the timing: asynchronous backing allows multiple blocks to be at different stages of the pipeline simultaneously (pipelining), while synchronous backing processes one block through the entire pipeline before starting the next."}
{"page_id": "reference-parachains-consensus-inclusion-pipeline", "page_title": "Inclusion Pipeline", "index": 1, "depth": 2, "title": "Pipeline Stages", "anchor": "pipeline-stages", "start_char": 1086, "end_char": 1604, "estimated_token_count": 156, "token_estimator": "heuristic-v1", "text": "## Pipeline Stages\n\nThe inclusion pipeline consists of three main stages:\n\n```mermaid\n%%{init: {\"flowchart\": {\"nodeSpacing\": 40, \"rankSpacing\": 60}}}%%\nflowchart LR\n  %% Keep the pipeline on one row (container is hidden)\n  subgraph Row[\" \"]\n    direction LR\n    G[\"Generation\"] --> B[\"Backing\"] --> I[\"Inclusion\"]\n  end\n  style Row fill:none,stroke:none\n\n  %% Context: plain text (no box) pointing to both G and B\n  C[\"Context\"]:::nobox\n  C -.-> G\n  C -.-> B\n\n  classDef nobox fill:none,stroke:none,color:inherit;\n```"}
{"page_id": "reference-parachains-consensus-inclusion-pipeline", "page_title": "Inclusion Pipeline", "index": 2, "depth": 3, "title": "Context", "anchor": "context", "start_char": 1604, "end_char": 2583, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "### Context\n\nTo build a parablock during the generation and backing stages, collators and validators require access to the state context of the parachain. This context is derived from two sources:\n\n  - **Relay Parent**: The relay chain block to which the parablock is anchored. Note that the relay parent of a parablock is always different from the relay chain block that eventually includes it. This context source resides on the relay chain.\n\n  - **Unincluded Segments**: Chains of candidate parablocks that have not yet been included in the relay chain. These segments represent sequences of block ancestors and may contain candidates at any stage pre-inclusion. A key feature enabled by [async backing](/reference/parachains/consensus/async-backing){target=\\_blank} is that collators can build new parablocks on top of these unincluded ancestors rather than being limited to ancestors already included in the relay chain state. This context source resides on the collators."}
{"page_id": "reference-parachains-consensus-inclusion-pipeline", "page_title": "Inclusion Pipeline", "index": 3, "depth": 3, "title": "Generation", "anchor": "generation", "start_char": 2583, "end_char": 3064, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "### Generation\n\nCollators execute their blockchain core functionality to generate a new block, producing a [proof-of-validity](https://wiki.polkadot.com/general/glossary/#proof-of-validity){target=\\_blank} (PoV), which is passed to validators selected for backing. The PoV is composed of:\n\n  - A list of state transitions called the **block candidate**\n  - The values in the parachain's database that the block modifies\n  - The hashes of the unaffected points in the Merkle tree"}
{"page_id": "reference-parachains-consensus-inclusion-pipeline", "page_title": "Inclusion Pipeline", "index": 4, "depth": 3, "title": "Backing", "anchor": "backing", "start_char": 3064, "end_char": 3623, "estimated_token_count": 124, "token_estimator": "heuristic-v1", "text": "### Backing \n\nA subset of active validators verify that the parablock follows the state transition rules of the parachain and sign a [validity statement](https://paritytech.github.io/polkadot-sdk/book/types/backing.html?#validity-attestation){target=\\_blank} about the PoV which can have a positive or negative outcome. With enough positive statements (at least 2/3 of assigned validators), the candidate is considered backable. It is then noted in a fork on the relay chain, at which point it is considered backed, ready for the next stage of the pipeline."}
{"page_id": "reference-parachains-consensus-inclusion-pipeline", "page_title": "Inclusion Pipeline", "index": 5, "depth": 3, "title": "Inclusion", "anchor": "inclusion", "start_char": 3623, "end_char": 3982, "estimated_token_count": 96, "token_estimator": "heuristic-v1", "text": "### Inclusion\n\n Validators gossip [erasure code chunks](https://paritytech.github.io/polkadot-sdk/book/types/availability.html#erasure-chunk){target=\\_blank} and put the parablock through the final [approval process](https://paritytech.github.io/polkadot-sdk/book/protocol-approval.html){target=\\_blank} before it is considered *included* in the relay chain."}
{"page_id": "reference-parachains-consensus", "page_title": "Parachain Consensus", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 23, "end_char": 936, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nParachains are independent blockchains built with the Polkadot SDK, designed to leverage Polkadotâ€™s relay chain for shared security and transaction finality. These specialized chains operate as part of Polkadotâ€™s execution sharding model, where each parachain manages its own state and transactions while relying on the relay chain for validation and consensus.\n\nAt the core of parachain functionality are collators, specialized nodes that sequence transactions into blocks and maintain the parachainâ€™s state. Collators optimize Polkadotâ€™s architecture by offloading state management from the relay chain, allowing relay chain validators to focus solely on validating parachain blocks.\n\nThis guide explores how parachain consensus works, including the roles of collators and validators, and the steps involved in securing parachain blocks within Polkadotâ€™s scalable and decentralized framework."}
{"page_id": "reference-parachains-consensus", "page_title": "Parachain Consensus", "index": 1, "depth": 2, "title": "The Role of Collators", "anchor": "the-role-of-collators", "start_char": 936, "end_char": 1584, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "## The Role of Collators\n\nCollators are responsible for sequencing end-user transactions into blocks and maintaining the current state of their respective parachains. Their role is akin to Ethereumâ€™s sequencers but optimized for Polkadot's architecture.\n\nKey responsibilities include:\n\n- **Transaction sequencing**: Organizing transactions into [Proof of Validity (PoV)](https://wiki.polkadot.com/general/glossary/#proof-of-validity){target=\\_blank} blocks.\n- **State management**: Maintaining parachain states without burdening the relay chain validators.\n- **Consensus participation**: Sending PoV blocks to relay chain validators for approval."}
{"page_id": "reference-parachains-consensus", "page_title": "Parachain Consensus", "index": 2, "depth": 2, "title": "Consensus and Validation", "anchor": "consensus-and-validation", "start_char": 1584, "end_char": 2553, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Consensus and Validation\n\nParachain consensus operates in tandem with the relay chain, leveraging [Nominated Proof of Stake (NPoS)](/reference/glossary/#nominated-proof-of-stake-npos){target=\\_blank} for shared security. The process ensures parachain transactions achieve finality through the following steps:\n\n1. **Packaging transactions**: Collators bundle transactions into PoV blocks (parablocks).\n2. **Submission to validator**: Parablocks are submitted to a randomly selected subset of relay chain validators, known as paravalidators.\n3. **Validation of PoV Blocks**: Paravalidators use the parachainâ€™s state transition function (already available on the relay chain) to verify transaction validity.\n4. **Backing and inclusion**: If a sufficient number of positive validations are received, the parablock is backed and included via a para-header on the relay chain.\n\nThe following sections describe the actions taking place during each stage of the process."}
{"page_id": "reference-parachains-consensus", "page_title": "Parachain Consensus", "index": 3, "depth": 3, "title": "Path of a Parachain Block", "anchor": "path-of-a-parachain-block", "start_char": 2553, "end_char": 5982, "estimated_token_count": 606, "token_estimator": "heuristic-v1", "text": "### Path of a Parachain Block\n\nPolkadot achieves scalability through execution sharding, where each parachain operates as an independent shard with its own blockchain and state. Shared security for all parachains is provided by the relay chain, powered by Nominated Proof of Stake (NPoS). This framework allows parachains to focus on transaction processing and state management, while the relay chain ensures validation and finality.\n\nThe journey of parachain transactions to reach consensus and finality can be described as follows:\n\n- Collators and parablocks:\n\n    - Collators, specialized nodes on parachains, package transactions into Proof of Validity (PoV) blocks, also called parablocks.\n    - These parablocks are sent to a subset of relay chain validators, known as paravalidators, for validation.\n    - The parachain's state transition function (Wasm blob) is not re-sent, as it is already stored on the relay chain.\n\n```mermaid\nflowchart TB\n    %% Subgraph: Parachain\n    subgraph Parachain\n        direction LR\n        Txs[Network Transactions]\n        Collator[Collator Node]\n        ParaBlock[ParaBlock + PoV]\n        Txs -->|Package Transactions| Collator\n        Collator -->|Create| ParaBlock\n    end\n\n    subgraph Relay[\"Relay Chain\"]\n        ParaValidator\n    end\n\n    %% Main Flow\n    Parachain -->|Submit To| Relay\n```\n\n- Validation by paravalidators:\n\n    - Paravalidators are groups of approximately five relay chain validators, randomly assigned to parachains and shuffled every minute.\n    - Each paravalidator downloads the parachain's Wasm blob and validates the parablock by ensuring all transactions comply with the parachainâ€™s state transition rules.\n    - Paravalidators sign positive or negative validation statements based on the blockâ€™s validity.\n\n- Backing and approval:\n\n    - If a parablock receives sufficient positive validation statements, it is backed and included on the relay chain as a para-header.\n    - An additional approval process resolves disputes. If a parablock contains invalid transactions, additional validators are tasked with verification.\n    - Validators who back invalid parablocks are penalized through slashing, creating strong incentives for honest behavior.\n\n```mermaid\nflowchart\n    subgraph RelayChain[\"Relay Chain\"]\n        direction TB\n        subgraph InitialValidation[\"Initial Validation\"]\n            direction LR\n            PValidators[ParaValidators]\n            Backing[Backing<br>Process]\n            Header[Submit Para-header<br>on Relay Chain]\n        end\n        subgraph Secondary[\"Secondary Validation\"]\n            Approval[Approval<br>Process]\n            Dispute[Dispute<br>Resolution]\n            Slashing[Slashing<br>Mechanism]\n        end\n        \n    end\n\n\n    %% Validation Process\n    PValidators -->|Download<br>Wasm<br>Validate Block| Backing\n    Backing -->|If Valid<br>Signatures| Header\n    InitialValidation -->|Additional<br>Verification| Secondary\n    \n    %% Dispute Flow\n    Approval -->|If Invalid<br>Detected| Dispute\n    Dispute -->|Penalize<br>Dishonest<br>Validators| Slashing\n```\n\nIt is important to understand that relay chain blocks do not store full parachain blocks (parablocks). Instead, they include para-headers, which serve as summaries of the backed parablocks. The complete parablock remains within the parachain network, maintaining its autonomy while relying on the relay chain for validation and finality."}
{"page_id": "reference-parachains-consensus", "page_title": "Parachain Consensus", "index": 4, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5982, "end_char": 6874, "estimated_token_count": 217, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nExplore more about Parachain consensus through these resources:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge learn\">Learn</span> __Elastic Scaling__\n\n    ---\n\n    Learn more about how Elastic Scaling boosts parachain performance.\n\n    [:octicons-arrow-right-24: Elastic Scaling](/reference/parachains/consensus/elastic-scaling/){target=\\_blank}\n\n-   <span class=\"badge learn\">Learn</span> __Asynchronous Backing__\n\n    ---\n\n    Read about pipelining parachain block production via Async Backing.\n\n    [:octicons-arrow-right-24: Asynchronous Backing](/reference/parachains/consensus/async-backing/){target=\\_blank}\n\n\n\n-   <span class=\"badge external\">Learn</span> __Parachain Wiki__\n\n    ---\n\n    Explore more on Parachains in the Wiki.\n\n    [:octicons-arrow-right-24: Parachains](https://wiki.polkadot.com/learn/learn-parachains/){target=\\_blank}\n\n\n\n</div>"}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 525, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nCryptography forms the backbone of blockchain technology, providing the mathematical verifiability crucial for consensus systems, data integrity, and user security. While a deep understanding of the underlying mathematical processes isn't necessary for most blockchain developers, grasping the fundamental applications of cryptography is essential. This page comprehensively overviews cryptographic implementations used across Polkadot SDK-based chains and the broader blockchain ecosystem."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 1, "depth": 2, "title": "Hash Functions", "anchor": "hash-functions", "start_char": 525, "end_char": 1170, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "## Hash Functions\n\nHash functions are fundamental to blockchain technology, creating a unique digital fingerprint for any piece of data, including simple text, images, or any other form of file. They map input data of any size to a fixed-size output (typically 32 bytes) using complex mathematical operations. Hashing is used to verify data integrity, create digital signatures, and provide a secure way to store passwords. This form of mapping is known as the [\"pigeonhole principle,\"](https://en.wikipedia.org/wiki/Pigeonhole_principle){target=\\_blank} it is primarily implemented to efficiently and verifiably identify data from large sets."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 2, "depth": 3, "title": "Key Properties of Hash Functions", "anchor": "key-properties-of-hash-functions", "start_char": 1170, "end_char": 1720, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Key Properties of Hash Functions\n\n- **Deterministic**: The same input always produces the same output.\n- **Quick computation**: It's easy to calculate the hash value for any given input.\n- **Pre-image resistance**: It's infeasible to generate the input data from its hash.\n- **Small changes in input yield large changes in output**: Known as the [\"avalanche effect\"](https://en.wikipedia.org/wiki/Avalanche_effect){target=\\_blank}.\n- **Collision resistance**: The probabilities are extremely low to find two different inputs with the same hash."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 3, "depth": 3, "title": "Blake2", "anchor": "blake2", "start_char": 1720, "end_char": 2257, "estimated_token_count": 126, "token_estimator": "heuristic-v1", "text": "### Blake2\n\nThe Polkadot SDK utilizes Blake2, a state-of-the-art hashing method that offers:\n\n- Equal or greater security compared to [SHA-2](https://en.wikipedia.org/wiki/SHA-2){target=\\_blank}.\n- Significantly faster performance than other algorithms.\n\nThese properties make Blake2 ideal for blockchain systems, reducing sync times for new nodes and lowering the resources required for validation. For detailed technical specifications about Blake2, see the [official Blake2 paper](https://www.blake2.net/blake2.pdf){target=\\_blank}."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 4, "depth": 2, "title": "Types of Cryptography", "anchor": "types-of-cryptography", "start_char": 2257, "end_char": 2412, "estimated_token_count": 22, "token_estimator": "heuristic-v1", "text": "## Types of Cryptography\n\nThere are two different ways that cryptographic algorithms are implemented: symmetric cryptography and asymmetric cryptography."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 5, "depth": 3, "title": "Symmetric Cryptography", "anchor": "symmetric-cryptography", "start_char": 2412, "end_char": 3256, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "### Symmetric Cryptography\n\nSymmetric encryption is a branch of cryptography that isn't based on one-way functions, unlike asymmetric cryptography. It uses the same cryptographic key to encrypt plain text and decrypt the resulting ciphertext.\n\nSymmetric cryptography is a type of encryption that has been used throughout history, such as the Enigma Cipher and the Caesar Cipher. It is still widely used today and can be found in Web2 and Web3 applications alike. There is only one single key, and a recipient must also have access to it to access the contained information.\n\n#### Advantages {: #symmetric-advantages }\n\n- Fast and efficient for large amounts of data.\n- Requires less computational power.\n\n#### Disadvantages {: #symmetric-disadvantages }\n\n- Key distribution can be challenging.\n- Scalability issues in systems with many users."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 6, "depth": 3, "title": "Asymmetric Cryptography", "anchor": "asymmetric-cryptography", "start_char": 3256, "end_char": 4221, "estimated_token_count": 182, "token_estimator": "heuristic-v1", "text": "### Asymmetric Cryptography\n\nAsymmetric encryption is a type of cryptography that uses two different keys, known as a keypair: a public key, used to encrypt plain text, and a private counterpart, used to decrypt the ciphertext.\n\nThe public key encrypts a fixed-length message that can only be decrypted with the recipient's private key and, sometimes, a set password. The public key can be used to cryptographically verify that the corresponding private key was used to create a piece of data without compromising the private key, such as with digital signatures. This has obvious implications for identity, ownership, and properties and is used in many different protocols across Web2 and Web3.\n\n#### Advantages {: #asymmetric-advantages }\n\n- Solves the key distribution problem.\n- Enables digital signatures and secure key exchange.\n\n#### Disadvantages {: #asymmetric-disadvantages }\n\n- Slower than symmetric encryption.\n- Requires more computational resources."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 7, "depth": 3, "title": "Trade-offs and Compromises", "anchor": "trade-offs-and-compromises", "start_char": 4221, "end_char": 5014, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "### Trade-offs and Compromises\n\nSymmetric cryptography is faster and requires fewer bits in the key to achieve the same level of security that asymmetric cryptography provides. However, it requires a shared secret before communication can occur, which poses issues to its integrity and a potential compromise point. On the other hand, asymmetric cryptography doesn't require the secret to be shared ahead of time, allowing for far better end-user security.\n\nHybrid symmetric and asymmetric cryptography is often used to overcome the engineering issues of asymmetric cryptography, as it is slower and requires more bits in the key to achieve the same level of security. It encrypts a key and then uses the comparatively lightweight symmetric cipher to do the \"heavy lifting\" with the message."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 8, "depth": 2, "title": "Digital Signatures", "anchor": "digital-signatures", "start_char": 5014, "end_char": 6403, "estimated_token_count": 266, "token_estimator": "heuristic-v1", "text": "## Digital Signatures\n\nDigital signatures are a way of verifying the authenticity of a document or message using asymmetric keypairs. They are used to ensure that a sender or signer's document or message hasn't been tampered with in transit, and for recipients to verify that the data is accurate and from the expected sender.\n\nSigning digital signatures only requires a low-level understanding of mathematics and cryptography. For a conceptual example -- when signing a check, it is expected that it cannot be cashed multiple times. This isn't a feature of the signature system but rather the check serialization system. The bank will check that the serial number on the check hasn't already been used. Digital signatures essentially combine these two concepts, allowing the signature to provide the serialization via a unique cryptographic fingerprint that cannot be reproduced.\n\nUnlike pen-and-paper signatures, knowledge of a digital signature cannot be used to create other signatures. Digital signatures are often used in bureaucratic processes, as they are more secure than simply scanning in a signature and pasting it onto a document.\n\nPolkadot SDK provides multiple different cryptographic schemes and is generic so that it can support anything that implements the [`Pair` trait](https://paritytech.github.io/polkadot-sdk/master/sp_core/crypto/trait.Pair.html){target=\\_blank}."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 9, "depth": 3, "title": "Example of Creating a Digital Signature", "anchor": "example-of-creating-a-digital-signature", "start_char": 6403, "end_char": 6977, "estimated_token_count": 117, "token_estimator": "heuristic-v1", "text": "### Example of Creating a Digital Signature\n\nThe process of creating and verifying a digital signature involves several steps:\n\n1. The sender creates a hash of the message.\n2. The hash is encrypted using the sender's private key, creating the signature.\n3. The message and signature are sent to the recipient.\n4. The recipient decrypts the signature using the sender's public key.\n5. The recipient hashes the received message and compares it to the decrypted hash.\n\nIf the hashes match, the signature is valid, confirming the message's integrity and the sender's identity."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 10, "depth": 2, "title": "Elliptic Curve", "anchor": "elliptic-curve", "start_char": 6977, "end_char": 7869, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Elliptic Curve\n\nBlockchain technology requires the ability to have multiple keys creating a signature for block proposal and validation. To this end, Elliptic Curve Digital Signature Algorithm (ECDSA) and Schnorr signatures are two of the most commonly used methods. While ECDSA is a far simpler implementation, Schnorr signatures are more efficient when it comes to multi-signatures.\n\nSchnorr signatures bring some noticeable features over the ECDSA/EdDSA schemes:\n\n- It is better for hierarchical deterministic key derivations.\n- It allows for native multi-signature through [signature aggregation](https://bitcoincore.org/en/2017/03/23/schnorr-signature-aggregation/){target=\\_blank}.\n- It is generally more resistant to misuse.\n\nOne sacrifice that is made when using Schnorr signatures over ECDSA is that both require 64 bytes, but only ECDSA signatures communicate their public key."}
{"page_id": "reference-parachains-cryptography", "page_title": "Cryptography", "index": 11, "depth": 3, "title": "Various Implementations", "anchor": "various-implementations", "start_char": 7869, "end_char": 8860, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "### Various Implementations\n\n- **[ECDSA](https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm){target=\\_blank}**: Polkadot SDK provides an ECDSA signature scheme using the [secp256k1](https://en.bitcoin.it/wiki/Secp256k1){target=\\_blank} curve. This is the same cryptographic algorithm used to secure [Bitcoin](https://en.wikipedia.org/wiki/Bitcoin){target=\\_blank} and [Ethereum](https://en.wikipedia.org/wiki/Ethereum){target=\\_blank}.\n\n- **[Ed25519](https://en.wikipedia.org/wiki/EdDSA#Ed25519){target=\\_blank}**: An EdDSA signature scheme using [Curve25519](https://en.wikipedia.org/wiki/Curve25519){target=\\_blank}. It is carefully engineered at several levels of design and implementation to achieve very high speeds without compromising security.\n\n- **[SR25519](https://research.web3.foundation/Polkadot/security/keys/accounts-more){target=\\_blank}**: Based on the same underlying curve as Ed25519. However, it uses Schnorr signatures instead of the EdDSA scheme."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 1595, "estimated_token_count": 332, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot SDK uses a lightweight and efficient encoding/decoding mechanism to optimize data transmission across the network. This mechanism, known as the _SCALE_ codec, is used for serializing and deserializing data.\n\nThe SCALE codec enables communication between the runtime and the outer node. This mechanism is designed for high-performance, copy-free data encoding and decoding in resource-constrained environments like the Polkadot SDK [Wasm runtime](/develop/parachains/deployment/build-deterministic-runtime/#introduction){target=\\_blank}.\n\nIt is not self-describing, meaning the decoding context must fully know the encoded data types. \n\nParity's libraries utilize the [`parity-scale-codec`](https://github.com/paritytech/parity-scale-codec){target=\\_blank} crate (a Rust implementation of the SCALE codec) to handle encoding and decoding for interactions between RPCs and the runtime.\n\nThe `codec` mechanism is ideal for Polkadot SDK-based chains because:\n\n- It is lightweight compared to generic serialization frameworks like [`serde`](https://serde.rs/){target=\\_blank}, which add unnecessary bulk to binaries.\n- It doesnâ€™t rely on Rustâ€™s `libstd`, making it compatible with `no_std` environments like Wasm runtime.\n- It integrates seamlessly with Rust, allowing easy derivation of encoding and decoding logic for new types using `#[derive(Encode, Decode)]`.\n\nDefining a custom encoding scheme in the Polkadot SDK-based chains, rather than using an existing Rust codec library, is crucial for enabling cross-platform and multi-language support."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 1, "depth": 2, "title": "SCALE Codec", "anchor": "scale-codec", "start_char": 1595, "end_char": 1798, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## SCALE Codec\n\nThe codec is implemented using the following traits:\n\n- [`Encode`](#encode)\n- [`Decode`](#decode)\n- [`CompactAs`](#compactas)\n- [`HasCompact`](#hascompact)\n- [`EncodeLike`](#encodelike)"}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 2, "depth": 3, "title": "Encode", "anchor": "encode", "start_char": 1798, "end_char": 2875, "estimated_token_count": 291, "token_estimator": "heuristic-v1", "text": "### Encode\n\nThe [`Encode`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.Encode.html){target=\\_blank} trait handles data encoding into SCALE format and includes the following key functions:\n\n- **`size_hint(&self) -> usize`**: Estimates the number of bytes required for encoding to prevent multiple memory allocations. This should be inexpensive and avoid complex operations. Optional if the size isnâ€™t known.\n- **`encode_to<T: Output>(&self, dest: &mut T)`**: Encodes the data, appending it to a destination buffer.\n- **`encode(&self) -> Vec<u8>`**: Encodes the data and returns it as a byte vector.\n- **`using_encoded<R, F: FnOnce(&[u8]) -> R>(&self, f: F) -> R`**: Encodes the data and passes it to a closure, returning the result.\n- **`encoded_size(&self) -> usize`**: Calculates the encoded size. Should be used when the encoded data isnâ€™t required.\n\n!!!tip\n    For best performance, value types should override `using_encoded`, and allocating types should override `encode_to`. It's recommended to implement `size_hint` for all types where possible."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 3, "depth": 3, "title": "Decode", "anchor": "decode", "start_char": 2875, "end_char": 3216, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "### Decode\n\nThe [`Decode`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.Decode.html){target=\\_blank} trait handles decoding SCALE-encoded data back into the appropriate types:\n\n- **`fn decode<I: Input>(value: &mut I) -> Result<Self, Error>`**: Decodes data from the SCALE format, returning an error if decoding fails."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 4, "depth": 3, "title": "CompactAs", "anchor": "compactas", "start_char": 3216, "end_char": 3566, "estimated_token_count": 109, "token_estimator": "heuristic-v1", "text": "### CompactAs\n\nThe [`CompactAs`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.CompactAs.html){target=\\_blank} trait wraps custom types for compact encoding:\n\n- **`encode_as(&self) -> &Self::As`**: Encodes the type as a compact type.\n- **`decode_from(_: Self::As) -> Result<Self, Error>`**: decodes from a compact encoded type."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 5, "depth": 3, "title": "HasCompact", "anchor": "hascompact", "start_char": 3566, "end_char": 3752, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### HasCompact\n\nThe [`HasCompact`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.HasCompact.html){target=\\_blank} trait indicates a type supports compact encoding."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 6, "depth": 3, "title": "EncodeLike", "anchor": "encodelike", "start_char": 3752, "end_char": 4038, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### EncodeLike\n\nThe [`EncodeLike`](https://docs.rs/parity-scale-codec/latest/parity_scale_codec/trait.EncodeLike.html){target=\\_blank} trait is used to ensure multiple types that encode similarly are accepted by the same function. When using `derive`, it is automatically implemented."}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 7, "depth": 3, "title": "Data Types", "anchor": "data-types", "start_char": 4038, "end_char": 11053, "estimated_token_count": 1201, "token_estimator": "heuristic-v1", "text": "### Data Types\n\nThe table below outlines how the Rust implementation of the Parity SCALE codec encodes different data types.\n\n| Type                          | Description                                                                                                                                                                                                                                                                                                                | Example SCALE Decoded Value                                                                                                                        | SCALE Encoded Value                                                     |\n|-------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n| Boolean                       | Boolean values are encoded using the least significant bit of a single byte.                                                                                                                                                                                                                                               | `false` / `true`                                                                                                                                   | `0x00` / `0x01`                                                         |\n| Compact/general integers      | A \"compact\" or general integer encoding is sufficient for encoding large integers (up to 2^536) and is more efficient at encoding most values than the fixed-width version.                                                                                                                                                | `unsigned integer 0` / `unsigned integer 1` / `unsigned integer 42` / `unsigned integer 69` / `unsigned integer 65535` / `BigInt(100000000000000)` | `0x00` / `0x04` / `0xa8` / `0x1501` / `0xfeff0300` / `0x0b00407a10f35a` |\n| Enumerations (tagged-unions)  | A fixed number of variants, each mutually exclusive and potentially implying a further value or series of values. Encoded as the first byte identifying the index of the variant that the value is. Any further bytes are used to encode any data that the variant implies. Thus, no more than 256 variants are supported. | `Int(42)` and `Bool(true)` where `enum IntOrBool { Int(u8), Bool(bool) }`                                                                          | `0x002a` and `0x0101`                                                   |\n| Fixed-width integers          | Basic integers are encoded using a fixed-width little-endian (LE) format.                                                                                                                                                                                                                                                  | `signed 8-bit integer 69` / `unsigned 16-bit integer 42` / `unsigned 32-bit integer 16777215`                                                      | `0x45` / `0x2a00` / `0xffffff00`                                        |\n| Options                       | One or zero values of a particular type.                                                                                                                                                                                                                                                                                   | `Some` / `None`                                                                                                                                    | `0x01` followed by the encoded value / `0x00`                           |\n| Results                       | Results are commonly used enumerations which indicate whether certain operations were successful or unsuccessful.                                                                                                                                                                                                          | `Ok(42)` / `Err(false)`                                                                                                                            | `0x002a` / `0x0100`                                                     |\n| Strings                       | Strings are Vectors of bytes (Vec<u8>) containing a valid UTF8 sequence.                                                                                                                                                                                                                                                   |                                                                                                                                                    |                                                                         |\n| Structs                       | For structures, the values are named, but that is irrelevant for the encoding (names are ignored - only order matters).                                                                                                                                                                                                    | `SortedVecAsc::from([3, 5, 2, 8])`                                                                                                                 | `[3, 2, 5, 8] `                                                         |\n| Tuples                        | A fixed-size series of values, each with a possibly different but predetermined and fixed type. This is simply the concatenation of each encoded value.                                                                                                                                                                    | Tuple of compact unsigned integer and boolean: `(3, false)`                                                                                        | `0x0c00`                                                                |\n| Vectors (lists, series, sets) | A collection of same-typed values is encoded, prefixed with a compact encoding of the number of items, followed by each item's encoding concatenated in turn.                                                                                                                                                              | Vector of unsigned `16`-bit integers: `[4, 8, 15, 16, 23, 42]`                                                                                     | `0x18040008000f00100017002a00`                                          |"}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 8, "depth": 2, "title": "Encode and Decode Rust Trait Implementations", "anchor": "encode-and-decode-rust-trait-implementations", "start_char": 11053, "end_char": 12105, "estimated_token_count": 444, "token_estimator": "heuristic-v1", "text": "## Encode and Decode Rust Trait Implementations\n\nHere's how the `Encode` and `Decode` traits are implemented:\n\n\n```rust\nuse parity_scale_codec::{Encode, Decode};\n\n[derive(Debug, PartialEq, Encode, Decode)]\nenum EnumType {\n    #[codec(index = 15)]\n    A,\n    B(u32, u64),\n    C {\n        a: u32,\n        b: u64,\n    },\n}\n\nlet a = EnumType::A;\nlet b = EnumType::B(1, 2);\nlet c = EnumType::C { a: 1, b: 2 };\n\na.using_encoded(|ref slice| {\n    assert_eq!(slice, &b\"\\x0f\");\n});\n\nb.using_encoded(|ref slice| {\n    assert_eq!(slice, &b\"\\x01\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\");\n});\n\nc.using_encoded(|ref slice| {\n    assert_eq!(slice, &b\"\\x02\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\");\n});\n\nlet mut da: &[u8] = b\"\\x0f\";\nassert_eq!(EnumType::decode(&mut da).ok(), Some(a));\n\nlet mut db: &[u8] = b\"\\x01\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\";\nassert_eq!(EnumType::decode(&mut db).ok(), Some(b));\n\nlet mut dc: &[u8] = b\"\\x02\\x01\\0\\0\\0\\x02\\0\\0\\0\\0\\0\\0\\0\";\nassert_eq!(EnumType::decode(&mut dc).ok(), Some(c));\n\nlet mut dz: &[u8] = &[0];\nassert_eq!(EnumType::decode(&mut dz).ok(), None);\n```"}
{"page_id": "reference-parachains-data-encoding", "page_title": "Data Encoding", "index": 9, "depth": 2, "title": "SCALE Codec Libraries", "anchor": "scale-codec-libraries", "start_char": 12105, "end_char": 13629, "estimated_token_count": 557, "token_estimator": "heuristic-v1", "text": "## SCALE Codec Libraries\n\nSeveral SCALE codec implementations are available in various languages. Here's a list of them:\n\n- **AssemblyScript**: [`LimeChain/as-scale-codec`](https://github.com/LimeChain/as-scale-codec){target=\\_blank}\n- **C**: [`MatthewDarnell/cScale`](https://github.com/MatthewDarnell/cScale){target=\\_blank}\n- **C++**: [`qdrvm/scale-codec-cpp`](https://github.com/qdrvm/scale-codec-cpp){target=\\_blank}\n- **JavaScript**: [`polkadot-js/api`](https://github.com/polkadot-js/api){target=\\_blank}\n- **Dart**: [`leonardocustodio/polkadart`](https://github.com/leonardocustodio/polkadart){target=\\_blank}\n- **Haskell**: [`airalab/hs-web3`](https://github.com/airalab/hs-web3/tree/master/packages/scale){target=\\_blank}\n- **Golang**: [`itering/scale.go`](https://github.com/itering/scale.go){target=\\_blank}\n- **Java**: [`splix/polkaj`](https://github.com/splix/polkaj){target=\\_blank}\n- **Python**: [`polkascan/py-scale-codec`](https://github.com/polkascan/py-scale-codec){target=\\_blank}\n- **Ruby**: [` wuminzhe/scale_rb`](https://github.com/wuminzhe/scale_rb){target=\\_blank}\n- **TypeScript**: [`parity-scale-codec-ts`](https://github.com/tjjfvi/subshape){target=\\_blank}, [`scale-ts`](https://github.com/unstoppablejs/unstoppablejs/tree/main/packages/scale-ts#scale-ts){target=\\_blank}, [`soramitsu/scale-codec-js-library`](https://github.com/soramitsu/scale-codec-js-library){target=\\_blank}, [`subsquid/scale-codec`](https://github.com/subsquid/squid-sdk/tree/master/substrate/scale-codec){target=\\_blank}"}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 607, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nInteroperability lies at the heart of the Polkadot ecosystem, enabling communication and collaboration across a diverse range of blockchains. By bridging the gaps between parachains, relay chains, and even external networks, Polkadot unlocks the potential for truly decentralized applications, efficient resource sharing, and scalable solutions.\n\nPolkadotâ€™s design ensures that blockchains can transcend their individual limitations by working together as part of a unified system. This cooperative architecture is what sets Polkadot apart in the blockchain landscape."}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 1, "depth": 2, "title": "Why Interoperability Matters", "anchor": "why-interoperability-matters", "start_char": 607, "end_char": 1641, "estimated_token_count": 169, "token_estimator": "heuristic-v1", "text": "## Why Interoperability Matters\n\nThe blockchain ecosystem is inherently fragmented. Different blockchains excel in specialized domains such as finance, gaming, or supply chain management, but these chains function in isolation without interoperability. This lack of connectivity stifles the broader utility of blockchain technology.\n\nInteroperability solves this problem by enabling blockchains to:\n\n- **Collaborate across networks**: Chains can interact to share assets, functionality, and data, creating synergies that amplify their individual strengths.\n- **Achieve greater scalability**: Specialized chains can offload tasks to others, optimizing performance and resource utilization.\n- **Expand use-case potential**: Cross-chain applications can leverage features from multiple blockchains, unlocking novel user experiences and solutions.\n\nIn the Polkadot ecosystem, interoperability transforms a collection of isolated chains into a cohesive, efficient network, pushing the boundaries of what blockchains can achieve together."}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 2, "depth": 2, "title": "Key Mechanisms for Interoperability", "anchor": "key-mechanisms-for-interoperability", "start_char": 1641, "end_char": 1921, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## Key Mechanisms for Interoperability\n\nAt the core of Polkadot's cross-chain collaboration are foundational technologies designed to break down barriers between networks. These mechanisms empower blockchains to communicate, share resources, and operate as a cohesive ecosystem."}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 3, "depth": 3, "title": "Cross-Consensus Messaging (XCM): The Backbone of Communication", "anchor": "cross-consensus-messaging-xcm-the-backbone-of-communication", "start_char": 1921, "end_char": 2750, "estimated_token_count": 151, "token_estimator": "heuristic-v1", "text": "### Cross-Consensus Messaging (XCM): The Backbone of Communication\n\nPolkadot's Cross-Consensus Messaging (XCM) is the standard framework for interaction between parachains, relay chains, and, eventually, external blockchains. XCM provides a trustless, secure messaging format for exchanging assets, sharing data, and executing cross-chain operations.\n\nThrough XCM, decentralized applications can:\n\n- Transfer tokens and other assets across chains.\n- Coordinate complex workflows that span multiple blockchains.\n- Enable seamless user experiences where underlying blockchain differences are invisible.\n- XCM exemplifies Polkadotâ€™s commitment to creating a robust and interoperable ecosystem.\n\nFor further information about XCM, check the [Get Started with XCM](/parachains/interoperability/get-started/){target=\\_blank} article."}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 4, "depth": 3, "title": "Bridges: Connecting External Networks", "anchor": "bridges-connecting-external-networks", "start_char": 2750, "end_char": 3530, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Bridges: Connecting External Networks\n\nWhile XCM enables interoperability within the Polkadot ecosystem, bridges extend this functionality to external blockchains such as Ethereum and Bitcoin. By connecting these networks, bridges allow Polkadot-based chains to access external liquidity, additional functionalities, and broader user bases.\n\nWith bridges, developers and users gain the ability to:\n\n- Integrate external assets into Polkadot-based applications.\n- Combine the strengths of Polkadotâ€™s scalability with the liquidity of other networks.\n- Facilitate accurate multi-chain applications that transcend ecosystem boundaries.\n\nFor more information about bridges in the Polkadot ecosystem, see the [Bridge Hub](/reference/polkadot-hub/bridging/){target=\\_blank} guide."}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 5, "depth": 2, "title": "The Polkadot Advantage", "anchor": "the-polkadot-advantage", "start_char": 3530, "end_char": 4248, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "## The Polkadot Advantage\n\nPolkadot was purpose-built for interoperability. Unlike networks that add interoperability as an afterthought, Polkadot integrates it as a fundamental design principle. This approach offers several distinct advantages:\n\n- **Developer empowerment**: Polkadotâ€™s interoperability tools allow developers to build applications that leverage multiple chainsâ€™ capabilities without added complexity.\n- **Enhanced ecosystem collaboration**: Chains in Polkadot can focus on their unique strengths while contributing to the ecosystemâ€™s overall growth.\n- **Future-proofing blockchain**: By enabling seamless communication, Polkadot ensures its ecosystem can adapt to evolving demands and technologies."}
{"page_id": "reference-parachains-interoperability", "page_title": "Interoperability", "index": 6, "depth": 2, "title": "Looking Ahead", "anchor": "looking-ahead", "start_char": 4248, "end_char": 4636, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Looking Ahead\n\nPolkadotâ€™s vision of interoperability extends beyond technical functionality, representing a shift towards a more collaborative blockchain landscape. By enabling chains to work together, Polkadot fosters innovation, efficiency, and accessibility, paving the way for a decentralized future where blockchains are not isolated competitors but interconnected collaborators."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 601, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot ecosystem is built on a robust set of networks designed to enable secure and scalable development. Whether you are testing new features or deploying to live production, Polkadot offers several layers of networks tailored for each stage of the development process. From local environments to experimental networks like Kusama and community-run TestNets such as Paseo, developers can thoroughly test, iterate, and validate their applications. This guide will introduce you to Polkadot's various networks and explain how they fit into the development workflow."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 1, "depth": 2, "title": "Network Overview", "anchor": "network-overview", "start_char": 601, "end_char": 3131, "estimated_token_count": 484, "token_estimator": "heuristic-v1", "text": "## Network Overview \n\nPolkadot's development process is structured to ensure new features and upgrades are rigorously tested before being deployed on live production networks. The progression follows a well-defined path, starting from local environments and advancing through TestNets, ultimately reaching the Polkadot MainNet. The diagram below outlines the typical progression of the Polkadot development cycle:\n\n``` mermaid\nflowchart LR\n    id1[Local] --> id2[Westend] --> id4[Kusama] --> id5[Polkadot]  \n    id1[Local] --> id3[Paseo] --> id5[Polkadot] \n```\n\nThis flow ensures developers can thoroughly test and iterate without risking real tokens or affecting production networks. Testing tools like [Chopsticks](#chopsticks) and various TestNets make it easier to experiment safely before releasing to production.\n\nA typical journey through the Polkadot core protocol development process might look like this:\n\n1. **Local development node**: Development starts in a local environment, where developers can create, test, and iterate on upgrades or new features using a local development node. This stage allows rapid experimentation in an isolated setup without any external dependencies.\n\n2. **Westend**: After testing locally, upgrades are deployed to [Westend](#westend), Polkadot's primary TestNet. Westend simulates real-world conditions without using real tokens, making it the ideal place for rigorous feature testing before moving on to production networks.\n\n3. **Kusama**: Once features have passed extensive testing on Westend, they move to Kusama, Polkadot's experimental and fast-moving \"canary\" network. Kusama operates as a high-fidelity testing ground with actual economic incentives, giving developers insights into how their features will perform in a real-world environment.\n\n4. **Polkadot**: After passing tests on Westend and Kusama, features are considered ready for deployment to Polkadot, the live production network.\n\n    In addition, parachain developers can leverage local TestNets like [Zombienet](#zombienet) and deploy upgrades on parachain TestNets.\n\n5. **Paseo**: For parachain and dApp developers, Paseo serves as a community-run TestNet that mirrors Polkadot's runtime. Like Westend for core protocol development, Paseo provides a testing ground for parachain development without affecting live networks.\n\n!!!note\n    The Rococo TestNet deprecation date was October 14, 2024. Teams should use Westend for Polkadot protocol and feature testing and Paseo for chain development-related testing."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 2, "depth": 2, "title": "Polkadot Development Networks", "anchor": "polkadot-development-networks", "start_char": 3131, "end_char": 3663, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Polkadot Development Networks\n\nDevelopment and testing are crucial to building robust dApps and parachains and performing network upgrades within the Polkadot ecosystem. To achieve this, developers can leverage various networks and tools that provide a risk-free environment for experimentation and validation before deploying features to live networks. These networks help avoid the costs and risks associated with real tokens, enabling testing for functionalities like governance, cross-chain messaging, and runtime upgrades."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 3, "depth": 2, "title": "Kusama Network", "anchor": "kusama-network", "start_char": 3663, "end_char": 4268, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "## Kusama Network\n\nKusama is the experimental version of Polkadot, designed for developers who want to move quickly and test their applications in a real-world environment with economic incentives. Kusama serves as a production-grade testing ground where developers can deploy features and upgrades with the pressure of game theory and economics in mind. It mirrors Polkadot but operates as a more flexible space for innovation.\n\nThe native token for Kusama is KSM. For more information about KSM, visit the [Native Assets](https://wiki.polkadot.com/kusama/kusama-getting-started/){target=\\_blank} page."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 4, "depth": 2, "title": "Test Networks", "anchor": "test-networks", "start_char": 4268, "end_char": 4488, "estimated_token_count": 47, "token_estimator": "heuristic-v1", "text": "## Test Networks\n\nThe following test networks provide controlled environments for testing upgrades and new features. TestNet tokens are available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 5, "depth": 3, "title": "Westend", "anchor": "westend", "start_char": 4488, "end_char": 5009, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "### Westend\n\nWestend is Polkadot's primary permanent TestNet. Unlike temporary test networks, Westend is not reset to the genesis block, making it an ongoing environment for testing Polkadot core features. Managed by Parity Technologies, Westend ensures that developers can test features in a real-world simulation without using actual tokens.\n\nThe native token for Westend is WND. More details about WND can be found on the [Native Assets](https://wiki.polkadot.com/learn/learn-dot/#__tabbed_2_2){target=\\_blank} page."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 6, "depth": 3, "title": "Paseo", "anchor": "paseo", "start_char": 5009, "end_char": 5579, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "### Paseo\n\n[Paseo](https://github.com/paseo-network){target=\\_blank} is a community-managed TestNet designed for parachain and dApp developers. It mirrors Polkadot's runtime and is maintained by Polkadot community members. Paseo provides a dedicated space for parachain developers to test their applications in a Polkadot-like environment without the risks associated with live networks.\n\nThe native token for Paseo is PAS. Additional information on PAS is available on the [Native Assets](https://wiki.polkadot.com/learn/learn-dot/#__tabbed_2_1){target=\\_blank} page."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 7, "depth": 2, "title": "Local Test Networks", "anchor": "local-test-networks", "start_char": 5579, "end_char": 6057, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Local Test Networks\n\nLocal test networks are an essential part of the development cycle for blockchain developers using the Polkadot SDK. They allow for fast, iterative testing in controlled, private environments without connecting to public TestNets. Developers can quickly spin up local instances to experiment, debug, and validate their code before deploying to larger TestNets like Westend or Paseo. Two key tools for local network testing are Zombienet and Chopsticks."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 8, "depth": 3, "title": "Zombienet", "anchor": "zombienet", "start_char": 6057, "end_char": 6981, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "### Zombienet\n\n[Zombienet](https://github.com/paritytech/zombienet){target=\\_blank} is a flexible testing framework for Polkadot SDK-based blockchains. It enables developers to create and manage ephemeral, short-lived networks. This feature makes Zombienet particularly useful for quick iterations, as it allows you to run multiple local networks concurrently, mimicking different runtime conditions. Whether you're developing a parachain or testing your custom blockchain logic, Zombienet gives you the tools to automate local testing.\n\nKey features of Zombienet include:\n\n- Creating dynamic, local networks with different configurations.\n- Running parachains and relay chains in a simulated environment.\n- Efficient testing of network components like cross-chain messaging and governance.\n\nZombienet is ideal for developers looking to test quickly and thoroughly before moving to more resource-intensive public TestNets."}
{"page_id": "reference-parachains-networks", "page_title": "Networks", "index": 9, "depth": 3, "title": "Chopsticks", "anchor": "chopsticks", "start_char": 6981, "end_char": 7834, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "### Chopsticks\n\n[Chopsticks](https://github.com/AcalaNetwork/chopsticks){target=\\_blank} is a tool designed to create forks of Polkadot SDK-based blockchains, allowing developers to interact with network forks as part of their testing process. This capability makes Chopsticks a powerful option for testing upgrades, runtime changes, or cross-chain applications in a forked network environment.\n\nKey features of Chopsticks include:\n\n- Forking live Polkadot SDK-based blockchains for isolated testing.\n- Simulating cross-chain messages in a private, controlled setup.\n- Debugging network behavior by interacting with the fork in real-time.\n\nChopsticks provides a controlled environment for developers to safely explore the effects of runtime changes. It ensures that network behavior is tested and verified before upgrades are deployed to live networks."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 20, "end_char": 1003, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEvery blockchain platform relies on a decentralized network of computers, called nodes, that communicate with each other about transactions and blocks. In this context, a node refers to the software running on the connected devices rather than the physical or virtual machines in the network.\n\nPolkadot SDK-based nodes consist of two main components, each with distinct responsibilities: the client (also called node) and the runtime.\n\nIf the system were a monolithic protocol, any modification would require updating the entire system. Instead, Polkadot achieves true upgradeability by defining an immutable meta-protocol (the client) and a protocol (the runtime) that can be upgraded independently.\n\nThis separation gives the [Polkadot Relay Chain](/polkadot-protocol/architecture/polkadot-chain){target=\\_blank} and all connected [parachains](/polkadot-protocol/architecture/parachains){target=\\_blank} an evolutionary advantage over other blockchain platforms."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 1, "depth": 2, "title": "Architectural Principles", "anchor": "architectural-principles", "start_char": 1003, "end_char": 1725, "estimated_token_count": 123, "token_estimator": "heuristic-v1", "text": "## Architectural Principles\n\nThe Polkadot SDK-based blockchain architecture is fundamentally built on two distinct yet interconnected components:\n\n- Client (Meta-protocol):\n    - Handles the foundational infrastructure of the blockchain.\n    - Manages runtime execution, networking, consensus, and other off-chain components.\n    - Provides an immutable base layer that ensures network stability.\n    - Upgradable only through hard forks.\n\n- Runtime (Protocol):\n    - Defines the blockchain's state transition logic.\n    - Determines the specific rules and behaviors of the blockchain.\n    - Compiled to WebAssembly (Wasm) for platform-independent execution.\n    - Capable of being upgraded without network-wide forking."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 2, "depth": 3, "title": "Advantages of this Architecture", "anchor": "advantages-of-this-architecture", "start_char": 1725, "end_char": 2106, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "### Advantages of this Architecture\n\n- **Forkless upgrades**: Runtime can be updated without disrupting the entire network.\n- **Modularity**: Clear separation allows independent development of client and runtime.\n- **Flexibility**: Enables rapid iteration and evolution of blockchain logic.\n- **Performance**: WebAssembly compilation provides efficient, cross-platform execution."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 3, "depth": 2, "title": "Node (Client)", "anchor": "node-client", "start_char": 2106, "end_char": 2939, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "## Node (Client)\n\nThe node, also known as the client, is the core component responsible for executing the Wasm runtime and orchestrating various essential blockchain components. It ensures the correct execution of the state transition function and manages multiple critical subsystems, including:\n\n- **Wasm execution**: Runs the blockchain runtime, which defines the state transition rules.\n- **Database management**: Stores blockchain data.\n- **Networking**: Facilitates peer-to-peer communication, block propagation, and transaction gossiping.\n- **Transaction pool (Mempool)**: Manages pending transactions before they are included in a block.\n- **Consensus mechanism**: Ensures agreement on the blockchain state across nodes.\n- **RPC services**: Provides external interfaces for applications and users to interact with the node."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 4, "depth": 2, "title": "Runtime", "anchor": "runtime", "start_char": 2939, "end_char": 3221, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Runtime\n\nThe runtime is more than just a set of rules. It's the fundamental logic engine that defines a blockchain's entire behavior. In Polkadot SDK-based blockchains, the runtime represents a complete, self-contained description of the blockchain's state transition function."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 5, "depth": 3, "title": "Characteristics", "anchor": "characteristics", "start_char": 3221, "end_char": 3555, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "### Characteristics\n\nThe runtime is distinguished by three key characteristics:\n\n- **Business logic**: Defines the complete application-specific blockchain behavior.\n- **WebAssembly compilation**: Ensures platform-independent, secure execution.\n- **On-chain storage**: Stored within the blockchain's state, allowing dynamic updates."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 6, "depth": 3, "title": "Key Functions", "anchor": "key-functions", "start_char": 3555, "end_char": 3840, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "### Key Functions\n\nThe runtime performs several critical functions, such as:\n\n- Define state transition rules.\n- Implement blockchain-specific logic.\n- Manage account interactions.\n- Control transaction processing.\n- Define governance mechanisms.\n- Handle custom pallets and modules."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 7, "depth": 2, "title": "Communication Between Node and Runtime", "anchor": "communication-between-node-and-runtime", "start_char": 3840, "end_char": 4112, "estimated_token_count": 53, "token_estimator": "heuristic-v1", "text": "## Communication Between Node and Runtime\n\nThe client and runtime communicate exclusively using [SCALE-encoded](/polkadot-protocol/parachain-basics/data-encoding){target=\\_blank} communication. This ensures efficient and compact data exchange between the two components."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 8, "depth": 3, "title": "Runtime APIs", "anchor": "runtime-apis", "start_char": 4112, "end_char": 4537, "estimated_token_count": 76, "token_estimator": "heuristic-v1", "text": "### Runtime APIs\n\nThe Runtime API consists of well-defined functions and constants a client assumes are implemented in the Runtime Wasm blob. These APIs enable the client to interact with the runtime to execute blockchain operations and retrieve information. The client invokes these APIs to:\n\n- Build, execute, and finalize blocks.\n- Access metadata.\n- Access consensus related information.\n- Handle transaction execution."}
{"page_id": "reference-parachains-node-and-runtime", "page_title": "Node and Runtime", "index": 9, "depth": 3, "title": "Host Functions", "anchor": "host-functions", "start_char": 4537, "end_char": 4937, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "### Host Functions\n\nDuring execution, the runtime can access certain external client functionalities via host functions. The specific functions the client exposes allow the runtime to perform operations outside the WebAssembly domain. Host functions enable the runtime to:\n\n- Perform cryptographic operations.\n- Access the current blockchain state.\n- Handle storage modifications.\n- Allocate memory."}
{"page_id": "reference-parachains-randomness", "page_title": "Randomness", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 1254, "estimated_token_count": 285, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nRandomness is crucial in Proof of Stake (PoS) blockchains to ensure a fair and unpredictable distribution of validator duties. However, computers are inherently deterministic, meaning the same input always produces the same output. What we typically refer to as \"random\" numbers on a computer are actually pseudo-random. These numbers rely on an initial \"seed,\" which can come from external sources like [atmospheric noise](https://www.random.org/randomness/){target=\\_blank}, [heart rates](https://mdpi.altmetric.com/details/47574324){target=\\_blank}, or even [lava lamps](https://en.wikipedia.org/wiki/Lavarand){target=\\_blank}. While this may seem random, given the same \"seed,\" the same sequence of numbers will always be generated.\n\nIn a global blockchain network, relying on real-world entropy for randomness isnâ€™t feasible because these inputs vary by time and location. If nodes use different inputs, blockchains can fork. Hence, real-world randomness isn't suitable for use as a seed in blockchain systems.\n\nCurrently, two primary methods for generating randomness in blockchains are used: [`RANDAO`](#randao) and [`VRF`](#vrf) (Verifiable Random Function). Polkadot adopts the `VRF` approach for its randomness."}
{"page_id": "reference-parachains-randomness", "page_title": "Randomness", "index": 1, "depth": 2, "title": "VRF", "anchor": "vrf", "start_char": 1254, "end_char": 2042, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "## VRF\n\nAÂ Verifiable Random Function (VRF)Â is a cryptographic function that generates a random number and proof that ensures the submitter produced the number. This proof allows anyone to verify the validity of the random number.\n\nPolkadot's VRF is similar to the one used in [**Ouroboros Praos**](https://eprint.iacr.org/2017/573.pdf){target=\\_blank}, which secures randomness for block production in systems like [BABE](/reference/polkadot-hub/consensus-and-security/pos-consensus/#block-production-babe){target=\\_blank} (Polkadotâ€™s block production mechanism). \n\nThe key difference is that Polkadot's VRF doesnâ€™t rely on a central clockâ€”avoiding the issue of whose clock to trust. Instead, it uses its own past results and slot numbers to simulate time and determine future outcomes."}
{"page_id": "reference-parachains-randomness", "page_title": "Randomness", "index": 2, "depth": 3, "title": "How VRF Works", "anchor": "how-vrf-works", "start_char": 2042, "end_char": 4579, "estimated_token_count": 537, "token_estimator": "heuristic-v1", "text": "### How VRF Works\n\nSlots on Polkadot are discrete units of time, each lasting six seconds, and can potentially hold a block. Multiple slots form an epoch, with 2400 slots making up one four-hour epoch.\n\nIn each slot, validators execute a \"die roll\" using a VRF. The VRF uses three inputs:\n\n1. A \"secret key,\" unique to each validator, is used for the die roll.\n2. An epoch randomness value, derived from the hash of VRF outputs from blocks two epochs ago (N-2), so past randomness influences the current epoch (N).\n3. The current slot number.\n\nThis process helps maintain fair randomness across the network.\n\nHere is a graphical representation:\n\n![](/images/reference/parachains/randomness/randomness-01.webp)\n\nThe VRF produces two outputs: a result (the random number) and a proof (verifying that the number was generated correctly).\n\nTheÂ resultÂ is checked by the validator against a protocol threshold. If it's below the threshold, the validator becomes a candidate for block production in that slot. \n\nThe validator then attempts to create a block, submitting it along with the `PROOF` and `RESULT`.\n\nSo, VRF can be expressed like:\n\n`(RESULT, PROOF) = VRF(SECRET, EPOCH_RANDOMNESS_VALUE, CURRENT_SLOT_NUMBER)`\n\nPut simply, performing a \"VRF roll\" generates a random number along with proof that the number was genuinely produced and not arbitrarily chosen.\n\nAfter executing the VRF, the `RESULT` is compared to a protocol-defined `THRESHOLD`. If the `RESULT` is below the `THRESHOLD`, the validator becomes a valid candidate to propose a block for that slot. Otherwise, the validator skips the slot.\n\nAs a result, there may be multiple validators eligible to propose a block for a slot. In this case, the block accepted by other nodes will prevail, provided it is on the chain with the latest finalized block as determined by the GRANDPA finality gadget. It's also possible for no block producers to be available for a slot, in which case the AURA consensus takes over. AURA is a fallback mechanism that randomly selects a validator to produce a block, running in parallel with BABE and only stepping in when no block producers exist for a slot. Otherwise, it remains inactive.\n\nBecause validators roll independently, no block candidates may appear in some slots if all roll numbers are above the threshold. \n\nTo verify resolution of this issue and that Polkadot block times remain near constant-time, see the [PoS Consensus](/reference/polkadot-hub/consensus-and-security/pos-consensus/){target=\\_blank} page of this documentation."}
{"page_id": "reference-parachains-randomness", "page_title": "Randomness", "index": 3, "depth": 2, "title": "RANDAO", "anchor": "randao", "start_char": 4579, "end_char": 5266, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## RANDAO\n\nAn alternative on-chain randomness method is Ethereum'sÂ RANDAO, where validators perform thousands of hashes on a seed and publish the final hash during a round. The collective input from all validators forms the random number, and as long as one honest validator participates, the randomness is secure.\n\nTo enhance security,Â RANDAOÂ can optionally be combined with aÂ Verifiable Delay Function (VDF), ensuring that randomness can't be predicted or manipulated during computation.\n\nFor more information about RANDAO, see the [Randomness - RANDAO](https://eth2book.info/capella/part2/building_blocks/randomness/){target=\\_blank} section of the Upgrading Ethereum documentation."}
{"page_id": "reference-parachains-randomness", "page_title": "Randomness", "index": 4, "depth": 2, "title": "VDFs", "anchor": "vdfs", "start_char": 5266, "end_char": 5943, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## VDFs\n\nVerifiable Delay Functions (VDFs) are time-bound computations that, even on parallel computers, take a set amount of time to complete. \n\nThey produce a unique result that can be quickly verified publicly. When combined with RANDAO, feeding RANDAO's output into a VDF introduces a delay that nullifies an attacker's chance to influence the randomness.\n\nHowever,Â VDFÂ likely requires specialized ASIC devices to run separately from standard nodes.\n\n!!!warning \n    While only one is needed to secure the system, and they will be open-source and inexpensive, running VDF devices involves significant costs without direct incentives, adding friction for blockchain users."}
{"page_id": "reference-parachains-randomness", "page_title": "Randomness", "index": 5, "depth": 2, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 5943, "end_char": 6503, "estimated_token_count": 124, "token_estimator": "heuristic-v1", "text": "## Additional Resources\n\nFor more information about the reasoning for choices made along with proofs, see Polkadot's research on blockchain randomness and sortition in the [Block production](https://research.web3.foundation/Polkadot/protocols/block-production){target=\\_blank} entry of the Polkadot Wiki. \n\nFor a discussion with Web3 Foundation researchers about when and under what conditions Polkadot's randomness can be utilized, see the [Discussion on Randomness used in Polkadot](https://github.com/use-ink/ink/issues/57){target=\\_blank} issue on GitHub."}
{"page_id": "reference-parachains", "page_title": "Parachains Overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 23, "end_char": 1338, "estimated_token_count": 235, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nA parachain is a specialized blockchain that connects to the Polkadot relay chain, benefiting from shared security, interoperability, and scalability. Parachains are built using the [Polkadot SDK](https://github.com/paritytech/polkadot-sdk){target=\\_blank}, a powerful toolkit written in Rust that provides everything needed to create custom blockchain logic while integrating seamlessly with the Polkadot network.\n\nUnlike standalone blockchains that must bootstrap their own validator sets and security, parachains leverage Polkadot's pooled security model. This allows parachain developers to focus on their application-specific functionality rather than consensus and security infrastructure. Parachains can communicate with each other through Cross-Consensus Messaging (XCM), enabling seamless interoperability across the Polkadot ecosystem.\n\nKey capabilities that parachains provide include:\n\n- **Shared security**: Inherit security from Polkadot's validator set without maintaining your own.\n- **Interoperability**: Communicate trustlessly with other parachains via XCM.\n- **Scalability**: Process transactions in parallel with other parachains.\n- **Customization**: Build application-specific logic tailored to your use case.\n- **Upgradeability**: Upgrade runtime logic without hard forks."}
{"page_id": "reference-parachains", "page_title": "Parachains Overview", "index": 1, "depth": 2, "title": "Polkadot SDK: Parachain Architecture", "anchor": "polkadot-sdk-parachain-architecture", "start_char": 1338, "end_char": 2576, "estimated_token_count": 308, "token_estimator": "heuristic-v1", "text": "## Polkadot SDK: Parachain Architecture\n\nBuilding a parachain involves understanding and utilizing several key components of the Polkadot SDK:\n\n![](/images/reference/parachains/index/overview-01.webp)\n\n- **[Substrate](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/substrate/index.html){target=\\_blank}**: The foundation providing core blockchain primitives and libraries.\n- **[FRAME](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/frame_runtime/index.html){target=\\_blank}**: A modular framework for building your parachain's runtime logic.\n- **[Cumulus](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/cumulus/index.html){target=\\_blank}**: Essential libraries and pallets that enable parachain functionality.\n- **[XCM (Cross Consensus Messaging)](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/xcm/index.html){target=\\_blank}**: The messaging format for communicating with other parachains and the relay chain.\n- **[Polkadot](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/polkadot/index.html){target=\\_blank}**: The relay chain that provides security and coordination."}
{"page_id": "reference-parachains", "page_title": "Parachains Overview", "index": 2, "depth": 3, "title": "Substrate: The Foundation", "anchor": "substrate-the-foundation", "start_char": 2576, "end_char": 4333, "estimated_token_count": 345, "token_estimator": "heuristic-v1", "text": "### Substrate: The Foundation\n\nSubstrate provides the core infrastructure that every parachain is built upon. It handles the low-level blockchain functionality, allowing you to focus on your application's unique features. Substrate includes implementations for networking, database management, consensus participation, and the execution environment for your runtime.\n\nEvery Polkadot SDK node consists of two main components:\n\n- **Client (Host)**: Handles infrastructure services.\n\n    - Native binary that runs on validator and collator nodes.\n    - Executes the Wasm-compiled runtime.\n    - Manages networking, database, mempool, and block production.\n    - Interfaces with the relay chain for validation.\n\n- **Runtime (State Transition Function)**: Contains your business logic.\n\n    - Defines how your Polkadot SDK node processes transactions.\n    - Compiled to [Wasm](https://webassembly.org/){target=\\_blank} for deterministic execution.\n    - Stored on-chain and upgradeable via governance.\n\n```mermaid\n%%{init: {'flowchart': {'padding': 5, 'nodeSpacing': 50, 'rankSpacing': 10}}}%%\ngraph TB\n    classDef title font-size:20px,font-weight:bold,stroke-width:0px\n    classDef clientStyle font-size:16px,font-weight:bold\n    classDef clientSubNodeStyle margin-top:10px\n    classDef runtimeCallExecutorStyle padding-top:10px\n\n    subgraph sg1[Parachain<br /> Node]\n        direction TB\n\n        I[RuntimeCall Executor]\n        B[Wasm Runtime - STF]\n\n        subgraph sg2[Client]\n            direction TB\n            C[Network and Blockchain<br/>Infrastructure Services<br/>+ Relay Chain Interface]\n        end\n\n        I --> B\n    end\n\n    class sg1 title\n    class sg2 clientStyle\n    class C clientSubNodeStyle\n    class I runtimeCallExecutorStyle\n\n```"}
{"page_id": "reference-parachains", "page_title": "Parachains Overview", "index": 3, "depth": 3, "title": "FRAME: Building Blocks for Your Runtime", "anchor": "frame-building-blocks-for-your-runtime", "start_char": 4333, "end_char": 6265, "estimated_token_count": 409, "token_estimator": "heuristic-v1", "text": "### FRAME: Building Blocks for Your Runtime\n\nFRAME provides modular components called [pallets](/reference/glossary#pallet){target=\\_blank} that you can compose to build your parachain's runtime. Each pallet provides specific functionality that you can customize and configure for your needs. This modular approach allows you to quickly assemble complex functionality without writing everything from scratch.\n\n```mermaid\ngraph LR\n    subgraph SP[\"<b style='font-size:18px;'>Parachain Runtime</b>\"]\n        direction LR\n        Timestamp ~~~ Aura ~~~ ParachainSystem\n        Balances ~~~ TransactionPayment ~~~ Sudo\n        subgraph Timestamp[\"Timestamp\"]\n            SS1[Custom Config]\n        end\n        subgraph Aura[\"Aura\"]\n            SS2[Custom Config]\n        end\n        subgraph ParachainSystem[\"Parachain System\"]\n            SS3[Custom Config]\n        end\n        subgraph Balances[\"Balances\"]\n            SS4[Custom Config]\n        end\n        subgraph TransactionPayment[\"Transaction Payment\"]\n            SS5[Custom Config]\n        end\n        subgraph Sudo[\"Sudo\"]\n            SS6[Custom Config]\n        end\n        style Timestamp stroke:#FF69B4\n        style Aura stroke:#FF69B4\n        style ParachainSystem stroke:#FF69B4\n        style Balances stroke:#FF69B4\n        style TransactionPayment stroke:#FF69B4\n        style Sudo stroke:#FF69B4\n        style SS1 stroke-dasharray: 5\n        style SS2 stroke-dasharray: 5\n        style SS3 stroke-dasharray: 5\n        style SS4 stroke-dasharray: 5\n        style SS5 stroke-dasharray: 5\n        style SS6 stroke-dasharray: 5\n\n    end\n    subgraph AP[\"<b style='font-size:18px;'>Available FRAME Pallets</b>\"]\n        direction LR\n        A1[Aura]~~~A2[Parachain<br>System]~~~A3[Transaction<br>Payment]~~~A4[Sudo]\n        B1[Identity]~~~B2[Balances]~~~B3[Assets]~~~B4[EVM]\n        C1[Timestamp]~~~C2[Staking]~~~C3[Contracts]~~~C4[and more...]\n    end\n    AP --> SP\n```"}
{"page_id": "reference-parachains", "page_title": "Parachains Overview", "index": 4, "depth": 3, "title": "Cumulus: Parachain-Specific Functionality", "anchor": "cumulus-parachain-specific-functionality", "start_char": 6265, "end_char": 6970, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### Cumulus: Parachain-Specific Functionality\n\nCumulus is what transforms a Polkadot SDK-based runtime into a parachain-capable runtime. It provides the essential components for communicating with the relay chain, participating in Polkadot's consensus, and handling parachain-specific operations like block validation and collation.\n\nKey Cumulus components include:\n\n- **Parachain system pallet**: Core parachain functionality and relay chain communication.\n- **Collator consensus**: Block production logic for parachain collators.\n- **Relay chain interface**: APIs for interacting with the Polkadot relay chain.\n- **Validation data**: Handling proof-of-validity data required by relay chain validators."}
{"page_id": "reference-parachains", "page_title": "Parachains Overview", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6970, "end_char": 8495, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nBuilding a parachain requires understanding the relationship between your chain and the Polkadot relay chain. The Polkadot SDK provides all the tools needed to design custom runtime logic, enable cross-chain communication, and deploy your parachain to production.\n\nThe following sections provide detailed guidance on each aspect of parachain development, from initial design through deployment and ongoing maintenance.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Launch a Simple Parachain__\n\n    ---\n\n    Walk through the complete parachain launch flow: from setup and deployment to obtaining coretime.\n\n    [:octicons-arrow-right-24: Deploy](/parachains/launch-a-parachain/set-up-the-parachain-template/)\n\n\n-   <span class=\"badge guide\">Guide</span> __Customize Your Runtime__\n\n    ---\n\n    Design your parachain's runtime logic and choose appropriate pallets for your use case.\n\n    [:octicons-arrow-right-24: Get Started](/parachains/customize-runtime/)\n\n-   <span class=\"badge guide\">Guide</span> __Interoperability__\n\n    ---\n\n    Implement XCM for trustless cross-chain communication with other parachains.\n\n    [:octicons-arrow-right-24: Learn More](/parachains/interoperability/get-started/)\n\n-   <span class=\"badge guide\">Guide</span> __Runtime Upgrades__\n\n    ---\n\n    Upgrade your parachain's runtime without hard forks using forkless upgrade mechanisms.\n\n    [:octicons-arrow-right-24: Maintain](/parachains/runtime-maintenance/runtime-upgrades/)\n\n</div>"}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 26, "end_char": 664, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub is Polkadotâ€™s system parachain that provides core functionality for the network, including issuing and managing on-chain assets. While the relay chain provides security, Polkadot Hub handles asset logicâ€”minting, burning, transfers, and metadataâ€”efficiently and cost-effectively.\n\nPolkadot Hub supports native assets issued on the parachain and foreign assets from other chains, both of which can move seamlessly across the network via XCM.\n\nThis guide explains how assets are created, managed, and moved across chains, including key operations, roles, and the differences between native and foreign assets."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 1, "depth": 2, "title": "Why Use Polkadot Hub?", "anchor": "why-use-polkadot-hub", "start_char": 664, "end_char": 1531, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "## Why Use Polkadot Hub?\n\nPolkadot Hub provides a standardized framework for creating and managing fungible and non-fungible assets. Projects can issue tokens, manage supply, and transfer assets across parachains, extending the functionality of the Polkadot relay chain, which only supports its native token (DOT).\n\n**Key features**:\n\n- **Built-in asset operations**: Mint, burn, and transfer like ERC-20 on Ethereum, but native to Polkadot's runtime.\n- **Custom asset creation**: Issue tokens or NFTs with configurable permissions and metadata.\n- **Low fees**: Transactions cost roughly one-tenth of relay chain fees.\n- **Lower deposits**: Minimal on-chain storage costs for asset data.\n- **Pay fees in any asset**: Users donâ€™t need DOT to transact; supported assets can cover fees.\n- **Cross-chain ready**: Assets can be transferred to other parachains using XCM."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 2, "depth": 2, "title": "Types of Assets", "anchor": "types-of-assets", "start_char": 1531, "end_char": 1995, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Types of Assets\n\nPolkadot Hub supports two types of assets:\n\n- **Native assets**: Tokens and NFTs issued directly on Polkadot Hub using the Assets pallet. These assets benefit from the platform's custom features, such as configurable permissions and low fees\n- **Foreign assets**: Tokens originating from other Polkadot parachains or external networks (like Ethereum, via bridges). Once registered on Polkadot Hub, they are treated similarly to native assets."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 3, "depth": 2, "title": "Asset Structure", "anchor": "asset-structure", "start_char": 1995, "end_char": 2518, "estimated_token_count": 104, "token_estimator": "heuristic-v1", "text": "## Asset Structure\n\nEach asset is identified by a unique ID and stores:\n\n- Asset administrators\n- Total supply and holder count\n- Minimum balance configuration\n- Sufficiencyâ€“whether the asset can keep an account alive without DOT\n- Metadata (name, symbol, decimals)\n\nIf a balance falls below the configured minimum, called the [existential deposit](/reference/glossary/#existential-deposit){target=\\_blank}, it may be removed as â€œdust.â€ This ensures efficient storage while giving developers control over asset economics."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 4, "depth": 2, "title": "How Native Assets Work", "anchor": "how-native-assets-work", "start_char": 2518, "end_char": 3094, "estimated_token_count": 111, "token_estimator": "heuristic-v1", "text": "## How Native Assets Work\n\nNative assets on Polkadot Hub are created and managed via the Assets pallet from the Polkadot SDK. This pallet defines the runtime logic for issuing, configuring, and administering fungible assets with customizable permissions.\n\nIt supports both permissioned and permissionless asset creation, enabling everything from simple user-issued tokens to governed assets controlled by teams or DAOs.\n\nFor implementation details, see the [Assets Pallet Rust docs](https://paritytech.github.io/polkadot-sdk/master/pallet_assets/index.html){target=\\_blank}."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 5, "depth": 3, "title": "Asset Operations", "anchor": "asset-operations", "start_char": 3094, "end_char": 4151, "estimated_token_count": 243, "token_estimator": "heuristic-v1", "text": "### Asset Operations\n\nThe Assets pallet provides both state-changing operations and read-only queries for full lifecycle management of assets.\n\nCore operations include:\n\n- **Asset issuance**: Create new assets and assign initial supply.\n- **Transfers**: Move assets between accounts with balance tracking.\n- **Burning**: Reduce total supply by destroying tokens.\n- **Delegated transfers**: Approve transfers on behalf of another account without giving up custody.\n- **Freezing and thawing**: Temporarily lock and unlock an account's balance.\n\nFor a complete list of extrinsics, see the [`pallet-assets` dispatchable functions reference](https://docs.rs/pallet-assets/latest/pallet_assets/pallet/enum.Call.html){target=\\_blank}.\n\nData queries make it possible to:\n\n- Check account balances and total supply.\n- Retrieve asset metadata and configuration details.\n- Inspect account and asset status on-chain.\n\nFor a full list of queries, see the [Pallet reference](https://docs.rs/pallet-assets/latest/pallet_assets/pallet/struct.Pallet.html){target=\\_blank}."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 6, "depth": 3, "title": "Roles and Permissions", "anchor": "roles-and-permissions", "start_char": 4151, "end_char": 4947, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "### Roles and Permissions\n\nThe Assets pallet uses role-based permissions to control who can manage different parts of an assetâ€™s lifecycle:\n\n- **Owner**: Overarching control, including destroying an asset class; can set or update Issuer, Freezer, and Admin roles.\n- **Admin**: Can freeze assets and forcibly transfer balances between accounts. Admins can also reduce the balance of an asset class across arbitrary accounts.\n- **Issuer**: Responsible for minting new tokens. When new assets are created, the Issuer is the account that controls their distribution to other accounts.\n- **Freezer**: Can lock the transfer of assets from an account, preventing the account holder from moving their balance.\n\nThese roles allow projects to enforce governance and security policies around their assets."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 7, "depth": 3, "title": "Freezing Assets", "anchor": "freezing-assets", "start_char": 4947, "end_char": 5469, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "### Freezing Assets\n\nAssets can be temporarily locked to prevent transfers from specific accounts. This is useful for dispute resolution, fraud prevention, or compliance controls.\n\n**How it works**:\n\n- Only authorized parties can freeze or unfreeze (thaw) assets.\n- Freezing pauses the movement of the asset without burning or removing it.\n- Once thawed, the asset can be transferred normally.\n\nFreezing provides a safe way to control asset flow while maintaining full ownership.\n\n**Key functions**: `freeze` and `thaw`."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 8, "depth": 3, "title": "Delegated Transfers", "anchor": "delegated-transfers", "start_char": 5469, "end_char": 6204, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Delegated Transfers\n\nPolkadot Hub supports delegated asset transfers, allowing one account to authorize another to move a limited amount of its assetsâ€”without giving up full control. This is useful for escrow logic, automated payments, and multi-party applications.\n\n**How it works**:\n\n- An account can grant permission to another account to transfer a specific amount of its assets.\n- Permissions can be revoked at any time, preventing further transfers.\n- Authorized accounts can execute transfers on behalf of the original owner within the approved limits.\n\nDelegated transfers simplify multi-step transactions and enable complex asset flows.\n\n**Key functions**: `approve_transfer`, `cancel_approval`, and `transfer_approved`."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 9, "depth": 2, "title": "How Foreign Assets Work", "anchor": "how-foreign-assets-work", "start_char": 6204, "end_char": 7066, "estimated_token_count": 157, "token_estimator": "heuristic-v1", "text": "## How Foreign Assets Work\n\nForeign assets are assets originating from other chains and are managed on Polkadot Hub via an instance of the Assets pallet that is configured specifically for foreign assets. It enables transfers, balance checks, and other standard asset operations, while handling foreign-asset specifics such as:\n\n- **Asset identifiers**: Foreign assets use an XCM multilocation as their identifier, rather than a numeric AssetId. This ensures assets from different chains can be referenced and moved safely across parachains.\n\n- **Transfers**: Once registered on Polkadot Hub, foreign assets can be transferred between accounts just like native assets. If supported, they can also be returned to their original blockchain using cross-chain messaging.\n\nThis unified interface makes it easy for dApps to handle both native and cross-chain assets."}
{"page_id": "reference-polkadot-hub-assets", "page_title": "Polkadot Hub Assets", "index": 10, "depth": 2, "title": "Moving Assets Across Chains", "anchor": "moving-assets-across-chains", "start_char": 7066, "end_char": 7453, "estimated_token_count": 72, "token_estimator": "heuristic-v1", "text": "## Moving Assets Across Chains\n\nPolkadot Hub enables assets to move safely between parachains and the relay chain using XCM (Cross-Consensus Messaging). XCM ensures assets can move securely between chains while preserving ownership and traceability\n\nTo learn more about asset transfers with XCM, please refer to the [Introduction to XCM](/parachains/interoperability/get-started/) page."}
{"page_id": "reference-polkadot-hub-bridging", "page_title": "Bridge Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 1065, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Bridge Hub system parachain plays a crucial role in facilitating trustless interactions between Polkadot, Kusama, Ethereum, and other blockchain ecosystems. By implementing on-chain light clients and supporting protocols like BEEFY and GRANDPA, Bridge Hub ensures seamless message transmission and state verification across chains. It also provides essential [pallets](/reference/glossary/#pallet){target=\\_blank} for sending and receiving messages, making it a cornerstone of Polkadotâ€™s interoperability framework. With built-in support for XCM (Cross-Consensus Messaging), Bridge Hub enables secure, efficient communication between diverse blockchain networks.\n\nThis guide covers the architecture, components, and deployment of the Bridge Hub system. You'll explore its trustless bridging mechanisms, key pallets for various blockchains, and specific implementations like Snowbridge and the Polkadot <> Kusama bridge. By the end, you'll understand how Bridge Hub enhances connectivity within the Polkadot ecosystem and beyond."}
{"page_id": "reference-polkadot-hub-bridging", "page_title": "Bridge Hub", "index": 1, "depth": 2, "title": "Trustless Bridging", "anchor": "trustless-bridging", "start_char": 1065, "end_char": 2671, "estimated_token_count": 313, "token_estimator": "heuristic-v1", "text": "## Trustless Bridging\n\nBridge Hub provides a mode of trustless bridging through its implementation of on-chain light clients and trustless relayers. Trustless bridges are essentially two one-way bridges, where each chain has a method of verifying the state of the other in a trustless manner through consensus proofs. In this context, \"trustless\" refers to the lack of need to trust a human when interacting with various system components. Trustless systems are based instead on trusting mathematics, cryptography, and code. The target chain and source chain both provide ways of verifying one another's state and actions (such as a transfer) based on the consensus and finality of both chains rather than an external mechanism controlled by a third party.\n\n[BEEFY (Bridge Efficiency Enabling Finality Yielder)](/reference/polkadot-hub/consensus-and-security/pos-consensus/#bridging-beefy){target=\\_blank} is instrumental in this solution. It provides a more efficient way to verify the consensus on the relay chain. It allows the participants in a network to verify finality proofs, meaning a remote chain like Ethereum can verify the state of Polkadot at a given block height. \n\nFor example, the Ethereum and Polkadot bridging solution that [Snowbridge](https://docs.snowbridge.network/){target=\\_blank} implements involves two light clients: one which verifies the state of Polkadot and the other which verifies the state of Ethereum. The light client for Polkadot is implemented in the runtime as a pallet, whereas the light client for Ethereum is implemented as a smart contract on the beacon chain."}
{"page_id": "reference-polkadot-hub-bridging", "page_title": "Bridge Hub", "index": 2, "depth": 2, "title": "Bridging Components", "anchor": "bridging-components", "start_char": 2671, "end_char": 3623, "estimated_token_count": 242, "token_estimator": "heuristic-v1", "text": "## Bridging Components\n\nIn any given Bridge Hub implementation (Kusama, Polkadot, or other relay chains), there are a few primary pallets that are utilized:\n\n- **[Pallet Bridge GRANDPA](https://paritytech.github.io/polkadot-sdk/master/pallet_bridge_grandpa/index.html){target=\\_blank}**: An on-chain GRANDPA light client for Substrate based chains.\n- **[Pallet Bridge Parachains](https://paritytech.github.io/polkadot-sdk/master/pallet_bridge_parachains/index.html){target=\\_blank}**: A finality module for parachains.\n- **[Pallet Bridge Messages](https://paritytech.github.io/polkadot-sdk/master/pallet_bridge_messages/index.html){target=\\_blank}**: A pallet which allows sending, receiving, and tracking of inbound and outbound messages.\n- **[Pallet XCM Bridge](https://paritytech.github.io/polkadot-sdk/master/pallet_xcm_bridge_hub/index.html){target=\\_blank}**: A pallet which, with the Bridge Messages pallet, adds XCM support to bridge pallets."}
{"page_id": "reference-polkadot-hub-bridging", "page_title": "Bridge Hub", "index": 3, "depth": 3, "title": "Ethereum-Specific Support", "anchor": "ethereum-specific-support", "start_char": 3623, "end_char": 4243, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "### Ethereum-Specific Support\n\nBridge Hub also has a set of components and pallets that support a bridge between Polkadot and Ethereum through [Snowbridge](https://github.com/Snowfork/snowbridge){target=\\_blank}.\n\nTo view the complete list of which pallets are included in Bridge Hub, visit the Subscan [Runtime Modules](https://bridgehub-polkadot.subscan.io/runtime){target=\\_blank} page. Alternatively, the source code for those pallets can be found in the Polkadot SDK [Snowbridge Pallets](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2506-2/bridges/snowbridge/pallets){target=\\_blank} repository."}
{"page_id": "reference-polkadot-hub-bridging", "page_title": "Bridge Hub", "index": 4, "depth": 2, "title": "Deployed Bridges", "anchor": "deployed-bridges", "start_char": 4243, "end_char": 4840, "estimated_token_count": 160, "token_estimator": "heuristic-v1", "text": "## Deployed Bridges\n\n- [**Snowbridge**](https://wiki.polkadot.com/learn/learn-snowbridge/){target=\\_blank}: A general-purpose, trustless bridge between Polkadot and Ethereum.\n- [**Hyperbridge**](https://wiki.polkadot.com/learn/learn-hyperbridge/){target=\\_blank}: A cross-chain solution built as an interoperability coprocessor, providing state-proof-based interoperability across all blockchains.\n- [**Polkadot <> Kusama Bridge**](https://wiki.polkadot.com/learn/learn-dot-ksm-bridge/){target=\\_blank}: A bridge that utilizes relayers to bridge the Polkadot and Kusama relay chains trustlessly."}
{"page_id": "reference-polkadot-hub-bridging", "page_title": "Bridge Hub", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4840, "end_char": 5467, "estimated_token_count": 172, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n- Go over the Bridge Hub README in the Polkadot SDK [Bridge-hub Parachains](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506-2/cumulus/parachains/runtimes/bridge-hubs/README.md){target=\\_blank} repository.\n- Take a deeper dive into bridging architecture in the Polkadot SDK [High-Level Bridge](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506-2/bridges/docs/high-level-overview.md){target=\\_blank} documentation.\n- Read more about [BEEFY and Bridging in the Polkadot Wiki](/reference/polkadot-hub/consensus-and-security/pos-consensus/#bridging-beefy){target=\\_blank}."}
{"page_id": "reference-polkadot-hub-collectives-and-daos", "page_title": "Collectives Chain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 824, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEstablished through [Referendum 81](https://polkadot-old.polkassembly.io/referendum/81){target=\\_blank}, the Collectives chain operates as a dedicated parachain exclusive to the Polkadot network with no counterpart on Kusama. This specialized infrastructure provides a foundation for various on-chain governance groups essential to Polkadot's ecosystem.\n\nThe architecture enables entire networks to function as unified entities, allowing them to present cohesive positions and participate in cross-network governance through [Bridge Hub](/polkadot-protocol/architecture/system-chains/bridge-hub){target=\\_blank}. This capability represents a fundamental advancement in Web3 principles, eliminating dependencies on traditional third-party intermediaries such as legal systems or jurisdictional authorities."}
{"page_id": "reference-polkadot-hub-collectives-and-daos", "page_title": "Collectives Chain", "index": 1, "depth": 2, "title": "Key Collectives", "anchor": "key-collectives", "start_char": 824, "end_char": 2288, "estimated_token_count": 274, "token_estimator": "heuristic-v1", "text": "## Key Collectives\n\nThe Collectives chain hosts several important governance bodies:\n\n- [**Polkadot Technical Fellowship**](https://wiki.polkadot.com/learn/learn-polkadot-technical-fellowship/){target=\\_blank}: A self-governing assembly of protocol experts and developers who oversee technical aspects of the Polkadot and Kusama networks. The Fellowship operates both on-chain through the collectives system and off-chain via GitHub repositories, public discussion forums, and monthly development calls that are publicly accessible.\n\n- [**Polkadot Alliance**](https://wiki.polkadot.com/general/glossary/#polkadot-alliance){target=\\_blank}: A consortium founded by seven leading parachain projects (Acala, Astar, Interlay, Kilt, Moonbeam, Phala, and Subscan) to establish development standards and ethical guidelines within the ecosystem. This ranked collective, comprised of \"Fellows\" and \"Allies,\" focuses on promoting best practices and identifying potential bad actors. Membership is primarily designed for organizations, projects, and other networks rather than individuals.\n\nThese collectives serve as pillars of Polkadot's decentralized governance model, enabling community-driven decision-making and establishing technical standards that shape the network's evolution. Through structured on-chain representation, they provide transparent mechanisms for ecosystem development while maintaining the core Web3 principles of trustlessness and decentralization."}
{"page_id": "reference-polkadot-hub-consensus-and-security-agile-coretime", "page_title": "Agile Coretime", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 1479, "estimated_token_count": 318, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAgile Coretime is the [scheduling](https://en.wikipedia.org/wiki/Scheduling_(computing)){target=\\_blank} framework on Polkadot that lets parachains efficiently access cores, which comprise an active validator set tasked with parablock validation. As the first blockchain to enable a flexible scheduling system for blockspace production, Polkadot offers unparalleled adaptability for parachains.\n\n``` mermaid\ngraph TB\n    A[Cores Designation]\n    B[Bulk Coretime]\n    C[On-Demand Coretime]\n    A --continuous--> B\n    A --flexible--> C \n```\n\nCores can be designated to a parachain either continuously through [bulk coretime](#bulk-coretime) or dynamically via [on-demand coretime](#on-demand-coretime). Additionally, Polkadot supports scheduling multiple cores in parallel through [elastic scaling](https://wiki.polkadot.com/learn/learn-elastic-scaling/){target=\\_blank}, which is a feature under active development on Polkadot. This flexibility empowers parachains to optimize their resource usage and block production according to their unique needs.\n\nIn this guide, you'll learn how bulk coretime enables continuous core access with features like interlacing and splitting, and how on-demand coretime provides flexible, pay-per-use scheduling for parachains. For a deep dive on Agile Coretime and its terminology, refer to the [Wiki doc](https://wiki.polkadot.com/learn/learn-agile-coretime/#introduction-to-agile-coretime){target=\\_blank}."}
{"page_id": "reference-polkadot-hub-consensus-and-security-agile-coretime", "page_title": "Agile Coretime", "index": 1, "depth": 2, "title": "Bulk Coretime", "anchor": "bulk-coretime", "start_char": 1479, "end_char": 2179, "estimated_token_count": 148, "token_estimator": "heuristic-v1", "text": "## Bulk Coretime\n\nBulk coretime is a fixed duration of continuous coretime represented by an NFT that can be purchased through [coretime sales](#coretime-sales) in DOT and can be split, shared, or resold. Currently, the duration of bulk coretime is set to 28 days. Coretime purchased in bulk and assigned to a single parachain is eligible for a price-capped renewal, providing a form of rent-controlled access, which is important for predicting the running costs in the near future. Suppose the bulk coretime is [interlaced](#coretime-interlacing) or [split](#coretime-splitting) or is kept idle without assigning it to a parachain. In that case, it will be ineligible for the price-capped renewal."}
{"page_id": "reference-polkadot-hub-consensus-and-security-agile-coretime", "page_title": "Agile Coretime", "index": 2, "depth": 3, "title": "Coretime Interlacing", "anchor": "coretime-interlacing", "start_char": 2179, "end_char": 2550, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "### Coretime Interlacing\n\nIt is the action of dividing bulk coretime across multiple parachains that produce blocks spaced uniformly in time. For example, think of multiple parachains taking turns producing blocks, demonstrating a simple form of interlacing. This feature can be used by parachains with a low transaction volume and need not continuously produce blocks."}
{"page_id": "reference-polkadot-hub-consensus-and-security-agile-coretime", "page_title": "Agile Coretime", "index": 3, "depth": 3, "title": "Coretime Splitting", "anchor": "coretime-splitting", "start_char": 2550, "end_char": 2815, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "### Coretime Splitting\n\nIt is the action of dividing bulk coretime into multiple contiguous regions. This feature can be used by parachains that need to produce blocks continuously but do not require the whole 28 days of bulk coretime and require only part of it."}
{"page_id": "reference-polkadot-hub-consensus-and-security-agile-coretime", "page_title": "Agile Coretime", "index": 4, "depth": 2, "title": "On-Demand Coretime", "anchor": "on-demand-coretime", "start_char": 2815, "end_char": 3028, "estimated_token_count": 42, "token_estimator": "heuristic-v1", "text": "## On-Demand Coretime\n\nPolkadot has dedicated cores assigned to provide core time on demand. These cores are excluded from the coretime sales and are reserved for on-demand parachains, which pay in DOT per block."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 761, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's Proof of Stake consensus model leverages a unique hybrid approach by design to promote decentralized and secure network operations. In traditional Proof of Stake (PoS) systems, a node's ability to validate transactions is tied to its token holdings, which can lead to centralization risks and limited validator participation. Polkadot addresses these concerns through its [Nominated Proof of Stake (NPoS)](/reference/glossary/#nominated-proof-of-stake-npos){target=\\_blank} model and a combination of advanced consensus mechanisms to ensure efficient block production and strong finality guarantees. This combination enables the Polkadot network to scale while maintaining security and decentralization."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 1, "depth": 2, "title": "Nominated Proof of Stake", "anchor": "nominated-proof-of-stake", "start_char": 761, "end_char": 1788, "estimated_token_count": 215, "token_estimator": "heuristic-v1", "text": "## Nominated Proof of Stake\n\nPolkadot uses Nominated Proof of Stake (NPoS) to select the validator set and secure the network. This model is designed to maximize decentralization and security by balancing the roles of [validators](https://wiki.polkadot.com/learn/learn-validator/){target=\\_blank} and [nominators](https://wiki.polkadot.com/learn/learn-nominator/){target=\\_blank}.\n\n- **Validators**: Play a key role in maintaining the network's integrity. They produce new blocks, validate parachain blocks, and ensure the finality of transactions across the relay chain.\n- **Nominators**: Support the network by selecting validators to back with their stake. This mechanism allows users who don't want to run a validator node to still participate in securing the network and earn rewards based on the validators they support.\n\nIn Polkadot's NPoS system, nominators can delegate their tokens to trusted validators, giving them voting power in selecting validators while spreading security responsibilities across the network."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 2, "depth": 2, "title": "Hybrid Consensus", "anchor": "hybrid-consensus", "start_char": 1788, "end_char": 2840, "estimated_token_count": 193, "token_estimator": "heuristic-v1", "text": "## Hybrid Consensus\n\nPolkadot employs a hybrid consensus model that combines two key protocols: a finality gadget called [GRANDPA](#finality-gadget-grandpa) and a block production mechanism known as [BABE](#block-production-babe). This hybrid approach enables the network to benefit from both rapid block production and provable finality, ensuring security and performance.\n\nThe hybrid consensus model has some key advantages:\n\n- **Probabilistic finality**: With BABE constantly producing new blocks, Polkadot ensures that the network continues to make progress, even when a final decision has not yet been reached on which chain is the true canonical chain.\n\n- **Provable finality**: GRANDPA guarantees that once a block is finalized, it can never be reverted, ensuring that all network participants agree on the finalized chain.\n\nBy using separate protocols for block production and finality, Polkadot can achieve rapid block creation and strong guarantees of finality while avoiding the typical trade-offs seen in traditional consensus mechanisms."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 3, "depth": 2, "title": "Block Production - BABE", "anchor": "block-production-babe", "start_char": 2840, "end_char": 4656, "estimated_token_count": 360, "token_estimator": "heuristic-v1", "text": "## Block Production - BABE\n\nBlind Assignment for Blockchain Extension (BABE) is Polkadot's block production mechanism, working with GRANDPA to ensure blocks are produced consistently across the network. As validators participate in BABE, they are assigned block production slots through a randomness-based lottery system. This helps determine which validator is responsible for producing a block at a given time. BABE shares similarities with [Ouroboros Praos](https://eprint.iacr.org/2017/573.pdf){target=\\_blank} but differs in key aspects like chain selection rules and slot timing.\n\nKey features of BABE include:\n\n- **Epochs and slots**: BABE operates in phases called epochs, each of which is divided into slots (around 6 seconds per slot). Validators are assigned slots at the beginning of each epoch based on stake and randomness.\n\n- **Randomized block production**: Validators enter a lottery to determine which will produce a block in a specific slot. This randomness is sourced from the relay chain's [randomness cycle](/reference/parachains/randomness/){target=\\_blank}.\n\n- **Multiple block producers per slot**: In some cases, more than one validator might win the lottery for the same slot, resulting in multiple blocks being produced. These blocks are broadcasted, and the network's fork choice rule helps decide which chain to follow.\n\n- **Handling empty slots**: If no validators win the lottery for a slot, a secondary selection algorithm ensures that a block is still produced. Validators selected through this method always produce a block, ensuring no slots are skipped.\n\nBABE's combination of randomness and slot allocation creates a secure, decentralized system for consistent block production while also allowing for fork resolution when multiple validators produce blocks for the same slot."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 4, "depth": 3, "title": "Validator Participation", "anchor": "validator-participation", "start_char": 4656, "end_char": 6311, "estimated_token_count": 331, "token_estimator": "heuristic-v1", "text": "### Validator Participation\n\nIn BABE, validators participate in a lottery for every slot to determine whether they are responsible for producing a block during that slot. This process's randomness ensures a decentralized and unpredictable block production mechanism.\n\nThere are two lottery outcomes for any given slot that initiate additional processes:\n\n- **Multiple validators in a slot**: Due to the randomness, multiple validators can be selected to produce a block for the same slot. When this happens, each validator produces a block and broadcasts it to the network resulting in a race condition. The network's topology and latency then determine which block reaches the majority of nodes first. BABE allows both chains to continue building until the finalization process resolves which one becomes canonical. The [Fork Choice](#fork-choice) rule is then used to decide which chain the network should follow.\n\n- **No validators in a slot**: On occasions when no validator is selected by the lottery, a [secondary validator selection algorithm](https://spec.polkadot.network/sect-block-production#defn-babe-secondary-slots){target=\\_blank} steps in. This backup ensures that a block is still produced, preventing skipped slots. However, if the primary block produced by a verifiable random function [(VRF)-selected](/reference/parachains/randomness/#vrf){target=\\_blank} validator exists for that slot, the secondary block will be ignored. As a result, every slot will have either a primary or a secondary block.\n\nThis design ensures continuous block production, even in cases of multiple competing validators or an absence of selected validators."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 5, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources", "start_char": 6311, "end_char": 6806, "estimated_token_count": 111, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nFor further technical insights about BABE, including cryptographic details and formal proofs, see the [BABE paper](https://research.web3.foundation/Polkadot/protocols/block-production/Babe){target=\\_blank} from Web3 Foundation.\n\nFor BABE technical definitions, constants, and formulas, see the [Block Production Lottery](https://spec.polkadot.network/sect-block-production#sect-block-production-lottery){target=\\_blank} section of the Polkadot Protocol Specification."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 6, "depth": 2, "title": "Finality Gadget - GRANDPA", "anchor": "finality-gadget-grandpa", "start_char": 6806, "end_char": 8324, "estimated_token_count": 292, "token_estimator": "heuristic-v1", "text": "## Finality Gadget - GRANDPA\n\nGRANDPA (GHOST-based Recursive ANcestor Deriving Prefix Agreement) serves as the finality gadget for Polkadot's relay chain. Operating alongside the BABE block production mechanism, it ensures provable finality, giving participants confidence that blocks finalized by GRANDPA cannot be reverted.\n\nKey features of GRANDPA include:\n\n- **Independent finality service**: GRANDPA runs separately from the block production process, operating in parallel to ensure seamless finalization.\n- **Chain-based finalization**: Instead of finalizing one block at a time, GRANDPA finalizes entire chains, speeding up the process significantly.\n- **Batch finalization**: Can finalize multiple blocks in a single round, enhancing efficiency and minimizing delays in the network.\n- **Partial synchrony tolerance**: GRANDPA works effectively in a partially synchronous network environment, managing both asynchronous and synchronous conditions.\n- **Byzantine fault tolerance**: Can handle up to 1/5 Byzantine (malicious) nodes, ensuring the system remains secure even when faced with adversarial behavior.\n\n??? note \"What is GHOST?\"\n    [GHOST (Greedy Heaviest-Observed Subtree)](https://eprint.iacr.org/2018/104.pdf){target=\\blank} is a consensus protocol used in blockchain networks to select the heaviest branch in a block tree. Unlike traditional longest-chain rules, GHOST can more efficiently handle high block production rates by considering the weight of subtrees rather than just the chain length."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 7, "depth": 3, "title": "Probabilistic vs. Provable Finality", "anchor": "probabilistic-vs-provable-finality", "start_char": 8324, "end_char": 9130, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "### Probabilistic vs. Provable Finality\n\nIn traditional Proof of Work (PoW) blockchains, finality is probabilistic. As blocks are added to the chain, the probability that a block is final increases, but it can never be guaranteed. Eventual consensus means that all nodes will agree on a single version of the blockchain over time, but this process can be unpredictable and slow.\n\nConversely, GRANDPA provides provable finality, which means that once a block is finalized, it is irreversible. By using Byzantine fault-tolerant agreements, GRANDPA finalizes blocks more efficiently and securely than probabilistic mechanisms like Nakamoto consensus. Like Ethereum's Casper the Friendly Finality Gadget (FFG), GRANDPA ensures that finalized blocks cannot be reverted, offering stronger consensus guarantees."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 8, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources-2", "start_char": 9130, "end_char": 9678, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nFor technical insights, including formal proofs and detailed algorithms, see the [GRANDPA paper](https://github.com/w3f/consensus/blob/master/pdf/grandpa.pdf){target=\\_blank} from Web3 Foundation.\n\nFor a deeper look at the code behind GRANDPA, see the following GitHub repositories:\n\n- [GRANDPA Rust implementation](https://github.com/paritytech/finality-grandpa){target=\\_blank}\n- [GRANDPA Pallet](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2506-2/substrate/frame/grandpa/src/lib.rs){target=\\_blank}"}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 9, "depth": 2, "title": "Fork Choice", "anchor": "fork-choice", "start_char": 9678, "end_char": 10520, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## Fork Choice\n\nThe fork choice of the relay chain combines BABE and GRANDPA:\n\n1. BABE must always build on the chain that GRANDPA has finalized.\n2. When there are forks after the finalized head, BABE builds on the chain with the most primary blocks to provide probabilistic finality.\n\n![Fork choice diagram](/images/reference/polkadot-hub/consensus-and-security/pos-consensus/consensus-protocols-01.webp)\n\nIn the preceding diagram, finalized blocks are black, and non-finalized blocks are yellow. Primary blocks are labeled '1', and secondary blocks are labeled '2.' The topmost chain is the longest chain originating from the last finalized block, but it is not selected because it only has one primary block at the time of evaluation. In comparison, the one below it originates from the last finalized block and has three primary blocks."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 10, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources-3", "start_char": 10520, "end_char": 11107, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nTo learn more about how BABE and GRANDPA work together to produce and finalize blocks on Kusama, see this [Block Production and Finalization in Polkadot](https://youtu.be/FiEAnVECa8c){target=\\_blank} talk from Web3 Foundation's Bill Laboon. \n\nFor an in-depth academic discussion about Polkadot's hybrid consensus model, see this [Block Production and Finalization in Polkadot: Understanding the BABE and GRANDPA Protocols](https://www.youtube.com/watch?v=1CuTSluL7v4&t=4s){target=\\_blank} MIT Cryptoeconomic Systems 2020 talk by Web3 Foundation's Bill Laboon."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 11, "depth": 2, "title": "Bridging - BEEFY", "anchor": "bridging-beefy", "start_char": 11107, "end_char": 12509, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "## Bridging - BEEFY\n\nBridge Efficiency Enabling Finality Yielder (BEEFY) is a specialized protocol that extends the finality guarantees provided by GRANDPA. It is specifically designed to facilitate efficient bridging between Polkadot relay chains (such as Polkadot and Kusama) and external blockchains like Ethereum. While GRANDPA is well-suited for finalizing blocks within Polkadot, it has limitations when bridging external chains that weren't built with Polkadot's interoperability features in mind. BEEFY addresses these limitations by ensuring other networks can efficiently verify finality proofs.\n\nKey features of BEEFY include:\n\n- **Efficient finality proof verification**: BEEFY enables external networks to easily verify Polkadot finality proofs, ensuring seamless communication between chains.\n- **Merkle Mountain Ranges (MMR)**: This data structure is used to efficiently store and transmit proofs between chains, optimizing data storage and reducing transmission overhead.\n- **ECDSA signature schemes**: BEEFY uses ECDSA signatures, which are widely supported on Ethereum and other EVM-based chains, making integration with these ecosystems smoother.\n- **Light client optimization**: BEEFY reduces the computational burden on light clients by allowing them to check for a super-majority of validator votes rather than needing to process all validator signatures, improving performance."}
{"page_id": "reference-polkadot-hub-consensus-and-security-pos-consensus", "page_title": "Proof of Stake Consensus", "index": 12, "depth": 3, "title": "Additional Resources", "anchor": "additional-resources-4", "start_char": 12509, "end_char": 12753, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "### Additional Resources\n\nFor BEEFY technical definitions, constants, and formulas, see the [Bridge design (BEEFY)](https://spec.polkadot.network/sect-finality#sect-grandpa-beefy){target=\\_blank} section of the Polkadot Protocol Specification."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 12, "end_char": 876, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot is a next-generation blockchain protocol designed to support a multi-chain future by enabling secure communication and interoperability between different blockchains. Built as a Layer-0 protocol, Polkadot introduces innovations like application-specific Layer-1 chains ([parachains](/polkadot-protocol/architecture/parachains/){targe=\\_blank}), shared security through [Nominated Proof of Stake (NPoS)](/reference/glossary/#nominated-proof-of-stake-npos){target=\\_blank}, and cross-chain interactions via its native [Cross-Consensus Messaging Format (XCM)](/parachains/interoperability/get-started/){target=\\_blank}.\n\nThis guide covers key aspects of Polkadotâ€™s architecture, including its high-level protocol structure, blockspace commoditization, and the role of its native token, DOT, in governance, staking, and resource allocation."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 1, "depth": 2, "title": "Polkadot 1.0", "anchor": "polkadot-10", "start_char": 876, "end_char": 2903, "estimated_token_count": 458, "token_estimator": "heuristic-v1", "text": "## Polkadot 1.0\n\nPolkadot 1.0 represents the state of Polkadot as of 2023, coinciding with the release of [Polkadot runtime v1.0.0](https://github.com/paritytech/polkadot/releases/tag/v1.0.0){target=\\_blank}. This section will focus on Polkadot 1.0, along with philosophical insights into network resilience and blockspace.\n\nAs a Layer-0 blockchain, Polkadot contributes to the multi-chain vision through several key innovations and initiatives, including:\n\n- **Application-specific Layer-1 blockchains (parachains)**: Polkadot's sharded network allows for parallel transaction processing, with shards that can have unique state transition functions, enabling custom-built L1 chains optimized for specific applications.\n\n- **Shared security and scalability**: L1 chains connected to Polkadot benefit from its [Nominated Proof of Stake (NPoS)](/reference/polkadot-hub/consensus-and-security/pos-consensus/#nominated-proof-of-stake){target=\\_blank} system, providing security out-of-the-box without the need to bootstrap their own.\n\n- **Secure interoperability**: Polkadot's native interoperability enables seamless data and value exchange between parachains. This interoperability can also be used outside of the ecosystem for bridging with external networks.\n\n- **Resilient infrastructure**: Decentralized and scalable, Polkadot ensures ongoing support for development and community initiatives via its on-chain [treasury](https://wiki.polkadot.com/learn/learn-polkadot-opengov-treasury/){target=\\_blank} and governance.\n\n- **Rapid L1 development**: The [Polkadot SDK](/reference/parachains/){target=\\_blank} allows fast, flexible creation and deployment of Layer-1 chains.\n\n- **Cultivating the next generation of Web3 developers**: Polkadot supports the growth of Web3 core developers through initiatives such as.\n\n    - [Polkadot Blockchain Academy](https://polkadot.com/blockchain-academy){target=\\_blank}\n    - [EdX courses](https://www.edx.org/school/web3x){target=\\_blank}\n    - Rust and Substrate courses (coming soon)"}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 2, "depth": 3, "title": "High-Level Architecture", "anchor": "high-level-architecture", "start_char": 2903, "end_char": 4245, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "### High-Level Architecture\n\nPolkadot features a chain that serves as the central component of the system. This chain is depicted as a ring encircled by several parachains that are connected to it.\n\nAccording to Polkadot's design, any blockchain that can compile to WebAssembly (Wasm) and adheres to the Parachains Protocol becomes a parachain on the Polkadot network.\n\nHereâ€™s a high-level overview of the Polkadot protocol architecture:\n\n![](/images/reference/polkadot-hub/consensus-and-security/relay-chain/relay-chain-01.webp){ style=\"background:white\" }\n\nParachains propose blocks to Polkadot validators, who check for availability and validity before finalizing them. With the relay chain providing security, collatorsâ€”full nodes of parachainsâ€”can focus on their tasks without needing strong incentives.\n\nThe [Cross-Consensus Messaging Format (XCM)](/parachains/interoperability/get-started/){target=\\_blank} allows parachains to exchange messages freely, leveraging the chain's security for trust-free communication.\n\nIn order to interact with chains that want to use their own finalization process (e.g., Bitcoin), Polkadot has [bridges](/reference/parachains/interoperability/#bridges-connecting-external-networks){target=\\_blank} that offer two-way compatibility, meaning that transactions can be made between different parachains."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 3, "depth": 3, "title": "Polkadot's Additional Functionalities", "anchor": "polkadots-additional-functionalities", "start_char": 4245, "end_char": 6180, "estimated_token_count": 422, "token_estimator": "heuristic-v1", "text": "### Polkadot's Additional Functionalities\n\nHistorically, obtaining core slots on Polkadot chain relied upon crowdloans and auctions. Chain cores were leased through auctions for three-month periods, up to a maximum of two years. Crowdloans enabled users to securely lend funds to teams for lease deposits in exchange for pre-sale tokens, which is the only way to access slots on Polkadot 1.0. Auctions are now deprecated in favor of [coretime](/polkadot-protocol/architecture/system-chains/coretime/){target=\\_blank}.\n\nAdditionally, the chain handles [staking](https://wiki.polkadot.com/learn/learn-staking/){target=\\_blank}, [accounts](/reference/parachains/accounts/){target=\\_blank}, balances, and [governance](/reference/governance/){target=\\_blank}.\n\n#### Agile Coretime\n\nThe new and more efficient way of obtaining core on Polkadot is to go through the process of purchasing coretime.\n\n[Agile coretime](/reference/polkadot-hub/consensus-and-security/agile-coretime/){target=\\_blank} improves the efficient use of Polkadot's network resources and offers economic flexibility for developers, extending Polkadot's capabilities far beyond the original vision outlined in the [whitepaper](https://polkadot.com/papers/Polkadot-whitepaper.pdf){target=\\_blank}.\n\nIt enables parachains to purchase monthly \"bulk\" allocations of coretime (the time allocated for utilizing a core, measured in Polkadot relay chain blocks), ensuring heavy-duty parachains that can author a block every six seconds with [Asynchronous Backing](https://wiki.polkadot.com/learn/learn-async-backing/#asynchronous-backing){target=\\_blank} can reliably renew their coretime each month. Although six-second block times are now the default, parachains have the option of producing blocks less frequently.\n\nRenewal orders are prioritized over new orders, offering stability against price fluctuations and helping parachains budget more effectively for project costs."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 4, "depth": 3, "title": "Polkadot's Resilience", "anchor": "polkadots-resilience", "start_char": 6180, "end_char": 7464, "estimated_token_count": 253, "token_estimator": "heuristic-v1", "text": "### Polkadot's Resilience\n\nDecentralization is a vital component of blockchain networks, but it comes with trade-offs:\n\n- An overly decentralized network may face challenges in reaching consensus and require significant energy to operate.\n- Also, a network that achieves consensus quickly risks centralization, making it easier to manipulate or attack.\n\nA network should be decentralized enough to prevent manipulative or malicious influence. In this sense, decentralization is a tool for achieving resilience.\n\nPolkadot 1.0 currently achieves resilience through several strategies:\n\n- **Nominated Proof of Stake (NPoS)**: Ensures that the stake per validator is maximized and evenly distributed among validators.\n\n- **Decentralized nodes**: Designed to encourage operators to join the network. This program aims to expand and diversify the validators in the ecosystem who aim to become independent of the program during their term. Feel free to explore more about the program on the official [Decentralized Nodes](https://nodes.web3.foundation/){target=\\_blank} page.\n\n- **On-chain treasury and governance**: Known as [OpenGov](/reference/governance/){target=\\_blank}, this system allows every decision to be made through public referenda, enabling any token holder to cast a vote."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 5, "depth": 3, "title": "Polkadot's Blockspace", "anchor": "polkadots-blockspace", "start_char": 7464, "end_char": 9276, "estimated_token_count": 363, "token_estimator": "heuristic-v1", "text": "### Polkadot's Blockspace\n\nPolkadot 1.0â€™s design allows for the commoditization of blockspace.\n\nBlockspace is a blockchain's capacity to finalize and commit operations, encompassing its security, computing, and storage capabilities. Its characteristics can vary across different blockchains, affecting security, flexibility, and availability.\n\n- **Security**: Measures the robustness of blockspace in Proof of Stake (PoS) networks linked to the stake locked on validator nodes, the variance in stake among validators, and the total number of validators. It also considers social centralization (how many validators are owned by single operators) and physical centralization (how many validators run on the same service provider).\n\n- **Flexibility**: Reflects the functionalities and types of data that can be stored, with high-quality data essential to avoid bottlenecks in critical processes.\n\n- **Availability**: Indicates how easily users can access blockspace. It should be easily accessible, allowing diverse business models to thrive, ideally regulated by a marketplace based on demand and supplemented by options for \"second-hand\" blockspace.\n\nPolkadot is built on core blockspace principles, but there's room for improvement. Tasks like balance transfers, staking, and governance are managed on the relay chain.\n\nDelegating these responsibilities to [system chains](/polkadot-protocol/architecture/system-chains/){target=\\_blank} could enhance flexibility and allow the relay chain to concentrate on providing shared security and interoperability.\n\nFor more information about blockspace, watch [Robert Habermeierâ€™s interview](https://www.youtube.com/watch?v=e1vISppPwe4){target=\\_blank} or read his [technical blog post](https://www.rob.tech/blog/polkadot-blockspace-over-blockchains/){target=\\_blank}."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 6, "depth": 2, "title": "DOT Token", "anchor": "dot-token", "start_char": 9276, "end_char": 9569, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "## DOT Token\n\nDOT is the native token of the Polkadot network, much like BTC for Bitcoin and Ether for the Ethereum blockchain. DOT has 10 decimals, uses the Planck base unit, and has a balance type of `u128`. The same is true for Kusama's KSM token with the exception of having 12 decimals."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 7, "depth": 3, "title": "Redenomination of DOT", "anchor": "redenomination-of-dot", "start_char": 9569, "end_char": 10121, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Redenomination of DOT\n    \nPolkadot conducted a community poll, which ended on 27 July 2020 at block 888,888, to decide whether to redenominate the DOT token. The stakeholders chose to redenominate the token, changing the value of 1 DOT from 1e12 plancks to 1e10 plancks.\n\nImportantly, this did not affect the network's total number of base units (plancks); it only affects how a single DOT is represented. The redenomination became effective 72 hours after transfers were enabled, occurring at block 1,248,328 on 21 August 2020 around 16:50 UTC."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 8, "depth": 3, "title": "The Planck Unit", "anchor": "the-planck-unit", "start_char": 10121, "end_char": 10527, "estimated_token_count": 84, "token_estimator": "heuristic-v1", "text": "### The Planck Unit\n\nThe smallest unit of account balance on Polkadot SDK-based blockchains (such as Polkadot and Kusama) is called _Planck_, named after the Planck length, the smallest measurable distance in the physical universe.\n\nSimilar to how BTC's smallest unit is the Satoshi and ETH's is the Wei, Polkadot's native token DOT equals 1e10 Planck, while Kusama's native token KSM equals 1e12 Planck."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 9, "depth": 3, "title": "Uses for DOT", "anchor": "uses-for-dot", "start_char": 10527, "end_char": 11094, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### Uses for DOT\n\nDOT serves three primary functions within the Polkadot network:\n\n- **Governance**: It is used to participate in the governance of the network.\n- **Staking**: DOT is staked to support the network's operation and security.\n- **Buying coretime**: Used to purchase coretime in-bulk or on-demand and access the  chain to benefit from Polkadot's security and interoperability.\n\nAdditionally, DOT can serve as a transferable token. For example, DOT, held in the treasury, can be allocated to teams developing projects that benefit the Polkadot ecosystem."}
{"page_id": "reference-polkadot-hub-consensus-and-security-relay-chain", "page_title": "Overview of the Polkadot Relay Chain", "index": 10, "depth": 2, "title": "JAM and the Road Ahead", "anchor": "jam-and-the-road-ahead", "start_char": 11094, "end_char": 12458, "estimated_token_count": 239, "token_estimator": "heuristic-v1", "text": "## JAM and the Road Ahead\n\nThe Join-Accumulate Machine (JAM) represents a transformative redesign of Polkadot's core architecture, envisioned as the successor to the current relay chain. Unlike traditional blockchain architectures, JAM introduces a unique computational model that processes work through two primary functions:\n\n- **Join**: Handles data integration.\n- **Accumulate**: Folds computations into the chain's state.\n\nJAM removes many of the opinions and constraints of the current relay chain while maintaining its core security properties. Expected improvements include:\n\n- **Permissionless code execution**: JAM is designed to be more generic and flexible, allowing for permissionless code execution through services that can be deployed without governance approval.\n- **More effective block time utilization**: JAM's efficient pipeline processing model places the prior state root in block headers instead of the posterior state root, enabling more effective utilization of block time for computations.\n\nThis architectural evolution promises to enhance Polkadot's scalability and flexibility while maintaining robust security guarantees. JAM is planned to be rolled out to Polkadot as a single, complete upgrade rather than a stream of smaller updates. This approach seeks to minimize the developer overhead required to address any breaking changes."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 504, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPeople chain is a specialized parachain within the Polkadot ecosystem dedicated to secure, decentralized identity management. \n\nThis solution empowers users to create, control, and verify their digital identities without reliance on centralized authorities. By prioritizing user sovereignty and data privacy, People chain establishes a foundation for trusted interactions throughout the Polkadot ecosystem while returning control of personal information to individuals."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 1, "depth": 2, "title": "Identity Management System", "anchor": "identity-management-system", "start_char": 504, "end_char": 953, "estimated_token_count": 77, "token_estimator": "heuristic-v1", "text": "## Identity Management System\n\nPeople chain provides a comprehensive identity framework allowing users to:\n\n- Establish verifiable on-chain identities.\n- Control disclosure of personal information.\n- Receive verification from trusted registrars.\n- Link multiple accounts under a unified identity.\n\nUsers must reserve funds in a bond to store their information on chain. These funds are locked, not spent, and returned when the identity is cleared."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 2, "depth": 3, "title": "Sub-Identities", "anchor": "sub-identities", "start_char": 953, "end_char": 1224, "estimated_token_count": 52, "token_estimator": "heuristic-v1", "text": "### Sub-Identities\n\nThe platform supports hierarchical identity structures through sub-accounts:\n\n- Primary accounts can establish up to 100 linked sub-accounts.\n- Each sub-account maintains its own distinct identity.\n- All sub-accounts require a separate bond deposit."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 3, "depth": 2, "title": "Verification Process", "anchor": "verification-process", "start_char": 1224, "end_char": 1249, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Verification Process"}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 4, "depth": 3, "title": "Judgment Requests", "anchor": "judgment-requests", "start_char": 1249, "end_char": 1598, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "### Judgment Requests\n\nAfter establishing an on-chain identity, users can request verification from [registrars](#registrars):\n\n1. Users specify the maximum fee they're willing to pay for judgment.\n2. Only registrars whose fees fall below this threshold can provide verification.\n3. Registrars assess the provided information and issue a judgment."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 5, "depth": 3, "title": "Judgment Classifications", "anchor": "judgment-classifications", "start_char": 1598, "end_char": 2385, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "### Judgment Classifications\n\nRegistrars can assign the following confidence levels to identity information:\n\n- **Unknown**: Default status; no judgment rendered yet.\n- **Reasonable**: Data appears valid but without formal verification (standard for most verified identities).\n- **Known good**: Information certified correct through formal verification (requires documentation; limited to registrars).\n- **Out of date**: Previously verified information that requires updating.\n- **Low quality**: Imprecise information requiring correction.\n- **Erroneous**: Incorrect information, potentially indicating fraudulent intent.\n\nA temporary \"Fee Paid\" status indicates judgment in progress. Both \"Fee Paid\" and \"Erroneous\" statuses lock identity information from modification until resolved."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 6, "depth": 3, "title": "Registrars", "anchor": "registrars", "start_char": 2385, "end_char": 3680, "estimated_token_count": 198, "token_estimator": "heuristic-v1", "text": "### Registrars\n\nRegistrars serve as trusted verification authorities within the People chain ecosystem. These entities validate user identities and provide attestations that build trust in the network.\n\n- Registrars set specific fees for their verification services.\n- They can specialize in verifying particular identity fields.\n- Verification costs vary based on complexity and thoroughness.\n\nWhen requesting verification, users specify their maximum acceptable fee. Only registrars whose fees fall below this threshold can provide judgment. Upon completing the verification process, the user pays the registrar's fee, and the registrar issues an appropriate confidence level classification based on their assessment.\n\nMultiple registrars operate across the Polkadot and People chain ecosystems, each with unique specializations and fee structures. To request verification:\n\n1. Research available registrars and their verification requirements.\n2. Contact your chosen registrar directly through their specified channels.\n3. Submit required documentation according to their verification process.\n4. Pay the associated verification fee.\n\nYou must contact specific registrars individually to request judgment. Each registrar maintains its own verification procedures and communication channels."}
{"page_id": "reference-polkadot-hub-people-and-identity", "page_title": "People Chain", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3680, "end_char": 4750, "estimated_token_count": 257, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Polkadot.js Guides about Identity__\n\n    ---\n\n    Step-by-step instructions for managing identities through the Polkadot.js interface, with practical examples and visual guides.\n\n    [:octicons-arrow-right-24: Reference](https://wiki.polkadot.com/learn/learn-guides-identity/)\n\n-   <span class=\"badge external\">External</span> __How to Set and Clear an Identity__\n\n    ---\n\n    Practical walkthrough covering identity setup and removal process on People chain.\n\n    [:octicons-arrow-right-24: Reference](https://support.polkadot.network/support/solutions/articles/65000181981-how-to-set-and-clear-an-identity)\n\n-   <span class=\"badge external\">External</span> __People Chain Runtime Implementation__\n\n    ---\n\n    Source code for the People chain runtime, detailing the technical architecture of decentralized identity management.\n\n    [:octicons-arrow-right-24: Reference](https://github.com/polkadot-fellows/runtimes/tree/main/system-parachains/people)\n\n</div>"}
{"page_id": "reference-polkadot-hub-smart-contracts", "page_title": "Polkadot Hub Smart Contracts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 35, "end_char": 674, "estimated_token_count": 109, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub enables developers to deploy and interact with Solidity contracts through REVM, a high-performance, Rust-based Ethereum Virtual Machine implementation. Polkadot-native precompiles bring Ethereum compatibility to Polkadot Hub, letting teams use familiar Solidity tooling, integrate with on-chain features like governance and XCM, and take advantage of cross-chain interoperability.\n\nFor projects that require maximum computational performance, Polkadot Hub also supports PolkaVM (PVM), a native RISC-V execution engine. PVM is optional and designed for high-throughput, performance-intensive smart contracts."}
{"page_id": "reference-polkadot-hub-smart-contracts", "page_title": "Polkadot Hub Smart Contracts", "index": 1, "depth": 3, "title": "REVM Smart Contracts", "anchor": "revm-smart-contracts", "start_char": 674, "end_char": 1692, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "### REVM Smart Contracts\n\n[REVM](https://github.com/bluealloy/revm){target=_blank} brings full EVM compatibility to Polkadot Hub through a fast, memory-safe Rust implementation of the Ethereum Virtual Machine. Unlike PolkaVM, which compiles contracts to RISC-V for native execution, REVM executes standard Ethereum bytecode directlyâ€”making it ideal for teams who want to migrate existing Solidity projects to Polkadot with minimal changes.\n\nWith REVM, developers can:\n\n- Deploy existing Solidity contracts without rewriting them.\n- Use familiar Ethereum tooling like Hardhat, Foundry, Remix, and MetaMask.\n- Interact with other parachains and on-chain assets using XCM and Polkadot Hub features.\n\nREVM builds on Rustâ€™s safety guarantees and performance optimizations while retaining full opcode compatibility with the EVM. \n\nEthereum-native developers can use Polkadot-native precompiles to access Polkadot featuresâ€”such as governance, treasury, multisig, and XCMâ€”within a unified, interoperable runtime environment."}
{"page_id": "reference-polkadot-hub-smart-contracts", "page_title": "Polkadot Hub Smart Contracts", "index": 2, "depth": 3, "title": "PVM Smart Contracts", "anchor": "pvm-smart-contracts", "start_char": 1692, "end_char": 2678, "estimated_token_count": 191, "token_estimator": "heuristic-v1", "text": "### PVM Smart Contracts\n\nPVM is Polkadot Hubâ€™s native, high-performance smart contract engine. Instead of emulating EVM bytecode, it runs contracts compiled to a [RISC-V](https://en.wikipedia.org/wiki/RISC-V){target=_blank} instruction set, unlocking higher performance and parallel execution while staying friendly to Ethereum-style development.\n\nWith PVM, developers can:\n\n- Write Solidity contracts and use familiar tooling (e.g., Hardhat, Foundry) targeting PVM\n- Benefit from fast, predictable execution with carefully metered gas/weight.\n- Access detailed observability through Substrate events and contract logs for indexing and debugging.\n\nPolkaVM delivers maximum performance for computationally intensive contracts, offering a native, high-throughput option for Ethereum-style developers on Polkadot Hub.\n\n!!! smartcontract \"PolkaVM Preview Release\"\n    PolkaVM smart contracts with Ethereum compatibility are in **early-stage development and may be unstable or incomplete**."}
{"page_id": "reference-polkadot-hub-smart-contracts", "page_title": "Polkadot Hub Smart Contracts", "index": 3, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 2678, "end_char": 3309, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy a Basic Contract__\n\n    ---\n\n    Learn step-by-step how to deploy a basic Solidity smart contract to Polkadot Hub.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Explore Development Environments__\n\n    ---\n\n    Check out the development environments you can use to build, test, and deploy smart contracts.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/dev-environments/local-dev-node/)\n\n</div>"}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 710, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub is the entry point for all users and application developers to Polkadot. It provides access to essential Web3 services, including smart contracts, staking, governance, identity management, and cross-ecosystem interoperabilityâ€”without requiring you to deploy or manage a parachain.\n\nThe Hub encompasses a set of core functionality that enables developers and users to build and interact with applications on Polkadot. This specialized system of parachains and services works together seamlessly to deliver a unified platform experience. The modular approach lets you interact with services optimized for specific use cases, while still benefiting from Polkadot's shared security."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 1, "depth": 2, "title": "Polkadot Hub Capabilities", "anchor": "polkadot-hub-capabilities", "start_char": 710, "end_char": 1822, "estimated_token_count": 197, "token_estimator": "heuristic-v1", "text": "## Polkadot Hub Capabilities\n\nWhether you're just getting started or building complex applications, the Hub supports the ability to:\n \n- Hold, send, and receive DOT and other assets across the network.\n- Stake DOT to participate in network security and earn rewards.\n- Vote in governance referendums and shape Polkadot's future.\n- Create both fungible and non-fungible tokens and assets for your projects.\n- Pay transaction fees in any asset, not just DOT.\n- Register as an individual and establish your on-chain identity.\n\nFor more sophisticated development use cases, the Hub enables you to:\n\n- Deploy Ethereum-compatible smart contracts using Solidity or other EVM languages.\n- Build decentralized applications that leverage Polkadot's security and interoperability.\n- Create and manage fungible tokens and NFTs with low fees and flexible operations.\n- Manage cross-chain interactions through XCM messaging with other parachains.\n- Set verified identities and apply for network opportunities like the Ambassador Program.\n- Join collectives and participate in governance organizations with specialized roles."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 2, "depth": 2, "title": "Core Components", "anchor": "core-components", "start_char": 1822, "end_char": 1981, "estimated_token_count": 24, "token_estimator": "heuristic-v1", "text": "## Core Components\n\nThe Polkadot Hub consists of several specialized system parachains and services working together as described in the following sections."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 3, "depth": 3, "title": "Smart Contracts", "anchor": "smart-contracts", "start_char": 1981, "end_char": 2483, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "### Smart Contracts\n\n[Smart Contracts](/reference/polkadot-hub/smart-contracts/){target=\\_blank} on Polkadot Hub enable developers to deploy Ethereum-compatible smart contracts written in Solidity and other familiar EVM languages. Build decentralized applications with full access to Polkadot's security, interoperability, and cross-chain capabilities. Smart contracts on the Hub benefit from lower fees and integration with native Polkadot features, such as identity management and asset operations."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 4, "depth": 3, "title": "Asset Management", "anchor": "asset-management", "start_char": 2483, "end_char": 3047, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "### Asset Management\n\n[Asset Management](/reference/polkadot-hub/assets/){target=\\_blank} provides the foundation for on-chain asset management. Create, manage, and transfer fungible tokens and NFTs across the ecosystem. Asset Management offers significantly lower transaction feesâ€”approximately one-tenth the cost of relay chain transactionsâ€”and reduced deposit requirements, making it ideal for projects managing digital assets at scale. It also enables payment of transaction fees in non-native assets, providing developers and users with greater flexibility."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 5, "depth": 3, "title": "People Chain", "anchor": "people-chain", "start_char": 3047, "end_char": 3489, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "### People Chain\n\n[People Chain](/reference/polkadot-hub/people-and-identity/){target=\\_blank} powers Polkadot's decentralized identity system. Establish verifiable on-chain identities, control disclosure of personal information, and receive verification from trusted registrars. People Chain enables secure identity management with hierarchical sub-account support, forming the foundation for trusted interactions throughout the ecosystem."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 6, "depth": 3, "title": "Bridge Hub", "anchor": "bridge-hub", "start_char": 3489, "end_char": 3900, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "### Bridge Hub\n\n[Bridge Hub](/reference/polkadot-hub/bridging/){target=\\_blank} facilitates trustless interactions between Polkadot and external blockchains like Ethereum and Kusama. Through implementations such as Snowbridge, Bridge Hub enables secure cross-chain communication via on-chain light clients and trustless relayers. This component ensures seamless interoperability beyond the Polkadot ecosystem."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 7, "depth": 3, "title": "Consensus & Security", "anchor": "consensus-security", "start_char": 3900, "end_char": 4337, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### Consensus & Security\n\n[Consensus and Security](/reference/polkadot-hub/consensus-and-security/){target=\\_blank} covers the fundamental mechanisms that protect the network. Learn about validator participation, how the relay chain validates all transactions, and the cryptoeconomic incentives that secure Polkadot. Understanding these mechanisms is essential for validators and anyone building critical infrastructure on the network."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 8, "depth": 3, "title": "Collectives & DAOs", "anchor": "collectives-daos", "start_char": 4337, "end_char": 4745, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "### Collectives & DAOs\n\n[Collectives and DAOs](/reference/polkadot-hub/collectives-and-daos/){target=\\_blank} enable specialized governance organizations within Polkadot. Participate in collective membership, manage treasury operations, and engage in coordinated decision-making with groups aligned around specific purposes. This functionality supports the creation of autonomous organizations on Polkadot."}
{"page_id": "reference-polkadot-hub", "page_title": "Polkadot Hub Overview", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4745, "end_char": 6331, "estimated_token_count": 396, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nConsider the following resources to explore specific Hub functionality.\n\n<div class=\"grid cards\" markdown>\n\n- <span class=\"badge learn\">Learn</span> **Smart Contracts**\n\n    ---\n\n    Deploy Ethereum-compatible smart contracts and build decentralized applications.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/smart-contracts/)\n\n- <span class=\"badge learn\">Learn</span> **Asset Management**\n\n    ---\n\n    Manage fungible tokens and NFTs with low fees and flexible asset operations.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/assets/)\n\n- <span class=\"badge learn\">Learn</span> **People Chain**\n\n    ---\n\n    Establish and verify decentralized identities for trusted interactions on Polkadot.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/people-and-identity/)\n\n- <span class=\"badge learn\">Learn</span> **Bridge Hub**\n\n    ---\n\n    Facilitate trustless cross-chain interactions with Ethereum and other blockchains.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/bridging/)\n\n- <span class=\"badge learn\">Learn</span> **Consensus & Security**\n\n    ---\n\n    Understand how Polkadot validates transactions and secures the network.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/consensus-and-security/)\n\n- <span class=\"badge learn\">Learn</span> **Collectives & DAOs**\n\n    ---\n\n    Participate in specialized governance organizations with coordinated decision-making.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/collectives-and-daos/)\n\n</div>"}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 14, "end_char": 624, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Chopsticks](https://github.com/AcalaNetwork/chopsticks/){target=\\_blank}, developed by the [Acala Foundation](https://github.com/AcalaNetwork){target=\\_blank}, is a versatile tool tailored for developers working on Polkadot SDK-based blockchains. With Chopsticks, you can fork live chains locally, replay blocks to analyze extrinsics, and simulate complex scenarios like XCM interactions, all without deploying to a live network.\n\nBy streamlining testing and experimentation, Chopsticks empowers developers to innovate and accelerate their blockchain projects within the Polkadot ecosystem."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 1, "depth": 3, "title": "Key Features", "anchor": "key-features", "start_char": 624, "end_char": 1560, "estimated_token_count": 207, "token_estimator": "heuristic-v1", "text": "### Key Features\n\n- **Local chain forking**: Fork live Polkadot SDK chains locally for testing and development.\n- **Block replay**: Replay specific blocks to analyze state changes and debug extrinsics.\n- **XCM testing**: Simulate cross-chain messaging between multiple parachains and relay chains.\n- **Storage manipulation**: Override storage values to test specific scenarios.\n- **WebSocket commands**: Control the forked environment with specialized RPC methods.\n- **Time travel**: Manipulate block timestamps for testing time-dependent logic.\n- **Build block modes**: Choose between batch, instant, or manual block production.\n\n!!! warning\n    Chopsticks uses [Smoldot](https://github.com/smol-dot/smoldot){target=\\_blank} light client, which only supports the native Polkadot SDK API. Consequently, a Chopsticks-based fork doesn't support Ethereum JSON-RPC calls, meaning you cannot use it to fork your chain and connect Metamask."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 2, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1560, "end_char": 1865, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- [Node.js](https://nodejs.org/en/){target=\\_blank}\n- A package manager such as [npm](https://www.npmjs.com/){target=\\_blank}, which should be installed with Node.js by default, or [yarn](https://yarnpkg.com/){target=\\_blank}"}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 3, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1865, "end_char": 2165, "estimated_token_count": 58, "token_estimator": "heuristic-v1", "text": "## Installation\n\nYou can install Chopsticks globally or locally in your project. Choose the option that best fits your development workflow. \n\n!!! tip\n    This documentation explains the features of Chopsticks version `1.2.2`. Make sure you're using the correct version to match these instructions."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 4, "depth": 3, "title": "Global Installation", "anchor": "global-installation", "start_char": 2165, "end_char": 2597, "estimated_token_count": 124, "token_estimator": "heuristic-v1", "text": "### Global Installation\n\nTo install Chopsticks globally, allowing you to use it across multiple projects, run:\n\n=== \"npm\"\n\n    ```bash\n    npm i -g @acala-network/chopsticks@1.2.2\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add -g @acala-network/chopsticks@1.2.2\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn global add @acala-network/chopsticks@1.2.2\n    ```\n\nNow, you should be able to run the `chopsticks` command from your terminal."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 5, "depth": 3, "title": "Local Installation", "anchor": "local-installation", "start_char": 2597, "end_char": 3265, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "### Local Installation\n\nTo use Chopsticks in a specific project, first create a new directory and initialize a Node.js project:\n\n```bash\nmkdir my-chopsticks-project\ncd my-chopsticks-project\nnpm init -y\n```\n\nThen, install Chopsticks as a local dependency:\n\n=== \"npm\"\n\n    ```bash\n    npm i @acala-network/chopsticks@1.2.2\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add @acala-network/chopsticks@1.2.2\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add @acala-network/chopsticks@1.2.2\n    ```\n\nFinally, you can run Chopsticks using the `npx` command. To see all available options and commands, run it with the `--help` flag:\n\n```bash\nnpx @acala-network/chopsticks --help\n```"}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 6, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 3265, "end_char": 3281, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 7, "depth": 3, "title": "Configuration Options", "anchor": "configuration-options", "start_char": 3281, "end_char": 4622, "estimated_token_count": 361, "token_estimator": "heuristic-v1", "text": "### Configuration Options\n\nTo run Chopsticks, you need to configure some parameters. This can be set either via a configuration file or the command-line interface (CLI). The parameters that can be configured are as follows:\n\n- **`genesis`**: The link to a parachain's raw genesis file to build the fork from, instead of an endpoint.\n- **`timestamp`**: Timestamp of the block to fork from.\n- **`endpoint`**: The endpoint of the parachain to fork.\n- **`block`**: Use to specify at which block hash or number to replay the fork.\n- **`wasm-override`**: Path of the Wasm to use as the parachain runtime, instead of an endpoint's runtime.\n- **`db`**: Path to the name of the file that stores or will store the parachain's database.\n- **`config`**: Path or URL of the config file.\n- **`port`**: The port to expose an endpoint on.\n- **`build-block-mode`**: How blocks should be built in the fork: batch, manual, instant.\n- **`import-storage`**: A pre-defined JSON/YAML storage path to override in the parachain's storage.\n- **`allow-unresolved-imports`**: Whether to allow Wasm unresolved imports when using a Wasm to build the parachain.\n- **`html`**: Include to generate storage diff preview between blocks.\n- **`mock-signature-host`**: Mock signature host so that any signature starts with `0xdeadbeef` and filled by `0xcd` is considered valid."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 8, "depth": 3, "title": "Configuration File", "anchor": "configuration-file", "start_char": 4622, "end_char": 5842, "estimated_token_count": 279, "token_estimator": "heuristic-v1", "text": "### Configuration File\n\nThe Chopsticks source repository includes a collection of [YAML](https://yaml.org/){target=\\_blank} files that can be used to set up various Polkadot SDK chains locally. You can download these configuration files from the [repository's `configs` folder](https://github.com/AcalaNetwork/chopsticks/tree/master/configs){target=\\_blank}.\n\nAn example of a configuration file for Polkadot is as follows:\n\n{% raw %}\n```yaml title=\"polkadot.yml\"\nendpoint:\n  - wss://rpc.ibp.network/polkadot\n  - wss://polkadot-rpc.dwellir.com\nmock-signature-host: true\nblock: ${env.POLKADOT_BLOCK_NUMBER}\ndb: ./db.sqlite\nruntime-log-level: 5\n\nimport-storage:\n  System:\n    Account:\n      - - - 5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\n        - providers: 1\n          data:\n            free: '10000000000000000000'\n  ParasDisputes:\n    $removePrefix: ['disputes'] # those can makes block building super slow\n```\n{% endraw %}\n\nThe configuration file allows you to modify the storage of the forked network by rewriting the pallet, state component, and value that you want to change. For example, Polkadot's file rewrites Alice's `system.Account` storage so that the free balance is set to `10000000000000000000`."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 9, "depth": 3, "title": "Create a Fork", "anchor": "create-a-fork", "start_char": 5842, "end_char": 7023, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "### Create a Fork\n\nTo run Chopsticks using a configuration file, utilize the `--config` flag. You can use a raw GitHub URL, a path to a local file, or simply the chain's name:\n\n=== \"Chain Name\"\n\n    ```bash\n    npx @acala-network/chopsticks --config=polkadot\n    ```\n\n=== \"GitHub URL\"\n\n    ```bash\n    npx @acala-network/chopsticks \\\n    --config=https://raw.githubusercontent.com/AcalaNetwork/chopsticks/master/configs/polkadot.yml\n    ```\n\n=== \"Local File Path\"\n\n    ```bash\n    npx @acala-network/chopsticks --config=configs/polkadot.yml\n    ```\n\nAlternatively, you can create a fork using CLI flags. For example, to fork Polkadot at block 100:\n\n```bash\nnpx @acala-network/chopsticks \\\n--endpoint wss://polkadot-rpc.dwellir.com \\\n--block 100\n```\n\nIf the fork is successful, you will see output indicating the RPC is listening:\n\n<div class=\"termynal\" data-termynal>\n    <span data-ty=\"input\">npx @acala-network/chopsticks --endpoint wss://polkadot-rpc.dwellir.com --block 100</span>\n    <span data-ty=\"output\">[19:12:21.023] INFO: Polkadot RPC listening on port 8000</span>\n</div>\nYou can now access the running Chopsticks fork using the default address: `ws://localhost:8000`."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 10, "depth": 3, "title": "Interact with a Fork", "anchor": "interact-with-a-fork", "start_char": 7023, "end_char": 8479, "estimated_token_count": 386, "token_estimator": "heuristic-v1", "text": "### Interact with a Fork\n\nYou can interact with the forked chain using various libraries such as [Polkadot.js](https://polkadot.js.org/docs/){target=\\_blank}.\n\n=== \"Via Polkadot.js Apps\"\n\n    To interact with Chopsticks via the hosted user interface, visit [Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank} and follow these steps:\n\n    1. Select the network icon in the top left corner.\n\n        ![](/images/reference/tools/chopsticks/chopsticks-1.webp)\n\n    2. Scroll to the bottom and select **Development**.\n    3. Choose **Custom**.\n    4. Enter `ws://localhost:8000` in the input field.\n    5. Select the **Switch** button.\n\n        ![](/images/reference/tools/chopsticks/chopsticks-2.webp)\n\n    You should now be connected to your local fork and can interact with it as you would with a real chain.\n\n=== \"Via Polkadot.js API\"\n\n    For programmatic interaction, you can use the [Polkadot.js](/reference/tools/polkadot-js-api/){target=\\_blank} library:\n\n    ```typescript title=\"connect-to-fork.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n\n    async function connectToFork() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n\n      // Now you can use 'api' to interact with your fork\n      console.log(`Connected to chain: ${await api.rpc.system.chain()}`);\n    }\n\n    connectToFork();\n\n    ```"}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 11, "depth": 3, "title": "Replay Blocks", "anchor": "replay-blocks", "start_char": 8479, "end_char": 9142, "estimated_token_count": 168, "token_estimator": "heuristic-v1", "text": "### Replay Blocks\n\nChopsticks lets you replay specific blocks in a chain, which is useful for debugging and analyzing state changes. Use the `run-block` subcommand with the following options:\n\n- **`output-path`**: Path to print output.\n- **`html`**: Generate HTML with storage diff.\n- **`open`**: Open generated HTML.\n\nFor example, to replay block 1000 from Polkadot and save the output to a JSON file:\n\n```bash\nnpx @acala-network/chopsticks run-block \\\n--endpoint wss://polkadot-rpc.dwellir.com \\\n--output-path ./polkadot-output.json \\\n--block 1000\n```\n\nThe output will include detailed information about the block execution, storage changes, and runtime logs."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 12, "depth": 3, "title": "Test XCM", "anchor": "test-xcm", "start_char": 9142, "end_char": 10498, "estimated_token_count": 386, "token_estimator": "heuristic-v1", "text": "### Test XCM\n\nTo test XCM (Cross-Consensus Messaging) messages between networks, you can fork multiple parachains and a relay chain locally using Chopsticks.\n\nUse the `xcm` subcommand with:\n\n- **`-r` / `--relaychain`**: Relay chain config file\n- **`-p` / `--parachain`**: Parachain config file (can be specified multiple times)\n\nFor example, to fork Moonbeam, Astar, and Polkadot, enabling XCM between them:\n\n```bash\nnpx @acala-network/chopsticks xcm \\\n--r polkadot \\\n--p moonbeam \\\n--p astar\n```\n\nAfter running it, you should see output indicating connections between the chains:\n\n<div class=\"termynal\" data-termynal>\n    <span data-ty=\"input\">npx @acala-network/chopsticks xcm --r polkadot --p moonbeam --p astar</span>\n    <span data-ty=\"output\">[13:46:12.631] INFO: Moonbeam RPC listening on port 8000</span>\n    <span data-ty=\"output\">[13:46:23.669] INFO: Astar RPC listening on port 8001</span>\n    <span data-ty=\"output\">[13:46:53.320] INFO: Polkadot RPC listening on port 8002</span>\n    <span data-ty=\"output\">[13:46:54.038] INFO (xcm): Connected relaychain 'Polkadot' with parachain 'Moonbeam'</span>\n    <span data-ty=\"output\">[13:46:55.028] INFO (xcm): Connected relaychain 'Polkadot' with parachain 'Astar'</span>\n</div>\nNow you can interact with your forked chains using the ports specified in the output and test XCM messages between them."}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 13, "depth": 2, "title": "WebSocket Commands", "anchor": "websocket-commands", "start_char": 10498, "end_char": 15298, "estimated_token_count": 1192, "token_estimator": "heuristic-v1", "text": "## WebSocket Commands\n\nChopstick's internal WebSocket server has special endpoints that allow manipulating the local Polkadot SDK chain.\n\n???+ interface \"dev_newBlock\"\n\n    Generates one or more new blocks.\n\n    **Parameters:**\n\n    - **`newBlockParams` (NewBlockParams)**: The parameters to build the new block with, including:\n        - **`count` (number)**: The number of blocks to build\n        - **`dmp` ({ msg: string, sentAt: number }[])**: The downward messages to include in the block\n        - **`hrmp` (Record<string | number, { data: string, sentAt: number }[]>)**: The horizontal messages to include in the block\n        - **`to` (number)**: The block number to build to\n        - **`transactions` (string[])**: The transactions to include in the block\n        - **`ump` (Record<number, string[]>)**: The upward messages to include in the block\n        - **`unsafeBlockHeight` (number)**: Build block using a specific block height (unsafe)\n\n    **Example:**\n\n    ```typescript title=\"dev-newblock-example.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n\n    async function main() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n      await api.rpc('dev_newBlock', { count: 1 });\n    }\n\n    main();\n\n    ```\n\n??? interface \"dev_setBlockBuildMode\"\n\n    Sets block build mode.\n\n    **Parameters:**\n\n    - **`buildBlockMode` (BuildBlockMode)**: The build mode. Can be:\n        - `Batch`: One block per batch (default)\n        - `Instant`: One block per transaction\n        - `Manual`: Only build when triggered\n\n    **Example:**\n\n    ```typescript title=\"dev-setBlockBuildMode-example.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n\n    async function main() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n      await api.rpc('dev_setBlockBuildMode', 'Instant');\n    }\n\n    main();\n\n    ```\n\n??? interface \"dev_setHead\"\n\n    Sets the head of the blockchain to a specific hash or number.\n\n    **Parameters:**\n\n    - **`hashOrNumber` (string | number)**: The block hash or number to set as head\n\n    **Example:**\n\n    ```typescript title=\"dev-setHead-example.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n\n    async function main() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n      await api.rpc('dev_setHead', 500);\n    }\n\n    main();\n\n    ```\n\n??? interface \"dev_setRuntimeLogLevel\"\n\n    Sets the runtime log level.\n\n    **Parameters:**\n\n    - **`runtimeLogLevel` (number)**: The runtime log level to set\n\n    **Example:**\n\n    ```typescript title=\"dev-setRuntimeLogLevel-example.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n\n    async function main() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n      await api.rpc('dev_setRuntimeLogLevel', 1);\n    }\n\n    main();\n\n    ```\n\n??? interface \"dev_setStorage\"\n\n    Creates or overwrites the value of any storage.\n\n    **Parameters:**\n\n    - **`values` (object)**: JSON object resembling the path to a storage value\n    - **`blockHash` (string)**: The block hash to set the storage value\n\n    **Example:**\n\n    ```typescript title=\"dev-setStorage-example.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n    import { Keyring } from '@polkadot/keyring';\n\n    async function main() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n      const keyring = new Keyring({ type: 'ed25519' });\n      const bob = keyring.addFromUri('//Bob');\n      const storage = {\n        System: {\n          Account: [[[bob.address], { data: { free: 100000 }, nonce: 1 }]],\n        },\n      };\n      await api.rpc('dev_setStorage', storage);\n    }\n\n    main();\n\n    ```\n\n??? interface \"dev_timeTravel\"\n\n    Sets the block's timestamp to a specific date. All future blocks will be sequentially created after this point in time.\n\n    **Parameters:**\n\n    - **`date` (string)**: Timestamp or date string to set\n\n    **Example:**\n\n    ```typescript title=\"dev-timeTravel-example.ts\"\n    import { ApiPromise, WsProvider } from '@polkadot/api';\n\n    async function main() {\n      const wsProvider = new WsProvider('ws://localhost:8000');\n      const api = await ApiPromise.create({ provider: wsProvider });\n      await api.isReady;\n      await api.rpc('dev_timeTravel', '2030-08-15T00:00:00');\n    }\n\n    main();\n\n    ```"}
{"page_id": "reference-tools-chopsticks", "page_title": "Chopsticks", "index": 14, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 15298, "end_char": 15763, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Chopsticks Support__\n\n    ---\n\n    For further support and information, refer to the official resources.\n\n    [:octicons-arrow-right-24: GitHub Repository](https://github.com/AcalaNetwork/chopsticks){target=\\_blank}\n\n    [:octicons-arrow-right-24: Create a GitHub Issue for Support](https://github.com/AcalaNetwork/chopsticks/issues){target=\\_blank}\n\n</div>"}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 9, "end_char": 445, "estimated_token_count": 99, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Dedot](https://github.com/dedotdev/dedot){target=\\_blank} is a next-generation JavaScript client for Polkadot and Polkadot SDK-based blockchains. Designed to elevate the dApp development experience, Dedot is built and optimized to be lightweight and tree-shakable, offering precise types and APIs suggestions for individual Polkadot SDK-based blockchains and [ink! smart contracts](https://use.ink/){target=\\_blank}."}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 1, "depth": 3, "title": "Key Features", "anchor": "key-features", "start_char": 445, "end_char": 1529, "estimated_token_count": 298, "token_estimator": "heuristic-v1", "text": "### Key Features\n\n- **Lightweight and tree-shakable**: No more bn.js or WebAssembly blobs, optimized for dapps bundle size.\n- **Fully typed API**: Comprehensive TypeScript support for seamless on-chain interaction and ink! smart contract integration.\n- **Multi-version JSON-RPC support**: Compatible with both [legacy](https://github.com/w3f/PSPs/blob/master/PSPs/drafts/psp-6.md){target=\\_blank} and [new](https://paritytech.github.io/json-rpc-interface-spec/introduction.html){target=\\_blank} JSON-RPC APIs for broad ecosystem interoperability.\n- **Light client support**: Designed to work with light clients such as [Smoldot](https://github.com/smol-dot/smoldot){target=\\_blank}.\n- **Native TypeScript for scale codec**: Implements scale codec parsing directly in TypeScript without relying on custom wrappers.\n- **Wallet integration**: Works out-of-the-box with [@polkadot/extension-based](https://github.com/polkadot-js/extension?tab=readme-ov-file#api-interface){target=\\_blank} wallets.\n- **Familiar API design**: Similar API style to Polkadot.js for easy and fast migration."}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 2, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1529, "end_char": 2152, "estimated_token_count": 177, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo add Dedot to your project, use the following command:\n\n=== \"npm\"\n\n    ```bash\n    npm i dedot\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add dedot\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add dedot\n    ```\n\nTo enable auto-completion/IntelliSense for individual chains, install the [`@dedot/chaintypes`](https://www.npmjs.com/package/@dedot/chaintypes){target=\\_blank} package as a development dependency:\n\n=== \"npm\"\n\n    ```bash\n    npm i -D @dedot/chaintypes\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add -D @dedot/chaintypes\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add -D @dedot/chaintypes\n    ```"}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 3, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 2152, "end_char": 2168, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 4, "depth": 3, "title": "Initialize a Client Instance", "anchor": "initialize-a-client-instance", "start_char": 2168, "end_char": 4242, "estimated_token_count": 522, "token_estimator": "heuristic-v1", "text": "### Initialize a Client Instance\n\nTo connect to and interact with different networks, Dedot provides two client options depending on your needs:\n\n- **[`DedotClient`](https://docs.dedot.dev/clients-and-providers/clients#dedotclient){target=\\_blank}**: Interacts with chains via the [new JSON-RPC APIs](https://paritytech.github.io/json-rpc-interface-spec/introduction.html){target=\\_blank}.\n- **[`LegacyClient`](https://docs.dedot.dev/clients-and-providers/clients#legacyclient){target=\\_blank}**: Interacts with chains via the [legacy JSON-RPC APIs](https://github.com/w3f/PSPs/blob/master/PSPs/drafts/psp-6.md){target=\\_blank}.\n\nUse the following snippets to connect to Polkadot using `DedotClient`:\n\n=== \"WebSocket\"\n\n    ```typescript\n    import { DedotClient, WsProvider } from 'dedot';\n    import type { PolkadotApi } from '@dedot/chaintypes';\n\n    // Initialize providers & clients\n    const provider = new WsProvider('wss://rpc.polkadot.io');\n    const client = await DedotClient.new<PolkadotApi>(provider);\n\n    ```\n\n=== \"Light Client (Smoldot)\"\n\n    ```typescript\n    import { DedotClient, SmoldotProvider } from 'dedot';\n    import type { PolkadotApi } from '@dedot/chaintypes';\n    import * as smoldot from 'smoldot';\n\n    // import `polkadot` chain spec to connect to Polkadot\n    import { polkadot } from '@substrate/connect-known-chains';\n\n    // Start smoldot instance & initialize a chain\n    const client = smoldot.start();\n    const chain = await client.addChain({ chainSpec: polkadot });\n\n    // Initialize providers & clients\n    const provider = new SmoldotProvider(chain);\n    const client = await DedotClient.new<PolkadotApi>(provider);\n\n    ```\n\nIf the node doesn't support new JSON-RPC APIs yet, you can connect to the network using the `LegacyClient`, which is built on top of the legacy JSON-RPC APIs.\n\n```typescript\nimport { LegacyClient, WsProvider } from 'dedot';\nimport type { PolkadotApi } from '@dedot/chaintypes';\n\nconst provider = new WsProvider('wss://rpc.polkadot.io');\nconst client = await LegacyClient.new<PolkadotApi>(provider);\n\n```"}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 5, "depth": 3, "title": "Enable Type and API Suggestions", "anchor": "enable-type-and-api-suggestions", "start_char": 4242, "end_char": 5662, "estimated_token_count": 377, "token_estimator": "heuristic-v1", "text": "### Enable Type and API Suggestions\n\nIt is recommended to specify the `ChainApi` interface (e.g., `PolkadotApi` in the example in the previous section) of the chain you want to interact with. This enables type and API suggestions/autocompletion for that particular chain (via IntelliSense). If you don't specify a `ChainApi` interface, a default `SubstrateApi` interface will be used.\n\n```typescript\nimport { DedotClient, WsProvider } from 'dedot';\nimport type { PolkadotApi, KusamaApi } from '@dedot/chaintypes';\n\nconst polkadotClient = await DedotClient.new<PolkadotApi>(\n  new WsProvider('wss://rpc.polkadot.io')\n);\nconst kusamaClient = await DedotClient.new<KusamaApi>(\n  new WsProvider('wss://kusama-rpc.polkadot.io')\n);\nconst genericClient = await DedotClient.new(\n  new WsProvider('ws://localhost:9944')\n);\n\n```\n\nIf you don't find the `ChainApi` for the network you're working with in [the list](https://github.com/dedotdev/chaintypes?tab=readme-ov-file#supported-networks){target=\\_blank}, you can generate the `ChainApi` (types and APIs) using the built-in [`dedot` cli](https://docs.dedot.dev/cli){target=\\_blank}.\n\n```bash\n# Generate ChainApi interface for Polkadot network via rpc endpoint: wss://rpc.polkadot.io\nnpx dedot chaintypes -w wss://rpc.polkadot.io\n```\n\nOr open a pull request to add your favorite network to the [`@dedot/chaintypes`](https://github.com/dedotdev/chaintypes){target=\\_blank} repo."}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 6, "depth": 3, "title": "Read On-Chain Data", "anchor": "read-on-chain-data", "start_char": 5662, "end_char": 6993, "estimated_token_count": 348, "token_estimator": "heuristic-v1", "text": "### Read On-Chain Data\n\nDedot provides several ways to read data from the chain:\n\n- **Access runtime constants**: Use the syntax `client.consts.<pallet>.<constantName>` to inspect runtime constants (parameter types).\n\n    ```typescript\n    const ss58Prefix = client.consts.system.ss58Prefix;\n    console.log('Polkadot ss58Prefix:', ss58Prefix);\n\n    ```\n\n- **Storage queries**: Use the syntax `client.query.<pallet>.<storgeEntry>` to query on-chain storage.\n\n    ```typescript\n    const balance = await client.query.system.account('INSERT_ADDRESS');\n    console.log('Balance:', balance.data.free);\n\n    ```\n\n- **Subscribe to storage changes**:\n\n    ```typescript\n    const unsub = await client.query.system.number((blockNumber) => {\n      console.log(`Current block number: ${blockNumber}`);\n    });\n\n    ```\n\n- **Call Runtime APIs**: Use the syntax `client.call.<runtimeApi>.<methodName>` to execute Runtime APIs.\n\n    ```typescript\n    const metadata = await client.call.metadata.metadataAtVersion(15);\n    console.log('Metadata V15', metadata);\n\n    ```\n\n- **Watch on-chain events**: Use the syntax `client.events.<pallet>.<eventName>` to access pallet events.\n    \n    ```typescript\n    const unsub = await client.events.system.NewAccount.watch((events) => {\n      console.log('New Account Created', events);\n    });\n\n    ```"}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 7, "depth": 3, "title": "Sign and Send Transactions", "anchor": "sign-and-send-transactions", "start_char": 6993, "end_char": 8719, "estimated_token_count": 439, "token_estimator": "heuristic-v1", "text": "### Sign and Send Transactions\n\nSign the transaction using `IKeyringPair` from Keyring ([`@polkadot/keyring`](https://polkadot.js.org/docs/keyring/start/sign-verify/){target=\\_blank}) and send the transaction.\n\n```typescript\nimport { cryptoWaitReady } from '@polkadot/util-crypto';\nimport { Keyring } from '@polkadot/keyring';\n// Setup keyring\nawait cryptoWaitReady();\nconst keyring = new Keyring({ type: 'sr25519' });\nconst alice = keyring.addFromUri('//Alice');\n// Send transaction\nconst unsub = await client.tx.balances\n  .transferKeepAlive('INSERT_DEST_ADDRESS', 2_000_000_000_000n)\n  .signAndSend(alice, async ({ status }) => {\n    console.log('Transaction status', status.type);\n    if (status.type === 'BestChainBlockIncluded') {\n      console.log(`Transaction is included in best block`);\n    }\n    if (status.type === 'Finalized') {\n      console.log(\n        `Transaction completed at block hash ${status.value.blockHash}`\n      );\n      await unsub();\n    }\n  });\n\n```\n\nYou can also use `Signer` from wallet extensions:\n\n```typescript\nconst injected = await window.injectedWeb3['polkadot-js'].enable('My dApp');\nconst account = (await injected.accounts.get())[0];\nconst signer = injected.signer;\nconst unsub = await client.tx.balances\n  .transferKeepAlive('INSERT_DEST_ADDRESS', 2_000_000_000_000n)\n  .signAndSend(account.address, { signer }, async ({ status }) => {\n    console.log('Transaction status', status.type);\n    if (status.type === 'BestChainBlockIncluded') {\n      console.log(`Transaction is included in best block`);\n    }\n    if (status.type === 'Finalized') {\n      console.log(\n        `Transaction completed at block hash ${status.value.blockHash}`\n      );\n      await unsub();\n    }\n  });\n\n```"}
{"page_id": "reference-tools-dedot", "page_title": "Dedot", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 8719, "end_char": 8855, "estimated_token_count": 36, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor more detailed information about Dedot, check the [official documentation](https://dedot.dev/){target=\\_blank}."}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 994, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nLight clients enable secure and efficient blockchain interaction without running a full node. They provide a trust-minimized alternative to JSON-RPC by verifying data through cryptographic proofs rather than blindly trusting remote nodes.\n\nThis guide covers:\n\n- What light clients are and how they work.\n- Their advantages compared to full nodes and JSON-RPC.\n- Available implementations in the Polkadot ecosystem.\n- How to use light clients in your applications.\n\nLight clients are particularly valuable for resource-constrained environments and applications requiring secure, decentralized blockchain access without the overhead of maintaining full nodes.\n\n!!!note \"Light node or light client?\"\n    The terms _light node_ and _light client_ are interchangeable. Both refer to a blockchain client that syncs without downloading the entire blockchain state. All nodes in a blockchain network are fundamentally clients, engaging in peer-to-peer communication."}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 1, "depth": 2, "title": "Light Clients Workflow", "anchor": "light-clients-workflow", "start_char": 994, "end_char": 2625, "estimated_token_count": 359, "token_estimator": "heuristic-v1", "text": "## Light Clients Workflow\n\nUnlike JSON-RPC interfaces, where an application must maintain a list of providers or rely on a single node, light clients are not limited to or dependent on a single node. They use cryptographic proofs to verify the blockchain's state, ensuring it is up-to-date and accurate. By verifying only block headers, light clients avoid syncing the entire state, making them ideal for resource-constrained environments.\n\n```mermaid\nflowchart LR\nDAPP([dApp])-- Query Account Info -->LC([Light Client])\nLC -- Request --> FN(((Full Node)))\nLC -- Response --> DAPP\nFN -- Response (validated via Merkle proof) --> LC\n```\n\nIn the diagram above, the decentralized application queries on-chain account information through the light client. The light client runs as part of the application and requires minimal memory and computational resources. It uses Merkle proofs to verify the state retrieved from a full node in a trust-minimized manner. Polkadot-compatible light clients utilize [warp syncing](https://spec.polkadot.network/sect-lightclient#sect-sync-warp-lightclient){target=\\_blank}, which downloads only block headers.\n\nLight clients can quickly verify the blockchain's state, including [GRANDPA finality](/polkadot-protocol/glossary#grandpa){target=\\_blank} justifications.\n\n!!!note \"What does it mean to be trust-minimized?\"\n    _Trust-minimized_ means that the light client does not need to fully trust the full node from which it retrieves the state. This is achieved through the use of Merkle proofs, which allow the light client to verify the correctness of the state by checking the Merkle tree root."}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 2, "depth": 2, "title": "JSON-RPC and Light Client Comparison", "anchor": "json-rpc-and-light-client-comparison", "start_char": 2625, "end_char": 4478, "estimated_token_count": 442, "token_estimator": "heuristic-v1", "text": "## JSON-RPC and Light Client Comparison\n\nAnother common method of communication between a user interface (UI) and a node is through the JSON-RPC protocol. Generally, the UI retrieves information from the node, fetches network or [pallet](/polkadot-protocol/glossary#pallet){target=\\_blank} data, and interacts with the blockchain. This is typically done in one of two ways:\n\n- **User-controlled nodes**: The UI connects to a node client installed on the user's machine.\n    - These nodes are secure, but installation and maintenance can be inconvenient.\n- **Publicly accessible nodes**: The UI connects to a third-party-owned publicly accessible node client.\n    - These nodes are convenient but centralized and less secure. Applications must maintain a list of backup nodes in case the primary node becomes unavailable.\n\nWhile light clients still communicate with [full nodes](/polkadot-protocol/glossary#full-node), they offer significant advantages for applications requiring a secure alternative to running a full node:\n\n| Full Node                                                                                       | Light Client                                                   |\n| :---------------------------------------------------------------------------------------------: | :------------------------------------------------------------: |\n| Fully verifies all blocks of the chain                                                          | Verifies only the authenticity of blocks                       |\n| Stores previous block data and the chain's storage in a database                                | Does not require a database                                    |\n| Installation, maintenance, and execution are resource-intensive and require technical expertise | No installation is typically included as part of the application |"}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 3, "depth": 2, "title": "Using Light Clients", "anchor": "using-light-clients", "start_char": 4478, "end_char": 4799, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "## Using Light Clients\n\nThe [`smoldot`](https://github.com/smol-dot/smoldot){target=\\_blank} client is the cornerstone of light client implementation for Polkadot SDK-based chains. It provides the primitives needed to build light clients and is also integrated into libraries such as [PAPI](#papi-light-client-support)."}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 4, "depth": 3, "title": "PAPI Light Client Support", "anchor": "papi-light-client-support", "start_char": 4799, "end_char": 5131, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "### PAPI Light Client Support\n\nThe [Polkadot API (PAPI)](/develop/toolkit/api-libraries/papi){target=\\_blank} library natively supports light client configurations powered by [`smoldot`](https://github.com/smol-dot/smoldot){target=\\_blank}. This allows developers to connect to multiple chains simultaneously using a light client."}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 5, "depth": 3, "title": "Substrate Connect - Browser Extension", "anchor": "substrate-connect-browser-extension", "start_char": 5131, "end_char": 5902, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "### Substrate Connect - Browser Extension\n\nThe [Substrate Connect browser extension](https://www.npmjs.com/package/@substrate/connect-extension-protocol){target=\\_blank} enables end-users to interact with applications connected to multiple blockchains or to connect their own blockchains to supported applications.\n\nEstablishing a sufficient number of peers can be challenging due to browser limitations on WebSocket connections from HTTPS pages, as many nodes require TLS. The Substrate Connect browser extension addresses this limitation by keeping chains synced in the background, enabling faster application performance.\n\nSubstrate Connect automatically detects whether the user has the extension installed. If not, an in-page Wasm light client is created for them."}
{"page_id": "reference-tools-light-clients", "page_title": "Light Clients", "index": 6, "depth": 2, "title": "Resources", "anchor": "resources", "start_char": 5902, "end_char": 6490, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## Resources\n\n- [What is a light client and why you should care?](https://medium.com/paritytech/what-is-a-light-client-and-why-you-should-care-75f813ae2670){target=\\_blank}\n- [Introducing Substrate Connect: Browser-Based Light Clients for Connecting to Substrate Chains](https://www.parity.io/blog/introducing-substrate-connect){target=\\_blank}\n- [Substrate Connect GitHub Repository](https://github.com/paritytech/substrate-connect/tree/master/projects/extension){target=\\_blank}\n- [Light Clients - Polkadot Specification](https://spec.polkadot.network/sect-lightclient){target=\\_blank}"}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 29, "end_char": 786, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nMoonwall is an end-to-end testing framework designed explicitly for Polkadot SDK-based blockchain networks. It addresses one of the most significant challenges in blockchain development: managing complex test environments and network configurations.\n\nMoonwall consolidates this complexity by providing the following:\n\n- A centralized configuration management system that explicitly defines all network parameters.\n- A standardized approach to environment setup across different Substrate-based chains.\n- Built-in utilities for common testing scenarios and network interactions.\n\nDevelopers can focus on writing meaningful tests rather than managing infrastructure complexities or searching through documentation for configuration options."}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 786, "end_char": 1110, "estimated_token_count": 116, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- [Node.js](https://nodejs.org/en/){target=\\_blank} (version 20.10 or higher).\n- A package manager such as [npm](https://www.npmjs.com/){target=\\_blank}, [yarn](https://yarnpkg.com/){target=\\_blank}, or [pnpm](https://pnpm.io/){target=\\_blank}."}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 2, "depth": 2, "title": "Install Moonwall", "anchor": "install-moonwall", "start_char": 1110, "end_char": 1450, "estimated_token_count": 63, "token_estimator": "heuristic-v1", "text": "## Install Moonwall\n\nMoonwall can be installed globally for system-wide access or locally within specific projects. This section covers both installation methods.\n\n!!! tip\n    This documentation corresponds to Moonwall version `5.15.0`. To avoid compatibility issues with the documented features, ensure you're using the matching version."}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 3, "depth": 3, "title": "Global Installation", "anchor": "global-installation", "start_char": 1450, "end_char": 1955, "estimated_token_count": 132, "token_estimator": "heuristic-v1", "text": "### Global Installation\n\nGlobal installation provides system-wide access to the Moonwall CLI, making it ideal for developers working across multiple blockchain projects. Install it by running one of the following commands:\n\n=== \"npm\"\n\n    ```bash\n    npm install -g @moonwall/cli@5.15.0\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm -g install @moonwall/cli@5.15.0\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn global add @moonwall/cli@5.15.0\n    ```\n\nNow, you can run the `moonwall` command from your terminal."}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 4, "depth": 3, "title": "Local Installation", "anchor": "local-installation", "start_char": 1955, "end_char": 2448, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "### Local Installation\n\nLocal installation is recommended for better dependency management and version control within a specific project. First, initialize your project:\n\n```bash\nmkdir my-moonwall-project\ncd my-moonwall-project\nnpm init -y\n```\n\nThen, install it as a local dependency:\n\n=== \"npm\"\n\n    ```bash\n    npm install @moonwall/cli@5.15.0\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm install @moonwall/cli@5.15.0\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add @moonwall/cli@5.15.0\n    ```"}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 5, "depth": 2, "title": "Initialize Moonwall", "anchor": "initialize-moonwall", "start_char": 2448, "end_char": 5873, "estimated_token_count": 767, "token_estimator": "heuristic-v1", "text": "## Initialize Moonwall\n\nThe `moonwall init` command launches an interactive wizard to create your configuration file:\n\n```bash\nmoonwall init\n```\n\nDuring setup, you will see prompts for the following parameters:\n\n- **`label`**: Identifies your test configuration.\n- **`global timeout`**: Maximum time (ms) for test execution.\n- **`environment name`**: Name for your testing environment.\n- **`network foundation`**: Type of blockchain environment to use.\n- **`tests directory`**: Location of your test files.\n\nSelect `Enter` to accept defaults or input custom values. You should see something like this:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>moonwall init</span>\n  <span data-ty>âœ” Provide a label for the config file moonwall_config</span>\n  <span data-ty>âœ” Provide a global timeout value 30000</span>\n  <span data-ty>âœ” Provide a name for this environment default_env</span>\n  <span data-ty>âœ” What type of network foundation is this? dev</span>\n  <span data-ty>âœ” Provide the path for where tests for this environment are kept tests/</span>\n  <span data-ty>? Would you like to generate this config? (no to restart from beginning) (Y/n)</span>\n</div>\n\nThe wizard generates a `moonwall.config` file:\n\n```json\n{\n    \"label\": \"moonwall_config\",\n    \"defaultTestTimeout\": 30000,\n    \"environments\": [\n        {\n            \"name\": \"default_env\",\n            \"testFileDir\": [\"tests/\"],\n            \"foundation\": {\n                \"type\": \"dev\"\n            }\n        }\n    ]\n}\n\n```\n\nThe default configuration requires specific details about your blockchain node and test requirements:\n\n- The `foundation` object defines how your test blockchain node will be launched and managed. The dev foundation, which runs a local node binary, is used for local development.\n\n    For more information about available options, check the [Foundations](https://moonsong-labs.github.io/moonwall/guide/intro/foundations.html){target=\\_blank} section.\n\n- The `connections` array specifies how your tests will interact with the blockchain node. This typically includes provider configuration and endpoint details.\n\n    A provider is a tool that allows you or your application to connect to a blockchain network and simplifies the low-level details of the process. A provider handles submitting transactions, reading state, and more. For more information on available providers, check the [Providers supported](https://moonsong-labs.github.io/moonwall/guide/intro/providers.html#providers-supported){target=\\_blank} page in the Moonwall documentation.\n\nHere's a complete configuration example for testing a local node using Polkadot.js as a provider:\n\n```json\n{\n    \"label\": \"moonwall_config\",\n    \"defaultTestTimeout\": 30000,\n    \"environments\": [\n        {\n            \"name\": \"default_env\",\n            \"testFileDir\": [\"tests/\"],\n            \"foundation\": {\n                \"launchSpec\": [\n                    {\n                        \"binPath\": \"./node-template\",\n                        \"newRpcBehaviour\": true,\n                        \"ports\": { \"rpcPort\": 9944 }\n                    }\n                ],\n                \"type\": \"dev\"\n            },\n            \"connections\": [\n                {\n                    \"name\": \"myconnection\",\n                    \"type\": \"polkadotJs\",\n                    \"endpoints\": [\"ws://127.0.0.1:9944\"]\n                }\n            ]\n        }\n    ]\n}\n\n```"}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 6, "depth": 2, "title": "Writing Tests", "anchor": "writing-tests", "start_char": 5873, "end_char": 8602, "estimated_token_count": 649, "token_estimator": "heuristic-v1", "text": "## Writing Tests\n\nMoonwall uses the [`describeSuite`](https://github.com/Moonsong-Labs/moonwall/blob/7568048c52e9f7844f38fb4796ae9e1b9205fdaa/packages/cli/src/lib/runnerContext.ts#L65){target=\\_blank} function to define test suites, like using [Mocha](https://mochajs.org/){target=\\_blank}. Each test suite requires the following:\n\n- **`id`**: Unique identifier for the suite.\n- **`title`**: Descriptive name for the suite.\n- **`foundationMethods`**: Specifies the testing environment (e.g., `dev` for local node testing).\n- **`testCases`**: A callback function that houses the individual test cases of this suite.\n\nThe following example shows how to test a balance transfer between two accounts:\n\n```ts\nimport '@polkadot/api-augment';\nimport { describeSuite, expect } from '@moonwall/cli';\nimport { Keyring } from '@polkadot/api';\n\ndescribeSuite({\n  id: 'D1',\n  title: 'Demo suite',\n  foundationMethods: 'dev',\n  testCases: ({ it, context, log }) => {\n    it({\n      id: 'T1',\n      title: 'Test Case',\n      test: async () => {\n        // Set up polkadot.js API and testing accounts\n        let api = context.polkadotJs();\n        let alice = new Keyring({ type: 'sr25519' }).addFromUri('//Alice');\n        let charlie = new Keyring({ type: 'sr25519' }).addFromUri('//Charlie');\n\n        // Query Charlie's account balance before transfer\n        const balanceBefore = (await api.query.system.account(charlie.address))\n          .data.free;\n\n        // Before transfer, Charlie's account balance should be 0\n        expect(balanceBefore.toString()).toEqual('0');\n        log('Balance before: ' + balanceBefore.toString());\n\n        // Transfer from Alice to Charlie\n        const amount = 1000000000000000;\n        await api.tx.balances\n          .transferAllowDeath(charlie.address, amount)\n          .signAndSend(alice);\n\n        // Wait for the transaction to be included in a block.\n        // This is necessary because the balance is not updated immediately.\n        // Block time is 6 seconds.\n        await new Promise((resolve) => setTimeout(resolve, 6000));\n\n        // Query Charlie's account balance after transfer\n        const balanceAfter = (await api.query.system.account(charlie.address))\n          .data.free;\n\n        // After transfer, Charlie's account balance should be 1000000000000000\n        expect(balanceAfter.toString()).toEqual(amount.toString());\n        log('Balance after: ' + balanceAfter.toString());\n      },\n    });\n  },\n});\n\n```\n\nThis test demonstrates several key concepts:\n\n- Initializing the Polkadot.js API through Moonwall's context and setting up test accounts.\n- Querying on-chain state.\n- Executing transactions.\n- Waiting for block inclusion.\n- Verifying results using assertions."}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 7, "depth": 2, "title": "Running the Tests", "anchor": "running-the-tests", "start_char": 8602, "end_char": 10012, "estimated_token_count": 426, "token_estimator": "heuristic-v1", "text": "## Running the Tests\n\nExecute your tests using the `test` Moonwall CLI command. For the default environment setup run:\n\n```bash\nmoonwall test default_env -c moonwall.config\n```\n\nThe test runner will output detailed results showing:\n\n- Test suite execution status.\n- Individual test case results.\n- Execution time.\n- Detailed logs and error messages (if any).\n\nExample output:\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>moonwall test default_env -c moonwall.config</span>\n  <span data-ty>stdout | tests/test1.ts > ðŸ—ƒï¸ D1 Demo suite > ðŸ“ D1T1 Test Case</span>\n  <span data-ty>2025-01-21T19:27:55.624Z test:default_env Balance before: 0</span>\n  <span data-ty></span>\n  <span data-ty>stdout | tests/test1.ts > ðŸ—ƒï¸ D1 Demo suite > ðŸ“ D1T1 Test Case</span>\n  <span data-ty>2025-01-21T19:28:01.637Z test:default_env Balance after: 1000000000000000</span>\n  <span data-ty></span>\n  <span data-ty> âœ“ default_env tests/test1.ts (1 test) 6443ms</span>\n  <span data-ty> âœ“ ðŸ—ƒï¸ D1 Demo suite > ðŸ“ D1T1 Test Case 6028ms</span>\n  <span data-ty></span>\n  <span data-ty> Test Files 1 passed (1)</span>\n  <span data-ty> Tests 1 passed (1)</span>\n  <span data-ty> Start at 16:27:53</span>\n  <span data-ty> Duration 7.95s (transform 72ms, setup 0ms, collect 1.31s, tests 6.44s, environment 0ms, prepare 46ms)</span>\n  <span data-ty></span>\n  <span data-ty>âœ… All tests passed</span>\n</div>"}
{"page_id": "reference-tools-moonwall", "page_title": "E2E Testing with Moonwall", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 10012, "end_char": 10240, "estimated_token_count": 54, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor a comprehensive guide to Moonwall's full capabilities, available configurations, and advanced usage, see the official [Moonwall](https://moonsong-labs.github.io/moonwall/){target=\\_blank} documentation."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 22, "end_char": 985, "estimated_token_count": 205, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [`polkadot-omni-node`](https://crates.io/crates/polkadot-omni-node/0.7.0){target=\\_blank} crate is a versatile, pre-built binary designed to simplify running parachains in the Polkadot ecosystem. Unlike traditional node binaries that are tightly coupled to specific runtime code, the `polkadot-omni-node` operates using an external [chain specification](/polkadot-protocol/glossary#chain-specification){target=\\_blank} file, allowing it to adapt dynamically to different parachains.\n\nThis approach enables it to act as a white-labeled node binary, capable of running most parachains that do not require custom node-level logic or extensions. Developers can leverage this flexibility to test, deploy, or operate parachain nodes without maintaining a dedicated codebase for each network.\n\nThis guide provides step-by-step instructions for installing the `polkadot-omni-node`, obtaining a chain specification, and spinning up a parachain node."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 985, "end_char": 1307, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following prerequisites:\n\n- **[Rust](https://rust-lang.org/tools/install/){target=\\_blank}**: Required to build and install the `polkadot-omni-node` binary.\n\nEnsure Rust's `cargo` command is available in your terminal by running:\n\n```bash\ncargo --version\n```"}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 2, "depth": 2, "title": "Install Polkadot Omni Node", "anchor": "install-polkadot-omni-node", "start_char": 1307, "end_char": 1745, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "## Install Polkadot Omni Node\n\nTo install `polkadot-omni-node` globally using `cargo`, run:\n\n```bash\ncargo install --locked polkadot-omni-node@0.7.0\n```\n\nThis command downloads and installs version 0.7.0 of the binary, making it available system-wide.\n\nTo confirm the installation, run:\n\n```bash\npolkadot-omni-node --version\n```\n\nYou should see the installed version number printed to the terminal, confirming a successful installation."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 3, "depth": 2, "title": "Obtain Chain Specifications", "anchor": "obtain-chain-specifications", "start_char": 1745, "end_char": 2581, "estimated_token_count": 202, "token_estimator": "heuristic-v1", "text": "## Obtain Chain Specifications\n\nThe `polkadot-omni-node` binary uses a chain specification file to configure and launch a parachain node. This file defines the parachain's genesis state and network settings.\n\nThe most common source for official chain specifications is the [`paritytech/chainspecs`](https://github.com/paritytech/chainspecs){target=\\_blank} repository. These specifications are also browsable in a user-friendly format via the [Chainspec Collection](https://paritytech.github.io/chainspecs/){target=\\_blank} website.\n\nTo obtain a chain specification:\n\n1. Visit the [Chainspec Collection](https://paritytech.github.io/chainspecs/){target=\\_blank} website.\n2. Find the parachain you want to run.\n3. Click the chain spec to open it.\n4. Copy the JSON content and save it locally as a `.json` file, e.g., `chain_spec.json`."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 4, "depth": 2, "title": "Run a Parachain Full Node", "anchor": "run-a-parachain-full-node", "start_char": 2581, "end_char": 3712, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "## Run a Parachain Full Node\n\nOnce you've installed `polkadot-omni-node` and saved the appropriate chain specification file, you can start a full node for your chosen parachain.\n\nTo see all available flags and configuration options, run:\n\n```bash\npolkadot-omni-node --help\n```\n\nTo launch the node, run the following command, replacing `./INSERT_PARACHAIN_CHAIN_SPEC.json` with the actual path to your saved chain spec file.\n\nThis command will:\n\n- Load the chain specification.\n- Initialize the node using the provided network configuration.\n- Begin syncing with the parachain network.\n\n```bash\npolkadot-omni-node --chain ./INSERT_PARACHAIN_CHAIN_SPEC.json --sync warp\n```\n\n- The `--chain` flag tells the `polkadot-omni-node` which parachain to run by pointing to its chain specification file.\n- The `--sync warp` flag enables warp sync, allowing the node to quickly catch up to the latest finalized state. Historical blocks are fetched in the background as the node continues operating.\n\nOnce started, the node will begin connecting to peers and syncing with the network. Youâ€™ll see logs in your terminal reflecting its progress."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 5, "depth": 2, "title": "Interact with the Node", "anchor": "interact-with-the-node", "start_char": 3712, "end_char": 4274, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "## Interact with the Node\n\nBy default, `polkadot-omni-node` exposes a WebSocket endpoint at `ws://localhost:9944`,  which you can use to interact with the running node. You can connect using:\n\n- **[Polkadot.js Apps](https://polkadot.js.org/apps/#/explorer){target=\\_blank}**: A web-based interface for exploring and interacting with Polkadot SDK-based chains.\n- Custom scripts using compatible [libraries](/develop/toolkit/api-libraries/){target=\\_blank}.\n\nOnce connected, you can review blocks, call extrinsics, inspect storage, and interact with the runtime."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 6, "depth": 2, "title": "Parachain Compatibility", "anchor": "parachain-compatibility", "start_char": 4274, "end_char": 5088, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## Parachain Compatibility\n\nThe `polkadot-omni-node` is designed to work with most parachains out of the box; however, your parachain's runtime must meet specific requirements and follow certain conventions to be compatible. This section outlines what your runtime needs to implement and configure to work seamlessly with the `polkadot-omni-node`:\n\n- Your runtime must implement the required runtime APIs (see below).\n- Your runtime must include and configure the required pallets.\n\nThe [`parachain-template`](https://github.com/paritytech/polkadot-sdk-parachain-template/tree/v0.0.4){target=_blank} provides a complete reference implementation that is fully compatible with the `polkadot-omni-node`. You can use it as a starting point or reference for ensuring your runtime meets all compatibility requirements."}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 7, "depth": 3, "title": "Required Runtime APIs", "anchor": "required-runtime-apis", "start_char": 5088, "end_char": 6424, "estimated_token_count": 295, "token_estimator": "heuristic-v1", "text": "### Required Runtime APIs\n\nYour parachain runtime must implement the following runtime APIs for the `polkadot-omni-node` to function properly:\n\n- **GetParachainInfo Runtime API**: The omni-node requires the [`GetParachainInfo`](https://paritytech.github.io/polkadot-sdk/master/cumulus_primitives_core/trait.GetParachainInfo.html){target=\\_blank} runtime API to identify and configure the parachain correctly. This API provides the parachain ID to the node.\n\n    ```rust title=\"runtime/src/apis.rs\"\n    impl cumulus_primitives_core::GetParachainInfo<Block> for Runtime {\n        fn parachain_id() -> cumulus_primitives_core::ParaId {\n            // Return your parachain ID\n            ParachainInfo::parachain_id()\n        }\n    }\n    ```\n\n- **Aura Runtime API**: For consensus, the `polkadot-omni-node` expects the [Aura runtime API](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/runtime/apis/trait.AuraApi.html){target=\\_blank} to be implemented.\n\n    ```rust title=\"runtime/src/apis.rs\"\n    impl sp_consensus_aura::AuraApi<Block, AuraId> for Runtime {\n        fn slot_duration() -> sp_consensus_aura::SlotDuration {\n            sp_consensus_aura::SlotDuration::from_millis(SLOT_DURATION)\n        }\n\n        fn authorities() -> Vec<AuraId> {\n            Aura::authorities().into_inner()\n        }\n    }\n    ```"}
{"page_id": "reference-tools-omninode", "page_title": "Polkadot Omni Node", "index": 8, "depth": 3, "title": "Required Pallets", "anchor": "required-pallets", "start_char": 6424, "end_char": 8913, "estimated_token_count": 566, "token_estimator": "heuristic-v1", "text": "### Required Pallets\n\nYour runtime must include and properly configure the following pallets:\n\n- **System Pallet**: The System pallet ([`frame-system`](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_frame/prelude/frame_system/index.html){target=\\_blank}) is fundamental and must be configured with appropriate types.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    #[frame_support::runtime]\n    impl frame_system::Config for Runtime {\n        type Block = Block;\n        type BlockNumber = BlockNumber;\n        // ... other configurations\n    }\n\n    // Must be named \"System\" for omni-node compatibility\n    pub type System = frame_system::Pallet<Runtime>;\n    ```\n\n- **ParachainSystem Pallet**: This pallet ([`cumulus-pallet-parachain-system`](https://paritytech.github.io/polkadot-sdk/master/cumulus_pallet_parachain_system/index.html){target=\\_blank}) enables parachain functionality and handles low-level details of being a parachain.\n\n    ```rust title=\"runtime/src/lib.rs\"\n    impl cumulus_pallet_parachain_system::Config for Runtime {\n        type RuntimeEvent = RuntimeEvent;\n        type OnSystemEvent = ();\n        // ... other configurations\n    }\n\n    // Must be named \"ParachainSystem\" for omni-node compatibility  \n    pub type ParachainSystem = cumulus_pallet_parachain_system::Pallet<Runtime>;\n    ```\n\n- **Aura Pallet**: For block authoring consensus ([`pallet-aura`](https://paritytech.github.io/polkadot-sdk/master/pallet_aura/index.html){target=\\_blank}).\n\n    ```rust title=\"runtime/src/lib.rs\"\n    impl pallet_aura::Config for Runtime {\n        type AuthorityId = AuraId;\n        type DisabledValidators = ();\n        type MaxAuthorities = MaxAuthorities;\n        type AllowMultipleBlocksPerSlot = ConstBool<false>;\n    }\n\n    pub type Aura = pallet_aura::Pallet<Runtime>;\n    ```\n\n- **ParachainInfo Pallet**: Provides parachain metadata ([`parachain-info`](https://paritytech.github.io/polkadot-sdk/master/staging_parachain_info/index.html){target=\\_blank}).\n\n    ```rust title=\"runtime/src/lib.rs\"\n    impl parachain_info::Config for Runtime {}\n\n    pub type ParachainInfo = parachain_info::Pallet<Runtime>;\n    ```\n\nIf you're migrating an existing parachain to use the `polkadot-omni-node`, you may need to perform runtime upgrades to add the required runtime APIs and pallets. Follow the standard parachain [runtime upgrade](/parachains/runtime-maintenance/runtime-upgrades/){target=\\_blank} procedures to implement these changes on your live network."}
{"page_id": "reference-tools-papi", "page_title": "Polkadot-API", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 16, "end_char": 1133, "estimated_token_count": 207, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Polkadot-API](https://github.com/polkadot-api/polkadot-api){target=\\_blank} (PAPI) is a set of libraries built to be modular, composable, and grounded in a â€œlight-client firstâ€ approach. Its primary aim is to equip dApp developers with an extensive toolkit for building fully decentralized applications.\n\nPAPI is optimized for light-client functionality, using the new JSON-RPC spec to support decentralized interactions fully. It provides strong TypeScript support with types and documentation generated directly from on-chain metadata, and it offers seamless access to storage reads, constants, transactions, events, and runtime calls. Developers can connect to multiple chains simultaneously and prepare for runtime updates through multi-descriptor generation and compatibility checks. PAPI is lightweight and performant, leveraging native BigInt, dynamic imports, and modular subpaths to avoid bundling unnecessary assets. It supports promise-based and observable-based APIs, integrates easily with Polkadot.js extensions, and offers signing options through browser extensions or private keys."}
{"page_id": "reference-tools-papi", "page_title": "Polkadot-API", "index": 1, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 1133, "end_char": 1149, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "reference-tools-papi", "page_title": "Polkadot-API", "index": 2, "depth": 3, "title": "API Instantiation", "anchor": "api-instantiation", "start_char": 1149, "end_char": 6190, "estimated_token_count": 1162, "token_estimator": "heuristic-v1", "text": "### API Instantiation\n\nTo instantiate the API, you can install the package by using the following command:\n\n=== \"npm\"\n\n    ```bash\n    npm i polkadot-api@1.17.2\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add polkadot-api@1.17.2\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add polkadot-api@1.17.2\n    ```\n\nThen, obtain the latest metadata from the target chain and generate the necessary types:\n\n```bash\n# Add the target chain\nnpx papi add dot -n polkadot\n```\n\nThe `papi add` command initializes the library by generating the corresponding types needed for the chain used. It assigns the chain a custom name and specifies downloading metadata from the Polkadot chain. You can replace `dot` with the name you prefer or with another chain if you want to add a different one. Once the latest metadata is downloaded, generate the required types:\n\n```bash\n# Generate the necessary types\nnpx papi\n```\n\nYou can now set up a [`PolkadotClient`](https://github.com/polkadot-api/polkadot-api/blob/main/packages/client/src/types.ts#L153){target=\\_blank} with your chosen provider to begin interacting with the API. Choose from Smoldot via WebWorker, Node.js, or direct usage, or connect through the WSS provider. The examples below show how to configure each option for your setup.\n\n=== \"Smoldot (WebWorker)\"\n\n    ```typescript\n    // `dot` is the identifier assigned during `npx papi add`\n    import { dot } from '@polkadot-api/descriptors';\n    import { createClient } from 'polkadot-api';\n    import { getSmProvider } from 'polkadot-api/sm-provider';\n    import { chainSpec } from 'polkadot-api/chains/polkadot';\n    import { startFromWorker } from 'polkadot-api/smoldot/from-worker';\n    import SmWorker from 'polkadot-api/smoldot/worker?worker';\n\n    const worker = new SmWorker();\n    const smoldot = startFromWorker(worker);\n    const chain = await smoldot.addChain({ chainSpec });\n\n    // Establish connection to the Polkadot relay chain\n    const client = createClient(getSmProvider(chain));\n\n    // To interact with the chain, obtain the `TypedApi`, which provides\n    // the necessary types for every API call on this chain\n    const dotApi = client.getTypedApi(dot);\n\n    ```\n\n=== \"Smoldot (Node.js)\"\n\n    ```typescript\n    // `dot` is the alias assigned during `npx papi add`\n    import { dot } from '@polkadot-api/descriptors';\n    import { createClient } from 'polkadot-api';\n    import { getSmProvider } from 'polkadot-api/sm-provider';\n    import { chainSpec } from 'polkadot-api/chains/polkadot';\n    import { startFromWorker } from 'polkadot-api/smoldot/from-node-worker';\n    import { fileURLToPath } from 'url';\n    import { Worker } from 'worker_threads';\n\n    // Get the path for the worker file in ESM\n    const workerPath = fileURLToPath(\n      import.meta.resolve('polkadot-api/smoldot/node-worker'),\n    );\n\n    const worker = new Worker(workerPath);\n    const smoldot = startFromWorker(worker);\n    const chain = await smoldot.addChain({ chainSpec });\n\n    // Set up a client to connect to the Polkadot relay chain\n    const client = createClient(getSmProvider(chain));\n\n    // To interact with the chain's API, use `TypedApi` for access to\n    // all the necessary types and calls associated with this chain\n    const dotApi = client.getTypedApi(dot);\n\n    ```\n\n=== \"Smoldot\"\n\n    ```typescript\n    // `dot` is the alias assigned when running `npx papi add`\n    import { dot } from '@polkadot-api/descriptors';\n    import { createClient } from 'polkadot-api';\n    import { getSmProvider } from 'polkadot-api/sm-provider';\n    import { chainSpec } from 'polkadot-api/chains/polkadot';\n    import { start } from 'polkadot-api/smoldot';\n\n    // Initialize Smoldot client\n    const smoldot = start();\n    const chain = await smoldot.addChain({ chainSpec });\n\n    // Set up a client to connect to the Polkadot relay chain\n    const client = createClient(getSmProvider(chain));\n\n    // Access the `TypedApi` to interact with all available chain calls and types\n    const dotApi = client.getTypedApi(dot);\n\n    ```\n\n=== \"WSS\"\n\n    ```typescript\n    // `dot` is the identifier assigned when executing `npx papi add`\n    import { dot } from '@polkadot-api/descriptors';\n    import { createClient } from 'polkadot-api';\n    // Use this import for Node.js environments\n    import { getWsProvider } from 'polkadot-api/ws-provider/web';\n    import { withPolkadotSdkCompat } from 'polkadot-api/polkadot-sdk-compat';\n\n    // Establish a connection to the Polkadot relay chain\n    const client = createClient(\n      // The Polkadot SDK nodes may have compatibility issues; using this enhancer is recommended.\n      // Refer to the Requirements page for additional details\n      withPolkadotSdkCompat(getWsProvider('wss://dot-rpc.stakeworld.io')),\n    );\n\n    // To interact with the chain, obtain the `TypedApi`, which provides\n    // the types for all available calls in that chain\n    const dotApi = client.getTypedApi(dot);\n\n    ```\n\nNow that you have set up the client, you can interact with the chain by reading and sending transactions."}
{"page_id": "reference-tools-papi", "page_title": "Polkadot-API", "index": 3, "depth": 3, "title": "Reading Chain Data", "anchor": "reading-chain-data", "start_char": 6190, "end_char": 7140, "estimated_token_count": 216, "token_estimator": "heuristic-v1", "text": "### Reading Chain Data\n\nThe `TypedApi` provides a streamlined way to read blockchain data through three main interfaces, each designed for specific data access patterns:\n\n- **Constants**: Access fixed values or configurations on the blockchain using the `constants` interface.\n\n    ```typescript\n    const version = await typedApi.constants.System.Version();\n    ```\n\n- **Storage queries**: Retrieve stored values by querying the blockchainâ€™s storage via the `query` interface.\n\n    ```typescript\n    const asset = await api.query.ForeignAssets.Asset.getValue(\n      token.location,\n      { at: 'best' },\n    );\n    ```\n\n- **Runtime APIs**: Interact directly with runtime APIs using the `apis` interface.\n\n    ```typescript\n    const metadata = await typedApi.apis.Metadata.metadata();\n    ```\n\nTo learn more about the different actions you can perform with the `TypedApi`, refer to the [TypedApi reference](https://papi.how/typed){target=\\_blank}."}
{"page_id": "reference-tools-papi", "page_title": "Polkadot-API", "index": 4, "depth": 3, "title": "Sending Transactions", "anchor": "sending-transactions", "start_char": 7140, "end_char": 8815, "estimated_token_count": 355, "token_estimator": "heuristic-v1", "text": "### Sending Transactions\n\nIn PAPI, the `TypedApi` provides the `tx` and `txFromCallData` methods to send transactions. \n\n- The `tx` method allows you to directly send a transaction with the specified parameters by using the `typedApi.tx.Pallet.Call` pattern:\n\n    ```typescript\n    const tx: Transaction = typedApi.tx.Pallet.Call({arg1, arg2, arg3});\n    ``` \n\n    For instance, to execute the `balances.transferKeepAlive` call, you can use the following snippet:\n\n    ```typescript\n    import { MultiAddress } from '@polkadot-api/descriptors';\n\n    const tx: Transaction = typedApi.tx.Balances.transfer_keep_alive({\n      dest: MultiAddress.Id('INSERT_DESTINATION_ADDRESS'),\n      value: BigInt(INSERT_VALUE),\n    });\n\n    ```\n\n    Ensure you replace `INSERT_DESTINATION_ADDRESS` and `INSERT_VALUE` with the actual destination address and value, respectively.\n\n- The `txFromCallData` method allows you to send a transaction using the call data. This option accepts binary call data and constructs the transaction from it. It validates the input upon creation and will throw an error if invalid data is provided. The pattern is as follows:\n\n    ```typescript\n    const callData = Binary.fromHex('0x...');\n    const tx: Transaction = typedApi.txFromCallData(callData);\n    ``` \n\n    For instance, to execute a transaction using the call data, you can use the following snippet:\n\n    ```typescript\n    const callData = Binary.fromHex('0x00002470617065726d6f6f6e');\n    const tx: Transaction = typedApi.txFromCallData(callData);\n    ```\n\nFor more information about sending transactions, refer to the [Transactions](https://papi.how/typed/tx#transactions){target=\\_blank} page."}
{"page_id": "reference-tools-papi", "page_title": "Polkadot-API", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 8815, "end_char": 8957, "estimated_token_count": 43, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor an in-depth guide on how to use PAPI, refer to the official [PAPI](https://papi.how/){target=\\_blank} documentation."}
{"page_id": "reference-tools-paraspell", "page_title": "ParaSpell XCM SDK", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 2383, "estimated_token_count": 522, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[ParaSpell](https://paraspell.github.io/docs/){target=\\_blank} is a comprehensive suite of open-source tools designed to simplify cross-chain interactions within the Polkadot ecosystem. At its core, ParaSpell is dedicated to enhancing the functionality of the [XCM (Cross-Consensus Messaging)](/parachains/interoperability/get-started/){target=\\_blank} protocol by providing developers with a unified and streamlined experience for building interoperable decentralized applications (dApps).\n\nThe primary goal of ParaSpell is to abstract away the complexities of the XCM protocol. While XCM is a powerful feature of the Polkadot network, its implementation can vary significantly between different parachains. ParaSpell addresses this challenge by providing a standardized set of tools that enable developers to easily integrate cross-chain functionality into their applications, saving valuable time and effort. ParaSpell is a \"common good\" software, meaning it is free, open-source, and dedicated to the growth of the Polkadot ecosystem.\n\nThe ParaSpell suite includes:\n\n- **[XCM SDK](https://paraspell.xyz/#xcm-sdk){target=\\_blank}**: Provides a unified layer to incorporate XCM into decentralized applications, simplifying complex cross-chain interactions.\n- **[XCM API](https://paraspell.xyz/#xcm-api){target=\\_blank}**: Offers an efficient, package-free approach to integrating XCM functionality while offloading heavy computing tasks, minimizing costs and improving application performance.\n- **[XCM Router](https://paraspell.xyz/#xcm-router){target=\\_blank}**: Enables cross-chain asset swaps in a single command, allowing developers to send one asset type (such as DOT on Polkadot) and receive a different asset on another chain (like ASTR on Astar).\n- **[XCM Analyser](https://paraspell.xyz/#xcm-analyser){target=\\_blank}**: Decodes and translates complex XCM multilocation data into readable information, supporting easier troubleshooting and debugging.\n- **[XCM Visualizator](https://paraspell.xyz/#xcm-visualizator){target=\\_blank}**: A tool designed to give developers a clear, interactive view of XCM activity across the Polkadot ecosystem, providing insights into cross-chain communication flow.\n- **[XCM Playground](https://paraspell.xyz/#try-it){target=\\_blank}**: An interactive playground for testing different XCM scenarios."}
{"page_id": "reference-tools-paraspell", "page_title": "ParaSpell XCM SDK", "index": 1, "depth": 3, "title": "ParaSpell XCM SDK", "anchor": "paraspell-xcm-sdk", "start_char": 2383, "end_char": 3290, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "### ParaSpell XCM SDK\n\nThe [ParaSpell XCM SDK](https://paraspell.github.io/docs/sdk/getting-started.html){target=\\_blank} is a core component of the ParaSpell toolset and a foundational library for developers looking to leverage XCM in their applications. It is the first and only XCM SDK in the ecosystem to support both PolkadotJS and Polkadot API, providing developers with flexibility and choice.\n\nThe SDK simplifies the process of creating and sending XCM messages by providing a user-friendly builder pattern. This allows developers to construct complex XCM calls with just a few lines of code, reducing the likelihood of errors and ensuring that messages are constructed correctly.\n\nBy using the ParaSpell XCM SDK, developers can significantly accelerate their development workflow and build powerful, interoperable dApps that take full advantage of the Polkadot network's cross-chain capabilities."}
{"page_id": "reference-tools-paraspell", "page_title": "ParaSpell XCM SDK", "index": 2, "depth": 2, "title": "Install ParaSpell", "anchor": "install-paraspell", "start_char": 3290, "end_char": 3634, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## Install ParaSpell\n\nIf you want to use ParaSpell in your project you can add it as a dependency with the following command:\n\n=== \"npm\"\n\n    ```bash\n    npm install --save @paraspell/sdk@11.12.6\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm add @paraspell/sdk@11.12.6\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn add @paraspell/sdk@11.12.6\n    ```"}
{"page_id": "reference-tools-paraspell", "page_title": "ParaSpell XCM SDK", "index": 3, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3634, "end_char": 4043, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nExplore more about ParaSpell through these resources:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge tutorial\">Tutorial</span> __Transfer Assets Between Parachains__\n\n    ---\n\n    Learn how to transfer assets across chains with ParaSpell.\n\n    [:octicons-arrow-right-24: Get Started](/chain-interactions/send-transactions/interoperability/transfer-assets-parachains/)\n\n</div>"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 0, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 454, "end_char": 1089, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Installation\n\nAdd Polkadart to your `pubspec.yaml`:\n\n=== \"All packages\"\n\n    ```bash\n    dart pub add polkadart polkadart_cli polkadart_keyring polkadart_scale_codec secp256k1_ecdsa sr25519 ss58 substrate_bip39 substrate_metadata\n    ```\n\n=== \"Core only\"\n\n    ```bash\n    dart pub add polkadart polkadart_cli polkadart_keyring\n    ```\n\nFor type-safe API generation, add the following to your `pubspec.yaml`:\n\n{% raw %}\n```yaml title=\"pubspec.yaml\"\npolkadart:\n  output_dir: lib/generated\n  chains:\n    polkadot: wss://rpc.polkadot.io\n    kusama: wss://kusama-rpc.polkadot.io\n    custom: wss://your-node.example.com\n```\n{% endraw %}"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 1, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 1089, "end_char": 1105, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 2, "depth": 3, "title": "Type Generation", "anchor": "type-generation", "start_char": 1105, "end_char": 1354, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "### Type Generation\n\nPolkadart provides a CLI tool to generate type definitions from any Polkadot-SDK compatible blockchain network. This allows you to build type-safe Dart applications without dealing with the low-level details of the blockchain."}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 3, "depth": 3, "title": "Run Generator", "anchor": "run-generator", "start_char": 1354, "end_char": 1421, "estimated_token_count": 19, "token_estimator": "heuristic-v1", "text": "### Run Generator\n\n```bash\ndart run polkadart_cli:generate -v\n```"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 4, "depth": 3, "title": "Use Generated Types", "anchor": "use-generated-types", "start_char": 1421, "end_char": 1964, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Use Generated Types\n\n```dart\nimport 'package:your_app/generated/polkadot/polkadot.dart';\nimport 'package:polkadart/polkadart.dart';\nimport 'package:ss58/ss58.dart';\n\nfinal provider = Provider.fromUri(Uri.parse('wss://rpc.polkadot.io'));\nfinal polkadot = Polkadot(provider);\n  \n// Account from SS58 address\nfinal account = Address.decode('19t9Q2ay58hMDaeg6eeBhqmHsRnc2jDMV3cYYw9zbc59HLj');\n\n// Retrieve Account Balance\nfinal accountInfo = await polkadot.query.system.account(account.pubkey);\nprint('Balance: ${accountInfo.data.free}')\n```"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 5, "depth": 3, "title": "Creating an API Instance", "anchor": "creating-an-api-instance", "start_char": 1964, "end_char": 2413, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "### Creating an API Instance\n\nAn API instance is required to interact with the blockchain. Polkadart provides a `Provider` class that allows you to connect to any network.\n\n```dart\nimport 'package:demo/generated/polkadot/polkadot.dart';\nimport 'package:polkadart/provider.dart';\n\nFuture<void> main(List<String> arguments) async {\n  final provider = Provider.fromUri(Uri.parse('wss://rpc.polkadot.io'));\n  final polkadot = Polkadot(provider);\n}\n```"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 6, "depth": 3, "title": "Reading Chain Data", "anchor": "reading-chain-data", "start_char": 2413, "end_char": 2909, "estimated_token_count": 111, "token_estimator": "heuristic-v1", "text": "### Reading Chain Data\n\nBesides querying the data using the `query` from the generated API, you can also use the State API for querying storage data, metadata, runtime information, and other chain information.\n\n```dart\nfinal stateApi = StateApi(provider);\n\n// Get current runtime version\nfinal runtimeVersion = await stateApi.getRuntimeVersion();\nprint(runtimeVersion.toJson());\n\n// Get metadata\nfinal metadata = await stateApi.getMetadata();\nprint('Metadata version: ${metadata.version}');\n```"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 7, "depth": 3, "title": "Subscribe to New Blocks", "anchor": "subscribe-to-new-blocks", "start_char": 2909, "end_char": 3197, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "### Subscribe to New Blocks\n\nYou can subscribe to new blocks on the blockchain using the `subscribe` method.\n\n```dart\nfinal subscription = await provider.subscribe('chain_subscribeNewHeads', []);\n\nsubscription.stream.forEach((response) {\n  print('New head: ${response.result}');\n});\n```"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 8, "depth": 3, "title": "Send a Transaction", "anchor": "send-a-transaction", "start_char": 3197, "end_char": 4956, "estimated_token_count": 380, "token_estimator": "heuristic-v1", "text": "### Send a Transaction\n\nPerhaps the most common operation done in any blockchain is transferring funds. Here you can see how that can be done using Polkadart:\n\n```dart\nfinal wallet = await KeyPair.sr25519.fromUri(\"//Alice\");\nprint('Alice\\' wallet: ${wallet.address}');\n\n// Get information necessary to build a proper extrinsic\nfinal runtimeVersion = await polkadot.rpc.state.getRuntimeVersion();\nfinal currentBlockNumber = (await polkadot.query.system.number()) - 1;\nfinal currentBlockHash = await polkadot.query.system.blockHash(currentBlockNumber);\nfinal genesisHash = await polkadot.query.system.blockHash(0);\nfinal nonce = await polkadot.rpc.system.accountNextIndex(wallet.address);\n\n// Make the encoded call\nfinal multiAddress = $MultiAddress().id(wallet.publicKey.bytes);\nfinal transferCall = polkadot.tx.balances.transferKeepAlive(dest: multiAddress, value: BigInt.one).encode();\n\n// Make the payload\nfinal payload = SigningPayload(\n    method: transferCall,\n    specVersion: runtimeVersion.specVersion,\n    transactionVersion: runtimeVersion.transactionVersion,\n    genesisHash: encodeHex(genesisHash),\n    blockHash: encodeHex(currentBlockHash),\n    blockNumber: currentBlockNumber,\n    eraPeriod: 64,\n    nonce: nonce,\n    tip: 0,\n).encode(polkadot.registry);\n\n// Sign the payload and build the final extrinsic\nfinal signature = wallet.sign(payload);\nfinal extrinsic = ExtrinsicPayload(\n  signer: wallet.bytes(),\n  method: transferCall,\n  signature: signature,\n  eraPeriod: 64,\n  blockNumber: currentBlockNumber,\n  nonce: nonce,\n  tip: 0,\n).encode(polkadot.registry, SignatureType.sr25519);\n\n// Send the extrinsic to the blockchain\nfinal author = AuthorApi(provider);\nawait author.submitAndWatchExtrinsic(extrinsic, (data) {\n  print(data);\n});\n```"}
{"page_id": "reference-tools-polkadart", "page_title": "Polkadart", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4956, "end_char": 5178, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nTo dive deeper into Polkadart, refer to theÂ [official Polkadart documentation](https://polkadart.dev/){target=\\_blank}, where you can find comprehensive guides for common use cases and advanced usage."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 385, "end_char": 669, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Polkadot.js API](https://github.com/polkadot-js/api){target=\\_blank} uses JavaScript/TypeScript to interact with Polkadot SDK-based chains. It allows you to query nodes, read chain state, and submit transactions through a dynamic, auto-generated API interface."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 1, "depth": 3, "title": "Dynamic API Generation", "anchor": "dynamic-api-generation", "start_char": 669, "end_char": 1033, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "### Dynamic API Generation\n\nUnlike traditional static APIs, the Polkadot.js API generates its interfaces automatically when connecting to a node. Here's what happens when you connect:\n\n1. The API connects to your node.\n2. It retrieves the chain's metadata.\n3. Based on this metadata, it creates specific endpoints in this format: `api.<type>.<module>.<section>`."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 2, "depth": 3, "title": "Available API Categories", "anchor": "available-api-categories", "start_char": 1033, "end_char": 1888, "estimated_token_count": 248, "token_estimator": "heuristic-v1", "text": "### Available API Categories\n\nYou can access three main categories of chain interactions:\n\n- **[Runtime constants](https://polkadot.js.org/docs/api/start/api.consts){target=\\_blank}** (`api.consts`):\n\n    - Access runtime constants directly.\n    - Returns values immediately without function calls.\n    - **Example**: `api.consts.balances.existentialDeposit`\n\n- **[State queries](https://polkadot.js.org/docs/api/start/api.query/){target=\\_blank}** (`api.query`):\n\n    - Read chain state.\n    - **Example**: `api.query.system.account(accountId)`\n\n- **[Transactions](https://polkadot.js.org/docs/api/start/api.tx/){target=\\_blank}** (`api.tx`):\n    - Submit extrinsics (transactions).\n    - **Example**: `api.tx.balances.transfer(accountId, value)`\n\nThe available methods and interfaces will automatically reflect what's possible on your connected chain."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 3, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1888, "end_char": 2441, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo add the Polkadot.js API to your project, use the following command to install the version `16.4.7` which supports any Polkadot SDK-based chain:\n\n=== \"npm\"\n    ```bash\n    npm i @polkadot/api@16.4.7\n    ```\n\n=== \"pnpm\"\n    ```bash\n    pnpm add @polkadot/api@16.4.7\n    ```\n\n=== \"yarn\"\n    ```bash\n    yarn add @polkadot/api@16.4.7\n    ```\n\nFor more detailed information about installation, see the [Installation](https://polkadot.js.org/docs/api/start/install/){target=\\_blank} section in the official Polkadot.js API documentation."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 4, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 2441, "end_char": 2457, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Get Started"}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 5, "depth": 3, "title": "Creating an API Instance", "anchor": "creating-an-api-instance", "start_char": 2457, "end_char": 3226, "estimated_token_count": 175, "token_estimator": "heuristic-v1", "text": "### Creating an API Instance\n\nTo interact with a Polkadot SDK-based chain, you must establish a connection through an API instance. The API provides methods for querying chain state, sending transactions, and subscribing to updates.\n\nTo create an API connection:\n\n```js\nimport { ApiPromise, WsProvider } from '@polkadot/api';\n\n// Create a WebSocket provider\nconst wsProvider = new WsProvider('wss://rpc.polkadot.io');\n\n// Initialize the API\nconst api = await ApiPromise.create({ provider: wsProvider });\n\n// Verify the connection by getting the chain's genesis hash\nconsole.log('Genesis Hash:', api.genesisHash.toHex());\n\n```\n\n!!!warning\n    All `await` operations must be wrapped in an async function or block since the API uses promises for asynchronous operations."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 6, "depth": 3, "title": "Reading Chain Data", "anchor": "reading-chain-data", "start_char": 3226, "end_char": 4066, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "### Reading Chain Data\n\nThe API provides several ways to read data from the chain. You can access:\n\n- **Constants**: Values that are fixed in the runtime and don't change without a runtime upgrade.\n\n    ```js\n    // Get the minimum balance required for a new account\n    const minBalance = api.consts.balances.existentialDeposit.toNumber();\n\n    ```\n\n- **State**: Current chain state that updates with each block.\n\n    ```js\n    // Example address\n    const address = '5DTestUPts3kjeXSTMyerHihn1uwMfLj8vU8sqF7qYrFabHE';\n\n    // Get current timestamp\n    const timestamp = await api.query.timestamp.now();\n\n    // Get account information\n    const { nonce, data: balance } = await api.query.system.account(address);\n\n    console.log(`\n      Timestamp: ${timestamp}\n      Free Balance: ${balance.free}\n      Nonce: ${nonce}\n    `);\n\n    ```"}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 7, "depth": 3, "title": "Sending Transactions", "anchor": "sending-transactions", "start_char": 4066, "end_char": 4881, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "### Sending Transactions\n\nTransactions (also called extrinsics) modify the chain state. Before sending a transaction, you need:\n\n- A funded account with sufficient balance to pay transaction fees.\n- The account's keypair for signing.\n\nTo make a transfer:\n\n```js\n// Assuming you have an `alice` keypair from the Keyring\nconst recipient = 'INSERT_RECIPIENT_ADDRESS';\nconst amount = 'INSERT_VALUE'; // Amount in the smallest unit (e.g., Planck for DOT)\n\n// Sign and send a transfer\nconst txHash = await api.tx.balances\n  .transfer(recipient, amount)\n  .signAndSend(alice);\n\nconsole.log('Transaction Hash:', txHash);\n\n```\n\nThe `alice` keypair in the example comes from a `Keyring` object. For more details about managing keypairs, see the [Keyring documentation](https://polkadot.js.org/docs/keyring){target=\\_blank}."}
{"page_id": "reference-tools-polkadot-js-api", "page_title": "Polkadot.js API", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4881, "end_char": 5042, "estimated_token_count": 44, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor more detailed information about the Polkadot.js API, check the [official documentation](https://polkadot.js.org/docs/){target=\\_blank}."}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 30, "end_char": 484, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Python Substrate Interface](https://github.com/polkascan/py-substrate-interface){target=\\_blank} is a powerful library that enables interaction with Polkadot SDK-based chains. It provides essential functionality for:\n\n- Querying on-chain storage.\n- Composing and submitting extrinsics.\n- SCALE encoding/decoding.\n- Interacting with Substrate runtime metadata.\n- Managing blockchain interactions through convenient utility methods."}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 1, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 484, "end_char": 791, "estimated_token_count": 72, "token_estimator": "heuristic-v1", "text": "## Installation\n\nInstall the library using `pip`:\n\n```py\npip install substrate-interface\n```\n\nFor more installation details, see the [Installation](https://jamdottech.github.io/py-polkadot-sdk/getting-started/installation/){target=\\_blank} section in the official Python Substrate Interface documentation."}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 2, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 791, "end_char": 971, "estimated_token_count": 32, "token_estimator": "heuristic-v1", "text": "## Get Started\n\nThis guide will walk you through the basic operations with the Python Substrate Interface: connecting to a node, reading chain state, and submitting transactions."}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 3, "depth": 3, "title": "Establishing Connection", "anchor": "establishing-connection", "start_char": 971, "end_char": 1488, "estimated_token_count": 130, "token_estimator": "heuristic-v1", "text": "### Establishing Connection\n\nThe first step is to establish a connection to a Polkadot SDK-based node. You can connect to either a local or remote node:\n\n```py\nfrom substrateinterface import SubstrateInterface\n\n# Connect to a node using websocket\nsubstrate = SubstrateInterface(\n    # For local node: \"ws://127.0.0.1:9944\"\n    # For Polkadot: \"wss://rpc.polkadot.io\"\n    # For Kusama: \"wss://kusama-rpc.polkadot.io\"\n    url=\"INSERT_WS_URL\"\n)\n\n# Verify connection\nprint(f\"Connected to chain: {substrate.chain}\")\n\n```"}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 4, "depth": 3, "title": "Reading Chain State", "anchor": "reading-chain-state", "start_char": 1488, "end_char": 2506, "estimated_token_count": 242, "token_estimator": "heuristic-v1", "text": "### Reading Chain State\n\nYou can query various on-chain storage items. To retrieve data, you need to specify three key pieces of information:\n\n- **Pallet name**: Module or pallet that contains the storage item you want to access.\n- **Storage item**: Specific storage entry you want to query within the pallet.\n- **Required parameters**: Any parameters needed to retrieve the desired data.\n\nHere's an example of how to check an account's balance and other details:\n\n```py\n# ...\n\n# Query account balance and info\naccount_info = substrate.query(\n    module=\"System\",  # The pallet name\n    storage_function=\"Account\",  # The storage item\n    params=[\"INSERT_ADDRESS\"],  # Account address in SS58 format\n)\n\n# Access account details from the result\nfree_balance = account_info.value[\"data\"][\"free\"]\nreserved = account_info.value[\"data\"][\"reserved\"]\nnonce = account_info.value[\"nonce\"]\n\nprint(\n    f\"\"\"\n    Account Details:\n    - Free Balance: {free_balance}\n    - Reserved: {reserved} \n    - Nonce: {nonce}\n    \"\"\"\n)\n\n```"}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 5, "depth": 3, "title": "Submitting Transactions", "anchor": "submitting-transactions", "start_char": 2506, "end_char": 3899, "estimated_token_count": 294, "token_estimator": "heuristic-v1", "text": "### Submitting Transactions\n\nTo modify the chain state, you need to submit transactions (extrinsics). Before proceeding, ensure you have:\n\n- A funded account with sufficient balance to pay transaction fees.\n- Access to the account's keypair.\n\nHere's how to create and submit a balance transfer:\n\n```py\n#...\n\n# Compose the transfer call\ncall = substrate.compose_call(\n    call_module=\"Balances\",  # The pallet name\n    call_function=\"transfer_keep_alive\",  # The extrinsic function\n    call_params={\n        'dest': 'INSERT_ADDRESS',  # Recipient's address\n        'value': 'INSERT_VALUE'  # Amount in smallest unit (e.g., Planck for DOT)\n    }\n)\n\n# Create a signed extrinsic\nextrinsic = substrate.create_signed_extrinsic(\n    call=call, keypair=keypair  # Your keypair for signing\n)\n\n# Submit and wait for inclusion\nreceipt = substrate.submit_extrinsic(\n    extrinsic, wait_for_inclusion=True  # Wait until the transaction is in a block\n)\n\nif receipt.is_success:\n    print(\n        f\"\"\"\n        Transaction successful:\n        - Extrinsic Hash: {receipt.extrinsic_hash}\n        - Block Hash: {receipt.block_hash}\n        \"\"\"\n    )\nelse:\n    print(f\"Transaction failed: {receipt.error_message}\")\n\n```\n\nThe `keypair` object is essential for signing transactions. See the [Keypair](https://jamdottech.github.io/py-polkadot-sdk/reference/keypair/){target=\\_blank} documentation for more details."}
{"page_id": "reference-tools-py-substrate-interface", "page_title": "Python Substrate Interface", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3899, "end_char": 4302, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you understand the basics, you can:\n\n- Explore more complex queries and transactions.\n- Learn about batch transactions and utility functions.\n- Discover how to work with custom pallets and types.\n\nFor comprehensive reference materials and advanced features, see the [Python Substrate Interface](https://jamdottech.github.io/py-polkadot-sdk/){target=\\_blank} documentation."}
{"page_id": "reference-tools-sidecar", "page_title": "Sidecar REST API", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 15, "end_char": 1185, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [Sidecar REST API](https://github.com/paritytech/substrate-api-sidecar){target=\\_blank} is a service that provides a REST interface for interacting with Polkadot SDK-based blockchains. With this API, developers can easily access a broad range of endpoints for nodes, accounts, transactions, parachains, and more.\n\nSidecar functions as a caching layer between your application and a Polkadot SDK-based node, offering standardized REST endpoints that simplify interactions without requiring complex, direct RPC calls. This approach is especially valuable for developers who prefer REST APIs or build applications in languages with limited WebSocket support.\n\nSome of the key features of the Sidecar API include:\n\n- **REST API interface**: Provides a familiar REST API interface for interacting with Polkadot SDK-based chains.\n- **Standardized endpoints**: Offers consistent endpoint formats across different chain implementations.\n- **Caching layer**: Acts as a caching layer to improve performance and reduce direct node requests.\n- **Multiple chain support**: Works with any Polkadot SDK-based chain, including Polkadot, Kusama, and custom chains."}
{"page_id": "reference-tools-sidecar", "page_title": "Sidecar REST API", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 1185, "end_char": 1484, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nSidecar API requires Node.js version 18.14 LTS or higher. Verify your Node.js version:\n\n```bash\nnode --version\n```\n\nIf you need to install or update Node.js, visit the [official Node.js website](https://nodejs.org/){target=\\_blank} to download and install the latest LTS version."}
{"page_id": "reference-tools-sidecar", "page_title": "Sidecar REST API", "index": 2, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 1484, "end_char": 2137, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo install Substrate API Sidecar, use one of the following commands:\n\n=== \"npm\"\n\n    ```bash\n    npm install -g @substrate/api-sidecar\n    ```\n\n=== \"pnpm\"\n\n    ```bash\n    pnpm install -g @substrate/api-sidecar\n    ```\n\n=== \"yarn\"\n\n    ```bash\n    yarn global add @substrate/api-sidecar\n    ```\n\nYou can confirm the installation by running:\n\n```bash\nsubstrate-api-sidecar --version\n```\n\nFor more information about the Sidecar API installation, see the [installation and usage](https://github.com/paritytech/substrate-api-sidecar?tab=readme-ov-file#npm-package-installation-and-usage){target=\\_blank} section of the Sidecar API README."}
{"page_id": "reference-tools-sidecar", "page_title": "Sidecar REST API", "index": 3, "depth": 2, "title": "Usage", "anchor": "usage", "start_char": 2137, "end_char": 5688, "estimated_token_count": 1005, "token_estimator": "heuristic-v1", "text": "## Usage\n\nTo use the Sidecar API, you have two options:\n\n- **Local node**: Run a node locally, which Sidecar will connect to by default, requiring no additional configuration. To start, run the following:\n\n    ```bash\n    substrate-api-sidecar\n    ```\n\n- **Remote node**: Connect Sidecar to a remote node by specifying the RPC endpoint for that chain. For example, to gain access to the Polkadot Asset Hub associated endpoints.\n\n    ```bash\n    SAS_SUBSTRATE_URL=wss://polkadot-asset-hub-rpc.polkadot.io substrate-api-sidecar\n    ```\n\n    For more configuration details, see the [Configuration](https://github.com/paritytech/substrate-api-sidecar?tab=readme-ov-file#configuration){target=\\_blank} section of the Sidecar API documentation.\n\nOnce the Sidecar API is running, youâ€™ll see output similar to this:\n\n<div id=\"termynal\" data-termynal>\n    <span data-ty='input'><span class='file-path'></span>SAS_SUBSTRATE_URL=wss://polkadot-asset-hub-rpc.polkadot.io substrate-api-sidecar</span>\n    <br>\n    <span data-ty>SAS:</span>\n    <span data-ty>ðŸ“¦ LOG:</span>\n    <span data-ty>   âœ… LEVEL: \"info\"</span>\n    <span data-ty>   âœ… JSON: false</span>\n    <span data-ty>   âœ… FILTER_RPC: false</span>\n    <span data-ty>   âœ… STRIP_ANSI: false</span>\n    <span data-ty>   âœ… WRITE: false</span>\n    <span data-ty>   âœ… WRITE_PATH: \"/opt/homebrew/lib/node_modules/@substrate/api-sidecar/build/src/logs\"</span>\n    <span data-ty>   âœ… WRITE_MAX_FILE_SIZE: 5242880</span>\n    <span data-ty>   âœ… WRITE_MAX_FILES: 5</span>\n    <span data-ty>ðŸ“¦ SUBSTRATE:</span>\n    <span data-ty>   âœ… URL: \"wss://polkadot-asset-hub-rpc.polkadot.io\"</span>\n    <span data-ty>   âœ… TYPES_BUNDLE: undefined</span>\n    <span data-ty>   âœ… TYPES_CHAIN: undefined</span>\n    <span data-ty>   âœ… TYPES_SPEC: undefined</span>\n    <span data-ty>   âœ… TYPES: undefined</span>\n    <span data-ty>   âœ… CACHE_CAPACITY: undefined</span>\n    <span data-ty>ðŸ“¦ EXPRESS:</span>\n    <span data-ty>   âœ… BIND_HOST: \"127.0.0.1\"</span>\n    <span data-ty>   âœ… PORT: 8080</span>\n    <span data-ty>   âœ… KEEP_ALIVE_TIMEOUT: 5000</span>\n    <span data-ty>ðŸ“¦ METRICS:</span>\n    <span data-ty>   âœ… ENABLED: false</span>\n    <span data-ty>   âœ… PROM_HOST: \"127.0.0.1\"</span>\n    <span data-ty>   âœ… PROM_PORT: 9100</span>\n    <span data-ty>   âœ… LOKI_HOST: \"127.0.0.1\"</span>\n    <span data-ty>   âœ… LOKI_PORT: 3100</span>\n    <span data-ty>   âœ… INCLUDE_QUERYPARAMS: false</span>\n    <br>\n    <span data-ty>2024-11-06 08:06:01 info: Version: 19.3.0</span>\n    <span data-ty>2024-11-06 08:06:02 warn: API/INIT: RPC methods not decorated: chainHead_v1_body, chainHead_v1_call, chainHead_v1_continue, chainHead_v1_follow, chainHead_v1_header, chainHead_v1_stopOperation, chainHead_v1_storage, chainHead_v1_unfollow, chainHead_v1_unpin, chainSpec_v1_chainName, chainSpec_v1_genesisHash, chainSpec_v1_properties, transactionWatch_v1_submitAndWatch, transactionWatch_v1_unwatch, transaction_v1_broadcast, transaction_v1_stop</span>\n    <span data-ty>2024-11-06 08:06:02 info: Connected to chain Polkadot Asset Hub on the statemint client at wss://polkadot-asset-hub-rpc.polkadot.io</span>\n    <span data-ty>2024-11-06 08:06:02 info: Listening on http://127.0.0.1:8080/</span>\n    <span data-ty>2024-11-06 08:06:02 info: Check the root endpoint (http://127.0.0.1:8080/) to see the available endpoints for the current node</span>\n</div>\nWith Sidecar running, you can access the exposed endpoints via a browser, [`Postman`](https://www.postman.com/){target=\\_blank}, [`curl`](https://curl.se/){target=\\_blank}, or your preferred tool."}
{"page_id": "reference-tools-sidecar", "page_title": "Sidecar REST API", "index": 4, "depth": 3, "title": "Endpoints", "anchor": "endpoints", "start_char": 5688, "end_char": 7028, "estimated_token_count": 394, "token_estimator": "heuristic-v1", "text": "### Endpoints\n\nSidecar API provides a set of REST endpoints that allow you to query different aspects of the chain, including blocks, accounts, and transactions. Each endpoint offers specific insights into the chainâ€™s state and activities.\n\nFor example, to retrieve the version of the node, use the `/node/version` endpoint:\n\n```bash\ncurl -X 'GET' \\\n  'http://127.0.0.1:8080/node/version' \\\n  -H 'accept: application/json'\n```\n\nAlternatively, you can access `http://127.0.0.1:8080/node/version` directly in a browser since itâ€™s a `GET` request.\n\nIn response, youâ€™ll see output similar to this (assuming youâ€™re connected to Polkadot Asset Hub):\n\n<div id=\"termynal\" data-termynal>\n    <span data-ty=\"input\"><span class=\"file-path\"></span>curl -X 'GET' 'http://127.0.0.1:8080/node/version' -H 'accept: application/json'</span>\n    <br>\n    <span data-ty>{</span>\n    <span data-ty>    \"clientVersion\": \"1.16.1-835e0767fe8\",</span>\n    <span data-ty>    \"clientImplName\": \"statemint\",</span>\n    <span data-ty>    \"chain\": \"Polkadot Asset Hub\"</span>\n    <span data-ty>}</span>\n</div>\nFor a complete list of available endpoints and their documentation, visit the [Sidecar API list endpoints](https://paritytech.github.io/substrate-api-sidecar/dist/){target=\\_blank}. You can learn about the endpoints and how to use them in your applications."}
{"page_id": "reference-tools-sidecar", "page_title": "Sidecar REST API", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 7028, "end_char": 7309, "estimated_token_count": 67, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nTo dive deeper, refer to the [official Sidecar documentation](https://github.com/paritytech/substrate-api-sidecar?tab=readme-ov-file#substrateapi-sidecar){target=\\_blank}. This provides a comprehensive guide to the available configurations and advanced usage."}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 403, "estimated_token_count": 68, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nSubxt is a Rust library designed to interact with Polkadot SDK-based blockchains. It provides a type-safe interface for submitting transactions, querying on-chain state, and performing other blockchain interactions. By leveraging Rust's strong type system, subxt ensures that your code is validated at compile time, reducing runtime errors and improving reliability."}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 403, "end_char": 734, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore using subxt, ensure you have the following requirements:\n\n- Rust and Cargo installed on your system. You can install them using [Rustup](https://rustup.rs/){target=\\_blank}.\n- A Rust project initialized. If you don't have one, create it with:\n    ```bash\n    cargo new my_project && cd my_project\n    ```"}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 2, "depth": 2, "title": "Installation", "anchor": "installation", "start_char": 734, "end_char": 2796, "estimated_token_count": 510, "token_estimator": "heuristic-v1", "text": "## Installation\n\nTo use subxt in your project, you must install the necessary dependencies. Each plays a specific role in enabling interaction with the blockchain:\n\n1. **Install the subxt CLI**: [`subxt-cli`](https://crates.io/crates/subxt-cli){target=\\_blank} is a command-line tool that provides utilities for working with Polkadot SDK metadata. In the context of subxt, it is essential to download chain metadata, which is required to generate type-safe Rust interfaces for interacting with the blockchain. Install it using the following:\n\n    ```bash\n    cargo install subxt-cli@0.44.0\n    ```\n\n2. **Add core dependencies**: These dependencies are essential for interacting with the blockchain.\n\n    - **[subxt](https://crates.io/crates/subxt){target=\\_blank}**: The main library for communicating with Polkadot SDK nodes. It handles RPC requests, encoding/decoding, and type generation.\n\n        ```bash\n        cargo add subxt@0.44.0\n        ```\n\n    - **[subxt-signer](https://crates.io/crates/subxt-signer){target=\\_blank}**: Provides cryptographic functionality for signing transactions. Without this, you can only read data but cannot submit transactions.\n\n        ```bash\n        cargo add subxt-signer@0.44.0\n        ```\n\n    - **[tokio](https://crates.io/crates/tokio){target=\\_blank}**: An asynchronous runtime for Rust. Since blockchain operations are async, Tokio enables the efficient handling of network requests. The `rt` feature enables Tokio's runtime, including the current-thread single-threaded scheduler, which is necessary for async execution. The `macros` feature provides procedural macros like `#[tokio::main]` to simplify runtime setup.\n\n        ```bash\n        cargo add tokio@1.44.2 --features rt,macros\n        ```\n\n    After adding the dependencies, your `Cargo.toml` should look like this:\n\n    ```toml\n    [package]\n    name = \"my_project\"\n    version = \"0.1.0\"\n    edition = \"2021\"\n\n    [dependencies]\n    subxt = \"0.41.0\"\n    subxt-signer = \"0.41.0\"\n    tokio = { version = \"1.44.2\", features = [\"rt\", \"macros\"] }\n\n    ```"}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 3, "depth": 2, "title": "Get Started", "anchor": "get-started", "start_char": 2796, "end_char": 2973, "estimated_token_count": 29, "token_estimator": "heuristic-v1", "text": "## Get Started\n\nThis guide will walk you through the fundamental operations of subxt, from setting up your environment to executing transactions and querying blockchain state."}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 4, "depth": 3, "title": "Download Chain Metadata", "anchor": "download-chain-metadata", "start_char": 2973, "end_char": 3364, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### Download Chain Metadata\n\nBefore interacting with a blockchain, you need to retrieve its metadata. This metadata defines storage structures, extrinsics, and other runtime details. Use the `subxt-cli` tool to download the metadata, replacing `INSERT_NODE_URL` with the URL of the node you want to interact with:\n\n```bash\nsubxt metadata --url INSERT_NODE_URL > polkadot_metadata.scale\n```"}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 5, "depth": 3, "title": "Generate Type-Safe Interfaces", "anchor": "generate-type-safe-interfaces", "start_char": 3364, "end_char": 5229, "estimated_token_count": 529, "token_estimator": "heuristic-v1", "text": "### Generate Type-Safe Interfaces\n\nUse the `#[subxt::subxt]` macro to generate a type-safe Rust interface from the downloaded metadata:\n\n```rust\n// Generate an interface that we can use from the node's metadata.\n#[subxt::subxt(runtime_metadata_path = \"./polkadot_metadata.scale\")]\npub mod polkadot {}\n```\n\nOnce subxt interfaces are generated, you can interact with your node in the following ways. You can use the links below to view the related subxt documentation:\n\n- **[Transactions](https://docs.rs/subxt/latest/subxt/book/usage/transactions/index.html){target=\\_blank}**: Builds and submits transactions, monitors their inclusion in blocks, and retrieves associated events.\n- **[Storage](https://docs.rs/subxt/latest/subxt/book/usage/storage/index.html){target=\\_blank}**: Enables querying of node storage data.\n- **[Events](https://docs.rs/subxt/latest/subxt/book/usage/events/index.html){target=\\_blank}**: Retrieves events emitted from recent blocks.\n- **[Constants](https://docs.rs/subxt/latest/subxt/book/usage/constants/index.html){target=\\_blank}**: Accesses constant values stored in nodes that remain unchanged across a specific runtime version.\n- **[Blocks](https://docs.rs/subxt/latest/subxt/book/usage/blocks/index.html){target=\\_blank}**: Loads recent blocks or subscribes to new/finalized blocks, allowing examination of extrinsics, events, and storage at those blocks.\n- **[Runtime APIs](https://docs.rs/subxt/latest/subxt/book/usage/runtime_apis/index.html){target=\\_blank}**: Makes calls into pallet runtime APIs to fetch data.\n- **[Custom values](https://docs.rs/subxt/latest/subxt/book/usage/custom_values/index.html){target=\\_blank}**: Accesses \"custom values\" contained within metadata.\n- **[Raw RPC calls](https://docs.rs/subxt/latest/subxt/book/usage/rpc/index.html){target=\\_blank}**: Facilitates raw RPC requests to compatible nodes."}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 6, "depth": 3, "title": "Initialize the Subxt Client", "anchor": "initialize-the-subxt-client", "start_char": 5229, "end_char": 6115, "estimated_token_count": 229, "token_estimator": "heuristic-v1", "text": "### Initialize the Subxt Client\n\nTo interact with a blockchain node using subxt, create an asynchronous main function and initialize the client. Replace `INSERT_NODE_URL` with the URL of your target node:\n\n```rust\nuse std::str::FromStr;\nuse subxt::utils::AccountId32;\nuse subxt::{OnlineClient, PolkadotConfig};\nuse subxt_signer::{bip39::Mnemonic,sr25519::Keypair};\n\n// Generate an interface that we can use from the node's metadata.\n#[subxt::subxt(runtime_metadata_path = \"./polkadot_metadata.scale\")]\npub mod polkadot {}\n\n#[tokio::main(flavor = \"current_thread\")]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Define the node URL.\n    const NODE_URL: &str = \"INSERT_NODE_URL\";\n\n    // Initialize the Subxt client to interact with the blockchain.\n    let api = OnlineClient::<PolkadotConfig>::from_url(NODE_URL).await?;\n\n    // Your code here...\n\n    Ok(())\n}\n```"}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 7, "depth": 3, "title": "Read Chain Data", "anchor": "read-chain-data", "start_char": 6115, "end_char": 7470, "estimated_token_count": 296, "token_estimator": "heuristic-v1", "text": "### Read Chain Data\n\nsubxt provides multiple ways to access on-chain data:\n\n- **Constants**: Constants are predefined values in the runtime that remain unchanged unless modified by a runtime upgrade.\n\n    For example, to retrieve the existential deposit, use:\n    \n    ```rust\n        // A query to obtain some constant.\n        let constant_query = polkadot::constants().balances().existential_deposit();\n\n        // Obtain the value.\n        let value = api.constants().at(&constant_query)?;\n\n        println!(\"Existential deposit: {:?}\", value);\n    ```\n\n- **State**: State refers to the current chain data, which updates with each block.\n\n    To fetch account information, replace `INSERT_ADDRESS` with the address you want to fetch data from and use:\n\n    ```rust\n        // Define the target account address.\n        const ADDRESS: &str = \"INSERT_ADDRESS\";\n        let account = AccountId32::from_str(ADDRESS).unwrap();\n\n        // Build a storage query to access account information.\n        let storage_query = polkadot::storage().system().account(&account.into());\n\n        // Fetch the latest state for the account.\n        let result = api\n            .storage()\n            .at_latest()\n            .await?\n            .fetch(&storage_query)\n            .await?\n            .unwrap();\n\n        println!(\"Account info: {:?}\", result);\n    ```"}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 8, "depth": 3, "title": "Submit Transactions", "anchor": "submit-transactions", "start_char": 7470, "end_char": 8944, "estimated_token_count": 311, "token_estimator": "heuristic-v1", "text": "### Submit Transactions\n\nTo submit a transaction, you must construct an extrinsic, sign it with your private key, and send it to the blockchain. Replace `INSERT_DEST_ADDRESS` with the recipient's address, `INSERT_AMOUNT` with the amount to transfer, and `INSERT_SECRET_PHRASE` with the sender's mnemonic phrase:\n\n```rust\n    // Define the recipient address and transfer amount.\n    const DEST_ADDRESS: &str = \"INSERT_DEST_ADDRESS\";\n    const AMOUNT: u128 = INSERT_AMOUNT;\n\n    // Convert the recipient address into an `AccountId32`.\n    let dest = AccountId32::from_str(DEST_ADDRESS).unwrap();\n\n    // Build the balance transfer extrinsic.\n    let balance_transfer_tx = polkadot::tx()\n        .balances()\n        .transfer_allow_death(dest.into(), AMOUNT);\n\n    // Load the sender's keypair from a mnemonic phrase.\n    const SECRET_PHRASE: &str = \"INSERT_SECRET_PHRASE\";\n    let mnemonic = Mnemonic::parse(SECRET_PHRASE).unwrap();\n    let sender_keypair = Keypair::from_phrase(&mnemonic, None).unwrap();\n\n    // Sign and submit the extrinsic, then wait for it to be finalized.\n    let events = api\n        .tx()\n        .sign_and_submit_then_watch_default(&balance_transfer_tx, &sender_keypair)\n        .await?\n        .wait_for_finalized_success()\n        .await?;\n\n    // Check for a successful transfer event.\n    if let Some(event) = events.find_first::<polkadot::balances::events::Transfer>()? {\n        println!(\"Balance transfer successful: {:?}\", event);\n    }\n```"}
{"page_id": "reference-tools-subxt", "page_title": "Subxt Rust API", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 8944, "end_char": 9174, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you've covered the basics dive into the official [subxt documentation](https://docs.rs/subxt/latest/subxt/book/index.html){target=\\_blank} for comprehensive reference materials and advanced features."}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 787, "estimated_token_count": 134, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAs described in the [Interoperability](/develop/interoperability){target=\\_blank} section, XCM (Cross-Consensus Messaging) is a protocol used in the Polkadot and Kusama ecosystems to enable communication and interaction between chains. It facilitates cross-chain communication, allowing assets, data, and messages to flow seamlessly across the ecosystem.\n\nAs XCM is central to enabling communication between blockchains, developers need robust tools to help interact with, build, and test XCM messages. Several XCM tools simplify working with the protocol by providing libraries, frameworks, and utilities that enhance the development process, ensuring that applications built within the Polkadot ecosystem can efficiently use cross-chain functionalities."}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 1, "depth": 2, "title": "Popular XCM Tools", "anchor": "popular-xcm-tools", "start_char": 787, "end_char": 809, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Popular XCM Tools"}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 2, "depth": 3, "title": "Moonsong Labs XCM Tools", "anchor": "moonsong-labs-xcm-tools", "start_char": 809, "end_char": 2190, "estimated_token_count": 333, "token_estimator": "heuristic-v1", "text": "### Moonsong Labs XCM Tools\n\n[Moonsong Labs XCM Tools](https://github.com/Moonsong-Labs/xcm-tools){target=\\_blank} provides a collection of scripts for managing and testing XCM operations between Polkadot SDK-based runtimes. These tools allow performing tasks like asset registration, channel setup, and XCM initialization. Key features include:\n\n- **Asset registration**: Registers assets, setting units per second (up-front fees), and configuring error (revert) codes.\n- **XCM initializer**: Initializes XCM, sets default XCM versions, and configures revert codes for XCM-related precompiles.\n- **HRMP manipulator**: Manages HRMP channel actions, including opening, accepting, or closing channels.\n- **XCM-Transactor-Info-Setter**: Configures transactor information, including extra weight and fee settings.\n- **Decode XCM**: Decodes XCM messages on the relay chain or parachains to help interpret cross-chain communication.\n\nTo get started, clone the repository and install the required dependencies:\n\n```bash\ngit clone https://github.com/Moonsong-Labs/xcm-tools && \ncd xcm-tools &&\nyarn install\n```\n\nFor a full overview of each script, visit the [scripts](https://github.com/Moonsong-Labs/xcm-tools/tree/main/scripts){target=\\_blank} directory or refer to the [official documentation](https://github.com/Moonsong-Labs/xcm-tools/blob/main/README.md){target=\\_blank} on GitHub."}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 3, "depth": 3, "title": "ParaSpell", "anchor": "paraspell", "start_char": 2190, "end_char": 2667, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "### ParaSpell\n\n[ParaSpell](/reference/tools/paraspell/){target=\\_blank} is a collection of open-source XCM tools that streamline cross-chain asset transfers and interactions across the Polkadot and Kusama ecosystems. It provides developers with an intuitive interface to build, test, and deploy interoperable dApps, featuring message composition, decoding, and practical utilities for parachain interactions that simplify debugging and cross-chain communication optimization."}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 4, "depth": 3, "title": "Astar XCM Tools", "anchor": "astar-xcm-tools", "start_char": 2667, "end_char": 4207, "estimated_token_count": 369, "token_estimator": "heuristic-v1", "text": "### Astar XCM Tools\n\nThe [Astar parachain](https://github.com/AstarNetwork/Astar/tree/master){target=\\_blank} offers a crate with a set of utilities for interacting with the XCM protocol. The [xcm-tools](https://github.com/AstarNetwork/Astar/tree/master/bin/xcm-tools){target=\\_blank} crate provides a straightforward method for users to locate a sovereign account or calculate an XC20 asset ID. Some commands included by the xcm-tools crate allow users to perform the following tasks:\n\n- **Sovereign accounts**: Obtain the sovereign account address for any parachain, either on the Relay Chain or for sibling parachains, using a simple command.\n- **XC20 EVM addresses**: Generate XC20-compatible Ethereum addresses for assets by entering the asset ID, making it easy to integrate assets across Ethereum-compatible environments.\n- **Remote accounts**: Retrieve remote account addresses needed for multi-location compatibility, using flexible options to specify account types and parachain IDs.\n\nTo start using these tools, clone the [Astar repository](https://github.com/AstarNetwork/Astar){target=\\_blank} and compile the xcm-tools package:\n\n```bash\ngit clone https://github.com/AstarNetwork/Astar &&\ncd Astar &&\ncargo build --release -p xcm-tools\n```\n\nAfter compiling, verify the setup with the following command:\n\n```bash\n./target/release/xcm-tools --help\n```\nFor more details on using Astar xcm-tools, consult the [official documentation](https://docs.astar.network/docs/learn/interoperability/xcm/integration/tools/){target=\\_blank}."}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 5, "depth": 3, "title": "Chopsticks", "anchor": "chopsticks", "start_char": 4207, "end_char": 4517, "estimated_token_count": 65, "token_estimator": "heuristic-v1", "text": "### Chopsticks\n\nThe Chopsticks library provides XCM functionality for testing XCM messages across networks, enabling you to fork multiple parachains along with a relay chain. For further details, see the [Chopsticks documentation](/tutorials/polkadot-sdk/testing/fork-live-chains/){target=\\_blank} about XCM."}
{"page_id": "reference-tools-xcm-tools", "page_title": "XCM Tools", "index": 6, "depth": 3, "title": "Moonbeam XCM SDK", "anchor": "moonbeam-xcm-sdk", "start_char": 4517, "end_char": 6146, "estimated_token_count": 385, "token_estimator": "heuristic-v1", "text": "### Moonbeam XCM SDK\n\nThe [Moonbeam XCM SDK](https://github.com/moonbeam-foundation/xcm-sdk){target=\\_blank} enables developers to easily transfer assets between chains, either between parachains or between a parachain and the relay chain, within the Polkadot/Kusama ecosystem. With the SDK, you don't need to worry about determining the [Multilocation](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#7-universal-consensus-location-identifiers){target=\\_blank} of the origin or destination assets or which extrinsics are used on which networks.\n\nThe SDK consists of two main packages:\n\n- **[XCM SDK](https://github.com/moonbeam-foundation/xcm-sdk/tree/main/packages/sdk){target=\\_blank}**: Core SDK for executing XCM transfers between chains in the Polkadot/Kusama ecosystem.\n- **[MRL SDK](https://github.com/moonbeam-foundation/xcm-sdk/tree/main/packages/mrl){target=\\_blank}**: Extension of the XCM SDK for transferring liquidity into and across the Polkadot ecosystem from other ecosystems like Ethereum.\n\nKey features include:\n\n- **Simplified asset transfers**: Abstracts away complex multilocation determinations and extrinsic selection.\n- **Cross-ecosystem support**: Enables transfers between Polkadot/Kusama chains and external ecosystems.\n- **Developer-friendly API**: Provides intuitive interfaces for cross-chain functionality.\n- **Comprehensive documentation**: Includes usage guides and API references for both packages.\n\nFor detailed usage examples and API documentation, visit the [official Moonbeam XCM SDK documentation](https://moonbeam-foundation.github.io/xcm-sdk/latest/){target=\\_blank}."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 853, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nZombienet is a testing framework designed for Polkadot SDK-based blockchain networks. It enables developers to efficiently deploy and test ephemeral blockchain environments on platforms like Kubernetes, Podman, and native setups. With its simple CLI and Domain Specific Language (DSL) for writing tests, Zombienet streamlines network spawning, testing, and performance validation.\n\nKey features include:\n\n- **Multi-provider support**: Run networks on Kubernetes, Podman, or locally as native processes.\n- **Network orchestration**: Spawn relay chains with multiple validators and parachains with collators.\n- **Test DSL**: Write natural-language test scripts to evaluate metrics, logs, events, and on-chain storage.\n- **Monitoring integration**: Built-in support for Prometheus, Grafana, and Tempo on supported providers."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 1, "depth": 2, "title": "Install Zombienet", "anchor": "install-zombienet", "start_char": 853, "end_char": 2808, "estimated_token_count": 453, "token_estimator": "heuristic-v1", "text": "## Install Zombienet\n\nZombienet releases are available on the [Zombienet repository](https://github.com/paritytech/zombienet){target=\\_blank}. Choose one of the following installation methods:\n\n=== \"Use the executable\"\n\n    Download the appropriate executable for your operating system from the [latest release](https://github.com/paritytech/zombienet/releases){target=\\_blank} page. Each release includes executables for Linux and macOS.\n\n    Make the downloaded file executable:\n\n    ```bash\n    chmod +x zombienet-macos-arm64\n    ```\n\n    Verify the installation:\n\n    ```bash\n    ./zombienet-macos-arm64 version\n    ```\n\n    Optionally, move the executable to your PATH:\n\n    ```bash\n    mv zombienet-macos-arm64 /usr/local/bin/zombienet\n    ```\n\n    Now you can use the `zombienet` command directly:\n\n    ```bash\n    zombienet version\n    ```\n\n=== \"Use Nix\"\n\n    For Nix users, the Zombienet repository provides a [`flake.nix`](https://github.com/paritytech/zombienet/blob/main/flake.nix){target=\\_blank} file. You need [Flakes](https://nixos.wiki/wiki/Flakes#Enable_flakes){target=\\_blank} enabled.\n    \n    Run Zombienet directly:\n\n    ```bash\n    nix run github:paritytech/zombienet/INSERT_ZOMBIENET_VERSION -- \\\n    spawn INSERT_ZOMBIENET_CONFIG_FILE_NAME.toml\n    ```\n\n    Or include Zombienet in your current shell:\n    \n    ```bash\n    nix shell github:paritytech/zombienet/INSERT_ZOMBIENET_VERSION\n    ```\n\n=== \"Use Docker\"\n\n    Run Zombienet using Docker:\n\n    ```bash\n    docker run -it --rm \\\n    -v $(pwd):/home/nonroot/zombie-net/host-current-files \\\n    paritytech/zombienet\n    ```\n\n    Inside the container, set up the necessary binaries:\n\n    ```bash\n    npm run zombie -- setup polkadot polkadot-parachain\n    ```\n\n    Add the binaries to your PATH:\n\n    ```bash\n    export PATH=/home/nonroot/zombie-net:$PATH\n    ```\n\n    Spawn a network:\n\n    ```bash\n    npm run zombie -- -p native spawn host-current-files/minimal.toml\n    ```"}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 2, "depth": 2, "title": "Providers", "anchor": "providers", "start_char": 2808, "end_char": 3392, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "## Providers\n\nZombienet supports different backend providers for running nodes: [Kubernetes](https://kubernetes.io/){target=\\_blank}, [Podman](https://podman.io/){target=\\_blank}, and native (local processes). Specify the provider using the `--provider` flag or in your network configuration file:\n\n```bash\nzombienet spawn network.toml --provider INSERT_PROVIDER\n```\n\nOr set it in the configuration:\n\n```toml title=\"network.toml\"\n[settings]\nprovider = \"INSERT_PROVIDER\"\n...\n```\n\nEnsure to replace `INSERT_PROVIDER` with the appropriate provider: `kubernetes`, `podman`, or `native`."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 3, "depth": 3, "title": "Kubernetes", "anchor": "kubernetes", "start_char": 3392, "end_char": 3866, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "### Kubernetes\n\nKubernetes is compatible with [GKE](https://cloud.google.com/kubernetes-engine){target=\\_blank}, [Docker Desktop](https://docs.docker.com/desktop/features/kubernetes/){target=\\_blank}, and [kind](https://kind.sigs.k8s.io/){target=\\_blank}.\n\n- **Requirements**: Install [`kubectl`](https://kubernetes.io/docs/tasks/tools/#kubectl){target=\\_blank} and ensure proper cluster permissions.\n- **Features**: Uses Prometheus operator for monitoring when available."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 4, "depth": 3, "title": "Podman", "anchor": "podman", "start_char": 3866, "end_char": 4304, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "### Podman\n\nPodman is a daemonless container engine for Linux. Zombienet supports Podman rootless as a provider.\n\n- **Requirements**: Install [Podman](https://podman.io/getting-started/installation){target=\\_blank} on Linux.\n\n- **Features**: Deploys Prometheus, Tempo, and Grafana for monitoring. Services are accessible at `http://127.0.0.1:34123` (Prometheus), `http://127.0.0.1:34125` (Tempo), and `http://127.0.0.1:41461` (Grafana)."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 5, "depth": 3, "title": "Native", "anchor": "native", "start_char": 4304, "end_char": 4779, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "### Native\n\nThe native provider runs nodes as local processes on your machine.\n\n- **Requirements**: Have the necessary binaries (`polkadot`, `polkadot-parachain`) in your PATH. Install them using:\n\n    ```bash\n    zombienet setup polkadot polkadot-parachain\n    ```\n\n    For custom binaries, specify the path in your configuration or add them to your PATH:\n\n    ```bash\n    export PATH=$PATH:INSERT_PATH_TO_BINARY\n    ```\n\n- **Features**: No additional monitoring features."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 6, "depth": 2, "title": "Configure Zombienet", "anchor": "configure-zombienet", "start_char": 4779, "end_char": 5039, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Configure Zombienet\n\nZombienet uses JSON or TOML configuration files to define network topology, nodes, and parameters. The [Zombienet repository](https://github.com/paritytech/zombienet/tree/main/examples){target=\\_blank} provides example configurations."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 7, "depth": 3, "title": "Basic Configuration", "anchor": "basic-configuration", "start_char": 5039, "end_char": 6314, "estimated_token_count": 281, "token_estimator": "heuristic-v1", "text": "### Basic Configuration\n\nA minimal configuration includes settings, relay chain configuration, and parachain configuration:\n\n=== \"TOML\"\n\n    ```toml title=\"basic-network.toml\"\n    [settings]\n    timeout = 1000\n\n    [relaychain]\n    chain = \"rococo-local\"\n    default_command = \"polkadot\"\n\n        [[relaychain.nodes]]\n        name = \"alice\"\n        validator = true\n\n        [[relaychain.nodes]]\n        name = \"bob\"\n        validator = true\n\n    [[parachains]]\n    id = 1000\n    chain = \"asset-hub-rococo-local\"\n\n        [parachains.collator]\n        name = \"collator-01\"\n        command = \"polkadot-parachain\"\n    ```\n\n=== \"JSON\"\n\n    ```json title=\"basic-network.json\"\n    {\n      \"settings\": {\n        \"timeout\": 1000\n      },\n      \"relaychain\": {\n        \"chain\": \"rococo-local\",\n        \"default_command\": \"polkadot\",\n        \"nodes\": [\n          {\n            \"name\": \"alice\",\n            \"validator\": true\n          },\n          {\n            \"name\": \"bob\",\n            \"validator\": true\n          }\n        ]\n      },\n      \"parachains\": [\n        {\n          \"id\": 1000,\n          \"chain\": \"asset-hub-rococo-local\",\n          \"collator\": {\n            \"name\": \"collator-01\",\n            \"command\": \"polkadot-parachain\"\n          }\n        }\n      ]\n    }\n    ```"}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 8, "depth": 3, "title": "CLI Commands", "anchor": "cli-commands", "start_char": 6314, "end_char": 7108, "estimated_token_count": 241, "token_estimator": "heuristic-v1", "text": "### CLI Commands\n\nZombienet provides the following commands:\n\n- **`spawn <networkConfig>`**: Spawn the network defined in the configuration file.\n- **`test <testFile>`**: Run tests on the spawned network.\n- **`setup <binaries>`**: Download and set up `polkadot` or `polkadot-parachain` binaries.\n- **`convert <filePath>`**: Convert a [polkadot-launch](https://github.com/paritytech/polkadot-launch){target=\\_blank} configuration to Zombienet format.\n- **`version`**: Print Zombienet version.\n- **`help`**: Print help information.\n\nCommon flags:\n\n- **`-p`, `--provider`**: Override the provider.\n- **`-d`, `--dir`**: Specify directory for network files.\n- **`-m`, `--monitor`**: Start as monitor without auto cleanup.\n- **`-c`, `--spawn-concurrency`**: Number of concurrent spawning processes."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 9, "depth": 2, "title": "Spawn a Network", "anchor": "spawn-a-network", "start_char": 7108, "end_char": 7572, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "## Spawn a Network\n\nTo spawn a network, create a configuration file and run:\n\n```bash\nzombienet spawn network.toml --provider native\n```\n\nZombienet will:\n\n1. Download or locate the required binaries.\n2. Generate chain specifications.\n3. Start relay chain validators.\n4. Register and start parachain collators.\n5. Display connection endpoints and logs.\n\nAccess the running nodes via the provided RPC endpoints (typically `ws://127.0.0.1:9944` for the first node)."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 10, "depth": 2, "title": "Write Tests", "anchor": "write-tests", "start_char": 7572, "end_char": 7814, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## Write Tests\n\nZombienet provides a Domain Specific Language (DSL) for writing tests in `.zndsl` files. Tests can evaluate:\n\n- Metrics from Prometheus\n- Log patterns\n- System events\n- On-chain storage\n- Custom JavaScript/TypeScript scripts"}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 11, "depth": 3, "title": "Test File Structure", "anchor": "test-file-structure", "start_char": 7814, "end_char": 8155, "estimated_token_count": 78, "token_estimator": "heuristic-v1", "text": "### Test File Structure\n\nTest files contain a header and body:\n\n```toml title=\"example-test.zndsl\"\nDescription: Example test suite\nNetwork: ./network.toml\nCreds: config\n\n# Test assertions\nalice: is up\nbob: is up\nalice: parachain 1000 is registered within 200 seconds\nalice: parachain 1000 block height is at least 10 within 300 seconds\n```"}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 12, "depth": 3, "title": "Run Tests", "anchor": "run-tests", "start_char": 8155, "end_char": 8331, "estimated_token_count": 41, "token_estimator": "heuristic-v1", "text": "### Run Tests\n\nExecute tests using:\n\n```bash\nzombienet test example-test.zndsl --provider native\n```\n\nThe test runner will execute each assertion and report pass/fail status."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 13, "depth": 3, "title": "Common Assertions", "anchor": "common-assertions", "start_char": 8331, "end_char": 8804, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "### Common Assertions\n\nSome frequently used assertions include:\n\n- **Well-known functions**: `alice: is up`, `alice: parachain 100 is registered within 225 seconds`\n- **Metrics**: `alice: reports node_roles is 4`\n- **Logs**: `alice: log line matches glob \"Imported #1\" within 10 seconds`\n- **System events**: `alice: system event matches \"\"paraId\":[0-9]+\" within 10 seconds`\n- **Custom scripts**: `alice: js-script ./script.js return is greater than 1 within 200 seconds`"}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 14, "depth": 2, "title": "Configuration Reference", "anchor": "configuration-reference", "start_char": 8804, "end_char": 9282, "estimated_token_count": 120, "token_estimator": "heuristic-v1", "text": "## Configuration Reference\n\nFor detailed configuration options, see:\n\n- [Configuration examples](https://github.com/paritytech/zombienet/tree/main/examples){target=\\_blank}: Sample configurations for various scenarios.\n- [Testing DSL specification](https://paritytech.github.io/zombienet/cli/test-dsl-definition-spec.html){target=\\_blank}: Complete DSL syntax reference.\n- [Zombienet book](https://paritytech.github.io/zombienet/){target=\\_blank}: Comprehensive documentation."}
{"page_id": "reference-tools-zombienet", "page_title": "Zombienet", "index": 15, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 9282, "end_char": 9774, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Zombienet Support__\n\n    ---\n\n    For further support and information, refer to the official resources.\n\n    [:octicons-arrow-right-24: GitHub Repository](https://github.com/paritytech/zombienet){target=\\_blank}\n\n    [:octicons-arrow-right-24: Element Channel](https://matrix.to/#/!FWyuEyNvIFygLnWNMh:parity.io?via=parity.io&via=matrix.org&via=web3.foundation){target=\\_blank}\n\n</div>"}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 0, "end_char": 1097, "estimated_token_count": 199, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Technical Reference section provides comprehensive documentation of Polkadot's architecture, core concepts, and development tooling. Whether you're exploring how Polkadot's relay chain coordinates parachains, understanding governance mechanisms, or building applications on the network, this reference covers the technical foundations you need.\n\nPolkadot is a multi-chain network that enables diverse, interconnected blockchains to share security and communicate seamlessly. Understanding how these components interact from the [relay chain](/polkadot-protocol/glossary#relay-chain){target=\\_blank} that validates [parachains](/polkadot-protocol/glossary#parachain){target=\\_blank} to the [governance](/reference/glossary#governance){target=\\_blank} mechanisms that evolve the protocol is essential for developers, validators, and network participants.\n\nThis guide organizes technical documentation across five core areas: Polkadot Hub, Parachains, On-Chain Governance, Glossary, and Tools, each providing detailed information on different aspects of the Polkadot ecosystem."}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 1, "depth": 2, "title": "Polkadot Hub", "anchor": "polkadot-hub", "start_char": 1097, "end_char": 2394, "estimated_token_count": 248, "token_estimator": "heuristic-v1", "text": "## Polkadot Hub\n\n[Polkadot Hub](/reference/polkadot-hub/){target=\\_blank} is the entry point to Polkadot for all users and application developers. It provides access to essential Web3 services including smart contracts, asset management, staking, governance, identity management, and cross-ecosystem interoperabilityâ€”without requiring you to deploy or manage a parachain.\n\nThe Hub encompasses a set of core functionality that enables developers and users to build and interact with applications on Polkadot. Key capabilities include:\n\n- **Smart contracts**: Deploy Ethereum-compatible smart contracts and build decentralized applications.\n- **Asset management**: Create, manage, and transfer fungible tokens and NFTs across the ecosystem.\n- **Staking**: Participate in network security and earn rewards by staking DOT.\n- **Governance**: Vote on proposals and participate in Polkadot's decentralized decision-making through OpenGov.\n- **Identity services**: Register and manage on-chain identities, enabling access to governance roles and network opportunities.\n- **Cross-chain interoperability**: Leverage XCM messaging to interact securely with other chains in the Polkadot ecosystem.\n- **Collectives and DAOs**: Participate in governance collectives and decentralized autonomous organizations."}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 2, "depth": 2, "title": "Parachains", "anchor": "parachains", "start_char": 2394, "end_char": 3713, "estimated_token_count": 293, "token_estimator": "heuristic-v1", "text": "## Parachains\n\n[Parachains](/reference/parachains/){target=\\_blank} are specialized blockchains that connect to the Polkadot relay chain, inheriting its security while maintaining their own application-specific logic. The parachains documentation covers:\n\n- **Accounts**: Deep dive into account types, storage, and management on parachains.\n- **Blocks, transactions and fees**: Understand block production, transaction inclusion, and fee mechanisms.\n- **Consensus**: Learn how parachain blocks are validated and finalized through the relay chain's consensus.\n- **Chain data**: Explore data structures, storage layouts, and state management.\n- **Cryptography**: Study cryptographic primitives used in Polkadot SDK-based chains.\n- **Data encoding**: Understand how data is encoded and decoded for blockchain compatibility.\n- **Networks**: Learn about networking protocols and peer-to-peer communication.\n- **Interoperability**: Discover [Cross-Consensus Messaging (XCM)](/parachains/interoperability/get-started/){target=\\_blank}, the standard for cross-chain communication.\n- **Randomness**: Understand how randomness is generated and used in Polkadot chains.\n- **Node and runtime**: Learn about parachain nodes, runtime environments, and the [Polkadot SDK](https://github.com/paritytech/polkadot-sdk){target=\\_blank}."}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 3, "depth": 2, "title": "On-Chain Governance", "anchor": "on-chain-governance", "start_char": 3713, "end_char": 4593, "estimated_token_count": 170, "token_estimator": "heuristic-v1", "text": "## On-Chain Governance\n\n[On-Chain governance](/reference/governance/){target=\\_blank} is the decentralized decision-making mechanism for the Polkadot network. It manages the evolution and modification of the network's runtime logic, enabling community oversight and approval for proposed changes. The governance documentation details:\n\n- **OpenGov framework**: Understand Polkadot's next-generation governance system with enhanced delegation, flexible tracks, and simultaneous referendums.\n- **Origins and tracks**: Learn how governance proposals are categorized, prioritized, and executed based on their privilege level and complexity.\n- **Voting and delegation**: Explore conviction voting, vote delegation, and how token holders participate in governance.\n- **Governance evolution**: See how Polkadot's governance has evolved from Governance V1 to the current OpenGov system."}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 4, "depth": 2, "title": "Glossary", "anchor": "glossary", "start_char": 4593, "end_char": 5034, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "## Glossary\n\nThe [Glossary](/reference/glossary/){target=\\_blank} provides quick-reference definitions for Polkadot-specific terminology. Essential terms include:\n\n- Blockchain concepts (blocks, transactions, state)\n- Consensus mechanisms (validators, collators, finality)\n- Polkadot-specific terms (relay chain, parachain, XCM, FRAME)\n- Network components (nodes, runtimes, storage)\n- Governance terminology (origins, tracks, referendums)"}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 5, "depth": 2, "title": "Tools", "anchor": "tools", "start_char": 5034, "end_char": 6301, "estimated_token_count": 349, "token_estimator": "heuristic-v1", "text": "## Tools\n\nThe [Tools](/reference/tools/){target=\\_blank} section documents essential development and interaction tools for the Polkadot ecosystem:\n\n- **Light clients**: Lightweight solutions for interacting with the network without running full nodes.\n- **JavaScript/TypeScript tools**: Libraries like [Polkadot.js API](/reference/tools/polkadot-js-api/){target=\\_blank} and [PAPI](/reference/tools/papi/){target=\\_blank} for building applications.\n- **Rust tools**: [Polkadart](/reference/tools/polkadart/){target=\\_blank} and other Rust-based libraries for SDK development.\n- **Python tools**: [py-substrate-interface](/reference/tools/py-substrate-interface/){target=\\_blank} for Python developers.\n- **Testing and development**: Tools like [Moonwall](/reference/tools/moonwall/){target=\\_blank}, [Chopsticks](/reference/tools/chopsticks/){target=\\_blank}, and [Omninode](/reference/tools/omninode/){target=\\_blank} for smart contract and parachain testing.\n- **Indexing and monitoring**: [Sidecar](/reference/tools/sidecar/){target=\\_blank} for data indexing and [Dedot](/reference/tools/dedot/){target=\\_blank} for substrate interaction.\n- **Cross-chain tools**: [ParaSpell](/reference/tools/paraspell/){target=\\_blank} for XCM integration and asset transfers."}
{"page_id": "reference", "page_title": "Technical Reference Overview", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6301, "end_char": 7664, "estimated_token_count": 334, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor detailed exploration of specific areas, proceed to any of the main sections:\n\n<div class=\"grid cards\" markdown>\n\n- <span class=\"badge learn\">Learn</span> **Polkadot Hub**\n\n    ---\n\n    Understand the relay chain's role in coordinating parachains, providing shared security, and enabling governance.\n\n    [:octicons-arrow-right-24: Reference](/reference/polkadot-hub/)\n\n- <span class=\"badge learn\">Learn</span> **Parachains**\n\n    ---\n\n    Deep dive into parachain architecture, consensus, data structures, and building application-specific blockchains.\n\n    [:octicons-arrow-right-24: Reference](/reference/parachains/)\n\n- <span class=\"badge learn\">Learn</span> **On-Chain Governance**\n\n    ---\n\n    Explore Polkadot's decentralized governance framework and how to participate in network decision-making.\n\n    [:octicons-arrow-right-24: Reference](/reference/governance/)\n\n- <span class=\"badge guide\">Guide</span> **Glossary**\n\n    ---\n\n    Quick reference for Polkadot-specific terminology and concepts used throughout the documentation.\n\n    [:octicons-arrow-right-24: Reference](/reference/glossary/)\n\n- <span class=\"badge guide\">Guide</span> **Tools**\n\n    ---\n\n    Discover development tools, libraries, and frameworks for building and interacting with Polkadot.\n\n    [:octicons-arrow-right-24: Reference](/reference/tools/)\n\n</div>"}
{"page_id": "smart-contracts-connect", "page_title": "Connect to Polkadot", "index": 0, "depth": 2, "title": "Networks Details", "anchor": "networks-details", "start_char": 771, "end_char": 1424, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "## Networks Details\n\nDevelopers can leverage smart contracts across diverse networks, from TestNets to MainNet. This section outlines the network specifications and connection details for each environment.\n\n=== \"Polkadot Hub TestNet\"\n\n    Network name\n\n    ```text\n    Polkadot Hub TestNet\n    ```\n\n    ---\n\n    Currency symbol\n    \n    ```text\n    PAS\n    ```\n\n    ---\n    \n    Chain ID\n    \n    ```text\n    420420422\n    ```\n\n    ---\n    \n    RPC URL\n    \n    ```text\n    https://testnet-passet-hub-eth-rpc.polkadot.io\n    ```\n\n    ---\n    \n    Block explorer URL\n    \n    ```text\n    https://blockscout-passet-hub.parity-testnet.parity.io/\n    ```"}
{"page_id": "smart-contracts-connect", "page_title": "Connect to Polkadot", "index": 1, "depth": 2, "title": "Test Tokens", "anchor": "test-tokens", "start_char": 1424, "end_char": 2438, "estimated_token_count": 233, "token_estimator": "heuristic-v1", "text": "## Test Tokens\n\nYou will need testnet tokens to perform transactions and engage with smart contracts on any chain. Here's how to obtain Paseo (PAS) tokens for testing purposes:\n\n1. Navigate to the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}. If the desired network is not already selected, choose it from the Network drop-down.\n\n2. Copy your address linked to the TestNet and paste it into the designated field.\n\n    ![](/images/smart-contracts/connect/connect-to-polkadot-01.webp)\n\n3. Click the **Get Some PASs** button to request free test PAS tokens. These tokens will be sent to your wallet shortly.\n\n    ![](/images/smart-contracts/connect/connect-to-polkadot-02.webp)\n\nNow that you have obtained PAS tokens in your wallet, youâ€™re ready to deploy and interact with smart contracts on Polkadot Hub TestNet! These tokens will allow you to pay for gas fees when executing transactions, deploying contracts, and testing your dApp functionality in a secure testnet environment."}
{"page_id": "smart-contracts-connect", "page_title": "Connect to Polkadot", "index": 2, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 2438, "end_char": 3502, "estimated_token_count": 253, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nFor your next steps, explore the various smart contract guides demonstrating how to use and integrate different tools and development environments into your workflow.\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Get started with Remix__\n\n    ---\n\n    Learn how to get started with Remix, a browser-based IDE for writing, deploying, and interacting with smart contracts.\n\n    [:octicons-arrow-right-24: Build with Remix IDE](/smart-contracts/dev-environments/remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy a contract using Remix__\n\n    ---\n\n    Deploy your first contract on Polkadot Hub using the Remix IDE.\n\n    [:octicons-arrow-right-24: Build with Remix IDE](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Interact with the blockchain with viem__\n\n    ---\n\n    Use viem to deploy and interact with smart contracts on Polkadot Hub.\n\n    [:octicons-arrow-right-24: Build with viem](/smart-contracts/libraries/viem/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 0, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 787, "end_char": 1258, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following:\n\n- [Node.js](https://nodejs.org/en){target=\\_blank} v22.10.0 or later installed on your system.\n- A crypto wallet (such as MetaMask) funded with test tokens. Refer to the [Connect to Polkadot](/smart-contracts/connect){target=\\_blank} guide for more details.\n- A basic understanding of React and JavaScript.\n- Some familiarity with blockchain fundamentals and Solidity (helpful but not required)."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 1, "depth": 2, "title": "Project Overview", "anchor": "project-overview", "start_char": 1258, "end_char": 2446, "estimated_token_count": 296, "token_estimator": "heuristic-v1", "text": "## Project Overview\n\nThis dApp will interact with a basic Storage contract that you will create and deploy with Hardhat. The contract will allow you to:\n\n- Store a number on the blockchain.\n- Retrieve the stored number from the blockchain.\n- Update the stored number with a new value.\n\nYour project directory will be organized as follows:\n\n```bash\npolkadot-hub-tutorial/\nâ”œâ”€â”€ storage-contract/          # Hardhat project for smart contract\nâ”‚   â”œâ”€â”€ contracts/\nâ”‚   â”‚   â””â”€â”€ Storage.sol\nâ”‚   â”œâ”€â”€ scripts/\nâ”‚   â”‚   â””â”€â”€ deploy.ts\nâ”‚   â”œâ”€â”€ artifacts/\nâ”‚   â”‚   â””â”€â”€ contracts/\nâ”‚   â”‚       â””â”€â”€ Storage.sol/\nâ”‚   â”‚           â””â”€â”€ Storage.json\nâ”‚   â”œâ”€â”€ hardhat.config.ts\nâ”‚   â”œâ”€â”€ .env\nâ”‚   â””â”€â”€ package.json\nâ”‚\nâ””â”€â”€ dapp/                 # Next.js dApp project\n    â”œâ”€â”€ abis/\n    â”‚   â””â”€â”€ Storage.json\n    â””â”€â”€ app/\n        â”œâ”€â”€ components/\n        â”‚   â”œâ”€â”€ ReadContract.tsx\n        â”‚   â”œâ”€â”€ WalletConnect.tsx\n        â”‚   â””â”€â”€ WriteContract.tsx\n        â”œâ”€â”€ utils/\n        â”‚   â”œâ”€â”€ contract.ts\n        â”‚   â””â”€â”€ viem.ts\n        â”œâ”€â”€ favicon.ico\n        â”œâ”€â”€ globals.css\n        â”œâ”€â”€ layout.tsx\n        â””â”€â”€ page.tsx\n```\n\nCreate the main folder for the project:\n\n```bash\nmkdir polkadot-hub-tutorial\ncd polkadot-hub-tutorial\n```"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 2, "depth": 2, "title": "Create and Deploy the Storage Contract", "anchor": "create-and-deploy-the-storage-contract", "start_char": 2446, "end_char": 2695, "estimated_token_count": 48, "token_estimator": "heuristic-v1", "text": "## Create and Deploy the Storage Contract\n\nBefore building the dApp, you'll need to create and deploy the Storage smart contract. This section will guide you through using Hardhat to write, compile, and deploy the contract to Polkadot Hub TestNet."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 3, "depth": 3, "title": "Set Up Hardhat Project", "anchor": "set-up-hardhat-project", "start_char": 2695, "end_char": 3094, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "### Set Up Hardhat Project\n\nFirst, create a new directory for your Hardhat project and initialize it:\n\n```bash\nmkdir storage-contract\ncd storage-contract\nnpm init -y\n```\n\nInstall Hardhat and its dependencies:\n\n```bash\nnpm install --save-dev hardhat@3.0.9\n```\n\nInitialize a new Hardhat project:\n\n```bash\nnpx hardhat --init\n```\n\nSelect **Create a TypeScript project** and accept the default options."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 4, "depth": 3, "title": "Create the Storage Contract", "anchor": "create-the-storage-contract", "start_char": 3094, "end_char": 3633, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Create the Storage Contract\n\nIn the `contracts` directory, create a new file called `Storage.sol` and add the following code:\n\n```solidity title=\"Storage.sol\"\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\ncontract Storage {\n    uint256 private storedNumber;\n\n    event NumberStored(uint256 newNumber);\n\n    function setNumber(uint256 _number) public {\n        storedNumber = _number;\n        emit NumberStored(_number);\n    }\n}\n```\n\nThis simple contract stores a single number and provides functions to read and update it."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 5, "depth": 3, "title": "Configure Hardhat for Polkadot Hub", "anchor": "configure-hardhat-for-polkadot-hub", "start_char": 3633, "end_char": 5430, "estimated_token_count": 415, "token_estimator": "heuristic-v1", "text": "### Configure Hardhat for Polkadot Hub\n\nUpdate your `hardhat.config.ts` file to include the Polkadot Hub TestNet configuration:\n\n```typescript title=\"hardhat.config.ts\" hl_lines=\"39-44\"\nimport type { HardhatUserConfig } from \"hardhat/config\";\n\nimport hardhatToolboxViemPlugin from \"@nomicfoundation/hardhat-toolbox-viem\";\nimport { configVariable } from \"hardhat/config\";\n\nconst config: HardhatUserConfig = {\n  plugins: [hardhatToolboxViemPlugin],\n  solidity: {\n    profiles: {\n      default: {\n        version: \"0.8.28\",\n      },\n      production: {\n        version: \"0.8.28\",\n        settings: {\n          optimizer: {\n            enabled: true,\n            runs: 200,\n          },\n        },\n      },\n    },\n  },\n  networks: {\n    hardhatMainnet: {\n      type: \"edr-simulated\",\n      chainType: \"l1\",\n    },\n    hardhatOp: {\n      type: \"edr-simulated\",\n      chainType: \"op\",\n    },\n    sepolia: {\n      type: \"http\",\n      chainType: \"l1\",\n      url: configVariable(\"SEPOLIA_RPC_URL\"),\n      accounts: [configVariable(\"SEPOLIA_PRIVATE_KEY\")],\n    },\n    polkadotTestNet: {\n      type: \"http\",\n      chainType: \"l1\",\n      url: 'http://127.0.0.1:8545',\n      accounts: [process.env.PRIVATE_KEY || ''],\n    },\n  },\n};\n\nexport default config;\n```\n\nCreate a `.env` file in the root of your Hardhat project:\n\n```text title=\".env\"\nPRIVATE_KEY=INSERT_PRIVATE_KEY_HERE\n```\n\nReplace `INSERT_PRIVATE_KEY_HERE` with your actual private key. You can get this by exporting the private key from your wallet (e.g., MetaMask).\n\n!!! warning\n    Never commit your private key to version control. Use environment variables or a `.env` file (and add it to `.gitignore`) to manage sensitive information. Keep your private key safe, and never share it with anyone. If it is compromised, your funds can be stolen."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 6, "depth": 3, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 5430, "end_char": 5579, "estimated_token_count": 29, "token_estimator": "heuristic-v1", "text": "### Compile the Contract\n\nCompile your Storage contract:\n\n```bash\nnpx hardhat compile\n```\n\nYou should see output indicating successful compilation."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 7, "depth": 3, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 5579, "end_char": 7216, "estimated_token_count": 416, "token_estimator": "heuristic-v1", "text": "### Deploy the Contract\n\nCreate a deployment script in the `ignition/modules` directory called `Storage.ts`:\n\n```typescript title=\"Storage.ts\"\nimport { buildModule } from \"@nomicfoundation/hardhat-ignition/modules\";\n\nexport default buildModule(\"StorageModule\", (m) => {\n  const storage = m.contract(\"Storage\");\n\n  return { storage };\n});\n```\n\nDeploy the contract to Polkadot Hub TestNet:\n\n```bash\nnpx hardhat ignition deploy ./ignition/modules/Storage.ts --network polkadotTestNet\n```\n\nYou should see output similar to:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat ignition deploy ./ignition/modules/Storage.ts --network polkadotTestNet</span>\n  <span data-ty>WARNING: You are using Node.js 23.11.0 which is not supported by Hardhat.</span>\n  <span data-ty>Please upgrade to 22.10.0 or a later LTS version (even major version number)</span>\n  <span data-ty>âœ” Confirm deploy to network polkadotTestNet (420420420)? â€¦ yes</span>\n  <span data-ty>Hardhat Ignition ðŸš€</span>\n  <span data-ty>Deploying [ StorageModule ]</span>\n  <span data-ty>Batch #1</span>\n  <span data-ty>  Executed StorageModule#Storage</span>\n  <span data-ty>[ StorageModule ] successfully deployed ðŸš€</span>\n  <span data-ty>Deployed Addresses</span>\n  <span data-ty>StorageModule#Storage - 0xc01Ee7f10EA4aF4673cFff62710E1D7792aBa8f3</span>\n</div>\n\n!!! note\n    Save the deployed contract address - you'll need it when building your dApp. In the following sections, we'll reference a pre-deployed contract at `0xc01Ee7f10EA4aF4673cFff62710E1D7792aBa8f3`, but you can use your own deployed contract address instead."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 8, "depth": 3, "title": "Export the Contract ABI", "anchor": "export-the-contract-abi", "start_char": 7216, "end_char": 7603, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "### Export the Contract ABI\n\nAfter deployment, you'll need the contract's Application Binary Interface (ABI) for your dApp. You can find it in the `artifacts/contracts/Storage.sol/Storage.json` file generated by Hardhat. You'll use this in the next section when setting up your dApp.\n\nNow that you have your contract deployed, you're ready to build the dApp that will interact with it!"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 9, "depth": 2, "title": "Set Up the DApp Project", "anchor": "set-up-the-dapp-project", "start_char": 7603, "end_char": 7800, "estimated_token_count": 59, "token_estimator": "heuristic-v1", "text": "## Set Up the DApp Project\n\nNavigate to the root of the project, and create a new Next.js project called `dapp`:\n\n```bash\nnpx create-next-app dapp --ts --eslint --tailwind --app --yes\ncd dapp\n```"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 10, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 7800, "end_char": 7959, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nInstall viem and related packages:\n\n```bash\nnpm install viem@2.38.5\nnpm install --save-dev typescript@5.9.3 @types/node@22.19.24\n```"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 11, "depth": 2, "title": "Connect to Polkadot Hub", "anchor": "connect-to-polkadot-hub", "start_char": 7959, "end_char": 10056, "estimated_token_count": 509, "token_estimator": "heuristic-v1", "text": "## Connect to Polkadot Hub\n\nTo interact with Polkadot Hub, you need to set up a [Public Client](https://viem.sh/docs/clients/public#public-client){target=\\_blank} that connects to the blockchain. In this example, you will interact with the Polkadot Hub TestNet, to experiment safely. Start by creating a new file called `utils/viem.ts` and add the following code:\n\n```typescript title=\"viem.ts\"\nimport { createPublicClient, http, createWalletClient, custom } from 'viem'\nimport 'viem/window';\n\nconst transport = http('http://127.0.0.1:8545') // TODO: change to the paseo asset hub RPC URL when it's available\n\n// Configure the Polkadot Testnet Hub chain\nexport const polkadotTestnet = {\n  id: 420420420,\n  name: 'Polkadot Testnet',\n  network: 'polkadot-testnet',\n  nativeCurrency: {\n    decimals: 18,\n    name: 'PAS',\n    symbol: 'PAS',\n  },\n  rpcUrls: {\n    default: {\n      http: ['http://127.0.0.1:8545'], // TODO: change to the paseo asset hub RPC URL\n    },\n  },\n} as const\n\n// Create a public client for reading data\nexport const publicClient = createPublicClient({\n  chain: polkadotTestnet,\n  transport\n})\n\n// Create a wallet client for signing transactions\nexport const getWalletClient = async () => {\n  if (typeof window !== 'undefined' && window.ethereum) {\n    const [account] = await window.ethereum.request({ method: 'eth_requestAccounts' });\n    return createWalletClient({\n      chain: polkadotTestnet,\n      transport: custom(window.ethereum),\n      account,\n    });\n  }\n  throw new Error('No Ethereum browser provider detected');\n};\n```\n\nThis file initializes a viem client, providing helper functions for obtaining a Public Client and a [Wallet Client](https://viem.sh/docs/clients/wallet#wallet-client){target=\\_blank}. The Public Client enables reading blockchain data, while the Wallet Client allows users to sign and send transactions. Also, note that by importing `viem/window` the global `window.ethereum` will be typed as an `EIP1193Provider`, check the [`window` Polyfill](https://viem.sh/docs/typescript#window-polyfill){target=\\_blank} reference for more information."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 12, "depth": 2, "title": "Set Up the Smart Contract Interface", "anchor": "set-up-the-smart-contract-interface", "start_char": 10056, "end_char": 11967, "estimated_token_count": 422, "token_estimator": "heuristic-v1", "text": "## Set Up the Smart Contract Interface\n\nFor this dApp, you'll use a simple [Storage contract](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-hardhat/#create-the-contract){target=\\_blank} that's already deployed in the Polkadot Hub TestNet: `0xc01Ee7f10EA4aF4673cFff62710E1D7792aBa8f3`. To interact with it, you need to define the contract interface.\n\nCreate a folder called `abis` at the root of your project, then create a file named `Storage.json` and paste the corresponding ABI of the Storage contract. You can copy and paste the following:\n\n```bash\ncp ./storage-contract/artifacts/contracts/Storage.sol/Storage.json ./dapp/abis/Storage.json\n```\n\nNext, create a file called `utils/contract.ts`:\n\n```typescript title=\"contract.ts\"\nimport { getContract } from 'viem';\nimport { publicClient, getWalletClient } from './viem';\nimport StorageABI from '../abis/Storage.json';\n\nexport const CONTRACT_ADDRESS = '0xc01Ee7f10EA4aF4673cFff62710E1D7792aBa8f3'; // TODO: change when the paseo asset hub RPC URL is available, and the contract is redeployed\nexport const CONTRACT_ABI = StorageABI.abi;\n\n// Create a function to get a contract instance for reading\nexport const getContractInstance = () => {\n  return getContract({\n    address: CONTRACT_ADDRESS,\n    abi: CONTRACT_ABI,\n    client: publicClient,\n  });\n};\n\n// Create a function to get a contract instance with a signer for writing\nexport const getSignedContract = async () => {\n  const walletClient = await getWalletClient();\n  return getContract({\n    address: CONTRACT_ADDRESS,\n    abi: CONTRACT_ABI,\n    client: walletClient,\n  });\n};\n```\n\nThis file defines the contract address, ABI, and functions to create a viem [contract instance](https://viem.sh/docs/contract/getContract#contract-instances){target=\\_blank} for reading and writing operations. viem's contract utilities enable more efficient, type-safe interaction with smart contracts."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 13, "depth": 2, "title": "Create the Wallet Connection Component", "anchor": "create-the-wallet-connection-component", "start_char": 11967, "end_char": 17994, "estimated_token_count": 1342, "token_estimator": "heuristic-v1", "text": "## Create the Wallet Connection Component\n\nNow, you can create a component to handle wallet connections. Create a new file called `components/WalletConnect.tsx`:\n\n```typescript title=\"WalletConnect.tsx\"\n\"use client\";\n\nimport React, { useState, useEffect } from \"react\";\nimport { polkadotTestnet } from \"../utils/viem\";\n\ninterface WalletConnectProps {\n  onConnect: (account: string) => void;\n}\n\nconst WalletConnect: React.FC<WalletConnectProps> = ({ onConnect }) => {\n  const [account, setAccount] = useState<string | null>(null);\n  const [chainId, setChainId] = useState<number | null>(null);\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Check if user already has an authorized wallet connection\n    const checkConnection = async () => {\n      if (typeof window !== 'undefined' && window.ethereum) {\n        try {\n          // eth_accounts doesn't trigger the wallet popup\n          const accounts = await window.ethereum.request({\n            method: 'eth_accounts',\n          }) as string[];\n          \n          if (accounts.length > 0) {\n            setAccount(accounts[0]);\n            const chainIdHex = await window.ethereum.request({\n              method: 'eth_chainId',\n            }) as string;\n            setChainId(parseInt(chainIdHex, 16));\n            onConnect(accounts[0]);\n          }\n        } catch (err) {\n          console.error('Error checking connection:', err);\n          setError('Failed to check wallet connection');\n        }\n      }\n    };\n\n    checkConnection();\n\n    if (typeof window !== 'undefined' && window.ethereum) {\n      // Setup wallet event listeners\n      window.ethereum.on('accountsChanged', (accounts: string[]) => {\n        setAccount(accounts[0] || null);\n        if (accounts[0]) onConnect(accounts[0]);\n      });\n\n      window.ethereum.on('chainChanged', (chainIdHex: string) => {\n        setChainId(parseInt(chainIdHex, 16));\n      });\n    }\n\n    return () => {\n      // Cleanup event listeners\n      if (typeof window !== 'undefined' && window.ethereum) {\n        window.ethereum.removeListener('accountsChanged', () => {});\n        window.ethereum.removeListener('chainChanged', () => {});\n      }\n    };\n  }, [onConnect]);\n\n  const connectWallet = async () => {\n    if (typeof window === 'undefined' || !window.ethereum) {\n      setError(\n        'MetaMask not detected! Please install MetaMask to use this dApp.'\n      );\n      return;\n    }\n\n    try {\n      // eth_requestAccounts triggers the wallet popup\n      const accounts = await window.ethereum.request({\n        method: 'eth_requestAccounts',\n      }) as string[];\n      \n      setAccount(accounts[0]);\n\n      const chainIdHex = await window.ethereum.request({\n        method: 'eth_chainId',\n      }) as string;\n      \n      const currentChainId = parseInt(chainIdHex, 16);\n      setChainId(currentChainId);\n\n      // Prompt user to switch networks if needed\n      if (currentChainId !== polkadotTestnet.id) {\n        await switchNetwork();\n      }\n\n      onConnect(accounts[0]);\n    } catch (err) {\n      console.error('Error connecting to wallet:', err);\n      setError('Failed to connect wallet');\n    }\n  };\n\n  const switchNetwork = async () => {\n    console.log('Switch network')\n    try {\n      await window.ethereum.request({\n        method: 'wallet_switchEthereumChain',\n        params: [{ chainId: `0x${polkadotTestnet.id.toString(16)}` }],\n      });\n    } catch (switchError: any) {\n      // Error 4902 means the chain hasn't been added to MetaMask\n      if (switchError.code === 4902) {\n        try {\n          await window.ethereum.request({\n            method: 'wallet_addEthereumChain',\n            params: [\n              {\n                chainId: `0x${polkadotTestnet.id.toString(16)}`,\n                chainName: polkadotTestnet.name,\n                rpcUrls: [polkadotTestnet.rpcUrls.default.http[0]],\n                nativeCurrency: {\n                  name: polkadotTestnet.nativeCurrency.name,\n                  symbol: polkadotTestnet.nativeCurrency.symbol,\n                  decimals: polkadotTestnet.nativeCurrency.decimals,\n                },\n              },\n            ],\n          });\n        } catch (addError) {\n          setError('Failed to add network to wallet');\n        }\n      } else {\n        setError('Failed to switch network');\n      }\n    }\n  };\n\n  // UI-only disconnection - MetaMask doesn't support programmatic disconnection\n  const disconnectWallet = () => {\n    setAccount(null);\n  };\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto\">\n      {error && <p className=\"text-red-500 text-sm mb-2\">{error}</p>}\n\n      {!account ? (\n        <button\n          onClick={connectWallet}\n          className=\"w-full bg-pink-500 hover:bg-pink-600 text-white font-bold py-2 px-4 rounded-lg transition\"\n        >\n          Connect Wallet\n        </button>\n      ) : (\n        <div className=\"flex flex-col items-center\">\n          <span className=\"text-sm font-mono bg-pink-100 px-2 py-1 rounded-md text-pink-700\">\n            {`${account.substring(0, 6)}...${account.substring(38)}`}\n          </span>\n          <button\n            onClick={disconnectWallet}\n            className=\"mt-3 w-full bg-gray-200 hover:bg-gray-300 text-pink-500 py-2 px-4 rounded-lg transition\"\n          >\n            Disconnect\n          </button>\n          {chainId !== polkadotTestnet.id && (\n            <button\n              onClick={switchNetwork}\n              className=\"mt-3 w-full bg-yellow-500 hover:bg-yellow-600 text-white font-bold py-2 px-4 rounded-lg transition\"\n            >\n              Switch to Polkadot Testnet\n            </button>\n          )}\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default WalletConnect;\n```\n\nThis component handles connecting to the wallet, switching networks if necessary, and keeping track of the connected account. It provides a button for users to connect their wallet and displays the connected account address once connected."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 14, "depth": 2, "title": "Create the Read Contract Component", "anchor": "create-the-read-contract-component", "start_char": 17994, "end_char": 20523, "estimated_token_count": 614, "token_estimator": "heuristic-v1", "text": "## Create the Read Contract Component\n\nNext, create a component to read data from the contract. Create a file called `components/ReadContract.tsx`:\n\n```typescript title=\"ReadContract.tsx\"\n'use client';\n\nimport React, { useState, useEffect } from 'react';\nimport { publicClient } from '../utils/viem';\nimport { CONTRACT_ADDRESS, CONTRACT_ABI } from '../utils/contract';\n\nconst ReadContract: React.FC = () => {\n  const [storedNumber, setStoredNumber] = useState<string | null>(null);\n  const [loading, setLoading] = useState<boolean>(true);\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Function to read data from the blockchain\n    const fetchData = async () => {\n      try {\n        setLoading(true);\n        // Call the smart contract's storedNumber function\n        const number = await publicClient.readContract({\n            address: CONTRACT_ADDRESS,\n            abi: CONTRACT_ABI,\n            functionName: 'storedNumber',\n            args: [],\n          }) as bigint;\n\n        setStoredNumber(number.toString());\n        setError(null);\n      } catch (err) {\n        console.error('Error fetching stored number:', err);\n        setError('Failed to fetch data from the contract');\n      } finally {\n        setLoading(false);\n      }\n    };\n\n    fetchData();\n\n    // Poll for updates every 10 seconds to keep UI in sync with blockchain\n    const interval = setInterval(fetchData, 10000);\n\n    // Clean up interval on component unmount\n    return () => clearInterval(interval);\n  }, []);\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto\">\n      <h2 className=\"text-lg font-bold text-center mb-4\">Contract Data</h2>\n      {loading ? (\n        <div className=\"flex justify-center my-4\">\n          <div className=\"w-6 h-6 border-4 border-pink-500 border-t-transparent rounded-full animate-spin\"></div>\n        </div>\n      ) : error ? (\n        <p className=\"text-red-500 text-center\">{error}</p>\n      ) : (\n        <div className=\"text-center\">\n          <p className=\"text-sm font-mono bg-pink-100 px-2 py-1 rounded-md text-pink-700\">\n            <strong>Stored Number:</strong> {storedNumber}\n          </p>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default ReadContract;\n```\n\nThis component reads the `storedNumber` value from the contract and displays it to the user. It also sets up a polling interval to refresh the data periodically, ensuring that the UI stays in sync with the blockchain state."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 15, "depth": 2, "title": "Create the Write Contract Component", "anchor": "create-the-write-contract-component", "start_char": 20523, "end_char": 28626, "estimated_token_count": 1822, "token_estimator": "heuristic-v1", "text": "## Create the Write Contract Component\n\nFinally, create a component that allows users to update the stored number. Create a file called `components/WriteContract.tsx`:\n\n```typescript title=\"WriteContract.tsx\"\n\"use client\";\n\nimport React, { useState, useEffect } from \"react\";\nimport { publicClient, getWalletClient } from '../utils/viem';\nimport { CONTRACT_ADDRESS, CONTRACT_ABI } from '../utils/contract';\n\ninterface WriteContractProps {\n  account: string | null;\n}\n\nconst WriteContract: React.FC<WriteContractProps> = ({ account }) => {\n  const [newNumber, setNewNumber] = useState<string>(\"\");\n  const [status, setStatus] = useState<{\n    type: string | null;\n    message: string;\n  }>({\n    type: null,\n    message: \"\",\n  });\n  const [isSubmitting, setIsSubmitting] = useState<boolean>(false);\n  const [isCorrectNetwork, setIsCorrectNetwork] = useState<boolean>(true);\n\n  // Check if the account is on the correct network\n  useEffect(() => {\n    const checkNetwork = async () => {\n      if (!account) return;\n\n      try {\n        // Get the chainId from the public client\n        const chainId = await publicClient.getChainId();\n\n        // Get the user's current chainId from their wallet\n        const walletClient = await getWalletClient();\n        if (!walletClient) return;\n\n        const walletChainId = await walletClient.getChainId();\n\n        // Check if they match\n        setIsCorrectNetwork(chainId === walletChainId);\n      } catch (err) {\n        console.error(\"Error checking network:\", err);\n        setIsCorrectNetwork(false);\n      }\n    };\n\n    checkNetwork();\n  }, [account]);\n\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n\n    // Validation checks\n    if (!account) {\n      setStatus({ type: \"error\", message: \"Please connect your wallet first\" });\n      return;\n    }\n\n    if (!isCorrectNetwork) {\n      setStatus({\n        type: \"error\",\n        message: \"Please switch to the correct network in your wallet\",\n      });\n      return;\n    }\n\n    if (!newNumber || isNaN(Number(newNumber))) {\n      setStatus({ type: \"error\", message: \"Please enter a valid number\" });\n      return;\n    }\n\n    try {\n      setIsSubmitting(true);\n      setStatus({ type: \"info\", message: \"Initiating transaction...\" });\n\n      // Get wallet client for transaction signing\n      const walletClient = await getWalletClient();\n\n      if (!walletClient) {\n        setStatus({ type: \"error\", message: \"Wallet client not available\" });\n        return;\n      }\n\n      // Check if account matches\n      if (\n        walletClient.account?.address.toLowerCase() !== account.toLowerCase()\n      ) {\n        setStatus({\n          type: \"error\",\n          message:\n            \"Connected wallet account doesn't match the selected account\",\n        });\n        return;\n      }\n\n      // Prepare transaction and wait for user confirmation in wallet\n      setStatus({\n        type: \"info\",\n        message: \"Please confirm the transaction in your wallet...\",\n      });\n\n      // Simulate the contract call first\n      console.log('newNumber', newNumber);\n      const { request } = await publicClient.simulateContract({\n        address: CONTRACT_ADDRESS,\n        abi: CONTRACT_ABI,\n        functionName: \"setNumber\",\n        args: [BigInt(newNumber)],\n        account: walletClient.account,\n      });\n\n      // Send the transaction with wallet client\n      const hash = await walletClient.writeContract(request);\n\n      // Wait for transaction to be mined\n      setStatus({\n        type: \"info\",\n        message: \"Transaction submitted. Waiting for confirmation...\",\n      });\n\n      const receipt = await publicClient.waitForTransactionReceipt({\n        hash,\n      });\n\n      setStatus({\n        type: \"success\",\n        message: `Transaction confirmed! Transaction hash: ${receipt.transactionHash}`,\n      });\n\n      setNewNumber(\"\");\n    } catch (err: any) {\n      console.error(\"Error updating number:\", err);\n\n      // Handle specific errors\n      if (err.code === 4001) {\n        // User rejected transaction\n        setStatus({ type: \"error\", message: \"Transaction rejected by user.\" });\n      } else if (err.message?.includes(\"Account not found\")) {\n        // Account not found on the network\n        setStatus({\n          type: \"error\",\n          message:\n            \"Account not found on current network. Please check your wallet is connected to the correct network.\",\n        });\n      } else if (err.message?.includes(\"JSON is not a valid request object\")) {\n        // JSON error - specific to your current issue\n        setStatus({\n          type: \"error\",\n          message:\n            \"Invalid request format. Please try again or contact support.\",\n        });\n      } else {\n        // Other errors\n        setStatus({\n          type: \"error\",\n          message: `Error: ${err.message || \"Failed to send transaction\"}`,\n        });\n      }\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n  return (\n    <div className=\"border border-pink-500 rounded-lg p-4 shadow-md bg-white text-pink-500 max-w-sm mx-auto space-y-4\">\n      <h2 className=\"text-lg font-bold\">Update Stored Number</h2>\n\n      {!isCorrectNetwork && account && (\n        <div className=\"p-2 rounded-md bg-yellow-100 text-yellow-700 text-sm\">\n          âš ï¸ You are not connected to the correct network. Please switch\n          networks in your wallet.\n        </div>\n      )}\n\n      {status.message && (\n        <div\n          className={`p-2 rounded-md break-words h-fit text-sm ${\n            status.type === \"error\"\n              ? \"bg-red-100 text-red-500\"\n              : status.type === \"success\"\n              ? \"bg-green-100 text-green-700\"\n              : \"bg-blue-100 text-blue-700\"\n          }`}\n        >\n          {status.message}\n        </div>\n      )}\n\n      <form onSubmit={handleSubmit} className=\"space-y-4\">\n        <input\n          type=\"number\"\n          placeholder=\"New Number\"\n          value={newNumber}\n          onChange={(e) => setNewNumber(e.target.value)}\n          disabled={isSubmitting || !account}\n          className=\"w-full p-2 border rounded-md focus:outline-none focus:ring-2 focus:ring-pink-400\"\n        />\n        <button\n          type=\"submit\"\n          disabled={\n            isSubmitting || !account || (!isCorrectNetwork && !!account)\n          }\n          className=\"w-full bg-pink-500 hover:bg-pink-600 text-white font-bold py-2 px-4 rounded-lg transition disabled:bg-gray-300\"\n        >\n          {isSubmitting ? \"Updating...\" : \"Update\"}\n        </button>\n      </form>\n\n      {!account && (\n        <p className=\"text-sm text-gray-500\">\n          Connect your wallet to update the stored number.\n        </p>\n      )}\n    </div>\n  );\n};\n\nexport default WriteContract;\n```\n\nThis component allows users to input a new number and send a transaction to update the value stored in the contract. It provides appropriate feedback during each step of the transaction process and handles error scenarios.\n\nUpdate the `app/page.tsx` file to integrate all components:\n\n```typescript title=\"page.tsx\"\n\"use client\";\n\nimport { useState } from \"react\";\nimport WalletConnect from \"./components/WalletConnect\";\nimport ReadContract from \"./components/ReadContract\";\nimport WriteContract from \"./components/WriteContract\";\n\nexport default function Home() {\n  const [account, setAccount] = useState<string | null>(null);\n\n  const handleConnect = (connectedAccount: string) => {\n    setAccount(connectedAccount);\n  };\n\n  return (\n    <section className=\"min-h-screen bg-white text-black flex flex-col justify-center items-center gap-4 py-10\">\n      <h1 className=\"text-2xl font-semibold text-center\">\n        Polkadot Hub - Zero To Hero DApp\n      </h1>\n      <WalletConnect onConnect={handleConnect} />\n      <ReadContract />\n      <WriteContract account={account} />\n    </section>\n  );\n}\n```\n\nRun the dApp:\n\n```bash\nnpm run dev\n```\n\nNavigate to `http://localhost:3000` in your browser, and you should see your dApp with the wallet connection button, the stored number displayed, and the form to update the number. You should see something like this:"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 16, "depth": 2, "title": "How It Works", "anchor": "how-it-works", "start_char": 28626, "end_char": 28719, "estimated_token_count": 18, "token_estimator": "heuristic-v1", "text": "## How It Works\n\nThis dApp uses components to interact with the blockchain in several ways."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 17, "depth": 3, "title": "Wallet Connection", "anchor": "wallet-connection", "start_char": 28719, "end_char": 29025, "estimated_token_count": 60, "token_estimator": "heuristic-v1", "text": "### Wallet Connection \n\nThe `WalletConnect` component uses the browser's Ethereum provider (MetaMask) to connect to the user's wallet and handles network switching to ensure the user is connected to the Polkadot Hub TestNet. Once connected, it provides the user's account address to the parent component."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 18, "depth": 3, "title": "Data Reads", "anchor": "data-reads", "start_char": 29025, "end_char": 29326, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "### Data Reads\n\nThe `ReadContract` component uses viem's `readContract` function to call the `storedNumber` view function and periodically poll for updates to keep the UI in sync with the blockchain state. The component also displays a loading indicator while fetching data and handles error states."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 19, "depth": 3, "title": "Data Writes", "anchor": "data-writes", "start_char": 29326, "end_char": 29728, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "### Data Writes\n\nThe `WriteContract` component uses viem's `writeContract` function to send a transaction to the `setNumber` function and ensures the wallet is connected before allowing a transaction. The component shows detailed feedback during transaction submission and confirmation. After a successful transaction, the value displayed in the `ReadContract` component will update on the next poll."}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 20, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 29728, "end_char": 30625, "estimated_token_count": 178, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nCongratulations! You've successfully built a fully functional dApp that interacts with a smart contract on Polkadot Hub using viem and Next.js. Your application can now:\n\n- Create a smart contract with Hardhat and deploy it to Polkadot Hub TestNet.\n- Connect to a user's wallet and handle network switching.\n- Read data from a smart contract and keep it updated.\n- Write data to the blockchain through transactions.\n\nThese fundamental skills provide the foundation for building more complex dApps on Polkadot Hub. With this knowledge, you can extend your application to interact with more sophisticated smart contracts and create advanced user interfaces.\n\nTo get started right away with a working example, you can clone the repository and navigate to the implementation:\n\n```bash\ngit clone https://github.com/polkadot-developers/revm-hardhat-examples.git\ncd zero-to-hero-dapp\n```"}
{"page_id": "smart-contracts-cookbook-dapps-zero-to-hero", "page_title": "Zero to Hero Smart Contract DApp", "index": 21, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 30625, "end_char": 31211, "estimated_token_count": 147, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Port Ethereum Projects to Polkadot Hub__\n\n    ---\n\n    Learn how to port an Ethereum project to Polkadot Hub using Hardhat and Viem.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/eth-dapps/uniswap-v2/)\n\n-   <span class=\"badge guide\">Guide</span> __Dive Deeper into Polkadot Precompiles__\n\n    ---\n\n    Learn how to use the Polkadot precompiles to interact with the blockchain.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/precompiles/)\n</div>"}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 21, "end_char": 687, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nDecentralized exchanges (DEXs) are a cornerstone of the DeFi ecosystem, allowing for permissionless token swaps without intermediaries. [Uniswap V2](https://docs.uniswap.org/contracts/v2/overview){target=\\_blank}, with its Automated Market Maker (AMM) model, revolutionized DEXs by enabling liquidity provision for any ERC-20 token pair.\n\nThis tutorial will guide you through how Uniswap V2 works so you can take advantage of it in your projects deployed to Polkadot Hub. By understanding these contracts, you'll gain hands-on experience with one of the most influential DeFi protocols and understand how it functions across blockchain ecosystems."}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 687, "end_char": 1160, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore starting, make sure you have:\n\n- Node.js (v16.0.0 or later) and npm installed.\n- Basic understanding of Solidity and JavaScript.\n- Familiarity with [Hardhat](/smart-contracts/dev-environments/hardhat/){target=\\_blank} development environment.\n- Some test tokens to cover transaction fees (obtained from the [Polkadot faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}).\n- Basic understanding of how AMMs and liquidity pools work."}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 2, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1160, "end_char": 2905, "estimated_token_count": 417, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nStart by cloning the Uniswap V2 project:\n\n1. Clone the Uniswap V2 repository:\n\n    ```\n    git clone https://github.com/polkadot-developers/polkavm-hardhat-examples.git\n    git checkout hardhat-polkadot-evm\n    cd polkavm-hardhat-examples/uniswap-v2-polkadot/\n    ```\n\n2. Install the required dependencies:\n\n    ```bash\n    npm install\n    ```\n\n3. Create a `.env` file in your project root to store your private keys (you can use as an example the `env.example` file):\n\n    ```text title=\".env\"\n    LOCAL_PRIV_KEY=\"INSERT_LOCAL_PRIVATE_KEY\"\n    AH_PRIV_KEY=\"INSERT_AH_PRIVATE_KEY\"\n    ```\n\n    Ensure to replace `\"INSERT_LOCAL_PRIVATE_KEY\"` with a private key available in the local environment (you can get them from this [file](https://github.com/paritytech/hardhat-polkadot/blob/main/packages/hardhat-polkadot-node/src/constants.ts#L21){target=\\_blank}). And `\"INSERT_AH_PRIVATE_KEY\"` with the account's private key you want to use to deploy the contracts. You can get this by exporting the private key from your wallet (e.g., MetaMask).\n\n    !!!warning\n        Keep your private key safe, and never share it with anyone. If it is compromised, your funds can be stolen.\n\n5. Compile the contracts:\n\n    ```bash\n    npx hardhat compile\n    ```\n\nIf the compilation is successful, you should see the following output:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat compile</span>\n  <span data-ty>Compiling 12 Solidity files</span>\n  <span data-ty>Successfully compiled 12 Solidity files</span>\n</div>\n\nAfter running the above command, you should see the compiled contracts in the `artifacts` directory. This directory contains the ABI and bytecode of your contracts."}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 3, "depth": 2, "title": "Understanding Uniswap V2 Architecture", "anchor": "understanding-uniswap-v2-architecture", "start_char": 2905, "end_char": 5257, "estimated_token_count": 527, "token_estimator": "heuristic-v1", "text": "## Understanding Uniswap V2 Architecture\n\nBefore interacting with the contracts, it's essential to understand the core architecture that powers Uniswap V2. This model forms the basis of nearly every modern DEX implementation and operates under automated market making, token pair liquidity pools, and deterministic pricing principles.\n\nAt the heart of Uniswap V2 lies a simple but powerful system composed of two major smart contracts:\n\n- **Factory contract**: The factory acts as a registry and creator of new trading pairs. When two ERC-20 tokens are to be traded, the Factory contract is responsible for generating a new Pair contract that will manage that specific token pairâ€™s liquidity pool. It keeps track of all deployed pairs and ensures uniquenessâ€”no duplicate pools can exist for the same token combination.\n- **Pair contract**: Each pair contract is a decentralized liquidity pool that holds reserves of two ERC-20 tokens. These contracts implement the core logic of the AMM, maintaining a constant product invariant (x \\* y = k) to facilitate swaps and price determination. Users can contribute tokens to these pools in return for LP (liquidity provider) tokens, which represent their proportional share of the reserves.\n\nThis minimal architecture enables Uniswap to be highly modular, trustless, and extensible. By distributing responsibilities across these components, developers, and users can engage with the protocol in a composable and predictable manner, making it an ideal foundation for DEX functionality across ecosystems, including Polkadot Hub.\n\nThe project scaffolding is as follows:\n\n```bash\nuniswap-V2-polkadot\nâ”œâ”€â”€ bin/\nâ”œâ”€â”€ contracts/\nâ”‚   â”œâ”€â”€ interfaces/\nâ”‚   â”‚   â”œâ”€â”€ IERC20.sol\nâ”‚   â”‚   â”œâ”€â”€ IUniswapV2Callee.sol\nâ”‚   â”‚   â”œâ”€â”€ IUniswapV2ERC20.sol\nâ”‚   â”‚   â”œâ”€â”€ IUniswapV2Factory.sol\nâ”‚   â”‚   â””â”€â”€ IUniswapV2Pair.sol\nâ”‚   â”œâ”€â”€ libraries/\nâ”‚   â”‚   â”œâ”€â”€ Math.sol\nâ”‚   â”‚   â”œâ”€â”€ SafeMath.sol\nâ”‚   â”‚   â””â”€â”€ UQ112x112.sol\nâ”‚   â”œâ”€â”€ test/\nâ”‚   â”‚   â””â”€â”€ ERC20.sol\nâ”‚   â”œâ”€â”€ UniswapV2ERC20.sol\nâ”‚   â”œâ”€â”€ UniswapV2Factory.sol\nâ”‚   â””â”€â”€ UniswapV2Pair.sol\nâ”œâ”€â”€ ignition/\nâ”œâ”€â”€ scripts/\nâ”‚   â””â”€â”€ deploy.js\nâ”œâ”€â”€ node_modules/\nâ”œâ”€â”€ test/\nâ”‚   â”œâ”€â”€ shared/\nâ”‚   â”‚   â”œâ”€â”€ fixtures.js\nâ”‚   â”‚   â””â”€â”€ utilities.js\nâ”‚   â”œâ”€â”€ UniswapV2ERC20.js\nâ”‚   â”œâ”€â”€ UniswapV2Factory.js\nâ”‚   â””â”€â”€ UniswapV2Pair.js\nâ”œâ”€â”€ .env.example\nâ”œâ”€â”€ .gitignore\nâ”œâ”€â”€ hardhat.config.js\nâ”œâ”€â”€ package.json\nâ””â”€â”€ README.md\n```"}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 4, "depth": 2, "title": "Test the Contracts", "anchor": "test-the-contracts", "start_char": 5257, "end_char": 7753, "estimated_token_count": 765, "token_estimator": "heuristic-v1", "text": "## Test the Contracts\n\nYou can run the provided test suite to ensure the contracts are working as expected. The tests cover various scenarios, including creating pairs, adding liquidity, and executing swaps.\n\nTo test it locally, you can run the following commands:\n\n1. Run the local `revive-dev-node`, for this, you can check the [Local Development Node](/smart-contracts/dev-environments/local-dev-node/){target=\\_blank} guide.\n\n2. In a new terminal, run the tests:\n\n    ```bash\n    npx hardhat test --network localNode\n    ```\n\nThe result should look like this:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat test --network localNode</span>\n  <span data-ty>Compiling 12 Solidity files</span>\n  <span data-ty>Successfully compiled 12 Solidity files</span>\n  <span data-ty></span>\n  <span data-ty>UniswapV2ERC20</span>\n  <span data-ty> âœ” name, symbol, decimals, totalSupply, balanceOf, DOMAIN_SEPARATOR, PERMIT_TYPEHASH (44ms)</span>\n  <span data-ty> âœ” approve (5128ms)</span>\n  <span data-ty> âœ” transfer (5133ms)</span>\n  <span data-ty> âœ” transfer:fail</span>\n  <span data-ty> âœ” transferFrom (6270ms)</span>\n  <span data-ty> âœ” transferFrom:max (6306ms)</span>\n  <span data-ty></span>\n  <span data-ty>UniswapV2Factory</span>\n  <span data-ty> âœ” feeTo, feeToSetter, allPairsLength</span>\n  <span data-ty> âœ” createPair (176ms)</span>\n  <span data-ty> âœ” createPair:reverse (1224ms)</span>\n  <span data-ty> âœ” setFeeTo (1138ms)</span>\n  <span data-ty> âœ” setFeeToSetter (1125ms)</span>\n  <span data-ty></span>\n  <span data-ty>UniswapV2Pair</span>\n  <span data-ty> âœ” mint (11425ms)</span>\n  <span data-ty> âœ” getInputPrice:0 (12590ms)</span>\n  <span data-ty> âœ” getInputPrice:1 (17600ms)</span>\n  <span data-ty> âœ” getInputPrice:2 (17618ms)</span>\n  <span data-ty> âœ” getInputPrice:3 (17704ms)</span>\n  <span data-ty> âœ” getInputPrice:4 (17649ms)</span>\n  <span data-ty> âœ” getInputPrice:5 (17594ms)</span>\n  <span data-ty> âœ” getInputPrice:6 (13643ms)</span>\n  <span data-ty> âœ” optimistic:0 (17647ms)</span>\n  <span data-ty> âœ” optimistic:1 (17946ms)</span>\n  <span data-ty> âœ” optimistic:2 (17657ms)</span>\n  <span data-ty> âœ” optimistic:3 (21625ms)</span>\n  <span data-ty> âœ” swap:token0 (12665ms)</span>\n  <span data-ty> âœ” swap:token1 (17631ms)</span>\n  <span data-ty> âœ” burn (17690ms)</span>\n  <span data-ty> âœ” feeTo:off (23900ms)</span>\n  <span data-ty> âœ” feeTo:on (24991ms)</span>\n  <span data-ty></span>\n  <span data-ty>28 passing (12m)</span>\n</div>"}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 5, "depth": 2, "title": "Deploy the Contracts", "anchor": "deploy-the-contracts", "start_char": 7753, "end_char": 9505, "estimated_token_count": 379, "token_estimator": "heuristic-v1", "text": "## Deploy the Contracts\n\nAfter successfully testing the contracts, you can deploy them to the local node or Polkadot Hub. The deployment script is located in the `scripts` directory and is named `deploy.js`. This script deploys the `Factory` and `Pair` contracts to the network.\n\nTo deploy the contracts, run the following command:\n\n```bash\nnpx hardhat run scripts/deploy.js --network localNode\n```\n\nThis command deploys the contracts to your local blockchain for development and testing. If you want to deploy to Polkadot Hub, you can use the following command:\n\n```bash\nnpx hardhat run scripts/deploy.js --network polkadotHubTestNet\n```\n\nThe command above deploys to the actual Polkadot Hub TestNet. It requires test tokens, persists on the network, and operates under real network conditions.\n\nThe deployment script will output the addresses of the deployed contracts. Save these addresses, as you will need them to interact with the contracts. For example, the output should look like this:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat run scripts/deploy.js --network localNode</span>\n  <span data-ty>Successfully compiled 12 Solidity files</span>\n  <span data-ty>Deploying contracts using 0xf24FF3a9CF04c71Dbc94D0b566f7A27B94566cac</span>\n  <span data-ty>Deploying UniswapV2ERC20...</span>\n  <span data-ty>ETH deployed to : 0x7acc1aC65892CF3547b1b0590066FB93199b430D</span>\n  <span data-ty>Deploying UniswapV2Factory...</span>\n  <span data-ty>Factory deployed to : 0x85b108660f47caDfAB9e0503104C08C1c96e0DA9</span>\n  <span data-ty>Deploying UniswapV2Pair with JsonRpcProvider workaround...</span>\n  <span data-ty>Pair deployed to : 0xF0e46847c8bFD122C4b5EEE1D4494FF7C5FC5104</span>\n</div>"}
{"page_id": "smart-contracts-cookbook-eth-dapps-uniswap-v2", "page_title": "Deploying Uniswap V2 on Polkadot", "index": 6, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 9505, "end_char": 10410, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThis tutorial guided you through deploying Uniswap V2 contracts to Polkadot Hub. This implementation brings the powerful AMM architecture to the Polkadot ecosystem, laying the foundation for the decentralized trading of ERC-20 token pairs.\n\nBy following this guide, you've gained practical experience with:\n\n- Setting up a Hardhat project for deploying to Polkadot Hub.\n- Understanding the Uniswap V2 architecture.\n- Testing Uniswap V2 contracts in a local environment.\n- Deploying contracts to both local and testnet environments.\n\nTo build on this foundation, you could extend this project by implementing functionality to create liquidity pools, execute token swaps, and build a user interface for interacting with your deployment.\n\nThis knowledge can be leveraged to build more complex DeFi applications or to integrate Uniswap V2 functionality into your existing projects on Polkadot."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 27, "end_char": 1362, "estimated_token_count": 322, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nDeploying smart contracts to [Polkadot Hub](/smart-contracts/overview/#smart-contract-development){target=\\_blank} can be accomplished through various tools and environments, each suited to different development workflows. This guide demonstrates how to deploy a basic PolkaVM (PVM) smart contract using four popular approaches: JavaScript with [Ethers.js](https://docs.ethers.org/v6/){target=\\_blank}, [Remix IDE](https://remix.live/){target=\\_blank}, [Hardhat](https://hardhat.org/){target=\\_blank}, and [Foundry](https://getfoundry.sh/){target=\\_blank}.\n\nAll these tools leverage the `revive` compiler to transform Solidity smart contracts into PolkaVM bytecode, making them compatible with Polkadot Hub's native smart contract environment. Whether you prefer working with lightweight JavaScript libraries, visual browser-based IDEs, comprehensive development frameworks, or fast command-line toolkits, this guide covers the deployment process for each approach.\n\n**Prerequisites:**\n\n- Basic understanding of Solidity programming.\n- [Node.js](https://nodejs.org/en/download){target=\\_blank} v22.13.1 or later (for JavaScript/Hardhat approaches).\n- Test tokens for gas fees (available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}).\n- A wallet with a private key for signing transactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 1, "depth": 2, "title": "JavaScript with Ethers.js", "anchor": "javascript-with-ethersjs", "start_char": 1362, "end_char": 1645, "estimated_token_count": 45, "token_estimator": "heuristic-v1", "text": "## JavaScript with Ethers.js\n\nEthers.js provides a lightweight approach for deploying contracts using pure JavaScript. This method is ideal for developers who want programmatic control over the deployment process or need to integrate contract deployment into existing applications."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 2, "depth": 3, "title": "Setup", "anchor": "setup", "start_char": 1645, "end_char": 1818, "estimated_token_count": 39, "token_estimator": "heuristic-v1", "text": "### Setup\n\nFirst, initialize your project and install dependencies:\n\n```bash\nmkdir ethers-deployment\ncd ethers-deployment\nnpm init -y\nnpm install ethers @parity/resolc\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 3, "depth": 3, "title": "Create and Compile Your Contract", "anchor": "create-and-compile-your-contract", "start_char": 1818, "end_char": 3875, "estimated_token_count": 491, "token_estimator": "heuristic-v1", "text": "### Create and Compile Your Contract\n\nCreate a simple storage contract in `contracts/Storage.sol`:\n\n```solidity title=\"contracts/Storage.sol\"\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n\ncontract Storage {\n    uint256 private storedNumber;\n\n    function store(uint256 num) public {\n        storedNumber = num;\n    }\n\n    function retrieve() public view returns (uint256) {\n        return storedNumber;\n    }\n}\n```\n\nCreate a compilation script `compile.js`:\n\n```javascript title=\"compile.js\"\nconst { compile } = require('@parity/resolc');\nconst { readFileSync, writeFileSync } = require('fs');\nconst { basename, join } = require('path');\n\nconst compileContract = async (solidityFilePath, outputDir) => {\n  try {\n    // Read the Solidity file\n    const source = readFileSync(solidityFilePath, 'utf8');\n\n    // Construct the input object for the compiler\n    const input = {\n      [basename(solidityFilePath)]: { content: source },\n    };\n\n    console.log(`Compiling contract: ${basename(solidityFilePath)}...`);\n\n    // Compile the contract\n    const out = await compile(input);\n\n    for (const contracts of Object.values(out.contracts)) {\n      for (const [name, contract] of Object.entries(contracts)) {\n        console.log(`Compiled contract: ${name}`);\n\n        // Write the ABI\n        const abiPath = join(outputDir, `${name}.json`);\n        writeFileSync(abiPath, JSON.stringify(contract.abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n\n        // Write the bytecode\n        const bytecodePath = join(outputDir, `${name}.polkavm`);\n        writeFileSync(\n          bytecodePath,\n          Buffer.from(contract.evm.bytecode.object, 'hex'),\n        );\n        console.log(`Bytecode saved to ${bytecodePath}`);\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath = join(__dirname, 'contracts/Storage.sol');\nconst outputDir = join(__dirname, 'contracts');\n\ncompileContract(solidityFilePath, outputDir);\n```\n\nRun the compilation:\n\n```bash\nnode compile.js\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 4, "depth": 3, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 3875, "end_char": 7017, "estimated_token_count": 714, "token_estimator": "heuristic-v1", "text": "### Deploy the Contract\n\nCreate a deployment script `deploy.js`:\n\n```javascript title=\"deploy.js\"\nconst { writeFileSync, existsSync, readFileSync } = require('fs');\nconst { join } = require('path');\nconst { ethers, JsonRpcProvider } = require('ethers');\n\nconst codegenDir = join(__dirname);\n\n// Creates a provider with specified RPC URL and chain details\nconst createProvider = (rpcUrl, chainId, chainName) => {\n  const provider = new JsonRpcProvider(rpcUrl, {\n    chainId: chainId,\n    name: chainName,\n  });\n  return provider;\n};\n\n// Reads and parses the ABI file for a given contract\nconst getAbi = (contractName) => {\n  try {\n    return JSON.parse(\n      readFileSync(join(codegenDir, 'contracts', `${contractName}.json`), 'utf8'),\n    );\n  } catch (error) {\n    console.error(\n      `Could not find ABI for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n\n// Reads the compiled bytecode for a given contract\nconst getByteCode = (contractName) => {\n  try {\n    const bytecodePath = join(\n      codegenDir,\n      'contracts',\n      `${contractName}.polkavm`,\n    );\n    return `0x${readFileSync(bytecodePath).toString('hex')}`;\n  } catch (error) {\n    console.error(\n      `Could not find bytecode for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n\nconst deployContract = async (contractName, mnemonic, providerConfig) => {\n  console.log(`Deploying ${contractName}...`);\n\n  try {\n    // Step 1: Set up provider and wallet\n    const provider = createProvider(\n      providerConfig.rpc,\n      providerConfig.chainId,\n      providerConfig.name,\n    );\n    const walletMnemonic = ethers.Wallet.fromPhrase(mnemonic);\n    const wallet = walletMnemonic.connect(provider);\n\n    // Step 2: Create and deploy the contract\n    const factory = new ethers.ContractFactory(\n      getAbi(contractName),\n      getByteCode(contractName),\n      wallet,\n    );\n    const contract = await factory.deploy();\n    await contract.waitForDeployment();\n\n    // Step 3: Save deployment information\n    const address = await contract.getAddress();\n    console.log(`Contract ${contractName} deployed at: ${address}`);\n\n    const addressesFile = join(codegenDir, 'contract-address.json');\n    const addresses = existsSync(addressesFile)\n      ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n      : {};\n    addresses[contractName] = address;\n    writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n  } catch (error) {\n    console.error(`Failed to deploy contract ${contractName}:`, error);\n  }\n};\n\nconst providerConfig = {\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n  name: 'polkadot-hub-testnet',\n};\n\nconst mnemonic = 'INSERT_MNEMONIC';\n\ndeployContract('Storage', mnemonic, providerConfig);\n```\n\nReplace the `INSERT_MNEMONIC` placeholder with your actual mnemonic.\n\nExecute the deployment:\n\n```bash\nnode deploy.js\n```\n\nAfter running this script, your contract will be deployed to Polkadot Hub, and its address will be saved in `contract-address.json` within your project directory. You can use this address for future contract interactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 5, "depth": 2, "title": "Remix IDE", "anchor": "remix-ide", "start_char": 7017, "end_char": 7225, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Remix IDE\n\nRemix IDE offers a visual, browser-based environment perfect for rapid prototyping and learning. It requires no local installation and provides an intuitive interface for contract development."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 6, "depth": 3, "title": "Access Remix", "anchor": "access-remix", "start_char": 7225, "end_char": 7750, "estimated_token_count": 138, "token_estimator": "heuristic-v1", "text": "### Access Remix\n\nNavigate to [https://remix.polkadot.io/](https://remix.polkadot.io/){target=\\_blank} in your web browser.\n\nThe interface will load with a default workspace containing sample contracts. In this interface, you can access a file explorer, edit your code, interact with various plugins for development, and use a terminal. By default, you will see the `contracts` folder with the `Storage.sol` file:\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-basic/deploy-basic-pvm/deploy-basic-pvm-01.webp)"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 7, "depth": 3, "title": "Compile", "anchor": "compile", "start_char": 7750, "end_char": 8149, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "### Compile\n\n1. To compile your contract:\n    1. Navigate to the **Solidity Compiler** tab, which is the third icon in the left sidebar.\n    2. Click **Compile Storage.sol** or press `Ctrl+S`.\n\n    ![](/images/smart-contracts/cookbook/smart-contracts/deploy-basic/deploy-basic-pvm/deploy-basic-pvm-02.webp)\n\nCompilation errors and warnings appear in the terminal panel at the bottom of the screen."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 8, "depth": 3, "title": "Deploy", "anchor": "deploy", "start_char": 8149, "end_char": 8651, "estimated_token_count": 127, "token_estimator": "heuristic-v1", "text": "### Deploy\n\n1. Navigate to the **Deploy & Run Transactions** tab.\n2. Click the **Environment** dropdown and select **Injected Provider - MetaMask** (ensure your MetaMask wallet is connected to Polkadot Hub TestNet).\n3. Click **Deploy**.\n4. Approve the transaction in your MetaMask wallet.\n\n    ![](/images/smart-contracts/cookbook/smart-contracts/deploy-basic/deploy-basic-pvm/deploy-basic-pvm-03.webp)\n\nYour deployed contract will appear in the **Deployed Contracts** section, ready for interaction."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 9, "depth": 2, "title": "Hardhat", "anchor": "hardhat", "start_char": 8651, "end_char": 8853, "estimated_token_count": 33, "token_estimator": "heuristic-v1", "text": "## Hardhat\n\nHardhat provides a comprehensive development environment with built-in testing, debugging, and deployment capabilities. It's ideal for professional development workflows and team projects."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 10, "depth": 3, "title": "Setup", "anchor": "setup-2", "start_char": 8853, "end_char": 9195, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "### Setup\n\nInitialize your Hardhat project:\n\n```bash\nmkdir hardhat-deployment\ncd hardhat-deployment\nnpm init -y\nnpm install --save-dev @parity/hardhat-polkadot@0.1.9\nnpx hardhat-polkadot init\n```\n\nSelect **Create a JavaScript project** when prompted.\n\nComplete the setup:\n\n```bash\necho '/ignition/deployments/' >> .gitignore\nnpm install\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 11, "depth": 3, "title": "Configure Hardhat", "anchor": "configure-hardhat", "start_char": 9195, "end_char": 10240, "estimated_token_count": 245, "token_estimator": "heuristic-v1", "text": "### Configure Hardhat\n\nEdit `hardhat.config.js`:\n\n```javascript title=\"hardhat.config.js\" hl_lines=\"21-26\"\nrequire(\"@nomicfoundation/hardhat-toolbox\")\nrequire(\"@parity/hardhat-polkadot\")\n\n/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n    solidity: \"0.8.28\",\n    resolc: {\n        compilerSource: \"npm\",\n    },\n    networks: {\n        hardhat: {\n            polkavm: true,\n            forking: {\n                url: \"https://testnet-passet-hub.polkadot.io\",\n            },\n            adapterConfig: {\n                adapterBinaryPath: \"../bin/eth-rpc\",\n                dev: true,\n            },\n        },\n        polkadotHubTestnet: {\n            polkavm: true,\n            url: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n            chainId: 420420422,\n            accounts: [vars.get('PRIVATE_KEY')],\n        },\n    },\n}\n```\n\nRun the following command to set the private key:\n\n```bash\nnpx hardhat vars set PRIVATE_KEY \"INSERT_PRIVATE_KEY\"\n```\n\nReplace `INSERT_PRIVATE_KEY` with your actual private key."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 12, "depth": 3, "title": "Create Your Contract", "anchor": "create-your-contract", "start_char": 10240, "end_char": 10621, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "### Create Your Contract\n\nReplace the default contract in `contracts/Storage.sol`:\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n\ncontract Storage {\n    uint256 private storedNumber;\n\n    function store(uint256 num) public {\n        storedNumber = num;\n    }\n\n    function retrieve() public view returns (uint256) {\n        return storedNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 13, "depth": 3, "title": "Compile", "anchor": "compile-2", "start_char": 10621, "end_char": 10667, "estimated_token_count": 14, "token_estimator": "heuristic-v1", "text": "### Compile\n\n```bash\nnpx hardhat compile\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 14, "depth": 3, "title": "Set Up Deployment", "anchor": "set-up-deployment", "start_char": 10667, "end_char": 10976, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "### Set Up Deployment\n\nCreate a deployment module in `ignition/modules/Storage.js`:\n\n```javascript\nconst { buildModule } = require('@nomicfoundation/hardhat-ignition/modules');\n\nmodule.exports = buildModule('StorageModule', (m) => {\n    const storage = m.contract('Storage');\n    return { storage };\n});\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 15, "depth": 3, "title": "Deploy", "anchor": "deploy-2", "start_char": 10976, "end_char": 11121, "estimated_token_count": 34, "token_estimator": "heuristic-v1", "text": "### Deploy\n\nDeploy to Polkadot Hub TestNet:\n\n```bash\nnpx hardhat ignition deploy ./ignition/modules/Storage.js --network polkadotHubTestnet\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 16, "depth": 2, "title": "Foundry", "anchor": "foundry", "start_char": 11121, "end_char": 11307, "estimated_token_count": 35, "token_estimator": "heuristic-v1", "text": "## Foundry\n\nFoundry offers a fast, modular toolkit written in Rust. It's perfect for developers who prefer command-line interfaces and need high-performance compilation and deployment."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 17, "depth": 3, "title": "Setup", "anchor": "setup-3", "start_char": 11307, "end_char": 11585, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "### Setup\n\nInstall Foundry for Polkadot:\n\n```bash\ncurl -L https://raw.githubusercontent.com/paritytech/foundry-polkadot/refs/heads/master/foundryup/install | bash\nfoundryup-polkadot\n```\n\nInitialize your project:\n\n```bash\nforge init foundry-deployment\ncd foundry-deployment\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 18, "depth": 3, "title": "Configure Foundry", "anchor": "configure-foundry", "start_char": 11585, "end_char": 11837, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "### Configure Foundry\n\nEdit `foundry.toml`:\n\n```toml\n[profile.default]\nsrc = \"src\"\nout = \"out\"\nlibs = [\"lib\"]\n\n[profile.default.resolc]\nresolc_compile = true\n\n[rpc_endpoints]\npolkadot_hub_testnet = \"https://testnet-passet-hub-eth-rpc.polkadot.io\"\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 19, "depth": 3, "title": "Create Your Contract", "anchor": "create-your-contract-2", "start_char": 11837, "end_char": 12212, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "### Create Your Contract\n\nReplace the default contract in `src/Storage.sol`:\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n\ncontract Storage {\n    uint256 private storedNumber;\n\n    function store(uint256 num) public {\n        storedNumber = num;\n    }\n\n    function retrieve() public view returns (uint256) {\n        return storedNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 20, "depth": 3, "title": "Compile", "anchor": "compile-3", "start_char": 12212, "end_char": 12392, "estimated_token_count": 46, "token_estimator": "heuristic-v1", "text": "### Compile\n\n```bash\nforge build --resolc\n```\n\nVerify the compilation by inspecting the bytecode (should start with `0x505`):\n\n```bash\nforge inspect Storage bytecode --resolc\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 21, "depth": 3, "title": "Deploy", "anchor": "deploy-3", "start_char": 12392, "end_char": 12573, "estimated_token_count": 41, "token_estimator": "heuristic-v1", "text": "### Deploy\n\nDeploy to Polkadot Hub TestNet:\n\n```bash\nforge create Storage \\\n    --rpc-url polkadot_hub_testnet \\\n    --private-key YOUR_PRIVATE_KEY \\\n    --resolc  --broadcast\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 22, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 12573, "end_char": 13294, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThis guide has demonstrated four different approaches to deploying smart contracts on Polkadot Hub. Each method offers distinct advantages:\n\n- **Ethers.js**: Best for lightweight, programmatic deployments and application integration\n- **Remix IDE**: Ideal for rapid prototyping, learning, and visual development\n- **Hardhat**: Perfect for professional workflows requiring comprehensive testing and debugging\n- **Foundry**: Excellent for developers who prefer fast, command-line driven development\n\nAll approaches use the `resolc` compiler to generate PolkaVM-compatible bytecode, ensuring your contracts run natively on Polkadot Hub. Choose the tool that best fits your workflow and project requirements."}
{"page_id": "smart-contracts-cookbook-smart-contracts-.deploy-basic-pvm", "page_title": "Deploy a Basic Contract to Polkadot Hub", "index": 23, "depth": 3, "title": "Next Steps", "anchor": "next-steps", "start_char": 13294, "end_char": 13872, "estimated_token_count": 156, "token_estimator": "heuristic-v1", "text": "### Next Steps\n\n- Deploy an ERC-20 token on Polkadot Hub, either using the [Deploy an ERC-20](/smart-contracts/cookbook/smart-contracts/deploy-erc20) guide or the [Deploy an ERC-20 to Polkadot Hub](/smart-contracts/cookbook/smart-contracts/deploy-erc20) guide.\n- Deploy an NFT on Polkadot Hub, either using the [Deploy an NFT](/smart-contracts/cookbook/smart-contracts/deploy-nft) guide or the [Deploy an NFT to Polkadot Hub](/smart-contracts/cookbook/smart-contracts/deploy-nft) guide.\n- Check out in details each [development environment](/smart-contracts/dev-environments/)."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 0, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 355, "end_char": 684, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\n- Basic understanding of Solidity programming.\n- Test tokens for gas fees (available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}). See the [step-by-step instructions](/smart-contracts/faucet/#get-test-tokens){target=\\_blank}.\n- A wallet with a private key for signing transactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 1, "depth": 2, "title": "Set Up Your Project", "anchor": "set-up-your-project", "start_char": 684, "end_char": 884, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Set Up Your Project\n\nInstall Foundry:\n\n```bash\ncurl -L https://foundry.paradigm.xyz | bash\nfoundryup\n```\n\nInitialize your project:\n\n```bash\nforge init foundry-deployment\ncd foundry-deployment\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 2, "depth": 2, "title": "Configure Foundry", "anchor": "configure-foundry", "start_char": 884, "end_char": 1087, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "## Configure Foundry\n\nEdit `foundry.toml`:\n\n```toml\n[profile.default]\nsrc = \"src\"\nout = \"out\"\nlibs = [\"lib\"]\n\n[rpc_endpoints]\npolkadot_hub_testnet = \"https://testnet-passet-hub-eth-rpc.polkadot.io\"\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 3, "depth": 2, "title": "Create Your Contract", "anchor": "create-your-contract", "start_char": 1087, "end_char": 1485, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Create Your Contract\n\nReplace the default contract in `src/Storage.sol`:\n\n```solidity title=\"src/Storage.sol\"\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n\ncontract Storage {\n    uint256 private storedNumber;\n\n    function store(uint256 num) public {\n        storedNumber = num;\n    }\n\n    function retrieve() public view returns (uint256) {\n        return storedNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 4, "depth": 2, "title": "Compile", "anchor": "compile", "start_char": 1485, "end_char": 1618, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Compile\n\n```bash\nforge build\n```\n\nVerify the compilation by inspecting the bytecode:\n\n```bash\nforge inspect Storage bytecode\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 5, "depth": 2, "title": "Deploy", "anchor": "deploy", "start_char": 1618, "end_char": 1862, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Deploy\n\nDeploy to Polkadot Hub TestNet:\n\n```bash\nforge create Storage \\\n    --rpc-url polkadot_hub_testnet \\\n    --private-key YOUR_PRIVATE_KEY \\\n    --broadcast\n```\n\nReplace the `YOUR_PRIVATE_KEY` placeholder with your actual private key."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-.foundry", "page_title": "Deploy a Basic Contract with Foundry", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 1862, "end_char": 2732, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Verify Your Contract__\n\n    ---\n\n    Now that you've deployed a basic contract, learn how to verify it with Foundry.\n    \n    [:octicons-arrow-right-24: Get Started](/smart-contracts/dev-environments/foundry/verify-a-contract/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n   \n    ---\n    \n    Walk through deploying a fully-functional ERC-20 to the Polkadot Hub using Foundry.\n    \n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/foundry/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT__\n\n    ---\n\n    Walk through deploying an NFT to the Polkadot Hub using Foundry.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/foundry/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 40, "end_char": 394, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis guide demonstrates how to deploy a basic Solidity smart contract to Polkadot Hub TestNet using [Hardhat](https://hardhat.org/){target=\\_blank}, which provides a comprehensive development environment with built-in testing, debugging, and deployment capabilities. It's ideal for professional development workflows and team projects."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 394, "end_char": 930, "estimated_token_count": 154, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n- A basic understanding of [Solidity](https://www.soliditylang.org/){target=\\_blank} programming.\n- [Node.js](https://nodejs.org/en/download){target=\\_blank} v22.13.1 or later installed.\n- Test tokens for gas fees, available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}. See [Get Test Tokens](/smart-contracts/faucet/#get-test-tokens){target=\\_blank} for a guide to using the faucet.\n- A wallet with a private key for signing transactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 2, "depth": 2, "title": "Set Up Your Project", "anchor": "set-up-your-project", "start_char": 930, "end_char": 1148, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Set Up Your Project\n\nUse the following terminal commands to create a directory and initialize your Hardhat project inside of it:\n\n```bash\nmkdir hardhat-deployment\ncd hardhat-deployment\nnpx hardhat@^2.27.0 init\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 3, "depth": 2, "title": "Configure Hardhat", "anchor": "configure-hardhat", "start_char": 1148, "end_char": 2194, "estimated_token_count": 247, "token_estimator": "heuristic-v1", "text": "## Configure Hardhat\n\nOpen `hardhat.config.ts` and update to add `polkadotTestnet` to the `networks` configuration as highlighted in the following example code:\n\n```typescript title='hardhat.config.ts' hl_lines='19-23'\nimport type { HardhatUserConfig } from 'hardhat/config';\n\nimport hardhatToolboxViemPlugin from '@nomicfoundation/hardhat-toolbox-viem';\nimport { vars } from 'hardhat/config';\n\n\nconst config: HardhatUserConfig = {\n  plugins: [hardhatToolboxViemPlugin],\n  solidity: {\n    version: '0.8.28',\n    settings: {\n      optimizer: {\n        enabled: true,\n        runs: 200,\n      },\n    },\n  },\n  networks: {\n    polkadotTestnet: {\n      url: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      chainId: 420420422,\n      accounts: [vars.get('PRIVATE_KEY')],\n    },\n  },\n};\n\nexport default config;\n\n```\n\n!!! tip\n    Visit the Hardhat [Configuration variables](https://v2.hardhat.org/hardhat-runner/docs/guides/configuration-variables){target=\\_blank} documentation to learn how to use Hardhat to handle your private keys securely."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 4, "depth": 2, "title": "Create the Contract", "anchor": "create-the-contract", "start_char": 2194, "end_char": 2856, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "## Create the Contract\n\nFollow these steps to create your smart contract:\n\n1. Delete the default contract file(s) in the `contracts` directory.\n\n2. Create a new file named `Storage.sol` inside the `contracts` directory.\n\n3. Add the following code to create the `Storage.sol` smart contract:\n\n    ```solidity title=\"Storage.sol\"\n    // SPDX-License-Identifier: MIT\n    pragma solidity ^0.8.9;\n\n    contract Storage {\n        uint256 private storedNumber;\n\n        function store(uint256 num) public {\n            storedNumber = num;\n        }\n\n        function retrieve() public view returns (uint256) {\n            return storedNumber;\n        }\n    }\n\n    ```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 5, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 2856, "end_char": 3477, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nCompile your `Storage.sol` contract using the following command:\n\n```bash\nnpx hardhat compile\n```\n\nYou will see a message in the terminal confirming the contract was successfully compiled, similar to the following:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat compile</span>\n  <span data-ty>Downloading solc 0.8.28</span>\n  <span data-ty>Downloading solc 0.8.28 (WASM build)</span>\n  <span data-ty>Compiled 1 Solidity file with solc 0.8.28 (evm target: cancun)</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 6, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 3477, "end_char": 5384, "estimated_token_count": 474, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nYou are now ready to deploy the contract to your chosen network. This example demonstrates deployment to the Polkadot TestNet. Deploy the contract as follows:\n\n1. Delete the default file(s) inside the `ignition/modules` directory.\n\n2. Create a new file named `Storage.ts` inside the `ignition/modules` directory.\n\n3. Open `ignition/modules/Storage.ts` and add the following code to create your deployment module:\n\n    ```typescript title=\"ignition/modules/Storage.ts\"\n    import { buildModule } from '@nomicfoundation/hardhat-ignition/modules';\n\n    export default buildModule('StorageModule', (m) => {\n      const storage = m.contract('Storage');\n      return { storage };\n    });\n\n    ```\n\n4. Deploy your contract to Polkadot Hub TestNet using the following command:\n\n    ```bash\n    npx hardhat ignition deploy ignition/modules/Storage.ts --network polkadotTestnet \n    ```\n\n5. Confirm the target deployment network name and chain ID when prompted:\n\n    <div id=\"termynal\" data-termynal markdown>\n      <span data-ty=\"input\">npx hardhat ignition deploy ignition/modules/Storage.ts --network polkadotTestnet</span>\n      <span data-ty>âœ” Confirm deploy to network polkadotTestnet (420420420)? â€¦ yes</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Hardhat Ignition ðŸš€</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Deploying [ StorageModule ]</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>[ StorageModule ] successfully deployed ðŸš€</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Deployed Addresses</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Storage - 0x12345.....</span>\n      <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n    </div>\nCongratulations! You've now deployed a basic smart contract to Polkadot Hub TestNet using Hardhat. Consider the following resources to build upon your progress."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-hardhat", "page_title": "Deploy a Basic Contract with Hardhat", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5384, "end_char": 5979, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to the Polkadot Hub using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT__\n\n    ---\n\n    Walk through deploying an NFT to the Polkadot Hub using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-hardhat/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-remix", "page_title": "Deploy a Basic Contract with Remix IDE", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 42, "end_char": 399, "estimated_token_count": 71, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis guide demonstrates how to deploy a basic Solidity smart contract to Polkadot Hub using [Remix IDE](https://remix.ethereum.org/){target=\\_blank}, which offers a visual, browser-based environment perfect for rapid prototyping and learning. It requires no local installation and provides an intuitive interface for contract development."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-remix", "page_title": "Deploy a Basic Contract with Remix IDE", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 399, "end_char": 961, "estimated_token_count": 160, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n- A basic understanding of [Solidity](https://www.soliditylang.org/){target=\\_blank} programming.\n- An EVM-compatible [wallet](/smart-contracts/connect/){target=\\_blank} connected to Polkadot Hub. This example utilizes [MetaMask](https://metamask.io/){target=\\_blank}.\n- Test tokens for gas fees, available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}. See [Get Test Tokens](/smart-contracts/faucet/#get-test-tokens){target=\\_blank} for a guide to using the faucet."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-remix", "page_title": "Deploy a Basic Contract with Remix IDE", "index": 2, "depth": 2, "title": "Locate Your Contract", "anchor": "locate-your-contract", "start_char": 961, "end_char": 1479, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "## Locate Your Contract\n\nThis guide uses a default contract contract provided by Remix IDE. Follow these steps to locate the contract in Remix:\n\n1. Navigate to [Remix IDE](https://remix.ethereum.org/){target=\\_blank} in your web browser.\n\n2. Once the default workspace loads, locate the `contracts` folder. Inside `contracts`, locate the `Storage.sol` file which you will use as your sample contract throughout this guide.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/remix-01.webp)"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-remix", "page_title": "Deploy a Basic Contract with Remix IDE", "index": 3, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 1479, "end_char": 2315, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nSolidity source code compiles into bytecode that can be deployed on the blockchain. During this process, the compiler checks the contract for syntax errors, ensures type safety, and generates the machine-readable instructions needed for blockchain execution. \n\nEnsure your `Storage.sol` contract is open in the Remix IDE editor, and use the following steps to compile:\n\n1. Select the **Solidity Compiler** plugin from the left panel.\n2. Select the **Compile Storage.sol** button.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/remix-02.webp)\n\nThe **Solidity Compiler** icon will display a green checkmark once the contract compiles successfully. If any issues arise during contract compilation, errors and warnings will appear in the terminal panel at the bottom of the screen."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-remix", "page_title": "Deploy a Basic Contract with Remix IDE", "index": 4, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 2315, "end_char": 3209, "estimated_token_count": 186, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nFollow these steps to deploy the contract using Remix: \n\n1. Select **Deploy & Run Transactions** from the left panel.\n2. Ensure your MetaMask wallet is connected to Polkadot Hub TestNet, then select the **Environment** dropdown and select **Injected Provider - MetaMask**.\n3. Select the **Deploy** button to initiate the deployment.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/remix-03.webp)\n\nWhen prompted, approve the transaction in your MetaMask wallet. After the deployment succeeds, the terminal will display the transaction details, including the contract address and transaction hash, and your contract will appear in the **Deployed Contracts** section.\n\nCongratulations! You've successfully deployed a basic smart contract to Polkadot Hub TestNet using Remix IDE. Consider the following resources to build upon your progress."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-basic-basic-remix", "page_title": "Deploy a Basic Contract with Remix IDE", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3209, "end_char": 3796, "estimated_token_count": 159, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to Polkadot Hub using Remix.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT__\n\n    ---\n\n    Walk through deploying an NFT to Polkadot Hub using Remix.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/)        \n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 34, "end_char": 771, "estimated_token_count": 184, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[ERC-20](https://eips.ethereum.org/EIPS/eip-20){target=\\_blank} tokens are fungible tokens commonly used for creating cryptocurrencies, governance tokens, and staking mechanisms. Polkadot Hub enables easy deployment of ERC-20 tokens via Ethereum-compatible smart contracts and tools.\n\nThis guide demonstrates how to deploy an ERC-20 contract on Polkadot Hub TestNet using [Hardhat](https://hardhat.org/){target=\\_blank}, an Ethereum development environment. The ERC-20 contract can be retrieved from OpenZeppelin's [GitHub repository](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v5.4.0/contracts/token/ERC20){target=\\_blank} or their [Contract Wizard](https://wizard.openzeppelin.com/){target=\\_blank}."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 771, "end_char": 1415, "estimated_token_count": 190, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n- A basic understanding of [Solidity](https://www.soliditylang.org/){target=\\_blank} programming and [ERC-20](https://ethereum.org/developers/docs/standards/tokens/erc-20/){target=\\_blank} fungible tokens.\n- [Node.js](https://nodejs.org/en/download){target=\\_blank} v22.13.1 or later installed.\n- Test tokens for gas fees, available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}. See [Get Test Tokens](/smart-contracts/faucet/#get-test-tokens){target=\\_blank} for a guide to using the faucet.\n- A wallet with a private key for signing transactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 2, "depth": 2, "title": "Set Up Your Project", "anchor": "set-up-your-project", "start_char": 1415, "end_char": 2061, "estimated_token_count": 152, "token_estimator": "heuristic-v1", "text": "## Set Up Your Project\n\nThis tutorial uses a [Hardhat ERC-20 template](https://github.com/polkadot-developers/revm-hardhat-examples/tree/master/erc20-hardhat){target=\\_blank} that contains all the necessary files. \n\nTo get started, take the following steps:\n\n1. Clone the GitHub repository locally:\n\n    ```bash\n    git clone https://github.com/polkadot-developers/revm-hardhat-examples/\n    cd revm-hardhat-examples/erc20-hardhat\n    ```\n\n2. Install the dependencies using the following command:\n\n    ```bash\n    npm i\n    ```\n    \n    This command will fetch all the necessary packages to help you use Hardhat to deploy an ERC-20 to Polkadot."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 3, "depth": 2, "title": "Configure Hardhat", "anchor": "configure-hardhat", "start_char": 2061, "end_char": 2964, "estimated_token_count": 232, "token_estimator": "heuristic-v1", "text": "## Configure Hardhat\n\nIf you started with the cloned Hardhat ERC-20 template, `hardhat.config.ts` is already configured to deploy to the Polkadot TestNet as shown in the example below:\n\n```ts title=\"hardhat.config.ts\" hl_lines=\"14-19\"\n\nconst config: HardhatUserConfig = {\n  solidity: {\n    version: \"0.8.28\",\n    settings: {\n      optimizer: {\n        enabled: true,\n        runs: 200,\n      },\n    },\n  },\n  networks: {\n    polkadotTestnet: {\n      url: vars.get(\"TESTNET_URL\", \"http://127.0.0.1:8545\"),\n      accounts: vars.has(\"TESTNET_PRIVATE_KEY\") ? [vars.get(\"TESTNET_PRIVATE_KEY\")] : [],\n    },\n  },\n  mocha: {\n    timeout: 40000,\n  },\n};\n\nexport default config;\n```\n\n!!! tip\n    Visit the Hardhat [Configuration variables](https://v2.hardhat.org/hardhat-runner/docs/guides/configuration-variables){target=\\_blank} documentation to learn how to use Hardhat to handle your private keys securely."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 4, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 2964, "end_char": 3197, "estimated_token_count": 44, "token_estimator": "heuristic-v1", "text": "## Compile the Contract \n\nNext, compile the contract included with the template by running the following command:\n\n```bash\nnpx hardhat compile\n```\n\nIf everything compiles successfully, you will see output similar to the following:"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 5, "depth": 2, "title": "Test the Contract", "anchor": "test-the-contract", "start_char": 3197, "end_char": 5062, "estimated_token_count": 576, "token_estimator": "heuristic-v1", "text": "## Test the Contract\n\nYou can view the predefined test file at [`test/MyToken.test.ts`](https://github.com/polkadot-developers/revm-hardhat-examples/blob/master/erc20-hardhat/test/MyToken.test.ts){target=\\_blank}. This example test includes verification of the following:\n\n- The token name and symbol exist (confirms deployment) and are correct.\n- The token owner is correctly configured.\n- The initial token supply is zero.\n- The owner can mint tokens.\n- The total supply increases after a mint.\n- Successful mints to different test addresses with expected account balance and total supply changes.\n\nRun the tests using the following command:\n\n```bash\nnpx hardhat test --network polkadotTestnet\n```\n\nIf tests are successful, you will see outputs similar to the following:\n\n<div id=\"termynal\" data-termynal markdown>\n  <span data-ty=\"input\">npx hardhat test --network polkadotTestnet</span>\n  <span data-ty></span>\n  <span data-ty>&nbsp;&nbsp;MyToken</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;Deployment</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;âœ” Should have correct name and symbol</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;âœ” Should set the right owner</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;âœ” Should have zero initial supply</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;Minting</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;âœ” Should allow owner to mint tokens</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;âœ” Should increase total supply on mint</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;Multiple mints</span>\n  <span data-ty>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;âœ” Should correctly track balance after multiple mints</span>\n  <span data-ty></span>\n  <span data-ty>&nbsp;&nbsp;6 passing (369ms)</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 6, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 5062, "end_char": 6719, "estimated_token_count": 425, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nYou are now ready to deploy the contract to your chosen network. This example demonstrates deployment to the Polkadot TestNet. Deploy the contract as follows:\n\n1. Run the following command in your terminal:\n\n    ```bash\n    npx hardhat ignition deploy ./ignition/modules/MyToken.ts --network polkadotTestnet\n    ```\n\n2. Confirm the target deployment network name and chain ID when prompted:\n\n    <div id=\"termynal\" data-termynal markdown>\n      <span data-ty=\"input\">npx hardhat ignition deploy ./ignition/modules/MyToken.ts --network polkadotTestnet</span>\n      <span data-ty>âœ” Confirm deploy to network polkadotTestnet (420420420)? â€¦ yes</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Hardhat Ignition ðŸš€</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Deploying [ TokenModule ]</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Batch #1</span>\n      <span data-ty> Executed TokenModule#MyToken</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Batch #2</span>\n      <span data-ty> Executed TokenModule#MyToken.mint</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>[ TokenModule ] successfully deployed ðŸš€</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Deployed Addresses</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>TokenModule#MyToken - 0xc01Ee7f10EA4aF4673cFff62710E1D7792aBa8f3</span>\n      <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n    </div>\n\nCongratulations! You've successfully deployed an ERC-20 token contract to Polkadot Hub TestNet using Hardhat. Consider the following resources to build upon your progress."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-hardhat", "page_title": "Deploy an ERC-20 Using Hardhat", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6719, "end_char": 7318, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT__\n\n    ---\n\n    Walk through deploying an NFT to the Polkadot Hub using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> __Create a DApp__\n\n    ---\n\n    Learn step-by-step how to build a fully functional dApp that interacts with a smart contract deployed via Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/dapps/zero-to-hero/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 36, "end_char": 778, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[ERC-20](https://eips.ethereum.org/EIPS/eip-20){target=\\_blank} tokens are fungible tokens commonly used for creating cryptocurrencies, governance tokens, and staking mechanisms. Polkadot Hub enables easy token deployment with Ethereum-compatible smart contracts and tools via the EVM backend.\n\nThis tutorial covers deploying an ERC-20 contract on Polkadot Hub TestNet using [Remix IDE](https://remix.ethereum.org/){target=\\_blank}, a web-based development tool. The ERC-20 contract can be retrieved from OpenZeppelin's [GitHub repository](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/v5.4.0/contracts/token/ERC20){target=\\_blank} or their [Contract Wizard](https://wizard.openzeppelin.com/){target=\\_blank}."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 778, "end_char": 1434, "estimated_token_count": 194, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have:\n\n- A basic understanding of [Solidity](https://www.soliditylang.org/){target=\\_blank} programming and [ERC-20](https://ethereum.org/developers/docs/standards/tokens/erc-20/){target=\\_blank} fungible tokens.\n- An EVM-compatible [wallet](/smart-contracts/connect/){target=\\_blank} connected to Polkadot Hub. This example utilizes [MetaMask](https://metamask.io/){target=\\_blank}.\n- Test tokens for gas fees, available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}. See [Get Test Tokens](/smart-contracts/faucet/#get-test-tokens){target=\\_blank} for a guide to using the faucet."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 2, "depth": 2, "title": "Create Your Contract", "anchor": "create-your-contract", "start_char": 1434, "end_char": 2792, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "## Create Your Contract\n\nFollow the steps below to create the ERC-20 contract:\n\n1. Navigate to [Remix IDE](https://remix.ethereum.org/){target=\\_blank} in your web browser.\n2. Select the **Create new file** button under the **contracts** folder, and name your contract `MyToken.sol`.\n\n    ![](/images/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/remix-01.webp)\n\n3. Now, paste the following ERC-20 contract code into `MyToken.sol`:\n\n    ```solidity title=\"MyToken.sol\"\n    // SPDX-License-Identifier: MIT\n    // Compatible with OpenZeppelin Contracts ^5.4.0\n    pragma solidity ^0.8.27;\n\n    import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\n    import {ERC20Permit} from \"@openzeppelin/contracts/token/ERC20/extensions/ERC20Permit.sol\";\n    import {Ownable} from \"@openzeppelin/contracts/access/Ownable.sol\";\n\n    contract MyToken is ERC20, Ownable, ERC20Permit {\n        constructor(address initialOwner)\n            ERC20(\"MyToken\", \"MTK\")\n            Ownable(initialOwner)\n            ERC20Permit(\"MyToken\")\n        {}\n\n        function mint(address to, uint256 amount) public onlyOwner {\n            _mint(to, amount);\n        }\n    }\n    ```\n    \n    !!! tip\n        The [OpenZeppelin Contracts Wizard](https://wizard.openzeppelin.com/){target=\\_blank} was used to generate this example ERC-20 contract."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 3, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 2792, "end_char": 3626, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nSolidity source code compiles into bytecode that can be deployed on the blockchain. During this process, the compiler checks the contract for syntax errors, ensures type safety, and generates the machine-readable instructions needed for blockchain execution.\n\nEnsure your `MyToken.sol` contract is open in the Remix IDE Editor, and use the following steps to compile:\n\n1. Select the **Solidity Compiler** plugin from the left panel.\n2. Select the **Compile MyToken.sol** button.\n\nThe **Solidity Compiler** icon will display a green checkmark once the contract compiles successfully. If any issues arise during contract compilation, errors and warnings will appear in the terminal panel at the bottom of the screen.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/remix-03.gif)"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 4, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 3626, "end_char": 4513, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nFollow these steps to deploy the contract using Remix:\n\n1. Select **Deploy & Run Transactions** from the left panel.\n2. Ensure your MetaMask wallet is connected to Polkadot Hub TestNet, then select the **Environment** dropdown and select **Injected Provider - MetaMask**.\n3. Configure the contract parameters by entering the address that will own the deployed token contract.\n4. Select the **Deploy** button to initiate the deployment.\n4. Approve the transaction in your MetaMask wallet when prompted.\n6. You will see the transaction details in the terminal when the deployment succeeds, including the contract address and deployment transaction hash.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/remix-04.gif)\n\nOnce successfully deployed, your contract will appear in the **Deployed Contracts** section, ready for interaction."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 5, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 4513, "end_char": 5688, "estimated_token_count": 254, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nOnce deployed, you can interact with your contract through Remix. Find your contract under **Deployed/Unpinned Contracts**, and select it to expand the available methods. In this example, you'll mint some tokens to a given address using the following steps:\n\n1. Expand the **mint** function, then enter the recipient address and the amount (remember to add 18 zeros for one whole token).\n2. Select **transact**.\n3. Approve the transaction in your MetaMask wallet when prompted.\n4. You will see a green check mark in the terminal when the transaction is successful.\n5. You can also call the **balanceOf** function by passing the address of the **mint** call to confirm the new balance.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/remix-05.gif)\n\nFeel free to explore and interact with the contract's other functions by selecting the method, providing any required parameters, and confirming the transaction in MetaMask when prompted.\n\nCongratulations! You've successfully deployed an ERC-20 token contract to Polkadot Hub TestNet using Remix IDE. Consider the following resources to build upon your progress."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-erc20-erc20-remix", "page_title": "Deploy an ERC-20 Using Remix IDE", "index": 6, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 5688, "end_char": 6072, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT with Remix__\n\n    ---\n\n    Walk through deploying an ERC-721 Non-Fungible Token (NFT) using OpenZeppelin's battle-tested NFT implementation and Remix.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 30, "end_char": 792, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nNon-Fungible Tokens (NFTs) represent unique digital assets commonly used for digital art, collectibles, gaming, and identity verification.\n\nThis guide demonstrates how to deploy an [ERC-721](https://eips.ethereum.org/EIPS/eip-721){target=\\_blank} NFT contract to [Polkadot Hub](/smart-contracts/overview/#smart-contract-development){target=\\_blank}. It showcases a secure approach using [OpenZeppelin's battle-tested NFT implementation](https://github.com/OpenZeppelin/openzeppelin-contracts){target=\\_blank} and the [Foundry](https://getfoundry.sh/){target=\\_blank} toolchain. Foundry, a fast, Rust-written toolkit, ensures high-performance compilation and is fully compatible with the Hubâ€™s EVM environment via standard Solidity compilation."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 792, "end_char": 1139, "estimated_token_count": 90, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\n- Basic understanding of Solidity programming and NFT standards.\n- Test tokens for gas fees (available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}). See the [step-by-step instructions](/smart-contracts/faucet/#get-test-tokens){target=\\_blank}.\n- A wallet with a private key for signing transactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 2, "depth": 2, "title": "Set Up Your Project", "anchor": "set-up-your-project", "start_char": 1139, "end_char": 1539, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Set Up Your Project\n\nTo get started, take the following steps:\n\n1. Install Foundry:\n\n    ```bash\n    curl -L https://foundry.paradigm.xyz | bash\n    foundryup\n    ```\n\n2. Initialize your project:\n\n    ```bash\n    forge init foundry-nft-deployment\n    cd foundry-nft-deployment\n    ```\n\n3. Install OpenZeppelin contracts:\n\n    ```bash\n    forge install OpenZeppelin/openzeppelin-contracts\n    ```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 3, "depth": 2, "title": "Configure Foundry", "anchor": "configure-foundry", "start_char": 1539, "end_char": 1843, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Configure Foundry\n\nEdit `foundry.toml`:\n\n```toml title=\"foundry.toml\"\n[profile.default]\nsrc = \"src\"\nout = \"out\"\nlibs = [\"lib\"]\nremappings = ['@openzeppelin/contracts/=lib/openzeppelin-contracts/contracts/']\n\n[rpc_endpoints]\npolkadot_hub_testnet = \"https://testnet-passet-hub-eth-rpc.polkadot.io\"\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 4, "depth": 2, "title": "Create Your Contract", "anchor": "create-your-contract", "start_char": 1843, "end_char": 2417, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "## Create Your Contract\n\nCreate `src/MyNFT.sol`:\n\n```solidity title=\"src/MyNFT.sol\"\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n\nimport \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\n\ncontract MyNFT is ERC721, Ownable {\n    uint256 private _nextTokenId;\n\n    constructor(address initialOwner)\n        ERC721(\"MyToken\", \"MTK\")\n        Ownable(initialOwner)\n    {}\n\n    function safeMint(address to) public onlyOwner {\n        uint256 tokenId = _nextTokenId++;\n        _safeMint(to, tokenId);\n    }\n}\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 5, "depth": 2, "title": "Compile", "anchor": "compile", "start_char": 2417, "end_char": 2548, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Compile\n\n```bash\nforge build\n```\n\nVerify the compilation by inspecting the bytecode:\n\n```bash\nforge inspect MyNFT bytecode\n```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 6, "depth": 2, "title": "Deploy", "anchor": "deploy", "start_char": 2548, "end_char": 2884, "estimated_token_count": 66, "token_estimator": "heuristic-v1", "text": "## Deploy\n\nDeploy to Polkadot Hub TestNet:\n\n```bash\nforge create MyNFT \\\n    --rpc-url polkadot_hub_testnet \\\n    --private-key YOUR_PRIVATE_KEY \\\n    --constructor-args YOUR_OWNER_ADDRESS \\\n    --broadcast\n```\n\nReplace `YOUR_PRIVATE_KEY` with your private key and `YOUR_OWNER_ADDRESS` with the address that will own the NFT contract."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-.foundry", "page_title": "Deploy an NFT to Polkadot Hub with Foundry", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 2884, "end_char": 3489, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Verify Your Contract__\n\n    ---\n\n    Now that you've deployed an NFT contract, learn how to verify it with Foundry.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/dev-environments/foundry/verify-a-contract/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to the Polkadot Hub using Foundry.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/foundry/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 35, "end_char": 853, "estimated_token_count": 192, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nNon-Fungible Tokens (NFTs) represent unique digital assets commonly used for digital art, collectibles, gaming, and identity verification.\n\nThis guide demonstrates how to deploy an [ERC-721](https://eips.ethereum.org/EIPS/eip-721){target=\\_blank} NFT contract to [Polkadot Hub](/smart-contracts/overview/#smart-contract-development){target=\\_blank} TestNet. You'll use OpenZeppelin's battle-tested [NFT implementation](https://github.com/OpenZeppelin/openzeppelin-contracts){target=\\_blank} and [Hardhat](https://hardhat.org/docs/getting-started){target=\\_blank}, a comprehensive development environment with built-in testing, debugging, and deployment capabilities. Hardhat uses standard Solidity compilation to generate EVM bytecode, making it fully compatible with Polkadot Hub's EVM environment."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 853, "end_char": 1503, "estimated_token_count": 192, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n- A basic understanding of [Solidity](https://www.soliditylang.org/){target=\\_blank} programming and [ERC-721](https://ethereum.org/developers/docs/standards/tokens/erc-721/){target=\\_blank} non-fungible tokens.\n- [Node.js](https://nodejs.org/en/download){target=\\_blank} v22.13.1 or later installed.\n- Test tokens for gas fees, available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}. See [Get Test Tokens](/smart-contracts/faucet/#get-test-tokens){target=\\_blank} for a guide to using the faucet.\n- A wallet with a private key for signing transactions."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 2, "depth": 2, "title": "Set Up Your Project", "anchor": "set-up-your-project", "start_char": 1503, "end_char": 1883, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Set Up Your Project\n\n1. Use the following terminal commands to create a directory and initialize your Hardhat project inside of it:\n\n    ```bash\n    mkdir hardhat-nft-deployment\n    cd hardhat-nft-deployment\n    npx hardhat@^2.27.0 init\n    ```\n\n2. Install the OpenZeppelin contract dependencies using the command:\n\n    ```bash\n    npm install @openzeppelin/contracts\n    ```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 3, "depth": 2, "title": "Configure Hardhat", "anchor": "configure-hardhat", "start_char": 1883, "end_char": 2927, "estimated_token_count": 247, "token_estimator": "heuristic-v1", "text": "## Configure Hardhat\n\nOpen `hardhat.config.ts` and update to add `polkadotTestnet` to the `networks` configuration as highlighted in the following example code:\n\n```typescript title=\"hardhat.config.ts\" hl_lines='18-23'\nimport type { HardhatUserConfig } from 'hardhat/config';\n\nimport hardhatToolboxViemPlugin from '@nomicfoundation/hardhat-toolbox-viem';\nimport { vars } from 'hardhat/config';\n\nconst config: HardhatUserConfig = {\n  plugins: [hardhatToolboxViemPlugin],\n  solidity: {\n    version: '0.8.28',\n    settings: {\n      optimizer: {\n        enabled: true,\n        runs: 200,\n      },\n    },\n  },\n  networks: {\n    polkadotTestnet: {\n      url: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      chainId: 420420422,\n      accounts: [vars.get('PRIVATE_KEY')],\n    },\n  },\n};\n\nexport default config;\n```\n\n!!! tip\n    Visit the Hardhat [Configuration variables](https://v2.hardhat.org/hardhat-runner/docs/guides/configuration-variables){target=\\_blank} documentation to learn how to use Hardhat to handle your private keys securely."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 4, "depth": 2, "title": "Create the Contract", "anchor": "create-the-contract", "start_char": 2927, "end_char": 3803, "estimated_token_count": 188, "token_estimator": "heuristic-v1", "text": "## Create the Contract\n\nFollow these steps to create your smart contract:\n\n1. Delete the default contract file(s) in the `contracts` directory.\n\n2. Create a new file named `MyNFT.sol` inside the `contracts` directory.\n\n3. Add the following code to create the `MyNFT.sol` smart contract:\n    ```solidity title=\"contracts/MyNFT.sol\"\n    // SPDX-License-Identifier: MIT\n    pragma solidity ^0.8.20;\n\n    import \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\n    import \"@openzeppelin/contracts/access/Ownable.sol\";\n\n    contract MyNFT is ERC721, Ownable {\n        uint256 private _nextTokenId;\n\n        constructor(\n            address initialOwner\n        ) ERC721(\"MyToken\", \"MTK\") Ownable(initialOwner) {}\n\n        function safeMint(address to) public onlyOwner {\n            uint256 tokenId = _nextTokenId++;\n            _safeMint(to, tokenId);\n        }\n    }\n\n    ```"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 5, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 3803, "end_char": 4421, "estimated_token_count": 187, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nCompile your `MyNFT.sol` contract using the following command:\n\n```bash\nnpx hardhat compile\n```\n\nYou will see a message in the terminal confirming the contract was successfully compiled, similar to the following:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>npx hardhat compile</span>\n  <span data-ty>Downloading solc 0.8.28</span>\n  <span data-ty>Downloading solc 0.8.28 (WASM build)</span>\n  <span data-ty>Compiled 1 Solidity file with solc 0.8.28 (evm target: cancun)</span>\n  <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 6, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 4421, "end_char": 6756, "estimated_token_count": 592, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nYou are now ready to deploy the contract to your chosen network. This example demonstrates deployment to the Polkadot TestNet. Deploy the contract as follows:\n\n1. Delete the default file(s) inside the `ignition/modules` directory.\n\n2. Create a new file named `MyNFT.ts` inside the `ignition/modules` directory.\n\n3. Open `ignition/modules/MyNFT.ts` and add the following code to create your deployment module:\n    ```typescript title=\"ignition/modules/MyNFT.ts\"\n    import { buildModule } from '@nomicfoundation/hardhat-ignition/modules';\n\n    export default buildModule('MyNFTModule', (m) => {\n      const initialOwner = m.getParameter('initialOwner', 'INSERT_OWNER_ADDRESS');\n      const myNFT = m.contract('MyNFT', [initialOwner]);\n      return { myNFT };\n    });\n\n    ```\n\n    Replace `INSERT_OWNER_ADDRESS` with your desired owner address.\n\n4. Deploy your contract to Polkadot Hub TestNet using the following command:\n\n    ```bash\n    npx hardhat ignition deploy ignition/modules/MyNFT.ts --network polkadotTestnet\n    ```\n\n5. Confirm the target deployment network name and chain ID when prompted:\n\n    <div id=\"termynal\" data-termynal markdown>\n      <span data-ty=\"input\">npx hardhat ignition deploy ignition/modules/MyNFT.ts --network polkadotHubTestnet</span>\n      <span data-ty>âœ” Confirm deploy to network polkadotTestnet (420420420)? â€¦ yes</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Hardhat Ignition ðŸš€</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Deploying [ MyNFTModule ]</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Batch #1</span>\n      <span data-ty> Executed MyNFTModule#MyNFT</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Batch #2</span>\n      <span data-ty> Executed MyNFTModule#MyNFT.safeMint</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>[ TokenModule ] successfully deployed ðŸš€</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>Deployed Addresses</span>\n      <span data-ty>&nbsp;</span>\n      <span data-ty>MyNFTModule#MyNFT - 0x1234.......</span>\n      <span data-ty=\"input\"><span class=\"file-path\"></span></span>\n    </div>\nCongratulations! You've successfully deployed an ERC-721 NFT contract to Polkadot Hub TestNet using Hardhat. Consider the following resources to build upon your progress."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-hardhat", "page_title": "Deploy an ERC-721 Using Hardhat", "index": 7, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 6756, "end_char": 7377, "estimated_token_count": 167, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to Polkadot Hub using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> __Create a DApp__\n\n    ---\n\n    Learn step-by-step how to build a fully functional dApp that interacts with a smart contract deployed via Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/dapps/zero-to-hero/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-remix", "page_title": "Deploy an ERC-721 NFT Using Remix", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 763, "estimated_token_count": 178, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nNon-Fungible Tokens (NFTs) represent unique digital assets commonly used for digital art, collectibles, gaming, and identity verification.\n\nThis guide demonstrates how to deploy an [ERC-721](https://eips.ethereum.org/EIPS/eip-721){target=\\_blank} NFT contract to [Polkadot Hub](/smart-contracts/overview/#smart-contract-development){target=\\_blank}. You'll use [OpenZeppelin's battle-tested NFT implementation](https://github.com/OpenZeppelin/openzeppelin-contracts){target=\\_blank} and [Remix](https://remix.ethereum.org/){target=\\_blank}, a visual, browser-based environment perfect for rapid prototyping and learning. It requires no local installation and provides an intuitive interface for contract development."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-remix", "page_title": "Deploy an ERC-721 NFT Using Remix", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 763, "end_char": 1368, "estimated_token_count": 181, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\n- A basic understanding of [Solidity](https://www.soliditylang.org/){target=\\_blank} programming and [ERC-721 NFT](https://ethereum.org/developers/docs/standards/tokens/erc-721/) standards.\n- An EVM-compatible [wallet](/smart-contracts/connect/){target=\\_blank} connected to Polkadot Hub. This example utilizes [MetaMask](https://metamask.io/){target=\\_blank}.\n- Test tokens for gas fees (available from the [Polkadot faucet](https://faucet.polkadot.io/){target=\\_blank}). See [Get Test Tokens](/smart-contracts/faucet/#get-test-tokens){target=\\_blank} for a guide to using the faucet."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-remix", "page_title": "Deploy an ERC-721 NFT Using Remix", "index": 2, "depth": 2, "title": "Create Your Contract", "anchor": "create-your-contract", "start_char": 1368, "end_char": 2563, "estimated_token_count": 289, "token_estimator": "heuristic-v1", "text": "## Create Your Contract\n\nFollow the steps below to create the ERC-721 contract:\n\n1. Navigate to [Remix IDE](https://remix.ethereum.org/){target=\\_blank} in your web browser.\n2. Select the **Create new file** button under the **contracts** folder, and name your contract `MyNFT.sol`.\n\n    ![](/images/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/remix-01.webp)\n\n3. Now, paste the following ERC-721 contract code into `MyNFT.sol`:\n\n    ```solidity title=\"contracts/MyNFT.sol\"\n    // SPDX-License-Identifier: MIT\n    pragma solidity ^0.8.20;\n\n    import \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\n    import \"@openzeppelin/contracts/access/Ownable.sol\";\n\n    contract MyNFT is ERC721, Ownable {\n        uint256 private _nextTokenId;\n\n        constructor(\n            address initialOwner\n        ) ERC721(\"MyToken\", \"MTK\") Ownable(initialOwner) {}\n\n        function safeMint(address to) public onlyOwner {\n            uint256 tokenId = _nextTokenId++;\n            _safeMint(to, tokenId);\n        }\n    }\n\n    ```\n\n    !!! tip\n        The [OpenZeppelin Contracts Wizard](https://wizard.openzeppelin.com/){target=\\_blank} was used to generate this example ERC-721 contract."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-remix", "page_title": "Deploy an ERC-721 NFT Using Remix", "index": 3, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 2563, "end_char": 3392, "estimated_token_count": 176, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nSolidity source code compiles into bytecode that can be deployed on the blockchain. During this process, the compiler checks the contract for syntax errors, ensures type safety, and generates the machine-readable instructions needed for blockchain execution.\n\nEnsure your `MyNFT.sol` contract is open in the Remix IDE Editor, and use the following steps to compile:\n\n1. Select the **Solidity Compiler** plugin from the left panel.\n2. Select the **Compile MyToken.sol** button.\n\nThe **Solidity Compiler** icon will display a green checkmark once the contract compiles successfully. If any issues arise during contract compilation, errors and warnings will appear in the terminal panel at the bottom of the screen.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/remix-02.webp)"}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-remix", "page_title": "Deploy an ERC-721 NFT Using Remix", "index": 4, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 3392, "end_char": 4543, "estimated_token_count": 249, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nFollow these steps to deploy the contract using Remix:\n\n1. Select **Deploy & Run Transactions** from the left panel.\n2. Ensure your MetaMask wallet is connected to Polkadot Hub TestNet, then select the **Environment** dropdown and select **Injected Provider - MetaMask**.\n\n    ![](/images/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/remix-03.webp)\n\n3. Configure the contract parameters by entering the address that will own the deployed NFT contract.\n4. Select the **Deploy** button to initiate the deployment.\n5. Approve the transaction in your MetaMask wallet when prompted.\n6. You will see the transaction details in the terminal when the deployment succeeds, including the contract address and deployment transaction hash.\n\n![](/images/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/remix-04.webp)\n\nOnce successfully deployed, your contract will appear in the **Deployed Contracts** section, ready for interaction.\n\nCongratulations! You've successfully deployed an ERC-721 NFT contract to Polkadot Hub TestNet using Remix IDE. Consider the following resources to build upon your progress."}
{"page_id": "smart-contracts-cookbook-smart-contracts-deploy-nft-nft-remix", "page_title": "Deploy an ERC-721 NFT Using Remix", "index": 5, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 4543, "end_char": 4877, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to Polkadot Hub using Remix.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/)\n\n</div>"}
{"page_id": "smart-contracts-cookbook", "page_title": "Smart Contracts Cookbook", "index": 0, "depth": 2, "title": "Get Tokens from the Faucet", "anchor": "get-tokens-from-the-faucet", "start_char": 222, "end_char": 796, "estimated_token_count": 236, "token_estimator": "heuristic-v1", "text": "## Get Tokens from the Faucet\n\n| Title                              | Difficulty  | Tools | Description                                                                                                           |\n|------------------------------------|:-----------:|-------|-----------------------------------------------------------------------------------------------------------------------|\n| [Faucet](/smart-contracts/faucet/) | ðŸŸ¢ Beginner | N/A   | Learn how to obtain test tokens from Polkadot faucets for development and testing purposes across different networks. |"}
{"page_id": "smart-contracts-cookbook", "page_title": "Smart Contracts Cookbook", "index": 1, "depth": 2, "title": "EVM Smart Contracts", "anchor": "evm-smart-contracts", "start_char": 796, "end_char": 2071, "estimated_token_count": 469, "token_estimator": "heuristic-v1", "text": "## EVM Smart Contracts\n\n| Title                                                                                                   | Difficulty  | Tools                          | Description                                                                                                                                                 |\n|---------------------------------------------------------------------------------------------------------|:-----------:|--------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Deploy an ERC-20 to Polkadot Hub](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/) | ðŸŸ¢ Beginner | EVM Wallet, Polkadot Remix IDE | Deploy an ERC-20 token on Polkadot Hub using PolkaVM. This guide covers contract creation, compilation, deployment, and interaction via Polkadot Remix IDE. |\n| [Deploy an NFT to Polkadot Hub](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/)        | ðŸŸ¢ Beginner | EVM Wallet, Polkadot Remix IDE | Deploy an NFT on Polkadot Hub using PolkaVM and OpenZeppelin. Learn how to compile, deploy, and interact with your contract using Polkadot Remix IDE.       |"}
{"page_id": "smart-contracts-cookbook", "page_title": "Smart Contracts Cookbook", "index": 2, "depth": 2, "title": "Port Ethereum DApps", "anchor": "port-ethereum-dapps", "start_char": 2071, "end_char": 2835, "estimated_token_count": 317, "token_estimator": "heuristic-v1", "text": "## Port Ethereum DApps\n\n| Title                                                                               |   Difficulty    | Tools   | Description                                                                                                                      |\n|-------------------------------------------------------------------------------------|:---------------:|---------|----------------------------------------------------------------------------------------------------------------------------------|\n| [Deploying Uniswap V2 on Polkadot](/smart-contracts/cookbook/eth-dapps/uniswap-v2/) | ðŸŸ¡ Intermediate | Hardhat | Learn how to deploy and test Uniswap V2 on Polkadot Hub using Hardhat, bringing AMM-based token swaps to the Polkadot ecosystem. |"}
{"page_id": "smart-contracts-dev-environments-hardhat", "page_title": "Use Hardhat with Polkadot Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 11, "end_char": 386, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Hardhat](https://hardhat.org/){target=\\_blank} is a flexible development environment for building, testing, and deploying smart contracts on Polkadot. Its task runner and plugin system support organizing contract code, running tests, managing deployments, and adding custom tooling. This page demonstrates how to set up a Hardhat project for Polkadot Hub."}
{"page_id": "smart-contracts-dev-environments-hardhat", "page_title": "Use Hardhat with Polkadot Hub", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 386, "end_char": 767, "estimated_token_count": 129, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore setting up Hardhat, make sure the following are installed:\n\n- [Node.js](https://nodejs.org/){target=\\_blank} (Hardhat requires an LTS Node version, even major numbers like 18.x, 20.x, or 22.x)\n- A package manager like [npm](https://www.npmjs.com/){target=\\_blank}, [pnpm](https://pnpm.io/){target=\\_blank}, or [yarn](https://yarnpkg.com/){target=\\_blank}"}
{"page_id": "smart-contracts-dev-environments-hardhat", "page_title": "Use Hardhat with Polkadot Hub", "index": 2, "depth": 2, "title": "Initialize a Hardhat Project", "anchor": "initialize-a-hardhat-project", "start_char": 767, "end_char": 2605, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "## Initialize a Hardhat Project\n\n1. Create a directory to hold your project files:\n\n    ```bash\n    mkdir hardhat-example\n    cd hardhat-example\n    ```\n\n2. Initialize a Hardhat project:\n\n    === \"npm\"\n\n        This single command sets up your project, installs Hardhat (and optionally the Toolbox), and intializes the project:\n\n        ```bash\n        npx hardhat@^2.27.0 init\n        ```\n\n    === \"pnpm\"\n\n        This single command sets up your project, installs Hardhat (and optionally the Toolbox), and intializes the project:\n\n        ```bash\n        pnpm dlx hardhat@^2.27.0 init\n        ```\n\n    === \"yarn\"\n\n        These commands manually set up your project, install Hardhat (and optionally the Toolbox), and initializes the project:\n\n        ```bash\n        # Initialize a new Node.js project\n        yarn init -y\n\n        # Install Hardhat and the Hardhat Toolbox locally\n        yarn add --dev hardhat@^2.27.0 @nomicfoundation/hardhat-toolbox\n\n        # Initialize a Hardhat project\n        npx hardhat init\n        ```\n\n3. You will be prompted to select certain configurations for your project. To quickly create a working setup, you can accept the default answers, which will create a JavaScript project, initialize it in the current directory, add a `.gitignore`, and install all dependencies.\n\nAfter completing the setup, your Hardhat project will be fully initialized with all necessary files and dependencies. You'll see the following core components in your project:\n\n- **`contracts`**: Stores your Solidity smart contracts.\n- **`ignition`**: Contains deployment modules for safely deploying your contracts to various networks.\n- **`test`**: Contains test files that validate contract functionality.\n- **`hardhat.config.js | .ts`**: Defines your project's settings, including networks, compiler options, and plugins."}
{"page_id": "smart-contracts-dev-environments-hardhat", "page_title": "Use Hardhat with Polkadot Hub", "index": 3, "depth": 2, "title": "Configure Hardhat for Polkadot Hub", "anchor": "configure-hardhat-for-polkadot-hub", "start_char": 2605, "end_char": 3669, "estimated_token_count": 250, "token_estimator": "heuristic-v1", "text": "## Configure Hardhat for Polkadot Hub\n\nTo use Hardhat with Polkadot Hub, define the network configuration in your `hardhat.config.ts` file:\n\n=== \"Polkadot TestNet\"\n\n    ```ts title='hardhat.config.ts'\n    import type { HardhatUserConfig } from 'hardhat/config';\n    import '@nomicfoundation/hardhat-toolbox';\n\n    // If you want to use a variable for your private key\n    import { vars } from 'hardhat/config';\n\n    const config: HardhatUserConfig = {\n    solidity: '0.8.28',\n    networks: {\n        polkadotTestnet: {\n        url: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n        chainId: 420420422,\n        accounts: [vars.get('PRIVATE_KEY')],\n        },\n    },\n    };\n\n    export default config;\n    ```\n\n!!! tip\n\n    To define a [configuration variable](https://v2.hardhat.org/hardhat-runner/docs/guides/configuration-variables){target=\\_blank} for your private key, run:\n\n    ```bash\n    npx hardhat vars set PRIVATE_KEY\n    ```\n\n    Hardhat will prompt you to enter your private key and store it so it can be referenced in your configuration file."}
{"page_id": "smart-contracts-dev-environments-hardhat", "page_title": "Use Hardhat with Polkadot Hub", "index": 4, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3669, "end_char": 4828, "estimated_token_count": 308, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy a Basic Contract__\n\n    ---\n\n    Ready to start using Hardhat? Learn how to compile, test, and deploy a basic contract.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to Polkadot Hub using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT__\n\n    ---\n\n    Walk through deploying an NFT to Polkadot Hub using Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-hardhat/)\n\n-   <span class=\"badge guide\">Guide</span> __Create a DApp__\n\n    ---\n\n    Learn step-by-step how to build a fully functional dApp that interacts with a smart contract deployed via Hardhat.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/dapps/zero-to-hero/)\n\n</div>"}
{"page_id": "smart-contracts-dev-environments-local-dev-node", "page_title": "Local Development Node", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 26, "end_char": 529, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nA local development node provides an isolated blockchain environment where you can deploy, test, and debug smart contracts without incurring network fees or waiting for block confirmations. This guide demonstrates how to set up a local Polkadot SDK-based node with smart contract capabilities.\n\nBy the end of this guide, you'll have:\n\n- A running node with smart contract support.\n- An ETH-RPC adapter for Ethereum-compatible tooling integration accessible at `http://localhost:8545`."}
{"page_id": "smart-contracts-dev-environments-local-dev-node", "page_title": "Local Development Node", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 529, "end_char": 858, "estimated_token_count": 76, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have done the following:\n\n- Completed the [Install Polkadot SDK Dependencies](/parachains/install-polkadot-sdk/){target=\\_blank} guide and successfully installed [Rust](https://rust-lang.org/){target=\\_blank} and the required packages to set up your development environment."}
{"page_id": "smart-contracts-dev-environments-local-dev-node", "page_title": "Local Development Node", "index": 2, "depth": 2, "title": "Install the Revive Dev Node and ETH-RPC Adapter", "anchor": "install-the-revive-dev-node-and-eth-rpc-adapter", "start_char": 858, "end_char": 2337, "estimated_token_count": 340, "token_estimator": "heuristic-v1", "text": "## Install the Revive Dev Node and ETH-RPC Adapter\n\nThe Polkadot SDK repository contains both the [Revive Dev node](https://github.com/paritytech/polkadot-sdk/tree/8e2b6f742a38bb13688e12abacded0aab2dbbb23/substrate/frame/revive/dev-node){target=\\_blank} implementation and the [ETH-RPC adapter](https://github.com/paritytech/polkadot-sdk/tree/8e2b6f742a38bb13688e12abacded0aab2dbbb23/substrate/frame/revive/rpc){target=\\_blank} required for Ethereum compatibility. Start by cloning the repository and navigating to the project directory:\n\n```bash\ngit clone https://github.com/paritytech/polkadot-sdk.git\ncd polkadot-sdk\n```\n\nNext, you need to compile the two essential components for your development environment. The Substrate node provides the core blockchain runtime with smart contract support, while the ETH-RPC adapter enables Ethereum JSON-RPC compatibility for existing tooling:\n\n```bash\ncargo build -p revive-dev-node --bin revive-dev-node --release\ncargo build -p pallet-revive-eth-rpc --bin eth-rpc --release\n```\n\nThe compilation process may take some time depending on your system specifications, potentially up to 30 minutes. Release builds are optimized for performance but take longer to compile than debug builds. After successful compilation, you can verify the binaries are available in the `target/release` directory:\n\n- **Revive Dev node path**: `polkadot-sdk/target/release/revive-dev-node`\n- **ETH-RPC adapter path**: `polkadot-sdk/target/release/eth-rpc`"}
{"page_id": "smart-contracts-dev-environments-local-dev-node", "page_title": "Local Development Node", "index": 3, "depth": 2, "title": "Run the Local Node", "anchor": "run-the-local-node", "start_char": 2337, "end_char": 8828, "estimated_token_count": 1912, "token_estimator": "heuristic-v1", "text": "## Run the Local Node\n\nWith the binaries compiled, you can now start your local development environment. The setup requires running two processes.\n\nStart the node first, which will initialize a local blockchain with the `dev` chain specification. This configuration includes `pallet-revive` for smart contract functionality and uses pre-funded development accounts for testing:\n\n```bash\n./target/release/revive-dev-node --dev\n```\n\nThe node will begin producing blocks immediately and display initialization logs:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>./target/release/revive-dev-node --dev</span>\n  <br />\n  <span data-ty>2025-05-29 10:42:35 Substrate Node</span>\n  <span data-ty>2025-05-29 10:42:35 âœŒï¸ version 3.0.0-dev-38b7581fc04</span>\n  <span data-ty>2025-05-29 10:42:35 â¤ï¸ by Parity Technologies &lt;admin@parity.io&gt;, 2017-2025</span>\n  <span data-ty>2025-05-29 10:42:35 ðŸ“‹ Chain specification: Development</span>\n  <span data-ty>2025-05-29 10:42:35 ðŸ· Node name: annoyed-aunt-3163</span>\n  <span data-ty>2025-05-29 10:42:35 ðŸ‘¤ Role: AUTHORITY</span>\n  <span data-ty>2025-05-29 10:42:35 ðŸ’¾ Database: RocksDb at /var/folders/x0/xl_kjddj3ql3bx7752yr09hc0000gn/T/substrate2P85EF/chains/dev/db/full</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ”¨ Initializing Genesis block/state (state: 0xfc05â€¦482e, header-hash: 0x1ae1â€¦b8b4)</span>\n  <span data-ty>2025-05-29 10:42:40 Creating transaction pool txpool_type=SingleState ready=Limit { count: 8192, total_bytes: 20971520 } future=Limit { count: 819, total_bytes: 2097152 }</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ‘´ Loading GRANDPA authority set from genesis on what appears to be first startup.</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ‘¶ Creating empty BABE epoch changes on what appears to be first startup.</span>\n  <span data-ty>2025-05-29 10:42:40 Using default protocol ID \"sup\" because none is configured in the chain specs</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ· Local node identity is: 12D3KooWAH8fgJv3hce7Yv4yKG4YXQiRqESFu6755DBnfZQU8Znm</span>\n  <span data-ty>2025-05-29 10:42:40 Running libp2p network backend</span>\n  <span data-ty>2025-05-29 10:42:40 local_peer_id=12D3KooWAH8fgJv3hce7Yv4yKG4YXQiRqESFu6755DBnfZQU8Znm</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ’» Operating system: macos</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ’» CPU architecture: aarch64</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ“¦ Highest known block at #0</span>\n  <span data-ty>2025-05-29 10:42:40 Error binding to '127.0.0.1:9615': Os { code: 48, kind: AddrInUse, message: \"Address already in use\" }</span>\n  <span data-ty>2025-05-29 10:42:40 Running JSON-RPC server: addr=127.0.0.1:63333,[::1]:63334</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ CPU single core score: 1.24 GiBs, parallelism score: 1.08 GiBs with expected cores: 8</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ Memory score: 49.42 GiBs</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ Disk score (seq. writes): 1.91 GiBs</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ Disk score (rand. writes): 529.02 MiBs</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ‘¶ Starting BABE Authorship worker</span>\n  <span data-ty>2025-05-29 10:42:40 ðŸ¥© BEEFY gadget waiting for BEEFY pallet to become available...</span>\n  <span data-ty>2025-05-29 10:42:40 Failed to trigger bootstrap: No known peers.</span>\n  <span data-ty>2025-05-29 10:42:42 ðŸ™Œ Starting consensus session on top of parent 0x1ae19030b13592b5e6fd326f26efc7b31a4f588303d348ef89ae9ebca613b8b4 (#0)</span>\n  <span data-ty>2025-05-29 10:42:42 ðŸŽ Prepared block for proposing at 1 (5 ms) hash: 0xe046f22307fba58a3bd0cc21b1a057843d4342da8876fd44aba206f124528df0; parent_hash: 0x1ae1â€¦b8b4; end: NoMoreTransactions; extrinsics_count: 2</span>\n  <span data-ty>2025-05-29 10:42:42 ðŸ”– Pre-sealed block for proposal at 1. Hash now 0xa88d36087e7bf8ee59c1b17e0003092accf131ff8353a620410d7283657ce36a, previously 0xe046f22307fba58a3bd0cc21b1a057843d4342da8876fd44aba206f124528df0.</span>\n  <span data-ty>2025-05-29 10:42:42 ðŸ‘¶ New epoch 0 launching at block 0xa88dâ€¦e36a (block slot 582842054 >= start slot 582842054).</span>\n  <span data-ty>2025-05-29 10:42:42 ðŸ‘¶ Next epoch starts at slot 582842254</span>\n  <span data-ty>2025-05-29 10:42:42 ðŸ† Imported #1 (0x1ae1â€¦b8b4 â†’ 0xa88dâ€¦e36a)</span>\n</div>\n\nFor debugging purposes or to monitor low-level operations, you can enable detailed logging by setting environment variables before running the command:\n\n```bash\nRUST_LOG=\"error,evm=debug,sc_rpc_server=info,runtime::revive=debug\" ./target/release/revive-dev-node --dev\n```\n\nOnce the node is running, open a new terminal window and start the ETH-RPC adapter. This component translates Ethereum JSON-RPC calls into Substrate-compatible requests, allowing you to use familiar Ethereum tools like MetaMask, Hardhat, or Ethers.js:\n\n```bash\n./target/release/eth-rpc --dev\n```\n\nYou should see logs indicating that the adapter is ready to accept connections:\n\n<div id=\"termynal\" data-termynal>\n  <span data-ty=\"input\"><span class=\"file-path\"></span>./target/release/eth-rpc --dev</span>\n  <br />\n  <span data-ty>2025-05-29 10:48:48 Running in --dev mode, RPC CORS has been disabled.</span>\n  <span data-ty>2025-05-29 10:48:48 Running in --dev mode, RPC CORS has been disabled.</span>\n  <span data-ty>2025-05-29 10:48:48 ðŸŒ Connecting to node at: ws://127.0.0.1:9944 ...</span>\n  <span data-ty>2025-05-29 10:48:48 ðŸŒŸ Connected to node at: ws://127.0.0.1:9944</span>\n  <span data-ty>2025-05-29 10:48:48 ðŸ’¾ Using in-memory database, keeping only 256 blocks in memory</span>\n  <span data-ty>2025-05-29 10:48:48 ã€½ï¸ Prometheus exporter started at 127.0.0.1:9616</span>\n  <span data-ty>2025-05-29 10:48:48 Running JSON-RPC server: addr=127.0.0.1:8545,[::1]:8545</span>\n  <span data-ty>2025-05-29 10:48:48 ðŸ”Œ Subscribing to new blocks (BestBlocks)</span>\n  <span data-ty>2025-05-29 10:48:48 ðŸ”Œ Subscribing to new blocks (FinalizedBlocks)</span>\n</div>\n\nSimilar to the Revive Dev node, you can enable detailed logging for the ETH-RPC adapter to troubleshoot issues:\n\n```bash\nRUST_LOG=\"info,eth-rpc=debug\" ./target/release/eth-rpc --dev\n```\n\nYour local development environment is now active and accessible at `http://localhost:8545`. This endpoint accepts standard Ethereum JSON-RPC requests, enabling seamless integration with existing Ethereum development tools and workflows. \n\nYou can connect wallets, deploy contracts using Remix or Hardhat, and interact with your smart contracts as you would on any Ethereum-compatible network."}
{"page_id": "smart-contracts-dev-environments-remix", "page_title": "Use the Remix IDE on Polkadot Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 462, "estimated_token_count": 98, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Remix](https://remix.ethereum.org/){target=\\_blank} is a browser-based IDE that makes it easy to write, compile, and deploy smart contracts without installing any local tools. Itâ€™s a great place to experiment, learn, and quickly test contracts on Polkadot. This page introduces the main parts of the Remix interface and shows how to connect it to Polkadot so you can deploy and interact with contracts directly from your browser."}
{"page_id": "smart-contracts-dev-environments-remix", "page_title": "Use the Remix IDE on Polkadot Hub", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 462, "end_char": 765, "estimated_token_count": 73, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have:\n\n- A browser with the [MetaMask](https://metamask.io/){target=\\_blank} extension installed\n- MetaMask connected to Polkadot (see the [Wallet Integrations](/smart-contracts/integrations/wallets/#metamask){target=\\_blank} guide for setup steps)"}
{"page_id": "smart-contracts-dev-environments-remix", "page_title": "Use the Remix IDE on Polkadot Hub", "index": 2, "depth": 2, "title": "Access Remix IDE", "anchor": "access-remix-ide", "start_char": 765, "end_char": 2656, "estimated_token_count": 412, "token_estimator": "heuristic-v1", "text": "## Access Remix IDE\n\nNavigate to [https://remix.ethereum.org/](https://remix.ethereum.org/){target=\\_blank}. The interface will load with a default workspace containing sample contracts. In this interface, you can access the following:\n\n- **Editor panel**: The main coding area where you write and modify your smart contract files. Supports syntax highlighting, auto-completion, and linting.\n- **Terminal**: Shows logs from the compiler, deployment events, transactions, and console.log output. Useful for debugging and tracking execution.\n- **Plugin panel**: Displays icons for each of the preloaded plugins, the plugin manager, and the settings menu. You'll see a few icons there for each of the preloaded plugins:\n\n    - **File explorer**: Displays your project workspace. You can create, open, rename, and organize Solidity files, scripts, and folders.\n    - **File search**: A quick search tool for finding symbols, functions, or text within your project files.\n    - **Solidity compiler**: A plugin that compiles your Solidity contracts. It allows you to select compiler versions, enable optimizations, and view compilation errors or warnings.\n    - **Deploy & run transactions**: Used to deploy contracts and interact with them. Allows you to choose an environment (JavaScript VM, injected provider, or custom RPC), deploy contracts, send transactions, and call read/write functions.\n    - **Debugger**: Allows you to step through a transaction execution line-by-line. You can inspect variables, stack values, storage slots, and opcodes to understand exactly how your contract behaved during a specific transaction.\n    - **Git**: Enables basic Git version control directly inside Remix. You can initialize repositories, view diffs, commit changes, and browse project history without needing an external Git client.\n\n![](/images/smart-contracts/dev-environments/remix/remix-01.webp)"}
{"page_id": "smart-contracts-dev-environments-remix", "page_title": "Use the Remix IDE on Polkadot Hub", "index": 3, "depth": 2, "title": "Connect Remix to Polkadot", "anchor": "connect-remix-to-polkadot", "start_char": 2656, "end_char": 3336, "estimated_token_count": 162, "token_estimator": "heuristic-v1", "text": "## Connect Remix to Polkadot\n\nYou can connect Remix to Polkadot from the **Deploy & run transactions** tab in the plugin panel:\n\n1. Switch your MetaMask network to Polkadot. For detailed steps on setting up MetaMask for Polkadot, see the [Wallet Integrations](/smart-contracts/integrations/wallets/#metamask){target=\\_blank} guide.\n2. Click on the **Environment** dropdown.\n3. Hover over **browser extension**.\n4. Select **Injected Provider - MetaMask**.\n\n![](/images/smart-contracts/dev-environments/remix/remix-02.webp)\n\nOnce connected, Remix will display your MetaMask account address under **Accounts**. To switch accounts, change it in MetaMaskâ€”Remix updates automatically."}
{"page_id": "smart-contracts-dev-environments-remix", "page_title": "Use the Remix IDE on Polkadot Hub", "index": 4, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 3336, "end_char": 4200, "estimated_token_count": 234, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Deploy a Basic Contract__\n\n    ---\n\n    Ready to start using Remix? Learn how to compile, test, and deploy a basic contract.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an ERC-20__\n\n    ---\n\n    Walk through deploying a fully-functional ERC-20 to Polkadot Hub using Remix.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/)\n\n-   <span class=\"badge guide\">Guide</span> __Deploy an NFT__\n\n    ---\n\n    Walk through deploying an NFT to Polkadot Hub using Remix.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/)\n\n</div>"}
{"page_id": "smart-contracts-explorers", "page_title": "Block Explorers", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 19, "end_char": 327, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nBlock explorers serve as comprehensive blockchain analytics platforms that provide access to on-chain data. These web applications function as search engines for blockchain networks, allowing users to query, visualize, and analyze blockchain data in real time through intuitive interfaces."}
{"page_id": "smart-contracts-explorers", "page_title": "Block Explorers", "index": 1, "depth": 2, "title": "Core Functionality", "anchor": "core-functionality", "start_char": 327, "end_char": 1017, "estimated_token_count": 139, "token_estimator": "heuristic-v1", "text": "## Core Functionality\n\nThese block explorers provide essential capabilities for interacting with smart contracts in Polkadot Hub:\n\n- **Transaction tracking**: Monitor transaction status, confirmations, fees, and metadata.\n- **Address analysis**: View account balances, transaction history, and associated contracts.\n- **Block information**: Examine block contents.\n- **Smart contract interaction**: Review contract code, verification status, and interaction history.\n- **Token tracking**: Monitor ERC-20, ERC-721, and other token standards with transfer history and holder analytics.\n- **Network statistics**: Access metrics on transaction volume, gas usage, and other network parameters."}
{"page_id": "smart-contracts-explorers", "page_title": "Block Explorers", "index": 2, "depth": 2, "title": "Available Block Explorers", "anchor": "available-block-explorers", "start_char": 1017, "end_char": 1229, "estimated_token_count": 30, "token_estimator": "heuristic-v1", "text": "## Available Block Explorers\n\nThe following block explorers are available for PolkaVM smart contracts, providing specialized tools for monitoring and analyzing contract activity within the Polkadot ecosystem."}
{"page_id": "smart-contracts-explorers", "page_title": "Block Explorers", "index": 3, "depth": 3, "title": "BlockScout", "anchor": "blockscout", "start_char": 1229, "end_char": 1618, "estimated_token_count": 89, "token_estimator": "heuristic-v1", "text": "### BlockScout\n\nBlockScout is an open-source explorer platform with a user-friendly interface adapted for PolkaVM contracts. It excels at detailed contract analytics and provides developers with comprehensive API access.\n\n- [Polkadot Hub TestNet BlockScout](https://blockscout-passet-hub.parity-testnet.parity.io/){target=\\_blank}\n\n![](/images/smart-contracts/explorers/explorers-01.webp)"}
{"page_id": "smart-contracts-faucet", "page_title": "Get Tokens from the Official Faucet", "index": 0, "depth": 2, "title": "Get Test Tokens", "anchor": "get-test-tokens", "start_char": 473, "end_char": 1160, "estimated_token_count": 182, "token_estimator": "heuristic-v1", "text": "## Get Test Tokens\n\nFor Polkadot Hub TestNet, you can use the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank} to obtain test tokens. Here's how to do it:\n\n1. Navigate to the [Polkadot Faucet](https://faucet.polkadot.io/?parachain=1111){target=\\_blank}. If the desired network is not already selected, choose it from the **Network** drop-down. This example uses the Polkadot Hub TestNet.\n2. Copy your address linked to the TestNet and paste it into the designated field.\n3. Click the **Get Some PASs** button to request free test PAS tokens. These tokens will be sent to your wallet shortly.\n\n![Polkadot Faucet](/images/smart-contracts/faucet/faucet-1.gif)"}
{"page_id": "smart-contracts-faucet", "page_title": "Get Tokens from the Official Faucet", "index": 1, "depth": 2, "title": "Things to Consider", "anchor": "things-to-consider", "start_char": 1160, "end_char": 1584, "estimated_token_count": 79, "token_estimator": "heuristic-v1", "text": "## Things to Consider\n\n!!! info \"Rate Limiting\"\n    Faucets typically implement rate limiting to prevent abuse. You may need to wait between requests if you've recently obtained tokens from the same faucet.\n\n!!! warning \"Network Compatibility\"\n    Ensure your wallet is connected to the correct network (Polkadot Hub TestNet) before requesting tokens. Tokens sent to addresses on different networks will not be accessible."}
{"page_id": "smart-contracts-faucet", "page_title": "Get Tokens from the Official Faucet", "index": 2, "depth": 2, "title": "Using Your Test Tokens", "anchor": "using-your-test-tokens", "start_char": 1584, "end_char": 1890, "estimated_token_count": 52, "token_estimator": "heuristic-v1", "text": "## Using Your Test Tokens\n\nGetting started with test tokens is the first step in your Polkadot development journey. These free resources enable you to build, experiment with, and refine your applications without financial constraints, ensuring your projects are robust and ready for deployment on MainNet."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 37, "end_char": 303, "estimated_token_count": 40, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThis guide helps Ethereum developers migrate their smart contracts to Polkadot Hub. Most contracts work without modifications on the REVM backend, while the PolkaVM backend offers enhanced performance with minimal adaptation for standard patterns."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 1, "depth": 2, "title": "Migration Considerations", "anchor": "migration-considerations", "start_char": 303, "end_char": 645, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "## Migration Considerations\n\nTake into account the following considerations before migrating your contracts:\n\n- Standard ERC-20, ERC-721, ERC-1155 tokens work without changes.\n- DeFi protocols, DEXs, and AMMs migrate seamlessly.\n- DAOs and governance contracts are fully compatible.\n- Most Solidity contracts deploy identically to Ethereum."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 2, "depth": 2, "title": "Migration Checklist", "anchor": "migration-checklist", "start_char": 645, "end_char": 1058, "estimated_token_count": 81, "token_estimator": "heuristic-v1", "text": "## Migration Checklist\n\nBefore migrating your contracts, review this checklist:\n\n- Factory contracts using PVM bytecode need pre-uploaded dependencies.\n- Contracts using `EXTCODECOPY` for runtime manipulation require review (for projects that will use PVM bytecode, not EVM bytecode).\n- Replace `transfer()` and `send()` with proper reentrancy guards (for projects that will use PVM bytecode, not EVM bytecode)."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 3, "depth": 2, "title": "Migration FAQs", "anchor": "migration-faqs", "start_char": 1058, "end_char": 1077, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Migration FAQs"}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 4, "depth": 3, "title": "Which backend should I choose?", "anchor": "which-backend-should-i-choose", "start_char": 1077, "end_char": 1706, "estimated_token_count": 107, "token_estimator": "heuristic-v1", "text": "### Which backend should I choose?\n\n- Choose REVM if you want:\n\n    - Zero-modification deployment of existing Ethereum contracts.\n    - Exact EVM behavior for audited code.\n    - Compatibility with tools that inspect EVM bytecode.\n    - Rapid deployment without optimization.\n\n- Choose PolkaVM if you want:\n\n    - Better performance for computation-heavy applications.\n    - Lower execution costs for intensive operations.\n    - Access to next-generation smart contract features.\n\nIf you are unsure which to choose, start with REVM for immediate compatibility, then consider PolkaVM for performance optimization once deployed."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 5, "depth": 3, "title": "Do I need to rewrite my Solidity code?", "anchor": "do-i-need-to-rewrite-my-solidity-code", "start_char": 1706, "end_char": 1825, "estimated_token_count": 26, "token_estimator": "heuristic-v1", "text": "### Do I need to rewrite my Solidity code?\n\nNo, for most contracts. Standard Solidity patterns work on both backends."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 6, "depth": 3, "title": "What about factory contracts?", "anchor": "what-about-factory-contracts", "start_char": 1825, "end_char": 3177, "estimated_token_count": 244, "token_estimator": "heuristic-v1", "text": "### What about factory contracts?\n\n- **REVM**: Factory contracts work identically to Ethereum with no changes needed. \n    \n    The original factory pattern is:\n\n    ```solidity\n    contract TokenFactory {\n        function createToken(string memory name) public returns (address) {\n            // Creates new contract at runtime\n            Token newToken = new Token(name);\n            return address(newToken);\n        }\n    }\n    ```\n\n- **PolkaVM**: Factory contracts require pre-uploading dependent contracts. \n\n    Here's how to adapt the original factory pattern:\n\n    ```solidity\n    contract TokenFactory {\n        // Reference pre-uploaded Token contract by hash\n        bytes32 public tokenCodeHash;\n        \n        constructor(bytes32 _tokenCodeHash) {\n            tokenCodeHash = _tokenCodeHash;\n        }\n        \n        function createToken(string memory name) public returns (address) {\n            // Instantiate from pre-uploaded code\n            Token newToken = new Token{salt: keccak256(abi.encode(name))}(name);\n            return address(newToken);\n        }\n    }\n    ```\n\nThe deployment steps for PolkaVM factories are:\n\n1. Upload the contract code to the chain.\n2. Note the returned code hash.\n3. Deploy the Factory contract with the contract code hash.\n4. Factory can now instantiate contracts using the pre-uploaded code."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 7, "depth": 3, "title": "How do gas costs compare?", "anchor": "how-do-gas-costs-compare", "start_char": 3177, "end_char": 3328, "estimated_token_count": 47, "token_estimator": "heuristic-v1", "text": "### How do gas costs compare?\n\nFor more information on gas costs, see the [Gas Model](/smart-contracts/for-eth-devs/gas-model/){target=\\_blank} page."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 8, "depth": 3, "title": "Which Solidity features are not supported?", "anchor": "which-solidity-features-are-not-supported", "start_char": 3328, "end_char": 3915, "estimated_token_count": 133, "token_estimator": "heuristic-v1", "text": "### Which Solidity features are not supported?\n\nFor REVM, any Solidity feature will function smoothly without requiring changes or adaptations. For PVM, there are considerations, as was mentioned above. \n\nFor PolkaVM, there are some considerations:\n\n- `EXTCODECOPY`: Only works in constructor code.\n- Runtime code modification: Use on-chain constructors instead.\n- **Gas stipends**: `address.send()` and `address.transfer()` don't provide reentrancy protection.\n- **Unsupported operations**: `pc`, `extcodecopy`, `selfdestruct`, `blobhash`, and `blobbasefee` (blob-related operations)."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 9, "depth": 3, "title": "How do I handle the existential deposit?", "anchor": "how-do-i-handle-the-existential-deposit", "start_char": 3915, "end_char": 4518, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### How do I handle the existential deposit?\n\nPolkadot requires accounts to maintain a minimum balance (existential deposit or ED) to remain active.\n\nThis is handled automatically for you:\n\n- Balance queries via Ethereum RPC automatically deduct the ED.\n- New account transfers include ED in transaction fees.\n- Contract-to-contract transfers draw ED from the transaction signer.\n\nYou typically don't need to do anything special, but be aware:\n\n- Accounts below ED threshold are automatically deleted.\n- ED is around 0.01 DOT (varies by network).\n- Your contracts don't need to manage this explicitly."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 10, "depth": 3, "title": "Can I use my existing development tools?", "anchor": "can-i-use-my-existing-development-tools", "start_char": 4518, "end_char": 5331, "estimated_token_count": 261, "token_estimator": "heuristic-v1", "text": "### Can I use my existing development tools?\n\nYes. Both backends support:\n\n- **Wallets**: [MetaMask](https://metamask.io/){target=\\_blank}, [Talisman](https://talisman.xyz/){target=\\_blank}, [SubWallet](https://www.subwallet.app/){target=\\_blank}\n- **Development frameworks**: [Hardhat](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-hardhat/){target=\\_blank}, [Remix](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/){target=\\_blank}\n- **Libraries**: [Ethers.js](/smart-contracts/libraries/ethers-js/){target=\\_blank}, [Web3.js](/smart-contracts/libraries/web3-js/){target=\\_blank}, [viem](/smart-contracts/libraries/viem/){target=\\_blank}\n- **Testing tools**: Your existing test suites work\n\nConnect to Polkadot Hub's Ethereum JSON-RPC endpoint and use your familiar workflow."}
{"page_id": "smart-contracts-for-eth-devs-.migration", "page_title": "Migration FAQs and Considerations", "index": 11, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 5331, "end_char": 6079, "estimated_token_count": 153, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nMost Ethereum contracts migrate to Polkadot Hub with minimal or no changes. Use REVM for seamless compatibility or PolkaVM for enhanced performance.\n\nThere are a few key points to keep in mind during migration:\n\n- Replace `transfer()` and `send()` with `.call{value}(\"\")` and use reentrancy guards (for projects that will use PVM bytecode, not EVM bytecode).\n- PolkaVM factory contracts using PVM bytecode need pre-uploaded dependencies.\n- Don't hardcode gas values.\n- Test thoroughly on [TestNet](/smart-contracts/connect/#__tabbed_1_1){target=\\_blank} before mainnet deployment.\n\nYour existing Solidity knowledge and tooling transfer directly to Polkadot Hub, making migration straightforward for standard smart contract patterns."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 41, "end_char": 885, "estimated_token_count": 149, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAsset Hub natively utilizes Polkadot's 32-byte account system while providing interoperability with Ethereum's 20-byte addresses through an automatic conversion system. When interacting with smart contracts:\n\n- Ethereum-compatible wallets (like MetaMask) can use their familiar 20-byte addresses.\n- Polkadot accounts continue using their native 32-byte format.\n- The Asset Hub chain automatically handles conversion between the two formats behind the scenes:\n\n    - 20-byte Ethereum addresses are padded with `0xEE` bytes to create valid 32-byte Polkadot accounts.\n    - 32-byte Polkadot accounts can optionally register a mapping to a 20-byte address for Ethereum compatibility.\n\nThis dual-format approach enables Asset Hub to maintain compatibility with Ethereum tooling while fully integrating with the Polkadot ecosystem."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 1, "depth": 2, "title": "Address Types and Mappings", "anchor": "address-types-and-mappings", "start_char": 885, "end_char": 1223, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## Address Types and Mappings\n\nThe platform handles two distinct address formats:\n\n- [Ethereum-style addresses (20 bytes)](https://ethereum.org/developers/docs/accounts/#account-creation){target=\\_blank}\n- [Polkadot native account IDs (32 bytes)](https://wiki.polkadot.com/learn/learn-account-advanced/#address-format){target=\\_blank}"}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 2, "depth": 3, "title": "Ethereum to Polkadot Mapping", "anchor": "ethereum-to-polkadot-mapping", "start_char": 1223, "end_char": 2268, "estimated_token_count": 237, "token_estimator": "heuristic-v1", "text": "### Ethereum to Polkadot Mapping\n\nThe [`AccountId32Mapper`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/struct.AccountId32Mapper.html){target=\\_blank} implementation in [`pallet_revive`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/index.html){target=\\_blank} handles the core address conversion logic. For converting a 20-byte Ethereum address to a 32-byte Polkadot address, the pallet uses a simple concatenation approach:\n\n- [**Core mechanism**](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_fallback_account_id){target=\\_blank}: Takes a 20-byte Ethereum address and extends it to 32 bytes by adding twelve `0xEE` bytes at the end. The key benefits of this approach are:\n    - Able to fully revert, allowing a smooth transition back to the Ethereum format.\n    - Provides clear identification of Ethereum-controlled accounts through the `0xEE` suffix pattern.\n    - Maintains cryptographic security with a `2^96` difficulty for pattern reproduction."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 3, "depth": 3, "title": "Polkadot to Ethereum Mapping", "anchor": "polkadot-to-ethereum-mapping", "start_char": 2268, "end_char": 4597, "estimated_token_count": 517, "token_estimator": "heuristic-v1", "text": "### Polkadot to Ethereum Mapping\n\nThe conversion from 32-byte Polkadot accounts to 20-byte Ethereum addresses is more complex than the reverse direction due to the lossy nature of the conversion. The [`AccountId32Mapper`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/struct.AccountId32Mapper.html){target=\\_blank} handles this through two distinct approaches:\n\n- **For Ethereum-derived accounts**: The system uses the [`is_eth_derived`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/fn.is_eth_derived.html){target=\\_blank} function to detect accounts that were originally Ethereum addresses (identified by the `0xEE` suffix pattern). For these accounts, the conversion strips the last 12 bytes to recover the original 20-byte Ethereum address.\n\n- **For native Polkadot accounts**: Since these accounts utilize the whole 32-byte space and weren't derived from Ethereum addresses, direct truncation would result in lost information. Instead, the system:\n\n    1. Hashes the entire 32-byte account using Keccak-256.\n    2. Takes the last 20 bytes of the hash to create the Ethereum address.\n    3. This ensures a deterministic mapping while avoiding simple truncation.\n\nThe conversion process is implemented through the [`to_address`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_address){target=\\_blank} function, which automatically detects the account type and applies the appropriate conversion method.\n\n**Stateful Mapping for Reversibility** : Since the conversion from 32-byte to 20-byte addresses is inherently lossy, the system provides an optional stateful mapping through the [`OriginalAccount`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/storage_types/struct.OriginalAccount.html){target=\\_blank} storage. When a Polkadot account registers a mapping (via the [`map`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.map){target=\\_blank} function), the system stores the original 32-byte account ID, enabling the [`to_account_id`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_account_id){target=\\_blank} function to recover the exact original account rather than falling back to a default conversion."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 4, "depth": 3, "title": "Account Mapping for Native Polkadot Accounts", "anchor": "account-mapping-for-native-polkadot-accounts", "start_char": 4597, "end_char": 5765, "estimated_token_count": 250, "token_estimator": "heuristic-v1", "text": "### Account Mapping for Native Polkadot Accounts\n\nIf you have a native Polkadot account (32-byte format) that was created with a Polkadot/Substrate keypair (Ed25519/Sr25519) rather than an Ethereum-compatible keypair (secp256k1), you'll need to map your account to enable Ethereum compatibility.\n\nTo map your account, call the [`map_account`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/dispatchables/fn.map_account.html){target=\\_blank} extrinsic of the [`pallet_revive`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/index.html){target=\\_blank} pallet using your original Substrate account. This creates a stateful mapping that allows your 32-byte account to interact with the Ethereum-compatible smart contract system.\n\nOnce mapped, you'll be able to:\n\n- Transfer funds between 20-byte format addresses.\n- Interact with smart contracts using Ethereum-compatible tools like MetaMask.\n- Maintain full reversibility to your original 32-byte account format.\n\n!!! warning \"Mapping Requirement\"\n    Without this mapping, native Polkadot accounts cannot transfer funds or interact with the Ethereum-compatible layer on the Hub."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 5, "depth": 2, "title": "Account Registration", "anchor": "account-registration", "start_char": 5765, "end_char": 6210, "estimated_token_count": 94, "token_estimator": "heuristic-v1", "text": "## Account Registration\n\nThe registration process is implemented through the [`map`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.map){target=\\_blank} function. This process involves:\n\n- Checking if the account is already mapped.\n- Calculating and collecting required deposits based on data size.\n- Storing the address suffix for future reference.\n- Managing the currency holds for security."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 6, "depth": 2, "title": "Fallback Accounts", "anchor": "fallback-accounts", "start_char": 6210, "end_char": 6664, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Fallback Accounts\n\nThe fallback mechanism is integrated into the [`to_account_id`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_account_id){target=\\_blank} function. It provides a safety net for address conversion by:\n\n- First, attempting to retrieve stored mapping data.\n- Falling back to the default conversion method if no mapping exists.\n- Maintaining consistency in address representation."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 7, "depth": 2, "title": "Contract Address Generation", "anchor": "contract-address-generation", "start_char": 6664, "end_char": 7262, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Contract Address Generation\n\nThe system supports two methods for generating contract addresses:\n\n- [CREATE1 method](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/fn.create1.html){target=\\_blank}:\n\n    - Uses the deployer address and nonce.\n    - Generates deterministic addresses for standard contract deployment.\n\n- [CREATE2 method](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/fn.create2.html){target=\\_blank}:\n\n    - Uses the deployer address, initialization code, input data, and salt.\n    - Enables predictable address generation for advanced use cases."}
{"page_id": "smart-contracts-for-eth-devs-accounts", "page_title": "Accounts in Asset Hub Smart Contracts", "index": 8, "depth": 2, "title": "Security Considerations", "anchor": "security-considerations", "start_char": 7262, "end_char": 8392, "estimated_token_count": 268, "token_estimator": "heuristic-v1", "text": "## Security Considerations\n\nThe address mapping system maintains security through several design choices evident in the implementation:\n\n- The stateless mapping requires no privileged operations, as shown in the [`to_fallback_account_id`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/trait.AddressMapper.html#tymethod.to_fallback_account_id){target=\\_blank} implementation.\n- The stateful mapping requires a deposit managed through the [`Currency`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/trait.Config.html#associatedtype.Currency){target=\\_blank} trait.\n- Mapping operations are protected against common errors through explicit checks.\n- The system prevents double-mapping through the [`ensure!(!Self::is_mapped(account_id))`](https://github.com/paritytech/polkadot-sdk/blob/stable2412/substrate/frame/revive/src/address.rs#L125){target=\\_blank} check.\n\nAll source code references are from the [`address.rs`](https://github.com/paritytech/polkadot-sdk/blob/stable2412/substrate/frame/revive/src/address.rs){target=\\_blank} file in the Revive pallet of the Polkadot SDK repository."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 34, "end_char": 478, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nAsset Hub smart contracts operate within the Polkadot ecosystem using the [`pallet_revive`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/){target=\\_blank} implementation, which provides EVM compatibility. While many aspects of blocks and transactions are inherited from the underlying parachain architecture, there are specific considerations and mechanisms unique to smart contract operations on Asset Hub."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 1, "depth": 2, "title": "Smart Contract Blocks", "anchor": "smart-contract-blocks", "start_char": 478, "end_char": 1101, "estimated_token_count": 131, "token_estimator": "heuristic-v1", "text": "## Smart Contract Blocks\n\nSmart contract blocks in Asset Hub follow the same fundamental structure as parachain blocks, inheriting all standard parachain block components. The `pallet_revive` implementation maintains this consistency while adding necessary [EVM-specific features](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm){target=\\_blank}. For detailed implementation specifics, the [`Block`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Block.html){target=\\_blank} struct in `pallet_revive` demonstrates how parachain and smart contract block implementations align."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 2, "depth": 2, "title": "Smart Contract Transactions", "anchor": "smart-contract-transactions", "start_char": 1101, "end_char": 1325, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Smart Contract Transactions\n\nAsset Hub implements a sophisticated transaction system that supports various transaction types and formats, encompassing both traditional parachain operations and EVM-specific interactions."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 3, "depth": 3, "title": "EVM Transaction Types", "anchor": "evm-transaction-types", "start_char": 1325, "end_char": 3375, "estimated_token_count": 437, "token_estimator": "heuristic-v1", "text": "### EVM Transaction Types\n\nThe system provides a fundamental [`eth_transact`](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/pallet/dispatchables/fn.eth_transact.html){target=\\_blank} interface for processing raw EVM transactions dispatched through [Ethereum JSON-RPC APIs](/smart-contracts/for-eth-devs/json-rpc-apis/){target=\\_blank}. This interface acts as a wrapper for Ethereum transactions, requiring an encoded signed transaction payload, though it cannot be dispatched directly. Building upon this foundation, the system supports multiple transaction formats to accommodate different use cases and optimization needs:\n\n- **[Legacy transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.TransactionLegacyUnsigned.html){target=\\_blank}**: The original Ethereum transaction format, providing basic transfer and contract interaction capabilities. These transactions use a simple pricing mechanism and are supported for backward compatibility.\n\n- **[EIP-1559 transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Transaction1559Unsigned.html){target=\\_blank}**: An improved transaction format that introduces a more predictable fee mechanism with base fee and priority fee components. This format helps optimize gas fee estimation and network congestion management.\n\n- **[EIP-2930 transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Transaction2930Unsigned.html){target=\\_blank}**: Introduces access lists to optimize gas costs for contract interactions by pre-declaring accessed addresses and storage slots.\n\n- **[EIP-4844 transactions](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/evm/struct.Transaction4844Unsigned.html){target=\\_blank}**: Implements blob-carrying transactions, designed to optimize Layer 2 scaling solutions by providing dedicated space for roll-up data.\n\nEach transaction type can exist in both signed and unsigned states, with appropriate validation and processing mechanisms for each."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 4, "depth": 2, "title": "Fees and Gas", "anchor": "fees-and-gas", "start_char": 3375, "end_char": 3583, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Fees and Gas\n\nAsset Hub implements a sophisticated resource management system that combines parachain transaction fees with EVM gas mechanics, providing both Ethereum compatibility and enhanced features."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 5, "depth": 3, "title": "Gas Model Overview", "anchor": "gas-model-overview", "start_char": 3583, "end_char": 5246, "estimated_token_count": 292, "token_estimator": "heuristic-v1", "text": "### Gas Model Overview\n\nGas serves as the fundamental unit for measuring computational costs, with each network operation consuming a specified amount. This implementation maintains compatibility with Ethereum's approach while adding parachain-specific optimizations.\n\n- **Dynamic gas scaling**: Asset Hub implements a dynamic pricing mechanism that reflects actual execution performance. This results in:\n\n    - More efficient pricing for computational instructions relative to I/O operations.\n    - Better correlation between gas costs and actual resource consumption.\n    - Need for developers to implement flexible gas calculation rather than hardcoding values.\n\n- **Multi-dimensional resource metering**: Asset Hub extends beyond the traditional single-metric gas model to track three distinct resources.\n\n    - `ref_time` (computation time):\n\n        - Functions as traditional gas equivalent.\n        - Measures actual computational resource usage.\n        - Primary metric for basic operation costs.\n\n\n    - `proof_size` (verification overhead):\n\n        - Tracks state proof size required for validator verification.\n        - Helps manage consensus-related resource consumption.\n        - Important for cross-chain operations.\n\n\n    - `storage_deposit` (state management):\n\n        - Manages blockchain state growth.\n        - Implements a deposit-based system for long-term storage.\n        - Refundable when storage is freed.\n\nThese resources can be limited at both transaction and contract levels, similar to Ethereum's gas limits. For more information, check the [Gas Model](/smart-contracts/for-eth-devs/gas-model/){target=\\_blank} documentation."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 6, "depth": 3, "title": "Fee Components", "anchor": "fee-components", "start_char": 5246, "end_char": 5722, "estimated_token_count": 84, "token_estimator": "heuristic-v1", "text": "### Fee Components\n\n- Base fees:\n\n    - Storage deposit for contract deployment.\n    - Minimum transaction fee for network access.\n    - Network maintenance costs.\n\n- Execution fees:\n\n    - Computed based on gas consumption.\n    - Converted to native currency using network-defined rates.\n    - Reflects actual computational resource usage.\n\n- Storage fees:\n\n    - Deposit for long-term storage usage.\n    - Refundable when storage is freed.\n    - Helps prevent state bloat."}
{"page_id": "smart-contracts-for-eth-devs-blocks-transactions-fees", "page_title": "Transactions and Fees on Asset Hub", "index": 7, "depth": 3, "title": "Gas Calculation and Conversion", "anchor": "gas-calculation-and-conversion", "start_char": 5722, "end_char": 6071, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "### Gas Calculation and Conversion\n\nThe system maintains precise conversion mechanisms between:\n\n- Substrate weights and EVM gas units.\n- Native currency and gas costs.\n- Different resource metrics within the multi-dimensional model.\n\nThis ensures accurate fee calculation while maintaining compatibility with existing Ethereum tools and workflows."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 23, "end_char": 562, "estimated_token_count": 87, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's smart contract platform supports two distinct virtual machine backends: Rust Ethereum Virtual Machine (REVM) and PolkaVM. Each backend has its own deployment characteristics and optimization strategies. REVM provides full Ethereum compatibility with familiar single-step deployment, while the RISC-V-based PolkaVM uses a more structured two-step approach optimized for its architecture. Understanding these differences ensures smooth deployment regardless of which backend you choose for your smart contracts."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 1, "depth": 2, "title": "REVM Deployment", "anchor": "revm-deployment", "start_char": 562, "end_char": 1098, "estimated_token_count": 92, "token_estimator": "heuristic-v1", "text": "## REVM Deployment\n\nThe REVM backend enables seamless deployment of Ethereum contracts without modification. Contracts deploy exactly as they would on Ethereum, using familiar tools and workflows.\n\nWith REVM, deployment mirrors the Ethereum flow exactly including: \n\n- Contracts are bundled and deployed in a single transaction. \n- Factory contracts can create new contracts at runtime.\n- Runtime code generation, including inline assembly, is supported.\n- Existing familiar tools like Hardhat, Foundry, and Remix work out of the box."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 2, "depth": 2, "title": "PolkaVM Deployment", "anchor": "polkavm-deployment", "start_char": 1098, "end_char": 1370, "estimated_token_count": 40, "token_estimator": "heuristic-v1", "text": "## PolkaVM Deployment\n\nPolkaVM implements a fundamentally different deployment model optimized for its RISC-V architecture. While simple contract deployments work seamlessly, advanced patterns like factory contracts require understanding the two-step deployment process."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 3, "depth": 3, "title": "Standard Contract Deployment", "anchor": "standard-contract-deployment", "start_char": 1370, "end_char": 1717, "estimated_token_count": 70, "token_estimator": "heuristic-v1", "text": "### Standard Contract Deployment\n\nFor most use cases, such as deploying ERC-20 tokens, NFT collections, or standalone contracts, deployment is transparent and requires no special steps. The [Revive compiler](https://github.com/paritytech/revive){target=\\_blank} handles the deployment process automatically when using standard Solidity patterns."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 4, "depth": 3, "title": "Two-Step Deployment Model", "anchor": "two-step-deployment-model", "start_char": 1717, "end_char": 2131, "estimated_token_count": 76, "token_estimator": "heuristic-v1", "text": "### Two-Step Deployment Model\n\nPolkaVM separates contract deployment into distinct phases:\n\n1. **Code upload**: Contract bytecode must be uploaded to the chain before instantiation.\n2. **Contract instantiation**: Contracts are created by referencing previously uploaded code via its hash.\n\nThis architecture differs from the EVM's bundled approach and has important implications for specific deployment patterns."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 5, "depth": 3, "title": "Factory Pattern Considerations", "anchor": "factory-pattern-considerations", "start_char": 2131, "end_char": 2970, "estimated_token_count": 172, "token_estimator": "heuristic-v1", "text": "### Factory Pattern Considerations\n\nThe common EVM pattern, where contracts dynamically create other contracts, requires adaptation for PolkaVM as follows:\n\n**EVM Factory Pattern:**\n```solidity\n// This works on REVM but requires modification for PolkaVM\ncontract Factory {\n    function createToken() public returns (address) {\n        // EVM bundles bytecode in the factory\n        return address(new Token());\n    }\n}\n```\n\n**PolkaVM Requirements:**\n\n- **Pre-upload dependent contracts**: All contracts that will be instantiated at runtime must be uploaded to the chain before the factory attempts to create them.\n- **Code hash references**: Factory contracts work with pre-uploaded code hashes rather than embedding bytecode.\n- **No runtime code generation**: Dynamic bytecode generation is not supported due to PolkaVM's RISC-V format."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 6, "depth": 3, "title": "Migration Strategy for Factory Contracts", "anchor": "migration-strategy-for-factory-contracts", "start_char": 2970, "end_char": 3499, "estimated_token_count": 112, "token_estimator": "heuristic-v1", "text": "### Migration Strategy for Factory Contracts\n\nWhen migrating factory contracts from Ethereum to PolkaVM:\n\n1. **Identify all contracts**: Determine which contracts will be instantiated at runtime.\n2. **Upload dependencies first**: Deploy all dependent contracts to the chain before deploying the factory.\n3. **Use on-chain constructors**: Leverage PolkaVM's on-chain constructor feature for flexible instantiation.\n4. **Avoid assembly creation**: Don't use `create` or `create2` opcodes in assembly blocks for manual deployment."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 7, "depth": 3, "title": "Architecture-Specific Limitations", "anchor": "architecture-specific-limitations", "start_char": 3499, "end_char": 4119, "estimated_token_count": 119, "token_estimator": "heuristic-v1", "text": "### Architecture-Specific Limitations\n\nPolkaVM's deployment model creates several specific constraints:\n\n- **`EXTCODECOPY` limitations**: Contracts using `EXTCODECOPY` to manipulate code at runtime will encounter issues.\n- **Runtime code modification**: Patterns that construct and mutate contract code on-the-fly are not supported.\n- **Assembly-based factories**: Factory contracts written in YUL assembly that generate code at runtime will fail with `CodeNotFound` errors.\n\nThese patterns are rare in practice and typically require dropping down to assembly, making them non-issues for standard Solidity development."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 8, "depth": 3, "title": "On-Chain Constructors", "anchor": "on-chain-constructors", "start_char": 4119, "end_char": 4457, "estimated_token_count": 53, "token_estimator": "heuristic-v1", "text": "### On-Chain Constructors\n\nPolkaVM provides on-chain constructors as an elegant alternative to runtime code modification:\n\n- Enable contract instantiation without runtime code generation.\n- Support flexible initialization patterns.\n- Maintain separation between code upload and contract creation.\n- Provide predictable deployment costs."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 9, "depth": 2, "title": "Gas Estimation vs Actual Consumption", "anchor": "gas-estimation-vs-actual-consumption", "start_char": 4457, "end_char": 5006, "estimated_token_count": 85, "token_estimator": "heuristic-v1", "text": "## Gas Estimation vs Actual Consumption\n\nBoth REVM and PolkaVM deployments may show significant differences between gas estimation and actual consumption. You might see estimates that are several times higher than the actual gas consumed (often around 30% of the estimate). This is normal behavior because pre-dispatch estimation cannot distinguish between computation weight and storage deposits, leading to conservative overestimation. Contract deployments are particularly affected as they consume significant storage deposits for code storage."}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 10, "depth": 2, "title": "Deployment Comparison", "anchor": "deployment-comparison", "start_char": 5006, "end_char": 5561, "estimated_token_count": 158, "token_estimator": "heuristic-v1", "text": "## Deployment Comparison\n\n| Feature | REVM Backend | PolkaVM Backend |\n|:-------:|:-------------:|:----------------:|\n| **Deployment Model** | Single-step bundled | Two-step upload and instantiate |\n| **Factory Patterns** | Direct runtime creation | Requires pre-uploaded code |\n| **Code Bundling** | Bytecode in transaction | Code hash references |\n| **Runtime Codegen** | Fully supported | Not supported |\n| **Simple Contracts** | No modifications needed | No modifications needed |\n| **Assembly Creation** | Supported | Discouraged, limited support |"}
{"page_id": "smart-contracts-for-eth-devs-contract-deployment", "page_title": "Contract Deployment", "index": 11, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 5561, "end_char": 5999, "estimated_token_count": 69, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nBoth backends support contract deployment effectively, with REVM offering drop-in Ethereum compatibility and PolkaVM providing a more structured two-step approach. For the majority of use casesâ€”deploying standard contracts like tokens or applicationsâ€”both backends work seamlessly. Advanced patterns like factory contracts may require adjustment for PolkaVM, but these adaptations are straightforward with proper planning."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 30, "end_char": 751, "estimated_token_count": 118, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot's smart contract platform supports two distinct virtual machine (VM) architectures, providing developers with flexibility in selecting the optimal execution backend for their specific needs. This approach strikes a balance between immediate Ethereum compatibility and long-term innovation, enabling developers to deploy either unmodified (Ethereum Virtual Machine) EVM contracts using Rust Ethereum Virtual Machine (REVM) or optimize for higher performance using PolkaVM (PVM).\n\nBoth VM options share common infrastructure, including RPC interfaces, tooling support, and precompiles. The following sections compare architectures and guide you in selecting the best VM for your project's needs."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 1, "depth": 2, "title": "Migrate from EVM", "anchor": "migrate-from-evm", "start_char": 751, "end_char": 1585, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "## Migrate from EVM\n\nThe [REVM backend](https://github.com/bluealloy/revm){target=\\_blank} integrates a complete Rust implementation of the EVM, enabling Solidity contracts to run unchanged on Polkadot's smart contract platform.\n\nREVM allows developers to use their existing Ethereum tooling and infrastructure to build on Polkadot. Choose REVM to:\n\n- Migrate existing Ethereum contracts without modifications.\n- Retain exact EVM behavior for audit tools. \n- Use developer tools that rely upon inspecting EVM bytecode.\n- Prioritize rapid deployment over optimization.\n- Work with established Ethereum infrastructure and tooling to build on Polkadot.\n\nREVM enables Ethereum developers to seamlessly migrate to Polkadot, achieving performance and fee improvements without modifying their existing contracts or developer tooling stack."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 2, "depth": 2, "title": "Upgrade to PolkaVM", "anchor": "upgrade-to-polkavm", "start_char": 1585, "end_char": 2542, "estimated_token_count": 203, "token_estimator": "heuristic-v1", "text": "## Upgrade to PolkaVM\n\n[**PolkaVM**](https://github.com/paritytech/polkavm){target=\\_blank} is a custom virtual machine optimized for performance with [RISC-V-based](https://en.wikipedia.org/wiki/RISC-V){target=\\_blank} architecture, supporting Solidity and additional high-performance languages. It serves as the core execution environment, integrated directly within the runtime. Choose the PolkaVM for:\n\n- An efficient interpreter for immediate code execution.\n- A planned [Just In Time (JIT)](https://en.wikipedia.org/wiki/Just-in-time_compilation){target=\\_blank} compiler for optimized performance.\n- Dual-mode execution capability, allowing selection of the most appropriate backend for specific workloads.\n- Optimized performance for short-running contract calls through the interpreter.\n\nThe interpreter remains particularly beneficial for contracts with minimal code execution, as it enables immediate code execution through lazy interpretation."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 3, "depth": 2, "title": "Architecture", "anchor": "architecture", "start_char": 2542, "end_char": 2674, "estimated_token_count": 21, "token_estimator": "heuristic-v1", "text": "## Architecture\n\nThe following key components of PolkaVM work together to enable Ethereum compatibility on Polkadot-based chains."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 4, "depth": 3, "title": "Revive Pallet", "anchor": "revive-pallet", "start_char": 2674, "end_char": 3953, "estimated_token_count": 232, "token_estimator": "heuristic-v1", "text": "### Revive Pallet\n\n[**`pallet_revive`**](https://paritytech.github.io/polkadot-sdk/master/pallet_revive/index.html){target=\\_blank} is a runtime module that executes smart contracts by adding extrinsics, runtime APIs, and logic to convert Ethereum-style transactions into formats compatible with Polkadot SDK-based blockchains. It processes Ethereum-style transactions through the following workflow:\n\n```mermaid\nsequenceDiagram\n    participant User as User/dApp\n    participant Proxy as Ethereum JSON RPC Proxy\n    participant Chain as Blockchain Node\n    participant Pallet as pallet_revive\n    \n    User->>Proxy: Submit Ethereum Transaction\n    Proxy->>Chain: Repackage as Polkadot Compatible Transaction\n    Chain->>Pallet: Process Transaction\n    Pallet->>Pallet: Decode Ethereum Transaction\n    Pallet->>Pallet: Execute Contract via PolkaVM\n    Pallet->>Chain: Return Results\n    Chain->>Proxy: Forward Results\n    Proxy->>User: Return Ethereum-compatible Response\n```\n\nThis proxy-based approach eliminates the need for node binary modifications, maintaining compatibility across different client implementations. Preserving the original Ethereum transaction payload simplifies the adaptation of existing tools, which can continue processing familiar transaction formats."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 5, "depth": 3, "title": "PolkaVM Design Fundamentals", "anchor": "polkavm-design-fundamentals", "start_char": 3953, "end_char": 4897, "estimated_token_count": 185, "token_estimator": "heuristic-v1", "text": "### PolkaVM Design Fundamentals\n\nPolkaVM differs from the EVM in two key ways that make it faster, more hardware-efficient, and easier to extend:\n\n- **Register-based design**: Instead of a stack machine, PolkaVM uses a RISC-Vâ€“style register model. This design:\n\n    - Uses a fixed set of registers to pass arguments, not an infinite stack.\n    - Maps cleanly to real hardware like x86-64.\n    - Simplifies compilation and boosts runtime efficiency.\n    - Enables tighter control over register allocation and performance tuning.\n\n- **64-bit word size**: PolkaVM runs on a native 64-bit word size, aligning directly with modern CPUs. This design:\n\n    - Executes arithmetic operations with direct hardware support.\n    - Maintains compatibility with Solidityâ€™s 256-bit types via YUL translation.\n    - Accelerates computation-heavy workloads through native word alignment.\n    - Integrates easily with low-level, performance-focused components."}
{"page_id": "smart-contracts-for-eth-devs-dual-vm-stack", "page_title": "Dual Virtual Machine Stack", "index": 6, "depth": 2, "title": "Where To Go Next", "anchor": "where-to-go-next", "start_char": 4897, "end_char": 5213, "estimated_token_count": 82, "token_estimator": "heuristic-v1", "text": "## Where To Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge learn\">Learn</span> __Contract Deployment__\n\n    ---\n\n    Learn how REVM and PVM compare for compiling and deploying smart contracts.\n\n    [:octicons-arrow-right-24: Reference](/smart-contracts/for-eth-devs/contract-deployment/)\n\n</div>"}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 294, "estimated_token_count": 49, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe Polkadot Hub implements a gas model that bridges Ethereum's familiar gas concept with Polkadot's more sophisticated resource metering system. This page explains how gas works in the Polkadot Hub and what developers need to know when building smart contracts."}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 1, "depth": 2, "title": "Understanding Resources in the Polkadot Hub", "anchor": "understanding-resources-in-the-polkadot-hub", "start_char": 294, "end_char": 1294, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "## Understanding Resources in the Polkadot Hub\n\nUnlike Ethereum, which uses a single gas value to measure everything, the Polkadot Hub tracks three separate resources:\n\n- **`ref_time`**: Measures computational time. It is the closest equivalent to traditional gas and represents the amount of CPU time your contract execution consumes.\n- **`proof_size`**: Measures the amount of state data that validators need to verify. When your contract reads from storage or makes state queries, this metric tracks the size of the proofs needed to validate those operations.\n- **`storage_deposit`**: Is a native balance that gets temporarily locked when your contract creates new storage entries. This prevents state bloat by requiring contracts to pay for the storage they use. The deposit is returned when the storage is freed.\n\nFor Ethereum wallet compatibility, the Polkadot Hub's RPC layer automatically maps these three dimensions into a single gas value that wallets can understand and display to users."}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 2, "depth": 2, "title": "Gas vs Weight", "anchor": "gas-vs-weight", "start_char": 1294, "end_char": 1710, "estimated_token_count": 80, "token_estimator": "heuristic-v1", "text": "## Gas vs Weight\n\nWhen you interact with the Polkadot Hub through an Ethereum wallet, you see familiar gas values. Under the hood, the runtime works with `weight` - a two-dimensional metric that combines `ref_time` and `proof_size`.\n\nThe system continuously translates between these representations: converting `weight` to gas when estimating costs, and converting gas back to `weight` when executing transactions."}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 3, "depth": 2, "title": "How Gas Estimation Works", "anchor": "how-gas-estimation-works", "start_char": 1710, "end_char": 2551, "estimated_token_count": 163, "token_estimator": "heuristic-v1", "text": "## How Gas Estimation Works\n\nWhen your wallet requests a gas estimate (`eth_estimateGas`), the Polkadot Hub performs a dry-run of your transaction. This test execution discovers:\n\n- How much computational time the contract will consume (`ref_time`).\n- How much state data needs to be verified (`proof_size`).\n- Whether any storage deposits are required (`storage_deposit`).\n\nThe system then calculates a gas estimate that covers all these costs, including:\n\n- Base transaction overhead (intrinsic costs like signature verification, nonce/account checks, and dispatch setup).\n- Transaction length fees (charges for the transaction size in bytes).\n- The actual contract execution costs.\n- Any storage deposits.\n\nThe gas estimate also includes a small safety buffer to account for slight differences between the test run and actual execution."}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 4, "depth": 2, "title": "Dynamic Gas Pricing", "anchor": "dynamic-gas-pricing", "start_char": 2551, "end_char": 3444, "estimated_token_count": 161, "token_estimator": "heuristic-v1", "text": "## Dynamic Gas Pricing\n\nPallet revive uses dynamic pricing through a \"fee multiplier\" that adjusts based on network congestion:\n\n- When blocks are full, the multiplier increases, making transactions more expensive.\n- When blocks are empty, the multiplier decreases, making transactions cheaper.\n- The multiplier updates after every block based on utilization.\n\nThis creates a market-based pricing mechanism similar to Ethereum's base fee, helping to manage network resources efficiently.\n\nThe gas price returned during estimation is simply the current fee multiplier value.\n\n!!! warning \"Important for Users\"\n    Because the fee multiplier can change between when you estimate gas and when your transaction executes, you can add a safety buffer (10-20%) to both your gas limit and gas price. This ensures your transaction will execute successfully even if network conditions change slightly."}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 5, "depth": 2, "title": "Transaction Execution Flow", "anchor": "transaction-execution-flow", "start_char": 3444, "end_char": 4940, "estimated_token_count": 353, "token_estimator": "heuristic-v1", "text": "## Transaction Execution Flow\n\nThe following diagram illustrates the complete lifecycle of a transaction from submission to settlement:\n\n```mermaid\ngraph TD\n    U[User/Wallet] --> M[Transaction pool]\n    M --> P[Pre-dispatch convert gas to weight and create hold]\n    P --> C{Sufficient funds}\n    C -->|No| R[Rejected]\n    C -->|Yes| X[Execute contract within limits]\n    X --> S[Settle fee from actual weight and length; refund]\n    S --> B[Included in block]\n```\n\nThe transaction execution flow is as follows:\n\n- **Pool and pre-dispatch**: The transaction enters the pool, `gas` is mapped to `weight`, and a temporary hold is created for the maximum fee exposure. Weight is a two-dimensional tuple (`ref_time`, `proof_size`). Each dimension is tracked independently. The [`WeightToFee`](https://docs.rs/pallet-transaction-payment/latest/pallet_transaction_payment/pallet/trait.Config.html#associatedtype.WeightToFee){target=\\_blank} conversion takes the maximum of the two dimensions (after applying their respective coefficients) to determine the fee.\n- **Funds check**: If the hold is insufficient, the transaction is rejected before any execution.\n- **Execution**: If sufficient, the contract runs within the derived weight limits; a `storage_deposit` may be reserved when new storage is created.\n- **Settlement**: Fees are charged from the actual `weight` used plus the length fee; any unused hold is refunded.\n- **Inclusion**: After settlement, the transaction is included in the block."}
{"page_id": "smart-contracts-for-eth-devs-gas-model", "page_title": "Gas Model on the Polkadot Hub", "index": 6, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 4940, "end_char": 5238, "estimated_token_count": 51, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThe Polkadot Hub's gas model is designed to be Ethereum-compatible while providing the flexibility and efficiency of Polkadot's resource metering system. Developers can build on Ethereum tooling while leveraging Polkadot's advanced features like multi-dimensional resource tracking."}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 17, "end_char": 509, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub provides Ethereum compatibility through its JSON-RPC interface, allowing developers to interact with the chain using familiar Ethereum tooling and methods. This document outlines the supported [Ethereum JSON-RPC methods](https://ethereum.org/developers/docs/apis/json-rpc/#json-rpc-methods){target=\\_blank} and provides examples of how to use them.\n\nThis guide uses the Polkadot Hub TestNet endpoint:\n\n```text\nhttps://testnet-passet-hub-eth-rpc.polkadot.io\n```"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 1, "depth": 2, "title": "Available Methods", "anchor": "available-methods", "start_char": 509, "end_char": 531, "estimated_token_count": 4, "token_estimator": "heuristic-v1", "text": "## Available Methods"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 2, "depth": 3, "title": "eth_accounts", "anchor": "eth_accounts", "start_char": 531, "end_char": 962, "estimated_token_count": 146, "token_estimator": "heuristic-v1", "text": "### eth_accounts\n\nReturns a list of addresses owned by the client. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_accounts){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_accounts\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_accounts\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 3, "depth": 3, "title": "eth_blockNumber", "anchor": "eth_blocknumber", "start_char": 962, "end_char": 1401, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "### eth_blockNumber\n\nReturns the number of the most recent block. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_blocknumber){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_blockNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_blockNumber\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 4, "depth": 3, "title": "eth_call", "anchor": "eth_call", "start_char": 1401, "end_char": 3625, "estimated_token_count": 707, "token_estimator": "heuristic-v1", "text": "### eth_call\n\nExecutes a new message call immediately without creating a transaction. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_call){target=\\_blank}.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction call object.\n    - **`to` ++\"string\"++**: Recipient address of the call. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: Hash of the method signature and encoded parameters. Must be a [data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`from` ++\"string\"++**: (Optional) Sender's address for the call. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (Optional) Gas limit to execute the call. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit of gas. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Value in wei to send with the call. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) Block tag or block number to execute the call at. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_call\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_call\",\n    \"params\":[{\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"data\": \"INSERT_ENCODED_CALL\"\n    }, \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_RECIPIENT_ADDRESS`, `INSERT_ENCODED_CALL`, and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 5, "depth": 3, "title": "eth_chainId", "anchor": "eth_chainid", "start_char": 3625, "end_char": 4055, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "### eth_chainId\n\nReturns the chain ID used for signing transactions. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_chainid){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_chainId\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_chainId\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 6, "depth": 3, "title": "eth_estimateGas", "anchor": "eth_estimategas", "start_char": 4055, "end_char": 6241, "estimated_token_count": 694, "token_estimator": "heuristic-v1", "text": "### eth_estimateGas\n\nEstimates gas required for a transaction. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_estimategas){target=\\_blank}.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction call object.\n    - **`to` ++\"string\"++**: Recipient address of the call. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: Hash of the method signature and encoded parameters. Must be a [data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`from` ++\"string\"++**: (Optional) Sender's address for the call. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (Optional) Gas limit to execute the call. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit of gas. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Value in wei to send with the call. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) Block tag or block number to execute the call at. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_estimateGas\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_estimateGas\",\n    \"params\":[{\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"data\": \"INSERT_ENCODED_FUNCTION_CALL\"\n    }],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_RECIPIENT_ADDRESS` and `INSERT_ENCODED_CALL` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 7, "depth": 3, "title": "eth_gasPrice", "anchor": "eth_gasprice", "start_char": 6241, "end_char": 6661, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "### eth_gasPrice\n\nReturns the current gas price in Wei. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_gasprice){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_gasPrice\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_gasPrice\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 8, "depth": 3, "title": "eth_getBalance", "anchor": "eth_getbalance", "start_char": 6661, "end_char": 7703, "estimated_token_count": 330, "token_estimator": "heuristic-v1", "text": "### eth_getBalance\n\nReturns the balance of a given address. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getbalance){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Address to query balance. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_getBalance\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBalance\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS` and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 9, "depth": 3, "title": "eth_getBlockByHash", "anchor": "eth_getblockbyhash", "start_char": 7703, "end_char": 8598, "estimated_token_count": 266, "token_estimator": "heuristic-v1", "text": "### eth_getBlockByHash\n\nReturns information about a block by its hash. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getblockbyhash){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockHash` ++\"string\"++**: The hash of the block to retrieve. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`fullTransactions` ++\"boolean\"++**: If `true`, returns full transaction details; if `false`, returns only transaction hashes.\n\n**Example**:\n\n```bash title=\"eth_getBlockByHash\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockByHash\",\n    \"params\":[\"INSERT_BLOCK_HASH\", INSERT_BOOLEAN],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_HASH` and `INSERT_BOOLEAN` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 10, "depth": 3, "title": "eth_getBlockByNumber", "anchor": "eth_getblockbynumber", "start_char": 8598, "end_char": 9617, "estimated_token_count": 301, "token_estimator": "heuristic-v1", "text": "### eth_getBlockByNumber\n\nReturns information about a block by its number. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getblockbynumber){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`fullTransactions` ++\"boolean\"++**: If `true`, returns full transaction details; if `false`, returns only transaction hashes.\n\n**Example**:\n\n```bash title=\"eth_getBlockByNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockByNumber\",\n    \"params\":[\"INSERT_BLOCK_VALUE\", INSERT_BOOLEAN],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_VALUE` and `INSERT_BOOLEAN` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 11, "depth": 3, "title": "eth_getBlockTransactionCountByNumber", "anchor": "eth_getblocktransactioncountbynumber", "start_char": 9617, "end_char": 10540, "estimated_token_count": 260, "token_estimator": "heuristic-v1", "text": "### eth_getBlockTransactionCountByNumber\n\nReturns the number of transactions in a block from a block number. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getblocktransactioncountbynumber){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n\n**Example**:\n\n```bash title=\"eth_getBlockTransactionCountByNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockTransactionCountByNumber\",\n    \"params\":[\"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 12, "depth": 3, "title": "eth_getBlockTransactionCountByHash", "anchor": "eth_getblocktransactioncountbyhash", "start_char": 10540, "end_char": 11350, "estimated_token_count": 228, "token_estimator": "heuristic-v1", "text": "### eth_getBlockTransactionCountByHash\n\nReturns the number of transactions in a block from a block hash. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getblocktransactioncountbyhash){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockHash` ++\"string\"++**: The hash of the block to retrieve. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getBlockTransactionCountByHash\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getBlockTransactionCountByHash\",\n    \"params\":[\"INSERT_BLOCK_HASH\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_HASH` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 13, "depth": 3, "title": "eth_getCode", "anchor": "eth_getcode", "start_char": 11350, "end_char": 12378, "estimated_token_count": 327, "token_estimator": "heuristic-v1", "text": "### eth_getCode\n\nReturns the code at a given address. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getcode){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Contract or account address to query code. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block).\n\n**Example**:\n\n```bash title=\"eth_getCode\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getCode\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS` and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 14, "depth": 3, "title": "eth_getLogs", "anchor": "eth_getlogs", "start_char": 12378, "end_char": 14329, "estimated_token_count": 630, "token_estimator": "heuristic-v1", "text": "### eth_getLogs\n\nReturns an array of all logs matching a given filter object. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getlogs){target=\\_blank}.\n\n**Parameters**:\n\n- **`filter` ++\"object\"++**: The filter object.\n    - **`fromBlock` ++\"string\"++**: (Optional) Block number or tag to start from. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n    - **`toBlock` ++\"string\"++**: (Optional) Block number or tag to end at. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n    - **`address` ++\"string\" or \"array of strings\"++**: (Optional) Contract address or a list of addresses from which to get logs. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`topics` ++\"array of strings\"++**: (Optional) Array of topics for filtering logs. Each topic can be a single [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string or an array of such strings (meaning OR).\n    - **`blockhash` ++\"string\"++**: (Optional) Hash of a specific block. Cannot be used with `fromBlock` or `toBlock`. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getLogs\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getLogs\",\n    \"params\":[{\n        \"fromBlock\": \"latest\",\n        \"toBlock\": \"latest\"\n    }],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 15, "depth": 3, "title": "eth_getStorageAt", "anchor": "eth_getstorageat", "start_char": 14329, "end_char": 15641, "estimated_token_count": 402, "token_estimator": "heuristic-v1", "text": "### eth_getStorageAt\n\nReturns the value from a storage position at a given address. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_getstorageat){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Contract or account address to query code. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`storageKey` ++\"string\"++**: Position in storage to retrieve data from. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block).\n\n**Example**:\n\n```bash title=\"eth_getStorageAt\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getStorageAt\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_STORAGE_KEY\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS`, `INSERT_STORAGE_KEY`, and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 16, "depth": 3, "title": "eth_getTransactionCount", "anchor": "eth_gettransactioncount", "start_char": 15641, "end_char": 16728, "estimated_token_count": 329, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionCount\n\nReturns the number of transactions sent from an address (nonce). [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_gettransactioncount){target=\\_blank}.\n\n**Parameters**:\n\n- **`address` ++\"string\"++**: Address to query balance. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block).\n\n**Example**:\n\n```bash title=\"eth_getTransactionCount\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionCount\",\n    \"params\":[\"INSERT_ADDRESS\", \"INSERT_BLOCK_VALUE\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_ADDRESS` and `INSERT_BLOCK_VALUE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 17, "depth": 3, "title": "eth_getTransactionByHash", "anchor": "eth_gettransactionbyhash", "start_char": 16728, "end_char": 17498, "estimated_token_count": 222, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionByHash\n\nReturns information about a transaction by its hash. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_gettransactionbyhash){target=\\_blank}.\n\n**Parameters**:\n\n- **`transactionHash` ++\"string\"++**: The hash of the transaction. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionByHash\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionByHash\",\n    \"params\":[\"INSERT_TRANSACTION_HASH\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_TRANSACTION_HASH` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 18, "depth": 3, "title": "eth_getTransactionByBlockNumberAndIndex", "anchor": "eth_gettransactionbyblocknumberandindex", "start_char": 17498, "end_char": 18704, "estimated_token_count": 330, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionByBlockNumberAndIndex\n\nReturns information about a transaction by block number and transaction index. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_gettransactionbyblocknumberandindex){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: The block value to be fetched. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`transactionIndex` ++\"string\"++**: The index of the transaction in the block. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionByBlockNumberAndIndex\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionByBlockNumberAndIndex\",\n    \"params\":[\"INSERT_BLOCK_VALUE\", \"INSERT_TRANSACTION_INDEX\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_VALUE` and `INSERT_TRANSACTION_INDEX` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 19, "depth": 3, "title": "eth_getTransactionByBlockHashAndIndex", "anchor": "eth_gettransactionbyblockhashandindex", "start_char": 18704, "end_char": 19785, "estimated_token_count": 296, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionByBlockHashAndIndex\n\nReturns information about a transaction by block hash and transaction index. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_gettransactionbyblockhashandindex){target=\\_blank}.\n\n**Parameters**:\n\n- **`blockHash` ++\"string\"++**: The hash of the block. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`transactionIndex` ++\"string\"++**: The index of the transaction in the block. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionByBlockHashAndIndex\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionByBlockHashAndIndex\",\n    \"params\":[\"INSERT_BLOCK_HASH\", \"INSERT_TRANSACTION_INDEX\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_BLOCK_HASH` and `INSERT_TRANSACTION_INDEX` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 20, "depth": 3, "title": "eth_getTransactionReceipt", "anchor": "eth_gettransactionreceipt", "start_char": 19785, "end_char": 20564, "estimated_token_count": 223, "token_estimator": "heuristic-v1", "text": "### eth_getTransactionReceipt\n\nReturns the receipt of a transaction by transaction hash. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_gettransactionreceipt){target=\\_blank}.\n\n**Parameters**:\n\n- **`transactionHash` ++\"string\"++**: The hash of the transaction. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_getTransactionReceipt\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_getTransactionReceipt\",\n    \"params\":[\"INSERT_TRANSACTION_HASH\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_TRANSACTION_HASH` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 21, "depth": 3, "title": "eth_maxPriorityFeePerGas", "anchor": "eth_maxpriorityfeepergas", "start_char": 20564, "end_char": 20979, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "### eth_maxPriorityFeePerGas\n\nReturns an estimate of the current priority fee per gas, in Wei, to be included in a block.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_maxPriorityFeePerGas\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_maxPriorityFeePerGas\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 22, "depth": 3, "title": "eth_sendRawTransaction", "anchor": "eth_sendrawtransaction", "start_char": 20979, "end_char": 21682, "estimated_token_count": 214, "token_estimator": "heuristic-v1", "text": "### eth_sendRawTransaction\n\nSubmits a raw transaction. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_sendrawtransaction){target=\\_blank}.\n\n**Parameters**:\n\n- **`callData` ++\"string\"++**: Signed transaction data. Must be a [data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_sendRawTransaction\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_sendRawTransaction\",\n    \"params\":[\"INSERT_CALL_DATA\"],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_CALL_DATA` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 23, "depth": 3, "title": "eth_sendTransaction", "anchor": "eth_sendtransaction", "start_char": 21682, "end_char": 24037, "estimated_token_count": 714, "token_estimator": "heuristic-v1", "text": "### eth_sendTransaction\n\nCreates and sends a new transaction. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_sendtransaction){target=\\_blank}.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction object.\n    - **`from` ++\"string\"++**: Address sending the transaction. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`to` ++\"string\"++**: (Optional) Recipient address. No need to provide this value when deploying a contract. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (optional, default: `90000`) gas limit for execution. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Amount of Ether to send. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: (Optional) Contract bytecode or encoded method call. Must be a [data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`nonce` ++\"string\"++**: (Optional) Transaction nonce. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n\n**Example**:\n\n```bash title=\"eth_sendTransaction\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_sendTransaction\",\n    \"params\":[{\n        \"from\": \"INSERT_SENDER_ADDRESS\",\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"gas\": \"INSERT_GAS_LIMIT\",\n        \"gasPrice\": \"INSERT_GAS_PRICE\",\n        \"value\": \"INSERT_VALUE\",\n        \"input\": \"INSERT_INPUT_DATA\",\n        \"nonce\": \"INSERT_NONCE\"\n    }],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_SENDER_ADDRESS`, `INSERT_RECIPIENT_ADDRESS`, `INSERT_GAS_LIMIT`, `INSERT_GAS_PRICE`, `INSERT_VALUE`, `INSERT_INPUT_DATA`, and `INSERT_NONCE` with the proper values.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 24, "depth": 3, "title": "eth_syncing", "anchor": "eth_syncing", "start_char": 24037, "end_char": 24478, "estimated_token_count": 150, "token_estimator": "heuristic-v1", "text": "### eth_syncing\n\nReturns an object with syncing data or `false` if not syncing. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#eth_syncing){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"eth_syncing\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"eth_syncing\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 25, "depth": 3, "title": "net_listening", "anchor": "net_listening", "start_char": 24478, "end_char": 24960, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "### net_listening\n\nReturns `true` if the client is currently listening for network connections, otherwise `false`. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#net_listening){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"net_listening\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"net_listening\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 26, "depth": 3, "title": "net_peerCount", "anchor": "net_peercount", "start_char": 24960, "end_char": 25313, "estimated_token_count": 115, "token_estimator": "heuristic-v1", "text": "### net_peerCount\n\nReturns the number of peers currently connected to the client.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"net_peerCount\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"net_peerCount\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 27, "depth": 3, "title": "net_version", "anchor": "net_version", "start_char": 25313, "end_char": 25735, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "### net_version\n\nReturns the current network ID as a string. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#net_version){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"net_version\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"net_version\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 28, "depth": 3, "title": "system_health", "anchor": "system_health", "start_char": 25735, "end_char": 26077, "estimated_token_count": 113, "token_estimator": "heuristic-v1", "text": "### system_health\n\nReturns information about the health of the system.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"system_health\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"system_health\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 29, "depth": 3, "title": "web3_clientVersion", "anchor": "web3_clientversion", "start_char": 26077, "end_char": 26519, "estimated_token_count": 142, "token_estimator": "heuristic-v1", "text": "### web3_clientVersion\n\nReturns the current client version. [Reference](https://ethereum.org/developers/docs/apis/json-rpc/#web3_clientversion){target=\\_blank}.\n\n**Parameters**:\n\nNone.\n\n**Example**:\n\n```bash title=\"web3_clientVersion\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"web3_clientVersion\",\n    \"params\":[],\n    \"id\":1\n}'\n```\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 30, "depth": 3, "title": "debug_traceBlockByNumber", "anchor": "debug_traceblockbynumber", "start_char": 26519, "end_char": 27595, "estimated_token_count": 324, "token_estimator": "heuristic-v1", "text": "### debug_traceBlockByNumber \n\nTraces a block's execution by its number and returns a detailed execution trace for each transaction.\n\n**Parameters**:\n\n- **`blockValue` ++\"string\"++**: The block number or tag to trace. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`options` ++\"object\"++**: (Optional) An object containing tracer options.\n    - **`tracer` ++\"string\"++**: The name of the tracer to use (e.g., `\"callTracer\"`, `\"opTracer\"`).\n    - Other tracer-specific options may be supported.\n\n**Example**:\n\n```bash title=\"debug_traceBlockByNumber\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"debug_traceBlockByNumber\",\n    \"params\":[\"INSERT_BLOCK_VALUE\", {\"tracer\": \"callTracer\"}],\n    \"id\":1\n}'\n```\n\nEnsure to replace `INSERT_BLOCK_VALUE` with a proper block number if needed.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 31, "depth": 3, "title": "debug_traceTransaction", "anchor": "debug_tracetransaction", "start_char": 27595, "end_char": 28439, "estimated_token_count": 249, "token_estimator": "heuristic-v1", "text": "### debug_traceTransaction\n\nTraces the execution of a single transaction by its hash and returns a detailed execution trace.\n\n**Parameters**:\n\n- **`transactionHash` ++\"string\"++**: The hash of the transaction to trace. Must be a [32 byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n- **`options` ++\"object\"++**: (Optional) An object containing tracer options (e.g., `tracer: \"callTracer\"`).\n\n**Example**:\n\n```bash title=\"debug_traceTransaction\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"debug_traceTransaction\",\n    \"params\":[\"INSERT_TRANSACTION_HASH\", {\"tracer\": \"callTracer\"}],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_TRANSACTION_HASH` with the proper value.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 32, "depth": 3, "title": "debug_traceCall", "anchor": "debug_tracecall", "start_char": 28439, "end_char": 30872, "estimated_token_count": 751, "token_estimator": "heuristic-v1", "text": "### debug_traceCall\n\nExecutes a new message call and returns a detailed execution trace without creating a transaction on the blockchain.\n\n**Parameters**:\n\n- **`transaction` ++\"object\"++**: The transaction call object, similar to `eth_call` parameters.\n    - **`to` ++\"string\"++**: Recipient address of the call. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`data` ++\"string\"++**: Hash of the method signature and encoded parameters. Must be a [data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`from` ++\"string\"++**: (Optional) Sender's address for the call. Must be a [20-byte data](https://ethereum.org/developers/docs/apis/json-rpc/#unformatted-data-encoding){target=\\_blank} string.\n    - **`gas` ++\"string\"++**: (Optional) Gas limit to execute the call. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`gasPrice` ++\"string\"++**: (Optional) Gas price per unit of gas. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n    - **`value` ++\"string\"++**: (Optional) Value in wei to send with the call. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string.\n- **`blockValue` ++\"string\"++**: (Optional) Block tag or block number to execute the call at. Must be a [quantity](https://ethereum.org/developers/docs/apis/json-rpc/#quantities-encoding){target=\\_blank} string or a [default block parameter](https://ethereum.org/developers/docs/apis/json-rpc/#default-block){target=\\_blank}.\n- **`options` ++\"object\"++**: (Optional) An object containing tracer options (e.g., `tracer: \"callTracer\"`).\n\n**Example**:\n\n```bash title=\"debug_traceCall\"\ncurl -X POST https://testnet-passet-hub-eth-rpc.polkadot.io \\\n-H \"Content-Type: application/json\" \\\n--data '{\n    \"jsonrpc\":\"2.0\",\n    \"method\":\"debug_traceCall\",\n    \"params\":[{\n        \"from\": \"INSERT_SENDER_ADDRESS\",\n        \"to\": \"INSERT_RECIPIENT_ADDRESS\",\n        \"data\": \"INSERT_ENCODED_CALL\"\n    }, \"INSERT_BLOCK_VALUE\", {\"tracer\": \"callTracer\"}],\n    \"id\":1\n}'\n```\n\nEnsure to replace the `INSERT_SENDER_ADDRESS`, `INSERT_RECIPIENT_ADDRESS`, `INSERT_ENCODED_CALL`, and `INSERT_BLOCK_VALUE` with the proper value.\n\n---"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 33, "depth": 2, "title": "Response Format", "anchor": "response-format", "start_char": 30872, "end_char": 31055, "estimated_token_count": 57, "token_estimator": "heuristic-v1", "text": "## Response Format\n\nAll responses follow the standard JSON-RPC 2.0 format:\n\n```json\n{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"result\": ... // The return value varies by method\n}\n```"}
{"page_id": "smart-contracts-for-eth-devs-json-rpc-apis", "page_title": "JSON-RPC APIs", "index": 34, "depth": 2, "title": "Error Handling", "anchor": "error-handling", "start_char": 31055, "end_char": 31274, "estimated_token_count": 64, "token_estimator": "heuristic-v1", "text": "## Error Handling\n\nIf an error occurs, the response will include an error object:\n\n```json\n{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"error\": {\n        \"code\": -32000,\n        \"message\": \"Error message here\"\n    }\n}\n```"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 0, "depth": 2, "title": "Quick Starts", "anchor": "quick-starts", "start_char": 173, "end_char": 1038, "estimated_token_count": 269, "token_estimator": "heuristic-v1", "text": "## Quick Starts\n\nKick off development fast with curated links for connecting, funding, exploring, and deploying your first contract.\n\n|                     Quick Start                     |         Tools         |                           Description                           |\n|:---------------------------------------------------:|:---------------------:|:---------------------------------------------------------------:|\n|  [Connect to Polkadot](/smart-contracts/connect/)   | Polkadot.js, MetaMask | Add the network, configure RPC, verify activity in the explorer |\n|     [Get Test Tokens](/smart-contracts/faucet/)     |           -           |    Request test funds to deploy and interact with contracts     |\n| [Explore Transactions](/smart-contracts/explorers/) |        Subscan        | Inspect transactions, logs, token transfers, and contract state |"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 1, "depth": 2, "title": "Build and Test Locally", "anchor": "build-and-test-locally", "start_char": 1038, "end_char": 1913, "estimated_token_count": 276, "token_estimator": "heuristic-v1", "text": "## Build and Test Locally\n\nSet up local environments and CI-friendly workflows to iterate quickly and validate changes before deploying.\n\n|                          Build and Test Locally                           |       Tools       |                  Description                   |\n|:-------------------------------------------------------------------------:|:-----------------:|:----------------------------------------------:|\n| [Run a Local Dev Node](/smart-contracts/dev-environments/local-dev-node/) | Polkadot SDK node | Spin up a local node for iterative development |\n|   [Use Remix for Development](/smart-contracts/dev-environments/remix/)   |       Remix       |         Connect Remix to Polkadot Hub          |\n| [Use Hardhat for Development](/smart-contracts/dev-environments/hardhat/) |      Hardhat      |     Project scaffolding and configuration      |"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 2, "depth": 2, "title": "Ethereum Developer Resources", "anchor": "ethereum-developer-resources", "start_char": 1913, "end_char": 3337, "estimated_token_count": 405, "token_estimator": "heuristic-v1", "text": "## Ethereum Developer Resources\n\nBridge your Ethereum knowledge with Polkadot Hub specifics: account mapping, fees, JSONâ€‘RPC, and deployment.\n\n|                                 Ethereum Developer Guides                                 |                           Description                           |\n|:-----------------------------------------------------------------------------------------:|:---------------------------------------------------------------:|\n|                    [Accounts](/smart-contracts/for-eth-devs/accounts/)                    | How 20â€‘byte Ethereum addresses map to 32â€‘byte Polkadot accounts |\n| [Blocks, Transactions, and Fees](/smart-contracts/for-eth-devs/blocks-transactions-fees/) |     Transaction types, fees, and multiâ€‘dimensional metering     |\n|                   [Gas Model](/smart-contracts/for-eth-devs/gas-model/)                   |        Gas vs. weight, proof size, and storage deposits         |\n|         [Contract Deployment](/smart-contracts/for-eth-devs/contract-deployment/)         |     Deployment patterns and best practices on Polkadot Hub      |\n|               [JSONâ€‘RPC APIs](/smart-contracts/for-eth-devs/json-rpc-apis/)               |        Supported Ethereum JSONâ€‘RPC methods and examples         |\n|               [Dual VM Stack](/smart-contracts/for-eth-devs/dual-vm-stack/)               |         Overview of EVM and native execution on the Hub         |"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 3, "depth": 2, "title": "Cookbook: Handsâ€‘on Tutorials", "anchor": "cookbook-handson-tutorials", "start_char": 3337, "end_char": 4613, "estimated_token_count": 393, "token_estimator": "heuristic-v1", "text": "## Cookbook: Handsâ€‘on Tutorials\n\nFollow stepâ€‘byâ€‘step guides that walk through common tasks and complete dApp examples.\n\n|                                            Tutorial                                            |        Tools        |                Description                |\n|:----------------------------------------------------------------------------------------------:|:-------------------:|:-----------------------------------------:|\n| [Deploy a Basic Contract](/smart-contracts/cookbook/smart-contracts/deploy-basic/basic-remix/) |        Remix        |      Minimal deployment walkthrough       |\n|    [Deploy an ERCâ€‘20](/smart-contracts/cookbook/smart-contracts/deploy-erc20/erc20-remix/)     | Remix, OpenZeppelin | Create, deploy, and mint a fungible token |\n|   [Deploy an NFT (ERCâ€‘721)](/smart-contracts/cookbook/smart-contracts/deploy-nft/nft-remix/)   | Remix, OpenZeppelin |    Build and deploy an NFT collection     |\n|                 [Uniswap V2](/smart-contracts/cookbook/eth-dapps/uniswap-v2/)                  |       Hardhat       | Full dApp project: compile, test, deploy  |\n|               [Zeroâ€‘toâ€‘Hero dApp](/smart-contracts/cookbook/dapps/zero-to-hero/)               |      Multiple       |  Endâ€‘toâ€‘end dApp patterns and practices   |"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 4, "depth": 2, "title": "Libraries", "anchor": "libraries", "start_char": 4613, "end_char": 5514, "estimated_token_count": 271, "token_estimator": "heuristic-v1", "text": "## Libraries\n\nChoose the client libraries that fit your stack for connecting wallets and calling contracts.\n\n|                      Library                       |                       Description                       |\n|:--------------------------------------------------:|:-------------------------------------------------------:|\n| [Ethers.js](/smart-contracts/libraries/ethers-js/) | Connect, sign, and interact with contracts using Ethers |\n|      [viem](/smart-contracts/libraries/viem/)      |        Typeâ€‘safe EVM interactions and utilities         |\n|     [Wagmi](/smart-contracts/libraries/wagmi/)     |  React hooks for wallet connections and contract calls  |\n|   [Web3.js](/smart-contracts/libraries/web3-js/)   |             Web3 provider and contract APIs             |\n|   [Web3.py](/smart-contracts/libraries/web3-py/)   |  Python toolkit for onâ€‘chain interactions and scripts   |"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 5, "depth": 2, "title": "Integrations", "anchor": "integrations", "start_char": 5514, "end_char": 5922, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "## Integrations\n\nIntegrate essential services like wallets, indexers, and oracles to round out your dApp.\n\n|                     Integration                     |                Description                |\n|:---------------------------------------------------:|:-----------------------------------------:|\n|  [Wallets](/smart-contracts/integrations/wallets/)  | Supported wallets and configuration notes |"}
{"page_id": "smart-contracts-get-started", "page_title": "Get Started with Smart Contracts", "index": 6, "depth": 2, "title": "Precompiles", "anchor": "precompiles", "start_char": 5922, "end_char": 6972, "estimated_token_count": 299, "token_estimator": "heuristic-v1", "text": "## Precompiles\n\nDiscover precompiled system contracts available on the Hub and how to use them.\n\n|                          Topic                           |                     Description                     |\n|:--------------------------------------------------------:|:---------------------------------------------------:|\n| [Overview of Precompiles](/smart-contracts/precompiles/) |      What precompiles are available on the Hub      |\n|  [ETH Native](/smart-contracts/precompiles/eth-native/)  |           EVM precompiles and interfaces            |\n|         [XCM](/smart-contracts/precompiles/xcm/)         |     Crossâ€‘chain messaging helpers for contracts     |\n\nFrom here, follow the quick starts to get connected, iterate locally with your preferred tools, and use the guides, libraries, integrations, and precompiles as you grow into productionâ€‘ready dApps. If you get stuck, [open an issue](https://github.com/polkadot-developers/polkadot-docs/issues/new?template=docs-issue.yml){target=\\_blank} or reach out in the community channels."}
{"page_id": "smart-contracts-integrations-wallets", "page_title": "Wallets for Polkadot Hub", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 28, "end_char": 495, "estimated_token_count": 75, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nConnecting a compatible wallet is the first essential step for interacting with the Polkadot Hub ecosystem. This guide explores wallet options that support both Substrate and Ethereum compatible layers, enabling transactions and smart contract interactions. Whether you're a developer testing on Polkadot Hub or a user accessing the MainNet, understanding wallet configuration is crucial for accessing the full range of Polkadot Hub's capabilities."}
{"page_id": "smart-contracts-integrations-wallets", "page_title": "Wallets for Polkadot Hub", "index": 1, "depth": 2, "title": "Connect Your Wallet", "anchor": "connect-your-wallet", "start_char": 495, "end_char": 519, "estimated_token_count": 5, "token_estimator": "heuristic-v1", "text": "## Connect Your Wallet"}
{"page_id": "smart-contracts-integrations-wallets", "page_title": "Wallets for Polkadot Hub", "index": 2, "depth": 3, "title": "MetaMask", "anchor": "metamask", "start_char": 519, "end_char": 2213, "estimated_token_count": 403, "token_estimator": "heuristic-v1", "text": "### MetaMask\n\n[MetaMask](https://metamask.io/){target=\\_blank} is a popular wallet for interacting with Ethereum-compatible chains. It allows users to connect to test networks that support Ethereum-based smart contracts. However, it's important to emphasize that MetaMask primarily facilitates interactions with smart contracts, giving users access to various chain functionalities. \n\nTo get started with MetaMask, you need to install the [MetaMask extension](https://metamask.io/download/){target=\\_blank} and add it to the browser. Once you install MetaMask, you can set up a new wallet and securely store your seed phrase. This phrase is crucial for recovery in case you lose access.\n\nFor example, to connect to the Polkadot Hub TestNet via MetaMask, you need to follow these steps:\n\n1. Open the MetaMask extension and click on the network icon to switch to the Polkadot Hub TestNet.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-1.webp){: .browser-extension}\n\n2. Click on the **Add a custom network** button.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-2.webp){: .browser-extension}\n\n3. Complete the necessary fields, then click the **Save** button (refer to the [Networks](/smart-contracts/connect/#networks-details){target=\\_blank} section for copy and paste parameters).\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-3.webp){: .browser-extension}\n\n4. Click on **Polkadot Hub TestNet** to switch the network.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-4.webp){: .browser-extension}\n\nThe steps in the preceding section can be used to connect to any chain by modifying the network specification and endpoint parameters."}
{"page_id": "smart-contracts-integrations-wallets", "page_title": "Wallets for Polkadot Hub", "index": 3, "depth": 3, "title": "SubWallet", "anchor": "subwallet", "start_char": 2213, "end_char": 4760, "estimated_token_count": 603, "token_estimator": "heuristic-v1", "text": "### SubWallet\n\n[SubWallet](https://www.subwallet.app/){target=\\_blank} is a popular non-custodial wallet solution for Polkadot and Ethereum ecosystems. It offers seamless integration with Polkadot SDK-based networks while maintaining Ethereum compatibility, making the wallet an ideal choice for users and developers to interact with Polkadot Hub.\n\nSubWallet now fully supports the [Polkadot Hub TestNet](/smart-contracts/connect/){target=\\_blank} where developers can deploy and interact with Ethereum-compatible, Solidity smart contracts.\n\nYou can easily view and manage your Paseo native token (PAS) using the Ethereum RPC endpoint (Passet Hub EVM) or the Substrate node RPC endpoint (passet-hub).\n\n??? code \"Polkadot Hub TestNet\"\n    You can see support here for Polkadot Hub's TestNet. The **Passet Hub EVM** network uses an ETH RPC endpoint, and the **passet-hub** uses a Substrate endpoint.\n    The ETH RPC endpoint will let you send transactions that follow an ETH format, while the Substrate endpoint will follow a Substrate transaction format.\n    Note the PAS token, which is the native token of the Polkadot Hub TestNet.\n\n    ![](/images/smart-contracts/integrations/wallets/subwallet-PAS.webp){: .browser-extension}\n\nTo connect to Polkadot Hub TestNet using SubWallet, follow these steps:\n\n1. Install the [SubWallet browser extension](https://chromewebstore.google.com/detail/subwallet-polkadot-wallet/onhogfjeacnfoofkfgppdlbmlmnplgbn?hl=en){target=\\_blank} and set up your wallet by following the on-screen instructions, or refer to our [step-by-step guide](https://docs.subwallet.app/main/extension-user-guide/getting-started/install-subwallet){target=\\_blank} for assistance.\n\n2. After setting up your wallet, click the List icon at the top left corner of the extension window to open **Settings**.\n\n    ![](/images/smart-contracts/integrations/wallets/subwallet-01.webp){: .browser-extension}\n\n3. Scroll down and select **Manage networks**.\n\n    ![](/images/smart-contracts/integrations/wallets/subwallet-02.webp){: .browser-extension}\n\n4. In the Manage network screen, either scroll down or type in the search bar to find the networks. Once done, enable the toggle next to the network name.\n\n    ![](/images/smart-contracts/integrations/wallets/subwallet-03.webp){: .browser-extension}\n\n   You are now ready to use SubWallet to interact with [Polkadot Hub TestNet](/smart-contracts/connect/#networks-details){target=\\_blank} seamlessly!\n\n![](/images/smart-contracts/integrations/wallets/subwallet-04.webp){: .browser-extension}"}
{"page_id": "smart-contracts-integrations-wallets", "page_title": "Wallets for Polkadot Hub", "index": 4, "depth": 3, "title": "Talisman", "anchor": "talisman", "start_char": 4760, "end_char": 6507, "estimated_token_count": 431, "token_estimator": "heuristic-v1", "text": "### Talisman\n\n[Talisman](https://talisman.xyz/){target=\\_blank} is a specialized wallet for the Polkadot ecosystem that supports both Substrate and EVM accounts, making it an excellent choice for Polkadot Hub interactions. Talisman offers a more integrated experience for Polkadot-based chains while still providing Ethereum compatibility.\n\nTo use Talisman with Polkadot Hub TestNet:\n\n1. Install the [Talisman extension](https://talisman.xyz/download){target=\\_blank} and set up your wallet by following the on-screen instructions.\n\n2. Once installed, click on the Talisman icon in your browser extensions and click on the **Settings** button.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-5.webp){: .browser-extension}\n\n3. Click the button **All settings**.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-6.webp){: .browser-extension}\n\n4. Go to the **Networks & Tokens** section.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-7.webp)\n\n5. Click the **Manage networks** button.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-8.webp)\n\n6. Click the **+ Add network** button.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-9.webp)\n\n7. Fill in the form with the required parameters and click the **Add network** button.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-10.webp)\n\n8. After that, you can switch to the Polkadot Hub TestNet by clicking on the network icon and selecting **Polkadot Hub TestNet**.\n\n    ![](/images/smart-contracts/integrations/wallets/wallets-11.webp)\n\nAfter selecting the network, Talisman will automatically configure the necessary RPC URL and chain ID for you. You can now use Talisman to interact with the Polkadot Hub TestNet."}
{"page_id": "smart-contracts-integrations-wallets", "page_title": "Wallets for Polkadot Hub", "index": 5, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 6507, "end_char": 7131, "estimated_token_count": 100, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nChoosing the right wallet for Polkadot Hub interactions depends on your specific requirements and familiarity with different interfaces. MetaMask provides a familiar entry point for developers with Ethereum experience, while Talisman offers deeper integration with Polkadot's unique features and native support for both EVM and Substrate accounts. By properly configuring your wallet connection, you gain access to the full spectrum of Polkadot Hub's capabilities.\n\n!!!info\n    Remember to always verify network parameters when connecting to ensure a secure and reliable connection to the Polkadot ecosystem."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 13, "end_char": 539, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Ethers.js](https://docs.ethers.org/v6/){target=\\_blank} is a lightweight library that enables interaction with Ethereum Virtual Machine (EVM)-compatible blockchains through JavaScript. Ethers is widely used as a toolkit to establish connections and read and write blockchain data. This article demonstrates using Ethers.js to interact and deploy smart contracts to Polkadot Hub.\n\nThis guide is intended for developers who are familiar with JavaScript and want to interact with Polkadot Hub using Ethers.js."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 539, "end_char": 895, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following installed:\n\n- **Node.js**: v22.13.1 or later, check the [Node.js installation guide](https://nodejs.org/en/download/current/){target=\\_blank}.\n- **npm**: v6.13.4 or later (comes bundled with Node.js).\n- **Solidity**: This guide uses Solidity `^0.8.9` for smart contract development."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 2, "depth": 2, "title": "Project Structure", "anchor": "project-structure", "start_char": 895, "end_char": 1403, "estimated_token_count": 144, "token_estimator": "heuristic-v1", "text": "## Project Structure\n\nThis project organizes contracts, scripts, and compiled artifacts for easy development and deployment.\n\n```text title=\"Ethers.js Polkadot Hub\"\nethers-project\nâ”œâ”€â”€ contracts\nâ”‚   â”œâ”€â”€ Storage.sol\nâ”œâ”€â”€ scripts\nâ”‚   â”œâ”€â”€ connectToProvider.js\nâ”‚   â”œâ”€â”€ fetchLastBlock.js\nâ”‚   â”œâ”€â”€ compile.js\nâ”‚   â”œâ”€â”€ deploy.js\nâ”‚   â”œâ”€â”€ checkStorage.js\nâ”œâ”€â”€ abis\nâ”‚   â”œâ”€â”€ Storage.json\nâ”œâ”€â”€ artifacts\nâ”‚   â”œâ”€â”€ Storage.bin\nâ”œâ”€â”€ contract-address.json\nâ”œâ”€â”€ node_modules/\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ package-lock.json\nâ””â”€â”€ README.md\n```"}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1403, "end_char": 1624, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nTo start working with Ethers.js, create a new folder and initialize your project by running the following commands in your terminal:\n\n```bash\nmkdir ethers-project\ncd ethers-project\nnpm init -y\n```"}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 4, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 1624, "end_char": 2083, "estimated_token_count": 122, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nNext, run the following command to install the Ethers.js library:\n\n```bash\nnpm install ethers\n```\n\nAdd the Solidity compiler so you can generate standard EVM bytecode:\n\n```bash\nnpm install --save-dev solc\n```\n\nThis guide uses `solc` version `0.8.33`.\n\n!!! tip\n    The sample scripts use ECMAScript modules. Add `\"type\": \"module\"` to your `package.json` (or rename the files to `.mjs`) so that `node` can run the `import` statements."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 5, "depth": 2, "title": "Set Up the Ethers.js Provider", "anchor": "set-up-the-ethersjs-provider", "start_char": 2083, "end_char": 4683, "estimated_token_count": 578, "token_estimator": "heuristic-v1", "text": "## Set Up the Ethers.js Provider\n\nA [`Provider`](https://docs.ethers.org/v6/api/providers/#Provider){target=\\_blank} is an abstraction of a connection to the Ethereum network, allowing you to query blockchain data and send transactions. It serves as a bridge between your application and the blockchain.\n\nTo interact with Polkadot Hub, you must set up an Ethers.js provider. This provider connects to a blockchain node, allowing you to query blockchain data and interact with smart contracts. In the root of your project, create a file named `connectToProvider.js` and add the following code:\n\n```js title=\"scripts/connectToProvider.js\"\nconst { JsonRpcProvider } = require('ethers');\n\nconst createProvider = (rpcUrl, chainId, chainName) => {\n  const provider = new JsonRpcProvider(rpcUrl, {\n    chainId: chainId,\n    name: chainName,\n  });\n\n  return provider;\n};\n\nconst PROVIDER_RPC = {\n  rpc: 'INSERT_RPC_URL',\n  chainId: 'INSERT_CHAIN_ID',\n  name: 'INSERT_CHAIN_NAME',\n};\n\ncreateProvider(PROVIDER_RPC.rpc, PROVIDER_RPC.chainId, PROVIDER_RPC.name);\n\n```\n\n!!! note\n    Replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, and `INSERT_CHAIN_NAME` with the appropriate values. For example, to connect to Polkadot Hub TestNet's Ethereum RPC instance, you can use the following parameters:\n\n    ```js\n    const PROVIDER_RPC = {\n        rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n        chainId: 420420422,\n        name: 'polkadot-hub-testnet'\n    };\n    ```\n\nTo connect to the provider, execute:\n\n```bash\nnode scripts/connectToProvider.js\n```\n\nWith the provider set up, you can start querying the blockchain. For instance, to fetch the latest block number:\n\n??? code \"fetchLastBlock.js code\"\n\n    ```js title=\"scripts/fetchLastBlock.js\"\n    const { JsonRpcProvider } = require('ethers');\n\n    const createProvider = (rpcUrl, chainId, chainName) => {\n      const provider = new JsonRpcProvider(rpcUrl, {\n        chainId: chainId,\n        name: chainName,\n      });\n\n      return provider;\n    };\n\n    const PROVIDER_RPC = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      chainId: 420420422,\n      name: 'polkadot-hub-testnet',\n    };\n\n    const main = async () => {\n      try {\n        const provider = createProvider(\n          PROVIDER_RPC.rpc,\n          PROVIDER_RPC.chainId,\n          PROVIDER_RPC.name,\n        );\n        const latestBlock = await provider.getBlockNumber();\n        console.log(`Latest block: ${latestBlock}`);\n      } catch (error) {\n        console.error('Error connecting to Polkadot Hub TestNet: ' + error.message);\n      }\n    };\n\n    main();\n\n    ```"}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 6, "depth": 2, "title": "Compile Contracts", "anchor": "compile-contracts", "start_char": 4683, "end_char": 5012, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "## Compile Contracts\n\nPolkadot Hub exposes an Ethereum JSON-RPC endpoint, so you can compile Solidity contracts to familiar EVM bytecode with the upstream [`solc`](https://www.npmjs.com/package/solc){target=\\_blank} compiler. The resulting artifacts work with any EVM-compatible toolchain and can be deployed through Ethers.js."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 7, "depth": 3, "title": "Sample Storage Smart Contract", "anchor": "sample-storage-smart-contract", "start_char": 5012, "end_char": 5837, "estimated_token_count": 171, "token_estimator": "heuristic-v1", "text": "### Sample Storage Smart Contract\n\nThis example demonstrates compiling a `Storage.sol` Solidity contract for deployment to Polkadot Hub. The contract's functionality stores a number and permits users to update it with a new value.\n\n```solidity title=\"contracts/Storage.sol\"\n//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 8, "depth": 3, "title": "Compile the Smart Contract", "anchor": "compile-the-smart-contract", "start_char": 5837, "end_char": 9394, "estimated_token_count": 810, "token_estimator": "heuristic-v1", "text": "### Compile the Smart Contract\n\nTo compile this contract, use the following script:\n\n```js title=\"scripts/compile.js\"\nconst solc = require('solc');\nconst { readFileSync, writeFileSync, mkdirSync, existsSync } = require('fs');\nconst { basename, join } = require('path');\n\nconst ensureDir = (dirPath) => {\n  if (!existsSync(dirPath)) {\n    mkdirSync(dirPath, { recursive: true });\n  }\n};\n\nconst compileContract = (solidityFilePath, abiDir, artifactsDir) => {\n  try {\n    // Read the Solidity file\n    const source = readFileSync(solidityFilePath, 'utf8');\n    const fileName = basename(solidityFilePath);\n    \n    // Construct the input object for the Solidity compiler\n    const input = {\n      language: 'Solidity',\n      sources: {\n        [fileName]: {\n          content: source,\n        },\n      },\n      settings: {\n        outputSelection: {\n          '*': {\n            '*': ['abi', 'evm.bytecode'],\n          },\n        },\n      },\n    };\n    \n    console.log(`Compiling contract: ${fileName}...`);\n    \n    // Compile the contract\n    const output = JSON.parse(solc.compile(JSON.stringify(input)));\n    \n    // Check for errors\n    if (output.errors) {\n      const errors = output.errors.filter(error => error.severity === 'error');\n      if (errors.length > 0) {\n        console.error('Compilation errors:');\n        errors.forEach(err => console.error(err.formattedMessage));\n        return;\n      }\n      // Show warnings\n      const warnings = output.errors.filter(error => error.severity === 'warning');\n      warnings.forEach(warn => console.warn(warn.formattedMessage));\n    }\n    \n    // Ensure output directories exist\n    ensureDir(abiDir);\n    ensureDir(artifactsDir);\n\n    // Process compiled contracts\n    for (const [sourceFile, contracts] of Object.entries(output.contracts)) {\n      for (const [contractName, contract] of Object.entries(contracts)) {\n        console.log(`Compiled contract: ${contractName}`);\n        \n        // Write the ABI\n        const abiPath = join(abiDir, `${contractName}.json`);\n        writeFileSync(abiPath, JSON.stringify(contract.abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n        \n        // Write the bytecode\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        writeFileSync(bytecodePath, contract.evm.bytecode.object);\n        console.log(`Bytecode saved to ${bytecodePath}`);\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath = join(__dirname, '../contracts/Storage.sol');\nconst abiDir = join(__dirname, '../abis');\nconst artifactsDir = join(__dirname, '../artifacts');\n\ncompileContract(solidityFilePath, abiDir, artifactsDir);\n```\n\n!!! note \n     The script above is tailored to the `Storage.sol` contract. It can be adjusted for other contracts by changing the file name or modifying the ABI and bytecode paths.\n\nThe ABI (Application Binary Interface) is a JSON representation of your contract's functions, events, and their parameters. It serves as the interface between your JavaScript code and the deployed smart contract, allowing your application to know how to format function calls and interpret returned data.\n\nExecute the script above by running:\n\n```bash\nnode scripts/compile.js\n```\n\nAfter executing the script, the Solidity contract is compiled into standard EVM bytecode. The ABI and bytecode are saved into files with `.json` and `.bin` extensions, respectively. You can now proceed with deploying the contract to Polkadot Hub, as outlined in the next section."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 9, "depth": 2, "title": "Deploy the Compiled Contract", "anchor": "deploy-the-compiled-contract", "start_char": 9394, "end_char": 17247, "estimated_token_count": 1672, "token_estimator": "heuristic-v1", "text": "## Deploy the Compiled Contract\n\nTo deploy your compiled contract to Polkadot Hub, you'll need a wallet with a private key to sign the deployment transaction.\n\nYou can create a `deploy.js` script in the root of your project to achieve this. The deployment script can be divided into key components:\n\n1. Set up the required imports and utilities:\n\n    ```js title=\"scripts/deploy.js\"\n    const { writeFileSync, existsSync, readFileSync } = require('fs');\n    const { join } = require('path');\n    const { ethers, JsonRpcProvider } = require('ethers');\n\n    ```\n\n2. Create a provider to connect to Polkadot Hub:\n\n    ```js title=\"scripts/deploy.js\"\n\n    // Creates a provider with specified RPC URL and chain details\n    const createProvider = (rpcUrl, chainId, chainName) => {\n      const provider = new JsonRpcProvider(rpcUrl, {\n        chainId: chainId,\n        name: chainName,\n      });\n      return provider;\n    };\n    ```\n \n3. Set up functions to read contract artifacts:\n\n    ```js title=\"scripts/deploy.js\"\n    // Reads and parses the ABI file for a given contract\n    const getAbi = (contractName) => {\n      try {\n        const abiPath = join(artifactsDir, `${contractName}.json`);\n        return JSON.parse(readFileSync(abiPath, 'utf8'));\n      } catch (error) {\n        console.error(\n          `Could not find ABI for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    // Reads the compiled bytecode for a given contract\n    const getByteCode = (contractName) => {\n      try {\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        const bytecode = readFileSync(bytecodePath, 'utf8').trim();\n        // Add 0x prefix if not present\n        return bytecode.startsWith('0x') ? bytecode : `0x${bytecode}`;\n      } catch (error) {\n        console.error(\n          `Could not find bytecode for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    ```\n\n4. Create the main deployment function:\n\n    ```js title=\"scripts/deploy.js\"\n    const deployContract = async (contractName, mnemonic, providerConfig) => {\n      console.log(`Deploying ${contractName}...`);\n      try {\n        // Step 1: Set up provider and wallet\n        const provider = createProvider(\n          providerConfig.rpc,\n          providerConfig.chainId,\n          providerConfig.name,\n        );\n        const walletMnemonic = ethers.Wallet.fromPhrase(mnemonic);\n        const wallet = walletMnemonic.connect(provider);\n\n        // Step 2: Create and deploy the contract\n        const factory = new ethers.ContractFactory(\n          getAbi(contractName),\n          getByteCode(contractName),\n          wallet,\n        );\n        const contract = await factory.deploy();\n        await contract.waitForDeployment();\n\n        // Step 3: Save deployment information\n        const address = await contract.getAddress();\n        console.log(`Contract ${contractName} deployed at: ${address}`);\n\n        const addressesFile = join(scriptsDir, 'contract-address.json');\n        const addresses = existsSync(addressesFile)\n          ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n          : {};\n\n        addresses[contractName] = address;\n        writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n      } catch (error) {\n        console.error(`Failed to deploy contract ${contractName}:`, error);\n      }\n    };\n    ```\n\n5. Configure and execute the deployment:\n\n    ```js title=\"scripts/deploy.js\"\n    const providerConfig = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io', //TODO: replace to `https://services.polkadothub-rpc.com/testnet` when ready\n      chainId: 420420422,\n      name: 'polkadot-hub-testnet',\n    };\n\n    const mnemonic = 'INSERT_MNEMONIC';\n\n    deployContract('Storage', mnemonic, providerConfig);\n    ```\n\n    !!! note\n        A mnemonic (seed phrase) is a series of words that can generate multiple private keys and their corresponding addresses. It's used here to derive the wallet that will sign and pay for the deployment transaction. **Always keep your mnemonic secure and never share it publicly**.\n\n        Ensure to replace the `INSERT_MNEMONIC` placeholder with your actual mnemonic.\n\n??? code \"View complete script\"\n\n    ```js title=\"scripts/deploy.js\"\n    const { writeFileSync, existsSync, readFileSync } = require('fs');\n    const { join } = require('path');\n    const { ethers, JsonRpcProvider } = require('ethers');\n\n    const scriptsDir = __dirname;\n    const artifactsDir = join(__dirname, '../contracts');\n\n    // Creates a provider with specified RPC URL and chain details\n    const createProvider = (rpcUrl, chainId, chainName) => {\n      const provider = new JsonRpcProvider(rpcUrl, {\n        chainId: chainId,\n        name: chainName,\n      });\n      return provider;\n    };\n\n    // Reads and parses the ABI file for a given contract\n    const getAbi = (contractName) => {\n      try {\n        const abiPath = join(artifactsDir, `${contractName}.json`);\n        return JSON.parse(readFileSync(abiPath, 'utf8'));\n      } catch (error) {\n        console.error(\n          `Could not find ABI for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    // Reads the compiled bytecode for a given contract\n    const getByteCode = (contractName) => {\n      try {\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        const bytecode = readFileSync(bytecodePath, 'utf8').trim();\n        // Add 0x prefix if not present\n        return bytecode.startsWith('0x') ? bytecode : `0x${bytecode}`;\n      } catch (error) {\n        console.error(\n          `Could not find bytecode for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    const deployContract = async (contractName, mnemonic, providerConfig) => {\n      console.log(`Deploying ${contractName}...`);\n      try {\n        // Step 1: Set up provider and wallet\n        const provider = createProvider(\n          providerConfig.rpc,\n          providerConfig.chainId,\n          providerConfig.name,\n        );\n        const walletMnemonic = ethers.Wallet.fromPhrase(mnemonic);\n        const wallet = walletMnemonic.connect(provider);\n\n        // Step 2: Create and deploy the contract\n        const factory = new ethers.ContractFactory(\n          getAbi(contractName),\n          getByteCode(contractName),\n          wallet,\n        );\n        const contract = await factory.deploy();\n        await contract.waitForDeployment();\n\n        // Step 3: Save deployment information\n        const address = await contract.getAddress();\n        console.log(`Contract ${contractName} deployed at: ${address}`);\n\n        const addressesFile = join(scriptsDir, 'contract-address.json');\n        const addresses = existsSync(addressesFile)\n          ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n          : {};\n\n        addresses[contractName] = address;\n        writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n      } catch (error) {\n        console.error(`Failed to deploy contract ${contractName}:`, error);\n      }\n    };\n\n    const providerConfig = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io', //TODO: replace to `https://services.polkadothub-rpc.com/testnet` when ready\n      chainId: 420420422,\n      name: 'polkadot-hub-testnet',\n    };\n\n    const mnemonic = 'INSERT_MNEMONIC';\n\n    deployContract('Storage', mnemonic, providerConfig);\n    ```\n\nTo run the script, execute the following command:\n\n```bash\nnode scripts/deploy.js\n```\n\nAfter running this script, your contract will be deployed to Polkadot Hub, and its address will be saved in `contract-address.json` within your project directory. You can use this address for future contract interactions."}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 10, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 17247, "end_char": 20687, "estimated_token_count": 751, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nOnce the contract is deployed, you can interact with it by calling its functions. For example, to set a number, read it and then modify that number by its double, you can create a file named `checkStorage.js` in the root of your project and add the following code:\n\n```js title=\"scripts/checkStorage.js\"\nconst { ethers } = require('ethers');\nconst { readFileSync } = require('fs');\nconst { join } = require('path');\n\nconst artifactsDir = join(__dirname, '../contracts');\n\nconst createProvider = (providerConfig) => {\n  return new ethers.JsonRpcProvider(providerConfig.rpc, {\n    chainId: providerConfig.chainId,\n    name: providerConfig.name,\n  });\n};\n\nconst createWallet = (mnemonic, provider) => {\n  return ethers.Wallet.fromPhrase(mnemonic).connect(provider);\n};\n\nconst loadContractAbi = (contractName, directory = artifactsDir) => {\n  const contractPath = join(directory, `${contractName}.json`);\n  const contractJson = JSON.parse(readFileSync(contractPath, 'utf8'));\n  return contractJson.abi || contractJson; // Depending on JSON structure\n};\n\nconst createContract = (contractAddress, abi, wallet) => {\n  return new ethers.Contract(contractAddress, abi, wallet);\n};\n\nconst interactWithStorageContract = async (\n  contractName,\n  contractAddress,\n  mnemonic,\n  providerConfig,\n  numberToSet,\n) => {\n  try {\n    console.log(`Setting new number in Storage contract: ${numberToSet}`);\n\n    // Create provider and wallet\n    const provider = createProvider(providerConfig);\n    const wallet = createWallet(mnemonic, provider);\n\n    // Load the contract ABI and create the contract instance\n    const abi = loadContractAbi(contractName);\n    const contract = createContract(contractAddress, abi, wallet);\n\n    // Send a transaction to set the stored number\n    const tx1 = await contract.setNumber(numberToSet);\n    await tx1.wait(); // Wait for the transaction to be mined\n    console.log(`Number successfully set to ${numberToSet}`);\n\n    // Retrieve the updated number\n    const storedNumber = await contract.storedNumber();\n    console.log(`Retrieved stored number:`, storedNumber.toString());\n\n    // Send a transaction to set the stored number\n    const tx2 = await contract.setNumber(numberToSet * 2);\n    await tx2.wait(); // Wait for the transaction to be mined\n    console.log(`Number successfully set to ${numberToSet * 2}`);\n\n    // Retrieve the updated number\n    const updatedNumber = await contract.storedNumber();\n    console.log(`Retrieved stored number:`, updatedNumber.toString());\n  } catch (error) {\n    console.error('Error interacting with Storage contract:', error.message);\n  }\n};\n\nconst providerConfig = {\n  name: 'asset-hub-smart-contracts',\n  rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  chainId: 420420422,\n};\n\nconst mnemonic = 'INSERT_MNEMONIC'\nconst contractName = 'Storage';\nconst contractAddress = 'INSERT_CONTRACT_ADDRESS'\nconst newNumber = 42;\n\ninteractWithStorageContract(\n  contractName,\n  contractAddress,\n  mnemonic,\n  providerConfig,\n  newNumber,\n);\n```\n\nEnsure you replace the `INSERT_MNEMONIC` and `INSERT_CONTRACT_ADDRESS` placeholders with actual values. Also, ensure the contract ABI file (`Storage.json`) is correctly referenced. The script prints the balance for `ADDRESS_TO_CHECK` before it writes and doubles the stored value, so pick any account you want to monitor.\n\nTo interact with the contract, run:\n\n```bash\nnode scripts/checkStorage.js\n```"}
{"page_id": "smart-contracts-libraries-ethers-js", "page_title": "Deploy Contracts to Polkadot Hub with Ethers.js", "index": 11, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 20687, "end_char": 21292, "estimated_token_count": 155, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundational knowledge to use Ethers.js with Polkadot Hub, you can:\n\n- **Dive into Ethers.js utilities**: Discover additional Ethers.js features, such as wallet management, signing messages, etc.\n- **Implement batch transactions**: Use Ethers.js to execute batch transactions for efficient multi-step contract interactions.\n- **Build scalable applications**: Combine Ethers.js with frameworks like [`Next.js`](https://nextjs.org/docs){target=\\_blank} or [`Node.js`](https://nodejs.org/en){target=\\_blank} to create full-stack decentralized applications (dApps)."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 8, "end_char": 285, "estimated_token_count": 56, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[viem](https://viem.sh/){target=\\_blank} is a lightweight TypeScript library designed for interacting with Ethereum-compatible blockchains. This comprehensive guide will walk you through using viem to interact with and deploy smart contracts to Polkadot Hub."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 285, "end_char": 641, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following installed:\n\n- **Node.js**: v22.13.1 or later, check the [Node.js installation guide](https://nodejs.org/en/download/current/){target=\\_blank}.\n- **npm**: v6.13.4 or later (comes bundled with Node.js).\n- **Solidity**: This guide uses Solidity `^0.8.9` for smart contract development."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 2, "depth": 2, "title": "Project Structure", "anchor": "project-structure", "start_char": 641, "end_char": 1067, "estimated_token_count": 125, "token_estimator": "heuristic-v1", "text": "## Project Structure\n\nThis project organizes contracts, scripts, and compiled artifacts for easy development and deployment.\n\n```text\nviem-project/\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tsconfig.json\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ chainConfig.ts\nâ”‚   â”œâ”€â”€ createClient.ts\nâ”‚   â”œâ”€â”€ createWallet.ts\nâ”‚   â”œâ”€â”€ compile.ts\nâ”‚   â”œâ”€â”€ deploy.ts\nâ”‚   â””â”€â”€ interact.ts\nâ”œâ”€â”€ contracts/\nâ”‚   â””â”€â”€ Storage.sol\nâ”œâ”€â”€ abis/\nâ”‚   â””â”€â”€ Storage.json\nâ””â”€â”€ artifacts/\n    â””â”€â”€ Storage.bin\n```"}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1067, "end_char": 1206, "estimated_token_count": 36, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\nFirst, create a new folder and initialize your project:\n\n```bash\nmkdir viem-project\ncd viem-project\nnpm init -y\n```"}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 4, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 1206, "end_char": 1579, "estimated_token_count": 86, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nInstall viem along with other necessary dependencies, including [`solc`](https://www.npmjs.com/package/solc){target=\\_blank}, which enables compiling smart contracts' EVM bytecode.\n\n```bash\n# Install viem and resolc\nnpm install viem solc\n\n# Install TypeScript and development dependencies\nnpm install --save-dev typescript ts-node @types/node\n```"}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 5, "depth": 2, "title": "Initialize Project", "anchor": "initialize-project", "start_char": 1579, "end_char": 2089, "estimated_token_count": 137, "token_estimator": "heuristic-v1", "text": "## Initialize Project\n\nInitialize a TypeScript project by running the following command:\n\n```bash\nnpx tsc --init\n```\n\nAdd the following scripts to your `package.json` file to enable running TypeScript files:\n\n```json\n{\n    \"scripts\": {\n        \"client\": \"ts-node src/createClient.ts\",\n        \"compile\": \"ts-node src/compile.ts\",\n        \"deploy\": \"ts-node src/deploy.ts\",\n        \"interact\": \"ts-node src/interact.ts\"\n    },\n}\n```\n\nCreate a directory for your TypeScript source files:\n\n```bash\nmkdir src\n```"}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 6, "depth": 2, "title": "Set Up the Chain Configuration", "anchor": "set-up-the-chain-configuration", "start_char": 2089, "end_char": 3044, "estimated_token_count": 205, "token_estimator": "heuristic-v1", "text": "## Set Up the Chain Configuration\n\nThe first step is to set up the chain configuration. Create a new file at `src/chainConfig.ts`:\n\n```typescript title=\"src/chainConfig.ts\"\nimport { http } from 'viem';\n\nexport const TRANSPORT = http('INSERT_RPC_URL');\n\n// Configure the Polkadot Hub chain\nexport const POLKADOT_HUB = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n```\n\nEnsure to replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, `INSERT_CHAIN_NAME`, `INSERT_NETWORK_NAME`, `INSERT_CHAIN_DECIMALS`, `INSERT_CURRENCY_NAME`, and `INSERT_CURRENCY_SYMBOL` with the proper values. Check the [Connect to Polkadot](/smart-contracts/connect/){target=\\_blank} page for more information on the possible values."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 7, "depth": 2, "title": "Set Up the viem Client", "anchor": "set-up-the-viem-client", "start_char": 3044, "end_char": 5252, "estimated_token_count": 505, "token_estimator": "heuristic-v1", "text": "## Set Up the viem Client\n\nTo interact with the chain, you need to create a client that is used solely for reading data. To accomplish this, create a new file at `src/createClient.ts`:\n\n```typescript title=\"src/createClient.ts\"\nimport { createPublicClient, createWalletClient, http } from 'viem';\n\nconst transport = http('INSERT_RPC_URL');\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n\n// Create a public client for reading data\nexport const publicClient = createPublicClient({\n  chain: assetHub,\n  transport,\n});\n\n```\n\nAfter setting up the [Public Client](https://viem.sh/docs/clients/public#public-client){target=\\_blank}, you can begin querying the blockchain. Here's an example of fetching the latest block number:\n\n??? code \"Fetch Last Block code\"\n\n    ```js title=\"src/fetchLastBlock.ts\"\n    import { createPublicClient, http } from 'viem';\n\n    const transport = http('https://testnet-passet-hub-eth-rpc.polkadot.io'); // TODO: change to paseo asset hub once ready\n\n    // Configure the Polkadot Hub chain\n    const polkadotHubTestnet = {\n      id: 420420422,\n      name: 'Polkadot Hub TestNet',\n      network: 'polkadot-hub-testnet',\n      nativeCurrency: {\n        decimals: 18,\n        name: 'PAS',\n        symbol: 'PAS',\n      },\n      rpcUrls: {\n        default: {\n          http: ['https://testnet-passet-hub-eth-rpc.polkadot.io'], // TODO: change to paseo asset hub once ready\n        },\n      },\n    } as const;\n\n    // Create a public client for reading data\n    export const publicClient = createPublicClient({\n      chain: polkadotHubTestnet,\n      transport,\n    });\n\n    const main = async () => {\n      try {\n        const block = await publicClient.getBlock();\n        console.log('Last block: ' + block.number.toString());\n      } catch (error: unknown) {\n        console.error('Error connecting to Polkadot Hub TestNet: ' + error);\n      }\n    };\n\n    main();\n    ```"}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 8, "depth": 2, "title": "Set Up a Wallet", "anchor": "set-up-a-wallet", "start_char": 5252, "end_char": 6609, "estimated_token_count": 299, "token_estimator": "heuristic-v1", "text": "## Set Up a Wallet\n\nIn case you need to sign transactions, you will need to instantiate a [Wallet Client](https://viem.sh/docs/clients/wallet#wallet-client){target=\\_blank} object within your project. To do so, create `src/createWallet.ts`:\n\n```typescript title=\"src/createWallet.ts\"\nimport { privateKeyToAccount } from 'viem/accounts';\nimport { createWalletClient, http } from 'viem';\n\nconst transport = http('INSERT_RPC_URL');\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n    public: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n\n// Create a wallet client for writing data\nexport const createWallet = (privateKey: `0x${string}`) => {\n  const account = privateKeyToAccount(privateKey);\n  return createWalletClient({\n    account,\n    chain: assetHub,\n    transport,\n  });\n};\n```\n\n!!!note\n    The wallet you import with your private key must have sufficient funds to pay for transaction fees when deploying contracts or interacting with them. Make sure to fund your wallet with the appropriate native tokens for the network you're connecting to."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 9, "depth": 2, "title": "Sample Smart Contract", "anchor": "sample-smart-contract", "start_char": 6609, "end_char": 7590, "estimated_token_count": 204, "token_estimator": "heuristic-v1", "text": "## Sample Smart Contract\n\nThis example demonstrates compiling a `Storage.sol` Solidity contract for deployment to Polkadot Hub. The contract's functionality stores a number and permits users to update it with a new value.\n\n```bash\nmkdir contracts artifacts\n```\n\nYou can use the following contract to interact with the blockchain. Paste the following contract in `contracts/Storage.sol`:\n\n```solidity title=\"contracts/Storage.sol\"\n//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 10, "depth": 2, "title": "Compile the Contract", "anchor": "compile-the-contract", "start_char": 7590, "end_char": 10649, "estimated_token_count": 723, "token_estimator": "heuristic-v1", "text": "## Compile the Contract\n\nCreate a new file at `src/compile.ts` for handling contract compilation:\n\n```typescript title=\"src/compile.ts\"\nimport solc from 'solc';\nimport { readFileSync, writeFileSync, mkdirSync, existsSync } from 'fs';\nimport { basename, join } from 'path';\n\nconst ensureDir = (dirPath: string): void => {\n  if (!existsSync(dirPath)) {\n    mkdirSync(dirPath, { recursive: true });\n  }\n};\n\nconst compileContract = (\n  solidityFilePath: string,\n  abiDir: string,\n  artifactsDir: string\n): void => {\n  try {\n    // Read the Solidity file\n    const source: string = readFileSync(solidityFilePath, 'utf8');\n    const fileName: string = basename(solidityFilePath);\n    \n    // Construct the input object for the Solidity compiler\n    const input = {\n      language: 'Solidity',\n      sources: {\n        [fileName]: {\n          content: source,\n        },\n      },\n      settings: {\n        outputSelection: {\n          '*': {\n            '*': ['abi', 'evm.bytecode'],\n          },\n        },\n      },\n    };\n    \n    console.log(`Compiling contract: ${fileName}...`);\n    \n    // Compile the contract\n    const output = JSON.parse(solc.compile(JSON.stringify(input)));\n    \n    // Check for errors\n    if (output.errors) {\n      const errors = output.errors.filter((error: any) => error.severity === 'error');\n      if (errors.length > 0) {\n        console.error('Compilation errors:');\n        errors.forEach((err: any) => console.error(err.formattedMessage));\n        return;\n      }\n      // Show warnings\n      const warnings = output.errors.filter((error: any) => error.severity === 'warning');\n      warnings.forEach((warn: any) => console.warn(warn.formattedMessage));\n    }\n    \n    // Ensure output directories exist\n    ensureDir(abiDir);\n    ensureDir(artifactsDir);\n    \n    // Process compiled contracts\n    for (const [sourceFile, contracts] of Object.entries(output.contracts)) {\n      for (const [contractName, contract] of Object.entries(contracts as any)) {\n        console.log(`Compiled contract: ${contractName}`);\n        \n        // Write the ABI\n        const abiPath = join(abiDir, `${contractName}.json`);\n        writeFileSync(abiPath, JSON.stringify((contract as any).abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n        \n        // Write the bytecode\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        writeFileSync(bytecodePath, (contract as any).evm.bytecode.object);\n        console.log(`Bytecode saved to ${bytecodePath}`);\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath: string = './contracts/Storage.sol';\nconst abiDir: string = './abis';\nconst artifactsDir: string = './artifacts';\n\ncompileContract(solidityFilePath, abiDir, artifactsDir);\n```\n\nTo compile your contract:\n\n```bash\nnpm run compile\n```\n\nAfter executing this script, you will see the compilation results including the generated `Storage.json` (containing the contract's ABI) and `Storage.bin` (containing the compiled bytecode)."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 11, "depth": 2, "title": "Deploy the Contract", "anchor": "deploy-the-contract", "start_char": 10649, "end_char": 13274, "estimated_token_count": 610, "token_estimator": "heuristic-v1", "text": "## Deploy the Contract\n\nCreate a new file at `src/deploy.ts` for handling contract deployment:\n\n```typescript title=\"src/deploy.ts\"\nimport { existsSync, readFileSync } from 'fs';\nimport { dirname, join } from 'path';\nimport { fileURLToPath } from 'url';\nimport { createWallet } from './createWallet.ts';\nimport { publicClient } from './createClient.ts';\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\nconst ABIS_DIR = join(__dirname, '../abis');\nconst ARTIFACTS_DIR = join(__dirname, '../artifacts');\n\nconst deployContract = async (\n  contractName: string,\n  privateKey: `0x${string}`\n) => {\n  try {\n    console.log(`Deploying ${contractName}...`);\n\n    const abiPath = join(ABIS_DIR, `${contractName}.json`);\n    const bytecodePath = join(ARTIFACTS_DIR, `${contractName}.bin`);\n\n    if (!existsSync(abiPath) || !existsSync(bytecodePath)) {\n      throw new Error(\n        `Missing artifacts for ${contractName}. Try running \"npm run compile\" first.`\n      );\n    }\n\n    // Read contract artifacts\n    const abi = JSON.parse(\n      readFileSync(abiPath, 'utf8')\n    );\n    const bytecode = `0x${readFileSync(bytecodePath, 'utf8').trim()}` as `0x${string}`;\n\n    // Create wallet\n    const wallet = createWallet(privateKey);\n\n    // Deploy contract\n    const hash = await wallet.deployContract({\n      abi,\n      bytecode,\n      args: [], // Add constructor arguments if needed\n    });\n\n    // Wait for deployment\n    const receipt = await publicClient.waitForTransactionReceipt({ hash });\n    const contractAddress = receipt.contractAddress;\n\n    console.log(`Contract deployed at: ${contractAddress}`);\n    return contractAddress;\n  } catch (error) {\n    console.error('Deployment failed:', error);\n    throw error;\n  }\n};\n\nconst privateKey = 'INSERT_PRIVATE_KEY';\ndeployContract('Storage', privateKey);\n```\n\nEnsure to replace `INSERT_PRIVATE_KEY` with the proper value. For further details on private key exportation, refer to the article [How to export an account's private key](https://support.metamask.io/configure/accounts/how-to-export-an-accounts-private-key/){target=\\_blank}.\n\n!!! warning\n    Never commit or share your private key. Exposed keys can lead to immediate theft of all associated funds. Use environment variables instead.\n\nTo deploy, run the following command:\n\n```bash\nnpm run deploy\n```\n\nIf everything is successful, you will see the address of your deployed contract displayed in the terminal. This address is unique to your contract on the network you defined in the chain configuration, and you'll need it for any future interactions with your contract."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 12, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 13274, "end_char": 15647, "estimated_token_count": 510, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nCreate a new file at `src/interact.ts` for interacting with your deployed contract:\n\n```typescript title=\"src/interact.ts\"\nimport { readFileSync } from 'fs';\nimport { dirname, join } from 'path';\nimport { fileURLToPath } from 'url';\nimport { publicClient } from './createClient.ts';\nimport { createWallet } from './createWallet.ts';\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\nconst ABI_PATH = join(__dirname, '../abis/Storage.json');\n\nconst STORAGE_ABI = JSON.parse(readFileSync(ABI_PATH, 'utf8'));\n\nconst interactWithStorage = async (\n  contractAddress: `0x${string}`,\n  privateKey: `0x${string}`\n) => {\n  try {\n    const wallet = createWallet(privateKey);\n    const currentNumber = await publicClient.readContract({\n      address: contractAddress,\n      abi: STORAGE_ABI,\n      functionName: 'storedNumber',\n      args: [],\n    });\n    console.log(`Stored number: ${currentNumber}`);\n\n    const newNumber = BigInt(42);\n    const { request } = await publicClient.simulateContract({\n      address: contractAddress,\n      abi: STORAGE_ABI,\n      functionName: 'setNumber',\n      args: [newNumber],\n      account: wallet.account,\n    });\n\n    const hash = await wallet.writeContract(request);\n    await publicClient.waitForTransactionReceipt({ hash });\n    console.log(`Number updated to ${newNumber}`);\n\n    const updatedNumber = await publicClient.readContract({\n      address: contractAddress,\n      abi: STORAGE_ABI,\n      functionName: 'storedNumber',\n      args: [],\n    });\n    console.log('Updated stored number:', updatedNumber);\n  } catch (error) {\n    console.error('Interaction failed:', error);\n  }\n};\n\nconst PRIVATE_KEY = 'INSERT_PRIVATE_KEY';\nconst CONTRACT_ADDRESS = 'INSERT_CONTRACT_ADDRESS';\n\ninteractWithStorage(CONTRACT_ADDRESS, PRIVATE_KEY);\n```\n\nEnsure to replace `INSERT_PRIVATE_KEY` and `INSERT_CONTRACT_ADDRESS` with the proper values.\n\nTo interact with the contract:\n\n```bash\nnpm run interact\n```\n\nFollowing a successful interaction, you will see the stored value before and after the transaction. The output will show the initial stored number (0 if you haven't modified it yet), confirm when the transaction to set the number to 42 is complete, and then display the updated stored number value. This demonstrates both reading from and writing to your smart contract."}
{"page_id": "smart-contracts-libraries-viem", "page_title": "viem for Polkadot Hub Smart Contracts", "index": 13, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 15647, "end_char": 17416, "estimated_token_count": 545, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundation for using viem with Polkadot Hub, consider exploring:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Advanced viem Features__\n\n    ---\n    Explore viem's documentation:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Multi call](https://viem.sh/docs/contract/multicall#multicall){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Batch transactions](https://viem.sh/docs/clients/transports/http#batch-json-rpc){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Custom actions](https://viem.sh/docs/clients/custom#extending-with-actions-or-configuration){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Test Frameworks__\n\n    ---\n\n    Integrate viem with the following frameworks for comprehensive testing:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Hardhat](https://hardhat.org/){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Foundry](https://getfoundry.sh/){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Event Handling__\n\n    ---\n\n    Learn how to subscribe to and process contract events:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Event subscription](https://viem.sh/docs/actions/public/watchEvent#watchevent){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Building dApps__\n\n    ---\n\n    Combine viem the following technologies to create full-stack applications:\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Next.js](https://nextjs.org/docs){target=\\_blank}</li>\n\n    <li>[:octicons-arrow-right-24: Node.js](https://nodejs.org/en){target=\\_blank}</li>\n    </ul>\n\n</div>"}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 9, "end_char": 437, "estimated_token_count": 97, "token_estimator": "heuristic-v1", "text": "## Introduction\n\n[Wagmi](https://wagmi.sh/){target=\\_blank} is a collection of [React Hooks](https://wagmi.sh/react/api/hooks){target=\\_blank} for interacting with Ethereum-compatible blockchains, focusing on developer experience, feature richness, and reliability.\n\nThis guide demonstrates how to use Wagmi to interact with and deploy smart contracts to Polkadot Hub, providing a seamless frontend integration for your dApps."}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 1, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 437, "end_char": 668, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nTo start working with Wagmi, create a new React project and initialize it by running the following commands in your terminal:\n\n```bash\nnpx create-next-app@latest wagmi-polkadot-hub\ncd wagmi-polkadot-hub\n```"}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 2, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 668, "end_char": 798, "estimated_token_count": 31, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nInstall Wagmi v3 and its peer dependencies:\n\n```bash\nnpm install wagmi@3 viem @tanstack/react-query\n```"}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 3, "depth": 2, "title": "Configure Wagmi for Polkadot Hub", "anchor": "configure-wagmi-for-polkadot-hub", "start_char": 798, "end_char": 2532, "estimated_token_count": 392, "token_estimator": "heuristic-v1", "text": "## Configure Wagmi for Polkadot Hub\n\nCreate a configuration file to initialize Wagmi with Polkadot Hub. In your project, create a file named `app/lib/wagmi.ts` and add the code below. Be sure to replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, `INSERT_CHAIN_NAME`, `INSERT_NETWORK_NAME`, `INSERT_CHAIN_DECIMALS`, `INSERT_CURRENCY_NAME`, and `INSERT_CURRENCY_SYMBOL` with your specific values.\n\n```typescript title=\"app/lib/wagmi.ts\"\nimport { http, createConfig } from 'wagmi'\n\n// Configure the Polkadot Hub chain\nconst assetHub = {\n  id: INSERT_CHAIN_ID,\n  name: 'INSERT_CHAIN_NAME',\n  network: 'INSERT_NETWORK_NAME',\n  nativeCurrency: {\n    decimals: INSERT_CHAIN_DECIMALS,\n    name: 'INSERT_CURRENCY_NAME',\n    symbol: 'INSERT_CURRENCY_SYMBOL',\n  },\n  rpcUrls: {\n    default: {\n      http: ['INSERT_RPC_URL'],\n    },\n  },\n} as const;\n\n// Create Wagmi config\nexport const config = createConfig({\n  chains: [assetHub],\n  transports: {\n    [assetHub.id]: http(),\n  },\n})\n```\n\n??? code \"Example Polkadot Hub TestNet Configuration\"\n\n    ```typescript title=\"src/lib/wagmi.ts\"\n    import { http, createConfig } from 'wagmi';\n\n    // Configure the Polkadot Hub chain\n    const assetHub = {\n      id: 420420422,\n      name: 'polkadot-hub-testnet',\n      network: 'polkadot-hub-testnet',\n      nativeCurrency: {\n        decimals: 18,\n        name: 'PAS',\n        symbol: 'PAS',\n      },\n      rpcUrls: {\n        default: {\n          http: ['https://testnet-passet-hub-eth-rpc.polkadot.io'], // TODO: change to paseo asset hub once ready\n        },\n      },\n    } as const;\n\n    // Create wagmi config\n    export const config = createConfig({\n      chains: [assetHub],\n      transports: {\n        [assetHub.id]: http(),\n      },\n    });\n    ```"}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 4, "depth": 2, "title": "Set Up the Wagmi Provider", "anchor": "set-up-the-wagmi-provider", "start_char": 2532, "end_char": 3576, "estimated_token_count": 263, "token_estimator": "heuristic-v1", "text": "## Set Up the Wagmi Provider\n\nTo enable Wagmi in your React application, you need to wrap your app with the [`WagmiProvider`](https://wagmi.sh/react/api/WagmiProvider#wagmiprovider){target=\\_blank}. Update your `app/layout.tsx` file (for Next.js app router) with the following code:\n\n```typescript title=\"app/layout.tsx\"\n// For app router (src/app/layout.tsx)\n\"use client\";\n\nimport { WagmiProvider } from \"wagmi\";\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { config } from \"./lib/wagmi\";\n\n// Create a query client\nconst queryClient = new QueryClient();\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body>\n        <WagmiProvider config={config}>\n          <QueryClientProvider client={queryClient}>\n            {children}\n          </QueryClientProvider>\n        </WagmiProvider>\n      </body>\n    </html>\n  );\n}\n\n```\n\n!!!note\n    If you are using a Next.js pages router, you should modify the `src/pages/_app.tsx` instead."}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 5, "depth": 2, "title": "Connect a Wallet", "anchor": "connect-a-wallet", "start_char": 3576, "end_char": 5105, "estimated_token_count": 382, "token_estimator": "heuristic-v1", "text": "## Connect a Wallet\n\nCreate a component to connect wallets to your dApp. Create a file named `app/components/ConnectWallet.tsx`:\n\n```typescript title=\"app/components/ConnectWallet.tsx\"\n\"use client\";\n\nimport React from \"react\";\nimport { useConnect, useConnection, useDisconnect } from \"wagmi\";\nimport { injected } from \"wagmi/connectors\";\n\nexport function ConnectWallet() {\n  const { connect } = useConnect();\n  const { address, isConnected } = useConnection();\n  const { disconnect } = useDisconnect();\n\n  if (isConnected) {\n    return (\n      <div>\n        <div>Connected to {address}</div>\n        <button onClick={() => disconnect()}>Disconnect</button>\n      </div>\n    );\n  }\n\n  return (\n    <button onClick={() => connect({ connector: injected() })}>\n      Connect Wallet\n    </button>\n  );\n}\n\n```\n\nThis component uses the following React hooks:\n\n- **[`useConnect`](https://wagmi.sh/react/api/hooks/useConnect#useconnect){target=\\_blank}**: Provides functions and state for connecting the user's wallet to your dApp. The `connect` function initiates the connection flow with the specified connector.\n- **[`useDisconnect`](https://wagmi.sh/react/api/hooks/useDisconnect#usedisconnect){target=\\_blank}**: Provides a function to disconnect the currently connected wallet.\n- **[`useConnection`](https://wagmi.sh/react/api/hooks/useConnection#useconnection){target=\\_blank}**: Returns data about the connected account, including the address and connection status. In Wagmi v3, `useAccount` has been renamed to `useConnection`."}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 6, "depth": 2, "title": "Fetch Blockchain Data", "anchor": "fetch-blockchain-data", "start_char": 5105, "end_char": 6591, "estimated_token_count": 359, "token_estimator": "heuristic-v1", "text": "## Fetch Blockchain Data\n\nWagmi provides various hooks to fetch blockchain data. Here's an example component that demonstrates some of these hooks:\n\n```typescript title=\"app/components/BlockchainInfo.tsx\"\n\"use client\";\n\nimport { useBlockNumber, useBalance, useConnection } from \"wagmi\";\n\nexport function BlockchainInfo() {\n  const { address } = useConnection();\n  // Get the latest block number\n  const { data: blockNumber } = useBlockNumber({ watch: true });\n\n  // Get balance for the connected wallet\n  const { data: balance } = useBalance({\n    address,\n  });\n\n  return (\n    <div>\n      <h2>Blockchain Information</h2>\n      <div>\n        <p>Current Block: {blockNumber?.toString() || \"Loading...\"}</p>\n\n        {address && balance && (\n          <p>\n            Balance:{\" \"}\n            {(\n              BigInt(balance.value) / BigInt(10 ** balance.decimals)\n            ).toLocaleString()}{\" \"}\n            {balance.symbol}\n          </p>\n        )}\n      </div>\n    </div>\n  );\n}\n\n```\n\nThis component uses the following React hooks:\n\n- **[`useBlockNumber`](https://wagmi.sh/react/api/hooks/useBlockNumber#useBlockNumber){target=\\_blank}**: Fetches the current block number of the connected chain. The `watch` parameter enables real-time updates when new blocks are mined.\n- **[`useBalance`](https://wagmi.sh/react/api/hooks/useBalance#useBalance){target=\\_blank}**: Retrieves the native token balance for a specified address, including value, symbol, and decimals information."}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 7, "depth": 2, "title": "Interact with Deployed Contract", "anchor": "interact-with-deployed-contract", "start_char": 6591, "end_char": 11034, "estimated_token_count": 984, "token_estimator": "heuristic-v1", "text": "## Interact with Deployed Contract\n\nThis guide uses a simple Storage contract already deployed to the Polkadot Hub TestNet. The code of that contract is:\n\n??? code \"Storage.sol\"\n\n    ```solidity title=\"Storage.sol\"\n    //SPDX-License-Identifier: MIT\n\n    // Solidity files have to start with this pragma.\n    // It will be used by the Solidity compiler to validate its version.\n    pragma solidity ^0.8.9;\n\n    contract Storage {\n        // Public state variable to store a number\n        uint256 public storedNumber;\n\n        /**\n        * Updates the stored number.\n        *\n        * The `public` modifier allows anyone to call this function.\n        *\n        * @param _newNumber - The new value to store.\n        */\n        function setNumber(uint256 _newNumber) public {\n            storedNumber = _newNumber;\n        }\n    }\n    ```\n\nCreate a component to interact with your deployed contract. Create a file named `app/components/StorageContract.tsx`:\n\n```typescript title=\"app/components/StorageContract.tsx\"\n\"use client\";\n\nimport { useState } from \"react\";\nimport {\n  useReadContract,\n  useWriteContract,\n  useWaitForTransactionReceipt,\n} from \"wagmi\";\n\nconst CONTRACT_ADDRESS =\n  \"INSERT_CONTRACT_ADDRESS\" as `0x${string}`;\n\nexport function StorageContract() {\n  const [number, setNumber] = useState<string>(\"42\");\n\n  // Contract ABI (should match your compiled contract)\n  const abi = [\n    {\n      inputs: [],\n      name: \"storedNumber\",\n      outputs: [{ internalType: \"uint256\", name: \"\", type: \"uint256\" }],\n      stateMutability: \"view\",\n      type: \"function\",\n    },\n    {\n      inputs: [\n        { internalType: \"uint256\", name: \"_newNumber\", type: \"uint256\" },\n      ],\n      name: \"setNumber\",\n      outputs: [],\n      stateMutability: \"nonpayable\",\n      type: \"function\",\n    },\n  ];\n\n  // Read the current stored number\n  const { data: storedNumber, refetch } = useReadContract({\n    address: CONTRACT_ADDRESS,\n    abi,\n    functionName: \"storedNumber\",\n  });\n\n  // Write to the contract\n  const { writeContract, data: hash, error, isPending } = useWriteContract();\n\n  // Wait for transaction to be mined\n  const { isLoading: isConfirming, isSuccess: isConfirmed } =\n    useWaitForTransactionReceipt({\n      hash,\n    });\n\n  const handleSetNumber = () => {\n    writeContract({\n      address: CONTRACT_ADDRESS,\n      abi,\n      functionName: \"setNumber\",\n      args: [BigInt(number)],\n    });\n  };\n\n  return (\n    <div>\n      <h2>Storage Contract Interaction</h2>\n      <div>\n        <p>Contract Address: {CONTRACT_ADDRESS}</p>\n        <p>Current Stored Number: {storedNumber?.toString() || \"Loading...\"}</p>\n      </div>\n\n      <div>\n        <input\n          type=\"number\"\n          value={number}\n          onChange={(e) => setNumber(e.target.value)}\n          disabled={isPending || isConfirming}\n        />\n        <button onClick={handleSetNumber} disabled={isPending || isConfirming}>\n          {isPending\n            ? \"Waiting for approval...\"\n            : isConfirming\n            ? \"Confirming...\"\n            : \"Set Number\"}\n        </button>\n      </div>\n\n      {error && <div className=\"error-message\">Error: {error.message}</div>}\n\n      {isConfirmed && (\n        <div className=\"success-message\">\n          Successfully updated!{\" \"}\n          <button onClick={() => refetch()}>Refresh</button>\n        </div>\n      )}\n    </div>\n  );\n}\n\n```\n\nThis component demonstrates how to interact with a smart contract using Wagmi's hooks:\n\n- **[`useReadContract`](https://wagmi.sh/react/api/hooks/useReadContract#useReadContract){target=\\_blank}**: Calls a read-only function on your smart contract to retrieve data without modifying the blockchain state.\n- **[`useWriteContract`](https://wagmi.sh/react/api/hooks/useWriteContract#useWriteContract){target=\\_blank}**: Calls a state-modifying function on your smart contract, which requires a transaction to be signed and sent.\n- **[`useWaitForTransactionReceipt`](https://wagmi.sh/react/api/hooks/useWaitForTransactionReceipt#useWaitForTransactionReceipt){target=\\_blank}**: Tracks the status of a transaction after it's been submitted, allowing you to know when it's been confirmed.\n\nThe component also includes proper state handling to:\n\n- Show the current value stored in the contract.\n- Allow users to input a new value.\n- Display transaction status (pending, confirming, or completed).\n- Handle errors.\n- Provide feedback when a transaction is successful."}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 8, "depth": 2, "title": "Integrate Components", "anchor": "integrate-components", "start_char": 11034, "end_char": 11792, "estimated_token_count": 183, "token_estimator": "heuristic-v1", "text": "## Integrate Components\n\nUpdate your main page to combine all the components. Create or update the file `src/app/page.tsx`:\n\n```typescript title=\"src/app/page.tsx\"\n\"use client\";\n\nimport { BlockchainInfo } from \"./components/BlockchainInfo\";\nimport { ConnectWallet } from \"./components/ConnectWallet\";\nimport { StorageContract } from \"./components/StorageContract\";\nimport { useConnection } from \"wagmi\";\n\nexport default function Home() {\n  const { isConnected } = useConnection();\n\n  return (\n    <main>\n      <h1>Wagmi - Polkadot Hub Smart Contracts</h1>\n      <ConnectWallet />\n      {isConnected ? <BlockchainInfo /> : <span>Connect your wallet</span>}\n      {isConnected ? <StorageContract /> : <span>Connect your wallet</span>}\n    </main>\n  );\n}\n\n```"}
{"page_id": "smart-contracts-libraries-wagmi", "page_title": "Wagmi for Polkadot Hub Smart Contracts", "index": 9, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 11792, "end_char": 13435, "estimated_token_count": 512, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\nNow that you have the foundational knowledge to use Wagmi with Polkadot Hub, consider exploring:\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Advanced Wagmi__\n\n    ---\n\n    Explore Wagmi's advanced features:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Watch Contract Events](https://wagmi.sh/core/api/actions/watchContractEvent#eventname){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Different Transports](https://wagmi.sh/react/api/transports){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Actions](https://wagmi.sh/react/api/actions){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Wallet Integration__\n\n    ---\n\n    Connect your dApp with popular wallet providers:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: MetaMask](https://wagmi.sh/core/api/connectors/metaMask){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: WalletConnect](https://wagmi.sh/core/api/connectors/walletConnect){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Coinbase Wallet](https://wagmi.sh/core/api/connectors/coinbaseWallet){target=\\_blank}</li>\n    </ul>\n\n-   <span class=\"badge external\">External</span> __Testing & Development__\n\n    ---\n\n    Enhance your development workflow:\n\n    <ul class=\"card-list\">\n    <li>[:octicons-arrow-right-24: Test Suite](https://wagmi.sh/dev/contributing#_6-running-the-test-suite){target=\\_blank}</li>\n    <li>[:octicons-arrow-right-24: Dev Playground](https://wagmi.sh/dev/contributing#_5-running-the-dev-playgrounds){target=\\_blank}</li>\n    </ul>\n</div>"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 298, "end_char": 857, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nInteracting with blockchains typically requires an interface between your application and the network. [Web3.js](https://web3js.readthedocs.io/){target=\\_blank} offers this interface through a comprehensive collection of libraries, facilitating seamless interaction with the nodes using HTTP or WebSocket protocols. This guide illustrates how to utilize Web3.js specifically for interactions with Polkadot Hub.\n\nThis guide is intended for developers who are familiar with JavaScript and want to interact with the Polkadot Hub using Web3.js."}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 1, "depth": 2, "title": "Prerequisites", "anchor": "prerequisites", "start_char": 857, "end_char": 1213, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Prerequisites\n\nBefore getting started, ensure you have the following installed:\n\n- **Node.js**: v22.13.1 or later, check the [Node.js installation guide](https://nodejs.org/en/download/current/){target=\\_blank}.\n- **npm**: v6.13.4 or later (comes bundled with Node.js).\n- **Solidity**: This guide uses Solidity `^0.8.9` for smart contract development."}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 2, "depth": 2, "title": "Project Structure", "anchor": "project-structure", "start_char": 1213, "end_char": 1691, "estimated_token_count": 135, "token_estimator": "heuristic-v1", "text": "## Project Structure\n\nThis project organizes contracts, scripts, and compiled artifacts for easy development and deployment.\n\n```text\nweb3js-project\nâ”œâ”€â”€ contracts\nâ”‚   â”œâ”€â”€ Storage.sol\nâ”œâ”€â”€ scripts\nâ”‚   â”œâ”€â”€ connectToProvider.js\nâ”‚   â”œâ”€â”€ fetchLastBlock.js\nâ”‚   â”œâ”€â”€ compile.js\nâ”‚   â”œâ”€â”€ deploy.js\nâ”‚   â”œâ”€â”€ updateStorage.js\nâ”œâ”€â”€ abis\nâ”‚   â”œâ”€â”€ Storage.json\nâ”œâ”€â”€ artifacts\nâ”‚   â”œâ”€â”€ Storage.bin\nâ”œâ”€â”€ contract-address.json\nâ”œâ”€â”€ node_modules/\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ package-lock.json\nâ””â”€â”€ README.md\n```"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 3, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 1691, "end_char": 1910, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\nTo start working with Web3.js, create a new folder and initialize your project by running the following commands in your terminal:\n\n```bash\nmkdir web3js-project\ncd web3js-project\nnpm init -y\n```"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 4, "depth": 2, "title": "Install Dependencies", "anchor": "install-dependencies", "start_char": 1910, "end_char": 2141, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Install Dependencies\n\nNext, run the following command to install the Web3.js library:\n\n```bash\nnpm install web3\n```\n\nAdd the Solidity compiler so you can generate standard EVM bytecode:\n\n```bash\nnpm install --save-dev solc\n```"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 5, "depth": 2, "title": "Set Up the Web3 Provider", "anchor": "set-up-the-web3-provider", "start_char": 2141, "end_char": 4335, "estimated_token_count": 500, "token_estimator": "heuristic-v1", "text": "## Set Up the Web3 Provider\n\nThe provider configuration is the foundation of any Web3.js application. It serves as a bridge between your application and the blockchain, allowing you to query blockchain data and interact with smart contracts.\n\nTo interact with Polkadot Hub, you must set up a Web3.js provider. This provider connects to a blockchain node, allowing you to query blockchain data and interact with smart contracts. In the `scripts` directory of your project, create a file named `connectToProvider.js` and add the following code:\n\n```js title=\"scripts/connectToProvider.js\"\nconst { Web3 } = require('web3');\n\nconst createProvider = (rpcUrl) => {\n  const web3 = new Web3(rpcUrl);\n  return web3;\n};\n\nconst PROVIDER_RPC = {\n  rpc: 'INSERT_RPC_URL',\n  chainId: 'INSERT_CHAIN_ID',\n  name: 'INSERT_CHAIN_NAME',\n};\n\ncreateProvider(PROVIDER_RPC.rpc);\n\n```\n\n!!! note\n    Replace `INSERT_RPC_URL`, `INSERT_CHAIN_ID`, and `INSERT_CHAIN_NAME` with the appropriate values. For example, to connect to Polkadot Hub TestNet's Ethereum RPC instance, you can use the following parameters:\n\n    ```js\n    const PROVIDER_RPC = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      chainId: 420420422,\n      name: 'polkadot-hub-testnet'\n    };\n    ```\n\nTo connect to the provider, execute:\n\n```bash\nnode scripts/connectToProvider.js\n```\n\nWith the provider set up, you can start querying the blockchain. For instance, to fetch the latest block number.\n\n??? code \"Fetch last block example\"\n\n    ```js title=\"scripts/fetchLastBlock.js\"\n    const { Web3 } = require('web3');\n\n    const createProvider = (rpcUrl) => {\n      const web3 = new Web3(rpcUrl);\n      return web3;\n    };\n\n    const PROVIDER_RPC = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n      chainId: 420420422,\n      name: 'polkadotTestNet',\n    };\n\n    const main = async () => {\n      try {\n        const web3 = createProvider(PROVIDER_RPC.rpc);\n        const latestBlock = await web3.eth.getBlockNumber();\n        console.log('Last block: ' + latestBlock);\n      } catch (error) {\n        console.error('Error connecting to Polkadot Hub TestNet: ' + error.message);\n      }\n    };\n\n    main();\n\n    ```"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 6, "depth": 2, "title": "Compile Contracts", "anchor": "compile-contracts", "start_char": 4335, "end_char": 4662, "estimated_token_count": 74, "token_estimator": "heuristic-v1", "text": "## Compile Contracts\n\nPolkadot Hub exposes an Ethereum JSON-RPC endpoint, so you can compile Solidity contracts to familiar EVM bytecode with the upstream [`solc`](https://www.npmjs.com/package/solc){target=\\_blank} compiler. The resulting artifacts work with any EVM-compatible toolchain and can be deployed through Web3.js."}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 7, "depth": 3, "title": "Sample Storage Smart Contract", "anchor": "sample-storage-smart-contract", "start_char": 4662, "end_char": 5367, "estimated_token_count": 145, "token_estimator": "heuristic-v1", "text": "### Sample Storage Smart Contract\n\nThis example demonstrates compiling a `Storage.sol` Solidity contract for deployment to Polkadot Hub. The contract's functionality stores a number and permits users to update it with a new value.\n\n```solidity title=\"contracts/Storage.sol\"\n//SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 8, "depth": 3, "title": "Compile the Smart Contract", "anchor": "compile-the-smart-contract", "start_char": 5367, "end_char": 8924, "estimated_token_count": 810, "token_estimator": "heuristic-v1", "text": "### Compile the Smart Contract\n\nTo compile this contract, use the following script:\n\n```js title=\"scripts/compile.js\"\nconst solc = require('solc');\nconst { readFileSync, writeFileSync, mkdirSync, existsSync } = require('fs');\nconst { basename, join } = require('path');\n\nconst ensureDir = (dirPath) => {\n  if (!existsSync(dirPath)) {\n    mkdirSync(dirPath, { recursive: true });\n  }\n};\n\nconst compileContract = (solidityFilePath, abiDir, artifactsDir) => {\n  try {\n    // Read the Solidity file\n    const source = readFileSync(solidityFilePath, 'utf8');\n    const fileName = basename(solidityFilePath);\n    \n    // Construct the input object for the Solidity compiler\n    const input = {\n      language: 'Solidity',\n      sources: {\n        [fileName]: {\n          content: source,\n        },\n      },\n      settings: {\n        outputSelection: {\n          '*': {\n            '*': ['abi', 'evm.bytecode'],\n          },\n        },\n      },\n    };\n    \n    console.log(`Compiling contract: ${fileName}...`);\n    \n    // Compile the contract\n    const output = JSON.parse(solc.compile(JSON.stringify(input)));\n    \n    // Check for errors\n    if (output.errors) {\n      const errors = output.errors.filter(error => error.severity === 'error');\n      if (errors.length > 0) {\n        console.error('Compilation errors:');\n        errors.forEach(err => console.error(err.formattedMessage));\n        return;\n      }\n      // Show warnings\n      const warnings = output.errors.filter(error => error.severity === 'warning');\n      warnings.forEach(warn => console.warn(warn.formattedMessage));\n    }\n    \n    // Ensure output directories exist\n    ensureDir(abiDir);\n    ensureDir(artifactsDir);\n\n    // Process compiled contracts\n    for (const [sourceFile, contracts] of Object.entries(output.contracts)) {\n      for (const [contractName, contract] of Object.entries(contracts)) {\n        console.log(`Compiled contract: ${contractName}`);\n        \n        // Write the ABI\n        const abiPath = join(abiDir, `${contractName}.json`);\n        writeFileSync(abiPath, JSON.stringify(contract.abi, null, 2));\n        console.log(`ABI saved to ${abiPath}`);\n        \n        // Write the bytecode\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        writeFileSync(bytecodePath, contract.evm.bytecode.object);\n        console.log(`Bytecode saved to ${bytecodePath}`);\n      }\n    }\n  } catch (error) {\n    console.error('Error compiling contracts:', error);\n  }\n};\n\nconst solidityFilePath = join(__dirname, '../contracts/Storage.sol');\nconst abiDir = join(__dirname, '../abis');\nconst artifactsDir = join(__dirname, '../artifacts');\n\ncompileContract(solidityFilePath, abiDir, artifactsDir);\n```\n\n!!! note \n     The script above is tailored to the `Storage.sol` contract. It can be adjusted for other contracts by changing the file name or modifying the ABI and bytecode paths.\n\nThe ABI (Application Binary Interface) is a JSON representation of your contract's functions, events, and their parameters. It serves as the interface between your JavaScript code and the deployed smart contract, allowing your application to know how to format function calls and interpret returned data.\n\nExecute the script above by running:\n\n```bash\nnode scripts/compile.js\n```\n\nAfter executing the script, the Solidity contract is compiled into standard EVM bytecode. The ABI and bytecode are saved into files with `.json` and `.bin` extensions, respectively. You can now proceed with deploying the contract to Polkadot Hub, as outlined in the next section."}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 9, "depth": 2, "title": "Deploy the Compiled Contract", "anchor": "deploy-the-compiled-contract", "start_char": 8924, "end_char": 16998, "estimated_token_count": 1793, "token_estimator": "heuristic-v1", "text": "## Deploy the Compiled Contract\n\nTo deploy your compiled contract to Polkadot Hub, you'll need a wallet with a private key to sign the deployment transaction.\n\nYou can create a `deploy.js` script in the `scripts` directory of your project to achieve this. The deployment script can be divided into key components:\n\n1. Set up the required imports and utilities:\n\n    ```js title=\"scripts/deploy.js\"\n    const { writeFileSync, existsSync, readFileSync } = require('fs');\n    const { join } = require('path');\n    const { Web3 } = require('web3');\n\n    const scriptsDir = __dirname;\n    const abisDir = join(__dirname, '../abis');\n    const artifactsDir = join(__dirname, '../artifacts');\n    ```\n\n2. Create a provider to connect to Polkadot Hub:\n\n    ```js title=\"scripts/deploy.js\"\n    const createProvider = (rpcUrl, chainId, chainName) => {\n      const web3 = new Web3(rpcUrl);\n      return web3;\n    };\n    ```\n\n3. Set up functions to read contract artifacts:\n\n    ```js title=\"scripts/deploy.js\"\n    const getAbi = (contractName) => {\n      try {\n        const abiPath = join(abisDir, `${contractName}.json`);\n        return JSON.parse(readFileSync(abiPath, 'utf8'));\n      } catch (error) {\n        console.error(\n          `Could not find ABI for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    const getByteCode = (contractName) => {\n      try {\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        const bytecode = readFileSync(bytecodePath, 'utf8').trim();\n        return bytecode.startsWith('0x') ? bytecode : `0x${bytecode}`;\n      } catch (error) {\n        console.error(\n          `Could not find bytecode for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n    ```\n\n4. Create the main deployment function:\n\n    ```js title=\"scripts/deploy.js\"\n    const deployContract = async (contractName, privateKey, providerConfig) => {\n      console.log(`Deploying ${contractName}...`);\n      try {\n        const web3 = createProvider(\n          providerConfig.rpc,\n          providerConfig.chainId,\n          providerConfig.name,\n        );\n\n        const formattedPrivateKey = privateKey.startsWith('0x') ? privateKey : `0x${privateKey}`;\n        const account = web3.eth.accounts.privateKeyToAccount(formattedPrivateKey);\n        web3.eth.accounts.wallet.add(account);\n        web3.eth.defaultAccount = account.address;\n\n        const abi = getAbi(contractName);\n        const bytecode = getByteCode(contractName);\n        const contract = new web3.eth.Contract(abi);\n        const deployTx = contract.deploy({\n          data: bytecode,\n        });\n\n        const gas = await deployTx.estimateGas();\n        const gasPrice = await web3.eth.getGasPrice();\n\n        console.log(`Estimated gas: ${gas}`);\n        console.log(`Gas price: ${web3.utils.fromWei(gasPrice, 'gwei')} gwei`);\n\n        const deployedContract = await deployTx.send({\n          from: account.address,\n          gas: gas,\n          gasPrice: gasPrice,\n        });\n\n        const address = deployedContract.options.address;\n        console.log(`Contract ${contractName} deployed at: ${address}`);\n\n        const addressesFile = join(scriptsDir, 'contract-address.json');\n        const addresses = existsSync(addressesFile)\n          ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n          : {};\n\n        addresses[contractName] = address;\n        writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n      } catch (error) {\n        console.error(`Failed to deploy contract ${contractName}:`, error);\n      }\n    };\n    ```\n\n5. Configure and execute the deployment:\n\n    ```js title=\"scripts/deploy.js\"\n    const providerConfig = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io', // TODO: replace to `https://services.polkadothub-rpc.com/testnet` when ready\n      chainId: 420420422,\n      name: 'polkadotTestNet',\n    };\n\n    const privateKey = 'INSERT_PRIVATE_KEY';\n\n    deployContract('Storage', privateKey, providerConfig);\n    ```\n\n    !!! note\n\n        A private key is a hexadecimal string that is used to sign and pay for the deployment transaction. **Always keep your private key secure and never share it publicly**.\n\n        Ensure to replace the `INSERT_PRIVATE_KEY` placeholder with your actual private key.\n\n??? code \"View complete script\"\n\n    ```js title=\"scripts/deploy.js\"\n    const { writeFileSync, existsSync, readFileSync } = require('fs');\n    const { join } = require('path');\n    const { Web3 } = require('web3');\n\n    const scriptsDir = __dirname;\n    const abisDir = join(__dirname, '../abis');\n    const artifactsDir = join(__dirname, '../artifacts');\n\n    const createProvider = (rpcUrl, chainId, chainName) => {\n      const web3 = new Web3(rpcUrl);\n      return web3;\n    };\n\n    const getAbi = (contractName) => {\n      try {\n        const abiPath = join(abisDir, `${contractName}.json`);\n        return JSON.parse(readFileSync(abiPath, 'utf8'));\n      } catch (error) {\n        console.error(\n          `Could not find ABI for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    const getByteCode = (contractName) => {\n      try {\n        const bytecodePath = join(artifactsDir, `${contractName}.bin`);\n        const bytecode = readFileSync(bytecodePath, 'utf8').trim();\n        return bytecode.startsWith('0x') ? bytecode : `0x${bytecode}`;\n      } catch (error) {\n        console.error(\n          `Could not find bytecode for contract ${contractName}:`,\n          error.message,\n        );\n        throw error;\n      }\n    };\n\n    const deployContract = async (contractName, privateKey, providerConfig) => {\n      console.log(`Deploying ${contractName}...`);\n      try {\n        const web3 = createProvider(\n          providerConfig.rpc,\n          providerConfig.chainId,\n          providerConfig.name,\n        );\n\n        const formattedPrivateKey = privateKey.startsWith('0x') ? privateKey : `0x${privateKey}`;\n        const account = web3.eth.accounts.privateKeyToAccount(formattedPrivateKey);\n        web3.eth.accounts.wallet.add(account);\n        web3.eth.defaultAccount = account.address;\n\n        const abi = getAbi(contractName);\n        const bytecode = getByteCode(contractName);\n        const contract = new web3.eth.Contract(abi);\n        const deployTx = contract.deploy({\n          data: bytecode,\n        });\n\n        const gas = await deployTx.estimateGas();\n        const gasPrice = await web3.eth.getGasPrice();\n\n        console.log(`Estimated gas: ${gas}`);\n        console.log(`Gas price: ${web3.utils.fromWei(gasPrice, 'gwei')} gwei`);\n\n        const deployedContract = await deployTx.send({\n          from: account.address,\n          gas: gas,\n          gasPrice: gasPrice,\n        });\n\n        const address = deployedContract.options.address;\n        console.log(`Contract ${contractName} deployed at: ${address}`);\n\n        const addressesFile = join(scriptsDir, 'contract-address.json');\n        const addresses = existsSync(addressesFile)\n          ? JSON.parse(readFileSync(addressesFile, 'utf8'))\n          : {};\n\n        addresses[contractName] = address;\n        writeFileSync(addressesFile, JSON.stringify(addresses, null, 2), 'utf8');\n      } catch (error) {\n        console.error(`Failed to deploy contract ${contractName}:`, error);\n      }\n    };\n\n    const providerConfig = {\n      rpc: 'https://testnet-passet-hub-eth-rpc.polkadot.io', // TODO: replace to `https://services.polkadothub-rpc.com/testnet` when ready\n      chainId: 420420422,\n      name: 'polkadotTestNet',\n    };\n\n    const privateKey = 'INSERT_PRIVATE_KEY';\n\n    deployContract('Storage', privateKey, providerConfig);\n\n\n    ```\n\nTo run the script, execute the following command:\n\n```bash\nnode scripts/deploy.js\n```\n\nAfter running this script, your contract will be deployed to Polkadot Hub, and its address will be saved in `contract-address.json` within your project directory. You can use this address for future contract interactions."}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 10, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 16998, "end_char": 19676, "estimated_token_count": 646, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nOnce the contract is deployed, you can interact with it by calling its functions. For example, to read the current stored value and then update it to a new value, you can create a file named `updateStorage.js` in the `scripts` directory of your project and add the following code:\n\n```js title=\"scripts/updateStorage.js\"\nconst { readFileSync } = require('fs');\nconst { join } = require('path');\nconst { Web3 } = require('web3');\n\nconst abisDir = join(__dirname, '../abis');\n\nconst getAbi = (contractName) => {\n  try {\n    const abiPath = join(abisDir, `${contractName}.json`);\n    return JSON.parse(readFileSync(abiPath, 'utf8'));\n  } catch (error) {\n    console.error(\n      `Could not find ABI for contract ${contractName}:`,\n      error.message,\n    );\n    throw error;\n  }\n};\n\nconst updateStorage = async (config) => {\n  try {\n    const web3 = new Web3(config.rpcUrl);\n    const formattedPrivateKey = config.privateKey.startsWith('0x') ? config.privateKey : `0x${config.privateKey}`;\n    const account = web3.eth.accounts.privateKeyToAccount(formattedPrivateKey);\n    web3.eth.accounts.wallet.add(account);\n\n    const abi = getAbi('Storage');\n    const contract = new web3.eth.Contract(abi, config.contractAddress);\n\n    const initialValue = await contract.methods.storedNumber().call();\n    console.log('Current stored value:', initialValue);\n\n    const updateTransaction = contract.methods.setNumber(1);\n    const gasEstimate = await updateTransaction.estimateGas({\n      from: account.address,\n    });\n    const gasPrice = await web3.eth.getGasPrice();\n\n    const receipt = await updateTransaction.send({\n      from: account.address,\n      gas: gasEstimate,\n      gasPrice: gasPrice,\n    });\n\n    console.log(`Transaction hash: ${receipt.transactionHash}`);\n\n    const newValue = await contract.methods.storedNumber().call();\n    console.log('New stored value:', newValue);\n\n    return receipt;\n  } catch (error) {\n    console.error('Update failed:', error);\n    throw error;\n  }\n};\n\nconst config = {\n  rpcUrl: 'https://testnet-passet-hub-eth-rpc.polkadot.io',\n  privateKey: 'INSERT_PRIVATE_KEY',\n  contractAddress: 'INSERT_CONTRACT_ADDRESS',\n};\n\nupdateStorage(config)\n  .then((receipt) => console.log('Update successful'))\n  .catch((error) => console.error('Update error'));\n```\n\nEnsure you replace the `INSERT_PRIVATE_KEY` and `INSERT_CONTRACT_ADDRESS` placeholders with actual values. Also, ensure the contract ABI file (`Storage.json`) is correctly referenced. The script reads the current stored value, sets it to 1, and then displays the updated value.\n\nTo interact with the contract, run:\n\n```bash\nnode scripts/updateStorage.js\n```"}
{"page_id": "smart-contracts-libraries-web3-js", "page_title": "Deploy Contracts to Polkadot Hub with Web3.js", "index": 11, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 19676, "end_char": 20077, "estimated_token_count": 110, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Web3.js Docs__\n\n    ---\n\n    Explore the Web3.js documentation to learn how to use additional features, such as wallet management, signing messages, subscribing to events, and more.\n\n    [:octicons-arrow-right-24: Get Started](https://web3js.readthedocs.io/en/v1.10.0/){target=\\_blank}\n\n</div>"}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 11, "end_char": 435, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nInteracting with blockchains typically requires an interface between your application and the network. [Web3.py](https://web3py.readthedocs.io/en/stable/index.html){target=\\_blank} offers this interface through a collection of libraries, facilitating seamless interaction with the nodes using HTTP or WebSocket protocols. \n\nThis guide illustrates how to utilize Web3.py for interactions with Polkadot Hub."}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 1, "depth": 2, "title": "Set Up the Project", "anchor": "set-up-the-project", "start_char": 435, "end_char": 816, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Set Up the Project\n\n1. To start working with Web3.py, begin by initializing your project:\n\n    ```bash\n    mkdir web3py-project\n    cd web3py-project\n    ```\n\n2. Create and activate a virtual environment for your project:\n\n    ```bash\n    python -m venv venv\n    source venv/bin/activate\n    ```\n\n3. Next, install the Web3.py library:\n\n    ```bash\n    pip install web3\n    ```"}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 2, "depth": 2, "title": "Set Up the Web3 Provider", "anchor": "set-up-the-web3-provider", "start_char": 816, "end_char": 2433, "estimated_token_count": 351, "token_estimator": "heuristic-v1", "text": "## Set Up the Web3 Provider\n\nThe [provider](https://web3py.readthedocs.io/en/stable/providers.html){target=\\_blank} configuration is the foundation of any Web3.py application.  It serves as a bridge between your application and the blockchain, allowing you to query blockchain data and interact with smart contracts.\n\nTo interact with Polkadot Hub, you must set up a Web3.py provider. This provider connects to a blockchain node, allowing you to query blockchain data and interact with smart contracts. The following code sets up the provider configuration:\n\n```python\nfrom web3 import Web3\n\nPROVIDER_RPC = \"INSERT_RPC_URL\"\nweb3 = Web3(Web3.HTTPProvider(PROVIDER_RPC))\n\n```\n\n!!! note\n    Replace `INSERT_RPC_URL` with the appropriate value. For instance, to connect to Polkadot Hub TestNet, use the following parameter:\n\n    ```python\n    PROVIDER_RPC = 'https://testnet-passet-hub-eth-rpc.polkadot.io'\n    ```\n\nWith the Web3 provider set up, start querying the blockchain. For instance, you can use the following code snippet to fetch the latest block number of the chain.\n\n??? code \"Fetch last block example\"\n\n    ```python title=\"fetch_last_block.py\"\n    from web3 import Web3\n\n\n    def main():\n        try:\n            PROVIDER_RPC = \"https://testnet-passet-hub-eth-rpc.polkadot.io\"\n            web3 = Web3(Web3.HTTPProvider(PROVIDER_RPC))\n            latest_block = web3.eth.block_number\n            print(\"Last block: \" + str(latest_block))\n        except Exception as error:\n            print(\"Error connecting to Polkadot Hub TestNet: \" + str(error))\n\n\n    if __name__ == \"__main__\":\n        main()\n\n    ```"}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 3, "depth": 2, "title": "Compile Contracts", "anchor": "compile-contracts", "start_char": 2433, "end_char": 2837, "estimated_token_count": 105, "token_estimator": "heuristic-v1", "text": "## Compile Contracts\n\nPolkadot Hub exposes an Ethereum JSON-RPC endpoint, so you can compile Solidity contracts to familiar EVM bytecode with the [`py-solc-x`](https://solcx.readthedocs.io/en/latest/){target=\\_blank} compiler. The resulting artifacts work with any EVM-compatible toolchain and can be deployed through Web3.py.\n\nFirst, install the `py-solc-x` package:\n\n```bash\npip install py-solc-x\n```"}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 4, "depth": 3, "title": "Sample Storage Smart Contract", "anchor": "sample-storage-smart-contract", "start_char": 2837, "end_char": 3652, "estimated_token_count": 169, "token_estimator": "heuristic-v1", "text": "### Sample Storage Smart Contract\n\nThis example demonstrates compiling a `Storage.sol` Solidity contract for deployment to Polkadot Hub. The contract's functionality stores a number and permits users to update it with a new value.\n\n```solidity title=\"Storage.sol\"\n//SPDX-License-Identifier: MIT\n\n// Solidity files have to start with this pragma.\n// It will be used by the Solidity compiler to validate its version.\npragma solidity ^0.8.9;\n\ncontract Storage {\n    // Public state variable to store a number\n    uint256 public storedNumber;\n\n    /**\n    * Updates the stored number.\n    *\n    * The `public` modifier allows anyone to call this function.\n    *\n    * @param _newNumber - The new value to store.\n    */\n    function setNumber(uint256 _newNumber) public {\n        storedNumber = _newNumber;\n    }\n}\n```"}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 5, "depth": 3, "title": "Compile the Smart Contract", "anchor": "compile-the-smart-contract", "start_char": 3652, "end_char": 5925, "estimated_token_count": 529, "token_estimator": "heuristic-v1", "text": "### Compile the Smart Contract\n\nTo compile this contract, create a Python script named `compile.py`:\n\n```python title=\"compile.py\"\nimport json\nimport solcx\nfrom pathlib import Path\n\nSOLC_VERSION = '0.8.9'\ntry:\n    solcx.install_solc(SOLC_VERSION)\nexcept Exception as e:\n    print(f\"Solc version {SOLC_VERSION} already installed or error: {e}\")\n\nsolcx.set_solc_version(SOLC_VERSION)\n\ncontract_path = Path('Storage.sol')\nwith open(contract_path, 'r') as file:\n    contract_source = file.read()\n\ncompiled_sol = solcx.compile_source(\n    contract_source,\n    output_values=['abi', 'bin'],\n    solc_version=SOLC_VERSION\n)\n\ncontract_id, contract_interface = compiled_sol.popitem()\n\nbytecode = contract_interface['bin']\nabi = contract_interface['abi']\n\nPath('abis').mkdir(exist_ok=True)\nPath('artifacts').mkdir(exist_ok=True)\n\nwith open('abis/Storage.json', 'w') as abi_file:\n    json.dump(abi, abi_file, indent=2)\n\nwith open('artifacts/Storage.bin', 'w') as bin_file:\n    bin_file.write(bytecode)\n\nprint(\"âœ… Contract compiled successfully!\")\nprint(f\"ðŸ“„ ABI saved to: abis/Storage.json\")\nprint(f\"ðŸ“¦ Bytecode saved to: artifacts/Storage.bin\")\n```\n\n!!! note \n    The script above is tailored to the `Storage.sol` contract. It can be adjusted for other contracts by changing the file name or modifying the ABI and bytecode paths.\n\nThe ABI (Application Binary Interface) is a JSON representation of your contract's functions, events, and their parameters. It serves as the interface between your Python code and the deployed smart contract, allowing your application to know how to format function calls and interpret returned data.\n\nExecute the script by running:\n\n```bash\npython compile.py\n```\n\nAfter executing the script, the Solidity contract is compiled into standard EVM bytecode. The ABI and bytecode are saved into files with `.json` and `.bin` extensions, respectively:\n\n- **ABI file (`abis/Storage.json`)**: Provides a JSON interface describing the contract's functions and how to interact with it.\n- **Bytecode file (`artifacts/Storage.bin`)**: Contains the low-level machine code executable on EVM that represents the compiled smart contract ready for blockchain deployment.\n\nYou can now proceed with deploying the contract to Polkadot Hub, as outlined in the next section."}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 6, "depth": 2, "title": "Contract Deployment", "anchor": "contract-deployment", "start_char": 5925, "end_char": 11250, "estimated_token_count": 1073, "token_estimator": "heuristic-v1", "text": "## Contract Deployment\n\nTo deploy your compiled contract to Polkadot Hub using Web3.py, you'll need an account with a private key to sign the deployment transaction. The deployment process is exactly the same as for any Ethereum-compatible chain, involving creating a contract instance, estimating gas, and sending a deployment transaction. Here's how to deploy the contract. ReplaceÂ `INSERT_RPC_URL`Â andÂ `INSERT_PRIVATE_KEY` with the appropriate values:\n\n```python title=\"deploy.py\"\nfrom web3 import Web3\nimport json\nimport time\nfrom pathlib import Path\n\nARTIFACTS_DIR = Path(__file__).parent\nABI_DIR = ARTIFACTS_DIR / \"abis\"\nBYTECODE_DIR = ARTIFACTS_DIR / \"artifacts\"\n\ndef get_abi(contract_name):\n    try:\n        with open(ABI_DIR / f\"{contract_name}.json\", 'r') as file:\n            return json.load(file)\n    except Exception as error:\n        print(f\"âŒ Could not find ABI for contract {contract_name}: {error}\")\n        raise error\n\ndef get_bytecode(contract_name):\n    try:\n        with open(BYTECODE_DIR / f\"{contract_name}.bin\", 'r') as file:\n            bytecode = file.read().strip()\n            return bytecode if bytecode.startswith('0x') else f\"0x{bytecode}\"\n    except Exception as error:\n        print(f\"âŒ Could not find bytecode for contract {contract_name}: {error}\")\n        raise error\n\ndef deploy_with_retry(config, max_retries=3):\n    \"\"\"Deploy with retry logic for RPC errors\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return deploy(config)\n        except Exception as error:\n            error_str = str(error)\n            if \"500\" in error_str or \"Internal Server Error\" in error_str or \"Connection\" in error_str:\n                if attempt < max_retries - 1:\n                    wait_time = (attempt + 1) * 3\n                    print(f\"RPC error, retrying in {wait_time} seconds... (attempt {attempt + 1}/{max_retries})\")\n                    time.sleep(wait_time)\n                    continue\n            raise error\n\ndef deploy(config):\n    try:\n        # Initialize Web3 with RPC URL and longer timeout\n        web3 = Web3(Web3.HTTPProvider(\n            config[\"rpc_url\"],\n            request_kwargs={'timeout': 120}\n        ))\n        \n        # Prepare account\n        formatted_private_key = config[\"private_key\"] if config[\"private_key\"].startswith('0x') else f\"0x{config['private_key']}\"\n        account = web3.eth.account.from_key(formatted_private_key)\n        print(f\"Deploying from address: {account.address}\")\n        \n        # Load ABI and bytecode\n        abi = get_abi('Storage')\n        bytecode = get_bytecode('Storage')\n        print(f\"Bytecode length: {len(bytecode)}\")\n        \n        # Create contract instance\n        contract = web3.eth.contract(abi=abi, bytecode=bytecode)\n        \n        # Get current nonce (this will test the connection)\n        print(\"Getting nonce...\")\n        nonce = web3.eth.get_transaction_count(account.address)\n        print(f\"Nonce: {nonce}\")\n        \n        # Estimate gas\n        print(\"Estimating gas...\")\n        gas_estimate = web3.eth.estimate_gas({\n            'from': account.address,\n            'data': bytecode\n        })\n        print(f\"Estimated gas: {gas_estimate}\")\n        \n        # Get gas price\n        print(\"Getting gas price...\")\n        gas_price = web3.eth.gas_price\n        print(f\"Gas price: {web3.from_wei(gas_price, 'gwei')} gwei\")\n        \n        # Build deployment transaction\n        print(\"Building transaction...\")\n        construct_txn = contract.constructor().build_transaction({\n            'from': account.address,\n            'nonce': nonce,\n            'gas': gas_estimate,\n            'gasPrice': gas_price,\n        })\n        \n        # Sign transaction\n        print(\"Signing transaction...\")\n        signed_txn = web3.eth.account.sign_transaction(construct_txn, private_key=formatted_private_key)\n        \n        # Send transaction\n        print(\"Sending transaction...\")\n        tx_hash = web3.eth.send_raw_transaction(signed_txn.raw_transaction)\n        print(f\"Transaction hash: {tx_hash.hex()}\")\n        \n        # Wait for transaction receipt\n        print(\"Waiting for transaction receipt...\")\n        tx_receipt = web3.eth.wait_for_transaction_receipt(tx_hash, timeout=300)\n        contract_address = tx_receipt.contractAddress\n        \n        # Log results\n        print(f\"âœ… Contract deployed at: {contract_address}\")\n        print(f\"Gas used: {tx_receipt.gasUsed}\")\n        print(f\"Block number: {tx_receipt.blockNumber}\")\n        \n        return web3.eth.contract(address=contract_address, abi=abi)\n    \n    except Exception as error:\n        print(f'âŒ Deployment failed: {error}')\n        raise error\n\nif __name__ == \"__main__\":\n    deployment_config = {\n        \"rpc_url\": \"https://testnet-passet-hub-eth-rpc.polkadot.io\",\n        \"private_key\": \"0xd505c673c48556d560696d129f0e611f041638cd42d81c33ddc0e490cdcf65fc\"\n    }\n    \n    deploy_with_retry(deployment_config)\n```\n\n!!!warning\n    Never commit or share your private key. Exposed keys can lead to immediate theft of all associated funds.\n\nTo run the script, execute the following command:\n\n```bash\npython deploy.py\n```\n\nAfter running this script, your contract will be deployed to Polkadot Hub, and its address will be printed in your terminal. You can use this address for future contract interactions."}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 7, "depth": 2, "title": "Interact with the Contract", "anchor": "interact-with-the-contract", "start_char": 11250, "end_char": 13697, "estimated_token_count": 483, "token_estimator": "heuristic-v1", "text": "## Interact with the Contract\n\nAfter deployment, interact with your contract using Web3.py methods. The example below demonstrates how to set and retrieve a number.\n\n```python title=\"update_storage.py\"\nfrom web3 import Web3\nimport json\n\n\ndef get_abi(contract_name):\n    try:\n        with open(f\"{contract_name}.json\", \"r\") as file:\n            return json.load(file)\n    except Exception as error:\n        print(f\"âŒ Could not find ABI for contract {contract_name}: {error}\")\n        raise error\n\n\nasync def update_storage(config):\n    try:\n        # Initialize Web3 with RPC URL\n        web3 = Web3(Web3.HTTPProvider(config[\"rpc_url\"]))\n\n        # Prepare account\n        account = web3.eth.account.from_key(config[\"private_key\"])\n\n        # Load ABI\n        abi = get_abi(\"Storage\")\n\n        # Create contract instance\n        contract = web3.eth.contract(address=config[\"contract_address\"], abi=abi)\n\n        # Get initial value\n        initial_value = contract.functions.storedNumber().call()\n        print(\"Current stored value:\", initial_value)\n\n        # Get current nonce\n        nonce = web3.eth.get_transaction_count(account.address)\n\n        # Prepare transaction\n        transaction = contract.functions.setNumber(1).build_transaction(\n            {\"from\": account.address, \"nonce\": nonce}\n        )\n\n        # Sign transaction\n        signed_txn = web3.eth.account.sign_transaction(\n            transaction, private_key=config[\"private_key\"]\n        )\n\n        # Send transaction\n        tx_hash = web3.eth.send_raw_transaction(signed_txn.raw_transaction)\n        print(f\"Transaction hash: {tx_hash.hex()}\")\n\n        # Wait for receipt\n        receipt = web3.eth.wait_for_transaction_receipt(tx_hash)\n\n        # Get updated value\n        new_value = contract.functions.storedNumber().call()\n        print(\"New stored value:\", new_value)\n\n        return receipt\n\n    except Exception as error:\n        print(\"Update failed:\", error)\n        raise error\n\n\nif __name__ == \"__main__\":\n    # Example usage\n    import asyncio\n\n    config = {\n        \"rpc_url\": \"INSERT_RPC_URL\",\n        \"private_key\": \"INSERT_PRIVATE_KEY\",\n        \"contract_address\": \"INSERT_CONTRACT_ADDRESS\",\n    }\n\n    asyncio.run(update_storage(config))\n\n```\n\nBe sure to replace the `INSERT_RPC_URL`, `INSERT_PRIVATE_KEY`, and `INSERT_CONTRACT_ADDRESS` placeholders with your specific values.\n\nTo interact with the contract, run:\n\n```bash\npython update_storage.py\n```"}
{"page_id": "smart-contracts-libraries-web3-py", "page_title": "Web3.py", "index": 8, "depth": 2, "title": "Where to Go Next", "anchor": "where-to-go-next", "start_char": 13697, "end_char": 14097, "estimated_token_count": 106, "token_estimator": "heuristic-v1", "text": "## Where to Go Next\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge external\">External</span> __Web3.py Docs__\n\n    ---\n\n    Explore the Web3.py documentation to learn how to use additional features, such as wallet management, signing messages, subscribing to events, and more.\n\n    [:octicons-arrow-right-24: Get Started](https://web3py.readthedocs.io/en/stable/){target=\\_blank}\n\n</div>"}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 35, "end_char": 710, "estimated_token_count": 103, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPolkadot Hub provides a production-ready smart contract platform that combines Ethereum compatibility with the performance and cross-chain capabilities of the Polkadot ecosystem. Developers can deploy smart contracts directly on Polkadot Hub while using familiar Ethereum tooling, workflows, and programming languages.\n\nBuilt with a dual-VM approach, Polkadot Hub offers two execution backends: REVM for unmodified EVM compatibility and native PolkaVM for optimized computationally expensive workloads. This dual-VM architecture enables developers to migrate existing Ethereum contracts instantly or optimize for speed and efficiency with native execution."}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 1, "depth": 2, "title": "Why Build on Polkadot Hub", "anchor": "why-build-on-polkadot-hub", "start_char": 710, "end_char": 740, "estimated_token_count": 7, "token_estimator": "heuristic-v1", "text": "## Why Build on Polkadot Hub"}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 2, "depth": 3, "title": "Ethereum Compatibility", "anchor": "ethereum-compatibility", "start_char": 740, "end_char": 1300, "estimated_token_count": 114, "token_estimator": "heuristic-v1", "text": "### Ethereum Compatibility\n\nDeploy existing Ethereum contracts with zero modifications while maintaining full compatibility with your existing development stack:\n\n- **Complete JSON-RPC API support**: Use MetaMask, Hardhat, Remix, Foundry, and all standard Ethereum tooling.\n- **Standard libraries**: Integrate Ethers.js, Web3.js, Viem, Wagmi, and Web3.py without changes.\n- **Solidity development**: Write contracts in Solidity or migrate existing code directly.\n- **Familiar workflows**: Maintain your existing deployment, testing, and monitoring processes."}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 3, "depth": 3, "title": "Performance Options", "anchor": "performance-options", "start_char": 1300, "end_char": 1823, "estimated_token_count": 102, "token_estimator": "heuristic-v1", "text": "### Performance Options\n\nChoose between two execution backends:\n\n- **REVM**: Run unmodified Ethereum contracts with full EVM/Ethereum compatibility.\n- **PolkaVM**: Compile to optimized RISC-V bytecode for enhanced performance and lower fees while keeping Ethereum-compatibility.\n\nBoth backends share the same RPC interface and tooling support, allowing seamless transitions. In addition, smart contracts can interact with Polkadot native services via [precompile contracts](/smart-contracts/precompiles/){target=\\_blank}."}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 4, "depth": 3, "title": "Cross-VM  & Cross-Chain Capabilities", "anchor": "cross-vm-cross-chain-capabilities", "start_char": 1823, "end_char": 2420, "estimated_token_count": 121, "token_estimator": "heuristic-v1", "text": "### Cross-VM  & Cross-Chain Capabilities\n\nSmart contracts written for one VM (for example, EVM) can interact directly with other smart contracts written for the RISC-V PolkaVM, and back. This allows to use full EVM compatible contracts but extend to heavy/complex execution workloads to the PolkaVM RISC-V backend.\n\nFurthermore, all smart contracts in Polkadot Hub can interact with any service in the Polkadot ecosystem through [XCM](/smart-contracts/precompiles/xcm/){target=\\_blank}, enabling token transfers, remote execution, and cross-chain composability without bridges or intermediaries."}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 5, "depth": 2, "title": "Other Smart Contract Environments", "anchor": "other-smart-contract-environments", "start_char": 2420, "end_char": 3436, "estimated_token_count": 214, "token_estimator": "heuristic-v1", "text": "## Other Smart Contract Environments\n\nBeyond Polkadot Hub's native PolkaVM support, the ecosystem offers two main alternatives for smart contract development:\n\n- **EVM-compatible parachains**: Provide access to Ethereum's extensive developer ecosystem, smart contract portability, and established tooling like Hardhat, Remix, Foundry, and OpenZeppelin. The main options include Moonbeam (the first full Ethereum-compatible parachain serving as an interoperability hub), Astar (featuring dual VM support for both EVM and WebAssembly contracts), and Acala (DeFi-focused with enhanced Acala EVM+ offering advanced DeFi primitives).\n\n- **Rust (ink!)**: ink! is a Rust-based framework that can compile to PolkaVM. It uses [`#[ink(...)]`](https://use.ink/docs/v6/macros-attributes/){target=\\_blank} attribute macros to create Polkadot SDK-compatible PolkaVM bytecode, offering strong memory safety from Rust, an advanced type system, high-performance PolkaVM execution, and platform independence with sandboxed security."}
{"page_id": "smart-contracts-overview", "page_title": "Smart Contracts Overview", "index": 6, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 3436, "end_char": 4446, "estimated_token_count": 254, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\n<div class=\"grid cards\" markdown>\n\n-   <span class=\"badge guide\">Guide</span> __Get Started__\n\n    ---\n\n    Quick-start guides for connecting, deploying, and building your first smart contract.\n\n    [:octicons-arrow-right-24: Get Started](/smart-contracts/get-started/)\n\n-   <span class=\"badge guide\">Guide</span> __Cookbook__\n\n    ---\n\n    Step-by-step tutorials for deploying contracts, tokens, NFTs, and full dApps.\n\n    [:octicons-arrow-right-24: View Tutorials](/smart-contracts/cookbook/)\n\n-   <span class=\"badge guide\">Guide</span> __Ethereum Developers__\n\n    ---\n\n    Understand key differences in accounts, fees, gas model, and deployment on Polkadot Hub.\n\n    [:octicons-arrow-right-24: Learn More](/smart-contracts/for-eth-devs/accounts/)\n\n-   <span class=\"badge guide\">Guide</span> __Precompiles__\n\n    ---\n\n    Discover advanced functionalities including XCM for cross-chain interactions.\n\n    [:octicons-arrow-right-24: Explore Precompiles](/smart-contracts/precompiles/)\n\n</div>"}
{"page_id": "smart-contracts-precompiles-eth-native", "page_title": "Ethereum-Native Precompiles", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 31, "end_char": 689, "estimated_token_count": 93, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nEthereum-native precompiles are special contract implementations that provide essential cryptographic and utility functions at the runtime level. These precompiles are available at predefined addresses and offer optimized, native implementations of commonly used operations that would be computationally expensive or impractical to implement in pure contract code.\n\nIn Polkadot Hub's Revive pallet, these precompiles maintain compatibility with standard Ethereum addresses, allowing developers familiar with Ethereum to seamlessly transition their smart contracts while benefiting from the performance optimizations of the PolkaVM runtime."}
{"page_id": "smart-contracts-precompiles-eth-native", "page_title": "Ethereum-Native Precompiles", "index": 1, "depth": 2, "title": "How to Use Precompiles", "anchor": "how-to-use-precompiles", "start_char": 689, "end_char": 1553, "estimated_token_count": 164, "token_estimator": "heuristic-v1", "text": "## How to Use Precompiles\n\nTo use a precompile in your smart contract, simply call the precompile's address as you would any other contract. Each precompile has a specific address (shown in the table below) and expects input data in a particular format. The precompile executes natively at the runtime level and returns the result directly to your contract.\n\nFor example, to use the ECRecover precompile to verify a signature, you would call address `0x0000000000000000000000000000000000000001` with the properly formatted signature data. The precompile handles the complex cryptographic operations efficiently and returns the recovered public key.\n\nYou can find sample contracts for each precompile in the [`precompiles-hardhat`](https://github.com/polkadot-developers/polkavm-hardhat-examples/tree/master/precompiles-hardhat/contracts){target=\\_blank} project."}
{"page_id": "smart-contracts-precompiles-eth-native", "page_title": "Ethereum-Native Precompiles", "index": 2, "depth": 2, "title": "Standard Precompiles in Polkadot Hub", "anchor": "standard-precompiles-in-polkadot-hub", "start_char": 1553, "end_char": 4789, "estimated_token_count": 873, "token_estimator": "heuristic-v1", "text": "## Standard Precompiles in Polkadot Hub\n\nRevive implements the standard set of Ethereum precompiles:\n\n|                                                                                   Contract Name                                                                                   | Address (Last Byte) |                                           Description                                           |\n| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------: | :---------------------------------------------------------------------------------------------: |\n|  [ECRecover](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/ecrecover.rs){target=\\_blank}   |        0x01         |                       Recovers the public key associated with a signature                       |\n|     [Sha256](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/sha256.rs){target=\\_blank}      |        0x02         |                              Implements the SHA-256 hash function                               |\n|  [Ripemd160](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/ripemd160.rs){target=\\_blank}   |        0x03         |                             Implements the RIPEMD-160 hash function                             |\n|   [Identity](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/identity.rs){target=\\_blank}    |        0x04         |                          Data copy function (returns input as output)                           |\n|     [Modexp](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/modexp.rs){target=\\_blank}      |        0x05         |                                     Modular exponentiation                                      |\n|   [Bn128Add](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/bn128.rs#L27){target=\\_blank}   |        0x06         |    Addition on the [alt_bn128 curve](https://eips.ethereum.org/EIPS/eip-196){target=\\_blank}    |\n|   [Bn128Mul](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/bn128.rs#L48){target=\\_blank}   |        0x07         | Multiplication on the [alt_bn128 curve](https://eips.ethereum.org/EIPS/eip-196){target=\\_blank} |\n| [Bn128Pairing](https://github.com/paritytech/polkadot-sdk/blob/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/bn128.rs#L69){target=\\_blank} |        0x08         |                              Pairing check on the alt_bn128 curve                               |\n|    [Blake2F](https://github.com/paritytech/polkadot-sdk/tree/polkadot-stable2503/substrate/frame/revive/src/pure_precompiles/blake2f.rs){target=\\_blank}     |        0x09         |                                  Blake2 compression function F                                  |"}
{"page_id": "smart-contracts-precompiles-eth-native", "page_title": "Ethereum-Native Precompiles", "index": 3, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 4789, "end_char": 5232, "estimated_token_count": 62, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nEthereum-native precompiles provide a powerful foundation for smart contract development on Polkadot Hub, offering high-performance implementations of essential cryptographic and utility functions. By maintaining compatibility with standard Ethereum precompile addresses and interfaces, Revive ensures that developers can leverage existing knowledge and tools while benefiting from the enhanced performance of native execution."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 18, "end_char": 909, "estimated_token_count": 189, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nThe [XCM (Cross-Consensus Message)](/parachains/interoperability/get-started/){target=\\_blank} precompile enables Polkadot Hub developers to access XCM functionality directly from their smart contracts using a Solidity interface.\n\nLocated at the fixed address `0x00000000000000000000000000000000000a0000`, the XCM precompile offers three primary functions:\n\n- **`execute`**: For local XCM execution.\n- **`send`**: For cross-chain message transmission.\n- **`weighMessage`**: For cost estimation.\n\nThis guide demonstrates how to interact with the XCM precompile through Solidity smart contracts using [Remix IDE](/smart-contracts/dev-environments/remix/){target=\\_blank}.\n\n!!!note\n    The XCM precompile provides the barebones XCM functionality. While it provides a lot of flexibility, it doesn't provide abstractions to hide away XCM details. These have to be built on top."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 1, "depth": 2, "title": "Precompile Interface", "anchor": "precompile-interface", "start_char": 909, "end_char": 4084, "estimated_token_count": 720, "token_estimator": "heuristic-v1", "text": "## Precompile Interface\n\nThe XCM precompile implements the `IXcm` interface, which defines the structure for interacting with XCM functionality. The source code for the interface is as follows:\n\n```solidity title=\"IXcm.sol\"\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n\n/// @dev The on-chain address of the XCM (Cross-Consensus Messaging) precompile.\naddress constant XCM_PRECOMPILE_ADDRESS = address(0xA0000);\n\n/// @title XCM Precompile Interface\n/// @notice A low-level interface for interacting with `pallet_xcm`.\n/// It forwards calls directly to the corresponding dispatchable functions,\n/// providing access to XCM execution and message passing.\n/// @dev Documentation:\n/// @dev - XCM: https://docs.polkadot.com/develop/interoperability\n/// @dev - SCALE codec: https://docs.polkadot.com/polkadot-protocol/parachain-basics/data-encoding\n/// @dev - Weights: https://docs.polkadot.com/polkadot-protocol/parachain-basics/blocks-transactions-fees/fees/#transactions-weights-and-fees\ninterface IXcm {\n    /// @notice Weight v2 used for measurement for an XCM execution\n    struct Weight {\n        /// @custom:property The computational time used to execute some logic based on reference hardware.\n        uint64 refTime;\n        /// @custom:property The size of the proof needed to execute some logic.\n        uint64 proofSize;\n    }\n\n    /// @notice Executes an XCM message locally on the current chain with the caller's origin.\n    /// @dev Internally calls `pallet_xcm::execute`.\n    /// @param message A SCALE-encoded Versioned XCM message.\n    /// @param weight The maximum allowed `Weight` for execution.\n    /// @dev Call @custom:function weighMessage(message) to ensure sufficient weight allocation.\n    function execute(bytes calldata message, Weight calldata weight) external;\n\n    /// @notice Sends an XCM message to another parachain or consensus system.\n    /// @dev Internally calls `pallet_xcm::send`.\n    /// @param destination SCALE-encoded destination MultiLocation.\n    /// @param message SCALE-encoded Versioned XCM message.\n    function send(bytes calldata destination, bytes calldata message) external;\n\n    /// @notice Estimates the `Weight` required to execute a given XCM message.\n    /// @param message SCALE-encoded Versioned XCM message to analyze.\n    /// @return weight Struct containing estimated `refTime` and `proofSize`.\n    function weighMessage(bytes calldata message) external view returns (Weight memory weight);\n}\n```\n\nThe interface defines a `Weight` struct that represents the computational cost of XCM operations. Weight has two components: \n\n- **`refTime`**: Computational time on reference hardware.\n- **`proofSize`**: The size of the proof required for execution.\n\nAll XCM messages must be encoded using the [SCALE codec](https://github.com/paritytech/parity-scale-codec?tab=readme-ov-file#parity-scale-codec){target=\\_blank}, Polkadot's standard serialization format.\n\n\n\nFor further information, check the [`precompiles/IXCM.sol`](https://github.com/paritytech/polkadot-sdk/blob/cb629d46ebf00aa65624013a61f9c69ebf02b0b4/polkadot/xcm/pallet-xcm/src/precompiles/IXcm.sol){target=\\_blank} file present in `pallet-xcm`."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 2, "depth": 2, "title": "Interact with the XCM Precompile", "anchor": "interact-with-the-xcm-precompile", "start_char": 4084, "end_char": 5225, "estimated_token_count": 286, "token_estimator": "heuristic-v1", "text": "## Interact with the XCM Precompile\n\nTo interact with the XCM precompile, you can use the precompile interface directly in [Remix IDE](/smart-contracts/dev-environments/remix/){target=\\_blank}:\n\n1. Create a new file called `IXcm.sol` in Remix.\n2. Copy and paste the `IXcm` interface code into the file.\n3. Compile the interface by selecting the button or using **Ctrl +S** keys:\n\n    ![](/images/smart-contracts/precompiles/xcm/xcm-01.webp)\n\n4. In the **Deploy & Run Transactions** tab, select the `IXcm` interface from the contract dropdown.\n5. Enter the precompile address `0x00000000000000000000000000000000000a0000` in the **At Address** input field.\n6. Select the **At Address** button to connect to the precompile.\n\n    ![](/images/smart-contracts/precompiles/xcm/xcm-02.webp)\n\n7. Once connected, you can use the Remix interface to interact with the XCM precompile's  `execute`, `send`, and `weighMessage` functions.\n\n    ![](/images/smart-contracts/precompiles/xcm/xcm-03.webp)\n\nThe main entrypoint of the precompile is the `execute` function. However, it's necessary to first call `weighMessage` to fill in the required parameters."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 3, "depth": 3, "title": "Weigh a Message", "anchor": "weigh-a-message", "start_char": 5225, "end_char": 7404, "estimated_token_count": 473, "token_estimator": "heuristic-v1", "text": "### Weigh a Message\n\nThe `weighMessage` function estimates the computational cost required to execute an XCM message. This estimate is crucial for understanding the resources needed before actually executing or sending a message.\n\nTo test this functionality in Remix, you can call `callWeighMessage` with a SCALE-encoded XCM message. For example, for testing, you can use the following encoded XCM message:\n\n```text title=\"encoded-xcm-message-example\"\n0x050c000401000003008c86471301000003008c8647000d010101000000010100368e8759910dab756d344995f1d3c79374ca8f70066d3a709e48029f6bf0ee7e\n```\n\n![](/images/smart-contracts/precompiles/xcm/xcm-04.webp)\n\nThis encoded message represents a sequence of XCM instructions:\n\n- **[Withdraw Asset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#withdrawasset){target=\\_blank}**: This instruction removes assets from the local chain's sovereign account or the caller's account, making them available for use in subsequent XCM instructions.\n- **[Buy Execution](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#buyexecution){target=\\_blank}**: This instruction purchases execution time on the destination chain using the withdrawn assets, ensuring the message can be processed.\n- **[Deposit Asset](https://github.com/polkadot-fellows/xcm-format?tab=readme-ov-file#depositasset){target=\\_blank}**: This instruction deposits the remaining assets into a specified account on the destination chain after execution costs have been deducted.\n\nThis encoded message is provided as an example. You can craft your own XCM message tailored to your specific use case as needed.\n\nThe function returns a `Weight` struct containing `refTime` and `proofSize` values, which indicate the estimated computational cost of executing this message. If successful, after calling the `callWeighMessage` function, you should see the `refTime` and `proofSize` of the message:\n\n![](/images/smart-contracts/precompiles/xcm/xcm-05.webp)\n\n!!!note\n    You can find many more examples of XCMs in this [gist](https://gist.github.com/franciscoaguirre/a6dea0c55e81faba65bedf700033a1a2){target=\\_blank}, which connects to the Polkadot Hub TestNet."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 4, "depth": 3, "title": "Execute a Message", "anchor": "execute-a-message", "start_char": 7404, "end_char": 8850, "estimated_token_count": 303, "token_estimator": "heuristic-v1", "text": "### Execute a Message\n\nThe `execute` function runs an XCM message locally using the caller's origin.\nThis function is the main entrypoint to cross-chain interactions.\n\nFollow these steps to execute a message:\n\n1. Call `weighMessage` with your message to get the required weight.\n2. Pass the same message bytes and the weight obtained from the previous step to `execute`.\nFor example, using the same message from the weighing example, you would call `execute` with:\n\n    - **`message`**: The encoded XCM message bytes.\n    - **`weight`**: The `Weight` struct returned from `weighMessage`.\n\n    You can use the [papi console](https://dev.papi.how/extrinsics#networkId=localhost&endpoint=wss%3A%2F%2Ftestnet-passet-hub.polkadot.io&data=0x1f03050c000401000003008c86471301000003008c8647000d010101000000010100368e8759910dab756d344995f1d3c79374ca8f70066d3a709e48029f6bf0ee7e0750c61e2901daad0600){target=\\_blank} to examine the complete extrinsic structure for this operation.\n\n3. On Remix, click on the **Transact** button to execute the XCM message:\n  \n    ![](/images/smart-contracts/precompiles/xcm/xcm-06.webp)\n\n    If successful, you will see the following output in the Remix terminal:\n\n    ![](/images/smart-contracts/precompiles/xcm/xcm-07.webp)\n\nAdditionally, you can verify that the execution of this specific message was successful by checking that the beneficiary account associated with the XCM message has received the funds accordingly."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 5, "depth": 3, "title": "Send a Message", "anchor": "send-a-message", "start_char": 8850, "end_char": 9576, "estimated_token_count": 143, "token_estimator": "heuristic-v1", "text": "### Send a Message\n\nWhile most cross-chain operations can be performed via `execute`, `send` is sometimes necessary, for example, when opening HRMP channels.\n\nTo send a message:\n\n1. Prepare your destination location encoded in XCM format.\n2. Prepare your XCM message (similar to the execute example).\n3. Call `send` with both parameters.\n\nThe destination parameter must be encoded according to XCM's location format, specifying the target parachain or consensus system. The message parameter contains the XCM instructions to be executed on the destination chain.\n\nUnlike `execute`, the `send` function doesn't require a weight parameter since the destination chain will handle execution costs according to its fee structure."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 6, "depth": 2, "title": "Cross Contract Calls", "anchor": "cross-contract-calls", "start_char": 9576, "end_char": 10074, "estimated_token_count": 83, "token_estimator": "heuristic-v1", "text": "## Cross Contract Calls\n\nBeyond direct interaction and wrapper contracts, you can integrate XCM functionality directly into your existing smart contracts by inheriting from or importing the `IXcm` interface. This approach enables you to embed cross-chain capabilities into your application logic seamlessly.\n\nWhether you're building DeFi protocols, governance systems, or any application requiring cross-chain coordination, you can incorporate XCM calls directly within your contract's functions."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 7, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 10074, "end_char": 10381, "estimated_token_count": 50, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nThe XCM precompile provides a simple yet powerful interface for cross-chain interactions within the Polkadot ecosystem and beyond.\nBy building and executing XCM programs, developers can build cross-chain applications that leverage the full potential of Polkadot's interoperability features."}
{"page_id": "smart-contracts-precompiles-xcm", "page_title": "Interact with the XCM Precompile", "index": 8, "depth": 2, "title": "Next Steps", "anchor": "next-steps", "start_char": 10381, "end_char": 10622, "estimated_token_count": 55, "token_estimator": "heuristic-v1", "text": "## Next Steps\n\nHead to the Polkadot Hub TestNet and start playing around with the precompile using [Hardhat](/smart-contracts/dev-environments/hardhat/){target=\\_blank}.\n\nYou can use PAPI to build XCM programs and test them with Chopsticks."}
{"page_id": "smart-contracts-precompiles", "page_title": "Advanced Functionalities via Precompiles", "index": 0, "depth": 2, "title": "Introduction", "anchor": "introduction", "start_char": 44, "end_char": 622, "estimated_token_count": 91, "token_estimator": "heuristic-v1", "text": "## Introduction\n\nPrecompiles serve a dual purpose in the Polkadot ecosystem: they not only enable high-performance smart contracts by providing native, optimized implementations of frequently used functions but will also eventually act as critical bridges, allowing contracts to interact with core platform capabilities.\n\nThis article explores how Polkadot leverages precompiles within the Revive pallet to enhance efficiency and how they will extend functionality for developers in the future, including planned access to native features like Cross-Consensus Messaging (XCM)."}
{"page_id": "smart-contracts-precompiles", "page_title": "Advanced Functionalities via Precompiles", "index": 1, "depth": 2, "title": "What are Precompiles?", "anchor": "what-are-precompiles", "start_char": 622, "end_char": 1796, "estimated_token_count": 233, "token_estimator": "heuristic-v1", "text": "## What are Precompiles?\n\nPrecompiles are special contract implementations that run directly at the runtime level rather than as on-chain PolkaVM contracts. In typical EVM environments, precompiles provide essential cryptographic and utility functionality at addresses that start with specific patterns. Revive follows this design pattern but with its own implementation optimized for PolkaVM.\n\nUsers interact with the dApp/contract, which in turn calls the PolkaVM. The PolkaVM detects the precompile address and calls the corresponding precompile. The precompile executes the native code and returns the result to the dApp/contract. The dApp/contract then returns the result to the user.\n\n```mermaid\nflowchart LR\n    User([\"User\"])\n    dApp[\"DApp/Contract\"]\n    PolkaVM[\"ETH RPC Adapter\"]\n    Precompiles[\"Precompiles\"]\n    Runtime[\"PolkaVM\"]\n\n    User --> dApp\n    dApp -->|\"Call<br>function\"| PolkaVM\n    PolkaVM -->|\"Detect<br>precompile<br>address\"| Precompiles\n    Precompiles -->|\"Execute<br>optimized<br>native code\"| Runtime\n\n    subgraph \"Polkadot Hub\"\n        PolkaVM\n        Precompiles\n        Runtime\n    end\n\n    classDef edgeLabel background:#eceff3;\n```"}
{"page_id": "smart-contracts-precompiles", "page_title": "Advanced Functionalities via Precompiles", "index": 2, "depth": 2, "title": "Conclusion", "anchor": "conclusion", "start_char": 1796, "end_char": 2355, "estimated_token_count": 88, "token_estimator": "heuristic-v1", "text": "## Conclusion\n\nFor smart contract developers, precompiles offer a powerful way to access both low-level, high-performance operations and core platform capabilities within the smart contract execution context. Through Revive, Polkadot exposes these native functionalities, allowing developers to build faster, more efficient contracts that can take full advantage of the Polkadot ecosystem.\n\nUnderstanding and utilizing precompiles can unlock advanced functionality and performance gains, making them an essential tool for anyone building on the Polkadot Hub."}
